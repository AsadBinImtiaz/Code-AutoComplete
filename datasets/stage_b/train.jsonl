{"input": "CDK class SqsEventSourceTest for AWS resource management", "output": "class SqsEventSourceTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const fn = new TestFunction(this, 'F');\n    const topic = new sns.Topic(this, 'T');\n\n    fn.addEventSource(new SnsEventSource(topic));\n  }\n}", "language": "typescript"}
{"input": "CDK class TransitGatewayBlackholeRoute for AWS resource management", "output": "export class TransitGatewayBlackholeRoute extends TransitGatewayRouteBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.TransitGatewayBlackholeRoute';\n  public readonly routeTable: ITransitGatewayRouteTable;\n  public readonly destinationCidrBlock: string;\n\n  constructor(scope: Construct, id: string, props: TransitGatewayBlackholeRouteProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnTransitGatewayRoute(this, id, {\n      blackhole: true,\n      destinationCidrBlock: props.destinationCidrBlock,\n      transitGatewayRouteTableId: props.transitGatewayRouteTable.routeTableId,\n    });\n\n    this.node.defaultChild = resource;\n    this.destinationCidrBlock = resource.destinationCidrBlock;\n    this.routeTable = props.transitGatewayRouteTable;\n  }\n}", "language": "typescript"}
{"input": "Represents an HTTPS record value.", "output": "export class HttpsRecordValue extends SvcbRecordValueBase {\n  /**\n   * An HTTPS AliasMode record value.\n   *\n   * @param targetName The domain name of the alternative endpoint.\n   */\n  public static alias(targetName: string): HttpsRecordValue {\n    return new HttpsRecordValue({ priority: 0, targetName });\n  }\n\n  /**\n   * An HTTPS ServiceMode record value.\n   */\n  public static service(props?: HttpsRecordServiceModeProps): HttpsRecordValue {\n    return new HttpsRecordValue({ priority: 1, targetName: '.', ...props });\n  }\n\n  private constructor(props: SvcbRecordValueBaseProps) {\n    super(props);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, MSK (Kafka), CloudFormation, ECS resources", "output": "class ManifestStack extends cdk.Stack {\n      constructor(scope: Construct, id: string, props: cdk.StackProps & { cluster: eks.Cluster }) {\n        super(scope, id, props);\n\n        // this role creates a dependency between this stack and the cluster stack\n        const role = new iam.Role(this, 'CrossRole', {\n          assumedBy: new iam.ServicePrincipal('sqs.amazonaws.com'),\n          roleName: props.cluster.clusterArn,\n        });\n\n        // make sure this manifest doesn't create a dependency between the cluster stack\n        // and this stack\n        new eks.KubernetesManifest(this, 'cross-stack', {\n          manifest: [{\n            kind: 'ConfigMap',\n            apiVersion: 'v1',\n            metadata: {\n              name: 'config-map',\n            },\n            data: {\n              foo: role.roleArn,\n            },\n          }],\n          cluster: props.cluster,\n        });\n      }\n    }\n\n    const { app } = testFixture();\n    const clusterStack = new ClusterStack(app, 'ClusterStack');\n    new ManifestStack(app, 'ManifestStack', { cluster: clusterStack.eksCluster });\n\n    // make sure we can synth (no circular dependencies between the stacks)\n    app.synth();\n  });\n\n  test('can declare a chart with a token from a different stack than the cluster that depends on the cluster stack', () => {\n    class ClusterStack extends cdk.Stack {\n      public eksCluster: eks.Cluster;\n\n      constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n        super(scope, id, props);\n        this.eksCluster = new eks.Cluster(this, 'Cluster', {\n          version: CLUSTER_VERSION,\n          prune: false,\n          kubectlLayer: new KubectlV31Layer(this, 'KubectlLayer'),\n        });\n      }\n    }\n\n    class ChartStack extends cdk.Stack {\n      constructor(scope: Construct, id: string, props: cdk.StackProps & { cluster: eks.Cluster }) {\n        super(scope, id, props);\n\n        // this role creates a dependency between this stack and the cluster stack\n        const role = new iam.Role(this, 'CrossRole', {\n          assumedBy: new iam.ServicePrincipal('sqs.amazonaws.com'),\n          roleName: props.cluster.clusterArn,\n        });\n\n        // make sure this chart doesn't create a dependency between the cluster stack\n        // and this stack\n        new eks.HelmChart(this, 'cross-stack', {\n          chart: role.roleArn,\n          cluster: props.cluster,\n        });\n      }\n    }", "language": "typescript"}
{"input": "Network configuration for the Browser tool.", "output": "export class BrowserNetworkConfiguration extends NetworkConfiguration {\n  /**\n   * Creates a public network configuration. PUBLIC is the default network mode.\n   * @returns A BrowserNetworkConfiguration.\n   * Run this tool to operate in a public environment with internet access, suitable for less sensitive or open-use scenarios.\n   */\n  public static usingPublicNetwork(): BrowserNetworkConfiguration {\n    return new BrowserNetworkConfiguration('PUBLIC');\n  }\n\n  /**\n   * Creates a network configuration from a VPC configuration.\n   * @param vpcConfig - The VPC configuration.\n   * @returns A BrowserNetworkConfiguration.\n   */\n  public static usingVpc(scope: Construct, vpcConfig: VpcConfigProps): BrowserNetworkConfiguration {\n    return new BrowserNetworkConfiguration('VPC', scope, vpcConfig);\n  }\n\n  /**\n   * Renders the network configuration as a CloudFormation property.\n   * @param browserConnections - The connections object to the browser.\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(browserConnections?: ec2.Connections): CfnBrowserCustom.BrowserNetworkConfigurationProperty {\n    return {\n      networkMode: this.networkMode,\n      vpcConfig: (this.networkMode === 'VPC' && browserConnections) ? {\n        subnets: this.vpcSubnets?.subnets?.map(subnet => subnet.subnetId) ?? [],\n        securityGroups: browserConnections?.securityGroups?.map(s => s.securityGroupId) ?? [],\n      } : undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "How existing instances should be updated", "output": "class UpdatePolicy {\n  /**\n   * Create a new AutoScalingGroup and switch over to it\n   */\n  public static replacingUpdate(): UpdatePolicy {\n    return new class extends UpdatePolicy {\n      public _renderUpdatePolicy(): CfnUpdatePolicy {\n        return {\n          autoScalingReplacingUpdate: { willReplace: true },\n        };\n      }\n    }();\n  }\n\n  /**\n   * Replace the instances in the AutoScalingGroup one by one, or in batches\n   */\n  public static rollingUpdate(options: RollingUpdateOptions = {}): UpdatePolicy {\n    const minSuccessPercentage = validatePercentage(options.minSuccessPercentage);\n\n    return new class extends UpdatePolicy {\n      public _renderUpdatePolicy(renderOptions: RenderUpdateOptions): CfnUpdatePolicy {\n        return {\n          autoScalingRollingUpdate: {\n            maxBatchSize: options.maxBatchSize,\n            minInstancesInService: options.minInstancesInService,\n            suspendProcesses: options.suspendProcesses ?? DEFAULT_SUSPEND_PROCESSES,\n            minSuccessfulInstancesPercent:\n              minSuccessPercentage ?? renderOptions.creationPolicy?.autoScalingCreationPolicy?.minSuccessfulInstancesPercent,\n            waitOnResourceSignals: options.waitOnResourceSignals ?? renderOptions.creationPolicy?.resourceSignal !== undefined ? true : undefined,\n            pauseTime: options.pauseTime?.toIsoString() ?? renderOptions.creationPolicy?.resourceSignal?.timeout,\n          },\n        };\n      }\n    }();\n  }\n\n  /**\n   * Render the ASG's CreationPolicy\n   * @internal\n   */\n  public abstract _renderUpdatePolicy(renderOptions: RenderUpdateOptions): CfnUpdatePolicy;\n}\n\n/**\n * Options for rendering UpdatePolicy\n */\ninterface RenderUpdateOptions {\n  /**\n   * The Creation Policy already created\n   *\n   * @default - no CreationPolicy configured\n   */\n  readonly creationPolicy?: CfnCreationPolicy;\n}\n\n/**\n * Options for customizing the rolling update\n */\nexport interface RollingUpdateOptions {\n  /**\n   * The maximum number of instances that AWS CloudFormation updates at once.\n   *\n   * This number affects the speed of the replacement.\n   *\n   * @default 1\n   */\n  readonly maxBatchSize?: number;\n\n  /**\n   * The minimum number of instances that must be in service before more instances are replaced.\n   *\n   * This number affects the speed of the replacement.\n   *\n   * @default 0\n   */\n  readonly minInstancesInService?: number;\n\n  /**\n   * Specifies the Auto Scaling processes to suspend during a stack update.\n   *\n   * Suspending processes prevents Auto Scaling from interfering with a stack\n   * update.\n   *\n   * @default HealthCheck, ReplaceUnhealthy, AZRebalance, AlarmNotification, ScheduledActions.\n   */\n  readonly suspendProcesses?: ScalingProcess[];\n\n  /**\n   * Specifies whether the Auto Scaling group waits on signals from new instances during an update.\n   *\n   * @default true if you configured `signals` on the AutoScalingGroup, false otherwise\n   */\n  readonly waitOnResourceSignals?: boolean;\n\n  /**\n   * The pause time after making a change to a batch of instances.\n   *\n   * @default - The `timeout` configured for `signals` on the AutoScalingGroup\n   */\n  readonly pauseTime?: Duration;\n\n  /**\n   * The percentage of instances that must signal success for the update to succeed.\n   *\n   * @default - The `minSuccessPercentage` configured for `signals` on the AutoScalingGroup\n   */\n  readonly minSuccessPercentage?: number;\n}\n\n/**\n * A set of group metrics\n */\nexport class GroupMetrics {\n  /**\n   * Report all group metrics.\n   */\n  public static all(): GroupMetrics {\n    return new GroupMetrics();\n  }\n\n  /**\n   * @internal\n   */\n  public _metrics = new Set<GroupMetric>();\n\n  constructor(...metrics: GroupMetric[]) {\n    metrics?.forEach(metric => this._metrics.add(metric));\n  }\n}\n\n/**\n * Group metrics that an Auto Scaling group sends to Amazon CloudWatch.\n */\nexport class GroupMetric {\n  /**\n   * The minimum size of the Auto Scaling group\n   */\n  public static readonly MIN_SIZE = new GroupMetric('GroupMinSize');\n\n  /**\n   * The maximum size of the Auto Scaling group\n   */\n  public static readonly MAX_SIZE = new GroupMetric('GroupMaxSize');\n\n  /**\n   * The number of instances that the Auto Scaling group attempts to maintain\n   */\n  public static readonly DESIRED_CAPACITY = new GroupMetric('GroupDesiredCapacity');\n\n  /**\n   * The number of instances that are running as part of the Auto Scaling group\n   * This metric does not include instances that are pending or terminating\n   */\n  public static readonly IN_SERVICE_INSTANCES = new GroupMetric('GroupInServiceInstances');\n\n  /**\n   * The number of instances that are pending\n   * A pending instance is not yet in service, this metric does not include instances that are in service or terminating\n   */\n  public static readonly PENDING_INSTANCES = new GroupMetric('GroupPendingInstances');\n\n  /**\n   * The number of instances that are in a Standby state\n   * Instances in this state are still running but are not actively in service\n   */\n  public static readonly STANDBY_INSTANCES = new GroupMetric('GroupStandbyInstances');\n\n  /**\n   * The number of instances that are in the process of terminating\n   * This metric does not include instances that are in service or pending\n   */\n  public static readonly TERMINATING_INSTANCES = new GroupMetric('GroupTerminatingInstances');\n\n  /**\n   * The total number of instances in the Auto Scaling group\n   * This metric identifies the number of instances that are in service, pending, and terminating\n   */\n  public static readonly TOTAL_INSTANCES = new GroupMetric('GroupTotalInstances');\n\n  /**\n   * The name of the group metric\n   */\n  public readonly name: string;\n\n  constructor(name: string) {\n    this.name = name;\n  }\n}\n\n/**\n * The strategies for when launches fail in an Availability Zone.\n */\nexport enum CapacityDistributionStrategy {\n  /**\n   * If launches fail in an Availability Zone, Auto Scaling will continue to attempt to launch in the unhealthy zone to preserve a balanced distribution.\n   */\n  BALANCED_ONLY = 'balanced-only',\n  /**\n   * If launches fail in an Availability Zone, Auto Scaling will attempt to launch in another healthy Availability Zone instead.\n   */\n  BALANCED_BEST_EFFORT = 'balanced-best-effort',\n}\n\nabstract class AutoScalingGroupBase extends Resource implements IAutoScalingGroup {\n  public abstract autoScalingGroupName: string;\n  public abstract autoScalingGroupArn: string;\n  public abstract readonly osType: ec2.OperatingSystemType;\n  protected albTargetGroup?: elbv2.ApplicationTargetGroup;\n  public readonly grantPrincipal: iam.IPrincipal = new iam.UnknownPrincipal({ resource: this });\n  protected hasCalledScaleOnRequestCount: boolean = false;\n\n  public get autoScalingGroupRef(): AutoScalingGroupReference {\n    return {\n      autoScalingGroupName: this.autoScalingGroupName,\n      autoScalingGroupArn: this.autoScalingGroupArn,\n    };\n  }\n\n  /**\n   * Send a message to either an SQS queue or SNS topic when instances launch or terminate\n   */\n  public addLifecycleHook(id: string, props: BasicLifecycleHookProps): LifecycleHook {\n    return new LifecycleHook(this, `LifecycleHook${id}`, {\n      autoScalingGroup: this,\n      ...props,\n    });\n  }\n\n  /**\n   * Add a pool of pre-initialized EC2 instances that sits alongside an Auto Scaling group\n   */\n  public addWarmPool(options?: WarmPoolOptions): WarmPool {\n    return new WarmPool(this, 'WarmPool', {\n      autoScalingGroup: this,\n      ...options,\n    });\n  }\n\n  /**\n   * Scale out or in based on time\n   */\n  public scaleOnSchedule(id: string, props: BasicScheduledActionProps): ScheduledAction {\n    return new ScheduledAction(this, `ScheduledAction${id}`, {\n      autoScalingGroup: this,\n      ...props,\n    });\n  }\n\n  /**\n   * Scale out or in to achieve a target CPU utilization\n   */\n  public scaleOnCpuUtilization(id: string, props: CpuUtilizationScalingProps): TargetTrackingScalingPolicy {\n    return new TargetTrackingScalingPolicy(this, `ScalingPolicy${id}`, {\n      autoScalingGroup: this,\n      predefinedMetric: PredefinedMetric.ASG_AVERAGE_CPU_UTILIZATION,\n      targetValue: props.targetUtilizationPercent,\n      ...props,\n    });\n  }\n\n  /**\n   * Scale out or in to achieve a target network ingress rate\n   */\n  public scaleOnIncomingBytes(id: string, props: NetworkUtilizationScalingProps): TargetTrackingScalingPolicy {\n    return new TargetTrackingScalingPolicy(this, `ScalingPolicy${id}`, {\n      autoScalingGroup: this,\n      predefinedMetric: PredefinedMetric.ASG_AVERAGE_NETWORK_IN,\n      targetValue: props.targetBytesPerSecond,\n      ...props,\n    });\n  }\n\n  /**\n   * Scale out or in to achieve a target network egress rate\n   */\n  public scaleOnOutgoingBytes(id: string, props: NetworkUtilizationScalingProps): TargetTrackingScalingPolicy {\n    return new TargetTrackingScalingPolicy(this, `ScalingPolicy${id}`, {\n      autoScalingGroup: this,\n      predefinedMetric: PredefinedMetric.ASG_AVERAGE_NETWORK_OUT,\n      targetValue: props.targetBytesPerSecond,\n      ...props,\n    });\n  }\n\n  /**\n   * Scale out or in to achieve a target request handling rate\n   *\n   * The AutoScalingGroup must have been attached to an Application Load Balancer\n   * in order to be able to call this.\n   */\n  public scaleOnRequestCount(id: string, props: RequestCountScalingProps): TargetTrackingScalingPolicy {\n    if (this.albTargetGroup === undefined) {\n      throw new ValidationError('Attach the AutoScalingGroup to a non-imported Application Load Balancer before calling scaleOnRequestCount()', this);\n    }\n\n    const resourceLabel = `${this.albTargetGroup.firstLoadBalancerFullName}/${this.albTargetGroup.targetGroupFullName}`;\n\n    if ((props.targetRequestsPerMinute === undefined) === (props.targetRequestsPerSecond === undefined)) {\n      throw new ValidationError('Specify exactly one of \\'targetRequestsPerMinute\\' or \\'targetRequestsPerSecond\\'', this);\n    }", "language": "typescript"}
{"input": "CDK class TableBucketPolicy for AWS resource management", "output": "export class TableBucketPolicy extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-s3tables-alpha.TableBucketPolicy';\n  /**\n   * The IAM PolicyDocument containing permissions represented by this policy.\n   */\n  public readonly document: iam.PolicyDocument;\n  /**\n   * @internal The underlying policy resource.\n   */\n  private readonly _resource: CfnTableBucketPolicy;\n\n  constructor(scope: Construct, id: string, props: TableBucketPolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Use default policy if not provided with props\n    this.document = props.resourcePolicy || new iam.PolicyDocument({});\n\n    this._resource = new CfnTableBucketPolicy(this, id, {\n      tableBucketArn: props.tableBucket.tableBucketArn,\n      resourcePolicy: this.document,\n    });\n\n    if (props.removalPolicy) {\n      this._resource.applyRemovalPolicy(props.removalPolicy);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class MixinsBuilder for AWS resource management", "output": "export class MixinsBuilder extends LibraryBuilder<MixinsServiceModule> {\n  private readonly filePattern: string;\n\n  public constructor(props: MixinsBuilderProps) {\n    super(props);\n    this.filePattern = '%moduleName%/cfn-props-mixins.generated.ts';\n  }\n\n  protected createServiceSubmodule(service: Service, submoduleName: string): MixinsServiceModule {\n    return new MixinsServiceModule({\n      submoduleName,\n      service,\n    });\n  }\n\n  protected addResourceToSubmodule(submodule: MixinsServiceModule, resource: Resource, _props?: AddServiceProps): void {\n    const service = this.db.incoming('hasResource', resource).only().entity;\n    const mixins = this.obtainMixinsModule(submodule, service);\n\n    const l1PropsMixin = new L1PropsMixin(mixins.module, this.db, resource, submodule.constructLibModule);\n    submodule.registerResource(resource.cloudFormationType, l1PropsMixin);\n\n    l1PropsMixin.build();\n  }\n\n  private createMixinsModule(submodule: MixinsServiceModule, service: Service): LocatedModule<Module> {\n    const module = new Module(`@aws-cdk/mixins-preview/${submodule.submoduleName}/mixins`);\n    const filePath = this.pathFor(this.filePattern, submodule.submoduleName, service);\n\n    submodule.registerModule({ module, filePath });\n\n    CDK_CORE.import(module, 'cdk');\n    CONSTRUCTS.import(module, 'constructs');\n    MIXINS_CORE.import(module, 'core', { fromLocation: relativeImportPath(filePath, '../core') });\n    MIXINS_COMMON.import(module, 'mixins', { fromLocation: '../../mixins' });\n    MIXINS_UTILS.import(module, 'helpers', { fromLocation: '../../util/property-mixins' });\n    submodule.constructLibModule.import(module, 'service');\n\n    return { module, filePath };\n  }\n\n  private obtainMixinsModule(submodule: MixinsServiceModule, service: Service): LocatedModule<Module> {\n    const mod = this.createMixinsModule(submodule, service);\n    if (this.modules.has(mod.filePath)) {\n      return {\n        module: this.modules.get(mod.filePath)!,\n        filePath: mod.filePath,\n      };\n    }\n\n    return this.rememberModule(mod);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates SNS, CloudFormation resources", "output": "class TestProductStack extends servicecatalog.ProductStack {\n  constructor(scope: any, id: string) {\n    super(scope, id);\n\n    new sns.Topic(this, 'TopicProduct');\n  }\n}", "language": "typescript"}
{"input": "CDK class Environment for AWS resource management", "output": "export class Environment extends EnvironmentBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appconfig.Environment';\n\n  /**\n   * Imports an environment into the CDK using its Amazon Resource Name (ARN).\n   *\n   * @param scope The parent construct\n   * @param id The name of the environment construct\n   * @param environmentArn The Amazon Resource Name (ARN) of the environment\n   */\n  public static fromEnvironmentArn(scope: Construct, id: string, environmentArn: string): IEnvironment {\n    const parsedArn = Stack.of(scope).splitArn(environmentArn, ArnFormat.SLASH_RESOURCE_NAME);\n    if (!parsedArn.resourceName) {\n      throw new ValidationError(`Missing required /$/{applicationId}/environment//$/{environmentId} from environment ARN: ${parsedArn.resourceName}`, scope);\n    }\n\n    const resourceName = parsedArn.resourceName.split('/');\n    if (resourceName.length != 3 || !resourceName[0] || !resourceName[2]) {\n      throw new ValidationError('Missing required parameters for environment ARN: format should be /$/{applicationId}/environment//$/{environmentId}', scope);\n    }\n\n    const applicationId = resourceName[0];\n    const environmentId = resourceName[2];\n\n    class Import extends EnvironmentBase {\n      public readonly applicationId = applicationId;\n      public readonly environmentId = environmentId;\n      public readonly environmentArn = environmentArn;\n      public readonly name?: string;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: environmentArn,\n    });\n  }\n\n  /**\n   * Imports an environment into the CDK from its attributes.\n   *\n   * @param scope The parent construct\n   * @param id The name of the environment construct\n   * @param attrs The attributes of the environment\n   */\n  public static fromEnvironmentAttributes(scope: Construct, id: string, attrs: EnvironmentAttributes): IEnvironment {\n    const applicationId = attrs.application.applicationId;\n    const environmentId = attrs.environmentId;\n\n    const stack = Stack.of(scope);\n    const environmentArn = stack.formatArn({\n      service: 'appconfig',\n      resource: 'application',\n      resourceName: `${applicationId}/environment/${environmentId}`,\n    });\n\n    class Import extends EnvironmentBase {\n      public readonly application = attrs.application;\n      public readonly applicationId = attrs.application.applicationId;\n      public readonly name = attrs.name;\n      public readonly environmentId = environmentId;\n      public readonly environmentArn = environmentArn;\n      public readonly description = attrs.description;\n      public readonly monitors = attrs.monitors;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: environmentArn,\n    });\n  }\n\n  /**\n   * The application associated with the environment.\n   */\n  public readonly application?: IApplication;\n\n  /**\n   * The name of the environment.\n   */\n  public readonly name?: string;\n\n  /**\n   * The description of the environment.\n   */\n  public readonly description?: string;\n\n  /**\n   * The monitors for the environment.\n   */\n  public readonly monitors?: Monitor[];\n\n  /**\n   * The ID of the environment.\n   *\n   * @attribute\n   */\n  public readonly environmentId: string;\n\n  /**\n   * The Amazon Resource Name (ARN) of the environment.\n   *\n   * @attribute\n   */\n  public readonly environmentArn: string;\n\n  /**\n   * The ID of the environment.\n   */\n  public readonly applicationId: string;\n\n  private readonly _cfnEnvironment: CfnEnvironment;\n\n  constructor(scope: Construct, id: string, props: EnvironmentProps) {\n    super(scope, id, {\n      physicalName: props.environmentName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.name = props.environmentName || Names.uniqueResourceName(this, {\n      maxLength: 64,\n      separator: '-',\n    });\n    this.application = props.application;\n    this.applicationId = this.application.applicationId;\n    this.description = props.description;\n    this.monitors = props.monitors;\n\n    const resource = new CfnEnvironment(this, 'Resource', {\n      applicationId: this.applicationId,\n      name: this.name,\n      description: this.description,\n      deletionProtectionCheck: props.deletionProtectionCheck,\n      monitors: this.monitors?.map((monitor) => {\n        return {\n          alarmArn: monitor.alarmArn,\n          ...(monitor.monitorType === MonitorType.CLOUDWATCH\n            ? { alarmRoleArn: monitor.alarmRoleArn || this.createOrGetAlarmRole().roleArn }\n            : { alarmRoleArn: monitor.alarmRoleArn }),\n        };\n      }),\n    });\n    this._cfnEnvironment = resource;\n\n    this.environmentId = this._cfnEnvironment.ref;\n    this.environmentArn = this.stack.formatArn({\n      service: 'appconfig',\n      resource: 'application',\n      resourceName: `${this.applicationId}/environment/${this.environmentId}`,\n    });\n    this.extensible = new ExtensibleBase(this, this.environmentArn, this.name);\n\n    this.application.addExistingEnvironment(this);\n  }\n\n  private createOrGetAlarmRole(): iam.IRole {\n    // the name is guaranteed to be set in line 243\n    const logicalId = `Role${getHash(this.name!)}`;\n    const existingRole = this.node.tryFindChild(logicalId) as iam.IRole;\n    if (existingRole) {\n      return existingRole;\n    }\n    // this scope is fine for cloudwatch:DescribeAlarms since it is readonly\n    // and it is required for composite alarms\n    // https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_DescribeAlarms.html\n    const policy = new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      actions: ['cloudwatch:DescribeAlarms'],\n      resources: ['*'],\n    });\n    const document = new iam.PolicyDocument({\n      statements: [policy],\n    });\n    const role = new iam.Role(this, logicalId, {\n      roleName: PhysicalName.GENERATE_IF_NEEDED,\n      assumedBy: new iam.ServicePrincipal('appconfig.amazonaws.com'),\n      inlinePolicies: {\n        ['AllowAppConfigMonitorAlarmPolicy']: document,\n      },\n    });\n    return role;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, CloudFormation resources", "output": "class RDSStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Creates a security group for AWS RDS\n        sg_rds = ec2.SecurityGroup(\n                self,\n                id=\"sg_rds\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_rds\"\n        )\n\n        # Adds an ingress rule which allows resources in the VPC's CIDR\n        # to access the database.\n        sg_rds.add_ingress_rule(\n            peer=ec2.Peer.ipv4(\"10.0.0.0/16\"),\n            connection=ec2.Port.tcp(3306)\n        )\n\n        # Master username is 'admin' and database password is automatically\n        # generated and stored in AWS Secrets Manager\n        my_sql = rds.DatabaseInstance(\n                self, \"RDS\",\n                engine=rds.DatabaseInstanceEngine.mysql(\n                    version=rds.MysqlEngineVersion.VER_8_0_16\n                ),\n                vpc=props['vpc'],\n                port=3306,\n                instance_type=ec2.InstanceType.of(\n                    ec2.InstanceClass.MEMORY4,\n                    ec2.InstanceSize.LARGE,\n                    ),\n                removal_policy=RemovalPolicy.DESTROY,\n                security_groups=[sg_rds]\n                )", "language": "python"}
{"input": "CDK Stack that creates EC2, VPC, IAM, KMS resources", "output": "class TestStack extends Stack {\n  public cache: ServerlessCache;\n  public constructor(scope: Construct, id: string, props: StackProps) {\n    super(scope, id, props);\n    const vpc = new Vpc(this, 'VPC');\n    const key = new Key(this, 'Key', {});\n    const securityGroup = new SecurityGroup(this, 'SecurityGroup', { vpc });\n    const user = new IamUser(this, 'User', {\n      userId: userName,\n      accessControl: AccessControl.fromAccessString('on ~* +@all'),\n    });\n    const userGroup = new UserGroup(this, 'UserGroup', { users: [user], userGroupName: userGroupName });\n    user.applyRemovalPolicy(RemovalPolicy.DESTROY);\n    userGroup.applyRemovalPolicy(RemovalPolicy.DESTROY);\n    this.cache = new ServerlessCache(this, 'Cache', {\n      description: 'Serverless cache',\n      vpc,\n      engine: CacheEngine.VALKEY_8,\n      serverlessCacheName: cacheName,\n      kmsKey: key,\n      vpcSubnets: { subnetType: SubnetType.PRIVATE_WITH_EGRESS },\n      securityGroups: [securityGroup],\n      userGroup,\n      backup: {\n        backupRetentionLimit: 2,\n        backupNameBeforeDeletion: 'last-snapshot-name',\n      },\n      cacheUsageLimits: {\n        dataStorageMinimumSize: Size.gibibytes(1),\n        dataStorageMaximumSize: Size.gibibytes(1),\n        requestRateLimitMinimum: 1_000,\n        requestRateLimitMaximum: 2_000,\n      },\n    });\n    this.cache.applyRemovalPolicy(RemovalPolicy.DESTROY);\n\n    const clientSG = new SecurityGroup(this, 'ClientSG', { vpc });\n    clientSG.connections.allowToDefaultPort(this.cache);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates VPC, CloudFormation resources", "output": "export class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    const vpc = new Vpc(this, 'Integ-VPC');\n    testCases.forEach((p: TestCaseProps, i) =>\n      new TestCase(this, `integ-aurora-serverlessv2-${i}`, {\n        ...p,\n        vpc,\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class IntegManifestWriter for AWS resource management", "output": "export class IntegManifestWriter {\n  public static readonly DEFAULT_FILENAME = 'integ.json';\n\n  public static write(manifest: IntegManifest, filePath: string) {\n    Manifest.saveIntegManifest(manifest, getFinalLocation(filePath));\n  }\n}", "language": "typescript"}
{"input": "Custom rewrite/redirect rule for an Amplify App. @see https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html", "output": "export class CustomRule {\n  /**\n   * Sets up a 200 rewrite for all paths to `index.html` except for path\n   * containing a file extension.\n   */\n  public static readonly SINGLE_PAGE_APPLICATION_REDIRECT = new CustomRule({\n    source: '</^[^.]+$/>',\n    target: '/index.html',\n    status: RedirectStatus.REWRITE,\n  });\n\n  /**\n   * The source pattern for a URL rewrite or redirect rule.\n   *\n   * @see https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html\n   */\n  public readonly source: string;\n\n  /**\n   * The target pattern for a URL rewrite or redirect rule.\n   *\n   * @see https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html\n   */\n  public readonly target: string;\n\n  /**\n   * The status code for a URL rewrite or redirect rule.\n   *\n   * @see https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html\n   *\n   * @default PERMANENT_REDIRECT\n   */\n  public readonly status?: RedirectStatus;\n\n  /**\n   * The condition for a URL rewrite or redirect rule, e.g. country code.\n   *\n   * @see https://docs.aws.amazon.com/amplify/latest/userguide/redirects.html\n   *\n   * @default - no condition\n   */\n  public readonly condition?: string;\n\n  constructor(options: CustomRuleOptions) {\n    this.source = options.source;\n    this.target = options.target;\n    this.status = options.status;\n    this.condition = options.condition;\n  }\n}", "language": "typescript"}
{"input": "CDK class StaticServicePrincipal for AWS resource management", "output": "class StaticServicePrincipal extends ServicePrincipal {\n      constructor(public readonly service: string) {\n        super(service);\n      }\n\n      public get policyFragment(): PrincipalPolicyFragment {\n        return new PrincipalPolicyFragment({\n          Service: [this.service],\n        }, this.opts.conditions);\n      }\n    }", "language": "typescript"}
{"input": "Error thrown when validation fails", "output": "export class ValidationError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'ValidationError';\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EventBridge, SNS, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const configurationSet = new ses.ConfigurationSet(this, 'ConfigurationSet', {\n      maxDeliveryDuration: Duration.minutes(10),\n    });\n\n    const topic = new sns.Topic(this, 'Topic');\n\n    configurationSet.addEventDestination('Sns', {\n      destination: ses.EventDestination.snsTopic(topic),\n    });\n\n    configurationSet.addEventDestination('CloudWatch', {\n      destination: ses.EventDestination.cloudWatchDimensions([{\n        source: ses.CloudWatchDimensionSource.MESSAGE_TAG,\n        name: 'ses:from-domain',\n        defaultValue: 'no_domain',\n      }]),\n    });\n\n    const bus = events.EventBus.fromEventBusName(this, 'EventBus', 'default');\n\n    configurationSet.addEventDestination('EventBridge', {\n      destination: ses.EventDestination.eventBus(bus),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, AppSync, CloudFormation resources", "output": "export class AppsyncGraphqlTypescriptResolverStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const api = new appsync.GraphqlApi(this, 'Api', {\n      name: 'Typescript-Resolver',\n      definition: appsync.Definition.fromFile(path.join(__dirname, 'schema.graphql')),\n      authorizationConfig: {\n        defaultAuthorization: {\n          authorizationType: appsync.AuthorizationType.IAM,\n        },\n      },\n    });\n\n    const noneDS = api.addNoneDataSource('NoneDS');\n\n    const execOptions: ExecSyncOptions = { stdio: ['ignore', process.stderr, 'inherit'] };\n\n    api.createResolver('GetTodoResolver', {\n      typeName: 'Query',\n      fieldName: 'getTodo',\n      runtime: appsync.FunctionRuntime.JS_1_0_0,\n      code: appsync.Code.fromAsset(path.join(__dirname, '..', 'resolvers'), {\n        bundling: {\n          outputType: cdk.BundlingOutput.SINGLE_FILE,\n          image: cdk.DockerImage.fromRegistry('public.ecr.aws/docker/library/node:20'),\n          environment: {\n            NPM_CONFIG_PREFIX: '/tmp/.npm-global',\n            NPM_CONFIG_CACHE: '/tmp/.npm-cache',\n          },\n          command: ['bash', '-c', ['npm install', 'npm run build','npm run dist', 'cp dist/appsync/* /asset-output',].join(' && '),],\n          local: {\n            tryBundle(outputDir: string) {\n              try {\n                execSync('esbuild --version', execOptions);\n              } catch {\n                console.log(\"esbuild not found locally, using docker build\")\n                return false;\n              }\n              execSync('npm run dist', execOptions);\n              fs.copyFileSync(path.join(__dirname, '..', 'resolvers', 'dist', '*'), outputDir );\n              return true;\n            },\n          },\n        }\n      }),\n      dataSource: noneDS\n    });\n  }\n}", "language": "typescript"}
{"input": "Construct that creates a custom resource that will perform an HTTP API Call", "output": "export class HttpApiCall extends ApiCallBase {\n  protected readonly apiCallResource: CustomResource;\n  public readonly provider: AssertionsProvider;\n\n  constructor(scope: Construct, id: string, props: HttpCallProps) {\n    super(scope, id);\n\n    let name = '';\n    if (!Token.isUnresolved(props.url)) {\n      const url = new URL(props.url);\n      name = `${url.hostname}${url.pathname}`.replace(/\\/|\\.|:/g, '');\n    }\n    this.provider = new AssertionsProvider(this, 'HttpProvider');\n    this.apiCallResource = new CustomResource(this, 'Default', {\n      serviceToken: this.provider.serviceToken,\n      properties: {\n        parameters: props,\n        expected: Lazy.any({ produce: () => this.expectedResult }),\n        stateMachineArn: Lazy.string({ produce: () => this.stateMachineArn }),\n        flattenResponse: Lazy.string({ produce: () => this.flattenResponse }),\n        salt: Date.now().toString(),\n      },\n      resourceType: `${HTTP_RESOURCE_TYPE}${name}`.substring(0, 60),\n    });\n\n    // Needed so that all the policies set up by the provider should be available before the custom resource is provisioned.\n    this.apiCallResource.node.addDependency(this.provider);\n    Aspects.of(this).add({\n      visit(node: IConstruct) {\n        if (node instanceof HttpApiCall) {\n          if (node.expectedResult) {\n            const result = node.apiCallResource.getAttString('assertion');\n\n            new CfnOutput(node, 'AssertionResults', {\n              value: result,\n            }).overrideLogicalId(`AssertionResults${id.replace(/[\\W_]+/g, '')}`);\n          }\n        }\n      },\n    }, { priority: AspectPriority.MUTATING });\n  }\n\n  public assertAtPath(_path: string, _expected: ExpectedResult): IApiCall {\n    return this;\n  }\n  public waitForAssertions(options?: WaiterStateMachineOptions | undefined): IApiCall {\n    const waiter = new WaiterStateMachine(this, 'WaitFor', {\n      ...options,\n    });\n    this.stateMachineArn = waiter.stateMachineArn;\n    this.provider.addPolicyStatementFromSdkCall('states', 'StartExecution');\n    return this;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, IAM resources", "output": "class EMRClusterStack(Stack):\n    def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        s3_log_bucket: str,\n        s3_script_bucket: str,\n        spark_script: str,\n        **kwargs,\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # VPC\n        vpc = ec2.Vpc(\n            self,\n            \"vpc\",\n            nat_gateways=0,\n            subnet_configuration=[\n                ec2.SubnetConfiguration(\n                    name=\"public\", subnet_type=ec2.SubnetType.PUBLIC\n                )\n            ],\n        )\n\n        # enable reading scripts from s3 bucket\n        read_scripts_policy = iam.PolicyStatement(\n            effect=iam.Effect.ALLOW,\n            actions=[\"s3:GetObject\",],\n            resources=[f\"arn:aws:s3:::{s3_script_bucket}/*\"],\n        )\n        read_scripts_document = iam.PolicyDocument()\n        read_scripts_document.add_statements(read_scripts_policy)\n\n        # emr service role\n        emr_service_role = iam.Role(\n            self,\n            \"emr_service_role\",\n            assumed_by=iam.ServicePrincipal(\"elasticmapreduce.amazonaws.com\"),\n            managed_policies=[\n                iam.ManagedPolicy.from_aws_managed_policy_name(\n                    \"service-role/AmazonElasticMapReduceRole\"\n                )\n            ],\n            inline_policies={\n                \"read_scripts_document\": read_scripts_document\n            },\n        )\n\n        # emr job flow role\n        emr_job_flow_role = iam.Role(\n            self,\n            \"emr_job_flow_role\",\n            assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"),\n            managed_policies=[\n                iam.ManagedPolicy.from_aws_managed_policy_name(\n                    \"service-role/AmazonElasticMapReduceforEC2Role\"\n                )\n            ],\n        )\n        # emr job flow profile\n        emr_job_flow_profile = iam.CfnInstanceProfile(\n            self,\n            \"emr_job_flow_profile\",\n            roles=[emr_job_flow_role.role_name],\n            instance_profile_name=\"emrJobFlowProfile_\",\n        )\n\n        assert emr_job_flow_profile.instance_profile_name is not None\n\n        # create emr cluster\n        emr.CfnCluster(\n            self,\n            \"emr_cluster\",\n            instances=emr.CfnCluster.JobFlowInstancesConfigProperty(\n                core_instance_group=emr.CfnCluster.InstanceGroupConfigProperty(\n                    instance_count=3, instance_type=\"m4.large\", market=\"SPOT\"\n                ),\n                ec2_subnet_id=vpc.public_subnets[0].subnet_id,\n                hadoop_version=\"Amazon\",\n                keep_job_flow_alive_when_no_steps=False,\n                master_instance_group=emr.CfnCluster.InstanceGroupConfigProperty(\n                    instance_count=1, instance_type=\"m4.large\", market=\"SPOT\"\n                ),\n            ),\n            # note job_flow_role is an instance profile (not an iam role)\n            job_flow_role=emr_job_flow_profile.instance_profile_name,\n            name=\"cluster_name\",\n            applications=[emr.CfnCluster.ApplicationProperty(name=\"Spark\")],\n            service_role=emr_service_role.role_name,\n            configurations=[\n                # use python3 for pyspark\n                emr.CfnCluster.ConfigurationProperty(\n                    classification=\"spark-env\",\n                    configurations=[\n                        emr.CfnCluster.ConfigurationProperty(\n                            classification=\"export\",\n                            configuration_properties={\n                                \"PYSPARK_PYTHON\": \"/usr/bin/python3\",\n                                \"PYSPARK_DRIVER_PYTHON\": \"/usr/bin/python3\",\n                            },\n                        )\n                    ],\n                ),\n                # enable apache arrow\n                emr.CfnCluster.ConfigurationProperty(\n                    classification=\"spark-defaults\",\n                    configuration_properties={\n                        \"spark.sql.execution.arrow.enabled\": \"true\"\n                    },\n                ),\n                # dedicate cluster to single jobs\n                emr.CfnCluster.ConfigurationProperty(\n                    classification=\"spark\",\n                    configuration_properties={\"maximizeResourceAllocation\": \"true\"},\n                ),\n            ],\n            log_uri=f\"s3://{s3_log_bucket}/{Aws.REGION}/elasticmapreduce/\",\n            release_label=\"emr-6.0.0\",\n            visible_to_all_users=False,\n            # the job to be done\n            steps=[\n                emr.CfnCluster.StepConfigProperty(\n                    hadoop_jar_step=emr.CfnCluster.HadoopJarStepConfigProperty(\n                        jar=\"command-runner.jar\",\n                        args=[\n                            \"spark-submit\",\n                            \"--deploy-mode\",\n                            \"cluster\",\n                            f\"s3://{s3_script_bucket}/scripts/{spark_script}\",\n                        ],\n                    ),\n                    name=\"step_name\",\n                    action_on_failure=\"CONTINUE\",\n                ),\n            ],\n        )", "language": "python"}
{"input": "CDK class InLineLambda for AWS resource management", "output": "class InLineLambda extends cdk.CfnResource {\n      public readonly tags: cdk.TagManager = new cdk.TagManager(cdk.TagType.STANDARD, resourceType);\n\n      protected renderProperties(properties: any): { [key: string]: any } {\n        properties.Tags = cdk.listMapper(cdk.cfnTagToCloudFormation)(this.tags.renderTags());\n        delete properties.tags;\n        return properties;\n      }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, IAM resources", "output": "class AmazonConnectStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str,  **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Add CDK Nag\n        Aspects.of(self).add(AwsSolutionsChecks())\n\n        # Amazon Connect instance\n        amazon_connect_instance = connect.CfnInstance(self, \"AmazonConnectInstance\",\n            attributes=connect.CfnInstance.AttributesProperty(\n                inbound_calls=True,\n                outbound_calls=True,\n                auto_resolve_best_voices=False,\n                contactflow_logs=True,\n                contact_lens=True,\n                early_media=False,\n                use_custom_tts_voices=False\n            ),\n            identity_management_type=\"CONNECT_MANAGED\",\n            instance_alias=\"amazon-connect-instance\"\n        )\n\n        # KMS key for call recordings and transcripts\n        call_recordings_key = kms.Key(self, \"CallRecordingsKey\",\n            enable_key_rotation=True,\n            pending_window=Duration.days(30),\n            alias=\"amazon-connect-call-recordings-key\"\n        )\n\n        # Access logs S3 Bucket for call recordings and transcripts\n        call_recordings_access_logs_bucket = s3.Bucket(self, \"CallRecordingsAccessLogsBucket\",\n            block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n            encryption=s3.BucketEncryption.KMS,\n            encryption_key=call_recordings_key,\n            removal_policy=RemovalPolicy.RETAIN,\n            enforce_ssl=True,\n            versioned=True,\n            bucket_name=\"amazon-connect-call-recordings-access-logs-bucket\"\n        )\n\n        # S3 Bucket for call recordings and transcripts\n        call_recordings_bucket = s3.Bucket(self, \"CallRecordingsBucket\",\n            block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n            encryption=s3.BucketEncryption.KMS,\n            encryption_key=call_recordings_key,\n            removal_policy=RemovalPolicy.RETAIN,\n            enforce_ssl=True,\n            versioned=True,\n            server_access_logs_bucket=call_recordings_access_logs_bucket,\n            bucket_name=\"amazon-connect-call-recordings-bucket\",\n            lifecycle_rules=[\n                s3.LifecycleRule(\n                    enabled=True,\n                    expiration=Duration.days(365*2)\n                )\n            ]\n        )\n\n        # Associate S3 bucket with Amazon Connect instance for call recordings and transcripts\n        call_recordings_storage_config = connect.CfnInstanceStorageConfig(self, \"CallRecordingsStorageConfig\",\n            instance_arn=amazon_connect_instance.attr_arn,\n            resource_type=\"CALL_RECORDINGS\",\n            storage_type=\"S3\",\n\n            s3_config=connect.CfnInstanceStorageConfig.S3ConfigProperty(\n                bucket_name=call_recordings_bucket.bucket_name,\n                bucket_prefix=\"recordings\",\n                encryption_config=connect.CfnInstanceStorageConfig.EncryptionConfigProperty(\n                    encryption_type=\"KMS\",\n                    key_id=call_recordings_key.key_arn\n                )\n            )\n        )\n\n        # IAM Role for CTR Delivery Stream\n        ctr_delivery_stream_role = iam.Role(self, \"CtrDeliveryStreamRole\",\n            assumed_by=iam.ServicePrincipal(\"firehose.amazonaws.com\"),\n            role_name=\"amazon-connect-ctr-delivery-stream-role\"\n        )\n\n        # Grant permissions to the CTR IAM role\n        ctr_delivery_stream_role.add_to_policy(iam.PolicyStatement(\n            actions=[\n                \"s3:PutObject\",\n                \"s3:GetObject\",\n                \"s3:ListBucket\",\n                \"s3:ListMultipartUploadParts\",\n                \"s3:AbortMultipartUpload\",\n                \"s3:GetBucketLocation\",\n                \"kms:Encrypt\",\n                \"kms:Decrypt\",\n                \"kms:ReEncrypt\",\n                \"kms:GenerateDataKey\",\n                \"kms:DescribeKey\",\n                \"kms:CreateGrant\"\n            ],\n            resources=[\n                call_recordings_bucket.bucket_arn,\n                call_recordings_key.key_arn\n            ]\n        ))\n\n        # Firehose Delivery Stream for CTR\n        ctr_delivery_stream = firehose.CfnDeliveryStream(self, \"CtrDeliveryStream\",\n            delivery_stream_name=\"amazon-connect-ctr-delivery-stream\",\n            delivery_stream_type=\"DirectPut\",\n            delivery_stream_encryption_configuration_input=firehose.CfnDeliveryStream.DeliveryStreamEncryptionConfigurationInputProperty(\n                key_type=\"CUSTOMER_MANAGED_CMK\",\n                key_arn=call_recordings_key.key_arn\n            ),\n            s3_destination_configuration=firehose.CfnDeliveryStream.S3DestinationConfigurationProperty(\n                bucket_arn=call_recordings_bucket.bucket_arn,\n                prefix=\"ctr/\",\n                role_arn=ctr_delivery_stream_role.role_arn,\n                buffering_hints=firehose.CfnDeliveryStream.BufferingHintsProperty(\n                    interval_in_seconds=60\n                ),\n                encryption_configuration=firehose.CfnDeliveryStream.EncryptionConfigurationProperty(\n                    kms_encryption_config=firehose.CfnDeliveryStream.KMSEncryptionConfigProperty(\n                        awskms_key_arn=call_recordings_key.key_arn\n                    )\n                )\n            )\n        )\n\n        # Associate Firehose Delivery Stream with Amazon Connect instance for CTR\n        ctr_storage_config = connect.CfnInstanceStorageConfig(self, \"CtrStorageConfig\",\n            instance_arn=amazon_connect_instance.attr_arn,\n            resource_type=\"CONTACT_TRACE_RECORDS\",\n            storage_type=\"KINESIS_FIREHOSE\",\n            kinesis_firehose_config=connect.CfnInstanceStorageConfig.KinesisFirehoseConfigProperty(\n                firehose_arn=ctr_delivery_stream.attr_arn\n            )\n        )\n\n        # KMS key for scheduled reports\n        scheduled_reports_key = kms.Key(self, \"ScheduledReportsKey\",\n            enable_key_rotation=True,\n            pending_window=Duration.days(30),\n            alias=\"amazon-connect-scheduled-reports-key\"\n        )\n\n\n        # Access logs S3 Bucket for scheduled reports\n        scheduled_reports_access_logs_bucket = s3.Bucket(self, \"ScheduledReportsAccessLogsBucket\",\n            block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n            encryption=s3.BucketEncryption.KMS,\n            encryption_key=scheduled_reports_key,\n            removal_policy=RemovalPolicy.RETAIN,\n            enforce_ssl=True,\n            bucket_name=\"amazon-connect-scheduled-reports-access-logs-bucket\"\n        )\n\n        # S3 Bucket for scheduled reports\n        scheduled_reports_bucket = s3.Bucket(self, \"ScheduledReportsBucket\",\n            block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n            encryption=s3.BucketEncryption.KMS,\n            encryption_key=scheduled_reports_key,\n            removal_policy=RemovalPolicy.RETAIN,\n            enforce_ssl=True,\n            versioned=True,\n            server_access_logs_bucket=scheduled_reports_access_logs_bucket,\n            bucket_name=\"amazon-connect-scheduled-reports-bucket\"\n        )\n\n        # Associate S3 bucket with Connect instance for scheduled reports\n        scheduled_reports_storage_config = connect.CfnInstanceStorageConfig(self, \"ScheduledReportsStorageConfig\",\n            instance_arn=amazon_connect_instance.attr_arn,\n            resource_type=\"SCHEDULED_REPORTS\",\n            storage_type=\"S3\",\n\n            s3_config=connect.CfnInstanceStorageConfig.S3ConfigProperty(\n                bucket_name=scheduled_reports_bucket.bucket_name,\n                bucket_prefix=\"reports\",\n                encryption_config=connect.CfnInstanceStorageConfig.EncryptionConfigProperty(\n                    encryption_type=\"KMS\",\n                    key_id=scheduled_reports_key.key_arn\n                )\n            )\n        )\n\n        # Assign phone number\n        phone_number = connect.CfnPhoneNumber(self, \"PhoneNumber\",\n            target_arn=amazon_connect_instance.attr_arn,\n            country_code=\"GB\",\n            description=\"Inbound Phone Number\",\n            type=\"DID\"\n        )\n\n        # Create hours of operation\n        hours_of_operation = connect.CfnHoursOfOperation(self, \"HoursOfOperation\",\n            config=[connect.CfnHoursOfOperation.HoursOfOperationConfigProperty(\n                day=\"MONDAY\",\n                start_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=9,\n                    minutes=0\n                ),\n                end_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=17,\n                    minutes=0\n                )\n            ),\n            connect.CfnHoursOfOperation.HoursOfOperationConfigProperty(\n                day=\"TUESDAY\",\n                start_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=9,\n                    minutes=0\n                ),\n                end_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=17,\n                    minutes=0\n                )\n            ),\n            connect.CfnHoursOfOperation.HoursOfOperationConfigProperty(\n                day=\"WEDNESDAY\",\n                start_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=9,\n                    minutes=0\n                ),\n                end_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=17,\n                    minutes=0\n                )\n            ),\n            connect.CfnHoursOfOperation.HoursOfOperationConfigProperty(\n                day=\"THURSDAY\",\n                start_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=9,\n                    minutes=0\n                ),\n                end_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=17,\n                    minutes=0\n                )\n            ),\n            connect.CfnHoursOfOperation.HoursOfOperationConfigProperty(\n                day=\"FRIDAY\",\n                start_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=9,\n                    minutes=0\n                ),\n                end_time=connect.CfnHoursOfOperation.HoursOfOperationTimeSliceProperty(\n                    hours=17,\n                    minutes=0\n                )\n            )],\n            instance_arn=amazon_connect_instance.attr_arn,\n            name=\"Main\",\n            time_zone=\"Europe/London\",\n            description=\"Business Hours of Operation\",\n        )", "language": "python"}
{"input": "CDK class DropSpamReceiptRule for AWS resource management", "output": "export class DropSpamReceiptRule extends Construct {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ses.DropSpamReceiptRule';\n\n  public readonly rule: ReceiptRule;\n\n  constructor(scope: Construct, id: string, props: DropSpamReceiptRuleProps) {\n    super(scope, id);\n\n    const fn = new DropSpamSingletonFunction(this, 'Function', {\n      uuid: '224e77f9-a32e-4b4d-ac32-983477abba16',\n    });\n\n    fn.addPermission('AllowSes', {\n      action: 'lambda:InvokeFunction',\n      principal: new iam.ServicePrincipal('ses.amazonaws.com'),\n      sourceAccount: Aws.ACCOUNT_ID,\n    });\n\n    this.rule = new ReceiptRule(this, 'Rule', {\n      actions: [\n        {\n          bind: () => ({\n            lambdaAction: {\n              functionArn: fn.functionArn,\n              invocationType: 'RequestResponse',\n            },\n          }),\n        },\n      ],\n      scanEnabled: true,\n      ruleSet: props.ruleSet,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class VirtualGateway for AWS resource management", "output": "export class VirtualGateway extends VirtualGatewayBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appmesh.VirtualGateway';\n\n  /**\n   * Import an existing VirtualGateway given an ARN\n   */\n  public static fromVirtualGatewayArn(scope: Construct, id: string, virtualGatewayArn: string): IVirtualGateway {\n    return new class extends VirtualGatewayBase {\n      private readonly parsedArn = cdk.Fn.split('/', cdk.Stack.of(scope).splitArn(virtualGatewayArn, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName!);\n      readonly mesh = Mesh.fromMeshName(this, 'Mesh', cdk.Fn.select(0, this.parsedArn));\n      readonly virtualGatewayArn = virtualGatewayArn;\n      readonly virtualGatewayName = cdk.Fn.select(2, this.parsedArn);\n    }(scope, id);\n  }\n\n  /**\n   * Import an existing VirtualGateway given its attributes\n   */\n  public static fromVirtualGatewayAttributes(scope: Construct, id: string, attrs: VirtualGatewayAttributes): IVirtualGateway {\n    return new class extends VirtualGatewayBase {\n      readonly mesh = attrs.mesh;\n      readonly virtualGatewayName = attrs.virtualGatewayName;\n      readonly virtualGatewayArn = cdk.Stack.of(this).formatArn({\n        service: 'appmesh',\n        resource: `mesh/${attrs.mesh.meshName}/virtualGateway`,\n        resourceName: this.virtualGatewayName,\n      });\n    }(scope, id);\n  }\n\n  /**\n   * The name of the VirtualGateway\n   */\n  public readonly virtualGatewayName: string;\n\n  /**\n   * The Amazon Resource Name (ARN) for the VirtualGateway\n   */\n  public readonly virtualGatewayArn: string;\n\n  /**\n   * The Mesh that the VirtualGateway belongs to\n   */\n  public readonly mesh: IMesh;\n\n  protected readonly listeners = new Array<VirtualGatewayListenerConfig>();\n\n  constructor(scope: Construct, id: string, props: VirtualGatewayProps) {\n    super(scope, id, {\n      physicalName: props.virtualGatewayName || cdk.Lazy.string({ produce: () => cdk.Names.uniqueId(this) }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.mesh = props.mesh;\n\n    if (!props.listeners) {\n      // Use listener default of http listener port 8080 if no listener is defined\n      this.listeners.push(VirtualGatewayListener.http().bind(this));\n    } else {\n      props.listeners.forEach(listener => this.listeners.push(listener.bind(this)));\n    }\n\n    const accessLogging = props.accessLog?.bind(this);\n\n    const node = new CfnVirtualGateway(this, 'Resource', {\n      virtualGatewayName: this.physicalName,\n      meshName: this.mesh.meshName,\n      meshOwner: renderMeshOwner(this.env.account, this.mesh.env.account),\n      spec: {\n        listeners: this.listeners.map(listener => listener.listener),\n        backendDefaults: props.backendDefaults !== undefined\n          ? {\n            clientPolicy: {\n              tls: renderTlsClientPolicy(this, props.backendDefaults?.tlsClientPolicy),\n            },\n          }\n          : undefined,\n        logging: accessLogging !== undefined ? {\n          accessLog: accessLogging.virtualGatewayAccessLog,\n        } : undefined,\n      },\n    });\n\n    this.virtualGatewayName = this.getResourceNameAttribute(node.attrVirtualGatewayName);\n    this.virtualGatewayArn = this.getResourceArnAttribute(node.ref, {\n      service: 'appmesh',\n      resource: `mesh/${props.mesh.meshName}/virtualGateway`,\n      resourceName: this.physicalName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class IntegManifestSynthesizer for AWS resource management", "output": "export class IntegManifestSynthesizer {\n  constructor(private readonly testCases: IntegTestCase[], private readonly enableLookups?: boolean) {}\n\n  synthesize(session: ISynthesisSession) {\n    const manifest: IntegManifest = {\n      enableLookups: this.enableLookups,\n      ...this.testCases\n        .map(tc => tc.manifest)\n        .reduce(mergeManifests, emptyManifest),\n    };\n\n    const snapshotDir = session.assembly.outdir;\n\n    IntegManifestWriter.write(manifest, snapshotDir);\n  }\n}", "language": "typescript"}
{"input": "Utility function to create alarms", "output": "const createAlarm = (alarmName: string, metric: cloudwatch.Metric) => {\n      return new cloudwatch.Alarm(this, alarmName, {\n        evaluationPeriods: 1,\n        threshold: 1,\n        comparisonOperator: cloudwatch.ComparisonOperator.GREATER_THAN_THRESHOLD,\n        metric: metric,\n      });\n    }", "language": "typescript"}
{"input": "Test for SQS Queue:\n    - Queue to process uploads\n    - Dead-letter Queue", "output": "def test_sqs_queue_created(template):\n    \"\"\"\n      Test for SQS Queue:\n          - Queue to process uploads\n          - Dead-letter Queue\n      \"\"\"\n    template.resource_count_is(\"AWS::SQS::Queue\", 2)\n    template.resource_count_is(\"AWS::SQS::QueuePolicy\", 1)", "language": "python"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation resources", "output": "class VpcNestedStack extends cdk.NestedStack {\n  public readonly vpc: ec2.Vpc;\n\n  constructor(scope: Construct, id: string, props?: cdk.NestedStackProps) {\n    super(scope, id, props);\n\n    this.vpc = new ec2.Vpc(this, 'nested-stack-vpc', {\n      ipAddresses: ec2.IpAddresses.cidr('10.0.0.0/16'),\n      natGateways: 0,\n      maxAzs: 3,\n      subnetConfiguration: [\n        {\n          name: 'public-subnet-1',\n          subnetType: ec2.SubnetType.PUBLIC,\n          cidrMask: 24,\n        },\n        // \ud83d\udc47 added private isolated subnets\n        {\n          name: 'private-isolated-subnet-1',\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n          cidrMask: 24,\n        },\n      ]\n    });\n  }\n}", "language": "typescript"}
{"input": "Mimic the singletonfunction construct in '@aws-cdk/aws-lambda'", "output": "class SingletonFunction extends Construct {\n  public readonly serviceToken: string;\n\n  public readonly lambdaFunction: LambdaFunctionProvider;\n  constructor(scope: Construct, id: string, props: SingletonFunctionProps) {\n    super(scope, id);\n    this.lambdaFunction = this.ensureFunction(props);\n    this.serviceToken = this.lambdaFunction.serviceToken;\n  }\n\n  private ensureFunction(props: SingletonFunctionProps): LambdaFunctionProvider {\n    const constructName = 'SingletonFunction' + slugify(props.uuid);\n    const existing = Stack.of(this).node.tryFindChild(constructName);\n    if (existing) {\n      return existing as LambdaFunctionProvider;\n    }\n\n    return new LambdaFunctionProvider(Stack.of(this), constructName, {\n      handler: props.handler,\n      logRetention: props.logRetention,\n    });\n  }\n\n  /**\n   * Add an IAM policy statement to the inline policy of the\n   * lambdas function's role\n   *\n   * **Please note**: this is a direct IAM JSON policy blob, *not* a `iam.PolicyStatement`\n   * object like you will see in the rest of the CDK.\n   *\n   *\n   * singleton.addToRolePolicy({\n   *   Effect: 'Allow',\n   *   Action: 's3:GetObject',\n   *   Resources: '*',\n   * });\n   */\n  public addToRolePolicy(statement: any): void {\n    this.lambdaFunction.addPolicies([statement]);\n  }\n\n  /**\n   * Create a policy statement from a specific api call\n   */\n  public addPolicyStatementFromSdkCall(service: string, api: string, resources?: string[]): void {\n    this.lambdaFunction.addPolicies([{\n      Action: [awsSdkToIamAction(service, api)],\n      Effect: 'Allow',\n      Resource: resources || ['*'],\n    }]);\n  }\n}\n\n/**\n * Properties for defining an AssertionsProvider\n */\nexport interface AssertionsProviderProps extends LambdaFunctionProviderProps {\n  /**\n   * This determines the uniqueness of each AssertionsProvider.\n   * You should only need to provide something different here if you\n   * _know_ that you need a separate provider\n   *\n   * @default - the default uuid is used\n   */\n  readonly uuid?: string;\n}\n\n/**\n * Represents an assertions provider. The creates a singletone\n * Lambda Function that will create a single function per stack\n * that serves as the custom resource provider for the various\n * assertion providers\n */\nexport class AssertionsProvider extends Construct {\n  /**\n   * The ARN of the lambda function which can be used\n   * as a serviceToken to a CustomResource\n   */\n  public readonly serviceToken: string;\n  /**\n   * A reference to the provider Lambda Function\n   * execution Role ARN\n   */\n  public readonly handlerRoleArn: Reference;\n\n  private readonly handler: SingletonFunction;\n\n  constructor(scope: Construct, id: string, props?: AssertionsProviderProps) {\n    super(scope, id);\n\n    this.handler = new SingletonFunction(this, 'AssertionsProvider', {\n      handler: props?.handler,\n      uuid: props?.uuid ?? '1488541a-7b23-4664-81b6-9b4408076b81',\n      logRetention: props?.logRetention,\n    });\n\n    this.handlerRoleArn = this.handler.lambdaFunction.roleArn;\n\n    this.serviceToken = this.handler.serviceToken;\n  }\n\n  /**\n   * Encode an object so it can be passed\n   * as custom resource parameters. Custom resources will convert\n   * all input parameters to strings so we encode non-strings here\n   * so we can then decode them correctly in the provider function\n   */\n  public encode(obj: any): any {\n    if (!obj) {\n      return obj;\n    }\n    return Object.fromEntries(Object.entries(obj).map(([key, value]) => [key, encodeValue(value)]));\n\n    function encodeValue(value: any): any {\n      if (ArrayBuffer.isView(value)) {\n        return {\n          $type: 'ArrayBufferView',\n          string: new TextDecoder().decode(value as Uint8Array),\n        };\n      }\n\n      return JSON.stringify(value);\n    }\n  }\n\n  /**\n   * Create a policy statement from a specific api call\n   */\n  public addPolicyStatementFromSdkCall(service: string, api: string, resources?: string[]): void {\n    this.handler.addPolicyStatementFromSdkCall(service, api, resources);\n  }\n\n  /**\n   * Add an IAM policy statement to the inline policy of the\n   * lambdas function's role\n   *\n   * **Please note**: this is a direct IAM JSON policy blob, *not* a `iam.PolicyStatement`\n   * object like you will see in the rest of the CDK.\n   *\n   *\n   * @example\n   * declare const provider: AssertionsProvider;\n   * provider.addToRolePolicy({\n   *   Effect: 'Allow',\n   *   Action: ['s3:GetObject'],\n   *   Resource: ['*'],\n   * });\n   */\n  public addToRolePolicy(statement: any): void {\n    this.handler.addToRolePolicy(statement);\n  }\n\n  /**\n   * Grant a principal access to invoke the assertion provider\n   * lambda function\n   * [disable-awslint:no-grants]\n   *\n   * @param principalArn the ARN of the principal that should be given\n   *  permission to invoke the assertion provider\n   */\n  public grantInvoke(principalArn: string): void {\n    new CfnResource(this, 'Invoke', {\n      type: 'AWS::Lambda::Permission',\n      properties: {\n        Action: 'lambda:InvokeFunction',\n        FunctionName: this.serviceToken,\n        Principal: principalArn,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class FunctionUrlOriginAccessControl for AWS resource management", "output": "export class FunctionUrlOriginAccessControl extends OriginAccessControlBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cloudfront.FunctionUrlOriginAccessControl';\n\n  /**\n   * Imports a Lambda Function URL origin access control from its id.\n   */\n  public static fromOriginAccessControlId(scope: Construct, id: string, originAccessControlId: string): IOriginAccessControl {\n    class Import extends Resource implements IOriginAccessControl {\n      public readonly originAccessControlId = originAccessControlId;\n      public readonly originAccessControlOriginType = OriginAccessControlOriginType.LAMBDA;\n\n      public get originAccessControlRef(): OriginAccessControlReference {\n        return {\n          originAccessControlId: this.originAccessControlId,\n        };\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * The unique identifier of this Origin Access Control.\n   * @attribute\n   */\n  public readonly originAccessControlId: string;\n\n  constructor(scope: Construct, id: string, props: FunctionUrlOriginAccessControlProps = {}) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnOriginAccessControl(this, 'Resource', {\n      originAccessControlConfig: {\n        description: props.description,\n        name: props.originAccessControlName ?? Names.uniqueResourceName(this, { maxLength: 64 }),\n        signingBehavior: props.signing?.behavior ?? SigningBehavior.ALWAYS,\n        signingProtocol: props.signing?.protocol ?? SigningProtocol.SIGV4,\n        originAccessControlOriginType: OriginAccessControlOriginType.LAMBDA, // Lambda specific OAC\n      },\n    });\n\n    this.originAccessControlId = resource.attrId;\n  }\n}", "language": "typescript"}
{"input": "Service connect app protocol.", "output": "export class AppProtocol {\n  /**\n   * HTTP app protocol.\n   */\n  public static http = new AppProtocol('http');\n  /**\n   * HTTP2 app protocol.\n   */\n  public static http2 = new AppProtocol('http2');\n  /**\n   * GRPC app protocol.\n   */\n  public static grpc = new AppProtocol('grpc');\n\n  /**\n   * Custom value.\n   */\n  public readonly value: string;\n\n  protected constructor(value: string) {\n    this.value = value;\n  }\n}", "language": "typescript"}
{"input": "CDK class GitHubEnterpriseSourceCredentials for AWS resource management", "output": "export class GitHubEnterpriseSourceCredentials extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codebuild.GitHubEnterpriseSourceCredentials';\n\n  constructor(scope: Construct, id: string, props: GitHubEnterpriseSourceCredentialsProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnSourceCredential(this, 'Resource', {\n      serverType: 'GITHUB_ENTERPRISE',\n      authType: 'PERSONAL_ACCESS_TOKEN',\n      token: props.accessToken.unsafeUnwrap(), // Safe usage\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF operations", "output": "def test_specified_resources_created(self):\n    template.resource_count_is('AWS::Lambda::Function', 1)\n    template.resource_count_is('AWS::Events::Rule', 1)", "language": "python"}
{"input": "CDK class DatabaseSecret for AWS resource management", "output": "export class DatabaseSecret extends secretsmanager.Secret {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.DatabaseSecret';\n\n  constructor(scope: Construct, id: string, props: DatabaseSecretProps) {\n    const excludeCharacters = props.excludeCharacters ?? DEFAULT_PASSWORD_EXCLUDE_CHARS;\n\n    super(scope, id, {\n      encryptionKey: props.encryptionKey,\n      description: `Generated by the CDK for stack: ${Aws.STACK_NAME}`,\n      secretName: props.secretName,\n      generateSecretString: {\n        passwordLength: 30, // Oracle password cannot have more than 30 characters\n        secretStringTemplate: JSON.stringify({\n          username: props.username,\n          dbname: props.dbname,\n          masterarn: props.masterSecret?.secretArn,\n        }),\n        generateStringKey: 'password',\n        excludeCharacters,\n      },\n      replicaRegions: props.replicaRegions,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.replaceOnPasswordCriteriaChanges) {\n      const hash = md5hash(JSON.stringify({\n        // Use here the options that influence the password generation.\n        // If at some point we add other password customization options\n        // they should be added here below (e.g. `passwordLength`).\n        excludeCharacters,\n      }));\n      const logicalId = `${Names.uniqueId(this)}${hash}`;\n\n      const secret = this.node.defaultChild as secretsmanager.CfnSecret;\n      secret.overrideLogicalId(logicalId.slice(-255)); // Take last 255 chars\n    }\n  }\n}", "language": "typescript"}
{"input": "Verify cdk.out directory is included in npmignore since we should not be publishing it.", "output": "export class CdkOutMustBeNpmIgnored extends ValidationRule {\n  public readonly name = 'package-info/npm-ignore-cdk-out';\n\n  public validate(pkg: PackageJson): void {\n    const npmIgnorePath = path.join(pkg.packageRoot, '.npmignore');\n\n    if (fs.existsSync(npmIgnorePath)) {\n      const npmIgnore = fs.readFileSync(npmIgnorePath);\n\n      if (!npmIgnore.includes('**/cdk.out')) {\n        pkg.report({\n          ruleName: this.name,\n          message: `${npmIgnorePath}: Must exclude **/cdk.out`,\n          fix: () => fs.writeFileSync(\n            npmIgnorePath,\n            `${npmIgnore}\\n# exclude cdk artifacts\\n**/cdk.out`,\n          ),\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportCertificates for AWS resource management", "output": "class ImportCertificates extends Construct {\n  public readonly serverCertificateArn: string;\n  public readonly clientCertificateArn: string;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const serviceToken = CustomResourceProvider.getOrCreate(this, IMPORT_CERTIFICATES_RESOURCE_TYPE, {\n      codeDirectory: path.join(__dirname, 'import-certificates-handler'),\n      runtime: STANDARD_CUSTOM_RESOURCE_PROVIDER_RUNTIME,\n      policyStatements: [{\n        Effect: 'Allow',\n        Action: ['acm:ImportCertificate', 'acm:DeleteCertificate'],\n        Resource: '*',\n      }],\n    });\n\n    const createCertificates = new CustomResource(this, 'CreateCertificates', {\n      resourceType: IMPORT_CERTIFICATES_RESOURCE_TYPE,\n      serviceToken,\n    });\n    this.serverCertificateArn = createCertificates.getAttString('ClientCertificateArn');\n    this.clientCertificateArn = createCertificates.getAttString('ServerCertificateArn');\n\n    new CustomResource(this, 'DeleteCertificates', {\n      resourceType: IMPORT_CERTIFICATES_RESOURCE_TYPE,\n      serviceToken,\n      properties: {\n        ServerCertificateArn: this.serverCertificateArn,\n        ClientCertificateArn: this.clientCertificateArn,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Component for AWS resource management", "output": "export class Component extends ComponentBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.Component';\n\n  /**\n   * Import an existing component given its ARN.\n   */\n  public static fromComponentArn(scope: Construct, id: string, componentArn: string): IComponent {\n    return this.fromComponentAttributes(scope, id, { componentArn });\n  }\n\n  /**\n   * Import an existing component given its name. The provided name must be normalized by converting all alphabetical\n   * characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromComponentName(scope: Construct, id: string, componentName: string): IComponent {\n    return this.fromComponentAttributes(scope, id, { componentName });\n  }\n\n  /**\n   * Import an existing component by providing its attributes. If the component name is provided as an attribute, it\n   * must be normalized by converting all alphabetical characters to lowercase, and replacing all spaces and underscores\n   * with hyphens.\n   */\n  public static fromComponentAttributes(scope: Construct, id: string, attrs: ComponentAttributes): IComponent {\n    if (attrs.componentArn && (attrs.componentName || attrs.componentVersion)) {\n      throw new cdk.ValidationError(\n        'a componentName or componentVersion cannot be provided when a componentArn is provided',\n        scope,\n      );\n    }\n\n    if (!attrs.componentArn && !attrs.componentName) {\n      throw new cdk.ValidationError('either componentArn or componentName is required', scope);\n    }\n\n    const componentArn =\n      attrs.componentArn ??\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'component',\n        resourceName: `${attrs.componentName}/${attrs.componentVersion ?? LATEST_VERSION}`,\n      });\n\n    const [componentName, componentVersion] = (() => {\n      if (attrs.componentName) {\n        return [attrs.componentName, attrs.componentVersion ?? LATEST_VERSION];\n      }\n\n      const componentNameVersion = cdk.Stack.of(scope).splitArn(\n        componentArn,\n        cdk.ArnFormat.SLASH_RESOURCE_NAME,\n      ).resourceName!;\n\n      const componentNameVersionSplit = cdk.Fn.split('/', componentNameVersion);\n      return [cdk.Fn.select(0, componentNameVersionSplit), cdk.Fn.select(1, componentNameVersionSplit)];\n    })();\n\n    class Import extends ComponentBase {\n      public readonly componentArn = componentArn;\n      public readonly componentName = componentName;\n      public readonly componentVersion = componentVersion;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Return whether the given object is a Component.\n   */\n  public static isComponent(x: any): x is Component {\n    return x !== null && typeof x === 'object' && COMPONENT_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the component\n   */\n  public readonly componentArn: string;\n\n  /**\n   * The name of the component\n   */\n  public readonly componentName: string;\n\n  /**\n   * The version of the component\n   */\n  public readonly componentVersion: string;\n\n  /**\n   * Whether the component is encrypted\n   */\n  public readonly encrypted: boolean;\n\n  /**\n   * The type of the component\n   *\n   * @attribute\n   */\n  public readonly componentType: string;\n\n  protected readonly kmsKey?: kms.IKey;\n\n  public constructor(scope: Construct, id: string, props: ComponentProps) {\n    super(scope, id, {\n      physicalName:\n        props.componentName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, COMPONENT_SYMBOL, { value: true });\n\n    this.validateComponentName();\n\n    props.supportedOsVersions?.forEach((osVersion) => {\n      if (osVersion.platform !== props.platform) {\n        throw new cdk.ValidationError(\n          `os version ${osVersion.osVersion} is not compatible with platform ${props.platform}`,\n          this,\n        );\n      }\n    });\n\n    const componentVersion = props.componentVersion ?? '1.0.0';\n    const supportedOsVersions = props.supportedOsVersions?.filter((osVersion) => osVersion.osVersion !== undefined);\n\n    const component = new CfnComponent(this, 'Resource', {\n      name: this.physicalName,\n      version: componentVersion,\n      changeDescription: props.changeDescription,\n      description: props.description,\n      platform: props.platform,\n      kmsKeyId: props.kmsKey?.keyArn,\n      tags: props.tags,\n      ...(supportedOsVersions?.length && {\n        supportedOsVersions: supportedOsVersions.map((osVersion) => osVersion.osVersion!),\n      }),\n      ...props.data.render(),\n    });\n\n    this.componentName = this.getResourceNameAttribute(component.attrName);\n    this.componentArn = this.getResourceArnAttribute(component.attrArn, {\n      service: 'imagebuilder',\n      resource: 'component',\n      resourceName: `${this.physicalName}/${componentVersion}`,\n    });\n    this.componentVersion = componentVersion;\n    this.encrypted = true; // Components are always encrypted\n    this.componentType = component.attrType;\n    this.kmsKey = props.kmsKey;\n  }\n\n  private validateComponentName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError(\n        `the componentName cannot be longer than 128 characters, got: '${this.physicalName}'`,\n        this,\n      );\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError(`the componentName cannot contain spaces, got: '${this.physicalName}'`, this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError(`the componentName cannot contain underscores, got: '${this.physicalName}'`, this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError(`the componentName must be lowercase, got: '${this.physicalName}'`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedGatewayTarget for AWS resource management", "output": "class ImportedGatewayTarget extends GatewayTargetBase {\n      public readonly targetArn = attrs.targetArn;\n      public readonly targetId = attrs.targetId;\n      public readonly name = attrs.gatewayTargetName;\n      public readonly description = attrs.status;\n      public readonly gateway = attrs.gateway;\n      public readonly credentialProviderConfigurations = [];\n      public readonly targetProtocolType = GatewayTargetProtocolType.MCP;\n      public readonly status = attrs.status;\n      public readonly statusReasons = undefined;\n      public readonly createdAt = attrs.createdAt;\n      public readonly updatedAt = attrs.updatedAt;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n      }\n    }", "language": "typescript"}
{"input": "An HTTP traffic generator.\n\nHits a specified URL at some TPS.", "output": "class GenGen(Construct):\n    \"\"\"\n    An HTTP traffic generator.\n\n    Hits a specified URL at some TPS.\n    \"\"\"\n\n    def __init__(self, scope: Construct, id: str, *, vpc: aws_ec2.IVpc, url: str, tps: int):\n        \"\"\"\n        Defines an instance of the traffic generator.\n\n        :param scope: construct scope\n        :param id:    construct id\n        :param vpc:   the VPC in which to host the traffic generator\n        :param url:   the URL to hit\n        :param tps:   the number of transactions per second\n        \"\"\"\n        super().__init__(scope, id)\n\n        # define an ECS cluster hosted within the requested VPC\n        cluster = aws_ecs.Cluster(self, 'cluster', vpc=vpc)\n\n        # define our task definition with a single container\n        # the image is built & published from a local asset directory\n        task_definition = aws_ecs.FargateTaskDefinition(self, 'PingTask')\n        task_definition.add_container('Pinger',\n                                      image=aws_ecs.ContainerImage.from_asset(\"pinger\"),\n                                      environment={'URL': url})\n\n        # define our fargate service. TPS determines how many instances we\n        # want from our task (each task produces a single TPS)\n        aws_ecs.FargateService(self, 'service',\n                               cluster=cluster,\n                               task_definition=task_definition,\n                               desired_count=tps)", "language": "python"}
{"input": "CDK class Table for AWS resource management", "output": "export class Table extends TableBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-dynamodb.Table';\n\n  /**\n   * Permits an IAM Principal to list all DynamoDB Streams.\n   * @deprecated Use `#grantTableListStreams` for more granular permission\n   *\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The principal (no-op if undefined)\n   */\n  public static grantListStreams(grantee: iam.IGrantable): iam.Grant {\n    return iam.Grant.addToPrincipal({\n      grantee,\n      actions: ['dynamodb:ListStreams'],\n      resourceArns: ['*'],\n    });\n  }\n\n  /**\n   * Creates a Table construct that represents an external table via table name.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param tableName The table's name.\n   */\n  public static fromTableName(scope: Construct, id: string, tableName: string): ITable {\n    return Table.fromTableAttributes(scope, id, { tableName });\n  }\n\n  /**\n   * Creates a Table construct that represents an external table via table arn.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param tableArn The table's ARN.\n   */\n  public static fromTableArn(scope: Construct, id: string, tableArn: string): ITable {\n    return Table.fromTableAttributes(scope, id, { tableArn });\n  }\n\n  /**\n   * Creates a Table construct that represents an external table.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param attrs A `TableAttributes` object.\n   */\n  public static fromTableAttributes(scope: Construct, id: string, attrs: TableAttributes): ITable {\n    class Import extends TableBase {\n      public readonly tableName: string;\n      public readonly tableArn: string;\n      public readonly tableStreamArn?: string;\n      public readonly encryptionKey?: kms.IKey;\n      public resourcePolicy?: iam.PolicyDocument;\n      public readonly hasIndex = (attrs.grantIndexPermissions ?? false) ||\n          (attrs.globalIndexes ?? []).length > 0 ||\n          (attrs.localIndexes ?? []).length > 0;\n      public readonly regions = [];\n\n      constructor(_tableArn: string, tableName: string, tableStreamArn?: string) {\n        super(scope, id);\n        this.tableArn = _tableArn;\n        this.tableName = tableName;\n        this.tableStreamArn = tableStreamArn;\n        this.encryptionKey = attrs.encryptionKey;\n      }\n\n      public addToResourcePolicy(_statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n        // Imported tables cannot have resource policies modified\n        return { statementAdded: false };\n      }\n    }\n\n    let name: string;\n    let arn: string;\n    const stack = Stack.of(scope);\n    if (!attrs.tableName) {\n      if (!attrs.tableArn) {\n        throw new ValidationError('One of tableName or tableArn is required!', scope);\n      }\n\n      arn = attrs.tableArn;\n      const maybeTableName = stack.splitArn(attrs.tableArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n      if (!maybeTableName) {\n        throw new ValidationError('ARN for DynamoDB table must be in the form: ...', scope);\n      }\n      name = maybeTableName;\n    } else {\n      if (attrs.tableArn) {\n        throw new ValidationError('Only one of tableArn or tableName can be provided', scope);\n      }\n      name = attrs.tableName;\n      arn = stack.formatArn({\n        service: 'dynamodb',\n        resource: 'table',\n        resourceName: attrs.tableName,\n      });\n    }\n\n    return new Import(arn, name, attrs.tableStreamArn);\n  }\n\n  public readonly encryptionKey?: kms.IKey;\n\n  /**\n   * Resource policy to assign to DynamoDB Table.\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-resourcepolicy.html\n   * @default - No resource policy statements are added to the created table.\n   */\n  public resourcePolicy?: iam.PolicyDocument;\n\n  /**\n   * @attribute\n   */\n  public readonly tableArn: string;\n\n  /**\n   * @attribute\n   */\n  public readonly tableName: string;\n\n  /**\n   * @attribute\n   */\n  public readonly tableStreamArn: string | undefined;\n\n  private readonly table: CfnTable;\n\n  private readonly keySchema = new Array<CfnTable.KeySchemaProperty>();\n  private readonly attributeDefinitions = new Array<CfnTable.AttributeDefinitionProperty>();\n  private readonly globalSecondaryIndexes = new Array<CfnTable.GlobalSecondaryIndexProperty>();\n  private readonly localSecondaryIndexes = new Array<CfnTable.LocalSecondaryIndexProperty>();\n\n  /**\n   * Schemas for the table and all of the indexes\n   */\n  private readonly schemas = new Map<string, KeySchema>();\n  private readonly nonKeyAttributes = new Set<string>();\n\n  private readonly tablePartitionKey?: Attribute;\n  private readonly tableSortKey?: Attribute;\n\n  private readonly billingMode: BillingMode;\n  private readonly tableScaling: ScalableAttributePair = {};\n  private readonly indexScaling = new Map<string, ScalableAttributePair>();\n  private readonly scalingRole: iam.IRole;\n\n  private readonly globalReplicaCustomResources = new Array<CustomResource>();\n\n  public readonly regions? = new Array<string>();\n\n  constructor(scope: Construct, id: string, props: TableProps) {\n    super(scope, id, {\n      physicalName: props.tableName,\n    });\n\n    if (!props?.partitionKey) {\n      throw new ValidationError('partitionKey is required for Table', this);\n    }\n\n    const normalizedSchema = parseKeySchema(props, this);\n    // We put the schema into 'secondaryIndexSchemas' under a well-known key, so\n    // that `schema()` and `schemaV2()` can retrieve it without additional case\n    // analysis. It's not really necessary otherwise.\n    this.schemas.set(SPECIAL_TABLE_SCHEMA_NAME, normalizedSchema);\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.resourcePolicy = props.resourcePolicy;\n\n    const { sseSpecification, encryptionKey } = this.parseEncryption(props);\n\n    const pointInTimeRecoverySpecification = this.validatePitr(props);\n\n    const contributorInsightsSpecification = this.validateCCI(props);\n\n    let streamSpecification: CfnTable.StreamSpecificationProperty | undefined;\n    if (props.replicationRegions) {\n      if (props.stream && props.stream !== StreamViewType.NEW_AND_OLD_IMAGES) {\n        throw new ValidationError('`stream` must be set to `NEW_AND_OLD_IMAGES` when specifying `replicationRegions`', this);\n      }\n      streamSpecification = { streamViewType: StreamViewType.NEW_AND_OLD_IMAGES };\n\n      this.billingMode = props.billingMode ?? BillingMode.PAY_PER_REQUEST;\n    } else {\n      this.billingMode = props.billingMode ?? BillingMode.PROVISIONED;\n      if (props.stream) {\n        streamSpecification = { streamViewType: props.stream };\n      }\n    }\n    this.validateProvisioning(props);\n\n    const kinesisStreamSpecification = props.kinesisStream\n      ? {\n        streamArn: props.kinesisStream.streamArn,\n        ...(props.kinesisPrecisionTimestamp && { approximateCreationDateTimePrecision: props.kinesisPrecisionTimestamp }),\n      }\n      : undefined;\n\n    this.table = new CfnTable(this, 'Resource', {\n      tableName: this.physicalName,\n      keySchema: this.keySchema,\n      attributeDefinitions: this.attributeDefinitions,\n      globalSecondaryIndexes: Lazy.any({ produce: () => this.globalSecondaryIndexes }, { omitEmptyArray: true }),\n      localSecondaryIndexes: Lazy.any({ produce: () => this.localSecondaryIndexes }, { omitEmptyArray: true }),\n      pointInTimeRecoverySpecification: pointInTimeRecoverySpecification,\n      billingMode: this.billingMode === BillingMode.PAY_PER_REQUEST ? this.billingMode : undefined,\n      provisionedThroughput: this.billingMode === BillingMode.PAY_PER_REQUEST ? undefined : {\n        readCapacityUnits: props.readCapacity || 5,\n        writeCapacityUnits: props.writeCapacity || 5,\n      },\n      ...(props.maxReadRequestUnits || props.maxWriteRequestUnits ?\n        {\n          onDemandThroughput: this.billingMode === BillingMode.PROVISIONED ? undefined : {\n            maxReadRequestUnits: props.maxReadRequestUnits || undefined,\n            maxWriteRequestUnits: props.maxWriteRequestUnits || undefined,\n          },\n        } : undefined),\n      sseSpecification,\n      streamSpecification,\n      tableClass: props.tableClass,\n      timeToLiveSpecification: props.timeToLiveAttribute ? { attributeName: props.timeToLiveAttribute, enabled: true } : undefined,\n      contributorInsightsSpecification: contributorInsightsSpecification,\n      kinesisStreamSpecification: kinesisStreamSpecification,\n      deletionProtectionEnabled: props.deletionProtection,\n      importSourceSpecification: this.renderImportSourceSpecification(props.importSource),\n      warmThroughput: props.warmThroughput ?? undefined,\n    });\n    this.table.applyRemovalPolicy(props.removalPolicy);\n\n    // Set up dynamic resourcePolicy that can be modified by addToResourcePolicy\n    if (this.resourcePolicy) {\n      this.table.resourcePolicy = { policyDocument: this.resourcePolicy };\n    }\n\n    this.encryptionKey = encryptionKey;\n\n    this.tableArn = this.getResourceArnAttribute(this.table.attrArn, {\n      service: 'dynamodb',\n      resource: 'table',\n      resourceName: this.physicalName,\n    });\n    this.tableName = this.getResourceNameAttribute(this.table.ref);\n\n    if (props.tableName) { this.node.addMetadata('aws:cdk:hasPhysicalName', this.tableName); }\n\n    this.tableStreamArn = streamSpecification ? this.table.attrStreamArn : undefined;\n\n    this.scalingRole = this.makeScalingRole();\n\n    this.addKey(props.partitionKey!, HASH_KEY_TYPE);\n    this.tablePartitionKey = props.partitionKey;\n\n    if (props.sortKey) {\n      this.addKey(props.sortKey, RANGE_KEY_TYPE);\n      this.tableSortKey = props.sortKey;\n    }\n\n    if (props.replicationRegions && props.replicationRegions.length > 0) {\n      this.createReplicaTables(props.replicationRegions, props.replicationTimeout, props.waitForReplicationToFinish, props.replicaRemovalPolicy);\n    }\n\n    this.node.addValidation({ validate: () => this.validateTable() });\n  }", "language": "typescript"}
{"input": "method to create a new AutoScaling group for managing WordPress instances. see user_data/wp_webserver txt file to see the User Data script", "output": "def create_wp_webserver(self, vpc, db):\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2)\n        user_data = self.get_user_data(\"wp_webserver\")\n        # we need to modify the user data script to provide the dns name of the\n        # mysql database installed in the private subnet.\n        user_data = re.sub('dbhost', db.instance_private_dns_name, user_data)\n\n        wp_as = autoscaling.AutoScalingGroup(self,\n                \"WordPressAS\",\n                vpc=vpc,\n                instance_type=ec2.InstanceType.of(ec2.InstanceClass.T3, ec2.InstanceSize.MEDIUM),\n                machine_image=amzn_linux,\n                user_data=ec2.UserData.custom(user_data),\n                vpc_subnets=ec2.SubnetSelection(availability_zones=[LZ_NAME],\n                                subnet_type=ec2.SubnetType.PRIVATE_ISOLATED),\n        )\n        # allow connections from wp_instance to db\n        db.connections.allow_from(wp_as, ec2.Port.tcp(3306), \"WP access on db port\")\n        return wp_as", "language": "python"}
{"input": "Test for S3 Bucket:\n    - Upload Bucket", "output": "def test_s3_bucket_with_event_notification_created(template):\n    \"\"\"\n      Test for S3 Bucket:\n          - Upload Bucket\n      \"\"\"\n    template.resource_count_is(\"Custom::S3BucketNotifications\", 1)\n    template.resource_count_is(\"AWS::S3::Bucket\", 1)", "language": "python"}
{"input": "CDK Stack that creates KMS, CloudWatch, CloudFormation resources", "output": "class SsmIncidentAlarmActionIntegrationTestStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const responsePlanName = 'test-response-plan';\n\n    const key = new kms.Key(this, 'Key', {\n      pendingWindow: Duration.days(7),\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    const replicationSet = new ssmIncidents.CfnReplicationSet(this, 'ReplicationSet', {\n      deletionProtected: false,\n      regions: [{\n        regionName: this.region,\n        regionConfiguration: {\n          sseKmsKeyId: key.keyArn,\n        },\n      }],\n    });\n\n    const responsePlan = new ssmIncidents.CfnResponsePlan(this, 'ResponsePlan', {\n      name: responsePlanName,\n      incidentTemplate: {\n        title: 'Incident Title',\n        impact: 1,\n      },\n    });\n\n    responsePlan.node.addDependency(replicationSet);\n\n    const metric = new cloudwatch.Metric({\n      namespace: 'CDK/Test',\n      metricName: 'Metric',\n      label: 'Metric [AVG: ${AVG}]',\n    });\n\n    const alarm = new cloudwatch.Alarm(this, 'Alarm1', {\n      metric,\n      threshold: 100,\n      evaluationPeriods: 3,\n    });\n    alarm.node.addDependency(responsePlan);\n\n    alarm.addAlarmAction(new cloudwatchActions.SsmIncidentAction(responsePlanName));\n  }\n}", "language": "typescript"}
{"input": "CDK class BonjourFargate for AWS resource management", "output": "class BonjourFargate(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create VPC and Fargate Cluster\n        # NOTE: Limit AZs to avoid reaching resource quotas\n        vpc = ec2.Vpc(\n            self, \"MyVpc\",\n            max_azs=2\n        )\n\n        cluster = ecs.Cluster(\n            self, 'Ec2Cluster',\n            vpc=vpc\n        )\n\n        fargate_service = ecs_patterns.NetworkLoadBalancedFargateService(\n            self, \"FargateService\",\n            cluster=cluster,\n            task_image_options=ecs_patterns.NetworkLoadBalancedTaskImageOptions(\n                image=ecs.ContainerImage.from_registry(\"amazon/amazon-ecs-sample\")\n            )\n        )\n\n        fargate_service.service.connections.security_groups[0].add_ingress_rule(\n            peer = ec2.Peer.ipv4(vpc.vpc_cidr_block),\n            connection = ec2.Port.tcp(80),\n            description=\"Allow http inbound from VPC\"\n        )\n\n        CfnOutput(\n            self, \"LoadBalancerDNS\",\n            value=fargate_service.load_balancer.load_balancer_dns_name\n        )", "language": "python"}
{"input": "CDK helper function for DynamoDB operations", "output": "def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        table_name: str,\n        table_replica_regions: List[ReplicaConfig],\n        **kwargs\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        ddb.CfnGlobalTable(\n            self,\n            \"global-table\",\n            table_name=table_name,\n            billing_mode=\"PAY_PER_REQUEST\",\n            attribute_definitions=[\n                ddb.CfnGlobalTable.AttributeDefinitionProperty(\n                    attribute_name=\"id\", attribute_type=\"S\"\n                )\n            ],\n            key_schema=[\n                ddb.CfnGlobalTable.KeySchemaProperty(\n                    attribute_name=\"id\", key_type=\"HASH\"\n                )\n            ],\n            replicas=[\n                ddb.CfnGlobalTable.ReplicaSpecificationProperty(\n                    region=replica_config[\"region\"],\n                    sse_specification=ddb.CfnGlobalTable.ReplicaSSESpecificationProperty(\n                        kms_master_key_id=cdk.Fn.import_value(\n                            replica_config[\"key_export_name\"]\n                        )\n                    ),\n                )\n                for replica_config in table_replica_regions\n            ],\n            sse_specification=ddb.CfnGlobalTable.SSESpecificationProperty(\n                sse_enabled=True, sse_type=\"KMS\"\n            ),\n            stream_specification=ddb.CfnGlobalTable.StreamSpecificationProperty(\n                stream_view_type=\"KEYS_ONLY\"\n            ),\n        )", "language": "python"}
{"input": "Health check settings for multiple types", "output": "export class HealthChecks {\n  /**\n   * Use EC2 only for health checks.\n   *\n   * @param options EC2 health checks options\n   */\n  public static ec2(options: Ec2HealthChecksOptions = {}): HealthChecks {\n    return new HealthChecks(['EC2'], options.gracePeriod);\n  }\n\n  /**\n   * Use additional health checks other than EC2.\n   *\n   * Specify types other than EC2, as EC2 is always enabled.\n   * It considers the instance unhealthy if it fails either the EC2 status checks or the additional health checks.\n   *\n   * @param options Additional health checks options\n   */\n  public static withAdditionalChecks(options: AdditionalHealthChecksOptions): HealthChecks {\n    return new HealthChecks(options.additionalTypes, options.gracePeriod);\n  }\n\n  private constructor(public readonly types: string[], public readonly gracePeriod?: Duration) {\n    if (types.length === 0) {\n      throw new UnscopedValidationError('At least one health check type must be specified in \\'additionalTypes\\' for \\'healthChecks\\'');\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class OpenSearchDataSource for AWS resource management", "output": "export class OpenSearchDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.OpenSearchDataSource';\n\n  constructor(scope: Construct, id: string, props: OpenSearchDataSourceProps) {\n    super(scope, id, props, {\n      type: 'AMAZON_OPENSEARCH_SERVICE',\n      openSearchServiceConfig: {\n        awsRegion: props.domain.env.region,\n        endpoint: `https://${props.domain.domainEndpoint}`,\n      },\n    });\n\n    props.domain.grantReadWrite(this);\n  }\n}", "language": "typescript"}
{"input": "Base class for Principals that wrap other principals", "output": "class PrincipalAdapter extends PrincipalBase {\n  public readonly assumeRoleAction: IPrincipal['assumeRoleAction'];\n  public readonly principalAccount: IPrincipal['principalAccount'];\n\n  constructor(protected readonly wrapped: IPrincipal) {\n    super();\n\n    this.assumeRoleAction = this.wrapped.assumeRoleAction;\n    this.principalAccount = this.wrapped.principalAccount;\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment { return this.wrapped.policyFragment; }\n\n  public addToPolicy(statement: PolicyStatement): boolean {\n    return this.wrapped.addToPolicy(statement);\n  }\n  public addToPrincipalPolicy(statement: PolicyStatement): AddToPrincipalPolicyResult {\n    return this.wrapped.addToPrincipalPolicy(statement);\n  }\n\n  /**\n   * Append the given string to the wrapped principal's dedupe string (if available)\n   */\n  protected appendDedupe(append: string): string | undefined {\n    const inner = ComparablePrincipal.dedupeStringFor(this.wrapped);\n    return inner !== undefined ? `${this.constructor.name}:${inner}:${append}` : undefined;\n  }\n}\n\n/**\n * An IAM principal with additional conditions specifying when the policy is in effect.\n *\n * For more information about conditions, see:\n * https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html\n */\nexport class PrincipalWithConditions extends PrincipalAdapter {\n  private additionalConditions: Conditions;\n\n  constructor(principal: IPrincipal, conditions: Conditions) {\n    super(principal);\n    this.additionalConditions = conditions;\n  }\n\n  public addToAssumeRolePolicy(doc: PolicyDocument) {\n    // Lazy import to avoid circular import dependencies during startup\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const adapter: typeof import('./private/policydoc-adapter') = require('./private/policydoc-adapter');\n\n    defaultAddPrincipalToAssumeRole(this.wrapped, new adapter.MutatingPolicyDocumentAdapter(doc, (statement) => {\n      // Avoid override of existing actions (see https://github.com/aws/aws-cdk/issues/28426)\n      statement.addActions(this.assumeRoleAction);\n      statement.addConditions(this.conditions);\n      return statement;\n    }));\n  }\n\n  /**\n   * Add a condition to the principal\n   */\n  public addCondition(key: string, value: Condition) {\n    validateConditionObject(value);\n\n    const existingValue = this.additionalConditions[key];\n    if (!existingValue) {\n      this.additionalConditions[key] = value;\n      return;\n    }\n    validateConditionObject(existingValue);\n\n    this.additionalConditions[key] = { ...existingValue, ...value };\n  }\n\n  /**\n   * Adds multiple conditions to the principal\n   *\n   * Values from the conditions parameter will overwrite existing values with the same operator\n   * and key.\n   */\n  public addConditions(conditions: Conditions) {\n    Object.entries(conditions).forEach(([key, value]) => {\n      this.addCondition(key, value);\n    });\n  }\n\n  /**\n   * The conditions under which the policy is in effect.\n   * See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   */\n  public get conditions() {\n    return this.mergeConditions(this.wrapped.policyFragment.conditions, this.additionalConditions);\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment(this.wrapped.policyFragment.principalJson, this.conditions);\n  }\n\n  public toString() {\n    return this.wrapped.toString();\n  }\n\n  /**\n   * JSON-ify the principal\n   *\n   * Used when JSON.stringify() is called\n   */\n  public toJSON() {\n    // Have to implement toJSON() because the default will lead to infinite recursion.\n    return this.policyFragment.principalJson;\n  }\n\n  public dedupeString(): string | undefined {\n    return this.appendDedupe(JSON.stringify(this.conditions));\n  }\n\n  private mergeConditions(principalConditions: Conditions, additionalConditions: Conditions): Conditions {\n    const mergedConditions: Conditions = {};\n    Object.entries(principalConditions).forEach(([operator, condition]) => {\n      mergedConditions[operator] = condition;\n    });\n\n    Object.entries(additionalConditions).forEach(([operator, condition]) => {\n      // merge the conditions if one of the additional conditions uses an\n      // operator that's already used by the principal's conditions merge the\n      // inner structure.\n      const existing = mergedConditions[operator];\n      if (!existing) {\n        mergedConditions[operator] = condition;\n        return; // continue\n      }\n\n      // if either the existing condition or the new one contain unresolved\n      // tokens, fail the merge. this is as far as we go at this point.\n      if (cdk.Token.isUnresolved(condition) || cdk.Token.isUnresolved(existing)) {\n        throw new UnscopedValidationError(`multiple \"${operator}\" conditions cannot be merged if one of them contains an unresolved token`);\n      }\n\n      validateConditionObject(existing);\n      validateConditionObject(condition);\n\n      mergedConditions[operator] = { ...existing, ...condition };\n    });\n    return mergedConditions;\n  }\n}\n\n/**\n * Enables session tags on role assumptions from a principal\n *\n * For more information on session tags, see:\n * https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html\n */\nexport class SessionTagsPrincipal extends PrincipalAdapter {\n  constructor(principal: IPrincipal) {\n    super(principal);\n  }\n\n  public addToAssumeRolePolicy(doc: PolicyDocument) {\n    // Lazy import to avoid circular import dependencies during startup\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const adapter: typeof import('./private/policydoc-adapter') = require('./private/policydoc-adapter');\n\n    defaultAddPrincipalToAssumeRole(this.wrapped, new adapter.MutatingPolicyDocumentAdapter(doc, (statement) => {\n      statement.addActions('sts:TagSession');\n      return statement;\n    }));\n  }\n\n  public dedupeString(): string | undefined {\n    return this.appendDedupe('');\n  }\n}\n\n/**\n * A collection of the fields in a PolicyStatement that can be used to identify a principal.\n *\n * This consists of the JSON used in the \"Principal\" field, and optionally a\n * set of \"Condition\"s that need to be applied to the policy.\n *\n * Generally, a principal looks like:\n *\n *     { '<TYPE>': ['ID', 'ID', ...] }\n *\n * And this is also the type of the field `principalJson`.  However, there is a\n * special type of principal that is just the string '*', which is treated\n * differently by some services. To represent that principal, `principalJson`\n * should contain `{ 'LiteralString': ['*'] }`.\n */\nexport class PrincipalPolicyFragment {\n  /**\n   *\n   * @param principalJson JSON of the \"Principal\" section in a policy statement\n   * @param conditions conditions that need to be applied to this policy\n   */\n  constructor(\n    public readonly principalJson: { [key: string]: string[] },\n    /**\n     * The conditions under which the policy is in effect.\n     * See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n     */\n    public readonly conditions: Conditions = {}) {\n  }\n}\n\n/**\n * Specify a principal by the Amazon Resource Name (ARN).\n * You can specify AWS accounts, IAM users, Federated SAML users, IAM roles, and specific assumed-role sessions.\n * You cannot specify IAM groups or instance profiles as principals\n *\n * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_principal.html\n */\nexport class ArnPrincipal extends PrincipalBase {\n  /**\n   *\n   * @param arn Amazon Resource Name (ARN) of the principal entity (i.e. arn:aws:iam::123456789012:user/user-name)\n   */\n  constructor(public readonly arn: string) {\n    super();\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ AWS: [this.arn] });\n  }\n\n  public toString() {\n    return `ArnPrincipal(${this.arn})`;\n  }\n\n  /**\n   * A convenience method for adding a condition that the principal is part of the specified\n   * AWS Organization.\n   */\n  public inOrganization(organizationId: string) {\n    return this.withConditions({\n      StringEquals: {\n        'aws:PrincipalOrgID': organizationId,\n      },\n    });\n  }\n\n  public dedupeString(): string | undefined {\n    return `ArnPrincipal:${this.arn}`;\n  }\n}\n\n/**\n * Specify AWS account ID as the principal entity in a policy to delegate authority to the account.\n */\nexport class AccountPrincipal extends ArnPrincipal {\n  public readonly principalAccount: string | undefined;\n\n  /**\n   *\n   * @param accountId AWS account ID (i.e. '123456789012')\n   */\n  constructor(public readonly accountId: any) {\n    super(new StackDependentToken(stack => `arn:${stack.partition}:iam::${accountId}:root`).toString());\n    if (!cdk.Token.isUnresolved(accountId) && typeof accountId !== 'string') {\n      throw new UnscopedValidationError('accountId should be of type string');\n    }\n    this.principalAccount = accountId;\n  }\n\n  public toString() {\n    return `AccountPrincipal(${this.accountId})`;\n  }\n}\n\n/**\n * Options for a service principal.\n */\nexport interface ServicePrincipalOpts {\n  /**\n   * The region in which you want to reference the service\n   *\n   * This is only necessary for *cross-region* references to *opt-in* regions. In those\n   * cases, the region name needs to be included to reference the correct service principal.\n   * In all other cases, the global service principal name is sufficient.\n   *\n   * This field behaves differently depending on whether the `@aws-cdk/aws-iam:standardizedServicePrincipals`\n   * flag is set or not:\n   *\n   * - If the flag is set, the input service principal is assumed to be of the form `SERVICE.amazonaws.com`.\n   *   That value will always be returned, unless the given region is an opt-in region and the service\n   *   principal is rendered in a stack in a different region, in which case `SERVICE.REGION.amazonaws.com`\n   *   will be rendered. Under this regime, there is no downside to always specifying the region property:\n   *   it will be rendered only if necessary.\n   * - If the flag is not set, the service principal will resolve to a single principal\n   *   whose name comes from the `@aws-cdk/region-info` package, using the region to override\n   *   the stack region. If there is no entry for this service principal in the database,, the input\n   *   service name is returned literally. This is legacy behavior and is not recommended.\n   *\n   * @default - the resolving Stack's region.\n   */\n  readonly region?: string;\n\n  /**\n   * Additional conditions to add to the Service Principal\n   *\n   * @default - No conditions\n   */\n  readonly conditions?: { [key: string]: any };\n}", "language": "typescript"}
{"input": "CDK class TxtRecord for AWS resource management", "output": "export class TxtRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.TxtRecord';\n\n  constructor(scope: Construct, id: string, props: TxtRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.TXT,\n      target: RecordTarget.fromValues(...props.values.map(v => formatTxt(v))),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ExampleResource for AWS resource management", "output": "export class ExampleResource extends ExampleResourceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.example-construct-library.ExampleResource';\n\n  /**\n   * Reference an existing ExampleResource,\n   * defined outside of the CDK code, by name.\n   *\n   * The class might contain more methods for referencing an existing resource,\n   * like fromExampleResourceArn,\n   * or fromExampleResourceAttributes\n   * (the last one if you want the importing behavior to be more customizable).\n   */\n  public static fromExampleResourceName(scope: Construct, id: string, exampleResourceName: string): IExampleResource {\n    // Imports are almost always implemented as a module-private\n    // inline class in the method itself.\n    // We extend ExampleResourceBase to reuse all of the logic inside it.\n    class Import extends ExampleResourceBase {\n      // we don't have an associated Role in this case\n      public readonly role = undefined;\n      // for imported resources, you always use the UnknownPrincipal,\n      // which ignores all modifications\n      public readonly grantPrincipal = new iam.UnknownPrincipal({ resource: this });\n\n      public readonly exampleResourceName = exampleResourceName;\n      // Since we have the name, we have to generate the ARN,\n      // using the Stack.formatArn helper method from the core library.\n      // We have to know the ARN components of ExampleResource in a few places, so,\n      // to avoid duplication, extract that into a module-private function\n      public readonly exampleResourceArn = Stack.of(scope)\n        .formatArn(exampleResourceArnComponents(exampleResourceName));\n    }\n\n    return new Import(scope, id);\n  }\n\n  // implement all fields that are abstract in ExampleResourceBase\n  public readonly exampleResourceArn: string;\n  public readonly exampleResourceName: string;\n  // while we know 'role' will actually never be undefined in this class,\n  // JSII does not allow changing the optionality of a field\n  // when overriding it, so it has to be 'role?'\n  public readonly role?: iam.IRole;\n  public readonly grantPrincipal: iam.IPrincipal;\n\n  /**\n   * The constructor of a construct has always 3 arguments:\n   * the parent Construct, the string identifier\n   * (locally unique within the scope of the parent),\n   * and a properties struct.\n   *\n   * If the props only have optional properties, like in our case,\n   * make sure to add a default value of an empty object to the props argument.\n   */\n  constructor(scope: Construct, id: string, props: ExampleResourceProps = {}) {\n    // Call the constructor from Resource superclass,\n\n    // which attaches this construct to the construct tree.\n    super(scope, id, {\n      // You need to let the Resource superclass know which of your properties\n      // signifies the resource's physical name.\n      // If your resource doesn't have a physical name,\n      // don't set this property.\n      // For more information on what exactly is a physical name,\n      // see the CDK guide: https://docs.aws.amazon.com/cdk/latest/guide/resources.html#resources_physical_names\n      physicalName: props.waitConditionHandleName,\n    });\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // We often add validations for properties,\n    // so that customers receive feedback about incorrect properties\n    // sooner than a CloudFormation deployment.\n    // However, when validating string (and number!) properties,\n    // it's important to remember that the value can be a CFN function\n    // (think a { Ref: ParameterName } expression in CloudFormation),\n    // and that sort of value would be also encoded as a string;\n    // so, we need to use the Token.isUnresolved() method from the core library\n    // to skip validation in that case.\n    if (props.waitConditionHandleName !== undefined &&\n        !Token.isUnresolved(props.waitConditionHandleName) &&\n        !/^[_a-zA-Z]+$/.test(props.waitConditionHandleName)) {\n      throw new ValidationError('waitConditionHandleName must be non-empty and contain only letters and underscores, ' +\n        `got: '${props.waitConditionHandleName}'`, this);\n    }\n\n    // Inside the implementation of the L2,\n    // we very often use L1 classes (those whose names begin with 'Cfn').\n    // However, it's important we don't 'leak' that fact to the API of the L2 class -\n    // so, we should never take L1 types as inputs in our props,\n    // and we should not surface any L1 classes in public fields or methods of the class.\n    // The 'Cfn*' class is purely an implementation detail.\n\n    // If this was a real resource, we would use a specific L1 for that resource\n    // (like a CfnBucket inside the Bucket class),\n    // but since this is just an example,\n    // we'll use CloudFormation wait conditions.\n\n    // Remember to always, always, pass 'this' as the first argument\n    // when creating any constructs inside your L2s!\n    // This guarantees that they get scoped correctly,\n    // and the CDK will make sure their locally-unique identifiers\n    // are globally unique, which makes your L2 compose.\n    const waitConditionHandle = new CfnWaitConditionHandle(this, 'WaitConditionHandle');\n\n    // The 'main' L1 you create should always have the logical ID 'Resource'.\n    // This is important, so that the ConstructNode.defaultChild method works correctly.\n    // The local variable representing the L1 is often called 'resource' as well.\n    const resource = new CfnWaitCondition(this, 'Resource', {\n      count: 0,\n      handle: waitConditionHandle.ref,\n      timeout: '10',\n    });\n\n    // The resource's physical name and ARN are set using\n    // some protected methods from the Resource superclass\n    // that correctly resolve when your L2 is used in another resource\n    // that is in a different AWS region or account than this one.\n    this.exampleResourceName = this.getResourceNameAttribute(\n      // A lot of the CloudFormation resources return their physical name\n      // when the Ref function is used on them.\n      // If your resource is like that, simply pass 'resource.ref' here.\n      // However, if Ref for your resource returns something else,\n      // it's often still possible to use CloudFormation functions to get out the physical name;\n      // for example, if Ref for your resource returns the ARN,\n      // and the ARN for your resource is of the form 'arn:aws:<service>:<region>:<account>:resource/physical-name',\n      // which is quite common,\n      // you can use Fn::Select and Fn::Split to take out the part after the '/' from the ARN:\n      Fn.select(1, Fn.split('/', resource.ref)),\n    );\n    this.exampleResourceArn = this.getResourceArnAttribute(\n      // A lot of the L1 classes have an 'attrArn' property -\n      // if yours does, use it here.\n      // However, if it doesn't,\n      // you can often formulate the ARN yourself,\n      // using the Stack.formatArn helper function.\n      // Here, we assume resource.ref returns the physical name of the resource.\n      Stack.of(this).formatArn(exampleResourceArnComponents(resource.ref)),\n      // always use the protected physicalName property for this second argument\n      exampleResourceArnComponents(this.physicalName));\n\n    // if a role wasn't passed, create one\n    const role = props.role || new iam.Role(this, 'Role', {\n      // of course, fill your correct service principal here\n      assumedBy: new iam.ServicePrincipal('cloudformation.amazonaws.com'),\n    });\n    this.role = role;\n    // we need this to correctly implement the iam.IGrantable interface\n    this.grantPrincipal = role;\n\n    // implement the ec2.IConnectable interface,\n    // by writing to the _connections field in ExampleResourceBase,\n    // if a VPC was passed in props\n    if (props.vpc) {\n      const securityGroups = (props.securityGroups ?? []).length === 0\n        // no security groups were provided - create one\n        ? [new ec2.SecurityGroup(this, 'SecurityGroup', {\n          vpc: props.vpc,\n        })]\n        : props.securityGroups;\n      this._connections = new ec2.Connections({ securityGroups });\n\n      // this is how you would use the VPC inputs to fill a subnetIds property of an L1:\n      new ec2.CfnVPCEndpoint(this, 'VpcEndpoint', {\n        vpcId: props.vpc.vpcId,\n        serviceName: 'ServiceName',\n        subnetIds: props.vpc.selectSubnets(props.vpcSubnets).subnetIds,\n      });\n    }\n\n    // this is how you apply the removal policy\n    resource.applyRemovalPolicy(props.removalPolicy, {\n      // this is the default to apply if props.removalPolicy is undefined\n      default: RemovalPolicy.RETAIN,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class EventsReflection for AWS resource management", "output": "export class EventsReflection extends ConstructReflection {\n  public get directEventMethods() {\n    return this.classType.allMethods.filter(isDirectEventMethod);\n  }\n\n  public get cloudTrailEventMethods() {\n    return this.classType.allMethods.filter(isCloudTrailEventMethod);\n  }\n}", "language": "typescript"}
{"input": "CDK class AliasTargetInstance for AWS resource management", "output": "export class AliasTargetInstance extends InstanceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicediscovery.AliasTargetInstance';\n  /**\n   * The Id of the instance\n   */\n  public readonly instanceId: string;\n\n  /**\n   * The Cloudmap service to which the instance is registered.\n   */\n  public readonly service: IService;\n\n  /**\n   * The Route53 DNS name of the alias target\n   */\n  public readonly dnsName: string;\n\n  constructor(scope: Construct, id: string, props: AliasTargetInstanceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.service.namespace.type === NamespaceType.HTTP) {\n      throw new ValidationError('Namespace associated with Service must be a DNS Namespace.', this);\n    }\n\n    // Should already be enforced when creating service, but validates if service is not instantiated with #createService\n    const dnsRecordType = props.service.dnsRecordType;\n    if (dnsRecordType !== DnsRecordType.A\n      && dnsRecordType !== DnsRecordType.AAAA\n      && dnsRecordType !== DnsRecordType.A_AAAA) {\n      throw new ValidationError('Service must use `A` or `AAAA` records to register an AliasRecordTarget.', this);\n    }\n\n    if (props.service.routingPolicy !== RoutingPolicy.WEIGHTED) {\n      throw new ValidationError('Service must use `WEIGHTED` routing policy.', this);\n    }\n\n    const resource = new CfnInstance(this, 'Resource', {\n      instanceAttributes: {\n        AWS_ALIAS_DNS_NAME: props.dnsName,\n        ...props.customAttributes,\n      },\n      instanceId: props.instanceId || Names.uniqueId(this),\n      serviceId: props.service.serviceId,\n    });\n\n    this.service = props.service;\n    this.instanceId = resource.ref;\n    this.dnsName = props.dnsName;\n  }\n}", "language": "typescript"}
{"input": "Group metrics that an Auto Scaling group sends to Amazon CloudWatch.", "output": "export class GroupMetric {\n  /**\n   * The minimum size of the Auto Scaling group\n   */\n  public static readonly MIN_SIZE = new GroupMetric('GroupMinSize');\n\n  /**\n   * The maximum size of the Auto Scaling group\n   */\n  public static readonly MAX_SIZE = new GroupMetric('GroupMaxSize');\n\n  /**\n   * The number of instances that the Auto Scaling group attempts to maintain\n   */\n  public static readonly DESIRED_CAPACITY = new GroupMetric('GroupDesiredCapacity');\n\n  /**\n   * The number of instances that are running as part of the Auto Scaling group\n   * This metric does not include instances that are pending or terminating\n   */\n  public static readonly IN_SERVICE_INSTANCES = new GroupMetric('GroupInServiceInstances');\n\n  /**\n   * The number of instances that are pending\n   * A pending instance is not yet in service, this metric does not include instances that are in service or terminating\n   */\n  public static readonly PENDING_INSTANCES = new GroupMetric('GroupPendingInstances');\n\n  /**\n   * The number of instances that are in a Standby state\n   * Instances in this state are still running but are not actively in service\n   */\n  public static readonly STANDBY_INSTANCES = new GroupMetric('GroupStandbyInstances');\n\n  /**\n   * The number of instances that are in the process of terminating\n   * This metric does not include instances that are in service or pending\n   */\n  public static readonly TERMINATING_INSTANCES = new GroupMetric('GroupTerminatingInstances');\n\n  /**\n   * The total number of instances in the Auto Scaling group\n   * This metric identifies the number of instances that are in service, pending, and terminating\n   */\n  public static readonly TOTAL_INSTANCES = new GroupMetric('GroupTotalInstances');\n\n  /**\n   * The name of the group metric\n   */\n  public readonly name: string;\n\n  constructor(name: string) {\n    this.name = name;\n  }\n}", "language": "typescript"}
{"input": "CDK class CommonResources for AWS resource management", "output": "export class CommonResources extends Construct {\n  public readonly cognitoUserPool: cognito.UserPool;\n  public readonly cognitoUserPoolAppClient: cognito.UserPoolClient;\n  public readonly cognitoIdentityPool: cognito.CfnIdentityPool;\n  public readonly cognitoIdentityPoolPolicy: cognito.CfnIdentityPoolRoleAttachment;\n  public readonly cognitoEndpoint: string;\n  public readonly vpc: ec2.Vpc;\n\n  constructor(scope: Construct, id: string, props: CommonResourcesConstructProps) {\n    super(scope, id);\n\n    // VPC\n    const vpc = new ec2.Vpc(this, \"Vpc\", {\n      vpcName: `${Aws.STACK_NAME}-vpc`,\n    });\n    this.vpc = vpc;\n\n    // Create Cognito User Pool\n    const userPool = new cognito.UserPool(this, 'CognitoUserPool', {\n      accountRecovery: cognito.AccountRecovery.EMAIL_ONLY,\n      advancedSecurityMode: cognito.AdvancedSecurityMode.OFF,\n      autoVerify: {\n        email: true,\n      },\n      deletionProtection: false,\n      enableSmsRole: false,\n      keepOriginal: {\n        email: true,\n      },\n      mfa: cognito.Mfa.OFF,\n      passwordPolicy: {\n        requireDigits: true,\n        minLength: 12,\n        requireLowercase: true,\n        requireUppercase: true,\n        requireSymbols: true,\n        tempPasswordValidity: Duration.days(7),\n      },\n      removalPolicy: RemovalPolicy.DESTROY,\n      selfSignUpEnabled: false,\n      signInAliases: {\n        username: false,\n        email: true,\n      },\n      signInCaseSensitive: false, // Since email address are not case sensitive\n      standardAttributes: {\n        email: {\n          required: true,\n          mutable: true,\n        },\n      },\n      userInvitation: {\n        // Settings for an admin signing up someone else\u2019s email for an account\n        emailSubject: 'Invite to join Opensearch CDK Example',\n        emailBody:\n          'Hello {username}, you have been invited to join Opensearch CDK Example! Your temporary password is {####}',\n        smsMessage:\n          'Hello {username}, your temporary password for Opensearch CDK Example is {####}',\n      },\n      userPoolName: `${Aws.STACK_NAME}-UserPool`,\n      userVerification: {\n        // Settings for a user signing themselves up\n        emailSubject: 'Verify your email for Opensearch CDK Example',\n        emailBody:\n          'Thanks for signing up for Opensearch CDK Example: Your verification code is {####}',\n        emailStyle: cognito.VerificationEmailStyle.CODE,\n      },\n    });\n\n    this.cognitoUserPool = userPool;\n\n    const appClient = userPool.addClient('AppClient', {\n      accessTokenValidity: Duration.hours(1),\n      authFlows: {\n        userPassword: true,\n        userSrp: true,\n        custom: true,\n      },\n      disableOAuth: true,\n      enableTokenRevocation: true,\n      generateSecret: false,\n      idTokenValidity: Duration.hours(1),\n      preventUserExistenceErrors: true,\n      readAttributes: new cognito.ClientAttributes().withStandardAttributes({\n        email: true,\n      }),\n      refreshTokenValidity: Duration.days(30),\n      supportedIdentityProviders: [],\n      userPoolClientName: `${Aws.STACK_NAME}-CognitoAppClient`,\n    });\n    this.cognitoUserPoolAppClient = appClient;\n\n    const domainPrefix = `${Aws.STACK_NAME}-${Aws.ACCOUNT_ID}`;\n\n    userPool.addDomain(\"CognitoDomain\", {\n      cognitoDomain: {\n        domainPrefix: domainPrefix,\n      },\n    });\n\n    this.cognitoEndpoint =\n        domainPrefix+\n        \".auth.\" +\n        cdk.Stack.of(this).region +\n        \".amazoncognito.com\";\n\n    // Create cognito identitypool\n    const identityPool = new cognito.CfnIdentityPool(this, \"IdentityPool\", {\n      allowUnauthenticatedIdentities: true, // Must allow so frontend can log data to cloudfront\n      identityPoolName: `${Aws.STACK_NAME}-identitypool`,\n      cognitoIdentityProviders: [\n        {\n          clientId: appClient.userPoolClientId,\n          providerName: userPool.userPoolProviderName,\n        },\n      ],\n    });\n    this.cognitoIdentityPool = identityPool;\n\n    this.cognitoIdentityPoolPolicy = new CfnIdentityPoolRoleAttachment(\n        this,\n        'IdentityRoles',\n        {\n          identityPoolId: identityPool.ref,\n          roles: {\n            authenticated: \"\",\n            unauthenticated: \"\"\n          }\n        },\n    );\n\n    // Create output for Cognito Userpool\n    const userpool = new cdk.CfnOutput(this, 'CognitoUserPoolId', {\n      value: userPool.userPoolId,\n      description: 'Cognito Userpool ID',\n    });\n\n    userpool.overrideLogicalId('CognitoUserPoolId');\n\n    const userpoolAppClient = new cdk.CfnOutput(this, 'CognitoUserPoolAppClient', {\n      value: appClient.userPoolClientId,\n      description: 'Cognito UserPool AppClient',\n    });\n\n    userpoolAppClient.overrideLogicalId('CognitoUserPoolAppClient');\n\n    const userpoolDomain = new cdk.CfnOutput(this, 'CognitoUserPoolDomain', {\n      value: this.cognitoEndpoint,\n      description: 'Cognito Userpool Domain',\n    });\n\n    userpoolDomain.overrideLogicalId('CognitoUserPoolDomain');\n\n\n  }\n}", "language": "typescript"}
{"input": "A secret environment variable.", "output": "class Secret {\n  /**\n   * Creates an environment variable value from a parameter stored in AWS\n   * Systems Manager Parameter Store.\n   */\n  public static fromSsmParameter(parameter: ssm.IParameter): Secret {\n    return {\n      arn: parameter.parameterArn,\n      grantRead: grantee => parameter.grantRead(grantee),\n    };\n  }\n\n  /**\n   * Creates a environment variable value from a secret stored in AWS Secrets\n   * Manager.\n   *\n   * @param secret the secret stored in AWS Secrets Manager\n   * @param field the name of the field with the value that you want to set as\n   * the environment variable value. Only values in JSON format are supported.\n   * If you do not specify a JSON field, then the full content of the secret is\n   * used.\n   */\n  public static fromSecretsManager(secret: secretsmanager.ISecret, field?: string): Secret {\n    return {\n      arn: field ? `${secret.secretArn}:${field}::` : secret.secretArn,\n      hasField: !!field,\n      grantRead: grantee => secret.grantRead(grantee),\n    };\n  }\n\n  /**\n   * Creates a environment variable value from a secret stored in AWS Secrets\n   * Manager.\n   *\n   * @param secret the secret stored in AWS Secrets Manager\n   * @param versionInfo the version information to reference the secret\n   * @param field the name of the field with the value that you want to set as\n   * the environment variable value. Only values in JSON format are supported.\n   * If you do not specify a JSON field, then the full content of the secret is\n   * used.\n   */\n  public static fromSecretsManagerVersion(secret: secretsmanager.ISecret, versionInfo: SecretVersionInfo, field?: string): Secret {\n    return {\n      arn: `${secret.secretArn}:${field ?? ''}:${versionInfo.versionStage ?? ''}:${versionInfo.versionId ?? ''}`,\n      hasField: !!field,\n      grantRead: grantee => secret.grantRead(grantee),\n    };\n  }\n\n  /**\n   * The ARN of the secret\n   */\n  public abstract readonly arn: string;\n\n  /**\n   * Whether this secret uses a specific JSON field\n   */\n  public abstract readonly hasField?: boolean;\n\n  /**\n   * Grants reading the secret to a principal\n   * [disable-awslint:no-grants]\n   */\n  public abstract grantRead(grantee: iam.IGrantable): iam.Grant;\n}", "language": "typescript"}
{"input": "Includes API for attaching annotations such as warning messages to constructs.", "output": "export class Annotations {\n  /**\n   * Returns the annotations API for a construct scope.\n   * @param scope The scope\n   */\n  public static of(scope: IConstruct) {\n    return new Annotations(scope);\n  }\n\n  private readonly stackTraces: boolean;\n\n  private constructor(private readonly scope: IConstruct) {\n    const disableTrace =\n      scope.node.tryGetContext(cxapi.DISABLE_METADATA_STACK_TRACE) ||\n      process.env.CDK_DISABLE_STACK_TRACE;\n\n    this.stackTraces = !disableTrace;\n  }\n\n  /**\n   * Acknowledge a warning. When a warning is acknowledged for a scope\n   * all warnings that match the id will be ignored.\n   *\n   * The acknowledgement will apply to all child scopes\n   *\n   * @example\n   * declare const myConstruct: Construct;\n   * Annotations.of(myConstruct).acknowledgeWarning('SomeWarningId', 'This warning can be ignored because...');\n   *\n   * @param id - the id of the warning message to acknowledge\n   * @param message optional message to explain the reason for acknowledgement\n   */\n  public acknowledgeWarning(id: string, message?: string): void {\n    Acknowledgements.of(this.scope).add(this.scope, id);\n\n    // We don't use message currently, but encouraging people to supply it is good for documentation\n    // purposes, and we can always add a report on it in the future.\n    void(message);\n\n    // Iterate over the construct and remove any existing instances of this warning\n    // (addWarningV2 will prevent future instances of it)\n    removeWarningDeep(this.scope, id);\n  }\n\n  /**\n   * Adds an acknowledgeable warning metadata entry to this construct.\n   *\n   * The CLI will display the warning when an app is synthesized, or fail if run\n   * in `--strict` mode.\n   *\n   * If the warning is acknowledged using `acknowledgeWarning()`, it will not be shown by\n   * the CLI, and will not cause `--strict` mode to fail synthesis.\n   *\n   * @example\n   * declare const myConstruct: Construct;\n   * Annotations.of(myConstruct).addWarningV2('my-library:Construct.someWarning', 'Some message explaining the warning');\n   *\n   * @param id the unique identifier for the warning. This can be used to acknowledge the warning\n   * @param message The warning message.\n   */\n  public addWarningV2(id: string, message: string) {\n    if (!Acknowledgements.of(this.scope).has(this.scope, id)) {\n      this.addMessage(cxschema.ArtifactMetadataEntryType.WARN, `${message} ${ackTag(id)}`);\n    }\n  }\n\n  /**\n   * Adds a warning metadata entry to this construct. Prefer using `addWarningV2`.\n   *\n   * The CLI will display the warning when an app is synthesized, or fail if run\n   * in `--strict` mode.\n   *\n   * Warnings added by this call cannot be acknowledged. This will block users from\n   * running in `--strict` mode until the deal with the warning, which makes it\n   * effectively not very different from `addError`. Prefer using `addWarningV2` instead.\n   *\n   * @param message The warning message.\n   */\n  public addWarning(message: string) {\n    this.addMessage(cxschema.ArtifactMetadataEntryType.WARN, message);\n  }\n\n  /**\n   * Acknowledge a info. When a info is acknowledged for a scope\n   * all infos that match the id will be ignored.\n   *\n   * The acknowledgement will apply to all child scopes\n   *\n   * @example\n   * declare const myConstruct: Construct;\n   * Annotations.of(myConstruct).acknowledgeInfo('SomeInfoId', 'This info can be ignored because...');\n   *\n   * @param id - the id of the info message to acknowledge\n   * @param message optional message to explain the reason for acknowledgement\n   */\n  public acknowledgeInfo(id: string, message?: string): void {\n    Acknowledgements.of(this.scope).add(this.scope, id);\n\n    // We don't use message currently, but encouraging people to supply it is good for documentation\n    // purposes, and we can always add a report on it in the future.\n    void(message);\n\n    // Iterate over the construct and remove any existing instances of this info\n    // (addInfoV2 will prevent future instances of it)\n    removeInfoDeep(this.scope, id);\n  }\n\n  /**\n   * Adds an acknowledgeable info metadata entry to this construct.\n   *\n   * The CLI will display the info when an app is synthesized.\n   *\n   * If the info is acknowledged using `acknowledgeInfo()`, it will not be shown by the CLI.\n   *\n   * @example\n   * declare const myConstruct: Construct;\n   * Annotations.of(myConstruct).addInfoV2('my-library:Construct.someInfo', 'Some message explaining the info');\n   *\n   * @param id the unique identifier for the info. This can be used to acknowledge the info\n   * @param message The info message.\n   */\n  public addInfoV2(id: string, message: string) {\n    if (!Acknowledgements.of(this.scope).has(this.scope, id)) {\n      this.addMessage(cxschema.ArtifactMetadataEntryType.INFO, `${message} ${ackTag(id)}`);\n    }\n  }\n\n  /**\n   * Adds an info metadata entry to this construct.\n   *\n   * The CLI will display the info message when apps are synthesized.\n   *\n   * @param message The info message.\n   */\n  public addInfo(message: string): void {\n    this.addMessage(cxschema.ArtifactMetadataEntryType.INFO, message);\n  }\n\n  /**\n   * Adds an { \"error\": <message> } metadata entry to this construct.\n   * The toolkit will fail deployment of any stack that has errors reported against it.\n   * @param message The error message.\n   */\n  public addError(message: string) {\n    this.addMessage(cxschema.ArtifactMetadataEntryType.ERROR, message);\n  }\n\n  /**\n   * Adds a deprecation warning for a specific API.\n   *\n   * Deprecations will be added only once per construct as a warning and will be\n   * deduplicated based on the `api`.\n   *\n   * If the environment variable `CDK_BLOCK_DEPRECATIONS` is set, this method\n   * will throw an error instead with the deprecation message.\n   *\n   * @param api The API being deprecated in the format `module.Class.property`\n   * (e.g. `@aws-cdk/core.Construct.node`).\n   * @param message The deprecation message to display, with information about\n   * alternatives.\n   */\n  public addDeprecation(api: string, message: string) {\n    const text = `The API ${api} is deprecated: ${message}. This API will be removed in the next major release`;\n\n    // throw if CDK_BLOCK_DEPRECATIONS is set\n    if (process.env.CDK_BLOCK_DEPRECATIONS) {\n      throw new UnscopedValidationError(`${this.scope.node.path}: ${text}`);\n    }\n\n    this.addWarningV2(`Deprecated:${api}`, text);\n  }\n\n  /**\n   * Adds a message metadata entry to the construct node, to be displayed by the CDK CLI.\n   *\n   * Records the message once per construct.\n   * @param level The message level\n   * @param message The message itself\n   */\n  private addMessage(level: string, message: string) {\n    const isNew = !this.scope.node.metadata.find((x) => x.data === message);\n    if (isNew) {\n      let normalizedMessage = typeof message === 'string' ? message : JSON.stringify(message);\n      this.scope.node.addMetadata(level, normalizedMessage, { stackTrace: this.stackTraces });\n    }\n  }\n}", "language": "typescript"}
{"input": "Text template configuration for prompts.", "output": "class TextTemplateConfiguration extends PromptTemplateConfiguration {\n  constructor(private readonly props: TextTemplateConfigurationProps) {\n    super();\n  }\n\n  public _render(): bedrock.CfnPrompt.PromptTemplateConfigurationProperty {\n    return {\n      text: {\n        inputVariables: this.props.inputVariables?.map((variable: string) => {\n          return { name: variable };\n        }),\n        text: this.props.text,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomDotnetLinuxInjector for AWS resource management", "output": "class CustomDotnetLinuxInjector extends appsignals.DotNetLinuxInjector {\n  get containerPath(): string {\n    return '/otel-snapshot';\n  }\n}", "language": "typescript"}
{"input": "A base stack class that implements custom logical name allocation. Adds a prefix if it is defined in the \"prefix\" context key. Use `cdk --context prefix=PREFIX` to set the prefix.", "output": "export class BaseStack extends Stack {\n  public allocateLogicalId(element: CfnElement) {\n    const orig = super.allocateLogicalId(element);\n    const prefix = this.node.tryGetContext('prefix');\n    return prefix ? prefix + orig : orig;\n  }\n}", "language": "typescript"}
{"input": "NetworkUtils contains helpers to work with network constructs (subnets/ranges)", "output": "export class NetworkUtils {\n  /**\n   * Validates an IPv4 address string.\n   *\n   * @param ipAddress The IPv4 address string to be validated.\n   * @returns True if the string is a valid IPv4 address, false otherwise.\n   * Validates an IPv4 string\n   *\n   * returns true of the string contains 4 numbers between 0-255 delimited by\n   * a `.` character\n   */\n  public static validIp(ipAddress: string): boolean {\n    const octets = ipAddress.split('.');\n    if (octets.length !== 4) {\n      return false;\n    }\n    return octets.map((octet: string) => parseInt(octet, 10)).\n      every((octet: number) => octet >= 0 && octet <= 255);\n  }\n\n  /**\n   * Converts a string representation of an IPv4 address to its corresponding numerical value.\n   *\n   * Uses the formula:\n   * (first octet * 256\u00b3) + (second octet * 256\u00b2) + (third octet * 256) +\n   * (fourth octet)\n   *\n   * @param  ipAddress the IP address (e.g. 174.66.173.168)\n   * @returns the integer value of the IP address (e.g 2923605416)\n   */\n  public static ipToNum(ipAddress: string): number {\n    if (!this.validIp(ipAddress)) {\n      throw new Error(`${ipAddress} is not valid`);\n    }\n\n    return ipAddress\n      .split('.')\n      .reduce(\n        (p: number, c: string, i: number) => p + parseInt(c, 10) * 256 ** (3 - i),\n        0,\n      );\n  }\n\n  /**\n   * Takes number and converts it to IPv4 address string\n   *\n   * Takes a number (e.g 2923605416) and converts it to an IPv4 address string\n   * currently only supports IPv4\n   *\n   * @param ipNum integer value of the IP address (e.g 2923605416)\n   * @returns IPv4 address (e.g. 174.66.173.168)\n   */\n  public static numToIp(ipNum: number): string {\n    // this all because bitwise math is signed\n    let remaining = ipNum;\n    const address = new Array<number>();\n    for (let i = 0; i < 4; i++) {\n      if (remaining !== 0) {\n        address.push(Math.floor(remaining / 256 ** (3 - i)));\n        remaining = remaining % 256 ** (3 - i);\n      } else {\n        address.push(0);\n      }\n    }\n    const ipAddress: string = address.join('.');\n    if ( !this.validIp(ipAddress) ) {\n      throw new Error(`${ipAddress} is not a valid IP Address`);\n    }\n    return ipAddress;\n  }\n}", "language": "typescript"}
{"input": "CDK class BonjourECS for AWS resource management", "output": "class BonjourECS(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, *kwargs)\n\n        vpc = ec2.Vpc(\n            self, \"MyVpc\",\n            max_azs=2\n        )\n\n        cluster = ecs.Cluster(\n            self, 'Ec2Cluster',\n            vpc=vpc\n        )\n\n        asg = autoscaling.AutoScalingGroup(\n            self, \"DefaultAutoScalingGroup\",\n            instance_type=ec2.InstanceType(\"t2.micro\"),\n            machine_image=ecs.EcsOptimizedImage.amazon_linux2(),\n            vpc=vpc,\n        )\n        capacity_provider = ecs.AsgCapacityProvider(self, \"AsgCapacityProvider\",\n            auto_scaling_group=asg\n        )\n        cluster.add_asg_capacity_provider(capacity_provider)\n\n        ecs_service = ecs_patterns.NetworkLoadBalancedEc2Service(\n            self, \"Ec2Service\",\n            cluster=cluster,\n            memory_limit_mib=512,\n            task_image_options=ecs_patterns.NetworkLoadBalancedTaskImageOptions(\n                image=ecs.ContainerImage.from_registry(\"amazon/amazon-ecs-sample\")\n            )\n        )\n\n        asg.connections.allow_from_any_ipv4(port_range=ec2.Port.tcp_range(32768, 65535), description=\"allow incoming traffic from ALB\")\n\n        CfnOutput(\n            self, \"LoadBalancerDNS\",\n            value=\"http://\"+ecs_service.load_balancer.load_balancer_dns_name\n        )", "language": "python"}
{"input": "CDK Stack that creates S3, Lambda, WAF, AppSync resources", "output": "class EventApiEventBridgeStack extends cdk.Stack {\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n  public readonly eventBus: events.EventBus;\n  public readonly sqsQueue: sqs.Queue;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const api = new appsync.EventApi(this, 'EventApiEventBridge', {\n      apiName: 'EventBridgeEventApi',\n    });\n\n    this.eventBus = new events.EventBus(this, 'test-bus');\n    this.sqsQueue = new sqs.Queue(this, 'test-queue');\n    new events.Rule(this, 'eventapi-rule', {\n      eventBus: this.eventBus,\n      eventPattern: {\n        source: ['appsync.eventapi'],\n      },\n      targets: [\n        new targets.SqsQueue(this.sqsQueue),\n      ],\n    });\n\n    const dataSource = api.addEventBridgeDataSource('eventbridgeds', this.eventBus);\n\n    api.addChannelNamespace('chat', {\n      code: appsync.Code.fromAsset(path.join(__dirname, 'integ-assets', 'eventapi-handlers', 'eb.js')),\n      publishHandlerConfig: {\n        dataSource: dataSource,\n      },\n    });\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: `wss://${api.realtimeDns}/event/realtime`,\n        EVENT_API_HTTP_URL: `https://${api.httpDns}/event`,\n        API_KEY: api.apiKeys.Default.attrApiKey,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets', 'eventapi-grant-assertion', 'index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.seconds(15),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'EventApiEventBridgeTestFunction', lambdaConfig);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, MSK (Kafka) resources", "output": "class SchedulescalingStack(Stack):\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        scaling = self.node.try_get_context(\"scaling\")\n        dayschedule = self.node.try_get_context(\"daytime\")\n        nightschedule = self.node.try_get_context(\"nightime\")\n\n        min_capacity = 1\n        max_capacity = 1\n\n        # daytime scaling schedule(UTC)\n        day_schedule = dayschedule[0][\"cron\"]\n        day_min = dayschedule[1][\"min\"]\n        day_max = dayschedule[2][\"max\"]\n\n        # nighttime scaling schedule(UTC)\n        night_schedule = nightschedule[0][\"cron\"]\n        night_min = nightschedule[1][\"min\"]\n        night_max = nightschedule[2][\"max\"]\n\n        vpc = ec2.Vpc(self, \"ecsVpc\", max_azs=2)\n\n        ecs_cluster = ecs.Cluster(\n            self,\n            id=\"ecscluster\",\n            vpc=vpc,\n            container_insights=True,\n            enable_fargate_capacity_providers=True,\n        )\n\n        # create task definition\n        task_definition = ecs.FargateTaskDefinition(self, \"taskdef\", cpu=256)\n        image = ecs.ContainerImage.from_registry(\"amazon/amazon-ecs-sample\")\n        container = task_definition.add_container(id=\"ecs-con-task\", image=image)\n        container.add_port_mappings(ecs.PortMapping(container_port=8080))\n\n        # define service\n        service = ecs.FargateService(\n            self, \"FargateService\", cluster=ecs_cluster, task_definition=task_definition\n        )\n        # define autoscaling\n        if scaling:\n            target = appscaling.ScalableTarget(\n                self,\n                \"ScalableTarget\",\n                service_namespace=appscaling.ServiceNamespace.ECS,\n                min_capacity=min_capacity,\n                max_capacity=max_capacity,\n                resource_id=f\"service/{ecs_cluster.cluster_name}/{service.service_name}\",\n                scalable_dimension=\"ecs:service:DesiredCount\",\n            )\n            target.scale_on_schedule(\n                \"daytime\",\n                schedule=appscaling.Schedule.expression(day_schedule),\n                min_capacity=day_min,\n                max_capacity=day_max,\n            )\n            target.scale_on_schedule(\n                \"nighttime\",\n                schedule=appscaling.Schedule.expression(night_schedule),\n                min_capacity=night_min,\n                max_capacity=night_max,\n            )", "language": "python"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation, EFS resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const bucket = new s3.Bucket(this, 'MyBucket');\n    const handler1 = new lambda.Function(this, 'MyFunction1', {\n      runtime: lambda.Runtime.NODEJS_20_X,\n      handler: 'index.handler',\n      code: lambda.Code.fromInline('foo'),\n    });\n\n    const handler2 = new lambda.Function(this, 'MyFunction2', {\n      runtime: lambda.Runtime.NODEJS_20_X,\n      handler: 'index.handler',\n      code: lambda.Code.fromInline('foo'),\n    });\n\n    new AccessPoint(this, 'MyObjectLambda1', {\n      bucket,\n      handler: handler1,\n      cloudWatchMetricsEnabled: true,\n      supportsGetObjectPartNumber: true,\n    });\n\n    new AccessPoint(this, 'MyObjectLambda2', {\n      bucket,\n      handler: handler2,\n      supportsGetObjectRange: true,\n      payload: { foo: 10 },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3WorkflowDataFromAsset for AWS resource management", "output": "class S3WorkflowDataFromAsset extends S3WorkflowData {\n  public constructor(asset: s3assets.Asset) {\n    super(asset.bucket, asset.s3ObjectKey);\n  }\n}", "language": "typescript"}
{"input": "A new managed or custom rule.", "output": "class RuleNew extends RuleBase {\n  /**\n   * Imports an existing rule.\n   *\n   * @param configRuleName the name of the rule\n   */\n  public static fromConfigRuleName(scope: Construct, id: string, configRuleName: string): IRule {\n    class Import extends RuleBase {\n      public readonly configRuleName = configRuleName;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The arn of the rule.\n   */\n  public abstract readonly configRuleArn: string;\n\n  /**\n   * The id of the rule.\n   */\n  public abstract readonly configRuleId: string;\n\n  /**\n   * The compliance status of the rule.\n   */\n  public abstract readonly configRuleComplianceType: string;\n\n  protected ruleScope?: RuleScope;\n  protected isManaged?: boolean;\n  protected isCustomWithChanges?: boolean;\n}", "language": "typescript"}
{"input": "Provides version information and image selection for CloudWatch Agent.", "output": "export class CloudWatchAgentVersion {\n  /**\n   * Default CloudWatch Agent image for Linux.\n   */\n  public static readonly CLOUDWATCH_AGENT_IMAGE = 'public.ecr.aws/cloudwatch-agent/cloudwatch-agent:latest';\n\n  /**\n   * CloudWatch Agent image for Windows Server 2019.\n   */\n  public static readonly CLOUDWATCH_AGENT_IMAGE_WIN2019 = 'public.ecr.aws/cloudwatch-agent/cloudwatch-agent:latest-windowsservercore2019';\n\n  /**\n   * CloudWatch Agent image for Windows Server 2022.\n   */\n  public static readonly CLOUDWATCH_AGENT_IMAGE_WIN2022 = 'public.ecr.aws/cloudwatch-agent/cloudwatch-agent:latest-windowsservercore2022';\n\n  /**\n   * Gets the appropriate CloudWatch Agent image based on the operating system.\n   * @param operatingSystemFamily - The ECS operating system family\n   * @returns The CloudWatch Agent image URI\n   */\n  public static getCloudWatchAgentImage(operatingSystemFamily?: ecs.OperatingSystemFamily): string {\n    let cloudWatchAgentImage = CloudWatchAgentVersion.CLOUDWATCH_AGENT_IMAGE;\n    if (operatingSystemFamily) {\n      switch (operatingSystemFamily) {\n        case ecs.OperatingSystemFamily.WINDOWS_SERVER_2019_CORE:\n        case ecs.OperatingSystemFamily.WINDOWS_SERVER_2019_FULL:\n          cloudWatchAgentImage = CloudWatchAgentVersion.CLOUDWATCH_AGENT_IMAGE_WIN2019;\n          break;\n        case ecs.OperatingSystemFamily.WINDOWS_SERVER_2022_CORE:\n        case ecs.OperatingSystemFamily.WINDOWS_SERVER_2022_FULL:\n          cloudWatchAgentImage = CloudWatchAgentVersion.CLOUDWATCH_AGENT_IMAGE_WIN2022;\n          break;\n      }\n    }\n    return cloudWatchAgentImage;\n  }\n}", "language": "typescript"}
{"input": "Verify that the package name matches the directory name", "output": "export class PackageNameMatchesDirectoryName extends ValidationRule {\n  public readonly name = 'naming/package-matches-directory';\n\n  public validate(pkg: PackageJson): void {\n    const parts = pkg.packageRoot.split(path.sep);\n\n    const expectedName = parts[parts.length - 2].startsWith('@')\n      ? parts.slice(parts.length - 2).join('/')\n      : parts[parts.length - 1];\n\n    expectJSON(this.name, pkg, 'name', expectedName);\n  }\n}", "language": "typescript"}
{"input": "CDK class WidgetService for AWS resource management", "output": "export class WidgetService extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const bucket = new s3.Bucket(this, \"WidgetStore\", {\n      // The default removal policy is RETAIN, which means that cdk destroy will not attempt to delete\n      // the new bucket, and it will remain in your account until manually deleted. By setting the policy to\n      // DESTROY, cdk destroy will attempt to delete the bucket, but will error if the bucket is not empty.\n      removalPolicy: cdk.RemovalPolicy.DESTROY, // NOT recommended for production code\n    });\n\n    const handler = new lambda.Function(this, \"WidgetHandler\", {\n      runtime: lambda.Runtime.NODEJS_20_X, // So we can use async in widget.js\n      code: lambda.AssetCode.fromAsset(\"resources\"),\n      handler: \"widgets.main\",\n      environment: {\n        BUCKET: bucket.bucketName\n      }\n    });\n\n    bucket.grantReadWrite(handler); // was: handler.role);\n\n    const api = new apigateway.RestApi(this, \"widgets-api\", {\n      restApiName: \"Widget Service\",\n      description: \"This service serves widgets.\"\n    });\n\n    const getWidgetsIntegration = new apigateway.LambdaIntegration(handler, {\n      requestTemplates: { \"application/json\": '{ \"statusCode\": \"200\" }' }\n    });\n\n    api.root.addMethod(\"GET\", getWidgetsIntegration); // GET /\n\n    // snippet-start:[cdk.typescript.widget_service.wire_up_functions]\n    const widget = api.root.addResource(\"{id}\");\n\n    // Add new widget to bucket with: POST /{id}\n    const postWidgetIntegration = new apigateway.LambdaIntegration(handler);\n\n    // Get a specific widget from bucket with: GET /{id}\n    const getWidgetIntegration = new apigateway.LambdaIntegration(handler);\n\n    // Remove a specific widget from the bucket with: DELETE /{id}\n    const deleteWidgetIntegration = new apigateway.LambdaIntegration(handler);\n\n    widget.addMethod(\"POST\", postWidgetIntegration); // POST /{id}\n    widget.addMethod(\"GET\", getWidgetIntegration); // GET /{id}\n    widget.addMethod(\"DELETE\", deleteWidgetIntegration); // DELETE /{id}\n    // snippet-end:[cdk.typescript.widget_service.wire_up_functions]\n  }\n}", "language": "typescript"}
{"input": "CDK Construct TheirConstruct for reusable infrastructure components", "output": "class TheirConstruct extends Construct {\n      constructor(scope: Construct, id: string) {\n        super(scope, id);\n\n        new YourConstruct(this, 'YourConstruct');\n        this.node.addValidation({ validate: () => ['their-error'] });\n      }\n    }", "language": "typescript"}
{"input": "Passing L2 key to L2 Events.Rule with CMK Deletion/Rotation patterns", "output": "class L2KeyOtherEventsWithL2Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l2Key = new Key(this, 'Key', {});\n    const l2KeyWithEvent = KeyEvents.fromKey(l2Key);\n\n    const fn = new Function(this, 'MyFuncA', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n\n    const rule = new Rule(this, 'L2RuleForL1', {\n      targets: [new LambdaFunction(fn)],\n    });\n\n    rule.addEventPattern(l2KeyWithEvent.kMSCMKDeletionPattern({}));\n    rule.addEventPattern(l2KeyWithEvent.kMSCMKRotationPattern({}));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, API Gateway resources", "output": "class MyWidgetServiceStack(Stack):\n\n    def __init__(self, app: App, id: str, **kwargs) -> None:\n        super().__init__(app, id)\n\n        bucket: s3.Bucket = s3.Bucket(self, \"WidgetStore\")\n\n        api: apigw.RestApi = apigw.RestApi(\n            self,\n            \"widgets-api\",\n            rest_api_name=\"Widget Service\",\n            description=\"This service serves widgets.\"\n        )\n\n        rest_api_role: iam.Role = iam.Role(\n            self,\n            \"RestAPIRole\",\n            assumed_by=iam.ServicePrincipal(\"apigateway.amazonaws.com\"),\n            managed_policies=[iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonS3FullAccess\")]\n        )\n\n        list_objects_response: apigw.IntegrationResponse = apigw.IntegrationResponse(status_code=\"200\")\n\n        list_objects_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n        )\n\n        get_widget_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n            request_templates={\"application/json\": \"#set($context.requestOverride.path.object = $input.params('id'))\"}\n        )\n\n        put_widget_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n            passthrough_behavior=apigw.PassthroughBehavior.NEVER,\n            request_parameters={\"integration.request.path.object\": \"method.request.path.id\"},\n            request_templates={\n                \"application/json\": \"#set($now=$context.requestTimeEpoch)\\n\"\n                                    \"#set($body=\\\"$input.params('id') created $now\\\")\"\n                                    \"\\n$util.base64Encode($body)\"}\n        )\n\n        get_widgets_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"GET\",\n            path=bucket.bucket_name,\n            options=list_objects_integration_options\n        )\n\n        get_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"GET\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=get_widget_integration_options\n        )\n\n        put_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"PUT\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=put_widget_integration_options\n        )\n\n        delete_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"DELETE\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=get_widget_integration_options\n        )\n\n        method_response: apigw.MethodResponse = apigw.MethodResponse(status_code=\"200\")\n\n        api.root.add_method(\n            \"GET\",\n            get_widgets_integration,\n            method_responses=[method_response]\n        )\n\n        widget = api.root.add_resource('{id}')\n        widget.add_method(\n            \"GET\",\n            get_widget_integration,\n            method_responses=[method_response]\n        )\n\n        widget.add_method(\n            \"POST\",\n            put_widget_integration,\n            method_responses=[method_response],\n            request_parameters={\"method.request.path.id\": True}\n        )\n\n        widget.add_method(\n            \"DELETE\",\n            delete_widget_integration,\n            method_responses=[method_response]\n        )", "language": "python"}
{"input": "CDK helper function for IAM, Glue operations", "output": "def test_glue_crawler_created(template):\n    template.resource_count_is(type=\"AWS::Glue::Crawler\", count=1)\n\n    template.has_resource_properties(type=\"AWS::IAM::Role\",\n                                     props={\n                                         \"RoleName\": \"glue-crawler-role\",\n                                         \"AssumeRolePolicyDocument\": {\n                                             \"Statement\": [{\n                                                 \"Action\": \"sts:AssumeRole\",\n                                                 \"Effect\": \"Allow\",\n                                                 \"Principal\": {\n                                                     \"Service\": \"glue.amazonaws.com\"\n                                                 }\n                                             }]\n                                         },\n                                         \"ManagedPolicyArns\": [\n                                             \"arn:aws:iam::aws:policy/AmazonS3FullAccess\",\n                                             \"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\",\n                                         ]\n                                     })\n\n    template.has_resource_properties(type=\"AWS::Glue::Crawler\",\n                                     props={\n                                         \"DatabaseName\": \"log-database\",\n                                         \"Name\": \"logs-crawler\",\n                                         \"Targets\": {\n                                             \"S3Targets\": [\n                                                 {\n                                                     \"Path\": {\n                                                         \"Fn::Join\": [\n                                                             \"\",\n                                                             [\n                                                                 \"s3://\",\n                                                                 {\"Ref\": \"logsbucketE18563D9\"},\n                                                                 \"/products\"\n                                                             ]\n                                                         ]\n                                                     }\n                                                 },\n                                                 {\n                                                     \"Path\": {\n                                                         \"Fn::Join\": [\n                                                             \"\",\n                                                             [\n                                                                 \"s3://\",\n                                                                 {\"Ref\": \"logsbucketE18563D9\"},\n                                                                 \"/users\"\n                                                             ]\n                                                         ]\n                                                     }\n                                                 }\n                                             ]\n                                         }\n                                     })", "language": "python"}
{"input": "CDK class Alarm for AWS resource management", "output": "export class Alarm extends AlarmBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cloudwatch.Alarm';\n\n  /**\n   * Conventional value for the threshold property when creating anomaly detection alarms.\n   *\n   * Anomaly detection alarms don't have numbered threshold. Instead, they have a dynamically\n   * calculated threshold based on the metric math expression that contains a metric expression.\n   *\n   * The `threshold` property is required, but the value is ignored. This\n   * constant has the value 0, and has a symbolic name to indicate why the\n   * threshold is 0. You can use `new AnomalyDetectionAlarm()` to avoid having to pass\n   * the `threshold` property at all.\n   */\n  public static readonly ANOMALY_DETECTION_NO_THRESHOLD = 0;\n\n  /**\n   * Import an existing CloudWatch alarm provided an Name.\n   *\n   * @param scope The parent creating construct (usually `this`)\n   * @param id The construct's name\n   * @param alarmName Alarm Name\n   */\n  public static fromAlarmName(scope: Construct, id: string, alarmName: string): IAlarm {\n    const stack = Stack.of(scope);\n\n    return this.fromAlarmArn(scope, id, stack.formatArn({\n      service: 'cloudwatch',\n      resource: 'alarm',\n      resourceName: alarmName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    }));\n  }\n\n  /**\n   * Import an existing CloudWatch alarm provided an ARN\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name\n   * @param alarmArn Alarm ARN (i.e. arn:aws:cloudwatch:<region>:<account-id>:alarm:Foo)\n   */\n  public static fromAlarmArn(scope: Construct, id: string, alarmArn: string): IAlarm {\n    class Import extends AlarmBase implements IAlarm {\n      public readonly alarmArn = alarmArn;\n      public readonly alarmName = Stack.of(scope).splitArn(alarmArn, ArnFormat.COLON_RESOURCE_NAME).resourceName!;\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * ARN of this alarm\n   *\n   * @attribute\n   */\n  public readonly alarmArn: string;\n\n  /**\n   * Name of this alarm.\n   *\n   * @attribute\n   */\n  public readonly alarmName: string;\n\n  /**\n   * The metric object this alarm was based on\n   */\n  public readonly metric: IMetric;\n\n  /**\n   * This metric as an annotation\n   */\n  private readonly annotation: HorizontalAnnotation;\n\n  constructor(scope: Construct, id: string, props: AlarmProps) {\n    super(scope, id, {\n      physicalName: props.alarmName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const comparisonOperator = props.comparisonOperator || ComparisonOperator.GREATER_THAN_OR_EQUAL_TO_THRESHOLD;\n    const isAnomalyDetection = isAnomalyDetectionOperator(comparisonOperator);\n\n    let threshold: number | undefined; // For a literal threshold value\n    let thresholdMetricId: string | undefined; // For anomaly detection\n    if (isAnomalyDetection) {\n      if (!isAnomalyDetectionMetric(props.metric)) {\n        throw new ValidationError(\n          `Anomaly detection operator ${comparisonOperator} requires an ANOMALY_DETECTION_BAND() metric. Use the construct AnomalyDetectionAlarm or wrap your metric in an ANOMALY_DETECTION_BAND expression.`,\n          this,\n        );\n      }\n\n      // For now the property `threshold` is required, so checking it against 'undefined' is a bit of a stretch, but reasonable.\n      if (props.threshold !== undefined && props.threshold !== Alarm.ANOMALY_DETECTION_NO_THRESHOLD) {\n        Annotations.of(this).addWarningV2(\n          'aws-cdk-lib/aws-cloudwatch:thresholdIgnoredForAnomalyDetection',\n          'threshold is unused for anomaly detection alarms. Use \\'Alarm.ANOMALY_DETECTION_NO_THRESHOLD\\' or use the AnomalyDetectionAlarm construct.',\n        );\n      }", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, IAM, CloudWatch Logs resources", "output": "class TestStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n    const vpc = new Vpc(this, 'VPC', { natGateways: 1 });\n\n    new FlowLog(this, 'FlowLogsCW', {\n      resourceType: FlowLogResourceType.fromVpc(vpc),\n      flowLogName: 'CustomFlowLogName',\n    });\n\n    vpc.addFlowLog('FlowLogsS3', {\n      destination: FlowLogDestination.toS3(),\n    });\n\n    vpc.addFlowLog('FlowLogsCloudwatch', {\n      destination: FlowLogDestination.toCloudWatchLogs(),\n    });\n\n    const bucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n    bucket.addToResourcePolicy(new PolicyStatement({\n      effect: Effect.ALLOW,\n      principals: [new ServicePrincipal('delivery.logs.amazonaws.com')],\n      actions: ['s3:PutObject'],\n      resources: [bucket.arnForObjects(`AWSLogs/${this.account}/*`)],\n      conditions: {\n        StringEquals: {\n          's3:x-amz-acl': 'bucket-owner-full-control',\n          'aws:SourceAccount': this.account,\n        },\n        ArnLike: {\n          'aws:SourceArn': this.formatArn({\n            service: 'logs',\n            resource: '*',\n          }),\n        },\n      },\n    }));\n    bucket.addToResourcePolicy(new PolicyStatement({\n      effect: Effect.ALLOW,\n      principals: [new ServicePrincipal('delivery.logs.amazonaws.com')],\n      actions: ['s3:GetBucketAcl', 's3:ListBucket'],\n      resources: [bucket.bucketArn],\n      conditions: {\n        StringEquals: {\n          'aws:SourceAccount': this.account,\n        },\n        ArnLike: {\n          'aws:SourceArn': this.formatArn({\n            service: 'logs',\n            resource: '*',\n          }),\n        },\n      },\n    }));\n\n    vpc.addFlowLog('FlowLogsS3KeyPrefix', {\n      destination: FlowLogDestination.toS3(bucket, 'prefix/'),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class DeliveryStream for AWS resource management", "output": "export class DeliveryStream extends DeliveryStreamBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-kinesisfirehose.DeliveryStream';\n\n  /**\n   * Import an existing delivery stream from its name.\n   */\n  static fromDeliveryStreamName(scope: Construct, id: string, deliveryStreamName: string): IDeliveryStream {\n    return this.fromDeliveryStreamAttributes(scope, id, { deliveryStreamName });\n  }\n\n  /**\n   * Import an existing delivery stream from its ARN.\n   */\n  static fromDeliveryStreamArn(scope: Construct, id: string, deliveryStreamArn: string): IDeliveryStream {\n    return this.fromDeliveryStreamAttributes(scope, id, { deliveryStreamArn });\n  }\n\n  /**\n   * Import an existing delivery stream from its attributes.\n   */\n  static fromDeliveryStreamAttributes(scope: Construct, id: string, attrs: DeliveryStreamAttributes): IDeliveryStream {\n    if (!attrs.deliveryStreamName && !attrs.deliveryStreamArn) {\n      throw new cdk.ValidationError('Either deliveryStreamName or deliveryStreamArn must be provided in DeliveryStreamAttributes', scope);\n    }\n    const deliveryStreamName = attrs.deliveryStreamName ??\n      cdk.Stack.of(scope).splitArn(attrs.deliveryStreamArn!, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n\n    if (!deliveryStreamName) {\n      throw new cdk.ValidationError(`No delivery stream name found in ARN: '${attrs.deliveryStreamArn}'`, scope);\n    }\n    const deliveryStreamArn = attrs.deliveryStreamArn ?? cdk.Stack.of(scope).formatArn({\n      service: 'firehose',\n      resource: 'deliverystream',\n      resourceName: attrs.deliveryStreamName,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n    class Import extends DeliveryStreamBase {\n      public readonly deliveryStreamName = deliveryStreamName!;\n      public readonly deliveryStreamArn = deliveryStreamArn;\n      public readonly grantPrincipal = attrs.role ?? new iam.UnknownPrincipal({ resource: this });\n    }\n    return new Import(scope, id);\n  }\n\n  readonly deliveryStreamName: string;\n\n  readonly deliveryStreamArn: string;\n\n  private _role?: iam.IRole;\n\n  public get grantPrincipal(): iam.IPrincipal {\n    // backwards compatibility - create role only once\n    this._role = this._role ?? new iam.Role(this, 'Service Role', {\n      assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n    });\n    return this._role;\n  }\n\n  constructor(scope: Construct, id: string, props: DeliveryStreamProps) {\n    super(scope, id, {\n      physicalName: props.deliveryStreamName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this._role = props.role;\n\n    if (props.encryption?.encryptionKey || props.source) {\n      this._role = this._role ?? new iam.Role(this, 'Service Role', {\n        assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n      });\n    }\n\n    if (\n      props.source &&\n        (props.encryption?.type === StreamEncryptionType.AWS_OWNED || props.encryption?.type === StreamEncryptionType.CUSTOMER_MANAGED)\n    ) {\n      throw new cdk.ValidationError('Requested server-side encryption but delivery stream source is a Kinesis data stream. Specify server-side encryption on the data stream instead.', this);\n    }\n    const encryptionKey = props.encryption?.encryptionKey ?? (props.encryption?.type === StreamEncryptionType.CUSTOMER_MANAGED ? new kms.Key(this, 'Key') : undefined);\n    const encryptionConfig = (encryptionKey || (props.encryption?.type === StreamEncryptionType.AWS_OWNED)) ? {\n      keyArn: encryptionKey?.keyArn,\n      keyType: encryptionKey ? 'CUSTOMER_MANAGED_CMK' : 'AWS_OWNED_CMK',\n    } : undefined;\n    /*\n     * In order for the service role to have access to the encryption key before the delivery stream is created, the\n     * CfnDeliveryStream below should have a dependency on the grant returned by the function call below:\n     * > `keyGrant?.applyBefore(resource)`\n     * However, an error during synthesis is thrown if this is added:\n     * > ${Token[PolicyDocument.###]} does not implement DependableTrait\n     * Data will not be lost if the permissions are not granted to the service role immediately; Firehose has a 24 hour\n     * period where data will be buffered and retried if access is denied to the encryption key. For that reason, it is\n     * acceptable to omit the dependency for now. See: https://github.com/aws/aws-cdk/issues/15790\n     */\n    if (this._role && encryptionKey) {\n      encryptionKey?.grantEncryptDecrypt(this._role);\n    }\n\n    let readStreamGrant = undefined;\n    if (this._role && props.source) {\n      readStreamGrant = props.source.grantRead(this._role);\n    }\n\n    const destinationConfig = props.destination.bind(this, {});\n    const sourceConfig = props.source?._bind(this, this._role?.roleArn);\n\n    const resource = new CfnDeliveryStream(this, 'Resource', {\n      deliveryStreamEncryptionConfigurationInput: encryptionConfig,\n      deliveryStreamName: props.deliveryStreamName,\n      deliveryStreamType: props.source ? 'KinesisStreamAsSource' : 'DirectPut',\n      ...sourceConfig,\n      ...destinationConfig,\n    });\n\n    destinationConfig.dependables?.forEach(dependable => resource.node.addDependency(dependable));\n\n    if (readStreamGrant) {\n      resource.node.addDependency(readStreamGrant);\n    }\n\n    this.deliveryStreamArn = this.getResourceArnAttribute(resource.attrArn, {\n      service: 'kinesis',\n      resource: 'deliverystream',\n      resourceName: this.physicalName,\n    });\n    this.deliveryStreamName = this.getResourceNameAttribute(resource.ref);\n  }\n}", "language": "typescript"}
{"input": "Returns a list of all attribute values for a given parameter type and attribute.", "output": "class FnValueOfAll extends FnBase {\n  /**\n   * Creates an ``Fn::ValueOfAll`` function.\n   * @param parameterType An AWS-specific parameter type, such as AWS::EC2::SecurityGroup::Id or AWS::EC2::VPC::Id. For more information, see Parameters in the AWS CloudFormation User Guide.\n   * @param attribute The name of an attribute from which you want to retrieve a value. For more information about attributes, see Supported Attributes.\n   */\n  constructor(parameterType: string, attribute: string) {\n    super('Fn::ValueOfAll', [parameterType, attribute]);\n  }\n}", "language": "typescript"}
{"input": "The Tag Aspect will handle adding a tag to this node and cascading tags to children", "output": "export class Tag extends TagBase {\n  /**\n   * DEPRECATED: add tags to the node of a construct and all its the taggable children\n   *\n   * @deprecated use `Tags.of(scope).add()`\n   */\n  public static add(scope: Construct, key: string, value: string, props: TagProps = {}) {\n    Annotations.of(scope).addDeprecation('@aws-cdk/core.Tag.add(scope,k,v)', 'Use \"Tags.of(scope).add(k,v)\" instead');\n    Tags.of(scope).add(key, value, props);\n  }\n\n  /**\n   * DEPRECATED: remove tags to the node of a construct and all its the taggable children\n   *\n   * @deprecated use `Tags.of(scope).remove()`\n   */\n  public static remove(scope: Construct, key: string, props: TagProps = {}) {\n    Annotations.of(scope).addDeprecation('@aws-cdk/core.Tag.remove(scope,k,v)', 'Use \"Tags.of(scope).remove(k,v)\" instead');\n    Tags.of(scope).remove(key, props);\n  }\n\n  /**\n   * The string value of the tag\n   */\n  public readonly value: string;\n\n  private readonly defaultPriority = 100;\n\n  constructor(key: string, value: string, props: TagProps = {}) {\n    super(key, props);\n    if (value === undefined) {\n      throw new UnscopedValidationError(`Tag '${key}' must have a value`);\n    }\n    this.value = value;\n  }\n\n  protected applyTag(resource: ITaggable) {\n    this.applyManager(resource.tags);\n  }\n\n  protected applyTagV2(resource: ITaggableV2) {\n    this.applyManager(resource.cdkTagManager);\n  }\n\n  private applyManager(mgr: TagManager) {\n    if (mgr.applyTagAspectHere(this.props.includeResourceTypes, this.props.excludeResourceTypes)) {\n      mgr.setTag(\n        this.key,\n        this.value,\n        this.props.priority ?? this.defaultPriority,\n        this.props.applyToLaunchedInstances !== false,\n      );\n    }\n  }\n}", "language": "typescript"}
{"input": "A scalable sagemaker endpoint attribute", "output": "export class ScalableInstanceCount extends appscaling.BaseScalableAttribute {\n  /**\n   * Constructs a new instance of the ScalableInstanceCount class.\n   */\n  constructor(scope: Construct, id: string, props: ScalableInstanceCountProps) {\n    super(scope, id, props);\n  }\n\n  /**\n   * Scales in or out to achieve a target requests per second per instance.\n   */\n  public scaleOnInvocations(id: string, props: InvocationsScalingProps) {\n    const predefinedMetric = appscaling.PredefinedMetric.SAGEMAKER_VARIANT_INVOCATIONS_PER_INSTANCE;\n\n    super.doScaleToTrackMetric(id, {\n      policyName: props.policyName,\n      disableScaleIn: props.disableScaleIn,\n      scaleInCooldown: props.scaleInCooldown,\n      scaleOutCooldown: props.scaleOutCooldown,\n      targetValue: this.calculateScalingTarget(props),\n      predefinedMetric,\n    });\n  }\n\n  /**\n   * Calculate target value based on a ScalableProductionVariant\n   *\n   * Documentation for the equation is here: https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-scaling-loadtest.html\n   * @param props the scaling properties.\n   */\n  private calculateScalingTarget(props: InvocationsScalingProps): number {\n    const safetyFactor = props.safetyFactor ?? 0.5;\n    if (safetyFactor <= 0.0 || safetyFactor > 1.0) {\n      throw new Error(`Safety factor (${safetyFactor}) must be greater than 0.0 and less than or equal 1.0`);\n    }\n    return safetyFactor * props.maxRequestsPerSecond * 60;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, EventBridge, MSK (Kafka) resources", "output": "class EventStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 1, restrictDefaultSecurityGroup: false });\n    const cluster = new ecs.Cluster(this, 'FargateCluster', { vpc });\n\n    // Create the scheduled task\n    new ScheduledFargateTask(this, 'ScheduledFargateTask', {\n      cluster,\n      scheduledFargateTaskImageOptions: {\n        image: new ecs.AssetImage(path.join(__dirname, '..', 'demo-image')),\n        memoryLimitMiB: 512,\n        cpu: 256,\n        environment: { TRIGGER: 'CloudWatch Events' },\n      },\n      desiredTaskCount: 2,\n      schedule: events.Schedule.rate(cdk.Duration.minutes(2)),\n      propagateTags: ecs.PropagatedTagSource.TASK_DEFINITION,\n      tags: [\n        {\n          key: 'my-tag',\n          value: 'my-tag-value',\n        },\n      ],\n    });\n\n    // Create the scheduled task with container name\n    new ScheduledFargateTask(this, 'ScheduledFargateTask2', {\n      cluster,\n      scheduledFargateTaskImageOptions: {\n        image: new ecs.AssetImage(path.join(__dirname, '..', 'demo-image')),\n        containerName: 'differentName',\n        memoryLimitMiB: 512,\n        cpu: 256,\n        environment: { TRIGGER: 'CloudWatch Events' },\n      },\n      desiredTaskCount: 2,\n      schedule: events.Schedule.rate(cdk.Duration.minutes(2)),\n      propagateTags: ecs.PropagatedTagSource.TASK_DEFINITION,\n      tags: [\n        {\n          key: 'my-tag',\n          value: 'my-tag-value',\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class InstanceSnapshoter for AWS resource management", "output": "export class InstanceSnapshoter extends Construct {\n  public readonly snapshotArn: string;\n\n  constructor(scope: Construct, id: string, props: InstanceSnapshoterProps) {\n    super(scope, id);\n\n    const instanceArn = Stack.of(this).formatArn({\n      service: 'rds',\n      resource: 'db',\n      resourceName: props.instance.instanceIdentifier,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    const snapshotArn = Stack.of(this).formatArn({\n      service: 'rds',\n      resource: 'snapshot',\n      resourceName: props.snapshotIdentifier,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    const code = lambda.Code.fromAsset(path.join(__dirname, 'instance-snapshot-handler'), { exclude: ['*.ts'] });\n    const onEventHandler = new lambda.Function(this, 'OnEventHandler', {\n      code,\n      runtime: lambda.Runtime.NODEJS_22_X,\n      handler: 'index.onEventHandler',\n      initialPolicy: [\n        new iam.PolicyStatement({\n          actions: ['rds:CreateDBSnapshot', 'rds:AddTagsToResource', 'rds:DeleteDBSnapshot'],\n          resources: [instanceArn, snapshotArn],\n        }),\n      ],\n    });\n\n    const isCompleteHandler = new lambda.Function(this, 'IsCompleteHandler', {\n      code,\n      runtime: lambda.Runtime.NODEJS_22_X,\n      handler: 'index.isCompleteHandler',\n      initialPolicy: [\n        new iam.PolicyStatement({\n          actions: ['rds:DescribeDBSnapshots'],\n          resources: [instanceArn, snapshotArn],\n        }),\n      ],\n    });\n\n    const provider = new cr.Provider(this, 'SnapshotProvider', {\n      onEventHandler,\n      isCompleteHandler,\n    });\n\n    const customResource = new CustomResource(this, 'Snapshot', {\n      resourceType: 'Custom::Snapshoter',\n      serviceToken: provider.serviceToken,\n      properties: {\n        DBInstanceIdentifier: props.instance.instanceIdentifier,\n        DBSnapshotIdentifier: props.snapshotIdentifier,\n      },\n    });\n    this.snapshotArn = customResource.getAttString('DBSnapshotArn');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, Cognito, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const userPool = new UserPool(this, 'UserPool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const role = new Role(this, 'Role', {\n      assumedBy: new ServicePrincipal('cognito-idp.amazonaws.com'),\n    });\n\n    new UserPoolGroup(this, 'UserPoolGroup', {\n      userPool: userPool,\n      groupName: 'test-group',\n      description: 'My user pool group',\n      precedence: 1,\n      role,\n    });\n\n    userPool.addGroup('AnotherUserPoolGroup', {});\n  }\n}", "language": "typescript"}
{"input": "CDK class NetworkMultipleTargetGroupsFargateService for AWS resource management", "output": "export class NetworkMultipleTargetGroupsFargateService extends NetworkMultipleTargetGroupsServiceBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs-patterns.NetworkMultipleTargetGroupsFargateService';\n\n  /**\n   * Determines whether the service will be assigned a public IP address.\n   */\n  public readonly assignPublicIp: boolean;\n\n  /**\n   * The Fargate service in this construct.\n   */\n  public readonly service: FargateService;\n\n  /**\n   * The Fargate task definition in this construct.\n   */\n  public readonly taskDefinition: FargateTaskDefinition;\n\n  /**\n   * The default target group for the service.\n   * @deprecated - Use `targetGroups` instead.\n   */\n  public readonly targetGroup: NetworkTargetGroup;\n\n  /**\n   * Constructs a new instance of the NetworkMultipleTargetGroupsFargateService class.\n   */\n  constructor(scope: Construct, id: string, props: NetworkMultipleTargetGroupsFargateServiceProps = {}) {\n    super(scope, id, props);\n\n    this.assignPublicIp = props.assignPublicIp ?? false;\n\n    if (props.taskDefinition && props.taskImageOptions) {\n      throw new ValidationError('You must specify only one of TaskDefinition or TaskImageOptions.', this);\n    } else if (props.taskDefinition) {\n      this.taskDefinition = props.taskDefinition;\n    } else if (props.taskImageOptions) {\n      const taskImageOptions = props.taskImageOptions;\n      this.taskDefinition = new FargateTaskDefinition(this, 'TaskDef', {\n        memoryLimitMiB: props.memoryLimitMiB,\n        cpu: props.cpu,\n        ephemeralStorageGiB: props.ephemeralStorageGiB,\n        executionRole: taskImageOptions.executionRole,\n        taskRole: taskImageOptions.taskRole,\n        family: taskImageOptions.family,\n        runtimePlatform: props.runtimePlatform,\n      });\n\n      const containerName = taskImageOptions.containerName ?? 'web';\n      const container = this.taskDefinition.addContainer(containerName, {\n        image: taskImageOptions.image,\n        logging: this.logDriver,\n        environment: taskImageOptions.environment,\n        secrets: taskImageOptions.secrets,\n        dockerLabels: taskImageOptions.dockerLabels,\n      });\n      if (taskImageOptions.containerPorts) {\n        for (const containerPort of taskImageOptions.containerPorts) {\n          container.addPortMappings({\n            containerPort,\n          });\n        }\n      }\n    } else {\n      throw new ValidationError('You must specify one of: taskDefinition or image', this);\n    }\n    if (!this.taskDefinition.defaultContainer) {\n      throw new ValidationError('At least one essential container must be specified', this);\n    }\n    if (this.taskDefinition.defaultContainer.portMappings.length === 0) {\n      this.taskDefinition.defaultContainer.addPortMappings({\n        containerPort: 80,\n      });\n    }\n\n    this.service = this.createFargateService(props);\n    if (props.targetGroups) {\n      this.addPortMappingForTargets(this.taskDefinition.defaultContainer, props.targetGroups);\n      this.targetGroup = this.registerECSTargets(this.service, this.taskDefinition.defaultContainer, props.targetGroups);\n    } else {\n      const containerPort = this.taskDefinition.defaultContainer.portMappings[0].containerPort;\n\n      if (!containerPort) {\n        throw new ValidationError('The first port mapping added to the default container must expose a single port', this);\n      }\n\n      this.targetGroup = this.listener.addTargets('ECS', {\n        targets: [this.service],\n        port: containerPort,\n      });\n    }\n  }\n\n  private createFargateService(props: NetworkMultipleTargetGroupsFargateServiceProps): FargateService {\n    const desiredCount = FeatureFlags.of(this).isEnabled(cxapi.ECS_REMOVE_DEFAULT_DESIRED_COUNT) ? this.internalDesiredCount : this.desiredCount;\n\n    return new FargateService(this, 'Service', {\n      cluster: this.cluster,\n      desiredCount: desiredCount,\n      taskDefinition: this.taskDefinition,\n      assignPublicIp: this.assignPublicIp,\n      serviceName: props.serviceName,\n      healthCheckGracePeriod: props.healthCheckGracePeriod,\n      propagateTags: props.propagateTags,\n      enableECSManagedTags: props.enableECSManagedTags,\n      cloudMapOptions: props.cloudMapOptions,\n      platformVersion: props.platformVersion,\n      enableExecuteCommand: props.enableExecuteCommand,\n      minHealthyPercent: props.minHealthyPercent,\n      maxHealthyPercent: props.maxHealthyPercent,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, SNS, SQS resources", "output": "class S3SnsSqsLambdaChainStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Create a SQS Queue.\n    // A dead-letter queue is optional but it helps capture any failed messages.\n    const deadLetterQueue = new sqs.Queue(this, 'CsvUploadDeadLetterQueue', {\n      queueName: 'CsvUploadDeadLetterQueue',\n      retentionPeriod: Duration.days(7)\n    });\n    const uploadQueue = new sqs.Queue(this, 'CsvUploadQueue', {\n      queueName: 'CsvUploadQueue',\n      visibilityTimeout: Duration.seconds(30),\n      deadLetterQueue: {\n        maxReceiveCount: 1,\n        queue: deadLetterQueue\n      }\n    });\n\n    // Create a SNS Topic.\n    const uploadEventTopic = new sns.Topic(this, 'CsvUploadTopic', {\n      topicName: 'CsvUploadTopic'\n    });\n\n    // Bind the SQS Queue to the SNS Topic.\n    const sqsSubscription = new snsSubscriptions.SqsSubscription(uploadQueue, {\n      rawMessageDelivery: true\n    });\n    uploadEventTopic.addSubscription(sqsSubscription);\n\n\n    // Create an S3 Bucket for uploading files.\n    const s3Bucket = new s3.Bucket(this, 'CsvBucket', {\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n      //! Change the following in production.\n      // This deletes the bucket when the stack is deleted (for easy cleanup).\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    // Binds the S3 bucket to the SNS Topic.\n    s3Bucket.addEventNotification(\n      // Modify the `s3.EventType.*` to handle other object operations.\n      s3.EventType.OBJECT_CREATED_PUT,\n      new s3Notifications.SnsDestination(uploadEventTopic), {\n      // The trigger will only fire on files with the .csv extension.\n      suffix: '.csv'\n    });\n\n\n    // Create a Lambda function that will be triggered by the SQS Queue.\n    const lambdaFunction = new lambdaNodejs.NodejsFunction(this, 'CsvUploadEventLambda', {\n      functionName: 'CsvUploadEventLambda',\n      entry: join(__dirname, '..', 'lambda', 'lambda.ts'),\n    });\n\n    // Bind the Lambda to the SQS Queue.\n    const invokeEventSource = new lambdaEvents.SqsEventSource(uploadQueue);\n    lambdaFunction.addEventSource(invokeEventSource);\n\n    // Outputs to help access the key resources.\n    new CfnOutput(this, 'DeadLetterQueueUrl', {\n      exportName: 'DeadLetterQueue',\n      value: `https://console.aws.amazon.com/sqs/home?region=${this.region}#queue/arn:aws:sqs:${this.region}:${this.account}:${deadLetterQueue.queueName}`\n    })\n    new CfnOutput(this, 'LambdaLogsUrl', {\n      exportName: 'LambdaLogs',\n      value: `https://console.aws.amazon.com/cloudwatch/home?region=${this.region}#logsV2:log-groups/log-group/$252Faws$252Flambda$252F${lambdaFunction.functionName}`\n    })\n    new CfnOutput(this, 'UploadCsvToBucketCommand', {\n      exportName: 'UploadCsvToBucketCommand',\n      value: `aws s3 cp example.csv s3://${s3Bucket.bucketName}/example.csv --acl bucket-owner-full-control`\n    })\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, Config resources", "output": "export class MainStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const ssmStack = new SsmStack(this, 'SsmStack');\n    const s3Stack = new S3Stack(this, 'S3Stack');\n    s3Stack.addDependency(ssmStack);\n\n    new cdk.CfnOutput(this, 'BucketName', {\n      value: s3Stack.bucket.bucketName,\n      description: 'Check config.json in this bucket',\n    });\n\n    new cdk.CfnOutput(this, 'ParameterName', {\n      value: ssmStack.ssmParam.parameterName,\n      description: 'SSM parameter name',\n    });\n\n    new cdk.CfnOutput(this, 'ExpectedValues', {\n      value: JSON.stringify(['subnet-12345', 'subnet-67890']),\n      description: 'Expected subnet values in config.json',\n    });\n\n    new cdk.CfnOutput(this, 'VerificationCommand', {\n      value: `aws s3 cp s3://${s3Stack.bucket.bucketName}/config.json - | jq .`,\n      description: 'Command to check the deployed JSON',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation, Lake Formation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const serviceLinkedRole = new CfnResource(this, 'ServiceLinkedRole', {\n      type: 'AWS::IAM::ServiceLinkedRole',\n      properties: {\n        AWSServiceName: 'es.amazonaws.com',\n        Description: 'Role for ElasticSearch VPC Test',\n      },\n    });\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { restrictDefaultSecurityGroup: false });\n    const domainProps: es.DomainProps = {\n      version: es.ElasticsearchVersion.V7_1,\n      removalPolicy: RemovalPolicy.DESTROY,\n      vpc,\n      zoneAwareness: {\n        enabled: true,\n      },\n      capacity: {\n        dataNodes: 2,\n      },\n    };\n    const domain = new es.Domain(this, 'Domain', domainProps);\n    domain.node.addDependency(serviceLinkedRole);\n  }\n}", "language": "typescript"}
{"input": "CDK class KafkaSelfManagedEventSourceTest for AWS resource management", "output": "class KafkaSelfManagedEventSourceTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\nMIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\ncmUuiAii9R0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\nc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n-----END CERTIFICATE-----\"\n`;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\nzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n-----END ENCRYPTED PRIVATE KEY-----`;\n\n    const fn = new TestFunction(this, 'F');\n    const rootCASecret = new secretsmanager.Secret(this, 'S', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'SC', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n        privateKey: cdk.SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n    rootCASecret.grantRead(fn);\n    clientCertificatesSecret.grantRead(fn);\n\n    const bootstrapServers = [\n      'my-self-hosted-kafka-broker-1:9092',\n      'my-self-hosted-kafka-broker-2:9092',\n      'my-self-hosted-kafka-broker-3:9092',\n    ];\n\n    fn.addEventSource(\n      new SelfManagedKafkaEventSource({\n        bootstrapServers,\n        topic: 'my-test-topic',\n        consumerGroupId: 'myTestConsumerGroup',\n        secret: clientCertificatesSecret,\n        authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n        rootCACertificate: rootCASecret,\n        startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n        filters: [\n          lambda.FilterCriteria.filter({\n            numericEquals: lambda.FilterRule.isEqual(1),\n          }),\n        ],\n      }),\n    );\n\n    const myKey = new Key(this, 'fc-test-key-name', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      pendingWindow: cdk.Duration.days(7),\n      description: 'KMS key for test fc encryption',\n    });\n\n    const fn2 = new TestFunction(this, 'F2');\n    rootCASecret.grantRead(fn2);\n    clientCertificatesSecret.grantRead(fn2);\n\n    fn2.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'my-test-topic2',\n      consumerGroupId: 'myTestConsumerGroup2',\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      filters: [\n        lambda.FilterCriteria.filter({\n          numericEquals: lambda.FilterRule.isEqual(2),\n        }),\n      ],\n      filterEncryption: myKey,\n    }));\n\n    const fn3 = new TestFunction(this, 'F3');\n    rootCASecret.grantRead(fn3);\n    clientCertificatesSecret.grantRead(fn3);\n\n    fn3.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'my-test-topic3',\n      consumerGroupId: 'myTestConsumerGroup3',\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      filters: [\n        lambda.FilterCriteria.filter({\n          numericEquals: lambda.FilterRule.isEqual(1),\n        }),\n      ],\n      provisionedPollerConfig: {\n        minimumPollers: 1,\n        maximumPollers: 3,\n      },\n    }));\n\n    const fn4 = new TestFunction(this, 'F4');\n    rootCASecret.grantRead(fn4);\n    clientCertificatesSecret.grantRead(fn4);\n\n    fn4.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'my-test-topic4',\n      consumerGroupId: 'myTestConsumerGroup4',\n      secret: clientCertificatesSecret,\n      authenticationMethod:\n        AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.AT_TIMESTAMP,\n      startingPositionTimestamp: 1730270400,\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class GrantReadWriteTest for AWS resource management", "output": "class GrantReadWriteTest extends GrantTestBase {\n  actions = perms.TABLE_READ_WRITE_ACCESS;\n  getTableName() {\n    return 'grant_read_write_table';\n  }\n  grantAccess() {\n    this.table.grantReadWrite(new iam.ServicePrincipal(PRINCIPAL));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, CloudFormation resources", "output": "class DynamoDBStack(cdk.NestedStack):\n    def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        table_name: str,\n        table_replica_regions: List[ReplicaConfig],\n        **kwargs\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        ddb.CfnGlobalTable(\n            self,\n            \"global-table\",\n            table_name=table_name,\n            billing_mode=\"PAY_PER_REQUEST\",\n            attribute_definitions=[\n                ddb.CfnGlobalTable.AttributeDefinitionProperty(\n                    attribute_name=\"id\", attribute_type=\"S\"\n                )\n            ],\n            key_schema=[\n                ddb.CfnGlobalTable.KeySchemaProperty(\n                    attribute_name=\"id\", key_type=\"HASH\"\n                )\n            ],\n            replicas=[\n                ddb.CfnGlobalTable.ReplicaSpecificationProperty(\n                    region=replica_config[\"region\"],\n                    sse_specification=ddb.CfnGlobalTable.ReplicaSSESpecificationProperty(\n                        kms_master_key_id=cdk.Fn.import_value(\n                            replica_config[\"key_export_name\"]\n                        )\n                    ),\n                )\n                for replica_config in table_replica_regions\n            ],\n            sse_specification=ddb.CfnGlobalTable.SSESpecificationProperty(\n                sse_enabled=True, sse_type=\"KMS\"\n            ),\n            stream_specification=ddb.CfnGlobalTable.StreamSpecificationProperty(\n                stream_view_type=\"KEYS_ONLY\"\n            ),\n        )", "language": "python"}
{"input": "The identity to use for DKIM", "output": "class DkimIdentity {\n  /**\n   * Easy DKIM\n   *\n   * @param signingKeyLength The length of the signing key. This can be changed at\n   *   most once per day.\n   *\n   * @see https://docs.aws.amazon.com/ses/latest/dg/send-email-authentication-dkim-easy.html\n   */\n  public static easyDkim(signingKeyLength?: EasyDkimSigningKeyLength): DkimIdentity {\n    return new EasyDkim(signingKeyLength);\n  }\n\n  /**\n   * Bring Your Own DKIM\n   *\n   * @param options Options for BYO DKIM\n   *\n   * @see https://docs.aws.amazon.com/ses/latest/dg/send-email-authentication-dkim-bring-your-own.html\n   */\n  public static byoDkim(options: ByoDkimOptions): DkimIdentity {\n    return new ByoDkim(options);\n  }\n\n  /**\n   * Binds this DKIM identity to the email identity\n   */\n  public abstract bind(emailIdentity: EmailIdentity, hostedZone?: route53.IPublicHostedZone): DkimIdentityConfig | undefined;\n}", "language": "typescript"}
{"input": "Adds statements to a bucket policy @mixin true", "output": "export class BucketPolicyStatementsMixins extends Mixin {\n  private readonly statements: PolicyStatement[];\n\n  public constructor(statements: PolicyStatement[]) {\n    super();\n    this.statements = statements;\n  }\n\n  public supports(construct: IConstruct): construct is CfnBucketPolicy {\n    return makeIsCfnResource('AWS::S3::BucketPolicy')(construct);\n  }\n\n  public applyTo(policy: IConstruct): IConstruct {\n    if (!this.supports(policy)) {\n      return policy;\n    }\n\n    const policyDocument = this.getPolicyDocument(policy);\n    policyDocument.addStatements(...this.statements);\n\n    policy.policyDocument = policyDocument;\n\n    return policy;\n  }\n\n  /**\n   * CfnBucketPolicy.policyDocument sometimes is a PolicyDocument object\n   * and sometimes is a plain object. We need to handle both cases.\n   */\n  private getPolicyDocument(policy: CfnBucketPolicy): PolicyDocument {\n    if (policy.policyDocument instanceof PolicyDocument) {\n      return policy.policyDocument;\n    }\n    return PolicyDocument.fromJson(policy.policyDocument);\n  }\n}", "language": "typescript"}
{"input": "CDK class TestCase for AWS resource management", "output": "class TestCase extends Construct {\n  constructor(scope: Construct, id: string, props: TestCaseProps) {\n    super(scope, id);\n    const cluster = new rds.DatabaseCluster(this, 'Integ-Cluster', {\n      engine: rds.DatabaseClusterEngine.auroraMysql({ version: rds.AuroraMysqlEngineVersion.VER_3_07_1 }),\n      writer: props.writer,\n      readers: props.readers,\n      removalPolicy: RemovalPolicy.DESTROY,\n      vpc: props.vpc,\n    });\n    cluster.metricServerlessDatabaseCapacity({\n      period: Duration.minutes(10),\n    }).createAlarm(this, 'capacity', {\n      threshold: 1.5,\n      evaluationPeriods: 3,\n    });\n    cluster.metricACUUtilization({\n      period: Duration.minutes(10),\n    }).createAlarm(this, 'alarm', {\n      evaluationPeriods: 3,\n      threshold: 90,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Interfaces for AWS resource management", "output": "export class Interfaces extends ExternalModule {\n  public readonly IEnvironmentAware = Type.fromName(this, 'IEnvironmentAware');\n\n  public readonly IBucketRef = Type.fromName(this, 'aws_s3.IBucketRef');\n  public readonly ILogGroupRef = Type.fromName(this, 'aws_logs.ILogGroupRef');\n  public readonly IDeliveryStreamRef = Type.fromName(this, 'aws_kinesisfirehose.IDeliveryStreamRef');\n}", "language": "typescript"}
{"input": "Test for table with schema and compaction settings", "output": "class SchemaTableStack extends core.Stack {\n  public readonly table: s3tables.Table;\n  public readonly namespace: s3tables.Namespace;\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n\n    this.tableBucket = new s3tables.TableBucket(this, 'SchemaBucket', {\n      tableBucketName: 'schema-table-bucket',\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    this.namespace = new s3tables.Namespace(this, 'SchemaNamespace', {\n      namespaceName: 'schema_table_namespace',\n      tableBucket: this.tableBucket,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    this.table = new s3tables.Table(this, 'SchemaTable', {\n      tableName: 'schema_test_table',\n      namespace: this.namespace,\n      openTableFormat: s3tables.OpenTableFormat.ICEBERG,\n      icebergMetadata: {\n        icebergSchema: {\n          schemaFieldList: [\n            {\n              name: 'id',\n              type: 'int',\n              required: true,\n            },\n            {\n              name: 'name',\n              type: 'string',\n            },\n            {\n              name: 'timestamp',\n              type: 'timestamp',\n            },\n          ],\n        },\n      },\n      compaction: {\n        status: s3tables.Status.ENABLED,\n        targetFileSizeMb: 128,\n      },\n      snapshotManagement: {\n        status: s3tables.Status.ENABLED,\n        maxSnapshotAgeHours: 48,\n        minSnapshotsToKeep: 5,\n      },\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class SecurityGroup for AWS resource management", "output": "export class SecurityGroup extends SecurityGroupBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.SecurityGroup';\n\n  /**\n   * Look up a security group by id.\n   *\n   * @deprecated Use `fromLookupById()` instead\n   */\n  public static fromLookup(scope: Construct, id: string, securityGroupId: string) {\n    return this.fromLookupAttributes(scope, id, { securityGroupId });\n  }\n\n  /**\n   * Look up a security group by id.\n   */\n  public static fromLookupById(scope: Construct, id: string, securityGroupId: string) {\n    return this.fromLookupAttributes(scope, id, { securityGroupId });\n  }\n\n  /**\n   * Look up a security group by name.\n   */\n  public static fromLookupByName(scope: Construct, id: string, securityGroupName: string, vpc: IVpc) {\n    return this.fromLookupAttributes(scope, id, { securityGroupName, vpc });\n  }\n\n  /**\n   * Import an existing security group into this app.\n   *\n   * This method will assume that the Security Group has a rule in it which allows\n   * all outbound traffic, and so will not add egress rules to the imported Security\n   * Group (only ingress rules).\n   *\n   * If your existing Security Group needs to have egress rules added, pass the\n   * `allowAllOutbound: false` option on import.\n   */\n  public static fromSecurityGroupId(scope: Construct, id: string, securityGroupId: string, options: SecurityGroupImportOptions = {}): ISecurityGroup {\n    class MutableImport extends SecurityGroupBase {\n      public securityGroupId = securityGroupId;\n      public allowAllOutbound = options.allowAllOutbound ?? true;\n      public allowAllIpv6Outbound = options.allowAllIpv6Outbound ?? false;\n\n      public addEgressRule(peer: IPeer, connection: Port, description?: string, remoteRule?: boolean) {\n        // Only if allowAllOutbound has been disabled\n        if (options.allowAllOutbound === false) {\n          super.addEgressRule(peer, connection, description, remoteRule);\n        }\n      }\n    }\n\n    class ImmutableImport extends SecurityGroupBase {\n      public securityGroupId = securityGroupId;\n      public allowAllOutbound = options.allowAllOutbound ?? true;\n      public allowAllIpv6Outbound = options.allowAllIpv6Outbound ?? false;\n\n      public addEgressRule(_peer: IPeer, _connection: Port, _description?: string, _remoteRule?: boolean) {\n        // do nothing\n      }\n\n      public addIngressRule(_peer: IPeer, _connection: Port, _description?: string, _remoteRule?: boolean) {\n        // do nothing\n      }\n    }\n\n    return options.mutable !== false\n      ? new MutableImport(scope, id)\n      : new ImmutableImport(scope, id);\n  }\n\n  /**\n   * Look up a security group.\n   */\n  private static fromLookupAttributes(scope: Construct, id: string, options: SecurityGroupLookupOptions) {\n    if (Token.isUnresolved(options.securityGroupId) || Token.isUnresolved(options.securityGroupName) || Token.isUnresolved(options.vpc?.vpcId)) {\n      throw new ValidationError('All arguments to look up a security group must be concrete (no Tokens)', scope);\n    }\n\n    const attributes: cxapi.SecurityGroupContextResponse = ContextProvider.getValue(scope, {\n      provider: cxschema.ContextProvider.SECURITY_GROUP_PROVIDER,\n      props: {\n        securityGroupId: options.securityGroupId,\n        securityGroupName: options.securityGroupName,\n        vpcId: options.vpc?.vpcId,\n      },\n      dummyValue: {\n        securityGroupId: 'sg-12345678',\n        allowAllOutbound: true,\n      } as cxapi.SecurityGroupContextResponse,\n    }).value;\n\n    return SecurityGroup.fromSecurityGroupId(scope, id, attributes.securityGroupId, {\n      allowAllOutbound: attributes.allowAllOutbound,\n      mutable: true,\n    });\n  }\n\n  /**\n   * An attribute that represents the security group name.\n   *\n   * @attribute\n   * @deprecated returns the security group ID, rather than the name.\n   */\n  public readonly securityGroupName: string;\n\n  /**\n   * The ID of the security group\n   *\n   * @attribute\n   */\n  public readonly securityGroupId: string;\n\n  /**\n   * The VPC ID this security group is part of.\n   *\n   * @attribute\n   */\n  public readonly securityGroupVpcId: string;\n\n  /**\n   * Whether the SecurityGroup has been configured to allow all outbound traffic\n   */\n  public readonly allowAllOutbound: boolean;\n\n  /**\n   * Whether the SecurityGroup has been configured to allow all outbound ipv6 traffic\n   */\n  public readonly allowAllIpv6Outbound: boolean;\n\n  private readonly securityGroup: CfnSecurityGroup;\n  private readonly directIngressRules: CfnSecurityGroup.IngressProperty[] = [];\n  private readonly directEgressRules: CfnSecurityGroup.EgressProperty[] = [];\n\n  /**\n   * Whether to disable optimization for inline security group rules.\n   */\n  private readonly disableInlineRules: boolean;\n\n  constructor(scope: Construct, id: string, props: SecurityGroupProps) {\n    super(scope, id, {\n      physicalName: props.securityGroupName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const groupDescription = props.description || this.node.path;\n\n    this.allowAllOutbound = props.allowAllOutbound !== false;\n    this.allowAllIpv6Outbound = props.allowAllIpv6Outbound ?? false;\n\n    this.disableInlineRules = props.disableInlineRules !== undefined ?\n      !!props.disableInlineRules :\n      !!this.node.tryGetContext(SECURITY_GROUP_DISABLE_INLINE_RULES_CONTEXT_KEY);\n\n    this.securityGroup = new CfnSecurityGroup(this, 'Resource', {\n      groupName: this.physicalName,\n      groupDescription,\n      securityGroupIngress: Lazy.any({ produce: () => this.directIngressRules }, { omitEmptyArray: true }),\n      securityGroupEgress: Lazy.any({ produce: () => this.directEgressRules }, { omitEmptyArray: true }),\n      vpcId: props.vpc.vpcId,\n    });\n\n    this.securityGroupId = this.securityGroup.attrGroupId;\n    this.securityGroupVpcId = this.securityGroup.attrVpcId;\n    this.securityGroupName = this.securityGroup.ref;\n\n    this.addDefaultEgressRule();\n    this.addDefaultIpv6EgressRule();\n  }\n\n  @MethodMetadata()\n  public addIngressRule(peer: IPeer, connection: Port, description?: string, remoteRule?: boolean) {\n    if (!peer.canInlineRule || !connection.canInlineRule || this.disableInlineRules) {\n      super.addIngressRule(peer, connection, description, remoteRule);\n      return;\n    }\n\n    if (description === undefined) {\n      description = `from ${peer.uniqueId}:${connection}`;\n    }\n\n    this.addDirectIngressRule({\n      ...peer.toIngressRuleConfig(),\n      ...connection.toRuleJson(),\n      description,\n    });\n  }\n\n  @MethodMetadata()\n  public addEgressRule(peer: IPeer, connection: Port, description?: string, remoteRule?: boolean) {\n    const isIpv6 = peer.toEgressRuleConfig().hasOwnProperty('cidrIpv6');\n\n    if (!isIpv6 && this.allowAllOutbound) {\n      // In the case of \"allowAllOutbound\", we don't add any more rules. There\n      // is only one rule which allows all traffic and that subsumes any other\n      // rule.\n      if (!remoteRule) { // Warn only if addEgressRule() was explicitly called\n        Annotations.of(this).addWarningV2('@aws-cdk/aws-ec2:ipv4IgnoreEgressRule', 'Ignoring Egress rule since \\'allowAllOutbound\\' is set to true; To add customized rules, set allowAllOutbound=false on the SecurityGroup');\n      }\n      return;\n    } else if (!isIpv6 && !this.allowAllOutbound) {\n      // Otherwise, if the bogus rule exists we can now remove it because the\n      // presence of any other rule will get rid of EC2's implicit \"all\n      // outbound\" rule anyway.\n      this.removeNoTrafficRule();\n    }\n\n    if (isIpv6 && this.allowAllIpv6Outbound) {\n      // In the case of \"allowAllIpv6Outbound\", we don't add any more rules. There\n      // is only one rule which allows all traffic and that subsumes any other\n      // rule.\n      if (!remoteRule) { // Warn only if addEgressRule() was explicitly called\n        Annotations.of(this).addWarningV2('@aws-cdk/aws-ec2:ipv6IgnoreEgressRule', 'Ignoring Egress rule since \\'allowAllIpv6Outbound\\' is set to true; To add customized rules, set allowAllIpv6Outbound=false on the SecurityGroup');\n      }\n      return;\n    }\n\n    if (!peer.canInlineRule || !connection.canInlineRule || this.disableInlineRules) {\n      super.addEgressRule(peer, connection, description, remoteRule);\n      return;\n    }\n\n    if (description === undefined) {\n      description = `from ${peer.uniqueId}:${connection}`;\n    }\n\n    const rule = {\n      ...peer.toEgressRuleConfig(),\n      ...connection.toRuleJson(),\n      description,\n    };\n\n    if (isAllTrafficRule(rule)) {\n      // We cannot allow this; if someone adds the rule in this way, it will be\n      // removed again if they add other rules. We also can't automatically switch\n      // to \"allOutbound=true\" mode, because we might have already emitted\n      // EgressRule objects (which count as rules added later) and there's no way\n      // to recall those. Better to prevent this for now.\n      throw new ValidationError('Cannot add an \"all traffic\" egress rule in this way; set allowAllOutbound=true (for ipv6) or allowAllIpv6Outbound=true (for ipv6) on the SecurityGroup instead.', this);\n    }\n\n    this.addDirectEgressRule(rule);\n  }", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, EKS resources", "output": "class AppStack extends cdk.Stack {\n      constructor(scope: Construct, id: string, props: cdk.StackProps & { cluster: eks.Cluster }) {\n        super(scope, id, props);\n\n        new eks.ServiceAccount(this, 'testAccount', { cluster: props.cluster, name: 'test-account', namespace: 'test' });\n      }\n    }", "language": "typescript"}
{"input": "CDK class PythonShellJob for AWS resource management", "output": "export class PythonShellJob extends Job {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.PythonShellJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n  public readonly role: iam.IRole;\n  public readonly grantPrincipal: iam.IPrincipal;\n\n  /**\n   * PythonShellJob constructor\n   */\n  constructor(scope: Construct, id: string, props: PythonShellJobProps) {\n    super(scope, id, { physicalName: props.jobName });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Set up role and permissions for principal\n    this.role = props.role;\n    this.grantPrincipal = this.role;\n\n    // Enable CloudWatch metrics and continuous logging by default as a best practice\n    const continuousLoggingArgs = this.setupContinuousLogging(this.role, props.continuousLogging);\n    const profilingMetricsArgs = { '--enable-metrics': '' };\n    const observabilityMetricsArgs = { '--enable-observability-metrics': 'true' };\n\n    // Gather executable arguments\n    const executableArgs = this.executableArguments(props);\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...executableArgs,\n      ...continuousLoggingArgs,\n      ...profilingMetricsArgs,\n      ...observabilityMetricsArgs,\n      ...this.checkNoReservedArgs(props.defaultArguments),\n    };\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.PYTHON_SHELL,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n        pythonVersion: props.pythonVersion ? props.pythonVersion : PythonVersion.THREE_NINE,\n      },\n      glueVersion: props.glueVersion ? props.glueVersion : GlueVersion.V3_0,\n      maxCapacity: props.maxCapacity ? props.maxCapacity : MaxCapacity.DPU_1_16TH,\n      maxRetries: props.jobRunQueuingEnabled ? 0 : props.maxRetries ? props.maxRetries : 0,\n      jobRunQueuingEnabled: props.jobRunQueuingEnabled ? props.jobRunQueuingEnabled : false,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      defaultArguments,\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n\n  /**\n   * Set the executable arguments with best practices enabled by default\n   *\n   * @returns An array of arguments for Glue to use on execution\n   */\n  private executableArguments(props: PythonShellJobProps) {\n    const args: { [key: string]: string } = {};\n    args['--job-language'] = JobLanguage.PYTHON;\n\n    // If no Python version set (default 3.9) or the version is set to 3.9 then set library-set argument\n    if (!props.pythonVersion || props.pythonVersion == PythonVersion.THREE_NINE) {\n      // Selecting this option includes common libraries for Python 3.9\n      args['library-set'] = 'analytics';\n    }\n\n    return args;\n  }\n}", "language": "typescript"}
{"input": "CDK class Api for AWS resource management", "output": "class Api extends Construct {\n  public readonly restApi: apigw.IRestApi;\n  private readonly resource: apigw.Resource;\n  constructor(scope: Construct, id: string, props: ApiProps) {\n    super(scope, id);\n    this.restApi = new apigw.RestApi(this, 'IntegApi'+props.statusCode, {\n      endpointTypes: [apigw.EndpointType.REGIONAL],\n    });\n    this.resource = this.restApi.root.addResource(props.path);\n    const integration = this.createIntegration(props.statusCode);\n    const options = {\n      methodResponses: [{\n        statusCode: props.statusCode,\n      }],\n    };\n    this.restApi.root.addMethod('GET', integration, options);\n    this.resource.addMethod('GET', integration, options);\n  }\n  public addResource(path: string, statusCode: string, resource?: apigw.Resource): void {\n    const subResource = (resource ?? this.resource).addResource(path);\n    const integration = this.createIntegration(statusCode);\n    subResource.addMethod('GET', integration, {\n      methodResponses: [{ statusCode }],\n    });\n  }\n  public addRootResource(path: string, statusCode: string): apigw.Resource {\n    const subResource = this.restApi.root.addResource(path);\n    const integration = this.createIntegration(statusCode);\n    subResource.addMethod('GET', integration, {\n      methodResponses: [{ statusCode }],\n    });\n    return subResource;\n  }\n\n  private createIntegration(statusCode: string): apigw.MockIntegration {\n    return new apigw.MockIntegration({\n      requestTemplates: { 'application/json': `{ statusCode: ${Number(statusCode)} }` },\n      integrationResponses: [{\n        statusCode: statusCode,\n        responseTemplates: {\n          'application/json': JSON.stringify({ message: 'Hello, world' }),\n        },\n      }],\n    });\n  }\n}", "language": "typescript"}
{"input": "Contains details about the Lambda function containing the orchestration logic carried out upon invoking the custom orchestration.", "output": "export class CustomOrchestrationExecutor {\n  /**\n   * Defines an orchestration executor with a Lambda function containing the business logic.\n   * @param lambdaFunction - Lambda function to be called by the orchestration.\n   */\n  public static fromLambda(lambdaFunction: IFunction): CustomOrchestrationExecutor {\n    return new CustomOrchestrationExecutor(lambdaFunction);\n  }\n\n  /**\n   * The type of orchestration this executor performs.\n   */\n  public readonly type: OrchestrationType = OrchestrationType.CUSTOM_ORCHESTRATION;\n\n  /**\n   * The Lambda function that contains the custom orchestration logic.\n   * This function is called when the agent needs to make decisions about action execution.\n   */\n  public readonly lambdaFunction: IFunction;\n\n  private constructor(lambdaFunction: IFunction) {\n    this.lambdaFunction = lambdaFunction;\n  }\n\n  /**\n   * Format as CFN properties\n   *\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): bedrock.CfnAgent.OrchestrationExecutorProperty {\n    return {\n      lambda: this.lambdaFunction?.functionArn,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation, Route 53 resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const hostedZone = new PublicHostedZone(this, 'HostedZone', {\n      zoneName: 'cdk.dev',\n    });\n\n    const lambdaFunction = new Function(this, 'Function', {\n      functionName: 'email-sending-lambda',\n      runtime: Runtime.PYTHON_3_11,\n      code: Code.fromAsset(path.join(__dirname, 'fixtures', 'send-email')),\n      handler: 'index.lambda_handler',\n    });\n\n    const emailIdentity = new ses.EmailIdentity(this, 'EmailIdentity', {\n      identity: ses.Identity.publicHostedZone(hostedZone),\n      mailFromDomain: 'mail.cdk.dev',\n    });\n\n    emailIdentity.grantSendEmail(lambdaFunction);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, Cognito, WAF resources", "output": "class EventApiStack extends cdk.Stack {\n  public readonly eventApi: appsync.EventApi;\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n\n  constructor(scope: Construct, id: string, props: EventApiStackProps) {\n    super(scope, id);\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n\n    const certificate = new acm.Certificate(this, 'Certificate', {\n      domainName: `*.${props.domainName}`,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    const userPool = new cognito.UserPool(this, 'Pool', {\n      userPoolName: 'myPool',\n      selfSignUpEnabled: true,\n      autoVerify: { email: true },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const client = userPool.addClient('lambda-app-client', {\n      preventUserExistenceErrors: true,\n      authFlows: {\n        adminUserPassword: true,\n      },\n    });\n\n    const authorizer = new lambda.Function(this, 'AuthorizerFunction', {\n      runtime: STANDARD_NODEJS_RUNTIME,\n      code: lambda.Code.fromInline(`\n            exports.handler = async (event) => {\n              console.log(\"Authorization event:\", JSON.stringify(event));\n\n              const isAuthorized = true;\n              if (isAuthorized) {\n                return {\n                  isAuthorized: true,\n                  resolverContext: {\n                    userId: 'user-id-example'\n                  }\n                };\n              } else {\n                return {\n                  isAuthorized: false\n                };\n              }\n            };\n          `),\n      handler: 'index.handler',\n    });\n\n    const cognitoProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.USER_POOL,\n      cognitoConfig: {\n        userPool: userPool,\n      },\n    };\n\n    const lambdaProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.LAMBDA,\n      lambdaAuthorizerConfig: {\n        handler: authorizer,\n      },\n    };\n\n    const apiKeyProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.API_KEY,\n    };\n\n    const iamProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.IAM,\n    };\n\n    const api = new appsync.EventApi(this, 'EventApi', {\n      apiName: 'api-overall-test',\n      ownerContact: 'test-owner-contact',\n      authorizationConfig: {\n        authProviders: [\n          cognitoProvider,\n          lambdaProvider,\n          apiKeyProvider,\n          iamProvider,\n        ],\n        connectionAuthModeTypes: [\n          appsync.AppSyncAuthorizationType.API_KEY,\n          appsync.AppSyncAuthorizationType.IAM,\n        ],\n        defaultPublishAuthModeTypes: [\n          appsync.AppSyncAuthorizationType.USER_POOL,\n        ],\n        defaultSubscribeAuthModeTypes: [\n          appsync.AppSyncAuthorizationType.IAM,\n        ],\n      },\n      logConfig: {\n        fieldLogLevel: appsync.AppSyncFieldLogLevel.ERROR,\n      },\n      domainName: {\n        certificate,\n        domainName: `api.${props.domainName}`,\n      },\n    });\n    this.eventApi = api;\n\n    new route53.CnameRecord(this, 'AppSyncCnameRecord', {\n      recordName: `api.${domainName}`,\n      zone: hostedZone,\n      domainName: this.eventApi.appSyncDomainName,\n    });\n\n    const defaultChannel = this.eventApi.addChannelNamespace('default');\n\n    new appsync.ChannelNamespace(this, 'ChannelNamespace', {\n      api,\n      authorizationConfig: {\n        publishAuthModeTypes: [\n          appsync.AppSyncAuthorizationType.API_KEY,\n        ],\n        subscribeAuthModeTypes: [\n          appsync.AppSyncAuthorizationType.API_KEY,\n        ],\n      },\n      code: appsync.Code.fromAsset(path.join(\n        __dirname,\n        'integ-assets',\n        'appsync-js-channel-namespace-handler.js',\n      )),\n    });\n\n    api.addChannelNamespace('AnotherChannelNamespace', {\n      code: appsync.Code.fromInline(`\n            function enrichEvent(event) {\n              return {\n                id: event.id,\n                payload: {\n                  ...event.payload,\n                  newField: 'newField'\n                }\n              }\n            }\n            export function onPublish(ctx) {\n              return ctx.events.map(enrichEvent);\n            }\n          `),\n    });\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: this.eventApi.customRealtimeEndpoint,\n        EVENT_API_HTTP_URL: this.eventApi.customHttpEndpoint,\n        API_KEY: this.eventApi.apiKeys.Default.attrApiKey,\n        USER_POOL_ID: userPool.userPoolId,\n        CLIENT_ID: client.userPoolClientId,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets/eventapi-grant-assertion/index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.minutes(2),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'ApiKeyConfigTestFunction', lambdaConfig);\n    this.eventApi.grantConnect(this.lambdaTestFn);\n    defaultChannel.grantPublishAndSubscribe(this.lambdaTestFn);\n\n    userPool.grant(this.lambdaTestFn,\n      'cognito-idp:SignUp',\n      'cognito-idp:AdminConfirmSignUp',\n      'cognito-idp:AdminDeleteUser',\n      'cognito-idp:AdminInitiateAuth',\n    );\n\n    const webAcl = new CfnWebACL(this, 'WebAcl', {\n      defaultAction: {\n        allow: {},\n      },\n      scope: 'REGIONAL',\n      visibilityConfig: {\n        cloudWatchMetricsEnabled: false,\n        metricName: 'webAclMetric',\n        sampledRequestsEnabled: false,\n      },\n    });\n\n    new CfnWebACLAssociation(this, 'WafAssociation', {\n      resourceArn: api.apiArn,\n      webAclArn: webAcl.attrArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "An environment owner", "output": "export class Owner {\n  /**\n   * Make an IAM user the environment owner\n   *\n   * User need to have AWSCloud9Administrator permissions\n   * @see https://docs.aws.amazon.com/cloud9/latest/user-guide/share-environment.html#share-environment-about\n   *\n   * @param user the User object to use as the environment owner\n   */\n  public static user(user: IUser): Owner {\n    return { ownerArn: user.userArn };\n  }\n\n  /**\n   * Make an IAM assumed role the environment owner\n   *\n   * @param accountId The account id of the target account\n   * @param roleName The name of the assumed role\n   */\n  public static assumedRole(accountId: string, roleName: string): Owner {\n    return { ownerArn: `arn:${cdk.Aws.PARTITION}:sts::${accountId}:assumed-role/${roleName}` };\n  }\n\n  /**\n   * Make an IAM federated user the environment owner\n   *\n   * @param accountId The AccountId of the target account\n   * @param userName The name of the federated user\n   */\n  public static federatedUser(accountId: string, userName: string): Owner {\n    return { ownerArn: `arn:${cdk.Aws.PARTITION}:sts::${accountId}:federated-user/${userName}` };\n  }\n\n  /**\n   * Make the Account Root User the environment owner (not recommended)\n   *\n   * @param accountId the AccountId to use as the environment owner.\n   */\n  public static accountRoot(accountId: string): Owner {\n    return { ownerArn: `arn:${cdk.Aws.PARTITION}:iam::${accountId}:root` };\n  }\n\n  /**\n   *\n   * @param ownerArn of environment owner.\n   */\n  private constructor(public readonly ownerArn: string) {}\n}", "language": "typescript"}
{"input": "CDK class Bucket for AWS resource management", "output": "export class Bucket extends BucketBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-s3.Bucket';\n\n  public static fromBucketArn(scope: Construct, id: string, bucketArn: string): IBucket {\n    return Bucket.fromBucketAttributes(scope, id, { bucketArn });\n  }\n\n  public static fromBucketName(scope: Construct, id: string, bucketName: string): IBucket {\n    return Bucket.fromBucketAttributes(scope, id, { bucketName });\n  }\n\n  /**\n   * Creates a Bucket construct that represents an external bucket.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param attrs A `BucketAttributes` object. Can be obtained from a call to\n   * `bucket.export()` or manually created.\n   */\n  public static fromBucketAttributes(scope: Construct, id: string, attrs: BucketAttributes): IBucket {\n    const stack = Stack.of(scope);\n    const region = attrs.region ?? stack.region;\n    const regionInfo = regionInformation.RegionInfo.get(region);\n    const urlSuffix = regionInfo.domainSuffix ?? stack.urlSuffix;\n\n    const bucketName = parseBucketName(scope, attrs);\n    if (!bucketName) {\n      throw new ValidationError('Bucket name is required', scope);\n    }\n    Bucket.validateBucketName(bucketName, true);\n\n    const oldEndpoint = `s3-website-${region}.${urlSuffix}`;\n    const newEndpoint = `s3-website.${region}.${urlSuffix}`;\n\n    let staticDomainEndpoint = regionInfo.s3StaticWebsiteEndpoint\n      ?? Lazy.string({ produce: () => stack.regionalFact(regionInformation.FactName.S3_STATIC_WEBSITE_ENDPOINT, newEndpoint) });\n\n    // Deprecated use of bucketWebsiteNewUrlFormat\n    if (attrs.bucketWebsiteNewUrlFormat !== undefined) {\n      staticDomainEndpoint = attrs.bucketWebsiteNewUrlFormat ? newEndpoint : oldEndpoint;\n    }\n\n    const websiteDomain = `${bucketName}.${staticDomainEndpoint}`;\n\n    class Import extends BucketBase {\n      public readonly bucketName = bucketName!;\n      public readonly bucketArn = parseBucketArn(scope, attrs);\n      public readonly bucketDomainName = attrs.bucketDomainName || `${bucketName}.s3.${urlSuffix}`;\n      public readonly bucketWebsiteUrl = attrs.bucketWebsiteUrl || `http://${websiteDomain}`;\n      public readonly bucketWebsiteDomainName = attrs.bucketWebsiteUrl ? Fn.select(2, Fn.split('/', attrs.bucketWebsiteUrl)) : websiteDomain;\n      public readonly bucketRegionalDomainName = attrs.bucketRegionalDomainName || `${bucketName}.s3.${region}.${urlSuffix}`;\n      public readonly bucketDualStackDomainName = attrs.bucketDualStackDomainName || `${bucketName}.s3.dualstack.${region}.${urlSuffix}`;\n      public readonly bucketWebsiteNewUrlFormat = attrs.bucketWebsiteNewUrlFormat ?? false;\n      public readonly encryptionKey = attrs.encryptionKey;\n      public readonly isWebsite = attrs.isWebsite ?? false;\n      public policy?: BucketPolicy = undefined;\n      public replicationRoleArn?: string = undefined;\n      protected autoCreatePolicy = false;\n      public disallowPublicAccess = false;\n      protected notificationsHandlerRole = attrs.notificationsHandlerRole;\n\n      /**\n       * Exports this bucket from the stack.\n       */\n      public export() {\n        return attrs;\n      }\n    }\n\n    return new Import(scope, id, {\n      account: attrs.account,\n      region: attrs.region,\n    });\n  }\n\n  /**\n   * Create a mutable `IBucket` based on a low-level `CfnBucket`.\n   */\n  public static fromCfnBucket(cfnBucket: CfnBucket): IBucket {\n    // use a \"weird\" id that has a higher chance of being unique\n    const id = '@FromCfnBucket';\n\n    // if fromCfnBucket() was already called on this cfnBucket,\n    // return the same L2\n    // (as different L2s would conflict, because of the mutation of the policy property of the L1 below)\n    const existing = cfnBucket.node.tryFindChild(id);\n    if (existing) {\n      return <IBucket>existing;\n    }\n\n    // handle the KMS Key if the Bucket references one\n    let encryptionKey: kms.IKey | undefined;\n    if (cfnBucket.bucketEncryption) {\n      const serverSideEncryptionConfiguration = (cfnBucket.bucketEncryption as any).serverSideEncryptionConfiguration;\n      if (Array.isArray(serverSideEncryptionConfiguration) && serverSideEncryptionConfiguration.length === 1) {\n        const serverSideEncryptionRuleProperty = serverSideEncryptionConfiguration[0];\n        const serverSideEncryptionByDefault = serverSideEncryptionRuleProperty.serverSideEncryptionByDefault;\n        if (serverSideEncryptionByDefault && Token.isUnresolved(serverSideEncryptionByDefault.kmsMasterKeyId)) {\n          const kmsIResolvable = Tokenization.reverse(serverSideEncryptionByDefault.kmsMasterKeyId);\n          if (kmsIResolvable instanceof CfnReference) {\n            const cfnElement = kmsIResolvable.target;\n            if (cfnElement instanceof kms.CfnKey) {\n              encryptionKey = kms.Key.fromCfnKey(cfnElement);\n            }\n          }\n        }\n      }\n    }\n\n    return new class extends BucketBase {\n      public readonly bucketArn = cfnBucket.attrArn;\n      public readonly bucketName = cfnBucket.ref;\n      public readonly bucketDomainName = cfnBucket.attrDomainName;\n      public readonly bucketDualStackDomainName = cfnBucket.attrDualStackDomainName;\n      public readonly bucketRegionalDomainName = cfnBucket.attrRegionalDomainName;\n      public readonly bucketWebsiteUrl = cfnBucket.attrWebsiteUrl;\n      public readonly bucketWebsiteDomainName = Fn.select(2, Fn.split('/', cfnBucket.attrWebsiteUrl));\n\n      public readonly encryptionKey = encryptionKey;\n      public readonly isWebsite = cfnBucket.websiteConfiguration !== undefined;\n      public policy = undefined;\n      public replicationRoleArn = undefined;\n      protected autoCreatePolicy = true;\n      public disallowPublicAccess = cfnBucket.publicAccessBlockConfiguration &&\n        (cfnBucket.publicAccessBlockConfiguration as any).blockPublicPolicy;\n\n      constructor() {\n        super(cfnBucket, id);\n\n        this.node.defaultChild = cfnBucket;\n      }\n    }();\n  }\n\n  /**\n   * Thrown an exception if the given bucket name is not valid.\n   *\n   * @param physicalName name of the bucket.\n   * @param allowLegacyBucketNaming allow legacy bucket naming style, default is false.\n   */\n  public static validateBucketName(physicalName: string, allowLegacyBucketNaming: boolean = false): void {\n    const bucketName = physicalName;\n    if (!bucketName || Token.isUnresolved(bucketName)) {\n      // the name is a late-bound value, not a defined string,\n      // so skip validation\n      return;\n    }\n\n    const errors: string[] = [];\n\n    // Rules codified from https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html\n    if (bucketName.length < 3 || bucketName.length > 63) {\n      errors.push('Bucket name must be at least 3 and no more than 63 characters');\n    }\n\n    const illegalCharsetRegEx = allowLegacyBucketNaming ? /[^A-Za-z0-9._-]/ : /[^a-z0-9.-]/;\n    const allowedEdgeCharsetRegEx = allowLegacyBucketNaming ? /[A-Za-z0-9]/ : /[a-z0-9]/;\n\n    const illegalCharMatch = bucketName.match(illegalCharsetRegEx);\n    if (illegalCharMatch) {\n      errors.push(allowLegacyBucketNaming\n        ? 'Bucket name must only contain uppercase or lowercase characters and the symbols, period (.), underscore (_), and dash (-)'\n        : 'Bucket name must only contain lowercase characters and the symbols, period (.) and dash (-)'\n        + ` (offset: ${illegalCharMatch.index})`,\n      );\n    }\n    if (!allowedEdgeCharsetRegEx.test(bucketName.charAt(0))) {\n      errors.push(allowLegacyBucketNaming\n        ? 'Bucket name must start with an uppercase, lowercase character or number'\n        : 'Bucket name must start with a lowercase character or number'\n        + ' (offset: 0)',\n      );\n    }\n    if (!allowedEdgeCharsetRegEx.test(bucketName.charAt(bucketName.length - 1))) {\n      errors.push(allowLegacyBucketNaming\n        ? 'Bucket name must end with an uppercase, lowercase character or number'\n        : 'Bucket name must end with a lowercase character or number'\n        + ` (offset: ${bucketName.length - 1})`,\n      );\n    }\n\n    const consecSymbolMatch = bucketName.match(/\\.-|-\\.|\\.\\./);\n    if (consecSymbolMatch) {\n      errors.push('Bucket name must not have dash next to period, or period next to dash, or consecutive periods'\n        + ` (offset: ${consecSymbolMatch.index})`);\n    }\n    if (/^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$/.test(bucketName)) {\n      errors.push('Bucket name must not resemble an IP address');\n    }\n\n    if (errors.length > 0) {\n      throw new UnscopedValidationError(`Invalid S3 bucket name (value: ${bucketName})${EOL}${errors.join(EOL)}`);\n    }\n  }\n\n  public readonly bucketArn: string;\n  public readonly bucketName: string;\n  public readonly bucketDomainName: string;\n  public readonly bucketWebsiteUrl: string;\n  public readonly bucketWebsiteDomainName: string;\n  public readonly bucketDualStackDomainName: string;\n  public readonly bucketRegionalDomainName: string;\n\n  public readonly encryptionKey?: kms.IKey;\n  public readonly isWebsite?: boolean;\n  public policy?: BucketPolicy;\n\n  public replicationRoleArn?: string;\n  protected autoCreatePolicy = true;\n  public disallowPublicAccess?: boolean;\n  private accessControl?: BucketAccessControl;\n  private readonly lifecycleRules: LifecycleRule[] = [];\n  private readonly transitionDefaultMinimumObjectSize?: TransitionDefaultMinimumObjectSize;\n  private readonly eventBridgeEnabled?: boolean;\n  private readonly metrics: BucketMetrics[] = [];\n  private readonly cors: CorsRule[] = [];\n  private readonly inventories: Inventory[] = [];\n  private readonly _resource: CfnBucket;\n\n  constructor(scope: Construct, id: string, props: BucketProps = {}) {\n    super(scope, id, {\n      physicalName: props.bucketName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.notificationsHandlerRole = props.notificationsHandlerRole;\n    this.notificationsSkipDestinationValidation = props.notificationsSkipDestinationValidation;\n\n    const { bucketEncryption, encryptionKey } = this.parseEncryption(props);\n    this.encryptionKey = encryptionKey;\n\n    Bucket.validateBucketName(this.physicalName);\n\n    let publicAccessBlockConfig: BlockPublicAccessOptions | undefined = props.blockPublicAccess;\n    if (props.blockPublicAccess && FeatureFlags.of(this).isEnabled(cxapi.S3_PUBLIC_ACCESS_BLOCKED_BY_DEFAULT)) {\n      publicAccessBlockConfig = this.setDefaultPublicAccessBlockConfig(props.blockPublicAccess);\n    }\n\n    const websiteConfiguration = this.renderWebsiteConfiguration(props);\n    this.isWebsite = (websiteConfiguration !== undefined);\n\n    const objectLockConfiguration = this.parseObjectLockConfig(props);\n    const replicationConfiguration = this.renderReplicationConfiguration(props);\n    this.replicationRoleArn = replicationConfiguration?.role;\n    this.objectOwnership = props.objectOwnership;\n    this.transitionDefaultMinimumObjectSize = props.transitionDefaultMinimumObjectSize;\n    const resource = new CfnBucket(this, 'Resource', {\n      bucketName: this.physicalName,\n      bucketEncryption,\n      versioningConfiguration: props.versioned ? { status: 'Enabled' } : undefined,\n      lifecycleConfiguration: Lazy.any({ produce: () => this.parseLifecycleConfiguration() }),\n      websiteConfiguration,\n      publicAccessBlockConfiguration: publicAccessBlockConfig,\n      metricsConfigurations: Lazy.any({ produce: () => this.parseMetricConfiguration() }),\n      corsConfiguration: Lazy.any({ produce: () => this.parseCorsConfiguration() }),\n      accessControl: Lazy.string({ produce: () => this.accessControl }),\n      loggingConfiguration: this.parseServerAccessLogs(props),\n      inventoryConfigurations: Lazy.any({ produce: () => this.parseInventoryConfiguration() }),\n      ownershipControls: Lazy.any({ produce: () => this.parseOwnershipControls() }),\n      accelerateConfiguration: props.transferAcceleration ? { accelerationStatus: 'Enabled' } : undefined,\n      intelligentTieringConfigurations: this.parseTieringConfig(props),\n      objectLockEnabled: objectLockConfiguration ? true : props.objectLockEnabled,\n      objectLockConfiguration: objectLockConfiguration,\n      replicationConfiguration,\n    });\n    this._resource = resource;\n\n    resource.applyRemovalPolicy(props.removalPolicy);\n\n    this.eventBridgeEnabled = props.eventBridgeEnabled;\n\n    this.bucketName = this.getResourceNameAttribute(resource.ref);\n    this.bucketArn = this.getResourceArnAttribute(resource.attrArn, {\n      region: '',\n      account: '',\n      service: 's3',\n      resource: this.physicalName,\n    });\n\n    this.bucketDomainName = resource.attrDomainName;\n    this.bucketWebsiteUrl = resource.attrWebsiteUrl;\n    this.bucketWebsiteDomainName = Fn.select(2, Fn.split('/', this.bucketWebsiteUrl));\n    this.bucketDualStackDomainName = resource.attrDualStackDomainName;\n    this.bucketRegionalDomainName = resource.attrRegionalDomainName;\n\n    this.disallowPublicAccess = props.blockPublicAccess && props.blockPublicAccess.blockPublicPolicy;\n    this.accessControl = props.accessControl;\n\n    // Enforce AWS Foundational Security Best Practice\n    if (props.enforceSSL) {\n      this.enforceSSLStatement();\n      this.minimumTLSVersionStatement(props.minimumTLSVersion);\n    } else if (props.minimumTLSVersion) {\n      throw new ValidationError('\\'enforceSSL\\' must be enabled for \\'minimumTLSVersion\\' to be applied', this);\n    }", "language": "typescript"}
{"input": "CDK Stack that creates IAM, Secrets Manager, CloudFormation resources", "output": "class ExampleStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    /// !show\n    const loginSecret = secretsmanager.Secret.fromSecretAttributes(this, 'Secret', {\n      secretArn: 'SomeLogin',\n    });\n\n    new iam.User(this, 'User', {\n      // Get the 'password' field from the secret that looks like\n      // { \"username\": \"XXXX\", \"password\": \"YYYY\" }\n      password: loginSecret.secretValueFromJson('password'),\n    });\n    /// !hide\n  }\n}", "language": "typescript"}
{"input": "Not a real instance type! Indicates that Batch will choose one it determines to be optimal for the workload.", "output": "export class OptimalInstanceType extends ec2.InstanceType {\n  constructor() {\n    // this is not a real instance type! Batch uses an `undefined` value to mean 'optimal',\n    // which tells Batch to select the optimal instance type.\n    super('optimal');\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for EC2, EKS operations", "output": "const tagAllSubnets = (type: string, subnets: ec2.ISubnet[], tag: string) => {\n      for (const subnet of subnets) {\n        // if this is not a concrete subnet, attach a construct warning\n        if (!ec2.Subnet.isVpcSubnet(subnet)) {\n          // message (if token): \"could not auto-tag public/private subnet with tag...\"\n          // message (if not token): \"count not auto-tag public/private subnet xxxxx with tag...\"\n          const subnetID = Token.isUnresolved(subnet.subnetId) || Token.isUnresolved([subnet.subnetId]) ? '' : ` ${subnet.subnetId}`;\n          Annotations.of(this).addWarningV2('@aws-cdk/aws-eks:clusterMustManuallyTagSubnet', `Could not auto-tag ${type} subnet${subnetID} with \"${tag}=1\", please remember to do this manually`);\n          continue;\n        }\n\n        Tags.of(subnet).add(tag, '1');\n      }\n    }", "language": "typescript"}
{"input": "CDK class ApiKey for AWS resource management", "output": "export class ApiKey extends ApiKeyBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.ApiKey';\n\n  /**\n   * Import an ApiKey by its Id\n   */\n  public static fromApiKeyId(scope: Construct, id: string, apiKeyId: string): IApiKey {\n    class Import extends ApiKeyBase {\n      public keyId = apiKeyId;\n      public keyArn = Stack.of(this).formatArn({\n        service: 'apigateway',\n        account: '',\n        resource: '/apikeys',\n        arnFormat: ArnFormat.SLASH_RESOURCE_NAME,\n        resourceName: apiKeyId,\n      });\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly keyId: string;\n  public readonly keyArn: string;\n\n  constructor(scope: Construct, id: string, props: ApiKeyProps = { }) {\n    super(scope, id, {\n      physicalName: props.apiKeyName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnApiKey(this, 'Resource', {\n      customerId: props.customerId,\n      description: props.description,\n      enabled: props.enabled ?? true,\n      generateDistinctId: props.generateDistinctId,\n      name: this.physicalName,\n      stageKeys: this.renderStageKeys(props.resources, props.stages),\n      value: props.value,\n    });\n\n    this.keyId = resource.ref;\n    this.keyArn = Stack.of(this).formatArn({\n      service: 'apigateway',\n      account: '',\n      resource: '/apikeys',\n      arnFormat: ArnFormat.SLASH_RESOURCE_NAME,\n      resourceName: this.keyId,\n    });\n  }\n\n  private renderStageKeys(resources?: IRestApi[], stages?: IStageRef[]): CfnApiKey.StageKeyProperty[] | undefined {\n    if (!resources && !stages) {\n      return undefined;\n    }\n\n    if (resources && stages) {\n      throw new ValidationError('Only one of \"resources\" or \"stages\" should be provided', this);\n    }\n\n    return resources\n      ? resources.map((resource: IRestApi) => {\n        const restApi = resource;\n        if (!restApi.deploymentStage) {\n          throw new ValidationError('Cannot add an ApiKey to a RestApi that does not contain a \"deploymentStage\".\\n'+\n          'Either set the RestApi.deploymentStage or create an ApiKey from a Stage', this);\n        }\n        const restApiId = restApi.restApiId;\n        const stageName = restApi.deploymentStage!.stageName.toString();\n        return { restApiId, stageName };\n      })\n      : stages ? stages.map((stage => {\n        return { restApiId: stage.stageRef.restApiId, stageName: stage.stageRef.stageName };\n      })) : undefined;\n  }\n}", "language": "typescript"}
{"input": "CDK class CfnTest for AWS resource management", "output": "class CfnTest extends CfnResource {\n      public _toCloudFormation() {\n        return new PostResolveToken({\n          xoo: 1234,\n        }, (props, _context) => {\n          validateString(props).assertSuccess();\n        });\n      }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudFormation, Config resources", "output": "export class WafRegionalStack extends cdk.Stack {\n\n  /**\n   * Take in list of rules\n   * Create output for use in WAF config\n   */\n  protected makeRules(listOfRules: listOfRules[] = []) {\n    let rules: wafv2.CfnRuleGroup.RuleProperty[] = [];\n\n    for (const r of listOfRules) {\n      let stateProp: wafv2.CfnWebACL.StatementProperty = {\n        managedRuleGroupStatement: {\n          name: r['name'],\n          vendorName: \"AWS\",\n        }\n      };\n      let overrideAction: wafv2.CfnWebACL.OverrideActionProperty = { none: {} }\n\n      let rule: wafv2.CfnRuleGroup.RuleProperty = {\n        name: r['name'],\n        priority: r['priority'],\n        // @ts-expect-error Property 'overrideAction' does not exist on type 'CfnRuleGroup.RuleProperty'\n        overrideAction: overrideAction,\n        statement: stateProp,\n        visibilityConfig: {\n          sampledRequestsEnabled: true,\n          cloudWatchMetricsEnabled: true,\n          metricName: r['name']\n        },\n      };\n      rules.push(rule);\n    };\n\n    // Allowed country list\n    let ruleGeoMatch: wafv2.CfnWebACL.RuleProperty = {\n      name: 'GeoMatch',\n      priority: 0,\n      action: {\n        block: {} // To disable, change to *count*\n      },\n      statement: {\n        notStatement: {\n          statement: {\n            geoMatchStatement: {\n              // Block connection if source not in the below country list\n              countryCodes: [\n                \"AR\", // Argentina\n                \"BO\", // Bolivia\n                \"BR\", // Brazil\n                \"CL\", // Chile\n                \"CO\", // Colombia\n                \"EC\", // Ecuador\n                \"FK\", // Falkland Islands\n                \"GF\", // French Guiana\n                \"GY\", // Guiana\n                \"GY\", // Guyana\n                \"PY\", // Paraguay\n                \"PE\", // Peru\n                \"SR\", // Suriname\n                \"UY\", // Uruguay\n                \"VE\", // Venezuela\n              ]\n            }\n          }\n        }\n      },\n      visibilityConfig: {\n        sampledRequestsEnabled: true,\n        cloudWatchMetricsEnabled: true,\n        metricName: 'GeoMatch'\n      }\n    }; // GeoMatch\n    rules.push(ruleGeoMatch);\n\n    /**\n     * The rate limit is the maximum number of requests from a\n     * single IP address that are allowed in a five-minute period.\n     * This value is continually evaluated,\n     * and requests will be blocked once this limit is reached.\n     * The IP address is automatically unblocked after it falls below the limit.\n     */\n    let ruleLimitRequests100: wafv2.CfnWebACL.RuleProperty = {\n      name: 'LimitRequests100',\n      priority: 1,\n      action: {\n        block: {} // To disable, change to *count*\n      },\n      statement: {\n        rateBasedStatement: {\n          limit: 100,\n          aggregateKeyType: \"IP\"\n        }\n      },\n      visibilityConfig: {\n        sampledRequestsEnabled: true,\n        cloudWatchMetricsEnabled: true,\n        metricName: 'LimitRequests100'\n      }\n    }; // limit requests to 100\n    rules.push(ruleLimitRequests100);\n\n    return rules;\n  } // function makeRules\n\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    /**\n     * List available Managed Rule Groups using AWS CLI\n     * aws wafv2 list-available-managed-rule-groups --scope REGIONAL\n     */\n    const managedRules: listOfRules[] = [{\n      \"name\": \"AWSManagedRulesCommonRuleSet\",\n      \"priority\": 10,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": []\n    }, {\n      \"name\": \"AWSManagedRulesAmazonIpReputationList\",\n      \"priority\": 20,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": []\n    }, {\n      \"name\": \"AWSManagedRulesKnownBadInputsRuleSet\",\n      \"priority\": 30,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": []\n    }, {\n      \"name\": \"AWSManagedRulesAnonymousIpList\",\n      \"priority\": 40,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": []\n    }, {\n      \"name\": \"AWSManagedRulesLinuxRuleSet\",\n      \"priority\": 50,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": []\n    }, {\n      \"name\": \"AWSManagedRulesUnixRuleSet\",\n      \"priority\": 60,\n      \"overrideAction\": \"none\",\n      \"excludedRules\": [],\n    }];\n\n\n    // WAF - Regional, for use in Load Balancers\n\n    const wafAclRegional = new wafv2.CfnWebACL(this, \"WafRegional\", {\n      defaultAction: { allow: {} },\n      /**\n       * The scope of this Web ACL.\n       * Valid options: CLOUDFRONT, REGIONAL.\n       * For CLOUDFRONT, you must create your WAFv2 resources\n       * in the US East (N. Virginia) Region, us-east-1\n       */\n      scope: \"REGIONAL\",\n      // Defines and enables Amazon CloudWatch metrics and web request sample collection.\n      visibilityConfig: {\n        cloudWatchMetricsEnabled: true,\n        metricName: \"waf-regional\",\n        sampledRequestsEnabled: true\n      },\n      description: \"WAFv2 ACL for Regional\",\n      name: \"waf-regional\",\n      rules: this.makeRules(managedRules),\n    }); // wafv2.CfnWebACL\n\n    cdk.Tags.of(wafAclRegional).add(\"Name\", \"waf-Regional\", { \"priority\": 300 });\n    cdk.Tags.of(wafAclRegional).add(\"Purpose\", \"WAF Regional\", { \"priority\": 300 });\n    cdk.Tags.of(wafAclRegional).add(\"CreatedBy\", \"CloudFormation\", { \"priority\": 300 });\n\n    new cdk.CfnOutput(this, \"wafAclRegionalArn\", {\n      value: wafAclRegional.attrArn,\n      description: \" WAF Regional arn\",\n      exportName: \"WafRegionalStack:WafAclRegionalArn\"\n    });\n  } // constructor\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation resources", "output": "export class LambdaLayerStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const layer = new lambda.LayerVersion(this, 'HelperLayer', {\n      code: lambda.Code.fromAsset('resources/layers/helper'),\n      description: 'Common helper utility',\n      compatibleRuntimes: [lambda.Runtime.NODEJS_LATEST],\n      removalPolicy: cdk.RemovalPolicy.DESTROY\n    });\n\n    const fn = new lambda.Function(this, 'LambdaFunction', {\n        runtime: lambda.Runtime.NODEJS_LATEST,\n        code: lambda.Code.fromAsset('resources/lambda'),\n        handler: 'index.handler',\n        layers: [layer]\n      }\n    );\n  }\n}", "language": "typescript"}
{"input": "The input to send to the event target", "output": "class RuleTargetInput {\n  /**\n   * Pass text to the event target\n   *\n   * May contain strings returned by `EventField.from()` to substitute in parts of the\n   * matched event.\n   *\n   * The Rule Target input value will be a single string: the string you pass\n   * here.  Do not use this method to pass a complex value like a JSON object to\n   * a Rule Target.  Use `RuleTargetInput.fromObject()` instead.\n   */\n  public static fromText(text: string): RuleTargetInput {\n    return new FieldAwareEventInput(text, InputType.Text);\n  }\n\n  /**\n   * Pass text to the event target, splitting on newlines.\n   *\n   * This is only useful when passing to a target that does not\n   * take a single argument.\n   *\n   * May contain strings returned by `EventField.from()` to substitute in parts\n   * of the matched event.\n   */\n  public static fromMultilineText(text: string): RuleTargetInput {\n    return new FieldAwareEventInput(text, InputType.Multiline);\n  }\n\n  /**\n   * Pass a JSON object to the event target\n   *\n   * May contain strings returned by `EventField.from()` to substitute in parts of the\n   * matched event.\n   *\n   * @returns RuleTargetInput\n   */\n  public static fromObject(obj: any): RuleTargetInput {\n    return new FieldAwareEventInput(obj, InputType.Object);\n  }\n\n  /**\n   * Take the event target input from a path in the event JSON\n   */\n  public static fromEventPath(path: string): RuleTargetInput {\n    return new LiteralEventInput({ inputPath: path });\n  }\n\n  protected constructor() {\n  }\n\n  /**\n   * Return the input properties for this input object\n   */\n  public abstract bind(rule: IRuleRef): RuleTargetInputProperties;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, Secrets Manager, CloudFormation resources", "output": "export class S3OnFailureDestinationStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const testLambdaFunction = new TestFunction(this, 'F');\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\n    MIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\n    cmUuiAii9R0=\n    -----END CERTIFICATE-----\n    -----BEGIN CERTIFICATE-----\n    MIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\n    c8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n    -----END CERTIFICATE-----\"\n    `;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\n    zp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n    -----END ENCRYPTED PRIVATE KEY-----`;\n\n    const rootCASecret = new secretsmanager.Secret(this, 'S', {\n      secretObjectValue: {\n        certificate: SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'SC', {\n      secretObjectValue: {\n        certificate: SecretValue.unsafePlainText(dummyCertString),\n        privateKey: SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n    rootCASecret.grantRead(testLambdaFunction);\n    clientCertificatesSecret.grantRead(testLambdaFunction);\n\n    const bootstrapServers = [\n      'my-self-hosted-kafka-broker-1:9092',\n      'my-self-hosted-kafka-broker-2:9092',\n      'my-self-hosted-kafka-broker-3:9092',\n    ];\n    const bucket = new Bucket(this, 'B', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n    const s3ofd = new S3OnFailureDestination(bucket);\n    testLambdaFunction.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'my-test-topic',\n      consumerGroupId: 'myTestConsumerGroup',\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      onFailure: s3ofd,\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class GrantReadWriteAllTablesTest for AWS resource management", "output": "class GrantReadWriteAllTablesTest extends GrantTestBase {\n  tableBucketName = 'grant-read-write-bucket-all-tables';\n  type = TestType.ALL_TABLES;\n  actions = perms.TABLE_BUCKET_READ_WRITE_ACCESS;\n  grantAccess() {\n    this.tableBucket.grantReadWrite(new iam.ServicePrincipal(PRINCIPAL), WILDCARD);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates API Gateway, Step Functions, CloudWatch Logs, CloudFormation resources", "output": "export class StepfunctionExternalDefinitionStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const logGroup = new logs.LogGroup(this, 'MyStateMachineLogGroup', {\n      logGroupName: '/aws/vendedlogs/states/MyStateMachine',\n      retention: logs.RetentionDays.ONE_WEEK, \n    });\n    \n    const workflow = fs.readFileSync('./workflow/stepfunction.json.asl', 'utf8');\n    const stateMachine= new stepfunctions.StateMachine(this, 'MyStateMachine', {\n      stateMachineType: stepfunctions.StateMachineType.EXPRESS,\n      definitionBody: stepfunctions.DefinitionBody.fromString(workflow.toString()),\n      logs: {\n        destination: logGroup,\n        level: stepfunctions.LogLevel.ALL,\n        includeExecutionData: true,\n      },\n    });\n    logGroup.grantWrite(stateMachine.role);\n\n    const api = new apigateway.RestApi(this, \"StepFuncApi\", {\n      restApiName: \"StepFuncApi\",\n      description: \"StepFuncApi\",\n      endpointTypes: [apigateway.EndpointType.REGIONAL]\n    });\n    const resource = api.root.addResource(\"orders\");\n    resource.addMethod(\"GET\", apigateway.StepFunctionsIntegration.startExecution(stateMachine));\n  }\n}", "language": "typescript"}
{"input": "Check that dependencies on @aws-cdk/ packages use point versions (not version ranges) and that they are also defined in `peerDependencies`.", "output": "export class MustDependonCdkByPointVersions extends ValidationRule {\n  public readonly name = 'dependencies/cdk-point-dependencies';\n\n  public validate(pkg: PackageJson): void {\n    // yes, ugly, but we have a bunch of references to other files in the repo.\n    // we use the root package.json to determine what should be the version\n    // across the repo: in local builds, this should be 0.0.0 and in CI builds\n    // this would be the actual version of the repo after it's been aligned\n    // using scripts/align-version.sh\n    const expectedVersion = require(path.join(monoRepoRoot(), 'package.json')).version; // eslint-disable-line @typescript-eslint/no-require-imports\n    const ignore = [\n      '@aws-cdk/aws-service-spec',\n      '@aws-cdk/service-spec-importers',\n      '@aws-cdk/service-spec-types',\n      '@aws-cdk/cloudformation-diff',\n      '@aws-cdk/cx-api',\n      '@aws-cdk/cloud-assembly-schema',\n      '@aws-cdk/region-info',\n      // Private packages\n      ...fs.readdirSync(path.join(monoRepoRoot(), 'tools', '@aws-cdk')).map((name) => `@aws-cdk/${name}`),\n      // Packages in the @aws-cdk namespace that are vended outside of the monorepo\n      '@aws-cdk/asset-kubectl-v20',\n      '@aws-cdk/asset-node-proxy-agent-v6',\n      '@aws-cdk/asset-awscli-v1',\n    ];\n\n    for (const [depName, depVersion] of Object.entries(pkg.dependencies)) {\n      if (!isCdkModuleName(depName) || ignore.includes(depName)) {\n        continue;\n      }\n\n      const peerDep = pkg.peerDependencies[depName];\n      if (!peerDep) {\n        pkg.report({\n          ruleName: this.name,\n          message: `dependency ${depName} must also appear in peerDependencies`,\n          fix: () => pkg.addPeerDependency(depName, expectedVersion),\n        });\n      }\n\n      if (peerDep !== expectedVersion) {\n        pkg.report({\n          ruleName: this.name,\n          message: `peer dependency ${depName} should have the version ${expectedVersion}`,\n          fix: () => pkg.addPeerDependency(depName, expectedVersion),\n        });\n      }\n\n      if (depVersion !== expectedVersion) {\n        pkg.report({\n          ruleName: this.name,\n          message: `dependency ${depName}: dependency version must be ${expectedVersion}`,\n          fix: () => pkg.addDependency(depName, expectedVersion),\n        });\n      }\n    }\n  }\n}\n\nexport class MustIgnoreSNK extends ValidationRule {\n  public readonly name = 'ignore/strong-name-key';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldContain(this.name, pkg, '.npmignore', '*.snk');\n    fileShouldContain(this.name, pkg, '.gitignore', '*.snk');\n  }\n}\n\nexport class MustIgnoreJunitXml extends ValidationRule {\n  public readonly name = 'ignore/junit';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldContain(this.name, pkg, '.npmignore', 'junit.xml');\n    fileShouldContain(this.name, pkg, '.gitignore', 'junit.xml');\n  }\n}\n\nexport class NpmIgnoreForJsiiModules extends ValidationRule {\n  public readonly name = 'ignore/jsii';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    fileShouldContain(this.name, pkg, '.npmignore',\n      '*.ts',\n      '!*.d.ts',\n      '!*.js',\n      '!*.lit.ts', // <- This is part of the module's documentation!\n      'coverage',\n      '.nyc_output',\n      '*.tgz',\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomAppRegistryAttributeGroup for AWS resource management", "output": "class CustomAppRegistryAttributeGroup extends cdk.Stack {\n  public readonly attributeGroup: appreg.AttributeGroup;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    const myAttributeGroup = new appreg.AttributeGroup(this, 'MyFirstAttributeGroup', {\n      attributeGroupName: 'MyFirstAttributeGroupName',\n      description: 'Test attribute group',\n      attributes: {},\n    });\n\n    this.attributeGroup = myAttributeGroup;\n  }\n}", "language": "typescript"}
{"input": "Chat template configuration for prompts.", "output": "class ChatTemplateConfiguration extends PromptTemplateConfiguration {\n  constructor(private readonly props: ChatTemplateConfigurationProps) {\n    super();\n  }\n\n  public _render(): bedrock.CfnPrompt.PromptTemplateConfigurationProperty {\n    return {\n      chat: {\n        inputVariables: this.props.inputVariables?.map((variable: string) => {\n          return { name: variable };\n        }),\n        messages: this.props.messages?.flatMap(m => m._render()),\n        system: this.props.system !== undefined ? [{ text: this.props.system }] : undefined,\n        toolConfiguration: this.props.toolConfiguration\n          ? {\n            toolChoice: this.props.toolConfiguration.toolChoice._render(),\n            tools: this.props.toolConfiguration.tools.map(tool => tool._render()),\n          }\n          : undefined,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class TestFixture for AWS resource management", "output": "class TestFixture {\n  public readonly app: cdk.App;\n  public readonly stack: cdk.Stack;\n  public readonly vpc: ec2.Vpc;\n  public readonly lb: elbv2.ApplicationLoadBalancer;\n  public readonly _listener: elbv2.ApplicationListener | undefined;\n\n  constructor(createListener?: boolean) {\n    this.app = new cdk.App();\n    this.stack = new cdk.Stack(this.app, 'Stack');\n    this.vpc = new ec2.Vpc(this.stack, 'VPC', {\n      maxAzs: 2,\n    });\n    this.lb = new elbv2.ApplicationLoadBalancer(this.stack, 'LB', { vpc: this.vpc });\n\n    createListener = createListener ?? true;\n    if (createListener) {\n      this._listener = this.lb.addListener('Listener', { port: 80, open: false });\n    }\n  }\n\n  public get listener(): elbv2.ApplicationListener {\n    if (this._listener === undefined) { throw new UnscopedValidationError('Did not create a listener'); }\n    return this._listener;\n  }\n}", "language": "typescript"}
{"input": "CDK class DefaultProperties for AWS resource management", "output": "class DefaultProperties extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const publicKey = `-----BEGIN PUBLIC KEY-----\nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAEHBm/D9UFf1z4czcAFuM7w+tstxxzoLVo\nfa1OT0gQjRYsy/YTcrKI5FS7ur3NZIcmiwqerr7dP0wSZjfEMNe82W1zWdkxHJ6Y\n73g9gZDxwGdjowZjEOIvAeH2Of6NeDOo\n-----END PUBLIC KEY-----`;\n    // Generated names are must be valid.\n    new ivs.PlaybackKeyPair(this, `PlaybackKeyPair-_${'a'.repeat(128)}`, {\n      publicKeyMaterial: publicKey,\n    });\n    new ivs.Channel(this, `Channel-_${'a'.repeat(128)}`);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, Cognito, AppSync, CloudFormation resources", "output": "class EventApiCognitoAuthStack extends cdk.Stack {\n  public readonly eventApi: appsync.EventApi;\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const userPool = new cognito.UserPool(this, 'Pool', {\n      userPoolName: 'myPool',\n      selfSignUpEnabled: true,\n      autoVerify: { email: true },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const client = userPool.addClient('lambda-app-client', {\n      preventUserExistenceErrors: true,\n      authFlows: {\n        adminUserPassword: true,\n      },\n    });\n\n    const cognitoProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.USER_POOL,\n      cognitoConfig: {\n        userPool: userPool,\n      },\n    };\n\n    this.eventApi = new appsync.EventApi(this, 'EventApiCognitoAuth', {\n      apiName: 'api-cognito-auth-test',\n      authorizationConfig: {\n        authProviders: [\n          cognitoProvider,\n        ],\n      },\n    });\n\n    this.eventApi.addChannelNamespace('default');\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: `wss://${this.eventApi.realtimeDns}/event/realtime`,\n        EVENT_API_HTTP_URL: `https://${this.eventApi.httpDns}/event`,\n        USER_POOL_ID: userPool.userPoolId,\n        CLIENT_ID: client.userPoolClientId,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets/eventapi-grant-assertion/index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.seconds(15),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'CognitoConfigTestFunction', lambdaConfig);\n    userPool.grant(this.lambdaTestFn,\n      'cognito-idp:SignUp',\n      'cognito-idp:AdminConfirmSignUp',\n      'cognito-idp:AdminDeleteUser',\n      'cognito-idp:AdminInitiateAuth',\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class ImageUriArtifact for AWS resource management", "output": "class ImageUriArtifact extends AgentRuntimeArtifact {\n  constructor(private readonly containerUri: string) {\n    super();\n\n    // Validate ECR container URI format per CloudFormation requirements\n    const ecrPattern = /^\\d{12}\\.dkr\\.ecr\\.([a-z0-9-]+)\\.amazonaws\\.com\\/((?:[a-z0-9]+(?:[._-][a-z0-9]+)*\\/)*[a-z0-9]+(?:[._-][a-z0-9]+)*)([:@]\\S+)$/;\n    if (!Token.isUnresolved(containerUri) && !ecrPattern.test(containerUri)) {\n      throw new ValidationError(\n        `Invalid ECR container URI format: ${containerUri}. Must be an ECR URI: {account}.dkr.ecr.{region}.amazonaws.com/{repository}:{tag}`,\n      );\n    }\n  }\n\n  public bind(_scope: Construct, _runtime: Runtime): void {\n    // No permissions are granted automatically when using a direct URI.\n    // Users must manage ECR pull permissions separately.\n  }\n\n  public _render(): CfnRuntime.AgentRuntimeArtifactProperty {\n    return {\n      containerUri: this.containerUri,\n    } as any;\n  }\n}", "language": "typescript"}
{"input": "CDK class SNSInteg for AWS resource management", "output": "class SNSInteg extends Stack {\n  public readonly publishEncryptedTopicFn: Function;\n\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const key = new Key(this, 'CustomKey', {\n      pendingWindow: Duration.days(7),\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const topic = new Topic(this, 'MyTopic', {\n      topicName: 'fooTopic',\n      displayName: 'fooDisplayName',\n      masterKey: key,\n    });\n\n    const feedbackRole = new Role(this, 'FeedbackRole', {\n      assumedBy: new ServicePrincipal('sns.amazonaws.com'),\n    });\n    const deliveryLoggingPolicy = new ManagedPolicy(this, 'Policy', {\n      document: new PolicyDocument({\n        statements: [new PolicyStatement({\n          actions: [\n            'logs:CreateLogGroup',\n            'logs:CreateLogStream',\n            'logs:PutLogEvents',\n            'logs:PutMetricFilter',\n            'logs:PutRetentionPolicy',\n          ],\n          resources: ['*'],\n        })],\n      }),\n    });\n    deliveryLoggingPolicy.attachToRole(feedbackRole);\n\n    topic.addLoggingConfig({\n      protocol: LoggingProtocol.HTTP,\n      failureFeedbackRole: feedbackRole,\n      successFeedbackRole: feedbackRole,\n      successFeedbackSampleRate: 50,\n    });\n\n    // Topic with signatureVersion\n    new Topic(this, 'MyTopicSignatureVersion', {\n      topicName: 'fooTopicSignatureVersion',\n      displayName: 'fooDisplayNameSignatureVersion',\n      signatureVersion: '2',\n    });\n\n    // Topic with tracingConfig\n    new Topic(this, 'MyTopicTracingConfig', {\n      topicName: 'fooTopicTracingConfig',\n      displayName: 'fooDisplayNameTracingConfig',\n      tracingConfig: TracingConfig.ACTIVE,\n    });\n\n    // Can import topic\n    const topic2 = new Topic(this, 'MyTopic2', {\n      topicName: 'fooTopic2',\n      displayName: 'fooDisplayName2',\n    });\n    const importedTopic2 = Topic.fromTopicArn(this, 'ImportedTopic2', topic2.topicArn);\n\n    const publishRole = new Role(this, 'PublishRole', {\n      assumedBy: new ServicePrincipal('s3.amazonaws.com'),\n    });\n    importedTopic2.grantPublish(publishRole);\n\n    // Can import encrypted topic by attributes\n    const topic3 = new Topic(this, 'MyTopic3', {\n      topicName: 'fooTopic3',\n      displayName: 'fooDisplayName3',\n      masterKey: key,\n    });\n    const importedTopic3 = Topic.fromTopicAttributes(this, 'ImportedTopic3', {\n      topicArn: topic3.topicArn,\n      keyArn: key.keyArn,\n    });\n    importedTopic3.grantPublish(publishRole);\n\n    // Create a function that publishes to an encrypted topic to verify grantPublish\n    this.publishEncryptedTopicFn = new Function(this, 'PublishEncryptedTopic', {\n      functionName: 'publish-encrypted-topic',\n      runtime: Runtime.PYTHON_3_12,\n      code: Code.fromAsset(path.join(__dirname, 'fixtures', 'publish-encrypted-topic')),\n      handler: 'index.lambda_handler',\n      environment: {\n        TOPIC_ARN: topic3.topicArn,\n      },\n    });\n    topic3.grantPublish(this.publishEncryptedTopicFn);\n  }\n}", "language": "typescript"}
{"input": "CDK class TestEvents for AWS resource management", "output": "class TestEvents:\n  def test_event_has_correct_rule(self):\n    template.has_resource_properties('AWS::Events::Rule', {\n      'ScheduleExpression': 'cron(0 18 ? * MON-FRI *)',\n      'State': 'ENABLED',\n      'Targets': Match.any_value(),\n    })", "language": "python"}
{"input": "A class that provides convenient access to special version tokens for LaunchTemplate versions.", "output": "export class LaunchTemplateSpecialVersions {\n  /**\n   * The special value that denotes that users of a Launch Template should\n   * reference the LATEST version of the template.\n   */\n  public static readonly LATEST_VERSION: string = '$Latest';\n\n  /**\n   * The special value that denotes that users of a Launch Template should\n   * reference the DEFAULT version of the template.\n   */\n  public static readonly DEFAULT_VERSION: string = '$Default';\n}", "language": "typescript"}
{"input": "Thumbnail configuration for IVS Recording configuration", "output": "export class ThumbnailConfiguration {\n  /**\n   * Disable the generation of thumbnails for recorded video\n   */\n  public static disable(): ThumbnailConfiguration {\n    return new ThumbnailConfiguration(RecordingMode.DISABLED);\n  }\n\n  /**\n   * Enable the generation of thumbnails for recorded video at a time interval.\n   *\n   * @param resolution The desired resolution of recorded thumbnails for a stream. If you do not specify this property, same resolution as Input stream is used.\n   * @param storage The format in which thumbnails are recorded for a stream. If you do not specify this property, `ThumbnailStorage.SEQUENTIAL` is set.\n   * @param targetInterval The targeted thumbnail-generation interval. If you do not specify this property, `Duration.seconds(60)` is set.\n   */\n  public static interval(resolution?: Resolution, storage?: Storage[], targetInterval?: Duration): ThumbnailConfiguration {\n    return new ThumbnailConfiguration(RecordingMode.INTERVAL, resolution, storage, targetInterval);\n  }\n\n  /**\n   * @param recordingMode Thumbnail recording mode. If you do not specify this property, `ThumbnailRecordingMode.INTERVAL` is set.\n   * @param resolution The desired resolution of recorded thumbnails for a stream. If you do not specify this property, same resolution as Input stream is used.\n   * @param storage The format in which thumbnails are recorded for a stream. If you do not specify this property, `ThumbnailStorage.SEQUENTIAL` is set.\n   * @param targetInterval The targeted thumbnail-generation interval. Must be between 1 and 60 seconds. If you do not specify this property, `Duration.seconds(60)` is set.\n   */\n  private constructor(\n    public readonly recordingMode?: RecordingMode,\n    public readonly resolution?: Resolution,\n    public readonly storage?: Storage[],\n    public readonly targetInterval?: Duration,\n  ) {\n    if (targetInterval === undefined || Token.isUnresolved(targetInterval)) {\n      return;\n    }\n\n    if (targetInterval.toMilliseconds() < Duration.seconds(1).toMilliseconds()) {\n      throw new Error(`\\`targetInterval\\` must be between 1 and 60 seconds, got ${targetInterval.toMilliseconds()} milliseconds.`);\n    }\n\n    if (targetInterval.toSeconds() > 60) {\n      throw new Error(`\\`targetInterval\\` must be between 1 and 60 seconds, got ${targetInterval.toSeconds()} seconds.`);\n    }\n  }\n}", "language": "typescript"}
{"input": "Metadata for a SAML user pool identity provider.", "output": "export class UserPoolIdentityProviderSamlMetadata {\n  /**\n   * Specify SAML metadata via a URL.\n   */\n  public static url(url: string): UserPoolIdentityProviderSamlMetadata {\n    return new UserPoolIdentityProviderSamlMetadata(url, UserPoolIdentityProviderSamlMetadataType.URL);\n  }\n\n  /**\n   * Specify SAML metadata via the contents of a file.\n   */\n  public static file(fileContent: string): UserPoolIdentityProviderSamlMetadata {\n    return new UserPoolIdentityProviderSamlMetadata(fileContent, UserPoolIdentityProviderSamlMetadataType.FILE);\n  }\n\n  /**\n   * Construct the metadata for a SAML identity provider.\n   *\n   * @param metadataContent A URL hosting SAML metadata, or the content of a file containing SAML metadata.\n   * @param metadataType The type of metadata, either a URL or file content.\n   */\n  private constructor(public readonly metadataContent: string, public readonly metadataType: UserPoolIdentityProviderSamlMetadataType) {\n  }\n}", "language": "typescript"}
{"input": "CDK class TestSourceWithDeadLetterTarget for AWS resource management", "output": "export class TestSourceWithDeadLetterTarget extends SourceWithDeadLetterTarget {\n  deadLetterTarget?: IQueue | ITopic;\n  public grantRead = jest.fn();\n\n  constructor(deadLetterTarget: IQueue | ITopic) {\n    super('source-arn', deadLetterTarget);\n    this.deadLetterTarget = deadLetterTarget;\n  }\n\n  grantPush(grantee: Role, deadLetterTarget?: IQueue | ITopic) {\n    if (deadLetterTarget instanceof Queue) {\n      deadLetterTarget.grantSendMessages(grantee);\n    } else if (deadLetterTarget instanceof Topic) {\n      deadLetterTarget.grantPublish(grantee);\n    }\n  }\n\n  bind(_pipe: IPipe): SourceConfig {\n    return {\n      sourceParameters: {},\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class Identity for AWS resource management", "output": "class Identity {\n  /**\n   * Verify an email address\n   *\n   * To complete the verification process look for an email from\n   * no-reply-aws@amazon.com, open it and click the link.\n   */\n  public static email(email: string): Identity {\n    return { value: email };\n  }\n\n  /**\n   * Verify a domain name\n   *\n   * DKIM records will have to be added manually to complete the verification\n   * process\n   */\n  public static domain(domain: string): Identity {\n    return { value: domain };\n  }\n\n  /**\n   * Verify a public hosted zone\n   *\n   * DKIM and MAIL FROM records will be added automatically to the hosted\n   * zone\n   */\n  public static publicHostedZone(hostedZone: IPublicHostedZone): Identity {\n    return {\n      value: hostedZone.zoneName,\n      hostedZone,\n    };\n  }\n\n  /**\n   * The value of the identity\n   */\n  public abstract readonly value: string;\n\n  /**\n   * The hosted zone associated with this identity\n   *\n   * @default - no hosted zone is associated and no records are created\n   */\n  public abstract readonly hostedZone?: IPublicHostedZone;\n}", "language": "typescript"}
{"input": "CDK class FileDefinitionBody for AWS resource management", "output": "export class FileDefinitionBody extends DefinitionBody {\n  constructor(public readonly path: string, private readonly options: s3_assets.AssetOptions = {}) {\n    super();\n  }\n\n  public bind(scope: Construct, _sfnPrincipal: iam.IPrincipal, _sfnProps: StateMachineProps, _graph?: StateGraph): DefinitionConfig {\n    const asset = new s3_assets.Asset(scope, 'DefinitionBody', {\n      path: this.path,\n      ...this.options,\n    });\n    return {\n      definitionS3Location: {\n        bucket: asset.s3BucketName,\n        key: asset.s3ObjectKey,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "A common superclass of all build sources that are backed by Git.", "output": "class GitSource extends Source {\n  private readonly cloneDepth?: number;\n  private readonly branchOrRef?: string;\n  private readonly fetchSubmodules?: boolean;\n\n  protected constructor(props: GitSourceProps) {\n    super(props);\n\n    this.cloneDepth = props.cloneDepth;\n    this.branchOrRef = props.branchOrRef;\n    this.fetchSubmodules = props.fetchSubmodules;\n  }\n\n  public bind(_scope: Construct, _project: IProject): SourceConfig {\n    const superConfig = super.bind(_scope, _project);\n    return {\n      sourceVersion: this.branchOrRef,\n      sourceProperty: {\n        ...superConfig.sourceProperty,\n        gitCloneDepth: this.cloneDepth,\n        gitSubmodulesConfig: this.fetchSubmodules ? {\n          fetchSubmodules: this.fetchSubmodules,\n        } : undefined,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class LavaPlainsOfMustafar for AWS resource management", "output": "class LavaPlainsOfMustafar(Stack):\n\n  def __init__(self, scope:Construct, id:str, **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n    vpc = ec2.Vpc(self, \"LavaPlainsVpc\",\n      cidr                 = \"10.99.0.0/16\",\n      max_azs              = 3,\n      enable_dns_hostnames = True,\n      enable_dns_support   = True,\n      subnet_configuration = [\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public1',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        ),\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public2',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        ),\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public3',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        )\n      ]\n    )\n\n    vpc_subnets = vpc.select_subnets(\n      subnet_type=ec2.SubnetType.PUBLIC,\n      one_per_az =True\n    )\n\n    subnet_ids = []\n    for subnet in vpc_subnets.subnets:\n      subnet_ids.append(subnet.subnet_id)\n\n    vpc_id = vpc.vpc_id\n\n    Oracle(self, \"LavaMiningDb\",\n      db_name=\"LavaMining\",\n      ingress_sources=[ec2.Peer.ipv4(\"10.10.10.10/32\")],\n      vpc_id=vpc_id,\n      subnet_ids=subnet_ids,\n      env={'region': 'us-east-1'},\n      description=\"Lava Mining DB\")", "language": "python"}
{"input": "IAM authorizer configuration", "output": "class IamAuthorizerConfiguration extends RuntimeAuthorizerConfiguration {\n  public _render(): undefined {\n    // For IAM authentication, return undefined to let AWS service use default\n    return undefined;\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedBedrockAgentRuntime for AWS resource management", "output": "class ImportedBedrockAgentRuntime extends RuntimeBase {\n      public readonly agentRuntimeArn = attrs.agentRuntimeArn;\n      public readonly agentRuntimeId = attrs.agentRuntimeId;\n      public readonly agentRuntimeName = attrs.agentRuntimeName;\n      public readonly agentRuntimeVersion = attrs.agentRuntimeVersion;\n      public readonly agentStatus = attrs.agentStatus;\n      public readonly description = attrs.description;\n      public readonly createdAt = attrs.createdAt;\n      public readonly lastUpdatedAt = attrs.lastUpdatedAt;\n\n      public readonly role: iam.IRole;\n      public readonly grantPrincipal: iam.IPrincipal;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n        this.role = iam.Role.fromRoleArn(this, 'Role', attrs.roleArn);\n        this.grantPrincipal = this.role;\n        if (attrs.securityGroups) {\n          this._connections = new ec2.Connections({\n            securityGroups: attrs.securityGroups,\n          });\n        }\n      }\n    }", "language": "typescript"}
{"input": "CDK class HttpStage for AWS resource management", "output": "export class HttpStage extends HttpStageBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigatewayv2.HttpStage';\n\n  /**\n   * Import an existing stage into this CDK app.\n   */\n  public static fromHttpStageAttributes(scope: Construct, id: string, attrs: HttpStageAttributes): IHttpStage {\n    class Import extends HttpStageBase {\n      public readonly isHttpStage = true;\n      protected readonly baseApi = attrs.api;\n      public readonly stageName = attrs.stageName;\n      public readonly api = attrs.api;\n\n      get url(): string {\n        throw new ValidationError('url is not available for imported stages.', scope);\n      }\n\n      get domainUrl(): string {\n        throw new ValidationError('domainUrl is not available for imported stages.', scope);\n      }\n\n      /**\n       * CLF Log format for HTTP API Stage.\n       *\n       * @see https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-logging.html\n       */\n      defaultAccessLogFormat(): AccessLogFormat {\n        return AccessLogFormat.clf();\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly stageName: string;\n  private readonly _api: IHttpApiRef;\n\n  constructor(scope: Construct, id: string, props: HttpStageProps) {\n    super(scope, id, {\n      physicalName: props.stageName ? props.stageName : DEFAULT_STAGE_NAME,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.stageVariables) {\n      Object.entries(props.stageVariables).forEach(([key, value]) => {\n        this.addStageVariable(key, value);\n      });\n    }\n\n    new CfnStage(this, 'Resource', {\n      apiId: props.httpApi.apiRef.apiId,\n      stageName: this.physicalName,\n      accessLogSettings: this._validateAccessLogSettings(props.accessLogSettings),\n      autoDeploy: props.autoDeploy,\n      defaultRouteSettings: props.throttle || props.detailedMetricsEnabled ? {\n        throttlingBurstLimit: props.throttle?.burstLimit,\n        throttlingRateLimit: props.throttle?.rateLimit,\n        detailedMetricsEnabled: props.detailedMetricsEnabled,\n      } : undefined,\n      description: props.description,\n      stageVariables: Lazy.any({ produce: () => this._stageVariables }),\n    });\n\n    this.stageName = this.physicalName;\n    this._api = props.httpApi;\n\n    if (props.domainMapping) {\n      this._addDomainMapping(props.domainMapping);\n    }\n  }\n\n  public get api(): IHttpApi {\n    return toIHttpApi(this._api);\n  }\n\n  protected get baseApi(): IApi {\n    return this.api;\n  }\n\n  /**\n   * The URL to this stage.\n   */\n  public get url(): string {\n    const s = Stack.of(this);\n    const urlPath = this.stageName === DEFAULT_STAGE_NAME ? '' : this.stageName;\n    return `https://${this.api.apiId}.execute-api.${s.region}.${s.urlSuffix}/${urlPath}`;\n  }\n\n  public get domainUrl(): string {\n    if (!this._apiMapping) {\n      throw new ValidationError('domainUrl is not available when no API mapping is associated with the Stage', this);\n    }\n    return this._apiMapping.domainUrl;\n  }\n\n  /**\n   * CLF Log format for HTTP API Stage.\n   *\n   * @see https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-logging.html\n   */\n  defaultAccessLogFormat(): AccessLogFormat {\n    return AccessLogFormat.clf();\n  }\n}", "language": "typescript"}
{"input": "Federated authentication", "output": "class FederatedAuthentication extends ClientVpnUserBasedAuthentication {\n  constructor(private readonly samlProvider: ISAMLProviderRef, private readonly selfServiceSamlProvider?: ISAMLProviderRef) {\n    super();\n  }\n\n  render(): any {\n    return {\n      type: 'federated-authentication',\n      federatedAuthentication: {\n        samlProviderArn: this.samlProvider.samlProviderRef.samlProviderArn,\n        selfServiceSamlProviderArn: this.selfServiceSamlProvider?.samlProviderRef.samlProviderArn,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "Physical ID of the custom resource.", "output": "export class PhysicalResourceId {\n  /**\n   * Extract the physical resource id from the path (dot notation) to the data in the API call response.\n   */\n  public static fromResponse(responsePath: string): PhysicalResourceId {\n    return new PhysicalResourceId(responsePath, undefined);\n  }\n\n  /**\n   * Explicit physical resource id.\n   */\n  public static of(id: string): PhysicalResourceId {\n    return new PhysicalResourceId(undefined, id);\n  }\n\n  /**\n   * @param responsePath Path to a response data element to be used as the physical id.\n   * @param id Literal string to be used as the physical id.\n   */\n  private constructor(public readonly responsePath?: string, public readonly id?: string) { }\n}", "language": "typescript"}
{"input": "The prefix to use for source NAT for a dual-stack network load balancer with UDP listeners.", "output": "export class SourceNatIpv6Prefix {\n  /**\n   * Use an automatically assigned IPv6 prefix\n   */\n  public static autoAssigned(): SourceNatIpv6Prefix {\n    return new SourceNatIpv6Prefix('auto_assigned');\n  }\n\n  /**\n   * Use a custom IPv6 prefix with /80 netmask\n   * @param prefix The IPv6 prefix\n   */\n  public static fromIpv6Prefix(prefix: string): SourceNatIpv6Prefix {\n    if (!prefix.includes('/')) {\n      throw new UnscopedValidationError(`IPv6 prefix must include netmask (e.g. 2001:db8::/80), got ${prefix}`);\n    }\n\n    const [_ipv6, netmask] = prefix.split('/');\n    if (netmask !== '80') {\n      throw new UnscopedValidationError(`IPv6 prefix must have a /80 netmask, got ${netmask}`);\n    }\n\n    return new SourceNatIpv6Prefix(prefix);\n  }\n\n  /**\n   * @param prefix The IPv6 prefix\n   */\n  constructor(public readonly prefix: string) {}\n}", "language": "typescript"}
{"input": "Represents a CloudFormation resource.", "output": "export class CfnResource extends CfnRefElement {\n  /**\n   * Check whether the given object is a CfnResource\n   */\n  public static isCfnResource(this: void, x: any): x is CfnResource {\n    return x !== null && typeof(x) === 'object' && x.cfnResourceType !== undefined;\n  }\n\n  // MAINTAINERS NOTE: this class serves as the base class for the generated L1\n  // (\"CFN\") resources (such as `s3.CfnBucket`). These resources will have a\n  // property for each CloudFormation property of the resource. This means that\n  // if at some point in the future a property is introduced with a name similar\n  // to one of the properties here, it will be \"masked\" by the derived class. To\n  // that end, we prefix all properties in this class with `cfnXxx` with the\n  // hope to avoid those conflicts in the future.\n\n  /**\n   * Options for this resource, such as condition, update policy etc.\n   */\n  public readonly cfnOptions: ICfnResourceOptions = {};\n\n  /**\n   * AWS resource type.\n   */\n  public readonly cfnResourceType: string;\n\n  /**\n   * AWS CloudFormation resource properties.\n   *\n   * This object is returned via cfnProperties\n   * @internal\n   */\n  protected readonly _cfnProperties: any;\n\n  /**\n   * An object to be merged on top of the entire resource definition.\n   */\n  private readonly rawOverrides: any = {};\n\n  /**\n   * Logical IDs of dependencies.\n   *\n   * Is filled during prepare().\n   */\n  private readonly dependsOn = new Set<CfnResource>();\n\n  /**\n   * Creates a resource construct.\n   * @param cfnResourceType The CloudFormation type of this resource (e.g. AWS::DynamoDB::Table)\n   */\n  constructor(scope: Construct, id: string, props: CfnResourceProps) {\n    super(scope, id);\n\n    if (!props.type) {\n      throw new ValidationError('The `type` property is required', this);\n    }\n\n    this.cfnResourceType = props.type;\n    this._cfnProperties = props.properties || {};\n\n    // if aws:cdk:enable-path-metadata is set, embed the current construct's\n    // path in the CloudFormation template, so it will be possible to trace\n    // back to the actual construct path.\n    if (Node.of(this).tryGetContext(cxapi.PATH_METADATA_ENABLE_CONTEXT)) {\n      this.addMetadata(cxapi.PATH_METADATA_KEY, Node.of(this).path);\n    }\n  }\n\n  public get env(): ResourceEnvironment {\n    return {\n      account: this.stack.account,\n      region: this.stack.region,\n    };\n  }\n\n  /**\n   * Sets the deletion policy of the resource based on the removal policy specified.\n   *\n   * The Removal Policy controls what happens to this resource when it stops\n   * being managed by CloudFormation, either because you've removed it from the\n   * CDK application or because you've made a change that requires the resource\n   * to be replaced.\n   *\n   * The resource can be deleted (`RemovalPolicy.DESTROY`), or left in your AWS\n   * account for data recovery and cleanup later (`RemovalPolicy.RETAIN`). In some\n   * cases, a snapshot can be taken of the resource prior to deletion\n   * (`RemovalPolicy.SNAPSHOT`). A list of resources that support this policy\n   * can be found in the following link:\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html#aws-attribute-deletionpolicy-options\n   */\n  public applyRemovalPolicy(policy: RemovalPolicy | undefined, options: RemovalPolicyOptions = {}) {\n    policy = policy || options.default || RemovalPolicy.RETAIN;\n\n    let deletionPolicy;\n    let updateReplacePolicy;\n\n    switch (policy) {\n      case RemovalPolicy.DESTROY:\n        deletionPolicy = CfnDeletionPolicy.DELETE;\n        updateReplacePolicy = CfnDeletionPolicy.DELETE;\n        break;\n\n      case RemovalPolicy.RETAIN:\n        deletionPolicy = CfnDeletionPolicy.RETAIN;\n        updateReplacePolicy = CfnDeletionPolicy.RETAIN;\n        break;\n\n      case RemovalPolicy.RETAIN_ON_UPDATE_OR_DELETE:\n        deletionPolicy = CfnDeletionPolicy.RETAIN_EXCEPT_ON_CREATE;\n        updateReplacePolicy = CfnDeletionPolicy.RETAIN;\n        break;\n\n      case RemovalPolicy.SNAPSHOT:\n        // https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html\n        const snapshottableResourceTypes = [\n          'AWS::DocDB::DBCluster',\n          'AWS::EC2::Volume',\n          'AWS::ElastiCache::CacheCluster',\n          'AWS::ElastiCache::ReplicationGroup',\n          'AWS::Neptune::DBCluster',\n          'AWS::RDS::DBCluster',\n          'AWS::RDS::DBInstance',\n          'AWS::Redshift::Cluster',\n        ];\n\n        // error if flag is set, warn if flag is not\n        const problematicSnapshotPolicy = !snapshottableResourceTypes.includes(this.cfnResourceType);\n        if (problematicSnapshotPolicy) {\n          if (FeatureFlags.of(this).isEnabled(cxapi.VALIDATE_SNAPSHOT_REMOVAL_POLICY) ) {\n            throw new ValidationError(`${this.cfnResourceType} does not support snapshot removal policy`, this);\n          } else {\n            Annotations.of(this).addWarningV2(`@aws-cdk/core:${this.cfnResourceType}SnapshotRemovalPolicyIgnored`, `${this.cfnResourceType} does not support snapshot removal policy. This policy will be ignored.`);\n          }\n        }\n\n        deletionPolicy = CfnDeletionPolicy.SNAPSHOT;\n        updateReplacePolicy = CfnDeletionPolicy.SNAPSHOT;\n        break;\n\n      default:\n        throw new ValidationError(`Invalid removal policy: ${policy}`, this);\n    }\n\n    this.cfnOptions.deletionPolicy = deletionPolicy;\n    if (options.applyToUpdateReplacePolicy !== false) {\n      this.cfnOptions.updateReplacePolicy = updateReplacePolicy;\n    }\n  }\n\n  /**\n   * Returns a token for an runtime attribute of this resource.\n   * Ideally, use generated attribute accessors (e.g. `resource.arn`), but this can be used for future compatibility\n   * in case there is no generated attribute.\n   * @param attributeName The name of the attribute.\n   */\n  public getAtt(attributeName: string, typeHint?: ResolutionTypeHint): Reference {\n    return CfnReference.for(this, attributeName, undefined, typeHint);\n  }\n\n  /**\n   * Adds an override to the synthesized CloudFormation resource. To add a\n   * property override, either use `addPropertyOverride` or prefix `path` with\n   * \"Properties.\" (i.e. `Properties.TopicName`).\n   *\n   * If the override is nested, separate each nested level using a dot (.) in the path parameter.\n   * If there is an array as part of the nesting, specify the index in the path.\n   *\n   * To include a literal `.` in the property name, prefix with a `\\`. In most\n   * programming languages you will need to write this as `\"\\\\.\"` because the\n   * `\\` itself will need to be escaped.\n   *\n   * For example,\n   * ```typescript\n   * cfnResource.addOverride('Properties.GlobalSecondaryIndexes.0.Projection.NonKeyAttributes', ['myattribute']);\n   * cfnResource.addOverride('Properties.GlobalSecondaryIndexes.1.ProjectionType', 'INCLUDE');\n   * ```\n   * would add the overrides\n   * ```json\n   * \"Properties\": {\n   *   \"GlobalSecondaryIndexes\": [\n   *     {\n   *       \"Projection\": {\n   *         \"NonKeyAttributes\": [ \"myattribute\" ]\n   *         ...\n   *       }\n   *       ...\n   *     },\n   *     {\n   *       \"ProjectionType\": \"INCLUDE\"\n   *       ...\n   *     },\n   *   ]\n   *   ...\n   * }\n   * ```\n   *\n   * The `value` argument to `addOverride` will not be processed or translated\n   * in any way. Pass raw JSON values in here with the correct capitalization\n   * for CloudFormation. If you pass CDK classes or structs, they will be\n   * rendered with lowercased key names, and CloudFormation will reject the\n   * template.\n   *\n   * @param path - The path of the property, you can use dot notation to\n   *        override values in complex types. Any intermediate keys\n   *        will be created as needed.\n   * @param value - The value. Could be primitive or complex.\n   */\n  public addOverride(path: string, value: any) {\n    const parts = splitOnPeriods(path);\n    let curr: any = this.rawOverrides;\n\n    while (parts.length > 1) {\n      const key = parts.shift()!;\n\n      // if we can't recurse further or the previous value is not an\n      // object overwrite it with an object.\n      const isObject = curr[key] != null && typeof(curr[key]) === 'object' && !Array.isArray(curr[key]);\n      if (!isObject) {\n        curr[key] = {};\n      }\n\n      curr = curr[key];\n    }\n\n    const lastKey = parts.shift()!;\n    curr[lastKey] = value;\n  }", "language": "typescript"}
{"input": "CDK class StandaloneMatchmakingConfiguration for AWS resource management", "output": "export class StandaloneMatchmakingConfiguration extends MatchmakingConfigurationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-gamelift-alpha.StandaloneMatchmakingConfiguration';\n\n  /**\n   * Import an existing matchmaking configuration from its name.\n   */\n  static fromStandaloneMatchmakingConfigurationName(scope: Construct, id: string, matchmakingConfigurationName: string): IMatchmakingConfiguration {\n    return this.fromMatchmakingConfigurationAttributes(scope, id, { matchmakingConfigurationName });\n  }\n\n  /**\n   * Import an existing matchmaking configuration from its ARN.\n   */\n  static fromStandaloneMatchmakingConfigurationArn(scope: Construct, id: string, matchmakingConfigurationArn: string): IMatchmakingConfiguration {\n    return this.fromMatchmakingConfigurationAttributes(scope, id, { matchmakingConfigurationArn });\n  }\n\n  /**\n   * The Identifier of the matchmaking configuration.\n   */\n  public readonly matchmakingConfigurationName: string;\n\n  /**\n   * The ARN of the matchmaking configuration.\n   */\n  public readonly matchmakingConfigurationArn: string;\n\n  /**\n   * The notification target for matchmaking events\n   */\n  public readonly notificationTarget?: sns.ITopic;\n\n  constructor(scope: Construct, id: string, props: StandaloneMatchmakingConfigurationProps) {\n    super(scope, id, {\n      physicalName: props.matchmakingConfigurationName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.matchmakingConfigurationName && !cdk.Token.isUnresolved(props.matchmakingConfigurationName)) {\n      if (props.matchmakingConfigurationName.length > 128) {\n        throw new Error(`Matchmaking configuration name can not be longer than 128 characters but has ${props.matchmakingConfigurationName.length} characters.`);\n      }\n\n      if (!/^[a-zA-Z0-9-\\.]+$/.test(props.matchmakingConfigurationName)) {\n        throw new Error(`Matchmaking configuration name ${props.matchmakingConfigurationName} can contain only letters, numbers, hyphens, back slash or dot with no spaces.`);\n      }\n    }\n\n    if (props.description && !cdk.Token.isUnresolved(props.description)) {\n      if (props.description.length > 1024) {\n        throw new Error(`Matchmaking configuration description can not be longer than 1024 characters but has ${props.description.length} characters.`);\n      }\n    }\n\n    if (props.customEventData && props.customEventData.length > 256) {\n      throw new Error(`Matchmaking configuration custom event data can not be longer than 256 characters but has ${props.customEventData.length} characters.`);\n    }\n\n    if (props.acceptanceTimeout && props.acceptanceTimeout.toSeconds() > 600) {\n      throw new Error(`Matchmaking configuration acceptance timeout can not exceed 600 seconds, actual ${props.acceptanceTimeout.toSeconds()} seconds.`);\n    }\n\n    if (props.requestTimeout && props.requestTimeout.toSeconds() > 43200) {\n      throw new Error(`Matchmaking configuration request timeout can not exceed 43200 seconds, actual ${props.requestTimeout.toSeconds()} seconds.`);\n    }\n\n    // Notification target\n    this.notificationTarget = props.notificationTarget;\n    if (!this.notificationTarget) {\n      this.notificationTarget = new sns.Topic(this, 'Topic', {});\n    }\n    // Be sure to add the right TopicPolicy to enable gamelift publish action to given topic\n    const topicPolicy = new sns.TopicPolicy(this, 'TopicPolicy', {\n      topics: [this.notificationTarget],\n    });\n    topicPolicy.document.addStatements(new iam.PolicyStatement({\n      actions: ['sns:Publish'],\n      principals: [new iam.ServicePrincipal('gamelift.amazonaws.com')],\n      resources: [this.notificationTarget.topicArn],\n    }));\n\n    const resource = new gamelift.CfnMatchmakingConfiguration(this, 'Resource', {\n      name: this.physicalName,\n      acceptanceRequired: Boolean(props.requireAcceptance),\n      acceptanceTimeoutSeconds: props.acceptanceTimeout && props.acceptanceTimeout.toSeconds(),\n      customEventData: props.customEventData,\n      description: props.description,\n      flexMatchMode: 'STANDALONE',\n      notificationTarget: this.notificationTarget.topicArn,\n      requestTimeoutSeconds: props.requestTimeout && props.requestTimeout.toSeconds() || cdk.Duration.seconds(300).toSeconds(),\n      ruleSetName: props.ruleSet.matchmakingRuleSetName,\n    });\n\n    this.matchmakingConfigurationName = this.getResourceNameAttribute(resource.ref);\n    this.matchmakingConfigurationArn = cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'matchmakingconfiguration',\n      resourceName: this.matchmakingConfigurationName,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3File for AWS resource management", "output": "export class S3File extends Construct {\n  public readonly objectKey: string;\n  public readonly url: string;\n  public readonly etag: string;\n\n  constructor(scope: Construct, id: string, props: S3FileProps) {\n    super(scope, id);\n\n    const resource = new CustomResource(this, 'Resource', {\n      serviceToken: S3FileProvider.getOrCreate(this),\n      resourceType: 'Custom::S3File',\n      properties: {\n        [api.PROP_BUCKET_NAME]: props.bucket.bucketName,\n        [api.PROP_CONTENTS]: props.contents,\n        [api.PROP_OBJECT_KEY]: props.objectKey,\n        [api.PROP_PUBLIC]: props.public,\n      },\n    });\n\n    this.objectKey = resource.getAttString(api.ATTR_OBJECT_KEY);\n    this.url = resource.getAttString(api.ATTR_URL);\n    this.etag = resource.getAttString(api.ATTR_ETAG);\n  }\n}", "language": "typescript"}
{"input": "CDK class ProdStage for AWS resource management", "output": "class ProdStage extends Stage {\n  constructor(scope: Construct, id: string, props?: StageProps) {\n    super(scope, id, props);\n    new ProdStack(this, 'ProdStack', props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ContainerRecipe for AWS resource management", "output": "export class ContainerRecipe extends ContainerRecipeBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.ContainerRecipe';\n\n  /**\n   * Import an existing container recipe given its ARN.\n   */\n  public static fromContainerRecipeArn(scope: Construct, id: string, containerRecipeArn: string): IContainerRecipe {\n    return this.fromContainerRecipeAttributes(scope, id, { containerRecipeArn });\n  }\n\n  /**\n   * Import the latest version of an existing container recipe given its name. The provided name must be normalized by\n   * converting all alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromContainerRecipeName(scope: Construct, id: string, containerRecipeName: string): IContainerRecipe {\n    return this.fromContainerRecipeAttributes(scope, id, { containerRecipeName });\n  }\n\n  /**\n   * Import an existing container recipe by providing its attributes. If the container recipe name is provided as an\n   * attribute, it must be normalized by converting all alphabetical characters to lowercase, and replacing all spaces\n   * and underscores with hyphens.\n   */\n  public static fromContainerRecipeAttributes(\n    scope: Construct,\n    id: string,\n    attrs: ContainerRecipeAttributes,\n  ): IContainerRecipe {\n    if (!attrs.containerRecipeArn && !attrs.containerRecipeName) {\n      throw new cdk.ValidationError(\n        'either either containerRecipeArn or containerRecipeName must be provided to import a container recipe',\n        scope,\n      );\n    }\n\n    const containerRecipeArn =\n      attrs.containerRecipeArn ??\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'container-recipe',\n        resourceName: `${attrs.containerRecipeName}/${attrs.containerRecipeVersion ?? LATEST_VERSION}`,\n      });\n\n    const [containerRecipeName, containerRecipeVersion] = (() => {\n      if (attrs.containerRecipeName) {\n        return [attrs.containerRecipeName, attrs.containerRecipeVersion ?? LATEST_VERSION];\n      }\n\n      const containerRecipeNameVersion = cdk.Stack.of(scope).splitArn(\n        containerRecipeArn,\n        cdk.ArnFormat.SLASH_RESOURCE_NAME,\n      ).resourceName!;\n\n      const containerRecipeNameVersionSplit = cdk.Fn.split('/', containerRecipeNameVersion);\n      return [cdk.Fn.select(0, containerRecipeNameVersionSplit), cdk.Fn.select(1, containerRecipeNameVersionSplit)];\n    })();\n\n    class Import extends ContainerRecipeBase {\n      public readonly containerRecipeArn = containerRecipeArn;\n      public readonly containerRecipeName = containerRecipeName;\n      public readonly containerRecipeVersion = containerRecipeVersion;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Return whether the given object is a ContainerRecipe.\n   */\n  public static isContainerRecipe(x: any): x is ContainerRecipe {\n    return x !== null && typeof x === 'object' && CONTAINER_RECIPE_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the container recipe\n   */\n  public readonly containerRecipeArn: string;\n\n  /**\n   * The name of the container recipe\n   */\n  public readonly containerRecipeName: string;\n\n  /**\n   * The version of the container recipe\n   */\n  public readonly containerRecipeVersion: string;\n\n  private readonly instanceBlockDevices: ec2.BlockDevice[] = [];\n\n  public constructor(scope: Construct, id: string, props: ContainerRecipeProps) {\n    super(scope, id, {\n      physicalName:\n        props.containerRecipeName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, CONTAINER_RECIPE_SYMBOL, { value: true });\n\n    this.validateContainerRecipeName();\n\n    this.addInstanceBlockDevice(...(props.instanceBlockDevices ?? []));\n\n    const components: CfnContainerRecipe.ComponentConfigurationProperty[] | undefined = props.components?.map(\n      (component) => ({\n        componentArn: component.component.componentArn,\n        ...(component.parameters && {\n          parameters: Object.entries(component.parameters).map(\n            ([name, param]): CfnContainerRecipe.ComponentParameterProperty => ({\n              name,\n              value: param.value,\n            }),\n          ),\n        }),\n      }),\n    );\n\n    const dockerfile =\n      props.dockerfile ??\n      DockerfileData.fromInline(\n        'FROM {{{ imagebuilder:parentImage }}}\\n{{{ imagebuilder:environments }}}\\n{{{ imagebuilder:components }}}',\n      );\n\n    const containerRecipeVersion = props.containerRecipeVersion ?? DEFAULT_RECIPE_VERSION;\n    const containerRecipe = new CfnContainerRecipe(this, 'Resource', {\n      name: this.physicalName,\n      version: containerRecipeVersion,\n      description: props.description,\n      parentImage: props.baseImage.image,\n      containerType: ContainerType.DOCKER,\n      targetRepository: {\n        repositoryName: props.targetRepository.repositoryName,\n        service: props.targetRepository.service,\n      },\n      platformOverride: props.osVersion?.platform,\n      imageOsVersionOverride: props.osVersion?.osVersion,\n      kmsKeyId: props.kmsKey?.keyArn,\n      instanceConfiguration: cdk.Lazy.any({ produce: () => this.buildInstanceConfiguration(props) }),\n      workingDirectory: props.workingDirectory,\n      tags: props.tags,\n      ...dockerfile.render(),\n      ...(components?.length && { components }),\n    });\n\n    this.containerRecipeName = this.getResourceNameAttribute(containerRecipe.attrName);\n    this.containerRecipeArn = this.getResourceArnAttribute(containerRecipe.attrArn, {\n      service: 'imagebuilder',\n      resource: 'container-recipe',\n      resourceName: `${this.physicalName}/${containerRecipeVersion}`,\n    });\n    this.containerRecipeVersion = containerRecipe.getAtt('Version').toString();\n  }\n\n  /**\n   * Adds block devices to attach to the instance used for building, testing, and distributing the container image.\n   *\n   * @param instanceBlockDevices - The list of block devices to attach\n   */\n  @MethodMetadata()\n  public addInstanceBlockDevice(...instanceBlockDevices: ec2.BlockDevice[]): void {\n    this.instanceBlockDevices.push(...instanceBlockDevices);\n  }\n\n  /**\n   * Renders the block devices provided as input to the construct, into the block device mapping structure that\n   * CfnContainerRecipe expects to receive.\n   *\n   * This is rendered at synthesis time, as users can add additional block devices with `addInstanceBlockDevice`, after\n   * the construct has been instantiated.\n   *\n   * @private\n   */\n  private renderBlockDevices(): CfnContainerRecipe.InstanceBlockDeviceMappingProperty[] | undefined {\n    const blockDevices = this.instanceBlockDevices.map(\n      (blockDevice): CfnContainerRecipe.InstanceBlockDeviceMappingProperty => {\n        const ebsDevice = blockDevice.volume.ebsDevice;\n        const ebs: CfnContainerRecipe.EbsInstanceBlockDeviceSpecificationProperty = {\n          ...(ebsDevice?.deleteOnTermination !== undefined && { deleteOnTermination: ebsDevice.deleteOnTermination }),\n          ...(ebsDevice?.encrypted !== undefined && { encrypted: ebsDevice.encrypted }),\n          ...(ebsDevice?.iops !== undefined && { iops: ebsDevice.iops }),\n          ...(ebsDevice?.kmsKey !== undefined && { kmsKeyId: ebsDevice.kmsKey.keyArn }),\n          ...(ebsDevice?.snapshotId !== undefined && { snapshotId: ebsDevice.snapshotId }),\n          ...(ebsDevice?.throughput !== undefined && { throughput: ebsDevice.throughput }),\n          ...(ebsDevice?.volumeSize !== undefined && { volumeSize: ebsDevice.volumeSize }),\n          ...(ebsDevice?.volumeType !== undefined && { volumeType: ebsDevice.volumeType }),\n        };\n\n        const mappingEnabled = blockDevice.mappingEnabled ?? true;\n        return {\n          deviceName: blockDevice.deviceName,\n          virtualName: blockDevice.volume.virtualName,\n          ...(!mappingEnabled && { noDevice: '' }),\n          ...(Object.keys(ebs).length && { ebs }),\n        };\n      },\n    );\n\n    return blockDevices.length ? blockDevices : undefined;\n  }\n\n  /**\n   * Generates the instance configuration property into the `InstanceConfiguration` type in the  CloudFormation L1\n   * definition.\n   *\n   * @param props The props passed as input to the construct\n   * @private\n   */\n  private buildInstanceConfiguration(\n    props: ContainerRecipeProps,\n  ): CfnContainerRecipe.InstanceConfigurationProperty | undefined {\n    const blockDevices = this.renderBlockDevices();\n\n    const instanceConfiguration: CfnContainerRecipe.InstanceConfigurationProperty = {\n      ...(blockDevices?.length && { blockDeviceMappings: blockDevices }),\n      ...(props.instanceImage !== undefined && { image: props.instanceImage.image }),\n    };\n\n    return Object.keys(instanceConfiguration).length ? instanceConfiguration : undefined;\n  }\n\n  private validateContainerRecipeName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError(\n        `the containerRecipeName cannot be longer than 128 characters, got: '${this.physicalName}'`,\n        this,\n      );\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError(`the containerRecipeName cannot contain spaces, got: '${this.physicalName}'`, this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError(\n        `the containerRecipeName cannot contain underscores, got: '${this.physicalName}'`,\n        this,\n      );\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError(`the containerRecipeName must be lowercase, got: '${this.physicalName}'`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class Repository for AWS resource management", "output": "export class Repository extends RepositoryBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codecommit.Repository';\n\n  /**\n   * Imports a codecommit repository.\n   * @param repositoryArn (e.g. `arn:aws:codecommit:us-east-1:123456789012:MyDemoRepo`)\n   */\n  public static fromRepositoryArn(scope: Construct, id: string, repositoryArn: string): IRepository {\n    const stack = Stack.of(scope);\n    const arn = stack.splitArn(repositoryArn, ArnFormat.NO_RESOURCE_NAME);\n    const repositoryName = arn.resource;\n    const region = arn.region;\n\n    class Import extends RepositoryBase {\n      public readonly repositoryArn = repositoryArn;\n      public readonly repositoryName = repositoryName;\n      public readonly repositoryCloneUrlHttp = makeCloneUrl(stack, repositoryName, 'https', region);\n      public readonly repositoryCloneUrlSsh = makeCloneUrl(stack, repositoryName, 'ssh', region);\n      public readonly repositoryCloneUrlGrc = makeCloneUrl(stack, repositoryName, 'grc', region);\n    }\n\n    return new Import(scope, id, {\n      account: arn.account,\n      region,\n    });\n  }\n\n  public static fromRepositoryName(scope: Construct, id: string, repositoryName: string): IRepository {\n    const stack = Stack.of(scope);\n\n    class Import extends RepositoryBase {\n      public repositoryName = repositoryName;\n      public repositoryArn = Stack.of(scope).formatArn({\n        service: 'codecommit',\n        resource: repositoryName,\n      });\n      public readonly repositoryCloneUrlHttp = makeCloneUrl(stack, repositoryName, 'https');\n      public readonly repositoryCloneUrlSsh = makeCloneUrl(stack, repositoryName, 'ssh');\n      public readonly repositoryCloneUrlGrc = makeCloneUrl(stack, repositoryName, 'grc');\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly repositoryArn: string;\n  public readonly repositoryName: string;\n  public readonly repositoryCloneUrlHttp: string;\n  public readonly repositoryCloneUrlSsh: string;\n  public readonly repositoryCloneUrlGrc: string;\n  private readonly triggers = new Array<CfnRepository.RepositoryTriggerProperty>();\n\n  constructor(scope: Construct, id: string, props: RepositoryProps) {\n    super(scope, id, {\n      physicalName: props.repositoryName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const repository = new CfnRepository(this, 'Resource', {\n      repositoryName: props.repositoryName,\n      repositoryDescription: props.description,\n      triggers: Lazy.any({ produce: () => this.triggers }, { omitEmptyArray: true }),\n      code: (props.code?.bind(this))?.code,\n      kmsKeyId: props.kmsKey?.keyRef.keyArn,\n    });\n\n    this.repositoryName = this.getResourceNameAttribute(repository.attrName);\n    this.repositoryArn = this.getResourceArnAttribute(repository.attrArn, {\n      service: 'codecommit',\n      resource: this.physicalName,\n    });\n    this.repositoryCloneUrlHttp = repository.attrCloneUrlHttp;\n    this.repositoryCloneUrlSsh = repository.attrCloneUrlSsh;\n    this.repositoryCloneUrlGrc = makeCloneUrl(Stack.of(this), this.repositoryName, 'grc');\n  }\n\n  /**\n   * Create a trigger to notify another service to run actions on repository events.\n   * @param arn   Arn of the resource that repository events will notify\n   * @param options Trigger options to run actions\n   */\n  @MethodMetadata()\n  public notify(arn: string, options?: RepositoryTriggerOptions): Repository {\n    let evt = options && options.events;\n    if (evt && evt.length > 1 && evt.indexOf(RepositoryEventTrigger.ALL) > -1) {\n      evt = [RepositoryEventTrigger.ALL];\n    }\n\n    const customData = options && options.customData;\n    const branches = options && options.branches;\n\n    let name = options && options.name;\n    if (!name) {\n      name = this.node.path + '/' + arn;\n    }\n\n    if (this.triggers.find(prop => prop.name === name)) {\n      throw new ValidationError(`Unable to set repository trigger named ${name} because trigger names must be unique`, this);\n    }\n\n    this.triggers.push({\n      destinationArn: arn,\n      name,\n      customData,\n      branches,\n      events: evt || [RepositoryEventTrigger.ALL],\n    });\n    return this;\n  }\n}", "language": "typescript"}
{"input": "CDK class Resource for AWS resource management", "output": "export class Resource extends ResourceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.Resource';\n\n  /**\n   * Import an existing resource\n   */\n  public static fromResourceAttributes(scope: Construct, id: string, attrs: ResourceAttributes): IResource {\n    class Import extends ResourceBase {\n      public readonly api = attrs.restApi;\n      public readonly resourceId = attrs.resourceId;\n      public readonly path = attrs.path;\n      public readonly defaultIntegration?: Integration = undefined;\n      public readonly defaultMethodOptions?: MethodOptions = undefined;\n      public readonly defaultCorsPreflightOptions?: CorsOptions = undefined;\n\n      public get parentResource(): IResource {\n        throw new ValidationError('parentResource is not configured for imported resource.', scope);\n      }\n\n      public get restApi(): RestApi {\n        throw new ValidationError('restApi is not configured for imported resource.', scope);\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly parentResource?: IResource;\n  public readonly api: IRestApi;\n  public readonly resourceId: string;\n  public readonly path: string;\n\n  public readonly defaultIntegration?: Integration;\n  public readonly defaultMethodOptions?: MethodOptions;\n  public readonly defaultCorsPreflightOptions?: CorsOptions;\n\n  constructor(scope: Construct, id: string, props: ResourceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    validateResourcePathPart(props.pathPart, scope);\n\n    this.parentResource = props.parent;\n\n    if (props.parent instanceof ResourceBase) {\n      props.parent._trackChild(props.pathPart, this);\n    }\n\n    const resourceProps: CfnResourceProps = {\n      restApiId: props.parent.api.restApiId,\n      parentId: props.parent.resourceId,\n      pathPart: props.pathPart,\n    };\n    const resource = new CfnResource(this, 'Resource', resourceProps);\n\n    this.resourceId = resource.ref;\n    this.api = props.parent.api;\n\n    // render resource path (special case for root)\n    this.path = props.parent.path;\n    if (!this.path.endsWith('/')) { this.path += '/'; }\n    this.path += props.pathPart;\n\n    const deployment = props.parent.api.latestDeployment;\n    if (deployment) {\n      deployment.node.addDependency(resource);\n      deployment.addToLogicalId({ resource: resourceProps });\n    }\n\n    // setup defaults based on properties and inherit from parent. method defaults\n    // are inherited per property, so children can override piecemeal.\n    this.defaultIntegration = props.defaultIntegration || props.parent.defaultIntegration;\n    this.defaultMethodOptions = {\n      ...props.parent.defaultMethodOptions,\n      ...props.defaultMethodOptions,\n    };\n    this.defaultCorsPreflightOptions = props.defaultCorsPreflightOptions || props.parent.defaultCorsPreflightOptions;\n\n    if (this.defaultCorsPreflightOptions) {\n      this.addCorsPreflight(this.defaultCorsPreflightOptions);\n    }\n  }\n\n  /**\n   * The RestApi associated with this Resource\n   * @deprecated - Throws an error if this Resource is not associated with an instance of `RestApi`. Use `api` instead.\n   */\n  public get restApi(): RestApi {\n    if (!this.parentResource) {\n      throw new ValidationError('parentResource was unexpectedly not defined', this);\n    }\n    return this.parentResource.restApi;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, CodePipeline resources", "output": "export class PipelineCrossRegionStack extends cdk.NestedStack {\n  constructor(scope: Construct, id: string, props?: cdk.NestedStackProps) {\n    super(scope, id, props);\n\n    const machine = cdk.Arn.format({\n      service: 'states',\n      resource: 'stateMachine',\n      account: cdk.Token.asString('123456789012'),\n      resourceName: 'MyStateMachine',\n      region: 'us-west-2',\n    }, this);\n    const stateMachine = sfn.StateMachine.fromStateMachineArn(this, 'StateMachine', machine);\n\n    const role = new Role(this, 'Role', {\n      roleName: 'MyPipelineRoleName',\n      assumedBy: new ServicePrincipal('codepipeline.amazonaws.com'),\n    });\n    new Pipeline(this, 'Pipeline', {\n      crossAccountKeys: true,\n      role,\n      stages: [\n        {\n          stageName: 'Source',\n          actions: [\n            new GitHubSourceAction({\n              actionName: 'Github',\n              owner: 'aws',\n              repo: 'aws-cdk',\n              branch: 'master',\n              oauthToken: SecretValue.unsafePlainText('test'),\n              output: new Artifact('Pipeline'),\n            }),\n          ],\n        },\n        {\n          stageName: 'Test',\n          actions: [\n            new StepFunctionInvokeAction({\n              actionName: 'Test',\n              stateMachine: stateMachine,\n              stateMachineInput: StateMachineInput.literal({}),\n            }),\n          ],\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "The ``Fn::GetAtt`` intrinsic function returns the value of an attribute from a resource in the template.", "output": "class FnGetAtt extends FnBase {\n  /**\n   * Creates a ``Fn::GetAtt`` function.\n   * @param logicalNameOfResource The logical name (also called logical ID) of the resource that contains the attribute that you want.\n   * @param attributeName The name of the resource-specific attribute whose value you want. See the resource's reference page for details about the attributes available for that resource type.\n   */\n  constructor(logicalNameOfResource: string, attributeName: string) {\n    super('Fn::GetAtt', [logicalNameOfResource, attributeName]);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::GetAZs`` returns an array that lists Availability Zones for a\n * specified region. Because customers have access to different Availability Zones, the intrinsic\n * function ``Fn::GetAZs`` enables template authors to write templates that adapt to the calling\n * user's access. That way you don't have to hard-code a full list of Availability Zones for a\n * specified region.\n */\nclass FnGetAZs extends FnBase {\n  /**\n   * Creates an ``Fn::GetAZs`` function.\n   * @param region The name of the region for which you want to get the Availability Zones.\n   *         You can use the AWS::Region pseudo parameter to specify the region in\n   *         which the stack is created. Specifying an empty string is equivalent to\n   *         specifying AWS::Region.\n   */\n  constructor(region?: string) {\n    super('Fn::GetAZs', region || '');\n  }\n}\n\n/**\n * The intrinsic function ``Fn::ImportValue`` returns the value of an output exported by another stack.\n * You typically use this function to create cross-stack references. In the following example\n * template snippets, Stack A exports VPC security group values and Stack B imports them.\n */\nclass FnImportValue extends FnBase {\n  /**\n   * Creates an ``Fn::ImportValue`` function.\n   * @param sharedValueToImport The stack output value that you want to import.\n   */\n  constructor(sharedValueToImport: string) {\n    super('Fn::ImportValue', sharedValueToImport);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::Select`` returns a single object from a list of objects by index.\n */\nclass FnSelect extends FnBase {\n  /**\n   * Creates an ``Fn::Select`` function.\n   * @param index The index of the object to retrieve. This must be a value from zero to N-1, where N represents the number of elements in the array.\n   * @param array The list of objects to select from. This list must not be null, nor can it have null entries.\n   */\n  constructor(index: number, array: any) {\n    super('Fn::Select', [index, array]);\n  }\n}\n\n/**\n * To split a string into a list of string values so that you can select an element from the\n * resulting string list, use the ``Fn::Split`` intrinsic function. Specify the location of splits\n * with a delimiter, such as , (a comma). After you split a string, use the ``Fn::Select`` function\n * to pick a specific element.\n */\nclass FnSplit extends FnBase {\n  /**\n   * Create an ``Fn::Split`` function.\n   * @param delimiter A string value that determines where the source string is divided.\n   * @param source The string value that you want to split.\n   */\n  constructor(delimiter: string, source: any) {\n    super('Fn::Split', [delimiter, source]);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::Sub`` substitutes variables in an input string with values that\n * you specify. In your templates, you can use this function to construct commands or outputs\n * that include values that aren't available until you create or update a stack.\n */\nclass FnSub extends FnBase {\n  /**\n   * Creates an ``Fn::Sub`` function.\n   * @param body A string with variables that AWS CloudFormation substitutes with their\n   *       associated values at runtime. Write variables as ${MyVarName}. Variables\n   *       can be template parameter names, resource logical IDs, resource attributes,\n   *       or a variable in a key-value map. If you specify only template parameter names,\n   *       resource logical IDs, and resource attributes, don't specify a key-value map.\n   * @param variables The name of a variable that you included in the String parameter.\n   *          The value that AWS CloudFormation substitutes for the associated variable name at runtime.\n   */\n  constructor(body: string, variables?: { [key: string]: any }) {\n    super('Fn::Sub', variables ? [body, variables] : body);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::Base64`` returns the Base64 representation of the input string.\n * This function is typically used to pass encoded data to Amazon EC2 instances by way of\n * the UserData property.\n */\nclass FnBase64 extends FnBase {\n  /**\n   * Creates an ``Fn::Base64`` function.\n   * @param data The string value you want to convert to Base64.\n   */\n  constructor(data: any) {\n    super('Fn::Base64', data);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::Cidr`` returns the specified Cidr address block.\n */\nclass FnCidr extends FnBase {\n  /**\n   * Creates an ``Fn::Cidr`` function.\n   * @param ipBlock  The user-specified default Cidr address block.\n   * @param count  The number of subnets' Cidr block wanted. Count can be 1 to 256.\n   * @param sizeMask The digit covered in the subnet.\n   */\n  constructor(ipBlock: any, count: any, sizeMask?: any) {\n    if (count < 1 || count > 256) {\n      throw new UnscopedValidationError(`Fn::Cidr's count attribute must be between 1 and 256, ${count} was provided.`);\n    }\n    super('Fn::Cidr', [ipBlock, count, sizeMask]);\n  }\n}\n\nclass FnConditionBase extends Intrinsic implements ICfnRuleConditionExpression {\n  readonly disambiguator = true;\n  constructor(type: string, value: any) {\n    super({ [type]: value });\n  }\n}\n\n/**\n * Returns true if all the specified conditions evaluate to true, or returns false if any one\n *  of the conditions evaluates to false. ``Fn::And`` acts as an AND operator. The minimum number of\n * conditions that you can include is 2, and the maximum is 10.\n */\nclass FnAnd extends FnConditionBase {\n  constructor(...condition: ICfnConditionExpression[]) {\n    super('Fn::And', condition);\n  }\n}\n\n/**\n * Compares if two values are equal. Returns true if the two values are equal or false\n * if they aren't.\n */\nclass FnEquals extends FnConditionBase {\n  /**\n   * Creates an ``Fn::Equals`` condition function.\n   * @param lhs A value of any type that you want to compare.\n   * @param rhs A value of any type that you want to compare.\n   */\n  constructor(lhs: any, rhs: any) {\n    super('Fn::Equals', [lhs, rhs]);\n  }\n}\n\n/**\n * Returns one value if the specified condition evaluates to true and another value if the\n * specified condition evaluates to false. Currently, AWS CloudFormation supports the ``Fn::If``\n * intrinsic function in the metadata attribute, update policy attribute, and property values\n * in the Resources section and Outputs sections of a template. You can use the AWS::NoValue\n * pseudo parameter as a return value to remove the corresponding property.\n */\nclass FnIf extends FnConditionBase {\n  /**\n   * Creates an ``Fn::If`` condition function.\n   * @param condition A reference to a condition in the Conditions section. Use the condition's name to reference it.\n   * @param valueIfTrue A value to be returned if the specified condition evaluates to true.\n   * @param valueIfFalse A value to be returned if the specified condition evaluates to false.\n   */\n  constructor(condition: string, valueIfTrue: any, valueIfFalse: any) {\n    super('Fn::If', [condition, valueIfTrue, valueIfFalse]);\n  }\n}", "language": "typescript"}
{"input": "A Kubernetes HostPath volume @see https://kubernetes.io/docs/concepts/storage/volumes/#hostpath", "output": "export class HostPathVolume extends EksVolume {\n  /**\n   * returns `true` if `x` is a HostPathVolume, `false` otherwise\n   */\n  public static isHostPathVolume(x: any) : x is HostPathVolume {\n    return x !== null && typeof(x) === 'object' && HOST_PATH_VOLUME_SYMBOL in x;\n  }\n\n  /**\n   * The path of the file or directory on the host to mount into containers on the pod.\n   *\n   * *Note*: HothPath Volumes present many security risks, and should be avoided when possible.\n   *\n   * @see https://kubernetes.io/docs/concepts/storage/volumes/#hostpath\n   */\n  public readonly path: string;\n\n  constructor(options: HostPathVolumeOptions) {\n    super(options);\n    this.path = options.hostPath;\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomPolicy for AWS resource management", "output": "export class CustomPolicy extends RuleNew {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.CustomPolicy';\n\n  /** @attribute */\n  public readonly configRuleName: string;\n\n  /** @attribute */\n  public readonly configRuleArn: string;\n\n  /** @attribute */\n  public readonly configRuleId: string;\n\n  /** @attribute */\n  public readonly configRuleComplianceType: string;\n\n  constructor(scope: Construct, id: string, props: CustomPolicyProps) {\n    super(scope, id, {\n      physicalName: props.configRuleName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (!props.policyText || [...props.policyText].length === 0) {\n      throw new ValidationError('Policy Text cannot be empty.', this);\n    }\n    if ([...props.policyText].length > 10000) {\n      throw new ValidationError('Policy Text is limited to 10,000 characters or less.', this);\n    }\n\n    const sourceDetails: SourceDetail[] = [];\n    this.ruleScope = props.ruleScope;\n\n    sourceDetails.push({\n      eventSource: EventSource.AWS_CONFIG,\n      messageType: MessageType.CONFIGURATION_ITEM_CHANGE_NOTIFICATION,\n    });\n    sourceDetails.push({\n      eventSource: EventSource.AWS_CONFIG,\n      messageType: MessageType.OVERSIZED_CONFIGURATION_ITEM_CHANGE_NOTIFICATION,\n    });\n    const rule = new CfnConfigRule(this, 'Resource', {\n      configRuleName: this.physicalName,\n      description: props.description,\n      inputParameters: props.inputParameters,\n      scope: Lazy.any({ produce: () => renderScope(this.ruleScope) }), // scope can use values such as stack id (see CloudFormationStackDriftDetectionCheck)\n      source: {\n        owner: 'CUSTOM_POLICY',\n        sourceDetails,\n        customPolicyDetails: {\n          enableDebugLogDelivery: props.enableDebugLog,\n          policyRuntime: 'guard-2.x.x',\n          policyText: props.policyText,\n        },\n      },\n      evaluationModes: props.evaluationModes?.modes.map((mode) => ({\n        mode,\n      })),\n    });\n\n    this.configRuleName = rule.ref;\n    this.configRuleArn = rule.attrArn;\n    this.configRuleId = rule.attrConfigRuleId;\n    this.configRuleComplianceType = rule.attrComplianceType;\n    this.isCustomWithChanges = true;\n  }\n}", "language": "typescript"}
{"input": "CDK class InstanceProfile for AWS resource management", "output": "export class InstanceProfile extends InstanceProfileBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-iam.InstanceProfile';\n\n  /**\n   * Import an existing InstanceProfile from an InstanceProfile name.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param instanceProfileName the name of the existing InstanceProfile to import\n   */\n  public static fromInstanceProfileName(scope: Construct, id: string, instanceProfileName: string): IInstanceProfile {\n    const instanceProfileArn = Stack.of(scope).formatArn({\n      service: 'iam',\n      region: '',\n      resource: 'instance-profile',\n      resourceName: instanceProfileName,\n    });\n    return InstanceProfile.fromInstanceProfileAttributes(scope, id, { instanceProfileArn });\n  }\n\n  /**\n   * Import an existing InstanceProfile from an InstanceProfile ARN.\n   *\n   * If the ARN comes from a Token, the InstanceProfile cannot have a path; if so, any attempt\n   * to reference its instanceProfileName will fail.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param instanceProfileArn the ARN of the exiting InstanceProfile to import\n   */\n  public static fromInstanceProfileArn(scope: Construct, id: string, instanceProfileArn: string): IInstanceProfile {\n    return InstanceProfile.fromInstanceProfileAttributes(scope, id, { instanceProfileArn });\n  }\n\n  /**\n   * Import an existing InstanceProfile from given InstanceProfile attributes.\n   *\n   * If the ARN comes from a Token, the InstanceProfile cannot have a path; if so, any attempt\n   * to reference its instanceProfileName will fail.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param attrs the attributes of the InstanceProfile to import\n   */\n  public static fromInstanceProfileAttributes(scope: Construct, id: string, attrs: InstanceProfileAttributes): IInstanceProfile {\n    class Import extends InstanceProfileBase {\n      public readonly instanceProfileName: string = Arn.extractResourceName(attrs.instanceProfileArn, 'instance-profile').split('/').pop()!;\n      public readonly instanceProfileArn: string = attrs.instanceProfileArn;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n        this._role = attrs.role;\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * Returns the name of this InstanceProfile.\n   */\n  public readonly instanceProfileName: string;\n\n  /**\n   * Returns the ARN of this InstanceProfile.\n   */\n  public readonly instanceProfileArn: string;\n\n  constructor(scope: Construct, id: string, props: InstanceProfileProps = {}) {\n    super(scope, id, { physicalName: props.instanceProfileName });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this._role = props.role || new Role(this, 'InstanceRole', {\n      roleName: PhysicalName.GENERATE_IF_NEEDED,\n      assumedBy: new ServicePrincipal('ec2.amazonaws.com'),\n    });\n\n    const instanceProfile = new CfnInstanceProfile(this, 'Resource', {\n      roles: [this._role.roleName],\n      instanceProfileName: this.physicalName,\n      path: props.path,\n    });\n\n    this.instanceProfileName = this.getResourceNameAttribute(instanceProfile.ref);\n    this.instanceProfileArn = this.getResourceArnAttribute(instanceProfile.attrArn, {\n      region: '',\n      service: 'iam',\n      resource: 'instance-profile',\n      resourceName: `${props.path ? props.path.substring(props.path.charAt(0) === '/' ? 1 : 0) : ''}${this.physicalName}`,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class LogsMixin for AWS resource management", "output": "class LogsMixin extends ClassType {\n  private readonly resourceType: Type;\n\n  constructor(\n    scope: Module,\n    public readonly db: SpecDatabase,\n    private readonly resource: Resource,\n    constructLibModule: ExternalModule,\n  ) {\n    super(scope, {\n      export: true,\n      name: `${naming.classNameFromResource(resource)}LogsMixin`,\n      implements: [MIXINS_CORE.IMixin],\n      extends: MIXINS_CORE.Mixin,\n      docs: {\n        summary: `Mixin to implement vended logs for ${resource.cloudFormationType}`,\n        ...util.splitDocumentation(resource.documentation),\n        stability: Stability.External,\n        docTags: {\n          cloudformationResource: resource.cloudFormationType,\n          mixin: 'true',\n        },\n        see: naming.cloudFormationDocLink({\n          resourceType: resource.cloudFormationType,\n        }),\n      },\n    });\n\n    this.resourceType = Type.fromName(constructLibModule, naming.classNameFromResource(this.resource));\n  }\n\n  /**\n   * Build the elements of the VendedLogsMixin Class\n   */\n  public build() {\n    this.makeConstructor();\n    const supports = this.makeSupportsMethod();\n    this.makeApplyToMethod(supports);\n  }\n\n  private makeConstructor() {\n    this.addProperty({\n      name: 'logType',\n      type: Type.STRING,\n      protected: true,\n      immutable: true,\n    });\n\n    this.addProperty({\n      name: 'logDelivery',\n      type: MIXINS_LOGS_DELIVERY.ILogsDelivery,\n      protected: true,\n      immutable: true,\n    });\n\n    const init = this.addInitializer({\n      docs: {\n        summary: `Create a mixin to enable vended logs for \\`${this.resource.cloudFormationType}\\`.`,\n      },\n    });\n\n    const logType = init.addParameter({\n      name: 'logType',\n      type: Type.STRING,\n      documentation: 'Type of logs that are getting vended',\n    });\n\n    const delivery = init.addParameter({\n      name: 'logDelivery',\n      type: MIXINS_LOGS_DELIVERY.ILogsDelivery,\n      documentation: 'Object in charge of setting up the delivery source, delivery destination, and delivery connection',\n    });\n\n    init.addBody(\n      expr.sym(new ThingSymbol('super', this.scope)).call(),\n      stmt.assign($this.logType, logType),\n      stmt.assign($this.logDelivery, delivery),\n    );\n  }\n\n  private makeSupportsMethod(): Method {\n    const method = this.addMethod({\n      name: 'supports',\n      returnType: Type.ambient(`construct is service.${this.resourceType.symbol}`),\n      docs: {\n        summary: 'Check if this mixin supports the given construct (has vendedLogs property)',\n      },\n    });\n\n    const construct = method.addParameter({\n      name: 'construct',\n      type: CONSTRUCTS.IConstruct,\n    });\n\n    method.addBody(\n      stmt.ret(\n        expr.binOp(\n          CallableProxy.fromName('CfnResource.isCfnResource', CDK_CORE).invoke(construct),\n          '&&',\n          expr.eq(expr.get(construct, 'cfnResourceType'), expr.lit(this.resource.cloudFormationType)),\n        ),\n      ),\n    );\n\n    return method;\n  }\n\n  private makeApplyToMethod(supports: Method) {\n    const method = this.addMethod({\n      name: 'applyTo',\n      returnType: CONSTRUCTS.IConstruct,\n      docs: {\n        summary: 'Apply vended logs configuration to the construct',\n      },\n    });\n\n    const resource = method.addParameter({\n      name: 'resource',\n      type: CONSTRUCTS.IConstruct,\n    });\n\n    const sourceArn = expr.ident('sourceArn');\n    const arnBuilder = $E(expr.sym(this.resourceType.symbol!)).callMethod(`arnFor${this.resource.name}`, resource);\n\n    method.addBody(\n      stmt\n        .if_(expr.not(CallableProxy.fromMethod(supports).invoke(resource)))\n        .then(stmt.block(stmt.ret(resource))),\n\n      stmt.constVar(sourceArn, arnBuilder),\n      $this.logDelivery.callMethod('bind', resource, $this.logType, sourceArn),\n\n      stmt.ret(resource),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, SSM Parameter Store, CloudFormation, Lake Formation resources", "output": "class UsingStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    // Parameter that contains version number, will be used to pass\n    // version value from token.\n    const parameterVersion = new cdk.CfnParameter(this, 'MyParameterVersion', {\n      type: 'Number',\n      default: 1,\n    }).valueAsNumber;\n\n    // Retrieve the latest value of the non-secret parameter\n    // with name \"/My/String/Parameter\".\n    const stringValue = ssm.StringParameter.fromStringParameterAttributes(this, 'MyValue', {\n      parameterName: '/My/Public/Parameter',\n      // 'version' can be specified but is optional.\n    }).stringValue;\n    const stringValueVersionFromToken = ssm.StringParameter.fromStringParameterAttributes(this, 'MyValueVersionFromToken', {\n      parameterName: '/My/Public/Parameter',\n      // parameter version from token\n      version: parameterVersion,\n    }).stringValue;\n\n    // Retrieve a specific version of the secret (SecureString) parameter.\n    const secretValue = ssm.StringParameter.fromSecureStringParameterAttributes(this, 'MySecureValue', {\n      parameterName: '/My/Secret/Parameter',\n    }).stringValue;\n    const secretValueVersion = ssm.StringParameter.fromSecureStringParameterAttributes(this, 'MySecureValueVersion', {\n      parameterName: '/My/Secret/Parameter',\n      version: 1,\n    }).stringValue;\n    const secretValueVersionFromToken = ssm.StringParameter.fromSecureStringParameterAttributes(this, 'MySecureValueVersionFromToken', {\n      parameterName: '/My/Secret/Parameter',\n      // parameter version from token\n      version: parameterVersion,\n    }).stringValue;\n\n    const user = new cdk.CfnResource(this, 'DummyResourceUsingStringParameters', {\n      type: 'AWS::IAM::User',\n      properties: {\n        LoginProfile: {\n          Password: cdk.Fn.join('-', [\n            stringValue,\n            stringValueVersionFromToken,\n            secretValue,\n            secretValueVersion,\n            secretValueVersionFromToken,\n          ]),\n        },\n      },\n    });\n    user.applyRemovalPolicy(cdk.RemovalPolicy.DESTROY);\n  }\n}", "language": "typescript"}
{"input": "CDK class Base for AWS resource management", "output": "class Base(Stack):\n    def __init__(self, app: App, id: str, props, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n\n        # pipeline requires versioned bucket\n        bucket = aws_s3.Bucket(\n            self, \"SourceBucket\",\n            bucket_name=f\"{props['namespace'].lower()}-{Aws.ACCOUNT_ID}\",\n            versioned=True,\n            removal_policy=RemovalPolicy.DESTROY)\n        # ssm parameter to get bucket name later\n        bucket_param = aws_ssm.StringParameter(\n            self, \"ParameterB\",\n            parameter_name=f\"{props['namespace']}-bucket\",\n            string_value=bucket.bucket_name,\n            description='cdk pipeline bucket'\n        )\n        # ecr repo to push docker container into\n        ecr = aws_ecr.Repository(\n            self, \"ECR\",\n            repository_name=f\"{props['namespace']}\",\n            removal_policy=RemovalPolicy.DESTROY\n        )\n        # codebuild project meant to run in pipeline\n        cb_docker_build = aws_codebuild.PipelineProject(\n            self, \"DockerBuild\",\n            project_name=f\"{props['namespace']}-Docker-Build\",\n            build_spec=aws_codebuild.BuildSpec.from_source_filename(\n                filename='pipeline_delivery/docker_build_buildspec.yml'),\n            environment=aws_codebuild.BuildEnvironment(\n                privileged=True,\n            ),\n            # pass the ecr repo uri into the codebuild project so codebuild knows where to push\n            environment_variables={\n                'ecr': aws_codebuild.BuildEnvironmentVariable(\n                    value=ecr.repository_uri),\n                'tag': aws_codebuild.BuildEnvironmentVariable(\n                    value='cdk')\n            },\n            description='Pipeline for CodeBuild',\n            timeout=Duration.minutes(60),\n        )\n        # codebuild iam permissions to read write s3\n        bucket.grant_read_write(cb_docker_build)\n\n        # codebuild permissions to interact with ecr\n        ecr.grant_pull_push(cb_docker_build)\n\n        CfnOutput(\n            self, \"ECRURI\",\n            description=\"ECR URI\",\n            value=ecr.repository_uri,\n        )\n        CfnOutput(\n            self, \"S3Bucket\",\n            description=\"S3 Bucket\",\n            value=bucket.bucket_name\n        )\n\n        self.output_props = props.copy()\n        self.output_props['bucket']= bucket\n        self.output_props['cb_docker_build'] = cb_docker_build\n\n    # pass objects to another stack\n    @property\n    def outputs(self):\n        return self.output_props", "language": "python"}
{"input": "CDK class BucketPinger for AWS resource management", "output": "export class BucketPinger extends Construct {\n  private _resource: CustomResource;\n\n  constructor(scope: Construct, id: string, props: BucketPingerProps) {\n    super(scope, id);\n\n    const func = new lambda.Function(this, 'Function', {\n      code: lambda.Code.fromAsset(path.join(__dirname, 'function')),\n      handler: 'index.handler',\n      runtime: lambda.Runtime.PYTHON_3_9,\n      timeout: props.timeout ?? Duration.minutes(1),\n      environment: {\n        BUCKET_NAME: props.bucketName,\n      },\n    });\n\n    if (!func.role) {\n      throw new Error('pinger lambda has no execution role!');\n    }\n\n    func.role.addToPrincipalPolicy(new iam.PolicyStatement({\n      actions: ['s3:DeleteBucket', 's3:ListBucket'],\n      resources: [`arn:aws:s3:::${props.bucketName}`],\n    }));\n\n    const provider = new cr.Provider(this, 'Provider', {\n      onEventHandler: func,\n    });\n\n    this._resource = new CustomResource(this, 'Resource', {\n      serviceToken: provider.serviceToken,\n    });\n  }\n\n  public get response() {\n    return Token.asString(this._resource.getAtt('Value'));\n  }\n}", "language": "typescript"}
{"input": "CDK class MixinsServiceModule for AWS resource management", "output": "class MixinsServiceModule extends BaseServiceSubmodule {\n  public readonly constructLibModule: ExternalModule;\n\n  public constructor(props: ServiceSubmoduleProps) {\n    super(props);\n    this.constructLibModule = new ExternalModule(`aws-cdk-lib/${props.submoduleName}`);\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderOidc for AWS resource management", "output": "export class UserPoolIdentityProviderOidc extends UserPoolIdentityProviderBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderOidc';\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderOidcProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const scopes = props.scopes ?? ['openid'];\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: this.getProviderName(props.name),\n      providerType: 'OIDC',\n      providerDetails: {\n        client_id: props.clientId,\n        client_secret: props.clientSecret,\n        authorize_scopes: scopes.join(' '),\n        attributes_request_method: props.attributeRequestMethod ?? OidcAttributeRequestMethod.GET,\n        oidc_issuer: props.issuerUrl,\n        authorize_url: props.endpoints?.authorization,\n        token_url: props.endpoints?.token,\n        attributes_url: props.endpoints?.userInfo,\n        jwks_uri: props.endpoints?.jwksUri,\n      },\n      idpIdentifiers: props.identifiers,\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n\n  private getProviderName(name?: string): string {\n    if (name) {\n      if (!Token.isUnresolved(name) && (name.length < 3 || name.length > 32)) {\n        throw new ValidationError(`Expected provider name to be between 3 and 32 characters, received ${name} (${name.length} characters)`, this);\n      }\n      // https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolidentityprovider.html#cfn-cognito-userpoolidentityprovider-providername\n      // u is for unicode\n      if (!name.match(/^[^_\\p{Z}][\\p{L}\\p{M}\\p{S}\\p{N}\\p{P}][^_\\p{Z}]+$/u)) {\n        throw new ValidationError(`Expected provider name must match [^_\\p{Z}][\\p{L}\\p{M}\\p{S}\\p{N}\\p{P}][^_\\p{Z}]+, received ${name}`, this);\n      }\n      return name;\n    }\n\n    const uniqueId = Names.uniqueId(this);\n\n    if (uniqueId.length < 3) {\n      return `${uniqueId}oidc`;\n    }\n\n    if (uniqueId.length > 32) {\n      return uniqueId.substring(0, 16) + uniqueId.substring(uniqueId.length - 16);\n    }\n    return uniqueId;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, SSM Parameter Store, CloudFormation, Config resources", "output": "class S3Stack extends cdk.NestedStack {\n  public readonly bucket: s3.Bucket;\n\n  constructor(scope: Construct, id: string, props?: cdk.NestedStackProps) {\n    super(scope, id, props);\n\n    const readParam = ssm.StringListParameter.fromStringListParameterName(\n      this,\n      'ReadParam',\n      '/repro/subnets',\n    );\n\n    this.bucket = new s3.Bucket(this, 'ReproBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    new s3deploy.BucketDeployment(this, 'DeployWithSsmParameter', {\n      sources: [\n        s3deploy.Source.jsonData('config.json', {\n          subnets: readParam.stringListValue,\n          expectedValues: ['subnet-12345', 'subnet-67890'],\n          version: '2.207.0',\n          issue: 'StringListParameter tokens not resolved in Source.jsonData',\n          timestamp: new Date().toISOString(),\n        }),\n      ],\n      destinationBucket: this.bucket,\n    });\n  }\n}", "language": "typescript"}
{"input": "Glue job Code from an S3 bucket.", "output": "export class S3Code extends Code {\n  constructor(private readonly bucket: s3.IBucket, private readonly key: string) {\n    super();\n  }\n\n  public bind(_scope: constructs.Construct, grantable: iam.IGrantable): CodeConfig {\n    this.bucket.grantRead(grantable, this.key);\n    return {\n      s3Location: {\n        bucketName: this.bucket.bucketName,\n        objectKey: this.key,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class BackupVault for AWS resource management", "output": "export class BackupVault extends BackupVaultBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-backup.BackupVault';\n\n  /**\n   * Import an existing backup vault by name\n   */\n  public static fromBackupVaultName(scope: Construct, id: string, backupVaultName: string): IBackupVault {\n    const backupVaultArn = Stack.of(scope).formatArn({\n      service: 'backup',\n      resource: 'backup-vault',\n      resourceName: backupVaultName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    return BackupVault.fromBackupVaultArn(scope, id, backupVaultArn);\n  }\n\n  /**\n   * Import an existing backup vault by arn\n   */\n  public static fromBackupVaultArn(scope: Construct, id: string, backupVaultArn: string): IBackupVault {\n    const parsedArn = Stack.of(scope).splitArn(backupVaultArn, ArnFormat.COLON_RESOURCE_NAME);\n\n    if (parsedArn.arnFormat !== ArnFormat.COLON_RESOURCE_NAME) {\n      throw new ValidationError(`Backup Vault Arn ${backupVaultArn} has the wrong format, expected ${ArnFormat.COLON_RESOURCE_NAME}.`, scope);\n    }\n    if (!parsedArn.resourceName) {\n      throw new ValidationError(`Backup Vault Arn ${backupVaultArn} does not have a resource name.`, scope);\n    }\n\n    class Import extends BackupVaultBase {\n      public readonly backupVaultName = parsedArn.resourceName!;\n      public readonly backupVaultArn = backupVaultArn;\n    }\n\n    return new Import(scope, id, {\n      account: parsedArn.account,\n      region: parsedArn.region,\n    });\n  }\n\n  public readonly backupVaultName: string;\n  public readonly backupVaultArn: string;\n\n  private readonly accessPolicy: iam.PolicyDocument;\n\n  constructor(scope: Construct, id: string, props: BackupVaultProps = {}) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.backupVaultName && !Token.isUnresolved(props.backupVaultName) && !/^[a-zA-Z0-9\\-_]{2,50}$/.test(props.backupVaultName)) {\n      throw new ValidationError('Expected vault name to match pattern `^[a-zA-Z0-9\\-_]{2,50}$`', this);\n    }\n\n    let notifications: CfnBackupVault.NotificationObjectTypeProperty | undefined;\n    if (props.notificationTopic) {\n      notifications = {\n        backupVaultEvents: props.notificationEvents || Object.values(BackupVaultEvents),\n        snsTopicArn: props.notificationTopic.topicArn,\n      };\n      props.notificationTopic.grantPublish(new iam.ServicePrincipal('backup.amazonaws.com'));\n    }\n\n    this.accessPolicy = props.accessPolicy ?? new iam.PolicyDocument();\n    if (props.blockRecoveryPointDeletion) {\n      this.blockRecoveryPointDeletion();\n    }\n\n    const vault = new CfnBackupVault(this, 'Resource', {\n      backupVaultName: props.backupVaultName || this.uniqueVaultName(),\n      accessPolicy: Lazy.any({ produce: () => this.accessPolicy.toJSON() }),\n      encryptionKeyArn: props.encryptionKey && props.encryptionKey.keyRef.keyArn,\n      notifications,\n      lockConfiguration: renderLockConfiguration(this, props.lockConfiguration),\n    });\n    vault.applyRemovalPolicy(props.removalPolicy);\n\n    this.backupVaultName = vault.attrBackupVaultName;\n    this.backupVaultArn = vault.attrBackupVaultArn;\n  }\n\n  /**\n   * Adds a statement to the vault access policy\n   */\n  @MethodMetadata()\n  public addToAccessPolicy(statement: iam.PolicyStatement) {\n    this.accessPolicy.addStatements(statement);\n  }\n\n  /**\n   * Adds a statement to the vault access policy that prevents anyone\n   * from deleting a recovery point.\n   */\n  @MethodMetadata()\n  public blockRecoveryPointDeletion() {\n    this.addToAccessPolicy(new iam.PolicyStatement({\n      effect: iam.Effect.DENY,\n      actions: [\n        'backup:DeleteRecoveryPoint',\n        'backup:UpdateRecoveryPointLifecycle',\n      ],\n      principals: [new iam.AnyPrincipal()],\n      resources: ['*'],\n    }));\n  }\n\n  private uniqueVaultName() {\n    // Max length of 50 chars, get the last 50 chars\n    const id = Names.uniqueId(this);\n    return id.substring(Math.max(id.length - 50, 0), id.length);\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedAccessPoint for AWS resource management", "output": "class ImportedAccessPoint extends AccessPointBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-efs.ImportedAccessPoint';\n  public readonly accessPointId: string;\n  public readonly accessPointArn: string;\n  private readonly _fileSystem?: IFileSystemRef;\n\n  constructor(scope: Construct, id: string, attrs: AccessPointAttributes) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, attrs);\n\n    if (!attrs.accessPointId) {\n      if (!attrs.accessPointArn) {\n        throw new ValidationError('One of accessPointId or AccessPointArn is required!', this);\n      }\n\n      this.accessPointArn = attrs.accessPointArn;\n      let maybeApId = Stack.of(scope).splitArn(attrs.accessPointArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n\n      if (!maybeApId) {\n        throw new ValidationError('ARN for AccessPoint must provide the resource name.', this);\n      }\n\n      this.accessPointId = maybeApId;\n    } else {\n      if (attrs.accessPointArn) {\n        throw new ValidationError('Only one of accessPointId or AccessPointArn can be provided!', this);\n      }\n\n      this.accessPointId = attrs.accessPointId;\n      this.accessPointArn = Stack.of(scope).formatArn({\n        service: 'elasticfilesystem',\n        resource: 'access-point',\n        resourceName: attrs.accessPointId,\n      });\n    }\n\n    this._fileSystem = attrs.fileSystem;\n  }\n\n  public get fileSystem() {\n    if (!this._fileSystem) {\n      throw new ValidationError(\"fileSystem is only available if 'fromAccessPointAttributes()' is used and a fileSystem is passed in as an attribute.\", this);\n    }\n\n    return toIFileSystem(this._fileSystem);\n  }\n}", "language": "typescript"}
{"input": "CDK class DashboardWithMetricIdAndVisibleIntegrationTest for AWS resource management", "output": "class DashboardWithMetricIdAndVisibleIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const dashboard = new Dashboard(this, 'Dash');\n\n    const lambdaInvocations = new Metric({\n      namespace: 'AWS/Lambda',\n      metricName: 'Invocations',\n      dimensionsMap: { FunctionName: 'test-function' },\n      label: 'Lambda Invocations',\n      id: 'lambda_invocations',\n      visible: true,\n    });\n\n    const lambdaErrors = new Metric({\n      namespace: 'AWS/Lambda',\n      metricName: 'Errors',\n      dimensionsMap: { FunctionName: 'test-function' },\n      label: 'Lambda Errors (Hidden for calculation)',\n      id: 'lambda_errors',\n      visible: false,\n    });\n\n    const lambdaDuration = new Metric({\n      namespace: 'AWS/Lambda',\n      metricName: 'Duration',\n      dimensionsMap: { FunctionName: 'test-function' },\n      label: 'Lambda Duration',\n      id: 'lambda_duration',\n      visible: true,\n    });\n\n    const lambdaThrottles = new Metric({\n      namespace: 'AWS/Lambda',\n      metricName: 'Throttles',\n      dimensionsMap: { FunctionName: 'test-function' },\n      label: 'Lambda Throttles (Hidden)',\n      id: 'lambda_throttles',\n      visible: false,\n    });\n\n    const errorRate = new MathExpression({\n      expression: 'lambda_errors / lambda_invocations * 100',\n      label: 'Error Rate (%)',\n    });\n\n    const widget = new GraphWidget({\n      title: 'Lambda Metrics with ID and Visible Properties',\n      left: [\n        lambdaInvocations,\n        lambdaErrors,\n        lambdaDuration,\n        lambdaThrottles,\n        errorRate,\n      ],\n    });\n\n    dashboard.addWidgets(widget);\n  }\n}", "language": "typescript"}
{"input": "Class which constructs the input from provided application name and stack props. With this input, the construct will create the Application.", "output": "class CreateTargetApplication extends TargetApplication {\n  constructor(\n    private readonly applicationOptions: CreateTargetApplicationOptions) {\n    super();\n  }\n  public bind(scope: Construct): BindTargetApplicationResult {\n    (this.applicationOptions.stackName as string) =\n      this.applicationOptions.stackName || `ApplicationAssociator-${hashValues(scope.node.addr)}-Stack`;\n    const stackId = this.applicationOptions.stackName;\n    (this.applicationOptions.description as string) =\n      this.applicationOptions.description || 'Stack to create AppRegistry application';\n    (this.applicationOptions.env as cdk.Environment) =\n      this.applicationOptions.env || { account: process.env.CDK_DEFAULT_ACCOUNT, region: process.env.CDK_DEFAULT_REGION };\n    (this.applicationOptions.emitApplicationManagerUrlAsOutput as boolean) = this.applicationOptions.emitApplicationManagerUrlAsOutput ?? true;\n\n    const applicationStack = new cdk.Stack(scope, stackId, this.applicationOptions);\n    const appRegApplication = new Application(applicationStack, 'DefaultCdkApplication', {\n      applicationName: this.applicationOptions.applicationName,\n      description: this.applicationOptions.applicationDescription || 'Application containing stacks deployed via CDK.',\n    });\n    cdk.Tags.of(appRegApplication).add('managedBy', 'CDK_Application_Associator');\n\n    if (this.applicationOptions.emitApplicationManagerUrlAsOutput) {\n      new cdk.CfnOutput(appRegApplication, 'ApplicationManagerUrl', {\n        value: `https://${appRegApplication.env.region}.console.aws.amazon.com/systems-manager/appmanager/application/AWS_AppRegistry_Application-${appRegApplication.applicationName}`,\n        description: 'System Manager Application Manager URL for the application created.',\n      });\n    }\n\n    return {\n      application: appRegApplication,\n      associateCrossAccountStacks: this.applicationOptions.associateCrossAccountStacks ?? false,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class ReportGroup for AWS resource management", "output": "export class ReportGroup extends ReportGroupBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codebuild.ReportGroup';\n\n  /**\n   * Reference an existing ReportGroup,\n   * defined outside of the CDK code,\n   * by name.\n   */\n  public static fromReportGroupName(scope: Construct, id: string, reportGroupName: string): IReportGroup {\n    class Import extends ReportGroupBase {\n      public readonly reportGroupName = reportGroupName;\n      public readonly reportGroupArn = renderReportGroupArn(scope, reportGroupName);\n      protected readonly exportBucket = undefined;\n      protected readonly type = undefined;\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly reportGroupArn: string;\n  public readonly reportGroupName: string;\n  protected readonly exportBucket?: s3.IBucket;\n  protected readonly type?: ReportGroupType;\n\n  constructor(scope: Construct, id: string, props: ReportGroupProps = {}) {\n    super(scope, id, {\n      physicalName: props.reportGroupName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    this.type = props.type ? props.type : ReportGroupType.TEST;\n    const resource = new CfnReportGroup(this, 'Resource', {\n      type: this.type,\n      exportConfig: {\n        exportConfigType: props.exportBucket ? 'S3' : 'NO_EXPORT',\n        s3Destination: props.exportBucket\n          ? {\n            bucket: props.exportBucket.bucketName,\n            encryptionDisabled: props.exportBucket.encryptionKey ? false : undefined,\n            encryptionKey: props.exportBucket.encryptionKey?.keyArn,\n            packaging: props.zipExport ? 'ZIP' : undefined,\n          }\n          : undefined,\n      },\n      name: props.reportGroupName,\n      deleteReports: props.deleteReports,\n    });\n    resource.applyRemovalPolicy(props.removalPolicy, {\n      default: cdk.RemovalPolicy.RETAIN,\n    });\n    this.reportGroupArn = this.getResourceArnAttribute(resource.attrArn,\n      reportGroupArnComponents(this.physicalName));\n    this.reportGroupName = this.getResourceNameAttribute(\n      // there is no separate name attribute,\n      // so use Fn::Select + Fn::Split to make one\n      cdk.Fn.select(1, cdk.Fn.split('/', resource.ref)),\n    );\n    this.exportBucket = props.exportBucket;\n\n    if (props.deleteReports && props.removalPolicy !== cdk.RemovalPolicy.DESTROY) {\n      throw new cdk.ValidationError('Cannot use \\'deleteReports\\' property on a report group without setting removal policy to \\'DESTROY\\'.', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, SNS, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\n        \"SELECT topic(2) as device_id, year, month, day FROM 'device/+/data'\",\n      ),\n    });\n\n    const snsTopic = new sns.Topic(this, 'MyTopic');\n    topicRule.addAction(new actions.SnsTopicAction(snsTopic));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation, EFS resources", "output": "class EfsStack extends cdk.Stack {\n  public readonly vpc: ec2.Vpc;\n  public readonly accessPoint: efs.AccessPoint;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.vpc = new ec2.Vpc(this, 'Vpc', {\n      maxAzs: 3,\n      natGateways: 1,\n    });\n\n    const fileSystem = new efs.FileSystem(this, 'Efs', {\n      vpc: this.vpc,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    this.accessPoint = fileSystem.addAccessPoint('AccessPoint', {\n      createAcl: {\n        ownerGid: '1001',\n        ownerUid: '1001',\n        permissions: '750',\n      },\n      path: '/export/lambda',\n      posixUser: {\n        gid: '1001',\n        uid: '1001',\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function checkCandidate", "output": "const checkCandidate = (candidate: IConstruct, distance: number) => {\n    // Check if candidate is the right type, connected to primary, and closer than current match\n    if (isRelatedResource(candidate) && isConnected(primary, candidate) && distance < closestDistance) {\n      closestMatch = candidate;\n      closestDistance = distance;\n    }\n  }", "language": "typescript"}
{"input": "CDK helper function for S3, EC2 operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        ################################################################################\n        # VPC\n        vpc = ec2.Vpc(self, \"OpenSearch VPC\", max_azs=3)\n\n        ################################################################################\n        # Amazon OpenSearch Service domain\n        es_sec_grp = ec2.SecurityGroup(\n            self,\n            \"OpenSearchSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"OpenSearchSecGrp\",\n        )\n\n        vpc_subnets = ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_NAT)\n        domain = opensearch.Domain(\n            self,\n            \"opensearch-stack-demo\",\n            version=opensearch.EngineVersion.OPENSEARCH_1_3,  # Upgrade when CDK upgrades\n            domain_name=DOMAIN_NAME,\n            removal_policy=RemovalPolicy.DESTROY,\n            capacity=opensearch.CapacityConfig(\n                data_node_instance_type=DOMAIN_DATA_NODE_INSTANCE_TYPE,\n                data_nodes=DOMAIN_DATA_NODE_INSTANCE_COUNT,\n                master_node_instance_type=DOMAIN_MASTER_NODE_INSTANCE_TYPE,\n                master_nodes=DOMAIN_MASTER_NODE_INSTANCE_COUNT,\n                warm_instance_type=DOMAIN_UW_NODE_INSTANCE_TYPE,\n                warm_nodes=DOMAIN_UW_NODE_INSTANCE_COUNT,\n            ),\n            ebs=opensearch.EbsOptions(\n                enabled=True,\n                volume_size=DOMAIN_INSTANCE_VOLUME_SIZE,\n                volume_type=ec2.EbsDeviceVolumeType.GP3,\n            ),\n            vpc=vpc,\n            vpc_subnets=[vpc_subnets],\n            security_groups=[es_sec_grp],\n            zone_awareness=opensearch.ZoneAwarenessConfig(\n                enabled=True, availability_zone_count=DOMAIN_AZ_COUNT\n            ),\n            enforce_https=True,\n            node_to_node_encryption=True,\n            encryption_at_rest={\"enabled\": True},\n            use_unsigned_basic_auth=True,\n            fine_grained_access_control={\n                \"master_user_name\": DOMAIN_ADMIN_UNAME,\n                \"master_user_password\": SecretValue.unsafe_plain_text(DOMAIN_ADMIN_PW),\n            },\n        )\n\n        CfnOutput(\n            self,\n            \"MasterUser\",\n            value=DOMAIN_ADMIN_UNAME,\n            description=\"Master User Name for Amazon OpenSearch Service\",\n        )\n\n        CfnOutput(\n            self,\n            \"MasterPW\",\n            value=DOMAIN_ADMIN_PW,\n            description=\"Master User Password for Amazon OpenSearch Service\",\n        )\n\n        ################################################################################\n        # Jump host to setup nginx proxy\n        sn_public = ec2.SubnetSelection(subnet_type=ec2.SubnetType.PUBLIC)\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            edition=ec2.AmazonLinuxEdition.STANDARD,\n            virtualization=ec2.AmazonLinuxVirt.HVM,\n            storage=ec2.AmazonLinuxStorage.GENERAL_PURPOSE,\n        )\n\n        # Instance Role and SSM Managed Policy\n        role = iam.Role(\n            self,\n            \"OpenSearchInstanceSSM\",\n            assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"),\n        )\n        role.add_managed_policy(\n            iam.ManagedPolicy.from_aws_managed_policy_name(\n                \"service-role/AmazonEC2RoleforSSM\"\n            )\n        )\n        role.add_managed_policy(\n            iam.ManagedPolicy.from_aws_managed_policy_name(\n                \"AmazonSSMManagedInstanceCore\"\n            )\n        )\n\n        proxy_instance_sec_grp = ec2.SecurityGroup(\n            self,\n            \"OpenSearchProxyInstanceSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"OpenSearchProxyInstanceSecGrp\",\n        )\n        proxy_instance_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(80))\n        proxy_instance_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(443))\n\n        es_sec_grp.add_ingress_rule(proxy_instance_sec_grp, ec2.Port.tcp(80))\n        es_sec_grp.add_ingress_rule(proxy_instance_sec_grp, ec2.Port.tcp(443))\n\n        instance = ec2.Instance(\n            self,\n            \"opensearch-proxy-instance\",\n            instance_type=ec2.InstanceType(EC2_INSTANCE_TYPE),\n            vpc=vpc,\n            machine_image=amzn_linux,\n            vpc_subnets=sn_public,\n            role=role,\n            security_group=proxy_instance_sec_grp\n\n        )\n\n        stmt = iam.PolicyStatement(actions=[\"es:*\"], resources=[domain.domain_arn])\n        instance.add_to_role_policy(stmt)\n\n        # Create SNS topic, subscription for alerting\n        sns_topic = sns.Topic(self, \"opensearch_demo_topic\")\n\n        sns_topic.add_subscription(\n            subscriptions.EmailSubscription(SNS_NOTIFICATION_EMAIL)\n        )\n\n        sns_policy_statement = iam.PolicyStatement(\n            actions=[\"sns:publish\"],\n            resources=[sns_topic.topic_arn],\n            effect=iam.Effect.ALLOW,\n        )\n        sns_policy = iam.ManagedPolicy(self, \"opensearch_demo_policy\")\n        sns_policy.add_statements(sns_policy_statement)\n\n        sns_role = iam.Role(\n            self,\n            \"opensearch_demo_sns_role\",\n            assumed_by=iam.ServicePrincipal(\"es.amazonaws.com\"),\n        )\n        sns_role.add_managed_policy(sns_policy)\n\n        # Add custom files which needs to be used as an asset\n        # Generally used for running post deployment commands such as to create index templates, manage ISM policy, create alerts etc\n        dirname = os.path.dirname(__file__)\n\n        # Add dashboards assets, Shows sample to import default dashboard for Sample web logs\n        dashboards_asset = Asset(\n            self,\n            \"DashboardsAsset\",\n            path=os.path.join(\n                dirname, \"../confs/export_opensearch_dashboards_web_logs.ndjson\"\n            ),\n        )\n        dashboards_asset.grant_read(instance.role)\n        dashboards_asset_path = instance.user_data.add_s3_download_command(\n            bucket=dashboards_asset.bucket,\n            bucket_key=dashboards_asset.s3_object_key,\n        )\n\n        # Configuration for nginx proxy\n        nginx_asset = Asset(\n            self,\n            \"NginxAsset\",\n            path=os.path.join(dirname, \"../confs/nginx_opensearch.conf\"),\n        )\n        nginx_asset.grant_read(instance.role)\n        nginx_asset_path = instance.user_data.add_s3_download_command(\n            bucket=nginx_asset.bucket,\n            bucket_key=nginx_asset.s3_object_key,\n        )\n\n        # Adhoc script to show samples for creating ISM, Alerts, Users etc\n        post_deployment_asset = Asset(\n            self,\n            \"PostDeploymentAsset\",\n            path=os.path.join(dirname, \"../confs/post_deployment_objects.sh\"),\n        )\n        post_deployment_asset.grant_read(instance.role)\n        post_deployment_asset_path = instance.user_data.add_s3_download_command(\n            bucket=post_deployment_asset.bucket,\n            bucket_key=post_deployment_asset.s3_object_key,\n        )\n\n        instance.user_data.add_commands(\n            \"yum update -y\",\n            \"yum install jq -y\",\n            \"amazon-linux-extras install nginx1.12\",\n            \"mkdir -p /home/ec2-user/assets\",\n            \"cd /home/ec2-user/assets\",\n            \"mv {} export_opensearch_dashboards_web_logs.ndjson\".format(\n                dashboards_asset_path\n            ),\n            \"mv {} nginx_opensearch.conf\".format(nginx_asset_path),\n            \"mv {} post_deployment_objects.sh\".format(post_deployment_asset_path),\n            \"pip install opensearch-py==1.0.0\",\n            \"wget https://raw.githubusercontent.com/aiven/demo-opensearch-python/main/full_format_recipes.json\",\n            \"openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/nginx/cert.key -out /etc/nginx/cert.crt -subj /C=US/ST=./L=./O=./CN=.\\n\"\n            \"cp nginx_opensearch.conf /etc/nginx/conf.d/\",\n            \"sed -i 's/DOMAIN_ENDPOINT/\"\n            + domain.domain_endpoint\n            + \"/g' /etc/nginx/conf.d/nginx_opensearch.conf\",\n            \"sed -i 's/DOMAIN_ENDPOINT/\"\n            + domain.domain_endpoint\n            + \"/g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=SNS_ROLE_ARN=\"\n            + sns_role.role_arn\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's/SNS_TOPIC_ARN/\"\n            + sns_topic.topic_arn\n            + \"/g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=DOMAIN_ADMIN_UNAME=\"\n            + DOMAIN_ADMIN_UNAME\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=DOMAIN_ADMIN_PW=\"\n            + DOMAIN_ADMIN_PW\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"systemctl restart nginx.service\",\n            \"chmod 500 post_deployment_objects.sh\",\n            \"sleep 5\",\n            \"bash --verbose post_deployment_objects.sh\",\n        )\n\n        CfnOutput(\n            self,\n            \"Dashboards URL (via Jump host)\",\n            value=\"https://\" + instance.instance_public_ip,\n            description=\"Dashboards URL via Jump host\",\n        )\n\n        CfnOutput(\n            self,\n            \"SNS Subscription Alert Message\",\n            value=SNS_NOTIFICATION_EMAIL,\n            description=\"Please confirm your SNS subscription received at\",\n        )", "language": "python"}
{"input": "CDK class EventFieldReplacer for AWS resource management", "output": "class EventFieldReplacer extends DefaultTokenResolver {\n      constructor() {\n        super(new StringConcat());\n      }\n\n      public resolveToken(t: Token, _context: IResolveContext) {\n        if (!isEventField(t)) { return Token.asString(t); }\n\n        const key = keyForField(t);\n        if (inputPathsMap[key] && inputPathsMap[key] !== t.path) {\n          throw new UnscopedValidationError(`Single key '${key}' is used for two different JSON paths: '${t.path}' and '${inputPathsMap[key]}'`);\n        }\n        inputPathsMap[key] = t.path;\n\n        return `<${key}>`;\n      }\n    }", "language": "typescript"}
{"input": "Node.js-specific implementation of the SDK injector. Handles Node.js auto-instrumentation setup and NODE_OPTIONS configuration.", "output": "export class NodeInjector extends Injector {\n  get command(): string[] {\n    return ['cp', '-a', '/autoinstrumentation/.', this.containerPath];\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    envsToInject[constants.NodeInstrumentation.NODE_OPTIONS] = ` --require ${this.containerPath}/autoinstrumentation.js`;\n  }\n\n  get containerPath(): string {\n    return '/otel-auto-instrumentation-nodejs';\n  }\n\n  protected overrideAdditionalEnvironments(envsToOverride: { [key: string]: string }, envsFromTaskDef: { [key: string]: string }): void {\n    if (envsFromTaskDef[constants.NodeInstrumentation.NODE_OPTIONS]) {\n      const originalNodeOptions = envsFromTaskDef[constants.NodeInstrumentation.NODE_OPTIONS] ?? '';\n      let renderedNodeOptions = `${originalNodeOptions} --require ${this.containerPath}/autoinstrumentation.js`;\n      envsToOverride[constants.NodeInstrumentation.NODE_OPTIONS] = renderedNodeOptions;\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class RestApi for AWS resource management", "output": "export class RestApi extends RestApiBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.RestApi';\n\n  /**\n   * Return whether the given object is a `RestApi`\n   */\n  public static isRestApi(x: any) : x is RestApi {\n    return x !== null && typeof(x) === 'object' && APIGATEWAY_RESTAPI_SYMBOL in x;\n  }\n\n  /**\n   * Import an existing RestApi.\n   */\n  public static fromRestApiId(scope: Construct, id: string, restApiId: string): IRestApi {\n    class Import extends RestApiBase {\n      public readonly restApiId = restApiId;\n\n      public addToResourcePolicy(_statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n        return { statementAdded: false };\n      }\n\n      public get root(): IResource {\n        throw new ValidationError('root is not configured when imported using `fromRestApiId()`. Use `fromRestApiAttributes()` API instead.', scope);\n      }\n\n      public get restApiRootResourceId(): string {\n        throw new ValidationError('restApiRootResourceId is not configured when imported using `fromRestApiId()`. Use `fromRestApiAttributes()` API instead.', scope);\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing RestApi that can be configured with additional Methods and Resources.\n   */\n  public static fromRestApiAttributes(scope: Construct, id: string, attrs: RestApiAttributes): IRestApi {\n    class Import extends RestApiBase {\n      public readonly restApiId = attrs.restApiId;\n      public readonly restApiName = attrs.restApiName ?? id;\n      public readonly restApiRootResourceId = attrs.rootResourceId;\n      public readonly root: IResource = new RootResource(this, {}, this.restApiRootResourceId);\n\n      public addToResourcePolicy(_statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n        return { statementAdded: false };\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly restApiId: string;\n\n  public readonly root: IResource;\n\n  public readonly restApiRootResourceId: string;\n\n  /**\n   * The list of methods bound to this RestApi\n   */\n  public readonly methods = new Array<Method>();\n\n  /**\n   * This list of deployments bound to this RestApi\n   */\n  private readonly deployments = new Array<Deployment>();\n\n  constructor(scope: Construct, id: string, props: RestApiProps = { }) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.minCompressionSize !== undefined && props.minimumCompressionSize !== undefined) {\n      throw new ValidationError('both properties minCompressionSize and minimumCompressionSize cannot be set at once.', scope);\n    }\n\n    this.resourcePolicy = props.policy;\n\n    const resource = new CfnRestApi(this, 'Resource', {\n      name: this.physicalName,\n      description: props.description,\n      policy: Lazy.any({ produce: () => this.resourcePolicy }),\n      failOnWarnings: props.failOnWarnings,\n      minimumCompressionSize: props.minCompressionSize?.toBytes() ?? props.minimumCompressionSize,\n      binaryMediaTypes: props.binaryMediaTypes,\n      endpointConfiguration: this._configureEndpoints(props),\n      apiKeySourceType: props.apiKeySourceType,\n      cloneFrom: props.cloneFrom?.restApiId,\n      parameters: props.parameters,\n      disableExecuteApiEndpoint: props.disableExecuteApiEndpoint,\n    });\n    this.node.defaultChild = resource;\n    this.restApiId = resource.ref;\n\n    this._configureCloudWatchRole(resource, props.cloudWatchRole, props.cloudWatchRoleRemovalPolicy);\n\n    this._configureDeployment(props);\n    if (props.domainName) {\n      this.addDomainName('CustomDomain', props.domainName);\n    }\n\n    this.root = new RootResource(this, props, resource.attrRootResourceId);\n    this.restApiRootResourceId = resource.attrRootResourceId;\n\n    this.node.addValidation({ validate: () => this.validateRestApi() });\n\n    Object.defineProperty(this, APIGATEWAY_RESTAPI_SYMBOL, { value: true });\n  }\n\n  /**\n   * Adds a statement to the resource policy associated with this rest api.\n   * A resource policy will be automatically created upon the first call to `addToResourcePolicy`.\n   *\n   * Note that this does not work with imported rest api.\n   *\n   * @param statement The policy statement to add\n   */\n  @MethodMetadata()\n  public addToResourcePolicy(statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n    this.resourcePolicy = this.resourcePolicy ?? new iam.PolicyDocument();\n    this.resourcePolicy.addStatements(statement);\n\n    return { statementAdded: true, policyDependable: this };\n  }\n\n  /**\n   * Adds a new model.\n   */\n  @MethodMetadata()\n  public addModel(id: string, props: ModelOptions): Model {\n    return new Model(this, id, {\n      ...props,\n      restApi: this,\n    });\n  }\n\n  /**\n   * Adds a new request validator.\n   */\n  @MethodMetadata()\n  public addRequestValidator(id: string, props: RequestValidatorOptions): RequestValidator {\n    return new RequestValidator(this, id, {\n      ...props,\n      restApi: this,\n    });\n  }\n\n  /**\n   * Internal API used by `Method` to keep an inventory of methods at the API\n   * level for validation purposes.\n   *\n   * @internal\n   */\n  public _attachMethod(method: Method) {\n    this.methods.push(method);\n\n    // add this method as a dependency to all deployments defined for this api\n    // when additional deployments are added, _attachDeployment is called and\n    // this method will be added there.\n    for (const dep of this.deployments) {\n      dep._addMethodDependency(method);\n    }\n  }\n\n  /**\n   * Attaches a deployment to this REST API.\n   *\n   * @internal\n   */\n  public _attachDeployment(deployment: Deployment) {\n    this.deployments.push(deployment);\n\n    // add all methods that were already defined as dependencies of this\n    // deployment when additional methods are added, _attachMethod is called and\n    // it will be added as a dependency to this deployment.\n    for (const method of this.methods) {\n      deployment._addMethodDependency(method);\n    }\n  }\n\n  /**\n   * Performs validation of the REST API.\n   */\n  private validateRestApi() {\n    if (this.methods.length === 0) {\n      return [\"The REST API doesn't contain any methods\"];\n    }\n\n    return [];\n  }\n}", "language": "typescript"}
{"input": "Platforms that are allowed with signing config. @see https://docs.aws.amazon.com/signer/latest/developerguide/gs-platform.html", "output": "export class Platform {\n  /**\n   * Specification of signature format and signing algorithms for AWS IoT Device.\n   */\n  public static readonly AWS_IOT_DEVICE_MANAGEMENT_SHA256_ECDSA = Platform.of('AWSIoTDeviceManagement-SHA256-ECDSA');\n\n  /**\n   * Specification of signature format and signing algorithms for AWS Lambda.\n   */\n  public static readonly AWS_LAMBDA_SHA384_ECDSA = Platform.of('AWSLambda-SHA384-ECDSA');\n\n  /**\n   * Specification of signature format and signing algorithms with\n   * SHA1 hash and RSA encryption for Amazon FreeRTOS.\n   */\n  public static readonly AMAZON_FREE_RTOS_TI_CC3220SF = Platform.of('AmazonFreeRTOS-TI-CC3220SF');\n\n  /**\n   * Specification of signature format and signing algorithms with\n   * SHA256 hash and ECDSA encryption for Amazon FreeRTOS.\n   */\n  public static readonly AMAZON_FREE_RTOS_DEFAULT = Platform.of('AmazonFreeRTOS-Default');\n\n  /**\n   * Specification of signature format and signing algorithms with\n   * SHA256 hash and ECDSA encryption for container registries with notation.\n   */\n  public static readonly NOTATION_OCI_SHA384_ECDSA = Platform.of('Notation-OCI-SHA384-ECDSA');\n\n  /**\n   * Custom signing profile platform.\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-signer-signingprofile.html#cfn-signer-signingprofile-platformid\n   *\n   * @param platformId - The id of signing platform.\n   */\n  public static of(platformId: string): Platform {\n    return new Platform(platformId);\n  }\n\n  /**\n   *\n   * @param platformId - The id of signing platform.\n   */\n  private constructor(public readonly platformId: string) {\n    this.platformId = platformId;\n  }\n}", "language": "typescript"}
{"input": "CDK class AppWithOutput for AWS resource management", "output": "export class AppWithOutput extends Stage {\n  public readonly theOutput: CfnOutput;\n\n  constructor(scope: Construct, id: string, props: AppWithOutputProps = {}) {\n    super(scope, id, props);\n\n    const stack = new BucketStack(this, props.stackId ?? 'Stack');\n    this.theOutput = new CfnOutput(stack, 'MyOutput', { value: stack.bucket.bucketRef.bucketName });\n  }\n}", "language": "typescript"}
{"input": "A time window during which EventBridge Scheduler invokes the schedule.", "output": "export class TimeWindow {\n  /**\n   * TimeWindow is disabled.\n   */\n  public static off(): TimeWindow {\n    return new TimeWindow('OFF');\n  }\n\n  /**\n   * TimeWindow is enabled.\n   */\n  public static flexible(maxWindow: Duration): TimeWindow {\n    if (maxWindow.toMinutes() < 1 || maxWindow.toMinutes() > 1440) {\n      throw new UnscopedValidationError(`The provided duration must be between 1 minute and 1440 minutes, got ${maxWindow.toMinutes()}`);\n    }\n    return new TimeWindow('FLEXIBLE', maxWindow);\n  }\n\n  /**\n   * Determines whether the schedule is invoked within a flexible time window.\n   */\n  public readonly mode: 'OFF' | 'FLEXIBLE';\n\n  /**\n   * The maximum time window during which the schedule can be invoked.\n   *\n   * Must be between 1 to 1440 minutes.\n   *\n   * @default - no value\n   */\n  public readonly maxWindow?: Duration;\n\n  private constructor(mode: 'OFF' | 'FLEXIBLE', maxWindow?: Duration) {\n    this.mode = mode;\n    this.maxWindow = maxWindow;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, Step Functions, SFn Tasks resources", "output": "class GlueStartJobRunWorkerStack extends cdk.Stack {\n  readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const codeAsset = new assets.Asset(this, 'Glue Job Script', {\n      path: path.join(__dirname, 'my-glue-script/job.py'),\n    });\n\n    const jobRole = new iam.Role(this, 'Glue Job Role', {\n      assumedBy: new iam.ServicePrincipal('glue.amazonaws.com'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/AWSGlueServiceRole'),\n      ],\n    });\n    codeAsset.grantRead(jobRole);\n\n    const job = new glue.CfnJob(this, 'Glue Job', {\n      name: 'My Glue Job',\n      glueVersion: '3.0',\n      command: {\n        name: 'glueetl',\n        pythonVersion: '3',\n        scriptLocation: `s3://${codeAsset.s3BucketName}/${codeAsset.s3ObjectKey}`,\n      },\n      role: jobRole.roleArn,\n    });\n\n    const jobTask = new GlueStartJobRun(this, 'Glue Job Task', {\n      glueJobName: job.name!,\n      integrationPattern: sfn.IntegrationPattern.RUN_JOB,\n      arguments: sfn.TaskInput.fromObject({\n        '--enable-metrics': 'true',\n      }),\n      workerConfiguration: {\n        workerTypeV2: WorkerTypeV2.of(sfn.JsonPath.stringAt('$.glue_jobs_configs.executor_type')),\n        numberOfWorkers: sfn.JsonPath.numberAt('$.glue_jobs_configs.max_number_workers'),\n      },\n    });\n\n    const startTask = new sfn.Pass(this, 'Start Task');\n    const endTask = new sfn.Pass(this, 'End Task');\n\n    this.stateMachine = new sfn.StateMachine(this, 'State Machine', {\n      definition: sfn.Chain.start(startTask).next(jobTask).next(endTask),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class DatabaseProxyEndpoint for AWS resource management", "output": "export class DatabaseProxyEndpoint extends DatabaseProxyEndpointBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.DatabaseProxyEndpoint';\n\n  /**\n   * Import an existing database proxy endpoint.\n   */\n  public static fromDatabaseProxyEndpointAttributes(\n    scope: Construct,\n    id: string,\n    attrs: DatabaseProxyEndpointAttributes,\n  ): IDatabaseProxyEndpoint {\n    class Import extends DatabaseProxyEndpointBase {\n      public readonly dbProxyEndpointName = attrs.dbProxyEndpointName;\n      public readonly dbProxyEndpointArn = attrs.dbProxyEndpointArn;\n      public readonly endpoint = attrs.endpoint;\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * DB Proxy Endpoint Name\n   *\n   * @attribute\n   */\n  public readonly dbProxyEndpointName: string;\n\n  /**\n   * DB Proxy Endpoint ARN\n   *\n   * @attribute\n   */\n  public readonly dbProxyEndpointArn: string;\n\n  /**\n   * The endpoint that you can use to connect to the DB proxy\n   *\n   * @attribute\n   */\n  public readonly endpoint: string;\n\n  constructor(scope: Construct, id: string, props: DatabaseProxyEndpointProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const physicalName = props.dbProxyEndpointName || Names.uniqueResourceName(this, { maxLength: 60 });\n\n    const vpcSubnetIds = props.vpc.selectSubnets(props.vpcSubnets).subnetIds;\n    if (vpcSubnetIds.length < 2) {\n      throw new ValidationError(`\\`subnets\\` requires at least 2 subnets, got ${vpcSubnetIds.length}`, this);\n    }\n\n    if (props.securityGroups && props.securityGroups.length == 0) {\n      throw new ValidationError('\\`securityGroups\\` must be undefined or a non-empty array.', this);\n    }\n\n    const resource = new CfnDBProxyEndpoint(this, 'Resource', {\n      dbProxyEndpointName: physicalName,\n      dbProxyName: props.dbProxy.dbProxyRef.dbProxyName,\n      vpcSubnetIds,\n      vpcSecurityGroupIds: props.securityGroups?.map(e => e.securityGroupId),\n      targetRole: props.targetRole,\n    });\n\n    this.dbProxyEndpointName = resource.dbProxyEndpointName;\n    this.dbProxyEndpointArn = resource.attrDbProxyEndpointArn;\n    this.endpoint = resource.attrEndpoint;\n  }\n}", "language": "typescript"}
{"input": "CDK Construct TestThirdPartyConstruct for reusable infrastructure components", "output": "class TestThirdPartyConstruct extends Construct {\n  // @ts-ignore\n  private static readonly [JSII_RUNTIME_SYMBOL] = { fqn: 'mycoolthing.TestConstruct', version: '1.2.3' };\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudWatch Logs resources", "output": "class ProducerStack(Stack):\n    def __init__(self, scope: Construct, id: str, *, \n                app_name: str, \n                consumer_account_id: str, \n                 **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create the EventBus\n        producer_event_bus = events.EventBus(\n            self, f\"{app_name}-producer-event-bus\"\n        )\n\n        # Create rule to forward events to consumer account\n        rule = events.Rule(\n            self, f\"{app_name}-forward-to-consumer-rule\",\n            event_bus=producer_event_bus,\n            event_pattern=events.EventPattern(\n                source=['com.myapp.events']\n            )\n        )\n\n        # Add target to forward to consumer account's event bus\n        consumer_bus = events.EventBus.from_event_bus_arn(\n            self,\n            'ConsumerEventBus',\n            f\"arn:aws:events:{Stack.of(self).region}:{consumer_account_id}:event-bus/default\"\n        )\n        rule.add_target(targets.EventBus(consumer_bus))\n\n        # Optional: Add CloudWatch target for monitoring\n        log_group = logs.LogGroup(self, f\"{app_name}-producer-logs\")\n        rule.add_target(targets.CloudWatchLogGroup(log_group))", "language": "python"}
{"input": "CDK helper function for EC2, IAM operations", "output": "def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc, \n                client_subnet, \n                zookeeper,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Amazon Linux AMI\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            edition=ec2.AmazonLinuxEdition.STANDARD,\n            virtualization=ec2.AmazonLinuxVirt.HVM,\n            storage=ec2.AmazonLinuxStorage.GENERAL_PURPOSE\n        )\n        \n        # MSK client Role\n        role = iam.Role(self, \"InstanceSSM\", assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"))\n\n        # AWS managed policy added to MSK client role\n        role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSSMManagedInstanceCore\"))\n\n        # MSK Client\n        instance = ec2.Instance(self, \"Instance\",\n            instance_type=ec2.InstanceType(constants[\"KAFKA_CLIENT_INSTANCE\"]),\n            machine_image=amzn_linux,\n            vpc = vpc,\n            vpc_subnets=client_subnet,\n            role = role,\n            \n        )\n\n        # Ec2 security group in the MSK VPC\n        client_security_group = ec2.SecurityGroup(self, 'InstanceSecurityGroup', vpc=vpc)\n        \n        # Enable connection from anywhere on port 22\n        client_security_group.add_ingress_rule(\n            ec2.Peer.ipv4('0.0.0.0/0'),\n            ec2.Port.tcp(22),\n        )\n        instance.add_security_group(client_security_group)\n\n        # Commands to install dependencies and create the kafka topic\n        instance.user_data.add_commands(\n            \"yum install java-1.8.0 -y\",\n            f'wget https://archive.apache.org/dist/kafka/{constants[\"KAFKA_VERSION\"]}/{constants[\"KAFKA_DOWNLOAD_VERSION\"]}.tgz',\n            f\"tar -xzf {constants['KAFKA_DOWNLOAD_VERSION']}.tgz\",\n            f\"./{constants['KAFKA_DOWNLOAD_VERSION']}/bin/kafka-topics.sh --create --zookeeper {zookeeper} --replication-factor 2 --partitions 1 --topic {constants['MSK_TOPIC']}\",\n        )", "language": "python"}
{"input": "CDK class CaaRecord for AWS resource management", "output": "export class CaaRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.CaaRecord';\n\n  constructor(scope: Construct, id: string, props: CaaRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.CAA,\n      target: RecordTarget.fromValues(...props.values.map(v => `${v.flag} ${v.tag} \"${v.value}\"`)),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK Construct YourConstruct for reusable infrastructure components", "output": "class YourConstruct extends Construct {\n      constructor(scope: Construct, id: string) {\n        super(scope, id);\n        this.node.addValidation({ validate: () => ['your-error1'] });\n      }\n    }", "language": "typescript"}
{"input": "CDK helper function for EC2, EFS operations", "output": "def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        elasticfilestore = efs.CfnFileSystem(\n                self, \"efs-storage\",\n                encrypted=False,\n                lifecycle_policies=None\n                )\n\n        sg_efs = ec2.SecurityGroup(\n                self,\n                id=\"sg_efs\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_efs\"\n                )\n\n        sg_efs.add_ingress_rule(\n                peer=ec2.Peer.ipv4(\"10.0.0.0/16\"),\n                connection=ec2.Port.tcp(2049)\n                )", "language": "python"}
{"input": "Represents an ECR image that will be constructed from the specified asset and can be bound as Lambda code.", "output": "export class AssetImageCode extends Code {\n  public readonly isInline: boolean = false;\n  private asset?: ecr_assets.DockerImageAsset;\n\n  constructor(private readonly directory: string, private readonly props: AssetImageCodeProps) {\n    super();\n  }\n\n  public bind(scope: Construct): CodeConfig {\n    // If the same AssetImageCode is used multiple times, retain only the first instantiation.\n    if (!this.asset) {\n      this.asset = new ecr_assets.DockerImageAsset(scope, 'AssetImage', {\n        directory: this.directory,\n        ...this.props,\n      });\n      this.asset.repository.grantPull(new iam.ServicePrincipal('lambda.amazonaws.com'));\n    } else if (cdk.Stack.of(this.asset) !== cdk.Stack.of(scope)) {\n      throw new ValidationError(`Asset is already associated with another stack '${cdk.Stack.of(this.asset).stackName}'. ` +\n        'Create a new Code instance for every stack.', scope);\n    }\n\n    return {\n      image: {\n        imageUri: this.asset.imageUri,\n        entrypoint: this.props.entrypoint,\n        cmd: this.props.cmd,\n        workingDirectory: this.props.workingDirectory,\n      },\n    };\n  }\n\n  public bindToResource(resource: cdk.CfnResource, options: ResourceBindOptions = { }) {\n    if (!this.asset) {\n      throw new ValidationError('bindToResource() must be called after bind()', resource);\n    }\n\n    const resourceProperty = options.resourceProperty || 'Code.ImageUri';\n\n    // https://github.com/aws/aws-cdk/issues/14593\n    this.asset.addResourceMetadata(resource, resourceProperty);\n  }\n}", "language": "typescript"}
{"input": "CDK class QueuedMatchmakingConfiguration for AWS resource management", "output": "export class QueuedMatchmakingConfiguration extends MatchmakingConfigurationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-gamelift-alpha.QueuedMatchmakingConfiguration';\n\n  /**\n   * Import an existing matchmaking configuration from its name.\n   */\n  static fromQueuedMatchmakingConfigurationName(scope: Construct, id: string, matchmakingConfigurationName: string): IMatchmakingConfiguration {\n    return this.fromMatchmakingConfigurationAttributes(scope, id, { matchmakingConfigurationName: matchmakingConfigurationName });\n  }\n\n  /**\n   * Import an existing matchmaking configuration from its ARN.\n   */\n  static fromQueuedMatchmakingConfigurationArn(scope: Construct, id: string, matchmakingConfigurationArn: string): IMatchmakingConfiguration {\n    return this.fromMatchmakingConfigurationAttributes(scope, id, { matchmakingConfigurationArn: matchmakingConfigurationArn });\n  }\n\n  /**\n   * The name of the matchmaking configuration.\n   */\n  public readonly matchmakingConfigurationName: string;\n\n  /**\n   * The ARN of the matchmaking configuration.\n   */\n  public readonly matchmakingConfigurationArn: string;\n\n  /**\n   * The notification target for matchmaking events\n   */\n  public readonly notificationTarget?: sns.ITopic;\n\n  /**\n   * A list of game session queue destinations\n   */\n  private readonly gameSessionQueues: IGameSessionQueue[] = [];\n\n  constructor(scope: Construct, id: string, props: QueuedMatchmakingConfigurationProps) {\n    super(scope, id, {\n      physicalName: props.matchmakingConfigurationName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.matchmakingConfigurationName && !cdk.Token.isUnresolved(props.matchmakingConfigurationName)) {\n      if (props.matchmakingConfigurationName.length > 128) {\n        throw new Error(`Matchmaking configuration name can not be longer than 128 characters but has ${props.matchmakingConfigurationName.length} characters.`);\n      }\n\n      if (!/^[a-zA-Z0-9-\\.]+$/.test(props.matchmakingConfigurationName)) {\n        throw new Error(`Matchmaking configuration name ${props.matchmakingConfigurationName} can contain only letters, numbers, hyphens, back slash or dot with no spaces.`);\n      }\n    }\n\n    if (props.description && !cdk.Token.isUnresolved(props.description)) {\n      if (props.description.length > 1024) {\n        throw new Error(`Matchmaking configuration description can not be longer than 1024 characters but has ${props.description.length} characters.`);\n      }\n    }\n\n    if (props.gameProperties && props.gameProperties.length > 16) {\n      throw new Error(`The maximum number of game properties allowed in the matchmaking configuration cannot be higher than 16, given ${props.gameProperties.length}`);\n    }\n\n    if (props.gameSessionData && props.gameSessionData.length > 4096) {\n      throw new Error(`Matchmaking configuration game session data can not be longer than 4096 characters but has ${props.gameSessionData.length} characters.`);\n    }\n\n    if (props.customEventData && props.customEventData.length > 256) {\n      throw new Error(`Matchmaking configuration custom event data can not be longer than 256 characters but has ${props.customEventData.length} characters.`);\n    }\n\n    if (props.acceptanceTimeout && props.acceptanceTimeout.toSeconds() > 600) {\n      throw new Error(`Matchmaking configuration acceptance timeout can not exceed 600 seconds, actual ${props.acceptanceTimeout.toSeconds()} seconds.`);\n    }\n\n    if (props.requestTimeout && props.requestTimeout.toSeconds() > 43200) {\n      throw new Error(`Matchmaking configuration request timeout can not exceed 43200 seconds, actual ${props.requestTimeout.toSeconds()} seconds.`);\n    }\n\n    // Notification target\n    this.notificationTarget = props.notificationTarget;\n    if (!this.notificationTarget) {\n      this.notificationTarget = new sns.Topic(this, 'Topic', {});\n    }\n    // Be sure to add the right TopicPolicy to enable gamelift publish action to given topic\n    const topicPolicy = new sns.TopicPolicy(this, 'TopicPolicy', {\n      topics: [this.notificationTarget],\n    });\n    topicPolicy.document.addStatements(new iam.PolicyStatement({\n      actions: ['sns:Publish'],\n      principals: [new iam.ServicePrincipal('gamelift.amazonaws.com')],\n      resources: [this.notificationTarget.topicArn],\n    }));\n\n    // Add all queues\n    (props.gameSessionQueues || []).forEach(this.addGameSessionQueue.bind(this));\n\n    const resource = new gamelift.CfnMatchmakingConfiguration(this, 'Resource', {\n      name: this.physicalName,\n      acceptanceRequired: Boolean(props.requireAcceptance),\n      acceptanceTimeoutSeconds: props.acceptanceTimeout && props.acceptanceTimeout.toSeconds(),\n      additionalPlayerCount: props.additionalPlayerCount,\n      backfillMode: props.manualBackfillMode ? 'MANUAL' : 'AUTOMATIC',\n      customEventData: props.customEventData,\n      description: props.description,\n      flexMatchMode: 'WITH_QUEUE',\n      gameProperties: this.parseGameProperties(props),\n      gameSessionData: props.gameSessionData,\n      gameSessionQueueArns: cdk.Lazy.list({ produce: () => this.parseGameSessionQueues() }),\n      notificationTarget: this.notificationTarget.topicArn,\n      requestTimeoutSeconds: props.requestTimeout && props.requestTimeout.toSeconds() || cdk.Duration.seconds(300).toSeconds(),\n      ruleSetName: props.ruleSet.matchmakingRuleSetName,\n    });\n\n    this.matchmakingConfigurationName = this.getResourceNameAttribute(resource.ref);\n    this.matchmakingConfigurationArn = cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'matchmakingconfiguration',\n      resourceName: this.matchmakingConfigurationName,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n  }\n\n  /**\n   * Adds a game session queue destination to the matchmaking configuration.\n   *\n   * @param gameSessionQueue A game session queue\n   */\n  @MethodMetadata()\n  public addGameSessionQueue(gameSessionQueue: IGameSessionQueue) {\n    this.gameSessionQueues.push(gameSessionQueue);\n  }\n\n  private parseGameSessionQueues(): string[] | undefined {\n    if (!this.gameSessionQueues || this.gameSessionQueues.length === 0) {\n      return undefined;\n    }\n\n    return this.gameSessionQueues.map((queue) => queue.gameSessionQueueArn);\n  }\n\n  private parseGameProperties(props: QueuedMatchmakingConfigurationProps): gamelift.CfnMatchmakingConfiguration.GamePropertyProperty[] | undefined {\n    if (!props.gameProperties || props.gameProperties.length === 0) {\n      return undefined;\n    }\n\n    return props.gameProperties.map(parseGameProperty);\n\n    function parseGameProperty(gameProperty: GameProperty): gamelift.CfnMatchmakingConfiguration.GamePropertyProperty {\n      return {\n        key: gameProperty.key,\n        value: gameProperty.value,\n      };\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ECS, CloudMap (Service Discovery) resources", "output": "export class SplitAtTargetGroup_ServiceStack extends Stack {\n  constructor(scope: Construct, id: string, props: SplitAtTargetGroup_ServiceStackProps) {\n    super(scope, id, props);\n\n    // Standard ECS service setup\n    const taskDefinition = new ecs.FargateTaskDefinition(this, 'TaskDef');\n    const container = taskDefinition.addContainer('web', {\n      image: ecs.ContainerImage.fromRegistry(\"amazon/amazon-ecs-sample\"),\n      memoryLimitMiB: 256,\n    });\n\n    container.addPortMappings({\n      containerPort: 80,\n      protocol: ecs.Protocol.TCP\n    });\n\n    const service = new ecs.FargateService(this, \"Service\", {\n      cluster: props.cluster,\n      taskDefinition,\n    });\n\n    // Connect service to TargetGroup\n    // NOTE: This does not introduce a cycle because ECS Services are self-registering\n    // (they point to the TargetGroup instead of the other way around).\n    props.targetGroup.addTarget(service);\n  }\n}", "language": "typescript"}
{"input": "The type of resource to create the flow log for", "output": "class FlowLogResourceType {\n  /**\n   * The subnet to attach the Flow Log to\n   */\n  public static fromSubnet(subnet: ISubnetRef): FlowLogResourceType {\n    return {\n      resourceType: 'Subnet',\n      resourceId: subnet.subnetRef.subnetId,\n    };\n  }\n\n  /**\n   * The VPC to attach the Flow Log to\n   */\n  public static fromVpc(vpc: IVpc): FlowLogResourceType {\n    return {\n      resourceType: 'VPC',\n      resourceId: vpc.vpcId,\n    };\n  }\n\n  /**\n   * The Network Interface to attach the Flow Log to\n   */\n  public static fromNetworkInterfaceId(id: string): FlowLogResourceType {\n    return {\n      resourceType: 'NetworkInterface',\n      resourceId: id,\n    };\n  }\n\n  /**\n   * The Transit Gateway to attach the Flow Log to\n   */\n  public static fromTransitGatewayId(id: string): FlowLogResourceType {\n    return {\n      resourceType: 'TransitGateway',\n      resourceId: id,\n    };\n  }\n\n  /**\n   * The Transit Gateway Attachment to attach the Flow Log to\n   */\n  public static fromTransitGatewayAttachmentId(id: string): FlowLogResourceType {\n    return {\n      resourceType: 'TransitGatewayAttachment',\n      resourceId: id,\n    };\n  }\n\n  /**\n   * The type of resource to attach a flow log to.\n   */\n  public abstract resourceType: string;\n\n  /**\n   * The Id of the resource that the flow log should be attached to.\n   */\n  public abstract resourceId: string;\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, WAF resources", "output": "class Ec2CloudwatchStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # The code from zhxinyua to create VPC, s3_endpoint, bastion, EC2, EBS, Cloudwatch event rule stop EC2, Backup for EC2\n\n        # create a new VPC\n        vpc_new = aws_ec2.Vpc(self, \"VpcFromCDK\", cidr=\"10.0.0.0/16\")\n        vpc_new.add_gateway_endpoint(\"S3Endpoint\",\n            service=aws_ec2.GatewayVpcEndpointAwsService.S3,\n            # Add only to ISOLATED subnets\n            subnets=[aws_ec2.SubnetSelection(subnet_type=aws_ec2.SubnetType.PUBLIC)\n            ]\n        )\n\n        # only allow a specific rang of IP to conncet bastion\n        # BastionHostLinux support two way to connect, one is SSM, second is EC2 Instance Connect\n        # EC2 Instance Connect are not supportd in CN\n        host_bastion = aws_ec2.BastionHostLinux(self, \"BastionHost\",\n                                                vpc=vpc_new,\n                                                subnet_selection=aws_ec2.SubnetSelection(subnet_type=aws_ec2.SubnetType.PUBLIC)\n                                                )\n\n        # write your own IP rang to access this bastion instead of 1.2.3.4/32\n        host_bastion.allow_ssh_access_from(aws_ec2.Peer.ipv4(\"1.2.3.4/32\"))\n\n        # use amazon linux as OS\n        amzn_linux = aws_ec2.MachineImage.latest_amazon_linux(generation=aws_ec2.AmazonLinuxGeneration.AMAZON_LINUX,\n                                                              edition=aws_ec2.AmazonLinuxEdition.STANDARD,\n                                                              virtualization=aws_ec2.AmazonLinuxVirt.HVM,\n                                                              storage=aws_ec2.AmazonLinuxStorage.GENERAL_PURPOSE)\n\n        # secure group\n        my_security_group = aws_ec2.SecurityGroup(self, \"SecurityGroup\",\n                                                  vpc=vpc_new,\n                                                  description=\"SecurityGroup from CDK\",\n                                                  security_group_name=\"CDK SecurityGroup\",\n                                                  allow_all_outbound=True,\n                                                  )\n\n        my_security_group.add_ingress_rule(aws_ec2.Peer.ipv4('10.0.0.0/16'), aws_ec2.Port.tcp(22), \"allow ssh access from the VPC\")\n\n        # set up an web instance in public subnet\n        work_server = aws_ec2.Instance(self, \"WebInstance\",\n                                       instance_type=aws_ec2.InstanceType(\"Write a EC2 instance type\"),\n                                       machine_image=amzn_linux,\n                                       vpc=vpc_new,\n                                       vpc_subnets=aws_ec2.SubnetSelection(subnet_type=aws_ec2.SubnetType.PUBLIC),\n                                       security_group=my_security_group,\n                                       key_name=\"Your SSH key pair name\")\n\n        # allow web connect\n        work_server.connections.allow_from_any_ipv4(aws_ec2.Port.tcp(80), \"allow http from world\")\n        work_server.connections.allow_from_any_ipv4(aws_ec2.Port.tcp(443), \"allow https from world\")\n\n        # set a second ebs to web instance\n        work_server.instance.add_property_override(\"BlockDeviceMappings\", [{\n            \"DeviceName\": \"/dev/sdb\",\n            \"Ebs\": {\"VolumeSize\": \"30\",\n                    \"VolumeType\": \"gp2\",\n                    \"DeleteOnTermination\": \"true\"}\n        }])\n\n        # Cloudwatch event rule to stop instances every day in 15:00 UTC\n        # they only use javascript SDK to call AWS API\n        # https://docs.aws.amazon.com/cdk/api/latest/python/aws_cdk.aws_events_targets/AwsApi.html\n        stop_EC2 = AwsApi(service=\"EC2\",\n                          action=\"stopInstances\",\n                          parameters={\"InstanceIds\": [work_server.instance_id, host_bastion.instance_id]})\n\n        Rule(self, \"ScheduleRule\", schedule=Schedule.cron(minute=\"0\", hour=\"15\"), targets=[stop_EC2])\n\n        # AWS backup part\n        # create a BackupVault\n        vault = backup.BackupVault(self, \"BackupVault\", backup_vault_name=\"CDK_Backup_Vault\")\n\n        # create a BackupPlan\n        plan = backup.BackupPlan(self, \"AWS-Backup-Plan\", backup_plan_name=\"CDK_Backup\")\n\n        # add buackup resources with two way for two resources\n        plan.add_selection(\"Selection\", resources=[\n            backup.BackupResource.from_ec2_instance(work_server),\n            backup.BackupResource.from_tag(\"Name\", \"BastionHost\")\n        ])\n\n        # details with backup rules\n        plan.add_rule(backup.BackupPlanRule(backup_vault=vault,\n                                            rule_name=\"CDK_Backup_Rule\",\n                                            schedule_expression=Schedule.cron(minute=\"0\", hour=\"16\", day=\"1\", month=\"1-12\"),\n                                            delete_after=Duration.days(130),\n                                            move_to_cold_storage_after=Duration.days(10)))\n\n        # output information after deploy\n        output = CfnOutput(self, \"BastionHost_information\",\n                                value=host_bastion.instance_public_ip,\n                                description=\"BastionHost's Public IP\")\n        output = CfnOutput(self, \"WebHost_information\",\n                                value=work_server.instance_public_ip,\n                                description=\"Web server's Public IP\")", "language": "python"}
{"input": "CDK class Application for AWS resource management", "output": "export class Application extends ApplicationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appconfig.Application';\n\n  /**\n   * Imports an AWS AppConfig application into the CDK using its Amazon Resource Name (ARN).\n   *\n   * @param scope The parent construct\n   * @param id The name of the application construct\n   * @param applicationArn The Amazon Resource Name (ARN) of the application\n   */\n  public static fromApplicationArn(scope: Construct, id: string, applicationArn: string): IApplication {\n    const parsedArn = cdk.Stack.of(scope).splitArn(applicationArn, cdk.ArnFormat.SLASH_RESOURCE_NAME);\n    const applicationId = parsedArn.resourceName;\n    if (!applicationId) {\n      throw new cdk.ValidationError('Missing required application id from application ARN', scope);\n    }\n\n    class Import extends ApplicationBase {\n      public readonly applicationId = applicationId!;\n      public readonly applicationArn = applicationArn;\n      protected readonly extensible = new ExtensibleBase(scope, this.applicationArn);\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Imports an AWS AppConfig application into the CDK using its ID.\n   *\n   * @param scope The parent construct\n   * @param id The name of the application construct\n   * @param applicationId The ID of the application\n   */\n  public static fromApplicationId(scope: Construct, id: string, applicationId: string): IApplication {\n    const stack = cdk.Stack.of(scope);\n    const applicationArn = stack.formatArn({\n      service: 'appconfig',\n      resource: 'application',\n      resourceName: applicationId,\n    });\n\n    class Import extends ApplicationBase {\n      public readonly applicationId = applicationId;\n      public readonly applicationArn = applicationArn;\n      protected readonly extensible = new ExtensibleBase(scope, this.applicationArn);\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Retrieves the Lambda layer version Amazon Resource Name (ARN) for the AWS AppConfig Lambda extension.\n   *\n   * @param region The region for the Lambda layer (for example, 'us-east-1')\n   * @param platform The platform for the Lambda layer (default is Platform.X86_64)\n   * @returns Lambda layer version ARN\n   */\n  public static getLambdaLayerVersionArn(region: string, platform?: Platform): string {\n    return lambdaLayerVersions[platform || Platform.X86_64][region];\n  }\n\n  /**\n   * Adds the AWS AppConfig Agent as a container to the provided ECS task definition.\n   *\n   * @param taskDef The ECS task definition [disable-awslint:ref-via-interface]\n   */\n  public static addAgentToEcs(taskDef: ecs.TaskDefinition) {\n    taskDef.addContainer('AppConfigAgentContainer', {\n      image: ecs.ContainerImage.fromRegistry('public.ecr.aws/aws-appconfig/aws-appconfig-agent:latest'),\n      containerName: 'AppConfigAgentContainer',\n    });\n  }\n\n  /**\n   * The description of the application.\n   */\n  public readonly description?: string;\n\n  /**\n   * The name of the application.\n   */\n  public readonly name?: string;\n\n  /**\n   * The ID of the application.\n   *\n   * @attribute\n   */\n  public readonly applicationId: string;\n\n  /**\n   * The Amazon Resource Name (ARN) of the application.\n   *\n   * @attribute\n   */\n  public readonly applicationArn: string;\n\n  private _application: CfnApplication;\n  protected extensible: ExtensibleBase;\n\n  constructor(scope: Construct, id: string, props: ApplicationProps = {}) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.description = props.description;\n    this.name = props.applicationName || cdk.Names.uniqueResourceName(this, {\n      maxLength: 64,\n      separator: '-',\n    });\n\n    this._application = new CfnApplication(this, 'Resource', {\n      name: this.name,\n      description: this.description,\n    });\n    this.applicationId = this._application.ref;\n    this.applicationArn = cdk.Stack.of(this).formatArn({\n      service: 'appconfig',\n      resource: 'application',\n      resourceName: this.applicationId,\n    });\n\n    this.extensible = new ExtensibleBase(this, this.applicationArn, this.name);\n  }\n}", "language": "typescript"}
{"input": "CDK class Stage for AWS resource management", "output": "export class Stage extends StageBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.Stage';\n\n  /**\n   * Import a Stage by its attributes\n   */\n  public static fromStageAttributes(scope: Construct, id: string, attrs: StageAttributes): IStage {\n    class Import extends StageBase {\n      public readonly stageName = attrs.stageName;\n      public readonly restApi = attrs.restApi;\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly stageName: string;\n  public readonly restApi: IRestApi;\n\n  private enableCacheCluster?: boolean;\n\n  constructor(scope: Construct, id: string, props: StageProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.enableCacheCluster = props.cacheClusterEnabled;\n\n    const methodSettings = this.renderMethodSettings(props); // this can mutate `this.cacheClusterEnabled`\n\n    // custom access logging\n    let accessLogSetting: CfnStage.AccessLogSettingProperty | undefined;\n    const accessLogDestination = props.accessLogDestination;\n    const accessLogFormat = props.accessLogFormat;\n    if (!accessLogDestination && !accessLogFormat) {\n      accessLogSetting = undefined;\n    } else {\n      if (accessLogFormat !== undefined &&\n        !Token.isUnresolved(accessLogFormat.toString()) &&\n        !/.*\\$context.(requestId|extendedRequestId)\\b.*/.test(accessLogFormat.toString())) {\n        throw new ValidationError('Access log must include either `AccessLogFormat.contextRequestId()` or `AccessLogFormat.contextExtendedRequestId()`', this);\n      }\n      if (accessLogFormat !== undefined && accessLogDestination === undefined) {\n        throw new ValidationError('Access log format is specified without a destination', this);\n      }\n\n      accessLogSetting = {\n        destinationArn: accessLogDestination?.bind(this).destinationArn,\n        format: accessLogFormat?.toString() ? accessLogFormat?.toString() : AccessLogFormat.clf().toString(),\n      };\n    }\n\n    // enable cache cluster if cacheClusterSize is set\n    if (props.cacheClusterSize !== undefined) {\n      if (this.enableCacheCluster === undefined) {\n        this.enableCacheCluster = true;\n      } else if (this.enableCacheCluster === false) {\n        throw new ValidationError(`Cannot set \"cacheClusterSize\" to ${props.cacheClusterSize} and \"cacheClusterEnabled\" to \"false\"`, this);\n      }\n    }\n\n    const cacheClusterSize = this.enableCacheCluster ? (props.cacheClusterSize || '0.5') : undefined;\n    const resource = new CfnStage(this, 'Resource', {\n      stageName: props.stageName || 'prod',\n      accessLogSetting,\n      cacheClusterEnabled: this.enableCacheCluster,\n      cacheClusterSize,\n      clientCertificateId: props.clientCertificateId,\n      deploymentId: props.deployment.deploymentId,\n      restApiId: props.deployment.api.restApiId,\n      description: props.description,\n      documentationVersion: props.documentationVersion,\n      variables: props.variables,\n      tracingEnabled: props.tracingEnabled,\n      methodSettings,\n    });\n\n    this.stageName = resource.ref;\n    this.restApi = props.deployment.api;\n\n    if (RestApiBase._isRestApiBase(this.restApi)) {\n      this.restApi._attachStage(this);\n    }\n  }\n\n  private renderMethodSettings(props: StageProps): CfnStage.MethodSettingProperty[] | undefined {\n    const settings = new Array<CfnStage.MethodSettingProperty>();\n    const self = this;\n\n    // extract common method options from the stage props\n    const commonMethodOptions: MethodDeploymentOptions = {\n      metricsEnabled: props.metricsEnabled,\n      loggingLevel: props.loggingLevel,\n      dataTraceEnabled: props.dataTraceEnabled,\n      throttlingBurstLimit: props.throttlingBurstLimit,\n      throttlingRateLimit: props.throttlingRateLimit,\n      cachingEnabled: props.cachingEnabled,\n      cacheTtl: props.cacheTtl,\n      cacheDataEncrypted: props.cacheDataEncrypted,\n    };\n\n    // if any of them are defined, add an entry for '/*/*'.\n    const hasCommonOptions = Object.keys(commonMethodOptions).map(v => (commonMethodOptions as any)[v]).filter(x => x !== undefined).length > 0;\n    if (hasCommonOptions) {\n      settings.push(renderEntry('/*/*', commonMethodOptions));\n    }\n\n    if (props.methodOptions) {\n      for (const path of Object.keys(props.methodOptions)) {\n        settings.push(renderEntry(path, props.methodOptions[path]));\n      }\n    }\n\n    return settings.length === 0 ? undefined : settings;\n\n    function renderEntry(path: string, options: MethodDeploymentOptions): CfnStage.MethodSettingProperty {\n      if (options.cachingEnabled) {\n        if (self.enableCacheCluster === undefined) {\n          self.enableCacheCluster = true;\n        } else if (self.enableCacheCluster === false) {\n          throw new ValidationError(`Cannot enable caching for method ${path} since cache cluster is disabled on stage`, self);\n        }\n      }\n\n      const { httpMethod, resourcePath } = parseMethodOptionsPath(path);\n\n      return {\n        httpMethod,\n        resourcePath,\n        cacheDataEncrypted: options.cacheDataEncrypted,\n        cacheTtlInSeconds: options.cacheTtl && options.cacheTtl.toSeconds(),\n        cachingEnabled: options.cachingEnabled,\n        dataTraceEnabled: options.dataTraceEnabled ?? false,\n        loggingLevel: options.loggingLevel,\n        metricsEnabled: options.metricsEnabled,\n        throttlingBurstLimit: options.throttlingBurstLimit,\n        throttlingRateLimit: options.throttlingRateLimit,\n      };\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class UsagePlan for AWS resource management", "output": "export class UsagePlan extends UsagePlanBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.UsagePlan';\n\n  /**\n   * Import an externally defined usage plan using its ARN.\n   *\n   * @param scope  the construct that will \"own\" the imported usage plan.\n   * @param id     the id of the imported usage plan in the construct tree.\n   * @param usagePlanId the id of an existing usage plan.\n   */\n  public static fromUsagePlanId(scope: Construct, id: string, usagePlanId: string): IUsagePlan {\n    class Import extends UsagePlanBase {\n      public readonly usagePlanId = usagePlanId;\n\n      constructor() {\n        super(scope, id);\n      }\n    }\n    return new Import();\n  }\n\n  /**\n   * @attribute\n   */\n  public readonly usagePlanId: string;\n\n  private readonly apiStages = new Array<UsagePlanPerApiStage>();\n\n  constructor(scope: Construct, id: string, props: UsagePlanProps = { }) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    let resource: CfnUsagePlan;\n\n    resource = new CfnUsagePlan(this, 'Resource', {\n      apiStages: Lazy.any({ produce: () => this.renderApiStages(this.apiStages) }),\n      description: props.description,\n      quota: this.renderQuota(props),\n      throttle: this.renderThrottle(props.throttle),\n      usagePlanName: props.name,\n    });\n\n    this.apiStages.push(...(props.apiStages || []));\n\n    this.usagePlanId = resource.ref;\n\n    // Add ApiKey when\n    if (props.apiKey) {\n      this.addApiKey(props.apiKey);\n    }\n  }\n\n  /**\n   * Adds an apiStage.\n   */\n  @MethodMetadata()\n  public addApiStage(apiStage: UsagePlanPerApiStage) {\n    this.apiStages.push(apiStage);\n  }\n\n  private renderApiStages(apiStages: UsagePlanPerApiStage[] | undefined): CfnUsagePlan.ApiStageProperty[] | undefined {\n    if (apiStages && apiStages.length > 0) {\n      const stages: CfnUsagePlan.ApiStageProperty[] = [];\n      apiStages.forEach((apiStage: UsagePlanPerApiStage) => {\n        stages.push(this.createStage(apiStage));\n      });\n      return stages;\n    }\n    return undefined;\n  }\n\n  private createStage(apiStage: UsagePlanPerApiStage): CfnUsagePlan.ApiStageProperty {\n    const stage = apiStage.stage ? apiStage.stage.stageName.toString() : undefined;\n    const apiId = apiStage.stage ? apiStage.stage.restApi.restApiId : undefined;\n    const throttle = this.renderThrottlePerMethod(apiStage.throttle);\n    return {\n      apiId,\n      stage,\n      throttle,\n    };\n  }\n\n  private renderQuota(props: UsagePlanProps) {\n    if (props.quota === undefined) {\n      return undefined;\n    } else {\n      const limit = props.quota ? props.quota.limit : undefined;\n      validateInteger(limit, 'Throttle quota limit');\n      const ret = {\n        limit: limit ? limit : undefined,\n        offset: props.quota ? props.quota.offset : undefined,\n        period: props.quota ? props.quota.period : undefined,\n      };\n      return ret;\n    }\n  }\n\n  private renderThrottle(props: ThrottleSettings | undefined): (CfnUsagePlan.ThrottleSettingsProperty | Token) {\n    let ret: CfnUsagePlan.ThrottleSettingsProperty | Token;\n    if (props !== undefined) {\n      const burstLimit = props.burstLimit;\n      validateInteger(burstLimit, 'Throttle burst limit');\n      const rateLimit = props.rateLimit;\n      validateDouble(rateLimit, 'Throttle rate limit');\n\n      ret = {\n        burstLimit: burstLimit,\n        rateLimit: rateLimit,\n      };\n    }\n    return ret!;\n  }\n\n  private renderThrottlePerMethod(throttlePerMethod?: ThrottlingPerMethod[]) {\n    const ret: { [key: string]: (CfnUsagePlan.ThrottleSettingsProperty | Token) } = {};\n    if (throttlePerMethod && throttlePerMethod.length > 0) {\n      throttlePerMethod.forEach((value: ThrottlingPerMethod) => {\n        const method: Method = value.method;\n        // this methodId is resource path and method for example /GET or /pets/GET\n        const methodId = `${method.resource.path}/${method.httpMethod}`;\n        ret[methodId] = this.renderThrottle(value.throttle);\n      });\n    }\n    return ret;\n  }\n}", "language": "typescript"}
{"input": "Possible Instances Types to use in Neptune cluster used for defining `DatabaseInstanceProps.instanceType`.", "output": "export class InstanceType {\n  /**\n   * db.x2g.large\n   */\n  public static readonly X2G_LARGE = InstanceType.of('db.x2g.large');\n\n  /**\n   * db.x2g.xlarge\n   */\n  public static readonly X2G_XLARGE = InstanceType.of('db.x2g.xlarge');\n\n  /**\n   * db.x2g.2xlarge\n   */\n  public static readonly X2G_2XLARGE = InstanceType.of('db.x2g.2xlarge');\n\n  /**\n   * db.x2g.4xlarge\n   */\n  public static readonly X2G_4XLARGE = InstanceType.of('db.x2g.4xlarge');\n\n  /**\n   * db.x2g.8xlarge\n   */\n  public static readonly X2G_8XLARGE = InstanceType.of('db.x2g.8xlarge');\n\n  /**\n   * db.x2g.12xlarge\n   */\n  public static readonly X2G_12XLARGE = InstanceType.of('db.x2g.12xlarge');\n\n  /**\n   * db.x2g.16xlarge\n   */\n  public static readonly X2G_16XLARGE = InstanceType.of('db.x2g.16xlarge');\n\n  /**\n   * db.x2iedn.xlarge\n   */\n  public static readonly X2IEDN_XLARGE = InstanceType.of('db.x2iedn.xlarge');\n\n  /**\n   * db.x2iedn.2xlarge\n   */\n  public static readonly X2IEDN_2XLARGE = InstanceType.of('db.x2iedn.2xlarge');\n\n  /**\n   * db.x2iedn.4xlarge\n   */\n  public static readonly X2IEDN_4XLARGE = InstanceType.of('db.x2iedn.4xlarge');\n\n  /**\n   * db.x2iedn.8xlarge\n   */\n  public static readonly X2IEDN_8XLARGE = InstanceType.of('db.x2iedn.8xlarge');\n\n  /**\n   * db.x2iedn.16xlarge\n   */\n  public static readonly X2IEDN_16XLARGE = InstanceType.of('db.x2iedn.16xlarge');\n\n  /**\n   * db.x2iedn.24xlarge\n   */\n  public static readonly X2IEDN_24XLARGE = InstanceType.of('db.x2iedn.24xlarge');\n\n  /**\n   * db.x2iedn.32xlarge\n   */\n  public static readonly X2IEDN_32XLARGE = InstanceType.of('db.x2iedn.32xlarge');\n\n  /**\n   * db.r6g.large\n   */\n  public static readonly R6G_LARGE = InstanceType.of('db.r6g.large');\n\n  /**\n   * db.r6g.xlarge\n   */\n  public static readonly R6G_XLARGE = InstanceType.of('db.r6g.xlarge');\n\n  /**\n   * db.r6g.2xlarge\n   */\n  public static readonly R6G_2XLARGE = InstanceType.of('db.r6g.2xlarge');\n\n  /**\n   * db.r6g.4xlarge\n   */\n  public static readonly R6G_4XLARGE = InstanceType.of('db.r6g.4xlarge');\n\n  /**\n   * db.r6g.8xlarge\n   */\n  public static readonly R6G_8XLARGE = InstanceType.of('db.r6g.8xlarge');\n\n  /**\n   * db.r6g.12xlarge\n   */\n  public static readonly R6G_12XLARGE = InstanceType.of('db.r6g.12xlarge');\n\n  /**\n   * db.r6g.16xlarge\n   */\n  public static readonly R6G_16XLARGE = InstanceType.of('db.r6g.16xlarge');\n\n  /**\n   * db.r6i.large\n   */\n  public static readonly R6I_LARGE = InstanceType.of('db.r6i.large');\n\n  /**\n   * db.r6i.xlarge\n   */\n  public static readonly R6I_XLARGE = InstanceType.of('db.r6i.xlarge');\n\n  /**\n   * db.r6i.2xlarge\n   */\n  public static readonly R6I_2XLARGE = InstanceType.of('db.r6i.2xlarge');\n\n  /**\n   * db.r6i.4xlarge\n   */\n  public static readonly R6I_4XLARGE = InstanceType.of('db.r6i.4xlarge');\n\n  /**\n   * db.r6i.8xlarge\n   */\n  public static readonly R6I_8XLARGE = InstanceType.of('db.r6i.8xlarge');\n\n  /**\n   * db.r6i.12xlarge\n   */\n  public static readonly R6I_12XLARGE = InstanceType.of('db.r6i.12xlarge');\n\n  /**\n   * db.r6i.16xlarge\n   */\n  public static readonly R6I_16XLARGE = InstanceType.of('db.r6i.16xlarge');\n\n  /**\n   * db.r6i.24xlarge\n   */\n  public static readonly R6I_24XLARGE = InstanceType.of('db.r6i.24xlarge');\n\n  /**\n   * db.r6i.32xlarge\n   */\n  public static readonly R6I_32XLARGE = InstanceType.of('db.r6i.32xlarge');\n\n  /**\n   * db.r5.large\n   */\n  public static readonly R5_LARGE = InstanceType.of('db.r5.large');\n\n  /**\n   * db.r5.xlarge\n   */\n  public static readonly R5_XLARGE = InstanceType.of('db.r5.xlarge');\n\n  /**\n   * db.r5.2xlarge\n   */\n  public static readonly R5_2XLARGE = InstanceType.of('db.r5.2xlarge');\n\n  /**\n   * db.r5.4xlarge\n   */\n  public static readonly R5_4XLARGE = InstanceType.of('db.r5.4xlarge');\n\n  /**\n   * db.r5.8xlarge\n   */\n  public static readonly R5_8XLARGE = InstanceType.of('db.r5.8xlarge');\n\n  /**\n   * db.r5.12xlarge\n   */\n  public static readonly R5_12XLARGE = InstanceType.of('db.r5.12xlarge');\n\n  /**\n   * db.r5.16xlarge\n   */\n  public static readonly R5_16XLARGE = InstanceType.of('db.r5.16xlarge');\n\n  /**\n   * db.r5.24xlarge\n   */\n  public static readonly R5_24XLARGE = InstanceType.of('db.r5.24xlarge');\n\n  /**\n   * db.r5d.large\n   */\n  public static readonly R5D_LARGE = InstanceType.of('db.r5d.large');\n\n  /**\n   * db.r5d.xlarge\n   */\n  public static readonly R5D_XLARGE = InstanceType.of('db.r5d.xlarge');\n\n  /**\n   * db.r5d.2xlarge\n   */\n  public static readonly R5D_2XLARGE = InstanceType.of('db.r5d.2xlarge');\n\n  /**\n   * db.r5d.4xlarge\n   */\n  public static readonly R5D_4XLARGE = InstanceType.of('db.r5d.4xlarge');\n\n  /**\n   * db.r5d.8xlarge\n   */\n  public static readonly R5D_8XLARGE = InstanceType.of('db.r5d.8xlarge');\n\n  /**\n   * db.r5d.12xlarge\n   */\n  public static readonly R5D_12XLARGE = InstanceType.of('db.r5d.12xlarge');\n\n  /**\n   * db.r5d.16xlarge\n   */\n  public static readonly R5D_16XLARGE = InstanceType.of('db.r5d.16xlarge');\n\n  /**\n   * db.r5d.24xlarge\n   */\n  public static readonly R5D_24XLARGE = InstanceType.of('db.r5d.24xlarge');\n\n  /**\n   * db.r4.large\n   */\n  public static readonly R4_LARGE = InstanceType.of('db.r4.large');\n\n  /**\n   * db.r4.xlarge\n   */\n  public static readonly R4_XLARGE = InstanceType.of('db.r4.xlarge');\n\n  /**\n   * db.r4.2xlarge\n   */\n  public static readonly R4_2XLARGE = InstanceType.of('db.r4.2xlarge');\n\n  /**\n   * db.r4.4xlarge\n   */\n  public static readonly R4_4XLARGE = InstanceType.of('db.r4.4xlarge');\n\n  /**\n   * db.r4.8xlarge\n   */\n  public static readonly R4_8XLARGE = InstanceType.of('db.r4.8xlarge');\n\n  /**\n   * db.t4g.medium\n   */\n  public static readonly T4G_MEDIUM = InstanceType.of('db.t4g.medium');\n\n  /**\n   * db.t3.medium\n   */\n  public static readonly T3_MEDIUM = InstanceType.of('db.t3.medium');\n\n  /**\n   * db.serverless\n   */\n  public static readonly SERVERLESS = InstanceType.of('db.serverless');\n\n  /**\n   * Build an InstanceType from given string or token, such as CfnParameter.\n   */\n  public static of(instanceType: string): InstanceType {\n    return new InstanceType(instanceType);\n  }\n\n  /**\n   * @internal\n   */\n  readonly _instanceType: string;\n\n  private constructor(instanceType: string) {\n    if (cdk.Token.isUnresolved(instanceType) || instanceType.startsWith('db.')) {\n      this._instanceType = instanceType;\n    } else {\n      throw new cdk.UnscopedValidationError(`instance type must start with 'db.'; (got ${instanceType})`);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomRule for AWS resource management", "output": "export class CustomRule extends RuleNew {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.CustomRule';\n  /** @attribute */\n  public readonly configRuleName: string;\n\n  /** @attribute */\n  public readonly configRuleArn: string;\n\n  /** @attribute */\n  public readonly configRuleId: string;\n\n  /** @attribute */\n  public readonly configRuleComplianceType: string;\n\n  constructor(scope: Construct, id: string, props: CustomRuleProps) {\n    super(scope, id, {\n      physicalName: props.configRuleName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (!props.configurationChanges && !props.periodic) {\n      throw new ValidationError('At least one of `configurationChanges` or `periodic` must be set to true.', this);\n    }\n\n    const sourceDetails: SourceDetail[] = [];\n    this.ruleScope = props.ruleScope;\n    if (props.configurationChanges) {\n      sourceDetails.push({\n        eventSource: EventSource.AWS_CONFIG,\n        messageType: MessageType.CONFIGURATION_ITEM_CHANGE_NOTIFICATION,\n      });\n      sourceDetails.push({\n        eventSource: EventSource.AWS_CONFIG,\n        messageType: MessageType.OVERSIZED_CONFIGURATION_ITEM_CHANGE_NOTIFICATION,\n      });\n    }\n\n    if (props.periodic) {\n      sourceDetails.push({\n        eventSource: EventSource.AWS_CONFIG,\n        maximumExecutionFrequency: props.maximumExecutionFrequency,\n        messageType: MessageType.SCHEDULED_NOTIFICATION,\n      });\n    }\n    const hash = createHash('sha256')\n      .update(JSON.stringify({\n        /* eslint-disable-next-line @typescript-eslint/unbound-method *//* REMOVEME: this is a latent bug */\n        fnName: props.lambdaFunction.functionName.toString,\n        accountId: Stack.of(this).resolve(this.env.account),\n        region: Stack.of(this).resolve(this.env.region),\n      }), 'utf8')\n      .digest('base64');\n    const customRulePermissionId: string = `CustomRulePermission${hash}`;\n    if (!props.lambdaFunction.permissionsNode.tryFindChild(customRulePermissionId)) {\n      props.lambdaFunction.addPermission(customRulePermissionId, {\n        principal: new iam.ServicePrincipal('config.amazonaws.com'),\n        sourceAccount: this.env.account,\n      });\n    }\n\n    if (props.lambdaFunction.role) {\n      props.lambdaFunction.role.addManagedPolicy(\n        iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/AWSConfigRulesExecutionRole'),\n      );\n    }\n\n    // The lambda permission must be created before the rule\n    this.node.addDependency(props.lambdaFunction);\n\n    const rule = new CfnConfigRule(this, 'Resource', {\n      configRuleName: this.physicalName,\n      description: props.description,\n      inputParameters: props.inputParameters,\n      maximumExecutionFrequency: props.maximumExecutionFrequency,\n      scope: Lazy.any({ produce: () => renderScope(this.ruleScope) }), // scope can use values such as stack id (see CloudFormationStackDriftDetectionCheck)\n      source: {\n        owner: 'CUSTOM_LAMBDA',\n        sourceDetails,\n        sourceIdentifier: props.lambdaFunction.functionArn,\n      },\n      evaluationModes: props.evaluationModes?.modes.map((mode) => ({\n        mode,\n      })),\n    });\n\n    this.configRuleName = rule.ref;\n    this.configRuleArn = rule.attrArn;\n    this.configRuleId = rule.attrConfigRuleId;\n    this.configRuleComplianceType = rule.attrComplianceType;\n\n    if (props.configurationChanges) {\n      this.isCustomWithChanges = true;\n    }\n  }\n}", "language": "typescript"}
{"input": "Test for importing an existing namespace", "output": "class ImportedNamespaceStack extends core.Stack {\n  public readonly namespace: s3tables.INamespace;\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n\n    this.tableBucket = new s3tables.TableBucket(this, 'ImportBucket', {\n      tableBucketName: 'namespace-import-bucket',\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    // Create a namespace to import\n    const createdNamespace = new s3tables.Namespace(this, 'CreatedNamespace', {\n      namespaceName: 'import_test_namespace',\n      tableBucket: this.tableBucket,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    // Import the namespace using fromNamespaceAttributes\n    this.namespace = s3tables.Namespace.fromNamespaceAttributes(this, 'ImportedNamespace', {\n      namespaceName: createdNamespace.namespaceName,\n      tableBucket: this.tableBucket,\n    });\n  }\n}", "language": "typescript"}
{"input": "Passing L2 Bucket to L1 Events.Rule with cloudtrail pattern", "output": "class L2BucketWithL1Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l2Bucket = new s3.Bucket(this, 'bucketL2');\n    const l2BucketWithEvent = BucketEvents.fromBucket(l2Bucket);\n\n    const trail = new Trail(this, 'Trail', {});\n    trail.addS3EventSelector([{ bucket: l2Bucket }], { readWriteType: ReadWriteType.ALL });\n\n    const fn2 = new Function(this, 'MyFuncC', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n    const rule2 = new CfnRule(this, 'RuleL1BucketL2', {\n      state: 'ENABLED',\n      eventPattern: l2BucketWithEvent.awsAPICallViaCloudTrailPattern(),\n      targets: [{ arn: fn2.functionArn, id: 'L2' }],\n    });\n\n    fn2.addPermission('L2', {\n      sourceArn: rule2.attrArn,\n      action: 'lambda:InvokeFunction',\n      principal: new ServicePrincipal('events.amazonaws.com'),\n    });\n  }\n}", "language": "typescript"}
{"input": "Build script must contain 'cdk-build'", "output": "export class MustUseCDKBuild extends ValidationRule {\n  public readonly name = 'package-info/scripts/build';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n    if (pkg.packageName === '@aws-cdk/custom-resource-handlers') { return; }\n\n    const buildScript = deepGet(pkg.json, ['scripts', 'build']) ?? '';\n    if (!buildScript.includes('cdk-build')) {\n      pkg.report({\n        ruleName: this.name,\n        message: `scripts.build should contain cdk-build is ${JSON.stringify(buildScript)}`,\n        fix: () => { deepSet(pkg.json, ['scripts', 'build'], 'cdk-build'); },\n      });\n    }\n\n    // cdk-build will write a hash file that we have to ignore.\n    const merkleMarker = '.LAST_BUILD';\n    fileShouldContain(this.name, pkg, '.gitignore', merkleMarker);\n    fileShouldContain(this.name, pkg, '.npmignore', merkleMarker);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF, SNS operations", "output": "def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc_id,\n                role_arn,\n                subnet_ids,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Create Iot Messaging Destination for MSK Cluster\n        destination = iot.CfnTopicRuleDestination(self, \"TopicDestination\", \n            vpc_properties=iot.CfnTopicRuleDestination.VpcDestinationPropertiesProperty(\n                role_arn=role_arn,\n                vpc_id=vpc_id,\n                subnet_ids=subnet_ids\n            )\n        )\n        self.arn = destination.attr_arn", "language": "python"}
{"input": "CDK helper function mockObjectKey", "output": "const mockObjectKey = (() => {\n          const hashType = options.assetHashType ?? (options.assetHash ? 'custom' : 'source');\n          switch (hashType) {\n            case 'source': return 'SOURCE_MOCK';\n            case 'output': return 'OUTPUT_MOCK';\n            case 'custom': {\n              if (!options.assetHash) { throw new Error('no custom hash'); }\n              return options.assetHash;\n            }\n          }\n\n          throw new Error('unexpected asset hash type');\n        }", "language": "typescript"}
{"input": "CDK class TransitGatewayRouteTable for AWS resource management", "output": "export class TransitGatewayRouteTable extends TransitGatewayRouteTableBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.TransitGatewayRouteTable';\n  public readonly routeTableId: string;\n  /**\n   * The Transit Gateway.\n   */\n  public readonly transitGateway: ITransitGateway;\n\n  constructor(scope: Construct, id: string, props: TransitGatewayRouteTableProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnTransitGatewayRouteTable(this, id, {\n      transitGatewayId: props.transitGateway.transitGatewayId,\n    });\n\n    this.node.defaultChild = resource;\n\n    this.routeTableId = resource.attrTransitGatewayRouteTableId;\n    this.transitGateway = props.transitGateway;\n  }\n}", "language": "typescript"}
{"input": "CDK class FirewallRuleGroupAssociation for AWS resource management", "output": "export class FirewallRuleGroupAssociation extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-route53resolver-alpha.FirewallRuleGroupAssociation';\n  /**\n   * The ARN (Amazon Resource Name) of the association\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationArn: string;\n\n  /**\n   * The date and time that the association was created\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationCreationTime: string;\n\n  /**\n   * The creator request ID\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationCreatorRequestId: string;\n\n  /**\n   * The ID of the association\n   *\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationId: string;\n\n  /**\n   * The owner of the association, used only for lists that are not managed by you.\n   * If you use AWS Firewall Manager to manage your firewalls from DNS Firewall,\n   * then this reports Firewall Manager as the managed owner.\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationManagedOwnerName: string;\n\n  /**\n   * The date and time that the association was last modified\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationModificationTime: string;\n\n  /**\n   * The status of the association\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationStatus: string;\n\n  /**\n   * Additional information about the status of the association\n   * @attribute\n   */\n  public readonly firewallRuleGroupAssociationStatusMessage: string;\n\n  constructor(scope: Construct, id: string, props: FirewallRuleGroupAssociationProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (!Token.isUnresolved(props.priority) && (props.priority <= 100 || props.priority >= 9000)) {\n      throw new ValidationError(`Priority must be greater than 100 and less than 9000, got ${props.priority}`, this);\n    }\n\n    const association = new CfnFirewallRuleGroupAssociation(this, 'Resource', {\n      firewallRuleGroupId: props.firewallRuleGroup.firewallRuleGroupId,\n      priority: props.priority,\n      vpcId: props.vpc.vpcId,\n    });\n\n    this.firewallRuleGroupAssociationArn = association.attrArn;\n    this.firewallRuleGroupAssociationCreationTime = association.attrCreationTime;\n    this.firewallRuleGroupAssociationCreatorRequestId = association.attrCreatorRequestId;\n    this.firewallRuleGroupAssociationId = association.attrId;\n    this.firewallRuleGroupAssociationManagedOwnerName = association.attrManagedOwnerName;\n    this.firewallRuleGroupAssociationModificationTime = association.attrModificationTime;\n    this.firewallRuleGroupAssociationStatus = association.attrStatus;\n    this.firewallRuleGroupAssociationStatusMessage = association.attrStatusMessage;\n  }\n}", "language": "typescript"}
{"input": "Represents a new Regional file system used as the destination file system for ReplicationConfiguration.", "output": "class RegionalFileSystem extends ReplicationConfiguration {\n  constructor(props: RegionalFileSystemProps) {\n    super(props);\n  }\n}", "language": "typescript"}
{"input": "Defines a parameter for an extension.", "output": "export class Parameter {\n  /**\n   * A required parameter for an extension.\n   *\n   * @param name The name of the parameter\n   * @param value The value of the parameter\n   * @param description A description for the parameter\n   */\n  public static required(name: string, value: string, description?: string): Parameter {\n    return new Parameter(name, true, value, description);\n  }\n\n  /**\n   * An optional parameter for an extension.\n   *\n   * @param name The name of the parameter\n   * @param value The value of the parameter\n   * @param description A description for the parameter\n   */\n  public static notRequired(name: string, value?: string, description?: string): Parameter {\n    return new Parameter(name, false, value, description);\n  }\n\n  /**\n   * The name of the parameter.\n   */\n  public readonly name: string;\n\n  /**\n   * A boolean that indicates if the parameter is required or optional.\n   */\n  public readonly isRequired: boolean;\n\n  /**\n   * The value of the parameter.\n   */\n  public readonly value?: string;\n\n  /**\n   * The description of the parameter.\n   */\n  public readonly description?: string;\n\n  private constructor(name: string, isRequired: boolean, value?: string, description?: string) {\n    this.name = name;\n    this.isRequired = isRequired;\n    this.value = value;\n    this.description = description;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates API Gateway, CloudFormation resources", "output": "class PetsStack extends NestedStack {\n  public readonly methods: Method[] = [];\n\n  constructor(scope: Construct, props: ResourceNestedStackProps) {\n    super(scope, 'integ-restapi-import-PetsStack', props);\n\n    const api = RestApi.fromRestApiAttributes(this, 'RestApi', {\n      restApiId: props.restApiId,\n      rootResourceId: props.rootResourceId,\n    });\n\n    const method = api.root.addResource('pets').addMethod('GET', new MockIntegration({\n      integrationResponses: [{\n        statusCode: '200',\n      }],\n      passthroughBehavior: PassthroughBehavior.NEVER,\n      requestTemplates: {\n        'application/json': '{ \"statusCode\": 200 }',\n      },\n    }), {\n      methodResponses: [{ statusCode: '200' }],\n    });\n\n    this.methods.push(method);\n  }\n}", "language": "typescript"}
{"input": "Helper to check if an error is of a certain type.", "output": "export class Errors {\n  /**\n   * Test whether the given errors is a ConstructionError.\n   *\n   * A ConstructionError is a generic error that will be thrown during the App construction or synthesis.\n   * To check for more specific errors, use the respective methods.\n   */\n  public static isConstructError(x: any): x is ConstructError {\n    return x !== null && typeof(x) === 'object' && CONSTRUCT_ERROR_SYMBOL in x;\n  }\n\n  /**\n   * Test whether the given error is a ValidationError.\n   *\n   * A ValidationError is thrown when input props are failing to pass the rules of the construct.\n   * It usually means the underlying CloudFormation resource(s) would not deploy with a given configuration.\n   */\n  public static isValidationError(x: any): x is ValidationError {\n    return Errors.isConstructError(x) && VALIDATION_ERROR_SYMBOL in x;\n  }\n\n  /**\n   * Test whether the given error is a AssertionError.\n   *\n   * An AssertionError is thrown when an assertion fails.\n   */\n  public static isAssertionError(x: any): x is AssertionError {\n    return Errors.isConstructError(x) && ASSERTION_ERROR_SYMBOL in x;\n  }\n\n  /**\n   * Test whether the given error is a CloudAssemblyError.\n   *\n   * A CloudAssemblyError is thrown for unexpected problems with the synthesized assembly.\n   */\n  public static isCloudAssemblyError(x: any): x is CloudAssemblyError {\n    return x !== null && typeof(x) === 'object' && ASSEMBLY_ERROR_SYMBOL in x;\n  }\n\n  /**\n   * Test whether the given error is an ExecutionError.\n   *\n   * An ExecutionError is thrown if an externally executed script or code failed.\n   */\n  public static isExecutionError(x: any): x is ExecutionError {\n    return x !== null && typeof(x) === 'object' && EXECUTION_ERROR_SYMBOL in x;\n  }\n\n  /**\n   * Test whether the given error is an AssumptionError.\n   *\n   * An AssumptionError is thrown when a construct made an assumption somewhere that doesn't hold true.\n   * This error always indicates a bug in the construct.\n   */\n  public static isAssumptionError(x: any): x is AssumptionError {\n    return x !== null && typeof(x) === 'object' && ASSUMPTION_ERROR_SYMBOL in x;\n  }\n}\n\ninterface ConstructInfo {\n  readonly fqn: string;\n  readonly version: string;\n}\n\n/**\n * Generic, abstract error class used for errors thrown from the users app during construction or synth.\n */\nabstract class ConstructError extends Error {\n  #time: string;\n  #constructPath?: string;\n  #constructInfo?: ConstructInfo;\n\n  /**\n   * The time the error was thrown.\n   */\n  public get time(): string {\n    return this.#time;\n  }\n\n  /**\n   * The level. Always `'error'`.\n   */\n  public get level(): 'error' {\n    return 'error';\n  }\n\n  /**\n   * The type of the error.\n   */\n  public abstract get type(): string;\n\n  /**\n   * The path of the construct this error is thrown from, if available.\n   */\n  public get constructPath(): string | undefined {\n    return this.#constructPath;\n  }\n\n  /**\n   * Information on the construct this error is thrown from, if available.\n   */\n  public get constructInfo(): ConstructInfo | undefined {\n    return this.#constructInfo;\n  }\n\n  constructor(msg: string, scope?: IConstruct, name?: string) {\n    super(msg);\n    Object.setPrototypeOf(this, ConstructError.prototype);\n    Object.defineProperty(this, CONSTRUCT_ERROR_SYMBOL, { value: true });\n\n    this.name = name ?? new.target.name;\n    this.#time = new Date().toISOString();\n    this.#constructPath = scope?.node.path;\n\n    if (scope) {\n      Error.captureStackTrace(this, scope.constructor);\n      try {\n        this.#constructInfo = scope ? constructInfoFromConstruct(scope) : undefined;\n      } catch (_) {\n        // we don't want to fail if construct info is not available\n      }", "language": "typescript"}
{"input": "CDK class TableV2 for AWS resource management", "output": "export class TableV2 extends TableBaseV2 {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-dynamodb.TableV2';\n\n  /**\n   * Creates a Table construct that represents an external table via table name.\n   *\n   * @param scope the parent creating construct (usually `this`)\n   * @param id the construct's name\n   * @param tableName the table's name\n   */\n  public static fromTableName(scope: Construct, id: string, tableName: string): ITableV2 {\n    return TableV2.fromTableAttributes(scope, id, { tableName });\n  }\n\n  /**\n   * Creates a Table construct that represents an external table via table ARN.\n   *\n   * @param scope the parent creating construct (usually `this`)\n   * @param id the construct's name\n   * @param tableArn the table's ARN\n   */\n  public static fromTableArn(scope: Construct, id: string, tableArn: string): ITableV2 {\n    return TableV2.fromTableAttributes(scope, id, { tableArn });\n  }\n\n  /**\n   * Creates a Table construct that represents an external table.\n   *\n   * @param scope the parent creating construct (usually `this`)\n   * @param id the construct's name\n   * @param attrs attributes of the table\n   */\n  public static fromTableAttributes(scope: Construct, id: string, attrs: TableAttributesV2): ITableV2 {\n    class Import extends TableBaseV2 {\n      public readonly tableArn: string;\n      public readonly tableName: string;\n      public readonly tableId?: string;\n      public readonly tableStreamArn?: string;\n      public readonly encryptionKey?: IKey;\n      public readonly resourcePolicy?: PolicyDocument;\n\n      protected readonly region: string;\n      protected readonly hasIndex = (attrs.grantIndexPermissions ?? false) ||\n        (attrs.globalIndexes ?? []).length > 0 ||\n        (attrs.localIndexes ?? []).length > 0;\n\n      public constructor(tableArn: string, tableName: string, tableId?: string, tableStreamArn?: string, resourcePolicy?: PolicyDocument) {\n        super(scope, id, { environmentFromArn: tableArn });\n\n        const resourceRegion = stack.splitArn(tableArn, ArnFormat.SLASH_RESOURCE_NAME).region;\n        if (!resourceRegion) {\n          throw new ValidationError('Table ARN must be of the form: arn:<partition>:dynamodb:<region>:<account>:table/<table-name>', this);\n        }\n\n        this.region = resourceRegion;\n        this.tableArn = tableArn;\n        this.tableName = tableName;\n        this.tableId = tableId;\n        this.tableStreamArn = tableStreamArn;\n        this.encryptionKey = attrs.encryptionKey;\n        this.resourcePolicy = resourcePolicy;\n      }\n\n      /**\n       * Adds a statement to the resource policy associated with this table.\n       *\n       * Note: This is a no-op for imported tables since resource policies cannot be modified.\n       *\n       * @param _statement The policy statement to add\n       */\n      public addToResourcePolicy(_statement: PolicyStatement): AddToResourcePolicyResult {\n        // No-op for imported tables - resource policies cannot be modified\n        return {\n          statementAdded: false,\n        };\n      }\n    }\n\n    let tableName: string;\n    let tableArn: string;\n    const stack = Stack.of(scope);\n    if (!attrs.tableArn) {\n      if (!attrs.tableName) {\n        throw new ValidationError('At least one of `tableArn` or `tableName` must be provided', scope);\n      }\n\n      tableName = attrs.tableName;\n      tableArn = stack.formatArn({\n        service: 'dynamodb',\n        resource: 'table',\n        resourceName: tableName,\n      });\n    } else {\n      if (attrs.tableName) {\n        throw new ValidationError('Only one of `tableArn` or `tableName` can be provided, but not both', scope);\n      }\n\n      tableArn = attrs.tableArn;\n      const resourceName = stack.splitArn(tableArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n      if (!resourceName) {\n        throw new ValidationError('Table ARN must be of the form: arn:<partition>:dynamodb:<region>:<account>:table/<table-name>', scope);\n      }\n      tableName = resourceName;\n    }\n\n    return new Import(tableArn, tableName, attrs.tableId, attrs.tableStreamArn);\n  }\n\n  /**\n   * @attribute\n   */\n  public readonly tableArn: string;\n\n  /**\n   * @attribute\n   */\n  public readonly tableName: string;\n\n  /**\n   * @attribute\n   */\n  public readonly tableStreamArn?: string;\n\n  /**\n   * @attribute\n   */\n  public readonly tableId?: string;\n\n  public readonly encryptionKey?: IKey;\n\n  /**\n   * @attribute\n   */\n  public resourcePolicy?: PolicyDocument;\n\n  protected readonly region: string;\n\n  protected readonly tags: TagManager;\n\n  private readonly billingMode: string;\n  private readonly partitionKey: Attribute;\n  private readonly hasSortKey: boolean;\n  private readonly tableOptions: TableOptionsV2;\n  private readonly encryption?: TableEncryptionV2;\n\n  private readonly keySchema: CfnGlobalTable.KeySchemaProperty[] = [];\n  private readonly attributeDefinitions: CfnGlobalTable.AttributeDefinitionProperty[] = [];\n  private readonly nonKeyAttributes = new Set<string>();\n\n  private readonly readProvisioning?: CfnGlobalTable.ReadProvisionedThroughputSettingsProperty;\n  private readonly writeProvisioning?: CfnGlobalTable.WriteProvisionedThroughputSettingsProperty;\n\n  private readonly maxReadRequestUnits?: number;\n  private readonly maxWriteRequestUnits?: number;\n\n  private readonly replicaTables = new Map<string, ReplicaTableProps>();\n  private readonly replicaKeys: { [region: string]: IKey } = {};\n  private readonly replicaTableArns: string[] = [];\n  private readonly replicaStreamArns: string[] = [];\n\n  private readonly globalSecondaryIndexes = new Map<string, CfnGlobalTable.GlobalSecondaryIndexProperty>();\n  private readonly localSecondaryIndexes = new Map<string, CfnGlobalTable.LocalSecondaryIndexProperty>();\n  private readonly globalSecondaryIndexReadCapacitys = new Map<string, Capacity>();\n  private readonly globalSecondaryIndexMaxReadUnits = new Map<string, number>();\n\n  public constructor(scope: Construct, id: string, props: TablePropsV2) {\n    super(scope, id, { physicalName: props.tableName ?? PhysicalName.GENERATE_IF_NEEDED });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.tableOptions = props;\n    this.partitionKey = props.partitionKey;\n    this.hasSortKey = props.sortKey !== undefined;\n    this.region = this.stack.region;\n    this.tags = new TagManager(TagType.STANDARD, CfnGlobalTable.CFN_RESOURCE_TYPE_NAME);\n\n    this.encryption = props.encryption;\n    this.encryptionKey = this.encryption?.tableKey;\n    this.configureReplicaKeys(this.encryption?.replicaKeyArns);\n\n    this.addKey(props.partitionKey, HASH_KEY_TYPE);\n    if (props.sortKey) {\n      this.addKey(props.sortKey, RANGE_KEY_TYPE);\n    }\n\n    this.validatePitr(props);\n\n    if (props.billing?.mode === BillingMode.PAY_PER_REQUEST || props.billing?.mode === undefined) {\n      this.maxReadRequestUnits = props.billing?._renderReadCapacity();\n      this.maxWriteRequestUnits = props.billing?._renderWriteCapacity();\n      this.billingMode = BillingMode.PAY_PER_REQUEST;\n    } else {\n      this.readProvisioning = props.billing?._renderReadCapacity();\n      this.writeProvisioning = props.billing?._renderWriteCapacity();\n      this.billingMode = props.billing.mode;\n    }\n\n    props.globalSecondaryIndexes?.forEach(gsi => this.addGlobalSecondaryIndex(gsi));\n    props.localSecondaryIndexes?.forEach(lsi => this.addLocalSecondaryIndex(lsi));\n\n    if (props.multiRegionConsistency === MultiRegionConsistency.STRONG) {\n      this.validateMrscConfiguration(props);\n    } else if (props.witnessRegion) {\n      throw new ValidationError('Witness region cannot be specified for a Multi-Region Eventual Consistency (MREC) Global Table - Witness regions are only supported for Multi-Region Strong Consistency (MRSC) Global Tables.', this);\n    }\n\n    // Initialize resourcePolicy from props or create empty one (KMS pattern)\n    this.resourcePolicy = props.resourcePolicy;\n\n    const resource = new CfnGlobalTable(this, 'Resource', {\n      tableName: this.physicalName,\n      keySchema: this.keySchema,\n      attributeDefinitions: Lazy.any({ produce: () => this.attributeDefinitions }),\n      replicas: Lazy.any({ produce: () => this.renderReplicaTables() }),\n      globalTableWitnesses: props.witnessRegion? [{ region: props.witnessRegion }] : undefined,\n      multiRegionConsistency: props.multiRegionConsistency ? props.multiRegionConsistency : undefined,\n      globalSecondaryIndexes: Lazy.any({ produce: () => this.renderGlobalIndexes() }, { omitEmptyArray: true }),\n      localSecondaryIndexes: Lazy.any({ produce: () => this.renderLocalIndexes() }, { omitEmptyArray: true }),\n      billingMode: this.billingMode,\n      writeProvisionedThroughputSettings: this.writeProvisioning,\n      writeOnDemandThroughputSettings: this.maxWriteRequestUnits\n        ? { maxWriteRequestUnits: this.maxWriteRequestUnits }\n        : undefined,\n      streamSpecification: Lazy.any(\n        { produce: () => props.dynamoStream ? { streamViewType: props.dynamoStream } : this.renderStreamSpecification() },\n      ),\n      sseSpecification: this.encryption?._renderSseSpecification(),\n      timeToLiveSpecification: props.timeToLiveAttribute\n        ? { attributeName: props.timeToLiveAttribute, enabled: true }\n        : undefined,\n      warmThroughput: props.warmThroughput ?? undefined,\n    });\n    resource.applyRemovalPolicy(props.removalPolicy);\n\n    this.tableArn = this.getResourceArnAttribute(resource.attrArn, {\n      service: 'dynamodb',\n      resource: 'table',\n      resourceName: this.physicalName,\n    });\n    this.tableName = this.getResourceNameAttribute(resource.ref);\n    this.tableId = resource.attrTableId;\n    this.tableStreamArn = resource.attrStreamArn;\n\n    props.replicas?.forEach(replica => this.addReplica(replica));\n\n    if (props.tableName) {\n      this.node.addMetadata('aws:cdk:hasPhysicalName', this.tableName);\n    }\n  }\n\n  /**\n   * Adds a statement to the resource policy associated with this table.\n   * A resource policy will be automatically created upon the first call to `addToResourcePolicy`.\n   *\n   * Note that this does not work with imported tables.\n   *\n   * @param statement The policy statement to add\n   */\n  @MethodMetadata()\n  public addToResourcePolicy(statement: PolicyStatement): AddToResourcePolicyResult {\n    // Initialize resourcePolicy if it doesn't exist\n    if (!this.resourcePolicy) {\n      this.resourcePolicy = new PolicyDocument({ statements: [] });\n    }\n\n    this.resourcePolicy.addStatements(statement);\n\n    return {\n      statementAdded: true,\n      policyDependable: this.resourcePolicy,\n    };\n  }", "language": "typescript"}
{"input": "CDK Stack that creates SQS, CloudFormation resources", "output": "class ProdStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new sqs.Queue(this, 'MyQueue', {\n      queueName: 'prod-queue',\n      visibilityTimeout: Duration.seconds(300),\n    });\n  }\n}", "language": "typescript"}
{"input": "Supports up to 3 file assets", "output": "export class MultipleFileAssetsApp extends Stage {\n  constructor(scope: Construct, id: string, props: MultipleFileAssetsProps) {\n    super(scope, id, props);\n    const stack = new Stack(this, 'Stack');\n\n    const fileNames = ['test-file-asset.txt', 'test-file-asset-two.txt', 'test-file-asset-three.txt'];\n    if (props.displayNames && props.displayNames.length !== props.n) {\n      throw new Error('Incorrect displayNames length');\n    }\n\n    for (let i = 0; i < props.n; i++) {\n      const displayName = props.displayNames ? props.displayNames[i] : undefined;\n      const fn = fileNames[i];\n      if (!fn) {\n        throw new ValidationError(`Got more displayNames than we have fileNames: ${i + 1}`, this);\n      }\n\n      new s3_assets.Asset(stack, `Asset${i + 1}`, {\n        path: path.join(__dirname, 'assets', fn),\n        displayName,\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, DynamoDB, VPC, IAM resources", "output": "class ChatAppStack extends Stack {\n    constructor(scope: Construct, id: string, props?: StackProps) {\n        super(scope, id, props);\n        const tableName = \"simplechat_connections\";\n\n        // initialise api\n        const name = id + \"-api\"\n        const api = new CfnApi(this, name, {\n            name: \"ChatAppApi\",\n            protocolType: \"WEBSOCKET\",\n            routeSelectionExpression: \"$request.body.action\",\n        });\n        const table = new Table(this, `${name}-table`, {\n            tableName: tableName,\n            partitionKey: {\n                name: \"connectionId\",\n                type: AttributeType.STRING,\n            },\n            readCapacity: 5,\n            writeCapacity: 5,\n            removalPolicy: RemovalPolicy.DESTROY\n        });\n\n        const connectFunc = new Function(this, 'connect-lambda', {\n            code: new AssetCode('./onconnect'),\n            handler: 'onconnectLambda.handler',\n            runtime: Runtime.NODEJS_LATEST,\n            timeout: Duration.seconds(300),\n            memorySize: 256,\n            environment: {\n                \"TABLE_NAME\": tableName,\n            }\n        });\n\n        table.grantReadWriteData(connectFunc)\n\n        const disconnectFunc = new Function(this, 'disconnect-lambda', {\n            code: new AssetCode('./ondisconnect'),\n            handler: 'ondisconnectLambda.handler',\n            runtime: Runtime.NODEJS_LATEST,\n            timeout: Duration.seconds(300),\n            memorySize: 256,\n            environment: {\n                \"TABLE_NAME\": tableName,\n            }\n        });\n\n        table.grantReadWriteData(disconnectFunc);\n\n        const messageFunc = new Function(this, 'message-lambda', {\n            code: new AssetCode('./sendmessage'),\n            handler: 'sendmessageLambda.handler',\n            runtime: Runtime.NODEJS_LATEST,\n            timeout: Duration.seconds(300),\n            memorySize: 256,\n            initialPolicy: [\n                new PolicyStatement({\n                    actions: [\n                        'execute-api:ManageConnections'\n                    ],\n                    resources: [\n                        \"arn:aws:execute-api:\" + config[\"region\"] + \":\" + config[\"account_id\"] + \":\" + api.ref + \"/*\"\n                    ],\n                    effect: Effect.ALLOW,\n                })\n            ],\n            environment: {\n                \"TABLE_NAME\": tableName,\n            }\n        });\n\n        table.grantReadWriteData(messageFunc);\n\n        // access role for the socket api to access the socket lambda\n        const policy = new PolicyStatement({\n            effect: Effect.ALLOW,\n            resources: [\n                connectFunc.functionArn,\n                disconnectFunc.functionArn,\n                messageFunc.functionArn\n            ],\n            actions: [\"lambda:InvokeFunction\"]\n        });\n\n        const role = new Role(this, `${name}-iam-role`, {\n            assumedBy: new ServicePrincipal(\"apigateway.amazonaws.com\")\n        });\n        role.addToPolicy(policy);\n\n        // lambda integration\n        const connectIntegration = new CfnIntegration(this, \"connect-lambda-integration\", {\n            apiId: api.ref,\n            integrationType: \"AWS_PROXY\",\n            integrationUri: \"arn:aws:apigateway:\" + config[\"region\"] + \":lambda:path/2015-03-31/functions/\" + connectFunc.functionArn + \"/invocations\",\n            credentialsArn: role.roleArn,\n        })\n        const disconnectIntegration = new CfnIntegration(this, \"disconnect-lambda-integration\", {\n            apiId: api.ref,\n            integrationType: \"AWS_PROXY\",\n            integrationUri: \"arn:aws:apigateway:\" + config[\"region\"] + \":lambda:path/2015-03-31/functions/\" + disconnectFunc.functionArn + \"/invocations\",\n            credentialsArn: role.roleArn\n        })\n        const messageIntegration = new CfnIntegration(this, \"message-lambda-integration\", {\n            apiId: api.ref,\n            integrationType: \"AWS_PROXY\",\n            integrationUri: \"arn:aws:apigateway:\" + config[\"region\"] + \":lambda:path/2015-03-31/functions/\" + messageFunc.functionArn + \"/invocations\",\n            credentialsArn: role.roleArn\n        })\n\n        const connectRoute = new CfnRoute(this, \"connect-route\", {\n            apiId: api.ref,\n            routeKey: \"$connect\",\n            authorizationType: \"NONE\",\n            target: \"integrations/\" + connectIntegration.ref,\n        });\n\n        const disconnectRoute = new CfnRoute(this, \"disconnect-route\", {\n            apiId: api.ref,\n            routeKey: \"$disconnect\",\n            authorizationType: \"NONE\",\n            target: \"integrations/\" + disconnectIntegration.ref,\n        });\n\n        const messageRoute = new CfnRoute(this, \"message-route\", {\n            apiId: api.ref,\n            routeKey: \"sendmessage\",\n            authorizationType: \"NONE\",\n            target: \"integrations/\" + messageIntegration.ref,\n        });\n\n        const deployment = new CfnDeployment(this, `${name}-deployment`, {\n            apiId: api.ref\n        });\n\n        new CfnStage(this, `${name}-stage`, {\n            apiId: api.ref,\n            autoDeploy: true,\n            deploymentId: deployment.ref,\n            stageName: \"dev\"\n        });\n\n        deployment.node.addDependency(connectRoute);\n        deployment.node.addDependency(disconnectRoute);\n        deployment.node.addDependency(messageRoute);\n\n\n        // add the domain name of the ws api to the cloudformation outputs\n        new CfnOutput(this, \"websocket-api-endpoint\", {\n            description: \"The endpoint for the websocket api\",\n            value: api.attrApiEndpoint + \"/dev\",\n            exportName: \"websocket-api-endpoint\"\n        });\n    }\n}", "language": "typescript"}
{"input": "Contains static factory methods for creating health checks for different protocols", "output": "export class HealthCheck {\n  /**\n   * Construct a HTTP health check\n   */\n  public static http(options: HttpHealthCheckOptions = {}): HealthCheck {\n    return new HealthCheck(\n      HealthCheckProtocolType.HTTP,\n      options.healthyThreshold,\n      options.interval,\n      options.timeout,\n      options.unhealthyThreshold,\n      options.path,\n    );\n  }\n\n  /**\n   * Construct a TCP health check\n   */\n  public static tcp(options: TcpHealthCheckOptions = {}): HealthCheck {\n    return new HealthCheck(\n      HealthCheckProtocolType.TCP,\n      options.healthyThreshold,\n      options.interval,\n      options.timeout,\n      options.unhealthyThreshold,\n    );\n  }\n\n  private constructor(\n    public readonly healthCheckProtocolType: HealthCheckProtocolType,\n    public readonly healthyThreshold: number = 1,\n    public readonly interval: cdk.Duration = cdk.Duration.seconds(5),\n    public readonly timeout: cdk.Duration = cdk.Duration.seconds(2),\n    public readonly unhealthyThreshold: number = 5,\n    public readonly path?: string,\n  ) {\n    if (this.healthCheckProtocolType === HealthCheckProtocolType.HTTP) {\n      if (this.path !== undefined && this.path.length === 0) {\n        throw new cdk.UnscopedValidationError('path length must be greater than 0');\n      }\n      if (this.path === undefined) {\n        this.path = '/';\n      }\n    }\n\n    if (this.healthyThreshold < 1 || this.healthyThreshold > 20) {\n      throw new cdk.UnscopedValidationError(`healthyThreshold must be between 1 and 20, got ${this.healthyThreshold}`);\n    }\n    if (this.unhealthyThreshold < 1 || this.unhealthyThreshold > 20) {\n      throw new cdk.UnscopedValidationError(`unhealthyThreshold must be between 1 and 20, got ${this.unhealthyThreshold}`);\n    }\n    if (this.interval.toSeconds() < 1 || this.interval.toSeconds() > 20) {\n      throw new cdk.UnscopedValidationError(`interval must be between 1 and 20 seconds, got ${this.interval.toSeconds()}`);\n    }\n    if (this.timeout.toSeconds() < 1 || this.timeout.toSeconds() > 20) {\n      throw new cdk.UnscopedValidationError(`timeout must be between 1 and 20 seconds, got ${this.timeout.toSeconds()}`);\n    }\n  }\n\n  public bind(): CfnService.HealthCheckConfigurationProperty {\n    return {\n      healthyThreshold: this.healthyThreshold,\n      interval: this.interval?.toSeconds(),\n      path: this.path,\n      protocol: this.healthCheckProtocolType,\n      timeout: this.timeout?.toSeconds(),\n      unhealthyThreshold: this.unhealthyThreshold,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class Secret for AWS resource management", "output": "export class Secret extends SecretBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-secretsmanager.Secret';\n\n  /**\n   * Return whether the given object is a Secret.\n   */\n  public static isSecret(x: any): x is Secret {\n    return x !== null && typeof(x) === 'object' && SECRET_SYMBOL in x;\n  }\n\n  /** @deprecated use `fromSecretCompleteArn` or `fromSecretPartialArn` */\n  public static fromSecretArn(scope: Construct, id: string, secretArn: string): ISecret {\n    const attrs = arnIsComplete(secretArn) ? { secretCompleteArn: secretArn } : { secretPartialArn: secretArn };\n    return Secret.fromSecretAttributes(scope, id, attrs);\n  }\n\n  /** Imports a secret by complete ARN. The complete ARN is the ARN with the Secrets Manager-supplied suffix. */\n  public static fromSecretCompleteArn(scope: Construct, id: string, secretCompleteArn: string): ISecret {\n    return Secret.fromSecretAttributes(scope, id, { secretCompleteArn });\n  }\n\n  /** Imports a secret by partial ARN. The partial ARN is the ARN without the Secrets Manager-supplied suffix. */\n  public static fromSecretPartialArn(scope: Construct, id: string, secretPartialArn: string): ISecret {\n    return Secret.fromSecretAttributes(scope, id, { secretPartialArn });\n  }\n\n  /**\n   * Imports a secret by secret name; the ARN of the Secret will be set to the secret name.\n   * A secret with this name must exist in the same account & region.\n   * @deprecated use `fromSecretNameV2`\n   */\n  public static fromSecretName(scope: Construct, id: string, secretName: string): ISecret {\n    return new class extends SecretBase {\n      public readonly encryptionKey = undefined;\n      public readonly secretArn = secretName;\n      public readonly secretName = secretName;\n      protected readonly autoCreatePolicy = false;\n      public get secretFullArn() { return undefined; }\n      // Overrides the secretArn for grant* methods, where the secretArn must be in ARN format.\n      // Also adds a wildcard to the resource name to support the SecretsManager-provided suffix.\n      protected get arnForPolicies() {\n        return Stack.of(this).formatArn({\n          service: 'secretsmanager',\n          resource: 'secret',\n          resourceName: this.secretName + '*',\n          arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n        });\n      }\n    }(scope, id);\n  }\n\n  /**\n   * Imports a secret by secret name.\n   * A secret with this name must exist in the same account & region.\n   * Replaces the deprecated `fromSecretName`.\n   * Please note this method returns ISecret that only contains partial ARN and could lead to AccessDeniedException\n   * when you pass the partial ARN to CLI or SDK to get the secret value. If your secret name ends with a hyphen and\n   * 6 characters, you should always use fromSecretCompleteArn() to avoid potential AccessDeniedException.\n   * @see https://docs.aws.amazon.com/secretsmanager/latest/userguide/troubleshoot.html#ARN_secretnamehyphen\n   */\n  public static fromSecretNameV2(scope: Construct, id: string, secretName: string): ISecret {\n    return new class extends SecretBase {\n      public readonly encryptionKey = undefined;\n      public readonly secretName = secretName;\n      public readonly secretArn = this.partialArn;\n      protected readonly autoCreatePolicy = false;\n      public get secretFullArn() { return undefined; }\n      // Creates a \"partial\" ARN from the secret name. The \"full\" ARN would include the SecretsManager-provided suffix.\n      private get partialArn(): string {\n        return Stack.of(this).formatArn({\n          service: 'secretsmanager',\n          resource: 'secret',\n          resourceName: secretName,\n          arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n        });\n      }\n    }(scope, id);\n  }\n\n  /**\n   * Import an existing secret into the Stack.\n   *\n   * @param scope the scope of the import.\n   * @param id    the ID of the imported Secret in the construct tree.\n   * @param attrs the attributes of the imported secret.\n   */\n  public static fromSecretAttributes(scope: Construct, id: string, attrs: SecretAttributes): ISecret {\n    let secretArn: string;\n    let secretArnIsPartial: boolean;\n\n    if (attrs.secretArn) {\n      if (attrs.secretCompleteArn || attrs.secretPartialArn) {\n        throw new ValidationError('cannot use `secretArn` with `secretCompleteArn` or `secretPartialArn`', scope);\n      }\n      secretArn = attrs.secretArn;\n      secretArnIsPartial = false;\n    } else {\n      if ((attrs.secretCompleteArn && attrs.secretPartialArn) ||\n          (!attrs.secretCompleteArn && !attrs.secretPartialArn)) {\n        throw new ValidationError('must use only one of `secretCompleteArn` or `secretPartialArn`', scope);\n      }\n      if (attrs.secretCompleteArn && !arnIsComplete(attrs.secretCompleteArn)) {\n        throw new ValidationError('`secretCompleteArn` does not appear to be complete; missing 6-character suffix', scope);\n      }\n      [secretArn, secretArnIsPartial] = attrs.secretCompleteArn ? [attrs.secretCompleteArn, false] : [attrs.secretPartialArn!, true];\n    }\n\n    return new class extends SecretBase {\n      public readonly encryptionKey = attrs.encryptionKey;\n      public readonly secretArn = secretArn;\n      public readonly secretName = parseSecretName(scope, secretArn);\n      protected readonly autoCreatePolicy = false;\n      public get secretFullArn() { return secretArnIsPartial ? undefined : secretArn; }\n      protected get arnForPolicies() { return secretArnIsPartial ? `${secretArn}-??????` : secretArn; }\n    }(scope, id, { environmentFromArn: secretArn });\n  }\n\n  public readonly encryptionKey?: kms.IKey;\n  public readonly secretArn: string;\n  public readonly secretName: string;\n\n  /**\n   * The string of the characters that are excluded in this secret\n   * when it is generated.\n   */\n  public readonly excludeCharacters?: string;\n\n  private replicaRegions: secretsmanager.CfnSecret.ReplicaRegionProperty[] = [];\n\n  protected readonly autoCreatePolicy = true;\n\n  constructor(scope: Construct, id: string, props: SecretProps = {}) {\n    super(scope, id, {\n      physicalName: props.secretName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.generateSecretString &&\n        (props.generateSecretString.secretStringTemplate || props.generateSecretString.generateStringKey) &&\n        !(props.generateSecretString.secretStringTemplate && props.generateSecretString.generateStringKey)) {\n      throw new ValidationError('`secretStringTemplate` and `generateStringKey` must be specified together.', this);\n    }\n\n    if ((props.generateSecretString ? 1 : 0)\n      + (props.secretStringBeta1 ? 1 : 0)\n      + (props.secretStringValue ? 1 : 0)\n      + (props.secretObjectValue ? 1 : 0)\n      > 1) {\n      throw new ValidationError('Cannot specify more than one of `generateSecretString`, `secretStringValue`, `secretObjectValue`, and `secretStringBeta1`.', this);\n    }\n\n    const secretString = props.secretObjectValue\n      ? this.resolveSecretObjectValue(props.secretObjectValue)\n      : props.secretStringValue?.unsafeUnwrap() ?? props.secretStringBeta1?.secretValue();\n\n    const resource = new secretsmanager.CfnSecret(this, 'Resource', {\n      description: props.description,\n      kmsKeyId: props.encryptionKey && props.encryptionKey.keyArn,\n      generateSecretString: props.generateSecretString ?? (secretString ? undefined : {}),\n      secretString,\n      name: this.physicalName,\n      replicaRegions: Lazy.any({ produce: () => this.replicaRegions }, { omitEmptyArray: true }),\n    });\n\n    resource.applyRemovalPolicy(props.removalPolicy, {\n      default: RemovalPolicy.DESTROY,\n    });\n\n    this.secretArn = this.getResourceArnAttribute(resource.ref, {\n      service: 'secretsmanager',\n      resource: 'secret',\n      resourceName: this.physicalName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    this.encryptionKey = props.encryptionKey;\n    const parseOwnedSecretName = FeatureFlags.of(this).isEnabled(cxapi.SECRETS_MANAGER_PARSE_OWNED_SECRET_NAME);\n    this.secretName = parseOwnedSecretName\n      ? parseSecretNameForOwnedSecret(this, this.secretArn, props.secretName)\n      : parseSecretName(this, this.secretArn);\n\n    // @see https://docs.aws.amazon.com/kms/latest/developerguide/services-secrets-manager.html#asm-authz\n    const principal =\n      new kms.ViaServicePrincipal(`secretsmanager.${Stack.of(this).region}.amazonaws.com`, new iam.AccountPrincipal(Stack.of(this).account));\n    this.encryptionKey?.grantEncryptDecrypt(principal);\n    this.encryptionKey?.grant(principal, 'kms:CreateGrant', 'kms:DescribeKey');\n\n    for (const replica of props.replicaRegions ?? []) {\n      this.addReplicaRegion(replica.region, replica.encryptionKey);\n    }\n\n    this.excludeCharacters = props.generateSecretString?.excludeCharacters;\n  }\n\n  private resolveSecretObjectValue(secretObject: { [key: string]: SecretValue }): string {\n    const resolvedObject: { [key: string]: string } = {};\n    for (const [key, value] of Object.entries(secretObject)) {\n      resolvedObject[key] = value.unsafeUnwrap();\n    }\n    return JSON.stringify(resolvedObject);\n  }\n\n  /**\n   * Adds a target attachment to the secret.\n   *\n   * @returns an AttachedSecret\n   *\n   * @deprecated use `attach()` instead\n   */\n  @MethodMetadata()\n  public addTargetAttachment(id: string, options: AttachedSecretOptions): SecretTargetAttachment {\n    return new SecretTargetAttachment(this, id, {\n      secret: this,\n      ...options,\n    });\n  }\n\n  /**\n   * Adds a replica region for the secret\n   *\n   * @param region The name of the region\n   * @param encryptionKey The customer-managed encryption key to use for encrypting the secret value.\n   */\n  @MethodMetadata()\n  public addReplicaRegion(region: string, encryptionKey?: kms.IKeyRef): void {\n    const stack = Stack.of(this);\n    if (!Token.isUnresolved(stack.region) && !Token.isUnresolved(region) && region === stack.region) {\n      throw new ValidationError('Cannot add the region where this stack is deployed as a replica region.', this);\n    }\n\n    this.replicaRegions.push({\n      region,\n      kmsKeyId: encryptionKey?.keyRef.keyArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, ECR resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props: TestStackProps) {\n    super(scope, id);\n\n    const runtimeArtifact = agentcore.AgentRuntimeArtifact.fromEcrRepository(props.asset.repository, props.asset.imageTag);\n    const imported = iam.Role.fromRoleArn(this, 'ImportedRole', props.role.roleArn);\n    const runtime = new agentcore.Runtime(this, 'TestRuntime', {\n      runtimeName: 'integ_test_runtime',\n      agentRuntimeArtifact: runtimeArtifact,\n      executionRole: imported,\n    });\n\n    runtime.addToRolePolicy(new iam.PolicyStatement({\n      actions: ['s3:GetObject'],\n      resources: ['arn:aws:s3:::my-bucket/my-object'],\n    }));\n    runtime.addToRolePolicy(new iam.PolicyStatement({\n      actions: ['dynamodb:Query'],\n      resources: ['arn:aws:dynamodb:us-east-1:123456789012:table/my-table'],\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class Step2DestinationAccount for AWS resource management", "output": "export class Step2DestinationAccount extends Stack {\n  public destinationS3Bucket: Bucket;\n  public destinationKmsKey: Key;\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const replicationRoleArn = new CfnParameter(this, \"replicationRoleArn\", {\n      type: \"String\",\n      description: \"The ARN of the replication role in the source account\",\n    });\n\n    const destinationKmsKey = new Key(\n      this,\n      `s3-cross-account-replication-dest-key`,\n      {\n        alias: Config.destinationKmsKeyAlias,\n        description:\n          \"Key used for KMS Encryption for the destination s3 bucket for cross account replication\",\n        policy: new PolicyDocument({\n          statements: [\n            new PolicyStatement({\n              sid: \"Enable IAM User Permissions\",\n              effect: Effect.ALLOW,\n              principals: [\n                new ArnPrincipal(\n                  `arn:aws:iam::${Config.destinationAccountId}:root`\n                ),\n              ],\n              actions: [\"kms:*\"],\n              resources: [\"*\"],\n            }),\n            new PolicyStatement({\n              sid: \"Enable Replication Permissions\",\n              effect: Effect.ALLOW,\n              principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n              actions: [\n                \"kms:Encrypt\",\n                \"kms:Decrypt\",\n                \"kms:ReEncrypt*\",\n                \"kms:GenerateDataKey*\",\n                \"kms:DescribeKey\",\n              ],\n              resources: [\"*\"],\n            }),\n          ],\n        }),\n        enableKeyRotation: true,\n      }\n    );\n\n    // Create the destination S3 bucket\n    const destinationS3Bucket = new Bucket(\n      this,\n      \"destination-bucket-to-replicate-to\",\n      {\n        bucketName: Config.destinationBucketName,\n        removalPolicy: RemovalPolicy.DESTROY,\n        autoDeleteObjects: true,\n        versioned: true,\n        accessControl: BucketAccessControl.PRIVATE,\n        publicReadAccess: false,\n        blockPublicAccess: new BlockPublicAccess(BlockPublicAccess.BLOCK_ALL),\n        bucketKeyEnabled: true,\n        encryption: BucketEncryption.KMS,\n        encryptionKey: destinationKmsKey,\n        enforceSSL: true,\n      }\n    );\n\n    // allow the principal to have all admin access to bucket\n    destinationS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Set Admin Access\",\n        effect: Effect.ALLOW,\n        principals: [\n          new ArnPrincipal(`arn:aws:iam::${Config.destinationAccountId}:root`),\n        ],\n        actions: [\"s3:*\"],\n        resources: [\n          `${destinationS3Bucket.bucketArn}`,\n          `${destinationS3Bucket.bucketArn}/*`,\n        ],\n      })\n    );\n\n    // allow the objects in the bucket to be replicated or deleted\n    destinationS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Set permissions for Objects\",\n        effect: Effect.ALLOW,\n        principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n        actions: [\"s3:ReplicateObject\", \"s3:ReplicateDelete\"],\n        resources: [`${destinationS3Bucket.bucketArn}/*`],\n      })\n    );\n\n    // allow the files in the bucket to be listed or versioned\n    destinationS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Set permissions on bucket\",\n        effect: Effect.ALLOW,\n        principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n        actions: [\n          \"s3:List*\",\n          \"s3:GetBucketVersioning\",\n          \"s3:PutBucketVersioning\",\n        ],\n        resources: [destinationS3Bucket.bucketArn],\n      })\n    );\n\n    // allows the ownership to change from the source bucket to the destination bucket\n    destinationS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Allow ownership change\",\n        effect: Effect.ALLOW,\n        principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n        actions: [\n          \"s3:ReplicateObject\",\n          \"s3:ReplicateDelete\",\n          \"s3:ObjectOwnerOverrideToBucketOwner\",\n          \"s3:ReplicateTags\",\n          \"s3:GetObjectVersionTagging\",\n        ],\n        resources: [`${destinationS3Bucket.bucketArn}/*`],\n      })\n    );\n\n    this.destinationKmsKey = destinationKmsKey;\n    this.destinationS3Bucket = destinationS3Bucket;\n    new CfnOutput(this, \"destinationKmsKeyArn\", {\n      value: destinationKmsKey.keyArn,\n    });\n    new CfnOutput(this, \"destinationS3Bucket\", {\n      value: destinationS3Bucket.bucketArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "The package must depend on cdk-build-tools", "output": "export class MustDependOnBuildTools extends ValidationRule {\n  public readonly name = 'dependencies/build-tools';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n\n    // We can't ACTUALLY require cdk-build-tools/package.json here,\n    // because WE don't depend on cdk-build-tools and we don't know if\n    // the package does.\n    expectDevDependency(this.name,\n      pkg,\n      '@aws-cdk/cdk-build-tools',\n      `${PKGLINT_VERSION}`);\n  }\n}\n\n/**\n * Build script must contain 'cdk-build'\n */\nexport class MustUseCDKBuild extends ValidationRule {\n  public readonly name = 'package-info/scripts/build';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n    if (pkg.packageName === '@aws-cdk/custom-resource-handlers') { return; }\n\n    const buildScript = deepGet(pkg.json, ['scripts', 'build']) ?? '';\n    if (!buildScript.includes('cdk-build')) {\n      pkg.report({\n        ruleName: this.name,\n        message: `scripts.build should contain cdk-build is ${JSON.stringify(buildScript)}`,\n        fix: () => { deepSet(pkg.json, ['scripts', 'build'], 'cdk-build'); },\n      });\n    }\n\n    // cdk-build will write a hash file that we have to ignore.\n    const merkleMarker = '.LAST_BUILD';\n    fileShouldContain(this.name, pkg, '.gitignore', merkleMarker);\n    fileShouldContain(this.name, pkg, '.npmignore', merkleMarker);\n  }\n}\n\n/**\n * Dependencies in both regular and peerDependencies must agree in semver\n *\n * In particular, verify that depVersion satisfies peerVersion. This prevents\n * us from instructing NPM to construct impossible closures, where we say:\n *\n *    peerDependency: A@1.0.0\n *    dependency: A@2.0.0\n *\n * There is no version of A that would satisfy this.\n *\n * The other way around is not necessary--the depVersion can be bumped without\n * bumping the peerVersion (if the API didn't change this may be perfectly\n * valid). This prevents us from restricting a user's potential combinations of\n * libraries unnecessarily.\n */\nexport class RegularDependenciesMustSatisfyPeerDependencies extends ValidationRule {\n  public readonly name = 'dependencies/peer-dependencies-satisfied';\n\n  public validate(pkg: PackageJson): void {\n    for (const [depName, peerRange] of Object.entries(pkg.peerDependencies)) {\n      const depRange = pkg.dependencies[depName];\n      if (depRange === undefined) { continue; }\n\n      // Make sure that depVersion satisfies peerVersion.\n      if (!semver.intersects(depRange, peerRange, { includePrerelease: true })) {\n        pkg.report({\n          ruleName: this.name,\n          message: `dependency ${depName}: concrete version ${depRange} does not match peer version '${peerRange}'`,\n          fix: () => pkg.addPeerDependency(depName, depRange),\n        });\n      }\n    }\n  }\n}\n\n/**\n * Check that dependencies on @aws-cdk/ packages use point versions (not version ranges)\n * and that they are also defined in `peerDependencies`.\n */\nexport class MustDependonCdkByPointVersions extends ValidationRule {\n  public readonly name = 'dependencies/cdk-point-dependencies';\n\n  public validate(pkg: PackageJson): void {\n    // yes, ugly, but we have a bunch of references to other files in the repo.\n    // we use the root package.json to determine what should be the version\n    // across the repo: in local builds, this should be 0.0.0 and in CI builds\n    // this would be the actual version of the repo after it's been aligned\n    // using scripts/align-version.sh\n    const expectedVersion = require(path.join(monoRepoRoot(), 'package.json')).version; // eslint-disable-line @typescript-eslint/no-require-imports\n    const ignore = [\n      '@aws-cdk/aws-service-spec',\n      '@aws-cdk/service-spec-importers',\n      '@aws-cdk/service-spec-types',\n      '@aws-cdk/cloudformation-diff',\n      '@aws-cdk/cx-api',\n      '@aws-cdk/cloud-assembly-schema',\n      '@aws-cdk/region-info',\n      // Private packages\n      ...fs.readdirSync(path.join(monoRepoRoot(), 'tools', '@aws-cdk')).map((name) => `@aws-cdk/${name}`),\n      // Packages in the @aws-cdk namespace that are vended outside of the monorepo\n      '@aws-cdk/asset-kubectl-v20',\n      '@aws-cdk/asset-node-proxy-agent-v6',\n      '@aws-cdk/asset-awscli-v1',\n    ];\n\n    for (const [depName, depVersion] of Object.entries(pkg.dependencies)) {\n      if (!isCdkModuleName(depName) || ignore.includes(depName)) {\n        continue;\n      }\n\n      const peerDep = pkg.peerDependencies[depName];\n      if (!peerDep) {\n        pkg.report({\n          ruleName: this.name,\n          message: `dependency ${depName} must also appear in peerDependencies`,\n          fix: () => pkg.addPeerDependency(depName, expectedVersion),\n        });\n      }\n\n      if (peerDep !== expectedVersion) {\n        pkg.report({\n          ruleName: this.name,\n          message: `peer dependency ${depName} should have the version ${expectedVersion}`,\n          fix: () => pkg.addPeerDependency(depName, expectedVersion),\n        });\n      }\n\n      if (depVersion !== expectedVersion) {\n        pkg.report({\n          ruleName: this.name,\n          message: `dependency ${depName}: dependency version must be ${expectedVersion}`,\n          fix: () => pkg.addDependency(depName, expectedVersion),\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, VPC, KMS resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const kmsKey = new kms.Key(this, 'DbSecurity');\n\n    new DatabaseCluster(this, 'Database', {\n      engine: DatabaseClusterEngine.auroraMysql({\n        version: AuroraMysqlEngineVersion.VER_3_07_1,\n      }),\n      vpc,\n      enablePerformanceInsights: true,\n      performanceInsightRetention: PerformanceInsightRetention.LONG_TERM,\n      performanceInsightEncryptionKey: kmsKey,\n      writer: ClusterInstance.provisioned('writer', {\n        instanceType: ec2.InstanceType.of(ec2.InstanceClass.R7G, ec2.InstanceSize.LARGE),\n      }),\n      readers: [ClusterInstance.provisioned('reader', {\n        instanceType: ec2.InstanceType.of(ec2.InstanceClass.R7G, ec2.InstanceSize.LARGE),\n      })],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, EC2, VPC resources", "output": "export class CodepipelineBuildDeployStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // modify gitignore file to remove unneeded files from the codecommit copy    \n    let gitignore = fs.readFileSync('.gitignore').toString().split(/\\r?\\n/);\n    gitignore.push('.git/');\n    gitignore = gitignore.filter(g => g != 'node_modules/');\n    gitignore.push('/node_modules/');\n    \n    const codeAsset = new Asset(this, 'SourceAsset', {\n      path: path.join(__dirname, \"../\"),\n      ignoreMode: IgnoreMode.GIT,\n      exclude: gitignore,\n    });\n    \n    const codeRepo = new codecommit.Repository(this, \"repo\", {\n      repositoryName: \"simple-code-repo\",\n      // Copies files from codepipeline-build-deploy directory to the repo as the initial commit\n      code: Code.fromAsset(codeAsset, 'main'),\n    });\n    \n    // Creates an Elastic Container Registry (ECR) image repository\n    const imageRepo = new ecr.Repository(this, \"imageRepo\");\n\n    // Creates a Task Definition for the ECS Fargate service\n    const fargateTaskDef = new ecs.FargateTaskDefinition(\n      this,\n      \"FargateTaskDef\"\n    );\n    fargateTaskDef.addContainer(\"container\", {\n      containerName: \"web\",\n      image: ecs.ContainerImage.fromEcrRepository(imageRepo),\n      portMappings: [{ containerPort: 80 }],\n    });\n\n    // CodeBuild project that builds the Docker image\n    const buildImage = new codebuild.Project(this, \"BuildImage\", {\n      buildSpec: codebuild.BuildSpec.fromSourceFilename(\"app/buildspec.yaml\"),\n      source: codebuild.Source.codeCommit({ repository: codeRepo }),\n      environment: {\n        privileged: true,\n        environmentVariables: {\n          AWS_ACCOUNT_ID: { value: process.env?.CDK_DEFAULT_ACCOUNT || \"\" },\n          REGION: { value: process.env?.CDK_DEFAULT_REGION || \"\" },\n          IMAGE_TAG: { value: \"latest\" },\n          IMAGE_REPO_NAME: { value: imageRepo.repositoryName },\n          REPOSITORY_URI: { value: imageRepo.repositoryUri },\n          TASK_DEFINITION_ARN: { value: fargateTaskDef.taskDefinitionArn },\n          TASK_ROLE_ARN: { value: fargateTaskDef.taskRole.roleArn },\n          EXECUTION_ROLE_ARN: { value: fargateTaskDef.executionRole?.roleArn },\n        },\n      },\n    });\n    \n    // CodeBuild project that builds the Docker image\n    const buildTest = new codebuild.Project(this, \"BuildTest\", {\n      buildSpec: codebuild.BuildSpec.fromSourceFilename(\"buildspec.yaml\"),\n      source: codebuild.Source.codeCommit({ repository: codeRepo }),\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.AMAZON_LINUX_2_4,  \n      }\n    });\n\n    // Grants CodeBuild project access to pull/push images from/to ECR repo\n    imageRepo.grantPullPush(buildImage);\n\n    // Lambda function that triggers CodeBuild image build project\n    const triggerCodeBuild = new lambda.Function(this, \"BuildLambda\", {\n      architecture: lambda.Architecture.ARM_64,\n      code: lambda.Code.fromAsset(\"./lambda\"),\n      handler: \"trigger-build.handler\",\n      runtime: lambda.Runtime.NODEJS_18_X,\n      environment: {\n        REGION: process.env.CDK_DEFAULT_REGION!,\n        CODEBUILD_PROJECT_NAME: buildImage.projectName,\n      },\n      // Allows this Lambda function to trigger the buildImage CodeBuild project\n      initialPolicy: [\n        new iam.PolicyStatement({\n          effect: iam.Effect.ALLOW,\n          actions: [\"codebuild:StartBuild\"],\n          resources: [buildImage.projectArn],\n        }),\n      ],\n    });\n\n    // Triggers a Lambda function using AWS SDK\n    const triggerLambda = new custom.AwsCustomResource(\n      this,\n      \"BuildLambdaTrigger\",\n      {\n        installLatestAwsSdk: true,\n        policy: custom.AwsCustomResourcePolicy.fromStatements([\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            actions: [\"lambda:InvokeFunction\"],\n            resources: [triggerCodeBuild.functionArn],\n          }),\n        ]),\n        onCreate: {\n          service: \"Lambda\",\n          action: \"invoke\",\n          physicalResourceId: custom.PhysicalResourceId.of(\"id\"),\n          parameters: {\n            FunctionName: triggerCodeBuild.functionName,\n            InvocationType: \"Event\",\n          },\n        },\n        onUpdate: {\n          service: \"Lambda\",\n          action: \"invoke\",\n          parameters: {\n            FunctionName: triggerCodeBuild.functionName,\n            InvocationType: \"Event\",\n          },\n        },\n      }\n    );\n\n    // Creates VPC for the ECS Cluster\n    const clusterVpc = new ec2.Vpc(this, \"ClusterVpc\", {\n      ipAddresses: ec2.IpAddresses.cidr(\"10.50.0.0/16\"),\n    });\n\n    // Deploys the cluster VPC after the initial image build triggers\n    clusterVpc.node.addDependency(triggerLambda);\n\n    // Creates a new blue Target Group that routes traffic from the public Application Load Balancer (ALB) to the\n    // registered targets within the Target Group e.g. (EC2 instances, IP addresses, Lambda functions)\n    // https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-target-groups.html\n    const targetGroupBlue = new elb.ApplicationTargetGroup(\n      this,\n      \"BlueTargetGroup\",\n      {\n        targetGroupName: \"alb-blue-tg\",\n        targetType: elb.TargetType.IP,\n        port: 80,\n        vpc: clusterVpc,\n      }\n    );\n\n    // Creates a new green Target Group\n    const targetGroupGreen = new elb.ApplicationTargetGroup(\n      this,\n      \"GreenTargetGroup\",\n      {\n        targetGroupName: \"alb-green-tg\",\n        targetType: elb.TargetType.IP,\n        port: 80,\n        vpc: clusterVpc,\n      }\n    );\n\n    // Creates a Security Group for the Application Load Balancer (ALB)\n    const albSg = new ec2.SecurityGroup(this, \"SecurityGroup\", {\n      vpc: clusterVpc,\n      allowAllOutbound: true,\n    });\n    albSg.addIngressRule(\n      ec2.Peer.anyIpv4(),\n      ec2.Port.tcp(80),\n      \"Allows access on port 80/http\",\n      false\n    );\n\n    // Creates a public ALB\n    const publicAlb = new elb.ApplicationLoadBalancer(this, \"PublicAlb\", {\n      vpc: clusterVpc,\n      internetFacing: true,\n      securityGroup: albSg,\n    });\n\n    // Adds a listener on port 80 to the ALB\n    const albListener = publicAlb.addListener(\"AlbListener80\", {\n      open: false,\n      port: 80,\n      defaultTargetGroups: [targetGroupBlue],\n    });\n\n    // Creates an ECS Fargate service\n    const fargateService = new ecs.FargateService(this, \"FargateService\", {\n      desiredCount: 1,\n      serviceName: \"fargate-frontend-service\",\n      taskDefinition: fargateTaskDef,\n      cluster: new ecs.Cluster(this, \"EcsCluster\", {\n        enableFargateCapacityProviders: true,\n        vpc: clusterVpc,\n      }),\n      // Sets CodeDeploy as the deployment controller\n      deploymentController: {\n        type: ecs.DeploymentControllerType.CODE_DEPLOY,\n      },\n    });\n\n    // Adds the ECS Fargate service to the ALB target group\n    fargateService.attachToApplicationTargetGroup(targetGroupBlue);\n\n    // Creates new pipeline artifacts\n    const sourceArtifact = new pipeline.Artifact(\"SourceArtifact\");\n    const buildArtifact = new pipeline.Artifact(\"BuildArtifact\");\n\n    // Creates the source stage for CodePipeline\n    const sourceStage = {\n      stageName: \"Source\",\n      actions: [\n        new pipelineactions.CodeCommitSourceAction({\n          actionName: \"AppCodeCommit\",\n          branch: \"main\",\n          output: sourceArtifact,\n          repository: codeRepo,\n        }),\n      ],\n    };\n\n    // Run jest test and send result to CodeBuild    \n    const testStage = {\n      stageName: \"Test\",\n      actions: [\n        new pipelineactions.CodeBuildAction({\n          actionName: \"JestCDK\",\n          input: new pipeline.Artifact(\"SourceArtifact\"),\n          project: buildTest,\n        }),\n      ],\n    };\n\n    // Creates the build stage for CodePipeline\n    const buildStage = {\n      stageName: \"Build\",\n      actions: [\n        new pipelineactions.CodeBuildAction({\n          actionName: \"DockerBuildPush\",\n          input: new pipeline.Artifact(\"SourceArtifact\"),\n          project: buildImage,\n          outputs: [buildArtifact],\n        }),\n      ],\n    };\n\n    // Creates a new CodeDeploy Deployment Group\n    const deploymentGroup = new codedeploy.EcsDeploymentGroup(\n      this,\n      \"CodeDeployGroup\",\n      {\n        service: fargateService,\n        // Configurations for CodeDeploy Blue/Green deployments\n        blueGreenDeploymentConfig: {\n          listener: albListener,\n          blueTargetGroup: targetGroupBlue,\n          greenTargetGroup: targetGroupGreen,\n        },\n      }\n    );\n\n    // Creates the deploy stage for CodePipeline\n    const deployStage = {\n      stageName: \"Deploy\",\n      actions: [\n        new pipelineactions.CodeDeployEcsDeployAction({\n          actionName: \"EcsFargateDeploy\",\n          appSpecTemplateInput: buildArtifact,\n          taskDefinitionTemplateInput: buildArtifact,\n          deploymentGroup: deploymentGroup,\n        }),\n      ],\n    };\n\n    // Creates an AWS CodePipeline with source, build, and deploy stages\n    new pipeline.Pipeline(this, \"BuildDeployPipeline\", {\n      pipelineName: \"ImageBuildDeployPipeline\",\n      stages: [sourceStage, testStage, buildStage, deployStage],\n    });\n\n    // Outputs the ALB public endpoint\n    new cdk.CfnOutput(this, \"PublicAlbEndpoint\", {\n      value: \"http://\" + publicAlb.loadBalancerDnsName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class DockerImageFunction for AWS resource management", "output": "export class DockerImageFunction extends Function {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-lambda.DockerImageFunction';\n\n  constructor(scope: Construct, id: string, props: DockerImageFunctionProps) {\n    super(scope, id, {\n      ...props,\n      handler: Handler.FROM_IMAGE,\n      runtime: Runtime.FROM_IMAGE,\n      code: props.code._bind(props.architecture),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ServerResources for AWS resource management", "output": "export class ServerResources extends Construct {\n  public instance: Instance;\n\n  constructor(scope: Construct, id: string, props: ServerProps) {\n    super(scope, id);\n\n    // Create an Asset Bucket for the Instance.  Assets in this bucket will be downloaded to the EC2 during deployment\n    const assetBucket = new Bucket(this, 'assetBucket', {\n      publicReadAccess: false,\n      removalPolicy: RemovalPolicy.DESTROY,\n      objectOwnership: ObjectOwnership.BUCKET_OWNER_PREFERRED,\n      autoDeleteObjects: true,\n    });\n\n    // Deploy the local assets to the Asset Bucket during the CDK deployment\n    new BucketDeployment(this, 'assetBucketDeployment', {\n      sources: [Source.asset('lib/resources/server/assets')],\n      destinationBucket: assetBucket,\n      retainOnDelete: false,\n      exclude: ['**/node_modules/**', '**/dist/**'],\n      memoryLimit: 512,\n    });\n\n    // Create a role for the EC2 instance to assume.  This role will allow the instance to put log events to CloudWatch Logs\n    const serverRole = new Role(this, 'serverEc2Role', {\n      assumedBy: new ServicePrincipal('ec2.amazonaws.com'),\n      inlinePolicies: {\n        ['RetentionPolicy']: new PolicyDocument({\n          statements: [\n            new PolicyStatement({\n              resources: ['*'],\n              actions: ['logs:PutRetentionPolicy'],\n            }),\n          ],\n        }),\n      },\n      managedPolicies: [\n        ManagedPolicy.fromAwsManagedPolicyName('AmazonSSMManagedInstanceCore'),\n        ManagedPolicy.fromAwsManagedPolicyName('CloudWatchAgentServerPolicy'),\n      ],\n    });\n\n    // Grant the EC2 role access to the bucket\n    assetBucket.grantReadWrite(serverRole);\n\n    const userData = UserData.forLinux();\n\n    // Add user data that is used to configure the EC2 instance\n    userData.addCommands(\n      'yum update -y',\n      'curl -sL https://dl.yarnpkg.com/rpm/yarn.repo | sudo tee /etc/yum.repos.d/yarn.repo',\n      'curl -sL https://rpm.nodesource.com/setup_18.x | sudo -E bash - ',\n      'yum install -y amazon-cloudwatch-agent nodejs python3-pip zip unzip docker yarn',\n      'sudo systemctl enable docker',\n      'sudo systemctl start docker',\n      'mkdir -p /home/ec2-user/sample',\n      'aws s3 cp s3://' +\n        assetBucket.bucketName +\n        '/sample /home/ec2-user/sample --recursive',\n    );\n\n    // Create a Security Group for the EC2 instance.  This group will allow SSH access to the EC2 instance\n    const ec2InstanceSecurityGroup = new SecurityGroup(\n      this,\n      'ec2InstanceSecurityGroup',\n      { vpc: props.vpc, allowAllOutbound: true },\n    );\n\n    // Determine the correct CPUType and Instance Class based on the props passed in\n    if (props.cpuType == 'ARM64') {\n      cpuType = AmazonLinuxCpuType.ARM_64;\n      instanceClass = InstanceClass.M7G;\n    } else {\n      cpuType = AmazonLinuxCpuType.X86_64;\n      instanceClass = InstanceClass.M5;\n    }\n\n    // Determine the correct InstanceSize based on the props passed in\n    switch (props.instanceSize) {\n      case 'large':\n        instanceSize = InstanceSize.LARGE;\n        break;\n      case 'xlarge':\n        instanceSize = InstanceSize.XLARGE;\n        break;\n      case 'xlarge2':\n        instanceSize = InstanceSize.XLARGE2;\n        break;\n      case 'xlarge4':\n        instanceSize = InstanceSize.XLARGE4;\n        break;\n      default:\n        instanceSize = InstanceSize.LARGE;\n    }\n\n    // Create the EC2 instance\n    this.instance = new Instance(this, 'Instance', {\n      vpc: props.vpc,\n      instanceType: InstanceType.of(instanceClass, instanceSize),\n      machineImage: MachineImage.latestAmazonLinux2023({\n        cachedInContext: false,\n        cpuType: cpuType,\n      }),\n      userData: userData,\n      securityGroup: ec2InstanceSecurityGroup,\n      init: CloudFormationInit.fromConfigSets({\n        configSets: {\n          default: ['config'],\n        },\n        configs: {\n          config: new InitConfig([\n            InitFile.fromObject('/etc/config.json', {\n              // Use CloudformationInit to create an object on the EC2 instance\n              STACK_ID: Stack.of(this).artifactId,\n            }),\n            InitFile.fromFileInline(\n              // Use CloudformationInit to copy a file to the EC2 instance\n              '/tmp/amazon-cloudwatch-agent.json',\n              './lib/resources/server/config/amazon-cloudwatch-agent.json',\n            ),\n            InitFile.fromFileInline(\n              '/etc/config.sh',\n              'lib/resources/server/config/config.sh',\n            ),\n            InitFile.fromString(\n              // Use CloudformationInit to write a string to the EC2 instance\n              '/home/ec2-user/.ssh/authorized_keys',\n              props.sshPubKey + '\\n',\n            ),\n            InitCommand.shellCommand('chmod +x /etc/config.sh'), // Use CloudformationInit to run a shell command on the EC2 instance\n            InitCommand.shellCommand('/etc/config.sh'),\n          ]),\n        },\n      }),\n\n      initOptions: {\n        timeout: Duration.minutes(10),\n        includeUrl: true,\n        includeRole: true,\n        printLog: true,\n      },\n      role: serverRole,\n    });\n\n    // Add the SSH Security Group to the EC2 instance\n    this.instance.addSecurityGroup(props.sshSecurityGroup);\n  }\n}", "language": "typescript"}
{"input": "Represents a Glue Job's Code assets (an asset can be a scripts, a jar, a python file or any other file).", "output": "class Code {\n  /**\n   * Job code as an S3 object.\n   * @param bucket The S3 bucket\n   * @param key The object key\n   */\n  public static fromBucket(bucket: s3.IBucket, key: string): S3Code {\n    return new S3Code(bucket, key);\n  }\n\n  /**\n   * Job code from a local disk path.\n   *\n   * @param path code file (not a directory).\n   */\n  public static fromAsset(path: string, options?: s3assets.AssetOptions): AssetCode {\n    return new AssetCode(path, options);\n  }\n\n  /**\n   * Called when the Job is initialized to allow this object to bind.\n   */\n  public abstract bind(scope: constructs.Construct, grantable: iam.IGrantable): CodeConfig;\n}", "language": "typescript"}
{"input": "CDK class RuntimeEndpoint for AWS resource management", "output": "export class RuntimeEndpoint extends RuntimeEndpointBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-agentcore-alpha.RuntimeEndpoint';\n\n  /**\n   * Import an existing Agent Runtime Endpoint using attributes\n   * This allows you to reference an Agent Runtime Endpoint that was created outside of CDK\n   *\n   * @param scope The construct scope\n   * @param id The construct id\n   * @param attrs The attributes of the existing Agent Runtime Endpoint\n   * @returns An IRuntimeEndpoint instance representing the imported endpoint\n   */\n  public static fromRuntimeEndpointAttributes(\n    scope: Construct,\n    id: string,\n    attrs: RuntimeEndpointAttributes,\n  ): IRuntimeEndpoint {\n    class ImportedBedrockAgentRuntimeEndpoint extends RuntimeEndpointBase {\n      public readonly agentRuntimeEndpointArn = attrs.agentRuntimeEndpointArn;\n      public readonly endpointName = attrs.endpointName;\n      public readonly agentRuntimeArn = attrs.agentRuntimeArn;\n      public readonly description = attrs.description;\n      public readonly status = attrs.status;\n      public readonly liveVersion = attrs.liveVersion;\n      public readonly targetVersion = attrs.targetVersion;\n      public readonly createdAt = attrs.createdAt;\n      public readonly endpointId = attrs.endpointId;\n      public readonly lastUpdatedAt = attrs.lastUpdatedAt;\n    }\n\n    return new ImportedBedrockAgentRuntimeEndpoint(scope, id);\n  }\n\n  // Properties from base interface\n  /**\n   * The ARN of the agent runtime endpoint\n   * @attribute\n   * @returns a token representing the ARN of this agent runtime endpoint\n   */\n  public readonly agentRuntimeEndpointArn: string;\n  /**\n   * The name of the endpoint\n   * @attribute\n   * @returns a token representing the name of this endpoint\n   */\n  public readonly endpointName: string;\n  /**\n   * The ARN of the agent runtime associated with this endpoint\n   * @attribute\n   * @returns a token representing the ARN of the agent runtime\n   */\n  public readonly agentRuntimeArn: string;\n  /**\n   * The status of the endpoint\n   * @attribute\n   * @returns a token representing the status of this endpoint\n   */\n  public readonly status?: string;\n  /**\n   * The live version of the endpoint\n   * @attribute\n   * @returns a token representing the live version of this endpoint\n   */\n  public readonly liveVersion?: string;\n  /**\n   * The target version of the endpoint\n   * @attribute\n   * @returns a token representing the target version of this endpoint\n   */\n  public readonly targetVersion?: string;\n  /**\n   * The timestamp when the endpoint was created\n   * @attribute\n   * @returns a token representing the creation timestamp of this endpoint\n   */\n  public readonly createdAt?: string;\n  /**\n   * Optional description for the endpoint\n   */\n  public readonly description?: string;\n  /**\n   * The unique identifier of the runtime endpoint\n   * @attribute\n   * @returns a token representing the ID of this endpoint\n   */\n  public readonly endpointId: string;\n  /**\n   * The ID of the agent runtime associated with this endpoint\n   */\n  public readonly agentRuntimeId: string;\n  /**\n   * The version of the agent runtime used by this endpoint\n   */\n  public readonly agentRuntimeVersion: string;\n  /**\n   * When this endpoint was last updated\n   * @attribute\n   * @returns a token representing the last update timestamp of this endpoint\n   */\n  public readonly lastUpdatedAt?: string;\n\n  private readonly endpointResource: bedrockagentcore.CfnRuntimeEndpoint;\n\n  constructor(scope: Construct, id: string, props: RuntimeEndpointProps) {\n    super(scope, id);\n\n    // CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Set and validate properties immediately\n    this.endpointName = props.endpointName;\n    this.validateEndpointName();\n\n    this.agentRuntimeId = props.agentRuntimeId;\n    this.validateAgentRuntimeId();\n\n    this.agentRuntimeVersion = props.agentRuntimeVersion ?? '1';\n    this.validateAgentRuntimeVersion();\n\n    this.description = props.description;\n    if (this.description) {\n      this.validateDescription();\n    }\n\n    if (props.tags) {\n      this.validateTags(props.tags);\n    }\n\n    const cfnProps: bedrockagentcore.CfnRuntimeEndpointProps = {\n      name: this.endpointName,\n      agentRuntimeId: Lazy.string({\n        produce: () => this.renderAgentRuntimeId(),\n      }),\n      agentRuntimeVersion: Lazy.string({\n        produce: () => this.renderAgentRuntimeVersion(),\n      }),\n      description: Lazy.string({\n        produce: () => this.renderDescription(),\n      }),\n      tags: props.tags ?? {},\n    };\n\n    this.endpointResource = new bedrockagentcore.CfnRuntimeEndpoint(this, 'Resource', cfnProps);\n\n    this.endpointId = this.endpointResource.attrId;\n    this.agentRuntimeEndpointArn = this.endpointResource.attrAgentRuntimeEndpointArn;\n    this.agentRuntimeArn = this.endpointResource.attrAgentRuntimeArn;\n    this.status = this.endpointResource.attrStatus;\n    this.liveVersion = this.endpointResource.attrLiveVersion;\n    this.targetVersion = this.endpointResource.attrTargetVersion;\n    this.createdAt = this.endpointResource.attrCreatedAt;\n    this.lastUpdatedAt = this.endpointResource.attrLastUpdatedAt;\n  }\n\n  /**\n   * Renders the agent runtime ID for CloudFormation\n   * @internal\n   */\n  private renderAgentRuntimeId(): string {\n    return this.agentRuntimeId;\n  }\n\n  /**\n   * Renders the agent runtime version for CloudFormation\n   * @internal\n   */\n  private renderAgentRuntimeVersion(): string {\n    return this.agentRuntimeVersion;\n  }\n\n  /**\n   * Renders the description for CloudFormation\n   * @internal\n   */\n  private renderDescription(): string | undefined {\n    return this.description;\n  }\n\n  /**\n   * Validates the endpoint name format\n   * Pattern: ^[a-zA-Z][a-zA-Z0-9_]{0,47}$\n   * @throws Error if validation fails\n   */\n  private validateEndpointName(): void {\n    // Skip validation if the name contains CDK tokens (unresolved values)\n    if (Token.isUnresolved(this.endpointName)) {\n      return;\n    }\n\n    // Validate length\n    const lengthErrors = validateStringField({\n      value: this.endpointName,\n      fieldName: 'Endpoint name',\n      minLength: 1,\n      maxLength: 48,\n    });\n\n    // Validate pattern\n    const patternErrors = validateFieldPattern(\n      this.endpointName,\n      'Endpoint name',\n      /^[a-zA-Z][a-zA-Z0-9_]{0,47}$/,\n      'Endpoint name must start with a letter and contain only letters, numbers, and underscores',\n    );\n\n    // Combine and throw if any errors\n    const allErrors = [...lengthErrors, ...patternErrors];\n    if (allErrors.length > 0) {\n      throw new ValidationError(allErrors.join('\\n'));\n    }\n  }\n\n  /**\n   * Validates the description format\n   * Must be between 1 and 256 characters (per CloudFormation specification)\n   * @throws Error if validation fails\n   */\n  private validateDescription(): void {\n    if (Token.isUnresolved(this.description)) {\n      return;\n    }\n\n    if (this.description) {\n      const errors = validateStringField({\n        value: this.description,\n        fieldName: 'Description',\n        minLength: 1,\n        maxLength: 256,\n      });\n\n      if (errors.length > 0) {\n        throw new ValidationError(errors.join('\\n'));\n      }\n    }\n  }\n\n  /**\n   * Validates the agent runtime ID format\n   * Pattern: ^[a-zA-Z][a-zA-Z0-9_]{0,99}-[a-zA-Z0-9]{10}$\n   * @throws Error if validation fails\n   */\n  private validateAgentRuntimeId(): void {\n    // Skip validation if the ID contains CDK tokens (unresolved values)\n    if (Token.isUnresolved(this.agentRuntimeId)) {\n      return;\n    }\n\n    // Validate pattern only (no length validation per AWS specs)\n    const patternErrors = validateFieldPattern(\n      this.agentRuntimeId,\n      'Agent runtime ID',\n      /^[a-zA-Z][a-zA-Z0-9_]{0,99}-[a-zA-Z0-9]{10}$/,\n      'Agent runtime ID must start with a letter, followed by up to 99 alphanumeric or underscore characters, then a hyphen, and exactly 10 alphanumeric characters',\n    );\n\n    if (patternErrors.length > 0) {\n      throw new ValidationError(patternErrors.join('\\n'));\n    }\n  }\n\n  /**\n   * Validates the agent runtime version format\n   * Pattern: ^([1-9][0-9]{0,4})$\n   * @throws Error if validation fails\n   */\n  private validateAgentRuntimeVersion(): void {\n    if (Token.isUnresolved(this.agentRuntimeVersion)) {\n      return;\n    }\n\n    // Validate pattern only (no length validation per AWS specs)\n    const patternErrors = validateFieldPattern(\n      this.agentRuntimeVersion,\n      'Agent runtime version',\n      /^[1-9]\\d{0,4}$/,\n      'Agent runtime version must be a number between 1 and 99999',\n    );\n\n    if (patternErrors.length > 0) {\n      throw new ValidationError(patternErrors.join('\\n'));\n    }\n  }\n\n  /**\n   * Validates the tags format\n   * @param tags The tags object to validate\n   * @throws Error if validation fails\n   */\n  private validateTags(tags: { [key: string]: string }): void {\n    for (const [key, value] of Object.entries(tags)) {\n      if (Token.isUnresolved(key) || Token.isUnresolved(value)) {\n        continue;\n      }\n\n      // Validate tag key length\n      const keyLengthErrors = validateStringField({\n        value: key,\n        fieldName: `Tag key \"${key}\"`,\n        minLength: 1,\n        maxLength: 256,\n      });\n\n      // Validate tag key pattern\n      const keyPatternErrors = validateFieldPattern(\n        key,\n        `Tag key \"${key}\"`,\n        /^[a-zA-Z0-9\\s._:/=+@-]*$/,\n        `Tag key \"${key}\" can only contain letters (a-z, A-Z), numbers (0-9), spaces, and special characters (._:/=+@-)`,\n      );\n\n      // Combine key errors and throw if any\n      const keyErrors = [...keyLengthErrors, ...keyPatternErrors];\n      if (keyErrors.length > 0) {\n        throw new ValidationError(keyErrors.join('\\n'));\n      }\n\n      if (value === undefined || value === null) {\n        throw new ValidationError(`Tag value for key \"${key}\" cannot be null or undefined`);\n      }\n\n      // Validate tag value length\n      const valueLengthErrors = validateStringField({\n        value: value,\n        fieldName: `Tag value for key \"${key}\"`,\n        minLength: 0,\n        maxLength: 256,\n      });\n\n      // Validate tag value pattern\n      const valuePatternErrors = validateFieldPattern(\n        value,\n        `Tag value for key \"${key}\"`,\n        /^[a-zA-Z0-9\\s._:/=+@-]*$/,\n        `Tag value for key \"${key}\" can only contain letters (a-z, A-Z), numbers (0-9), spaces, and special characters (._:/=+@-)`,\n      );\n\n      // Combine value errors and throw if any\n      const valueErrors = [...valueLengthErrors, ...valuePatternErrors];\n      if (valueErrors.length > 0) {\n        throw new ValidationError(valueErrors.join('\\n'));\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: aws lambda invoke --function-name <function name> --invocation-type Event --payload $(base64 <<<''OK'') response.json", "output": "class TestStack extends Stack {\n  public readonly functionNames: string[] = [];\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const pythonFunction39 = new lambda.PythonFunction(this, 'my_handler_inline', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_9,\n    });\n    this.functionNames.push(pythonFunction39.functionName);\n\n    const pythonFunction310 = new lambda.PythonFunction(this, 'my_handler_python_310', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_10,\n    });\n    this.functionNames.push(pythonFunction310.functionName);\n\n    const pythonFunction311 = new lambda.PythonFunction(this, 'my_handler_python_311', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_11,\n    });\n    this.functionNames.push(pythonFunction311.functionName);\n\n    const pythonFunction39Excludes = new lambda.PythonFunction(this, 'my_handler_inline_excludes', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_9,\n      bundling: {\n        assetExcludes: ['.ignorefile'],\n      },\n    });\n    this.functionNames.push(pythonFunction39Excludes.functionName);\n\n    const pythonFunction310Excludes = new lambda.PythonFunction(this, 'my_handler_python_310_excludes', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_10,\n      bundling: {\n        assetExcludes: ['.ignorefile'],\n      },\n    });\n    this.functionNames.push(pythonFunction310Excludes.functionName);\n\n    const pythonFunction311Excludes = new lambda.PythonFunction(this, 'my_handler_python_311_excludes', {\n      entry: path.join(__dirname, 'lambda-handler-pipenv'),\n      runtime: Runtime.PYTHON_3_11,\n      bundling: {\n        assetExcludes: ['.ignorefile'],\n      },\n    });\n    this.functionNames.push(pythonFunction311Excludes.functionName);\n  }\n}", "language": "typescript"}
{"input": "Error thrown to skip generation of an event and discard all generated code for it", "output": "class SkipEventError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'SkipEventError';\n  }\n}", "language": "typescript"}
{"input": "CDK class ScalaSparkStreamingJob for AWS resource management", "output": "export class ScalaSparkStreamingJob extends SparkJob {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.ScalaSparkStreamingJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n\n  /**\n   * ScalaSparkStreamingJob constructor\n   */\n  constructor(scope: Construct, id: string, props: ScalaSparkStreamingJobProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...this.executableArguments(props),\n      ...this.nonExecutableCommonArguments(props),\n    };\n\n    if ((!props.workerType && props.numberOfWorkers !== undefined) || (props.workerType && props.numberOfWorkers === undefined)) {\n      throw new ValidationError('Both workerType and numberOfWorkers must be set', this);\n    }\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.STREAMING,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n      },\n      glueVersion: props.glueVersion ? props.glueVersion : GlueVersion.V4_0,\n      workerType: props.workerType ? props.workerType : WorkerType.G_1X,\n      numberOfWorkers: props.numberOfWorkers ? props.numberOfWorkers : 10,\n      maxRetries: props.jobRunQueuingEnabled ? 0 : props.maxRetries,\n      jobRunQueuingEnabled: props.jobRunQueuingEnabled ? props.jobRunQueuingEnabled : false,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      defaultArguments,\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n\n  /**\n   * Set the executable arguments with best practices enabled by default\n   *\n   * @returns An array of arguments for Glue to use on execution\n   */\n  private executableArguments(props: ScalaSparkStreamingJobProps) {\n    const args: { [key: string]: string } = {};\n    args['--job-language'] = JobLanguage.SCALA;\n    args['--class'] = props.className;\n    this.setupExtraCodeArguments(args, props);\n    return args;\n  }\n}", "language": "typescript"}
{"input": "Interface for classes that provide the connection-specification parts of a security group rule", "output": "export class Port {\n  /**\n   * A single TCP port\n   */\n  public static tcp(port: number): Port {\n    return new Port({\n      protocol: Protocol.TCP,\n      fromPort: port,\n      toPort: port,\n    });\n  }\n\n  /**\n   * A TCP port range\n   */\n  public static tcpRange(startPort: number, endPort: number) {\n    return new Port({\n      protocol: Protocol.TCP,\n      fromPort: startPort,\n      toPort: endPort,\n    });\n  }\n\n  /**\n   * Any TCP traffic\n   */\n  public static allTcp() {\n    return new Port({\n      protocol: Protocol.TCP,\n      fromPort: 1026,\n      toPort: 60000,\n    });\n  }\n\n  /**\n   * A single UDP port\n   */\n  public static udp(port: number): Port {\n    return new Port({\n      protocol: Protocol.UDP,\n      fromPort: port,\n      toPort: port,\n    });\n  }\n\n  /**\n   * A UDP port range\n   */\n  public static udpRange(startPort: number, endPort: number) {\n    return new Port({\n      protocol: Protocol.UDP,\n      fromPort: startPort,\n      toPort: endPort,\n    });\n  }\n\n  /**\n   * Any UDP traffic\n   */\n  public static allUdp() {\n    return new Port({\n      protocol: Protocol.UDP,\n      fromPort: 1026,\n      toPort: 60000,\n    });\n  }\n\n  constructor(private readonly props: PortProps) {}\n\n  /**\n   * Produce the ingress rule JSON for the given connection\n   */\n  public toJson(): any {\n    return {\n      protocol: this.props.protocol,\n      fromPort: this.props.fromPort,\n      toPort: this.props.toPort,\n    };\n  }\n}", "language": "typescript"}
{"input": "Class for configuring application load balancer listener when registering targets.", "output": "class ApplicationListenerConfig extends ListenerConfig {\n  constructor(private readonly listener: elbv2.ApplicationListener, private readonly props?: elbv2.AddApplicationTargetsProps) {\n    super();\n  }\n\n  /**\n   * Create and attach a target group to listener.\n   */\n  public addTargets(id: string, target: LoadBalancerTargetOptions, service: BaseService) {\n    const props = this.props || {};\n    const protocol = props.protocol;\n    const port = props.port ?? (protocol === elbv2.ApplicationProtocol.HTTPS ? 443 : 80);\n    this.listener.addTargets(id, {\n      ...props,\n      targets: [\n        service.loadBalancerTarget({\n          ...target,\n        }),\n      ],\n      port,\n    });\n  }\n}", "language": "typescript"}
{"input": "Determines whether any HTTP headers (and if so, which headers) are included in requests that CloudFront sends to the origin.", "output": "export class OriginRequestHeaderBehavior {\n  /**\n   * HTTP headers are not included in requests that CloudFront sends to the origin.\n   * Any headers that are listed in a CachePolicy are still included in origin requests.\n   */\n  public static none() { return new OriginRequestHeaderBehavior('none'); }\n\n  /**\n   * All HTTP headers in viewer requests are included in requests that CloudFront sends to the origin.\n   * Additionally, any additional CloudFront headers provided are included; the additional headers are added by CloudFront.\n   * @see https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-cloudfront-headers.html\n   */\n  public static all(...cloudfrontHeaders: string[]) {\n    if (cloudfrontHeaders.length > 0) {\n      if (!cloudfrontHeaders.every(header => header.startsWith('CloudFront-'))) {\n        throw new UnscopedValidationError('additional CloudFront headers passed to `OriginRequestHeaderBehavior.all()` must begin with \\'CloudFront-\\'');\n      }\n      return new OriginRequestHeaderBehavior('allViewerAndWhitelistCloudFront', cloudfrontHeaders);\n    } else {\n      return new OriginRequestHeaderBehavior('allViewer');\n    }\n  }\n\n  /** Listed headers are included in requests that CloudFront sends to the origin. */\n  public static allowList(...headers: string[]) {\n    if (headers.length === 0) {\n      throw new UnscopedValidationError('At least one header to allow must be provided');\n    }\n    if (headers.map(header => header.toLowerCase()).some(header => ['authorization', 'accept-encoding'].includes(header))) {\n      throw new UnscopedValidationError('you cannot pass `Authorization` or `Accept-Encoding` as header values; use a CachePolicy to forward these headers instead');\n    }\n    return new OriginRequestHeaderBehavior('whitelist', headers);\n  }\n\n  /** All headers except the provided `headers` are included in requests that CloudFront sends to the origin. */\n  public static denyList(...headers: string[]) {\n    if (headers.length === 0) {\n      throw new UnscopedValidationError('At least one header to deny must be provided');\n    }\n    return new OriginRequestHeaderBehavior('allExcept', headers);\n  }\n\n  /** The behavior of headers: allow all, none or an allow list. */\n  public readonly behavior: string;\n  /** The headers for the allow list or the included CloudFront headers, if applicable. */\n  public readonly headers?: string[];\n\n  private constructor(behavior: string, headers?: string[]) {\n    this.behavior = behavior;\n    this.headers = headers;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, MSK (Kafka), CloudFormation, ECS resources", "output": "export class ECSStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props?: ECSStackProps) {\n        super(scope, id, props);\n\n        const cluster = new ecs.Cluster(this, 'Cluster', {\n            vpc: props?.vpc\n        });\n\n        const loadBalancedFargateService = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'Service', {\n            cluster,\n            memoryLimitMiB: 512,\n            desiredCount: 1,\n            cpu: 256,\n            taskImageOptions: {\n                image: ecs.ContainerImage.fromAsset('app', {}),\n            },\n        });\n\n        loadBalancedFargateService.targetGroup.configureHealthCheck({\n            path: '/health',\n        });\n    }\n}", "language": "typescript"}
{"input": "CDK class TestCustomResource for AWS resource management", "output": "class TestCustomResource extends Construct {\n  public readonly resource: CustomResource;\n\n  constructor(scope: Construct, id: string, opts: { removalPolicy?: cdk.RemovalPolicy } = {}) {\n    super(scope, id);\n\n    const singletonLambda = new lambda.SingletonFunction(this, 'Lambda', {\n      uuid: 'TestCustomResourceProvider',\n      code: new lambda.InlineCode('def hello(): pass'),\n      runtime: lambda.Runtime.PYTHON_3_9,\n      handler: 'index.hello',\n      timeout: cdk.Duration.minutes(5),\n    });\n\n    this.resource = new CustomResource(this, 'Resource', {\n      ...opts,\n      provider: CustomResourceProvider.fromLambda(singletonLambda),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, IAM, Kinesis resources", "output": "class TestStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new Vpc(this, 'VPC', { natGateways: 1 });\n\n    new FlowLog(this, 'FlowLogsCW', {\n      resourceType: FlowLogResourceType.fromVpc(vpc),\n      flowLogName: 'CustomFlowLogName',\n    });\n\n    const destinationBucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    const deliveryStreamRole = new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n    });\n    destinationBucket.grantReadWrite(deliveryStreamRole);\n    deliveryStreamRole.addToPolicy(new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      actions: [\n        'kinesis:DescribeStream',\n        'kinesis:GetShardIterator',\n        'kinesis:GetRecords',\n        'kinesis:ListShards',\n      ],\n      resources: ['*'],\n    }));\n\n    const deliveryStream = new firehose.CfnDeliveryStream(this, 'DeliveryStream', {\n      s3DestinationConfiguration: {\n        bucketArn: destinationBucket.bucketArn,\n        roleArn: deliveryStreamRole.roleArn,\n      },\n    });\n\n    vpc.addFlowLog('FlowLogsKinesisDataFirehose', {\n      destination: FlowLogDestination.toKinesisDataFirehoseDestination(deliveryStream.attrArn),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, SSM Parameter Store, WAF resources", "output": "export class EventBridgeLambdaStack extends cdk.Stack {\n  constructor(app: cdk.App, id: string) {\n    super(app, id);\n\n    // SNS Topic\n    const topic = new sns.Topic(this, 'Topic', {\n      displayName: 'Lambda SNS Topic',\n    });\n\n    //Email Variable\n    const emailaddress = new CfnParameter(this, \"email\", {\n      type: \"String\",\n      description: \"The name of the Amazon S3 bucket where uploaded files will be stored.\"});\n\n    // Subscription to the topic\n    topic.addSubscription(new subscriptions.EmailSubscription(emailaddress.valueAsString));\n\n    // Lambda Function to publish message to SNS\n    const lambdaFn = new lambda.Function(this, 'Singleton', {\n      code: new lambda.InlineCode(fs.readFileSync('lambda-handler.py', { encoding: 'utf-8' })),\n      handler: 'index.main',\n      timeout: cdk.Duration.seconds(300),\n      runtime: lambda.Runtime.PYTHON_3_9,\n      environment: {'TOPIC_ARN': topic.topicArn}\n      \n    });\n\n    // Run the eventbridge every minute\n    const rule = new events.Rule(this, 'Rule', {\n      schedule: events.Schedule.expression('cron(* * ? * * *)')\n    });\n\n    // Add the lambda function as a target to the eventbridge\n    rule.addTarget(new targets.LambdaFunction(lambdaFn));\n\n    // Add the permission to the lambda function to publish to SNS\n    const snsTopicPolicy = new iam.PolicyStatement({\n      actions: ['sns:publish'],\n      resources: ['*'],\n    });\n\n    // Add the permission to the lambda function to publish to SNS\n    lambdaFn.addToRolePolicy(snsTopicPolicy);\n\n  }\n}", "language": "typescript"}
{"input": "Possible Instances Types to use in Neptune cluster used for defining `DatabaseClusterProps.engineVersion`.", "output": "export class EngineVersion {\n  /**\n   * Neptune engine version 1.0.1.0\n   */\n  public static readonly V1_0_1_0 = new EngineVersion('1.0.1.0');\n  /**\n   * Neptune engine version 1.0.1.1\n   */\n  public static readonly V1_0_1_1 = new EngineVersion('1.0.1.1');\n  /**\n   * Neptune engine version 1.0.1.2\n   */\n  public static readonly V1_0_1_2 = new EngineVersion('1.0.1.2');\n  /**\n   * Neptune engine version 1.0.2.1\n   */\n  public static readonly V1_0_2_1 = new EngineVersion('1.0.2.1');\n  /**\n   * Neptune engine version 1.0.2.2\n   */\n  public static readonly V1_0_2_2 = new EngineVersion('1.0.2.2');\n  /**\n   * Neptune engine version 1.0.3.0\n   */\n  public static readonly V1_0_3_0 = new EngineVersion('1.0.3.0');\n  /**\n   * Neptune engine version 1.0.4.0\n   */\n  public static readonly V1_0_4_0 = new EngineVersion('1.0.4.0');\n  /**\n   * Neptune engine version 1.0.4.1\n   */\n  public static readonly V1_0_4_1 = new EngineVersion('1.0.4.1');\n  /**\n   * Neptune engine version 1.0.5.0\n   */\n  public static readonly V1_0_5_0 = new EngineVersion('1.0.5.0');\n  /**\n   * Neptune engine version 1.1.0.0\n   */\n  public static readonly V1_1_0_0 = new EngineVersion('1.1.0.0');\n  /**\n   * Neptune engine version 1.1.1.0\n   */\n  public static readonly V1_1_1_0 = new EngineVersion('1.1.1.0');\n  /**\n   * Neptune engine version 1.2.0.0\n   */\n  public static readonly V1_2_0_0 = new EngineVersion('1.2.0.0');\n  /**\n   * Neptune engine version 1.2.0.1\n   */\n  public static readonly V1_2_0_1 = new EngineVersion('1.2.0.1');\n  /**\n   * Neptune engine version 1.2.0.2\n   */\n  public static readonly V1_2_0_2 = new EngineVersion('1.2.0.2');\n  /**\n   * Neptune engine version 1.2.1.0\n   */\n  public static readonly V1_2_1_0 = new EngineVersion('1.2.1.0');\n  /**\n   * Neptune engine version 1.2.1.1\n   */\n  public static readonly V1_2_1_1 = new EngineVersion('1.2.1.1');\n  /**\n   * Neptune engine version 1.2.1.2\n   */\n  public static readonly V1_2_1_2 = new EngineVersion('1.2.1.2');\n  /**\n   * Neptune engine version 1.3.0.0\n   */\n  public static readonly V1_3_0_0 = new EngineVersion('1.3.0.0');\n  /**\n   * Neptune engine version 1.3.1.0\n   */\n  public static readonly V1_3_1_0 = new EngineVersion('1.3.1.0');\n  /**\n   * Neptune engine version 1.3.2.0\n   */\n  public static readonly V1_3_2_0 = new EngineVersion('1.3.2.0');\n  /**\n   * Neptune engine version 1.3.2.1\n   */\n  public static readonly V1_3_2_1 = new EngineVersion('1.3.2.1');\n  /**\n   * Neptune engine version 1.3.3.0\n   */\n  public static readonly V1_3_3_0 = new EngineVersion('1.3.3.0');\n  /**\n   * Neptune engine version 1.3.4.0\n   */\n  public static readonly V1_3_4_0 = new EngineVersion('1.3.4.0');\n  /**\n   * Neptune engine version 1.4.0.0\n   */\n  public static readonly V1_4_0_0 = new EngineVersion('1.4.0.0');\n  /**\n   * Neptune engine version 1.4.1.0\n   */\n  public static readonly V1_4_1_0 = new EngineVersion('1.4.1.0');\n  /**\n   * Neptune engine version 1.4.2.0\n   */\n  public static readonly V1_4_2_0 = new EngineVersion('1.4.2.0');\n  /**\n   * Neptune engine version 1.4.3.0\n   */\n  public static readonly V1_4_3_0 = new EngineVersion('1.4.3.0');\n  /**\n   * Neptune engine version 1.4.4.0\n   */\n  public static readonly V1_4_4_0 = new EngineVersion('1.4.4.0');\n  /**\n   * Neptune engine version 1.4.5.0\n   */\n  public static readonly V1_4_5_0 = new EngineVersion('1.4.5.0');\n  /**\n   * Neptune engine version 1.4.5.1\n   */\n  public static readonly V1_4_5_1 = new EngineVersion('1.4.5.1');\n  /**\n   * Neptune engine version 1.4.6.0\n   */\n  public static readonly V1_4_6_0 = new EngineVersion('1.4.6.0');\n  /**\n   * Neptune engine version 1.4.6.1\n   */\n  public static readonly V1_4_6_1 = new EngineVersion('1.4.6.1');\n  /**\n   * Constructor for specifying a custom engine version\n   * @param version the engine version of Neptune\n   */\n  public constructor(public readonly version: string) { }\n}", "language": "typescript"}
{"input": "Represents a container instance image that is used to launch the instance used for building the container for an EC2 Image Builder container build.", "output": "export class ContainerInstanceImage {\n  /**\n   * The AMI ID to use to launch the instance for building the container image\n   *\n   * @param amiId The AMI ID to use as the container instance image\n   */\n  public static fromAmiId(amiId: string): ContainerInstanceImage {\n    return new ContainerInstanceImage(amiId);\n  }\n\n  /**\n   * The SSM parameter to use to launch the instance for building the container image\n   *\n   * @param parameter The SSM parameter to use as the container instance image\n   */\n  public static fromSsmParameter(parameter: ssm.IStringParameter): ContainerInstanceImage {\n    return new ContainerInstanceImage(`ssm:${parameter.parameterArn}`);\n  }\n\n  /**\n   * The ARN of the SSM parameter used to launch the instance for building the container image\n   *\n   * @param parameterName The name of the SSM parameter used as the container instance image\n   */\n  public static fromSsmParameterName(parameterName: string): ContainerInstanceImage {\n    return new ContainerInstanceImage(`ssm:${parameterName}`);\n  }\n\n  /**\n   * The string value of the container instance image to use in a container recipe. This can either be:\n   * - an SSM parameter reference, prefixed with `ssm:` and followed by the parameter name or ARN\n   * - an AMI ID\n   *\n   * @param containerInstanceImageString The container instance image as a direct string value\n   */\n  public static fromString(containerInstanceImageString: string): ContainerInstanceImage {\n    return new ContainerInstanceImage(containerInstanceImageString);\n  }\n\n  /**\n   * The rendered container instance image to use\n   **/\n  public readonly image: string;\n\n  protected constructor(image: string) {\n    this.image = image;\n  }\n}", "language": "typescript"}
{"input": "CDK class IcePlainsOfHoth for AWS resource management", "output": "class IcePlainsOfHoth(Stack):\n\n  def __init__(self, scope:Construct, id:str, **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n    vpc = ec2.Vpc(self, \"IcePlainsVpc\",\n      cidr                 = \"10.99.0.0/16\",\n      max_azs              = 3,\n      enable_dns_hostnames = True,\n      enable_dns_support   = True,\n      subnet_configuration = [\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public1',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        ),\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public2',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        ),\n        ec2.SubnetConfiguration(\n          cidr_mask   = 24,\n          name        = 'public3',\n          subnet_type = ec2.SubnetType.PUBLIC,\n        )\n      ]\n    )\n\n    vpc_subnets = vpc.select_subnets(\n      subnet_type=ec2.SubnetType.PUBLIC,\n      one_per_az =True\n    )\n\n    subnet_ids = []\n    for subnet in vpc_subnets.subnets:\n      subnet_ids.append(subnet.subnet_id)\n\n    vpc_id = vpc.vpc_id\n\n    Aurora(self, \"EchoBaseDb\",\n      db_name=\"EchoBase\",\n      ingress_sources=[ec2.Peer.ipv4(\"10.10.10.10/32\")],\n      vpc_id=vpc_id,\n      subnet_ids=subnet_ids,\n      env={'region': 'us-east-1'},\n      description=\"Echo Base DB\")", "language": "python"}
{"input": "Snapshot test for namespace with default parameters", "output": "class DefaultNamespaceStack extends core.Stack {\n  public readonly namespace: s3tables.Namespace;\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n\n    this.tableBucket = new s3tables.TableBucket(this, 'DefaultBucket', {\n      tableBucketName: 'namespace-test-bucket',\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    this.namespace = new s3tables.Namespace(this, 'DefaultNamespace', {\n      namespaceName: 'default_test_namespace',\n      tableBucket: this.tableBucket,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for API Gateway operations", "output": "def add_cors_options(self, apigw_resource):\n        apigw_resource.add_method('OPTIONS', MockIntegration(\n            integration_responses=[{\n                'statusCode': '200',\n                'responseParameters': {\n                    'method.response.header.Access-Control-Allow-Headers': \"'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token'\",\n                    'method.response.header.Access-Control-Allow-Origin': \"'*'\",\n                    'method.response.header.Access-Control-Allow-Methods': \"'GET,OPTIONS'\"\n                }\n            }\n            ],\n            passthrough_behavior=PassthroughBehavior.WHEN_NO_MATCH,\n            request_templates={\"application/json\":\"{\\\"statusCode\\\":200}\"}\n        ),\n        method_responses=[{\n            'statusCode': '200',\n            'responseParameters': {\n                'method.response.header.Access-Control-Allow-Headers': True,\n                'method.response.header.Access-Control-Allow-Methods': True,\n                'method.response.header.Access-Control-Allow-Origin': True,\n                }\n            }\n        ],\n    )", "language": "python"}
{"input": "CDK Construct for IAM infrastructure components", "output": "class TestConstruct extends Construct {\n      // we pretend to be a aws-iam.Role for this test\n      static readonly [JSII_RUNTIME_SYMBOL] = {\n        fqn: 'aws-cdk-lib.aws-iam.Role',\n      };\n\n      constructor() {\n        super(null as any, '');\n\n        // enable metadata collection\n        this.node.setContext(ENABLE_ADDITIONAL_METADATA_COLLECTION, true);\n      }\n    }", "language": "typescript"}
{"input": "CDK class EmailIdentity for AWS resource management", "output": "export class EmailIdentity extends EmailIdentityBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ses.EmailIdentity';\n\n  /**\n   * Use an existing email identity\n   */\n  public static fromEmailIdentityName(scope: Construct, id: string, emailIdentityName: string): IEmailIdentity {\n    class Import extends EmailIdentityBase {\n      public readonly emailIdentityName = emailIdentityName;\n\n      public readonly emailIdentityArn = this.stack.formatArn({\n        service: 'ses',\n        resource: 'identity',\n        resourceName: this.emailIdentityName,\n      });\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an email identity by ARN\n   */\n  public static fromEmailIdentityArn(scope: Construct, id: string, emailIdentityArn: string): IEmailIdentity {\n    // emailIdentityArn is in the format 'arn:aws:ses:{region}:{account}:identity/{name}'\n    const stack = Stack.of(scope);\n    const parsedArn = stack.splitArn(emailIdentityArn, ArnFormat.SLASH_RESOURCE_NAME);\n\n    if (parsedArn.service !== 'ses' || parsedArn.resource !== 'identity' || !parsedArn.resourceName) {\n      throw new ValidationError(`Invalid email identity ARN: ${emailIdentityArn}`, scope);\n    }\n\n    const emailIdentityName = parsedArn.resourceName;\n\n    class Import extends EmailIdentityBase {\n      public readonly emailIdentityName = emailIdentityName;\n      public readonly emailIdentityArn = emailIdentityArn;\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly emailIdentityName: string;\n\n  public readonly emailIdentityArn: string;\n\n  /**\n   * The host name for the first token that you have to add to the\n   * DNS configurationfor your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenName1: string;\n\n  /**\n   * The host name for the second token that you have to add to the\n   * DNS configuration for your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenName2: string;\n\n  /**\n   * The host name for the third token that you have to add to the\n   * DNS configuration for your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenName3: string;\n\n  /**\n   * The record value for the first token that you have to add to the\n   * DNS configuration for your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenValue1: string;\n\n  /**\n   * The record value for the second token that you have to add to the\n   * DNS configuration for your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenValue2: string;\n\n  /**\n   * The record value for the third token that you have to add to the\n   * DNS configuration for your domain\n   *\n   * @attribute\n   */\n  public readonly dkimDnsTokenValue3: string;\n\n  /**\n   * DKIM records for this identity\n   */\n  public readonly dkimRecords: DkimRecord[];\n\n  constructor(scope: Construct, id: string, props: EmailIdentityProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const dkimIdentity = props.dkimIdentity ?? DkimIdentity.easyDkim();\n\n    const identity = new CfnEmailIdentity(this, 'Resource', {\n      emailIdentity: props.identity.value,\n      configurationSetAttributes: undefinedIfNoKeys({\n        configurationSetName: props.configurationSet?.configurationSetRef.configurationSetName,\n      }),\n      dkimAttributes: undefinedIfNoKeys({\n        signingEnabled: props.dkimSigning,\n      }),\n      dkimSigningAttributes: dkimIdentity.bind(this, props.identity.hostedZone),\n      feedbackAttributes: undefinedIfNoKeys({\n        emailForwardingEnabled: props.feedbackForwarding,\n      }),\n      mailFromAttributes: undefinedIfNoKeys({\n        mailFromDomain: props.mailFromDomain,\n        behaviorOnMxFailure: props.mailFromBehaviorOnMxFailure,\n      }),\n    });\n\n    if (props.mailFromDomain && props.identity.hostedZone) {\n      new route53.MxRecord(this, 'MailFromMxRecord', {\n        zone: props.identity.hostedZone,\n        recordName: props.mailFromDomain,\n        values: [{\n          priority: 10,\n          hostName: `feedback-smtp.${Stack.of(this).region}.amazonses.com`,\n        }],\n      });\n\n      new route53.TxtRecord(this, 'MailFromTxtRecord', {\n        zone: props.identity.hostedZone,\n        recordName: props.mailFromDomain,\n        values: ['v=spf1 include:amazonses.com ~all'],\n      });\n    }\n\n    this.emailIdentityName = identity.ref;\n\n    this.emailIdentityArn = this.stack.formatArn({\n      service: 'ses',\n      resource: 'identity',\n      resourceName: this.emailIdentityName,\n    });\n\n    this.dkimDnsTokenName1 = identity.attrDkimDnsTokenName1;\n    this.dkimDnsTokenName2 = identity.attrDkimDnsTokenName2;\n    this.dkimDnsTokenName3 = identity.attrDkimDnsTokenName3;\n    this.dkimDnsTokenValue1 = identity.attrDkimDnsTokenValue1;\n    this.dkimDnsTokenValue2 = identity.attrDkimDnsTokenValue2;\n    this.dkimDnsTokenValue3 = identity.attrDkimDnsTokenValue3;\n\n    this.dkimRecords = [\n      { name: this.dkimDnsTokenName1, value: this.dkimDnsTokenValue1 },\n      { name: this.dkimDnsTokenName2, value: this.dkimDnsTokenValue2 },\n      { name: this.dkimDnsTokenName3, value: this.dkimDnsTokenValue3 },\n    ];\n  }\n}", "language": "typescript"}
{"input": "Helper class for working with `IComparablePrincipal`s", "output": "export class ComparablePrincipal {\n  /**\n   * Whether or not the given principal is a comparable principal\n   */\n  public static isComparablePrincipal(this: void, x: IPrincipal): x is IComparablePrincipal {\n    return 'dedupeString' in x;\n  }\n\n  /**\n   * Return the dedupeString of the given principal, if available\n   */\n  public static dedupeStringFor(this: void, x: IPrincipal): string | undefined {\n    return ComparablePrincipal.isComparablePrincipal(x) ? x.dedupeString() : undefined;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, WAF, EventBridge, CloudWatch Logs resources", "output": "export class consumerStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props: consumerStackProps) {\n      super(scope, id, props);\n  \n      // Create or reference the consumer event bus\n      const consumerEventBus = new EventBus(this, `${props.appName}-consumer-event-bus`);\n  \n      // Add policy to allow producer account to put events\n      consumerEventBus.addToResourcePolicy(new PolicyStatement({\n        sid: 'allowProducerAccount',\n        effect: Effect.ALLOW,\n        principals: [new AccountPrincipal(props.producerAccountId)],\n        actions: ['events:PutEvents'],\n        resources: [consumerEventBus.eventBusArn]\n      }));\n  \n      // Create consumer rules\n      const consumerRule = new Rule(this, `${props.appName}-consumer-rule`, {\n        eventBus: consumerEventBus,\n        eventPattern: {\n          // Define more specific filtering here\n          source: ['com.myapp.events'],\n          detail: {\n            type: ['specific-event-type']\n          }\n        }\n      });\n  \n      // Add target (e.g., CloudWatch)\n      consumerRule.addTarget(new CloudWatchLogGroup(\n        new LogGroup(this, `${props.appName}-consumer-logs`)\n      ));\n    }\n  }", "language": "typescript"}
{"input": "CDK Stack that creates SSM Parameter Store, CloudFormation resources", "output": "class ConsumerStack extends Stack {\n  constructor(scope: Construct, id: string, props: consumerDeployProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    new ssm.StringListParameter(this, 'GetAtt', {\n      stringListValue: props.stringListGetAtt,\n    });\n\n    new ssm.StringListParameter(this, 'Ref', {\n      stringListValue: props.stringListRef.valueAsList,\n    });\n\n    new ssm.StringListParameter(this, 'Manual', {\n      stringListValue: props.manualStringList,\n    });\n  }\n}", "language": "typescript"}
{"input": "Python-specific implementation of the SDK injector. Handles Python auto-instrumentation setup and PYTHONPATH configuration.", "output": "export class PythonInjector extends Injector {\n  protected static readonly PYTHON_ENVS: EnvironmentExtension[] = [\n    {\n      name: constants.PythonInstrumentation.OTEL_PYTHON_DISTRO,\n      value: constants.PythonInstrumentation.OTEL_PYTHON_DISTRO_AWS_DISTRO,\n    },\n    {\n      name: constants.PythonInstrumentation.OTEL_PYTHON_CONFIGURATOR,\n      value: constants.PythonInstrumentation.OTEL_PYTHON_CONFIGURATOR_AWS_CONFIGURATOR,\n    },\n  ];\n  get command(): string[] {\n    return ['cp', '-a', '/autoinstrumentation/.', this.containerPath];\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    for (const env of PythonInjector.PYTHON_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n    envsToInject[constants.PythonInstrumentation.PYTHONPATH] = `${this.containerPath}/opentelemetry/instrumentation/auto_instrumentation:${this.containerPath}`;\n  }\n\n  get containerPath(): string {\n    return '/otel-auto-instrumentation-python';\n  }\n\n  protected overrideAdditionalEnvironments(envsToOverride: { [key: string]: string }, envsFromTaskDef: { [key: string]: string }): void {\n    if (envsFromTaskDef[constants.PythonInstrumentation.PYTHONPATH]) {\n      const pythonPath = envsFromTaskDef[constants.PythonInstrumentation.PYTHONPATH];\n      envsToOverride[constants.PythonInstrumentation.PYTHONPATH] = `${this.containerPath}/opentelemetry/instrumentation/auto_instrumentation:${pythonPath}:${this.containerPath}`;\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class MixinsUtils for AWS resource management", "output": "class MixinsUtils extends ExternalModule {\n  public readonly deepMerge = $E(expr.sym(new ThingSymbol('deepMerge', this)));\n  public readonly shallowAssign = $E(expr.sym(new ThingSymbol('shallowAssign', this)));\n}", "language": "typescript"}
{"input": "CDK helper function test_s3_buckets_created", "output": "def test_s3_buckets_created(template):\n    template.resource_count_is(type=\"AWS::S3::Bucket\", count=2)\n\n    template.has_resource_properties(type=\"AWS::S3::Bucket\",\n                                     props={\n                                         \"BucketName\": {\n                                             \"Fn::Join\": [\n                                                 \"\",\n                                                 [\n                                                     \"auditing-logs-\",\n                                                     {\"Ref\": \"AWS::AccountId\"}\n                                                 ]\n                                             ]\n                                         }\n                                     })\n\n    template.has_resource_properties(type=\"AWS::S3::Bucket\",\n                                     props={\n                                         \"BucketName\": {\n                                             \"Fn::Join\": [\n                                                 \"\",\n                                                 [\n                                                     \"auditing-analysis-output-\",\n                                                     {\"Ref\": \"AWS::AccountId\"}\n                                                 ]\n                                             ]\n                                         }\n                                     })", "language": "python"}
{"input": "CDK class HttpsRecord for AWS resource management", "output": "export class HttpsRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.HttpsRecord';\n\n  constructor(scope: Construct, id: string, props: HttpsRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.HTTPS,\n      target: props.target ?? RecordTarget.fromValues(...(props.values?.map((v) => v.toString()) ?? [])),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (!!props.values === !!props.target) {\n      throw new ValidationError('Specify exactly one of either values or target.', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function get_user_data", "output": "def get_user_data(self, filename):\n        with open('./user_data/' + filename) as f:\n            user_data = f.read()\n        return user_data", "language": "python"}
{"input": "CDK class TopicPolicy for AWS resource management", "output": "export class TopicPolicy extends Resource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-sns.TopicPolicy';\n\n  /**\n   * The IAM policy document for this policy.\n   */\n  public readonly document = new PolicyDocument({\n    // statements must be unique, so we use the statement index.\n    // potantially SIDs can change as a result of order change, but this should\n    // not have an impact on the policy evaluation.\n    // https://docs.aws.amazon.com/sns/latest/dg/AccessPolicyLanguage_SpecialInfo.html\n    assignSids: true,\n  });\n\n  constructor(scope: Construct, id: string, props: TopicPolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.document = props.policyDocument ?? this.document;\n\n    if (props.enforceSSL) {\n      props.topics.map(t => this.document.addStatements(this.createSSLPolicyDocument(t.topicArn)));\n    }\n\n    new CfnTopicPolicy(this, 'Resource', {\n      policyDocument: this.document,\n      topics: props.topics.map(t => t.topicArn),\n    });\n  }\n\n  /**\n   * Adds a statement to enforce encryption of data in transit when publishing to the topic.\n   *\n   * For more information, see https://docs.aws.amazon.com/sns/latest/dg/sns-security-best-practices.html#enforce-encryption-data-in-transit.\n   */\n  protected createSSLPolicyDocument(topicArn: string): PolicyStatement {\n    return new PolicyStatement ({\n      sid: 'AllowPublishThroughSSLOnly',\n      actions: ['sns:Publish'],\n      effect: Effect.DENY,\n      resources: [topicArn],\n      conditions: {\n        Bool: { 'aws:SecureTransport': 'false' },\n      },\n      principals: [new StarPrincipal()],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class QueuePolicy for AWS resource management", "output": "export class QueuePolicy extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-sqs.QueuePolicy';\n  /**\n   * The IAM policy document for this policy.\n   */\n  public readonly document = new PolicyDocument();\n\n  constructor(scope: Construct, id: string, props: QueuePolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnQueuePolicy(this, 'Resource', {\n      policyDocument: this.document,\n      queues: props.queues.map(q => q.queueUrl),\n    });\n  }\n\n  /**\n   * Not currently supported by AWS CloudFormation.\n   *\n   * This attribute temporarily existed in CloudFormation, and then was removed again.\n   *\n   * @attribute\n   */\n  public get queuePolicyId(): string {\n    throw new ValidationError('QueuePolicy.queuePolicyId has been removed from CloudFormation', this);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Cognito, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    // For SP initiated SAML\n    const userpool = new UserPool(this, 'pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    new UserPoolIdentityProviderSaml(this, 'samlProvider', {\n      userPool: userpool,\n      name: 'provider',\n      metadata: UserPoolIdentityProviderSamlMetadata.url('https://fujifish.github.io/samling/public/metadata.xml'),\n      encryptedResponses: true,\n      requestSigningAlgorithm: SigningAlgorithm.RSA_SHA256,\n    });\n\n    const client = userpool.addClient('client');\n\n    const domain = userpool.addDomain('domain', {\n      cognitoDomain: {\n        domainPrefix: 'cdk-test-pool',\n      },\n    });\n\n    // For IdP initiated SAML\n    const userpoolForIdpInitiatedSaml = new UserPool(this, 'poolForIdpInitiatedSaml', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const idpInitiatedProvider = new UserPoolIdentityProviderSaml(this, 'samlProviderIdpInitiated', {\n      userPool: userpoolForIdpInitiatedSaml,\n      name: 'IdPInitiatedProvider',\n      metadata: UserPoolIdentityProviderSamlMetadata.url('https://fujifish.github.io/samling/public/metadata.xml'),\n      idpInitiated: true,\n    });\n    userpoolForIdpInitiatedSaml.addClient('idpInitiatedClient', {\n      supportedIdentityProviders: [UserPoolClientIdentityProvider.custom(idpInitiatedProvider.providerName)],\n    });\n\n    new CfnOutput(this, 'SignInLink', {\n      value: domain.signInUrl(client, {\n        redirectUri: 'https://example.com',\n      }),\n    });\n  }\n}", "language": "typescript"}
{"input": "Stack, which creates LambdaRestApi Gateway, with TokenAuthorizer @export @class GatewayLambdaAuth @extends {cdk.Stack}", "output": "export class GatewayLambdaAuth extends cdk.Stack {\n  readonly operationalLambda: cdk.aws_lambda.IFunction;\n  readonly lambdaIntegration: cdk.aws_apigateway.LambdaIntegration;\n\n  readonly operationalEntryPath = path.join(__dirname + \"/../lambdas/operational/index.ts\")\n  readonly authLambdaEntryPath = path.join(__dirname + \"/../lambdas/authorizer/index.ts\")\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    /** Creating operational Lambda, which server the request */\n    let operationalLambda = this.getOperationalFunction();\n\n    /** Lambda, which takes incoming request and checks the authorization and authentication */\n    let authorizerLambda = this.getLambdaAuthFunction();\n\n    /** Generating Token Authorization, which will be injected to API Gateway */\n    let lambdaTokenAuthorizer = this.getTokenAuthorizer(authorizerLambda)\n\n    /** Creating Lambda Rest API, which integrates Endpoint to Lambda */\n    let lambdaRestApi = this.createRestApi(operationalLambda, lambdaTokenAuthorizer);\n\n    /** Creating /health resource at root for lambda Rest API */\n    const healthResource = lambdaRestApi.root.addResource(\"health\");\n    healthResource.addMethod(\"GET\");\n\n    /** Returning Output with URL made as part of lambdaRestApi */\n    new cdk.CfnOutput(this, \"apiUrl\", { value: lambdaRestApi.url });\n  }\n\n\n  /**\n   * Creating Operational Lambda, to server the incoming request\n   *\n   * @private\n   * @return {*}  {cdk.aws_lambda.IFunction}\n   * @memberof GatewayLambdaAuth\n   */\n  private getOperationalFunction(): cdk.aws_lambda.IFunction {\n    return new cdk.aws_lambda_nodejs.NodejsFunction(this, \"operational-lambda\", {\n      runtime: cdk.aws_lambda.Runtime.NODEJS_18_X,\n      handler: \"index.handler\",\n      bundling: {\n        sourceMap: true,\n        minify: true,\n      },\n      description: 'Operational Lambda',\n      entry: this.operationalEntryPath,\n      environment: {\n        NODE_OPTIONS: '--enable-source-maps',\n      },\n      logRetention: cdk.aws_logs.RetentionDays.ONE_DAY,\n      memorySize: 512,\n      timeout: cdk.Duration.minutes(2),\n    });\n  }\n\n\n  /**\n   * Creating Authorization Lambda, to validate incoming request\n   *\n   * @private\n   * @return {*}  {cdk.aws_lambda.IFunction}\n   * @memberof GatewayLambdaAuth\n   */\n  private getLambdaAuthFunction(): cdk.aws_lambda.IFunction {\n    return new cdk.aws_lambda_nodejs.NodejsFunction(this, \"authentication-lambda\", {\n      runtime: cdk.aws_lambda.Runtime.NODEJS_18_X,\n      handler: \"index.handler\",\n      bundling: {\n        sourceMap: true,\n        minify: true,\n      },\n      description: 'Lambda Authorizer',\n      entry: this.authLambdaEntryPath,\n      environment: {\n        NODE_OPTIONS: '--enable-source-maps',\n      },\n      logRetention: cdk.aws_logs.RetentionDays.ONE_DAY,\n      memorySize: 512,\n      timeout: cdk.Duration.minutes(2),\n    });\n  }\n\n\n  /**\n   * Creating Token Authorizer, to inject auth-lambda into Rest API Gateway\n   *\n   * @private\n   * @param {IFunction} authorizerLambda\n   * @return {*}  {cdk.aws_apigateway.TokenAuthorizer}\n   * @memberof GatewayLambdaAuth\n   */\n  private getTokenAuthorizer(authorizerLambda: cdk.aws_lambda.IFunction): cdk.aws_apigateway.TokenAuthorizer {\n    return new cdk.aws_apigateway.TokenAuthorizer(\n      this,\n      \"operationalAuthorizer\",\n      {\n        handler: authorizerLambda,\n      }\n    );\n  }\n\n\n  /**\n   * Creating Lambda Rest API, that integrates API to Operational Lambda with Token Authorizer\n   *\n   * @private\n   * @param {cdk.aws_lambda.IFunction} operationalLambda\n   * @param {cdk.aws_apigateway.TokenAuthorizer} lambdaAuthorizer\n   * @return {*}  {cdk.aws_apigateway.LambdaRestApi}\n   * @memberof GatewayLambdaAuth\n   */\n  private createRestApi(\n    operationalLambda: cdk.aws_lambda.IFunction,\n    lambdaAuthorizer: cdk.aws_apigateway.TokenAuthorizer\n  ): cdk.aws_apigateway.LambdaRestApi {\n    const logGroup = this.createApiGatewayAccessLogsGroup(this);\n    return new cdk.aws_apigateway.LambdaRestApi(this, \"rest-api-gateway\", {\n      handler: operationalLambda,\n      proxy: false,\n      deployOptions: {\n        stageName: \"dev\",\n        accessLogDestination: new cdk.aws_apigateway.LogGroupLogDestination(\n          logGroup\n        ),\n        accessLogFormat:\n          cdk.aws_apigateway.AccessLogFormat.jsonWithStandardFields(),\n      },\n      defaultMethodOptions: {\n        authorizer: lambdaAuthorizer,\n      },\n    });\n  }\n\n\n  /**\n   * Creating Access-log Group, for API Gateway\n   *\n   * @private\n   * @param {Construct} scope\n   * @return {*}  {cdk.aws_logs.ILogGroup}\n   * @memberof GatewayLambdaAuth\n   */\n  private createApiGatewayAccessLogsGroup(\n    scope: Construct\n  ): cdk.aws_logs.ILogGroup {\n    const logGroupName = \"apigateway-auth-lambda\";\n    const logRetention = new cdk.aws_logs.LogRetention(\n      scope,\n      \"apiGwLogGroupConstruct\",\n      {\n        logGroupName: logGroupName,\n        retention: cdk.aws_logs.RetentionDays.ONE_WEEK,\n        removalPolicy: cdk.RemovalPolicy.DESTROY,\n      }\n    );\n    const logGroup = cdk.aws_logs.LogGroup.fromLogGroupArn(\n      scope,\n      \"apiGwLogGroup\",\n      logRetention.logGroupArn\n    );\n    return logGroup;\n  }\n}", "language": "typescript"}
{"input": "Three stacks where the last one depends on the earlier 2", "output": "export class ThreeStackApp extends Stage {\n  constructor(scope: Construct, id: string, props?: StageProps) {\n    super(scope, id, props);\n\n    const stack1 = new BucketStack(this, 'Stack1');\n    const stack2 = new BucketStack(this, 'Stack2');\n    const stack3 = new BucketStack(this, 'Stack3');\n\n    stack3.addDependency(stack1);\n    stack3.addDependency(stack2);\n  }\n}", "language": "typescript"}
{"input": "CDK class TestLambda for AWS resource management", "output": "class TestLambda:\n  def test_specified_resources_created(self):\n    template.resource_count_is('AWS::Lambda::Function', 1)\n    template.resource_count_is('AWS::Events::Rule', 1)\n\n  def test_lambda_function_has_correct_properties(self):\n    dependency_capture = Capture()\n    template.has_resource('AWS::Lambda::Function', {\n      'Properties':{\n        'Code': {\n          'ZipFile': \"def main(event, context):\\n    print(\\\"I'm running!\\\")\\n\",\n        },\n        'Handler': 'index.main',\n        'Runtime': 'python3.12',\n        'Timeout': 300,\n      },\n      'DependsOn':[dependency_capture]\n    })\n\n    assert 'SingletonServiceRole' in dependency_capture.as_string()\n\n  def test_lambda_has_correct_iam_permissions(self):\n    role_capture = Capture()\n    template.has_resource_properties('AWS::IAM::Role', {\n      'AssumeRolePolicyDocument': Match.object_like({\n        'Statement': [{\n          'Action': 'sts:AssumeRole',\n          'Effect': 'Allow',\n          'Principal': {\n            'Service': 'lambda.amazonaws.com'\n          },\n        }],\n      }),\n      'ManagedPolicyArns': [{\n        'Fn::Join': Match.array_with([\n          [ 'arn:', { 'Ref': 'AWS::Partition' }, role_capture ],\n        ]),\n      }],\n    })\n\n    assert 'AWSLambdaBasicExecutionRole' in role_capture.as_string()\n\n  def test_lambda_not_running_in_vpc(self):\n    template.has_resource('AWS::Lambda::Function', {\n      'Vpc': Match.absent()\n    })", "language": "python"}
{"input": "CDK class TestCaseBase for AWS resource management", "output": "class TestCaseBase extends cdk.Stack {\n  public readonly listParam: ssm.IStringListParameter;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    this.listParam = new ssm.StringListParameter(this, 'ListParam', {\n      parameterName: paramName,\n      stringListValue: paramValue,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class AutoScalingFargateService for AWS resource management", "output": "class AutoScalingFargateService extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create a cluster\n    const vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 2 });\n    const cluster = new ecs.Cluster(this, 'fargate-service-autoscaling', { vpc });\n\n    // Create Fargate Service\n    const fargateService = new ecs_patterns.NetworkLoadBalancedFargateService(this, 'sample-app', {\n      cluster,\n      taskImageOptions: {\n        image: ecs.ContainerImage.fromRegistry(\"amazon/amazon-ecs-sample\")\n      },\n    });\n\n    // Setup AutoScaling policy\n    const scaling = fargateService.service.autoScaleTaskCount({ maxCapacity: 2 });\n    scaling.scaleOnCpuUtilization('CpuScaling', {\n      targetUtilizationPercent: 50,\n      scaleInCooldown: cdk.Duration.seconds(60),\n      scaleOutCooldown: cdk.Duration.seconds(60)\n    });\n\n    new cdk.CfnOutput(this, 'LoadBalancerDNS', { value: fargateService.loadBalancer.loadBalancerDnsName });\n  }\n}", "language": "typescript"}
{"input": "Determines whether any cookies in viewer requests are included in the cache key and automatically included in requests that CloudFront sends to the origin.", "output": "export class CacheCookieBehavior {\n  /**\n   * Cookies in viewer requests are not included in the cache key and\n   * are not automatically included in requests that CloudFront sends to the origin.\n   */\n  public static none() { return new CacheCookieBehavior('none'); }\n\n  /**\n   * All cookies in viewer requests are included in the cache key and are automatically included in requests that CloudFront sends to the origin.\n   */\n  public static all() { return new CacheCookieBehavior('all'); }\n\n  /**\n   * Only the provided `cookies` are included in the cache key and automatically included in requests that CloudFront sends to the origin.\n   */\n  public static allowList(...cookies: string[]) {\n    if (cookies.length === 0) {\n      throw new UnscopedValidationError('At least one cookie to allow must be provided');\n    }\n    return new CacheCookieBehavior('whitelist', cookies);\n  }\n\n  /**\n   * All cookies except the provided `cookies` are included in the cache key and\n   * automatically included in requests that CloudFront sends to the origin.\n   */\n  public static denyList(...cookies: string[]) {\n    if (cookies.length === 0) {\n      throw new UnscopedValidationError('At least one cookie to deny must be provided');\n    }\n    return new CacheCookieBehavior('allExcept', cookies);\n  }\n\n  /** The behavior of cookies: allow all, none, an allow list, or a deny list. */\n  public readonly behavior: string;\n  /** The cookies to allow or deny, if the behavior is an allow or deny list. */\n  public readonly cookies?: string[];\n\n  private constructor(behavior: string, cookies?: string[]) {\n    this.behavior = behavior;\n    this.cookies = cookies;\n  }\n}", "language": "typescript"}
{"input": "Proxy target: Instance or Cluster A target group is a collection of databases that the proxy can connect to. Currently, you can specify only one RDS DB instance or Aurora DB cluster.", "output": "export class ProxyTarget {\n  /**\n   * From instance\n   *\n   * @param instance RDS database instance\n   */\n  public static fromInstance(instance: IDatabaseInstance): ProxyTarget {\n    return new ProxyTarget(instance, undefined);\n  }\n\n  /**\n   * From cluster\n   *\n   * @param cluster RDS database cluster\n   */\n  public static fromCluster(cluster: IDatabaseCluster): ProxyTarget {\n    return new ProxyTarget(undefined, cluster);\n  }\n\n  private constructor(\n    private readonly dbInstance: IDatabaseInstance | undefined,\n    private readonly dbCluster: IDatabaseCluster | undefined) {\n  }\n\n  /**\n   * Bind this target to the specified database proxy.\n   */\n  public bind(proxy: DatabaseProxy): ProxyTargetConfig {\n    const engine: IEngine | undefined = this.dbInstance?.engine ?? this.dbCluster?.engine;\n\n    if (!engine) {\n      const errorResource = this.dbCluster ?? this.dbInstance;\n      throw new ValidationError(`Could not determine engine for proxy target '${errorResource?.node.path}'. ` +\n        'Please provide it explicitly when importing the resource', proxy);\n    }\n\n    const engineFamily = engine.engineFamily;\n    if (!engineFamily) {\n      throw new ValidationError('RDS proxies require an engine family to be specified on the database cluster or instance. ' +\n        `No family specified for engine '${engineDescription(engine)}'`, proxy);\n    }\n\n    // allow connecting to the Cluster/Instance from the Proxy\n    this.dbCluster?.connections.allowDefaultPortFrom(proxy, 'Allow connections to the database Cluster from the Proxy');\n    this.dbInstance?.connections.allowDefaultPortFrom(proxy, 'Allow connections to the database Instance from the Proxy');\n\n    return {\n      engineFamily,\n      dbClusters: this.dbCluster ? [this.dbCluster] : undefined,\n      dbInstances: this.dbInstance ? [this.dbInstance] : undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "method to create a NAT Instance in the public subnet see user_data/nat_instance txt file to see the User Data script used to configured the NAT rules", "output": "def create_nat_instance(self, vpc):\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2)\n        user_data = self.get_user_data(\"nat_instance\")\n        nat = ec2.Instance(self, \"NATInstanceInLZ\",\n                 vpc=vpc,\n                 security_group=self.create_nat_SG(vpc),\n                 instance_type=ec2.InstanceType.of(ec2.InstanceClass.T3, ec2.InstanceSize.MEDIUM),\n                 machine_image=amzn_linux,\n                 user_data=ec2.UserData.custom(user_data),\n                 vpc_subnets=ec2.SubnetSelection(availability_zones=[LZ_NAME], subnet_type=ec2.SubnetType.PUBLIC),\n                 source_dest_check=False\n                )\n        return nat", "language": "python"}
{"input": "CDK class OSCluster for AWS resource management", "output": "export class OSCluster extends Construct {\n  public os_region: string;\n  public os_endpoint: string;\n  public os_domain_name: string;\n  public os_domain_arn: string;\n  constructor(scope: Construct, id: string, props: OSClusterConstructProps) {\n    super(scope, id);\n\n    let vpcCidrBlock = props.vpc.vpcCidrBlock;\n    let splitVpcCidrBlock = vpcCidrBlock.split(\"/\");\n    const baseVpcIPAddress = splitVpcCidrBlock[0];\n\n    const cognitoAuthRole = new Role(this, \"cognitoAuthRole\", {\n      assumedBy: new WebIdentityPrincipal(\n        \"cognito-identity.amazonaws.com\"\n      ).withConditions({\n        StringEquals: {\n          \"cognito-identity.amazonaws.com:aud\": props.identityPool.ref,\n        },\n        \"ForAnyValue:StringLike\": {\n          \"cognito-identity.amazonaws.com:amr\": \"authenticated\",\n        },\n      }),\n    });\n\n    const cognitoAuthRolePolicy = new PolicyStatement({\n      actions: [\"cognito-identity:GetCredentialsForIdentity\"],\n      resources: [\"*\"],\n    });\n\n    cognitoAuthRole.addToPolicy(cognitoAuthRolePolicy);\n\n    const cognitoUnAuthRole = new Role(this, \"cognitoUnAuthRole\", {\n          assumedBy: new WebIdentityPrincipal(\n            \"cognito-identity.amazonaws.com\"\n          ).withConditions({\n            StringEquals: {\n              \"cognito-identity.amazonaws.com:aud\": props.identityPool.ref,\n            },\n            \"ForAnyValue:StringLike\": {\n              \"cognito-identity.amazonaws.com:amr\": \"unauthenticated\",\n            },\n          }),\n        });\n\n        const cognitoUnAuthRolePolicy = new PolicyStatement({\n          actions: [\"cognito-identity:GetCredentialsForIdentity\"],\n          resources: [\"*\"],\n        });\n\n        cognitoUnAuthRole.addToPolicy(cognitoUnAuthRolePolicy);\n\n    props.identityPoolPolicy.roles.authenticated = cognitoAuthRole.roleArn;\n      props.identityPoolPolicy.roles.unauthenticated = cognitoUnAuthRole.roleArn;\n\n    const opensearchCognitoRole = new Role(this, \"opensearchCognitoRole\", {\n      assumedBy: new ServicePrincipal(\"es.amazonaws.com\"),\n    });\n    // Add a managed policy to a role you can use\n    opensearchCognitoRole.addManagedPolicy(\n      ManagedPolicy.fromAwsManagedPolicyName(\n        \"AmazonOpenSearchServiceCognitoAccess\"\n      )\n    );\n\n    const securityGroup = new ec2.SecurityGroup(this, \"nginxProxyServer-sg\", {\n      vpc: props.vpc,\n      allowAllOutbound: true,\n      description: \"Nginx and Opensearch Security group\",\n    });\n\n    // OpenSearch domain\n    const domain = new Domain(this, \"Domain\", {\n      version: EngineVersion.openSearch('2.9'),\n      domainName: `${Aws.STACK_NAME}-domain`,\n      nodeToNodeEncryption: true,\n      enforceHttps: true,\n      tlsSecurityPolicy: TLSSecurityPolicy.TLS_1_2,\n      encryptionAtRest: {\n        enabled: true,\n      },\n      vpc: props.vpc,\n      capacity: {\n        dataNodes: 2,\n        multiAzWithStandbyEnabled: false,\n        dataNodeInstanceType: 't3.medium.search'\n      },\n      removalPolicy: RemovalPolicy.DESTROY,\n      zoneAwareness: {\n        enabled: true,\n        availabilityZoneCount: 2,\n      },\n      securityGroups: [securityGroup],\n      cognitoDashboardsAuth: {\n        identityPoolId: props.identityPool.ref,\n        userPoolId: props.userPool.userPoolId,\n        role: opensearchCognitoRole,\n      },\n    });\n\n    domain.addAccessPolicies(\n      new PolicyStatement({\n        principals: [cognitoAuthRole],\n        actions: [\"es:ESHttp*\"],\n        resources: [domain.domainArn + \"/*\"],\n      })\n    );\n\n    //add EC2 Nginx proxy server\n    securityGroup.addIngressRule(\n      ec2.Peer.anyIpv4(),\n      ec2.Port.tcp(443),\n      \"HTTPS from anywhere\"\n    );\n\n    const instance = new ec2.Instance(this, \"nginxProxyServer\", {\n      vpc: props.vpc,\n      instanceType: ec2.InstanceType.of(\n        ec2.InstanceClass.T3,\n        ec2.InstanceSize.MEDIUM\n      ),\n      machineImage: new ec2.AmazonLinuxImage({\n        generation: ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n      }),\n      vpcSubnets: { subnetType: ec2.SubnetType.PUBLIC },\n      securityGroup: securityGroup,\n      init: ec2.CloudFormationInit.fromConfigSets({\n        configSets: {\n          default: [\"installNginx\", \"copyConfig\", \"config\"],\n        },\n        configs: {\n          installNginx: new ec2.InitConfig([\n            ec2.InitFile.fromFileInline(\n              \"/etc/install.sh\",\n              \"./lib/install.sh\"\n            ),\n            ec2.InitCommand.shellCommand(\"chmod +x /etc/install.sh\"),\n            ec2.InitCommand.shellCommand(\"/etc/install.sh\"),\n          ]),\n          copyConfig: new ec2.InitConfig([\n            ec2.InitFile.fromObject(\"/etc/config.json\", {\n              OS_DOMAIN_HOST: domain.domainEndpoint,\n              COGNITO_HOST: props.cognitoEndpoint,\n              VPC_BASE_IP: baseVpcIPAddress,\n            }),\n          ]),\n          config: new ec2.InitConfig([\n            ec2.InitFile.fromFileInline(\n              \"/etc/nginx/conf.d/default.conf\",\n              \"./lib/default.conf\"\n            ),\n            ec2.InitFile.fromFileInline(\n              \"/etc/config_nginx.sh\",\n              \"./lib/config_nginx.sh\"\n            ),\n            ec2.InitCommand.shellCommand(\"chmod +x /etc/config_nginx.sh\"),\n            ec2.InitCommand.shellCommand(\"/etc/config_nginx.sh\"),\n          ]),\n        },\n      }),\n      initOptions: {\n        timeout: Duration.minutes(15),\n      },\n    });\n\n    this.os_region = `${Aws.REGION}`\n    this.os_endpoint = \"https://\" + domain.domainEndpoint\n    this.os_domain_name = domain.domainName\n    this.os_domain_arn = domain.domainArn\n\n    // Outputs\n    const osDomainHost = new CfnOutput(this, \"OpenSearchDomainHost\", {\n      value: domain.domainEndpoint,\n    });\n    osDomainHost.overrideLogicalId('OpenSearchDomainHost');\n\n\n    const dashboardUrl = new CfnOutput(this, \"NginxOpensearchDashboardUrl\", {\n      value: \"https://\" + instance.instancePublicDnsName,\n    });\n    dashboardUrl.overrideLogicalId('NginxOpensearchDashboardUrl');\n  }\n}", "language": "typescript"}
{"input": "The value of a constant in a component document", "output": "export class ComponentConstantValue {\n  /**\n   * Creates a string type constant in a component document\n   *\n   * @param value The value of the constant\n   */\n  public static fromString(value: string): ComponentConstantValue {\n    return new ComponentConstantValue('string', value);\n  }\n\n  /**\n   * The data type of the constant\n   */\n  public readonly type: string;\n\n  /**\n   * The value of the constant\n   */\n  public readonly value: any;\n\n  protected constructor(type: string, value: any) {\n    this.type = type;\n    this.value = value;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, IAM operations", "output": "def __init__(self, app: App, id: str, **kwargs) -> None:\n        super().__init__(app, id)\n\n        bucket: s3.Bucket = s3.Bucket(self, \"WidgetStore\")\n\n        api: apigw.RestApi = apigw.RestApi(\n            self,\n            \"widgets-api\",\n            rest_api_name=\"Widget Service\",\n            description=\"This service serves widgets.\"\n        )\n\n        rest_api_role: iam.Role = iam.Role(\n            self,\n            \"RestAPIRole\",\n            assumed_by=iam.ServicePrincipal(\"apigateway.amazonaws.com\"),\n            managed_policies=[iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonS3FullAccess\")]\n        )\n\n        list_objects_response: apigw.IntegrationResponse = apigw.IntegrationResponse(status_code=\"200\")\n\n        list_objects_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n        )\n\n        get_widget_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n            request_templates={\"application/json\": \"#set($context.requestOverride.path.object = $input.params('id'))\"}\n        )\n\n        put_widget_integration_options: apigw.IntegrationOptions = apigw.IntegrationOptions(\n            credentials_role=rest_api_role,\n            integration_responses=[list_objects_response],\n            passthrough_behavior=apigw.PassthroughBehavior.NEVER,\n            request_parameters={\"integration.request.path.object\": \"method.request.path.id\"},\n            request_templates={\n                \"application/json\": \"#set($now=$context.requestTimeEpoch)\\n\"\n                                    \"#set($body=\\\"$input.params('id') created $now\\\")\"\n                                    \"\\n$util.base64Encode($body)\"}\n        )\n\n        get_widgets_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"GET\",\n            path=bucket.bucket_name,\n            options=list_objects_integration_options\n        )\n\n        get_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"GET\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=get_widget_integration_options\n        )\n\n        put_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"PUT\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=put_widget_integration_options\n        )\n\n        delete_widget_integration: apigw.AwsIntegration = apigw.AwsIntegration(\n            service=\"s3\",\n            integration_http_method=\"DELETE\",\n            path=\"{}/{{object}}\".format(bucket.bucket_name),\n            options=get_widget_integration_options\n        )\n\n        method_response: apigw.MethodResponse = apigw.MethodResponse(status_code=\"200\")\n\n        api.root.add_method(\n            \"GET\",\n            get_widgets_integration,\n            method_responses=[method_response]\n        )\n\n        widget = api.root.add_resource('{id}')\n        widget.add_method(\n            \"GET\",\n            get_widget_integration,\n            method_responses=[method_response]\n        )\n\n        widget.add_method(\n            \"POST\",\n            put_widget_integration,\n            method_responses=[method_response],\n            request_parameters={\"method.request.path.id\": True}\n        )\n\n        widget.add_method(\n            \"DELETE\",\n            delete_widget_integration,\n            method_responses=[method_response]\n        )", "language": "python"}
{"input": "CDK class ExtendedLB for AWS resource management", "output": "class ExtendedLB extends elbv2.ApplicationLoadBalancer {\n  constructor(scope: Construct, id: string, props: elbv2.BaseLoadBalancerProps) {\n    super(scope, id, props);\n\n    const accessLogsBucket = new s3.Bucket(this, 'ALBAccessLogsBucket', {\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n      encryption: s3.BucketEncryption.S3_MANAGED,\n      versioned: true,\n      serverAccessLogsPrefix: 'selflog/',\n      enforceSSL: true,\n    });\n    this.logAccessLogs(accessLogsBucket);\n\n    const connectionLogsBucket = new s3.Bucket(this, 'ALBConnectionLogsBucket', {\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n      encryption: s3.BucketEncryption.S3_MANAGED,\n      versioned: true,\n      serverAccessLogsPrefix: 'selflog/',\n      enforceSSL: true,\n    });\n    this.logConnectionLogs(connectionLogsBucket);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Secrets Manager, CloudFormation, CodeBuild resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const secrets = secretsmanager.Secret.fromSecretCompleteArn(this, 'MySecrets',\n      `arn:aws:secretsmanager:${this.region}:${this.account}:secret:my-secrets-123456`);\n\n    new codebuild.Project(this, 'MyProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: ['ls'],\n          },\n        },\n      }),\n      grantReportGroupPermissions: false,\n      /// !show\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.fromDockerRegistry('my-registry/my-repo', {\n          secretsManagerCredentials: secrets,\n        }),\n      },\n      /// !hide\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Construct TestConstruct2 for reusable infrastructure components", "output": "class TestConstruct2 extends Resource {\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.core.TestConstruct2';\n\n  constructor(scope: Construct, id: string, _props: TestConstructProps = {}) {\n    super(scope, id);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, CloudFormation resources", "output": "class TheNestedStack extends NestedStack {\n  constructor(scope: Construct, id: string, props?: NestedStackProps) {\n    super(scope, id, props);\n\n    const asset = new ecr_assets.DockerImageAsset(this, 'my-image', {\n      directory: path.join(__dirname, 'demo-image'),\n    });\n\n    const user = new iam.User(this, 'User');\n    asset.repository.grantPull(user);\n\n    new CfnOutput(this, 'output', { value: asset.imageUri });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, Step Functions, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const task = new tasks.EvaluateExpression(this, 'Task', {\n      expression: '$.a + $.b',\n      runtime: lambda.Runtime.NODEJS_22_X,\n    });\n\n    new sfn.StateMachine(this, 'StateMachine', {\n      definition: task,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Step Functions, CloudFormation resources", "output": "class DistributedMapStack extends cdk.Stack {\n  readonly bucket: s3.Bucket;\n  readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.bucket = new s3.Bucket(this, 'Bucket', {\n      autoDeleteObjects: true,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const distributedMap = new sfn.DistributedMap(this, 'DistributedMap', {\n      itemReader: new sfn.S3CsvItemReader({\n        bucket: this.bucket,\n        key: CSV_KEY,\n        csvHeaders: sfn.CsvHeaders.useFirstRow(),\n        csvDelimiter: sfn.CsvDelimiter.SEMICOLON,\n      }),\n      resultWriterV2: new sfn.ResultWriterV2({\n        bucket: this.bucket,\n        prefix: 'my-prefix',\n      }),\n    });\n    distributedMap.itemProcessor(new sfn.Pass(this, 'Pass'));\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definition: distributedMap,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class PermissionsBoundary for AWS resource management", "output": "export class PermissionsBoundary {\n  /**\n   * Apply a permissions boundary with the given name to all IAM Roles\n   * and Users created within a scope.\n   *\n   * The name can include placeholders for the partition, region, qualifier, and account\n   * These placeholders will be replaced with the actual values if available. This requires\n   * that the Stack has the environment specified, it does not work with environment\n   * agnostic stacks.\n   *\n   * - '${AWS::Partition}'\n   * - '${AWS::Region}'\n   * - '${AWS::AccountId}'\n   * - '${Qualifier}'\n   *\n   * @param name the name of the permissions boundary policy\n   *\n   * @example\n   * new Stage(app, 'ProdStage', {\n   *   permissionsBoundary: PermissionsBoundary.fromName('my-custom-permissions-boundary'),\n   * });\n   */\n  public static fromName(name: string): PermissionsBoundary {\n    return new PermissionsBoundary(name);\n  }\n\n  /**\n   * Apply a permissions boundary with the given ARN to all IAM Roles\n   * and Users created within a scope.\n   *\n   * The arn can include placeholders for the partition, region, qualifier, and account\n   * These placeholders will be replaced with the actual values if available. This requires\n   * that the Stack has the environment specified, it does not work with environment\n   * agnostic stacks.\n   *\n   * - '${AWS::Partition}'\n   * - '${AWS::Region}'\n   * - '${AWS::AccountId}'\n   * - '${Qualifier}'\n   *\n   * @param arn the ARN of the permissions boundary policy\n   *\n   * @example\n   * new Stage(app, 'ProdStage', {\n   *   permissionsBoundary: PermissionsBoundary.fromArn('arn:aws:iam::${AWS::AccountId}:policy/my-custom-permissions-boundary'),\n   * });\n   */\n  public static fromArn(arn: string): PermissionsBoundary {\n    return new PermissionsBoundary(undefined, arn);\n  }\n\n  private constructor(private readonly policyName?: string, private readonly policyArn?: string) {\n  }\n\n  /**\n   * Apply the permissions boundary to the given scope\n   *\n   * Different permissions boundaries can be applied to different scopes\n   * and the most specific will be applied.\n   *\n   * @internal\n   */\n  public _bind(scope: Construct, _options: PermissionsBoundaryBindOptions = {}): void {\n    scope.node.setContext(PERMISSIONS_BOUNDARY_CONTEXT_KEY, {\n      name: this.policyName,\n      arn: this.policyArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "Class for integrating Application Signals into an ECS task definition.", "output": "export class ApplicationSignalsIntegration extends Construct {\n  private sdkInjector?: sdk.Injector;\n  private mountVolumeName: string = 'opentelemetry-auto-instrumentation';\n  private cloudWatchAgentSidecar?: agent.CloudWatchAgentOptions;\n\n  constructor(\n    scope: Construct,\n    id: string,\n    props: ApplicationSignalsIntegrationProps) {\n    super(scope, id);\n    this.cloudWatchAgentSidecar = props.cloudWatchAgentSidecar;\n\n    let runtimePlatformObj = props.instrumentation.runtimePlatform ?? (props.taskDefinition as any).runtimePlatform;\n    let cpuArch = ecs.CpuArchitecture.X86_64;\n    let isWindows = false;\n\n    if (runtimePlatformObj) {\n      const runtimePlatform = runtimePlatformObj as ecs.RuntimePlatform;\n      if (runtimePlatform.operatingSystemFamily) {\n        isWindows = runtimePlatform.operatingSystemFamily.isWindows();\n        if (runtimePlatform.cpuArchitecture) {\n          cpuArch = runtimePlatform.cpuArchitecture;\n        }\n      }\n    }\n\n    const overrideEnvironments = [];\n    if (props.serviceName) {\n      // If service.name is also provided in OTEL_RESOURCE_ATTRIBUTES, then OTEL_SERVICE_NAME takes precedence.\n      overrideEnvironments.push({\n        name: constants.CommonExporting.OTEL_SERVICE_NAME,\n        value: props.serviceName,\n      });\n    }\n    overrideEnvironments.push(...props.overrideEnvironments ?? []);\n\n    if (props.instrumentation.sdkVersion instanceof inst.JavaInstrumentationVersion) {\n      this.sdkInjector = new sdk.JavaInjector(\n        this.mountVolumeName,\n        props.instrumentation.sdkVersion,\n        overrideEnvironments,\n      );\n    } else if (props.instrumentation.sdkVersion instanceof inst.PythonInstrumentationVersion) {\n      this.sdkInjector = new sdk.PythonInjector(\n        this.mountVolumeName,\n        props.instrumentation.sdkVersion,\n        overrideEnvironments,\n      );\n    } else if (props.instrumentation.sdkVersion instanceof inst.DotnetInstrumentationVersion) {\n      if (isWindows) {\n        this.sdkInjector = new sdk.DotNetWindowsInjector(\n          this.mountVolumeName,\n          props.instrumentation.sdkVersion,\n          overrideEnvironments,\n        );\n      } else {\n        this.sdkInjector = new sdk.DotNetLinuxInjector(\n          this.mountVolumeName,\n          props.instrumentation.sdkVersion,\n          cpuArch,\n          overrideEnvironments,\n        );\n      }\n    } else if (props.instrumentation.sdkVersion instanceof inst.NodeInstrumentationVersion) {\n      this.sdkInjector = new sdk.NodeInjector(\n        this.mountVolumeName,\n        props.instrumentation.sdkVersion,\n        overrideEnvironments,\n      );\n    }\n\n    this.mutateTaskDefinition(props.taskDefinition);\n  }\n\n  private mutateTaskDefinition(taskDefinition: ecs.TaskDefinition) {\n    taskDefinition.addVolume({\n      name: this.mountVolumeName,\n    });\n\n    let defaultContainer = taskDefinition.defaultContainer!;\n    if (this.sdkInjector) {\n      this.sdkInjector.renderDefaultContainer(taskDefinition);\n      let initContainer = this.sdkInjector.injectInitContainer(taskDefinition);\n      defaultContainer.addContainerDependencies({\n        container: initContainer,\n        condition: ecs.ContainerDependencyCondition.SUCCESS,\n      });\n    }\n\n    if (this.cloudWatchAgentSidecar) {\n      const cloudWatchAgent = new agent.CloudWatchAgentIntegration(this, 'CloudWatchAgentSidecar',\n        {\n          taskDefinition: taskDefinition,\n          ...this.cloudWatchAgentSidecar,\n        },\n      );\n      defaultContainer.addContainerDependencies({\n        container: cloudWatchAgent.agentContainer,\n        condition: ecs.ContainerDependencyCondition.START,\n      });\n    } else {\n      Annotations.of(this).addWarningV2(this.node.id, ' Application Signals functionality requires prior deployment of the CloudWatch Agent with appropriate security group settings. Missing or incorrect configurations will prevent successful collection of observability data.');\n    }\n  }\n}", "language": "typescript"}
{"input": "Represents a Docker image in ECR that can be bound as Lambda Code.", "output": "export class EcrImageCode extends Code {\n  public readonly isInline: boolean = false;\n\n  constructor(private readonly repository: ecr.IRepository, private readonly props: EcrImageCodeProps = {}) {\n    super();\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    this.repository.grantPull(new iam.ServicePrincipal('lambda.amazonaws.com'));\n\n    return {\n      image: {\n        imageUri: this.repository.repositoryUriForTagOrDigest(this.props?.tagOrDigest ?? this.props?.tag ?? 'latest'),\n        cmd: this.props.cmd,\n        entrypoint: this.props.entrypoint,\n        workingDirectory: this.props.workingDirectory,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation resources", "output": "export class EC2Stack extends Stack {\n  constructor(scope: Construct, id: string, props: EC2StackProps) {\n    super(scope, id, props);\n\n    const { logLevel, sshPubKey, cpuType, instanceSize } = props;\n\n    // Validate environment variables\n    envValidator(props);\n\n    // Create VPC and Security Group\n    const vpcResources = new VPCResources(this, 'VPC');\n\n    // Create EC2 Instance\n    const serverResources = new ServerResources(this, 'EC2', {\n      vpc: vpcResources.vpc,\n      sshSecurityGroup: vpcResources.sshSecurityGroup,\n      logLevel: logLevel,\n      sshPubKey: sshPubKey,\n      cpuType: cpuType,\n      instanceSize: instanceSize.toLowerCase(),\n    });\n\n    // SSM Command to start a session\n    new CfnOutput(this, 'ssmCommand', {\n      value: `aws ssm start-session --target ${serverResources.instance.instanceId}`,\n    });\n\n    // SSH Command to connect to the EC2 Instance\n    new CfnOutput(this, 'sshCommand', {\n      value: `ssh ec2-user@${serverResources.instance.instancePublicDnsName}`,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class PipelineProject for AWS resource management", "output": "export class PipelineProject extends Project {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codebuild.PipelineProject';\n\n  constructor(scope: Construct, id: string, props?: PipelineProjectProps) {\n    super(scope, id, {\n      source: new CodePipelineSource(),\n      artifacts: new CodePipelineArtifacts(),\n      ...props,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class L1PropsMixin for AWS resource management", "output": "class L1PropsMixin extends ClassType {\n  public scope: Module;\n  private readonly propsType: StructType;\n  private readonly decider: ResourceDecider;\n  private readonly relationshipDecider: RelationshipDecider;\n  private readonly converter: TypeConverter;\n\n  constructor(\n    scope: Module,\n    public readonly db: SpecDatabase,\n    private readonly resource: Resource,\n    private readonly constructLibModule: ExternalModule,\n  ) {\n    super(scope, {\n      export: true,\n      name: `${naming.classNameFromResource(resource)}PropsMixin`,\n      implements: [MIXINS_CORE.IMixin],\n      extends: MIXINS_CORE.Mixin,\n      docs: {\n        summary: `L1 property mixin for ${resource.cloudFormationType}`,\n        ...util.splitDocumentation(resource.documentation),\n        stability: Stability.External,\n        docTags: {\n          cloudformationResource: resource.cloudFormationType,\n          mixin: 'true',\n        },\n        see: naming.cloudFormationDocLink({\n          resourceType: resource.cloudFormationType,\n        }),\n      },\n    });\n\n    this.scope = scope;\n    this.propsType = new StructType(this.scope, {\n      export: true,\n      name: `${naming.classNameFromResource(resource)}MixinProps`,\n      docs: {\n        summary: `Properties for ${this.name}`,\n        stability: Stability.External,\n        see: naming.cloudFormationDocLink({\n          resourceType: this.resource.cloudFormationType,\n        }),\n      },\n    });\n\n    this.relationshipDecider = new RelationshipDecider(this.resource, db, {\n      enableRelationships: false,\n      enableNestedRelationships: false,\n      refsImportLocation: 'aws-cdk-lib/interfaces',\n    });\n    this.converter = TypeConverter.forMixin({\n      db: db,\n      resource: this.resource,\n      resourceClass: this,\n      relationshipDecider: this.relationshipDecider,\n    });\n    this.decider = new ResourceDecider(this.resource, this.converter, this.relationshipDecider);\n  }\n\n  /**\n   * Build the elements of the L1PropsMixin Class and types\n   */\n  public build() {\n    // Build the props type with all properties optional\n    for (const prop of this.decider.propsProperties) {\n      if (prop.propertySpec.type.fqn) {\n        continue;\n      }\n      this.propsType.addProperty({\n        ...prop.propertySpec,\n        optional: true,\n      });\n    }\n\n    this.makeConstructor();\n    const supports = this.makeSupportsMethod();\n    this.makeApplyToMethod(supports);\n  }\n\n  private makeConstructor() {\n    const optionsType = MIXINS_COMMON.CfnPropertyMixinOptions;\n\n    this.addProperty({\n      name: 'CFN_PROPERTY_KEYS',\n      type: Type.arrayOf(Type.STRING),\n      protected: true,\n      immutable: true,\n      static: true,\n      initializer: expr.list(this.propsType.properties.map(p => expr.lit(p.name))),\n    });\n\n    this.addProperty({\n      name: 'props',\n      type: this.propsType.type,\n      protected: true,\n      immutable: true,\n    });\n\n    this.addProperty({\n      name: 'strategy',\n      type: MIXINS_COMMON.PropertyMergeStrategy,\n      protected: true,\n      immutable: true,\n    });\n\n    const init = this.addInitializer({\n      docs: {\n        summary: `Create a mixin to apply properties to \\`${this.resource.cloudFormationType}\\`.`,\n      },\n    });\n\n    const props = init.addParameter({\n      name: 'props',\n      type: this.propsType.type,\n      documentation: 'L1 properties to apply',\n    });\n\n    const options = init.addParameter({\n      name: 'options',\n      type: optionsType,\n      optional: true,\n      default: expr.object(),\n      documentation: 'Mixin options',\n    });\n\n    init.addBody(\n      expr.sym(new ThingSymbol('super', this.scope)).call(),\n      stmt.assign($this.props, props),\n      stmt.assign($this.strategy, expr.binOp(options?.prop('strategy'), '??', MIXINS_COMMON.PropertyMergeStrategy.MERGE)),\n    );\n  }\n\n  private makeSupportsMethod(): Method {\n    const resClass = Type.fromName(this.constructLibModule, naming.classNameFromResource(this.resource));\n\n    const method = this.addMethod({\n      name: 'supports',\n      returnType: Type.ambient(`construct is service.${resClass.symbol}`),\n      docs: {\n        summary: 'Check if this mixin supports the given construct',\n      },\n    });\n\n    const construct = method.addParameter({\n      name: 'construct',\n      type: CONSTRUCTS.IConstruct,\n    });\n\n    method.addBody(\n      stmt.ret(\n        expr.binOp(\n          CallableProxy.fromName('CfnResource.isCfnResource', CDK_CORE).invoke(construct),\n          '&&',\n          expr.eq(expr.get(construct, 'cfnResourceType'), expr.lit(this.resource.cloudFormationType)),\n        ),\n      ),\n    );\n\n    return method;\n  }\n\n  private makeApplyToMethod(supports: Method) {\n    const method = this.addMethod({\n      name: 'applyTo',\n      returnType: CONSTRUCTS.IConstruct,\n      docs: {\n        summary: 'Apply the mixin properties to the construct',\n      },\n    });\n\n    const construct = method.addParameter({\n      name: 'construct',\n      type: CONSTRUCTS.IConstruct,\n    });\n\n    const CFN_PROPERTY_KEYS = $T(this.type).CFN_PROPERTY_KEYS;\n\n    method.addBody(\n      stmt\n        .if_(CallableProxy.fromMethod(supports).invoke(construct))\n        .then(\n          stmt.block(\n            stmt\n              .if_(expr.eq($this.strategy, MIXINS_COMMON.PropertyMergeStrategy.MERGE))\n              .then(\n                stmt.block(\n                  MIXINS_UTILS.deepMerge(construct, $this.props, CFN_PROPERTY_KEYS),\n                ),\n              )\n              .else(\n                stmt.block(\n                  MIXINS_UTILS.shallowAssign(construct, $this.props, CFN_PROPERTY_KEYS),\n                ),\n              ),\n          ),\n        ),\n      stmt.ret(construct),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class RequestAuthorizer for AWS resource management", "output": "export class RequestAuthorizer extends LambdaAuthorizer {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.RequestAuthorizer';\n  public readonly authorizerId: string;\n\n  public readonly authorizerArn: string;\n\n  protected readonly authorizerProps: CfnAuthorizerProps;\n\n  constructor(scope: Construct, id: string, props: RequestAuthorizerProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if ((props.resultsCacheTtl === undefined || props.resultsCacheTtl.toSeconds() !== 0) && props.identitySources.length === 0) {\n      throw new ValidationError('At least one Identity Source is required for a REQUEST-based Lambda authorizer if caching is enabled.', scope);\n    }\n\n    const restApiId = this.lazyRestApiId();\n\n    const authorizerProps: CfnAuthorizerProps = {\n      name: props.authorizerName ?? Names.uniqueId(this),\n      restApiId,\n      type: 'REQUEST',\n      authorizerUri: lambdaAuthorizerArn(props.handler),\n      authorizerCredentials: props.assumeRole?.roleArn,\n      authorizerResultTtlInSeconds: props.resultsCacheTtl?.toSeconds() ?? Duration.minutes(5).toSeconds(),\n      identitySource: props.identitySources.map(is => is.toString()).join(','),\n    };\n\n    this.authorizerProps = authorizerProps;\n\n    const resource = new CfnAuthorizer(this, 'Resource', authorizerProps);\n\n    this.authorizerId = resource.ref;\n    this.authorizerArn = Stack.of(this).formatArn({\n      service: 'execute-api',\n      resource: restApiId,\n      resourceName: `authorizers/${this.authorizerId}`,\n    });\n\n    this.setupPermissions();\n  }\n}", "language": "typescript"}
{"input": "CDK class JsonPrincipal for AWS resource management", "output": "class JsonPrincipal extends PrincipalBase {\n  public readonly policyFragment: PrincipalPolicyFragment;\n\n  constructor(json: any = { }) {\n    super();\n\n    // special case: if principal is a string, turn it into a \"LiteralString\" principal,\n    // so we render the exact same string back out.\n    if (typeof(json) === 'string') {\n      json = { [LITERAL_STRING_KEY]: [json] };\n    }\n    if (typeof(json) !== 'object') {\n      throw new UnscopedValidationError(`JSON IAM principal should be an object, got ${JSON.stringify(json)}`);\n    }\n\n    this.policyFragment = {\n      principalJson: json,\n      conditions: {},\n    };\n  }\n\n  public dedupeString(): string | undefined {\n    return JSON.stringify(this.policyFragment);\n  }\n}", "language": "typescript"}
{"input": "A test stack It contains a single Bucket. Such robust. Much uptime.", "output": "export class BucketStack extends Stack {\n  public readonly bucket: s3.IBucket;\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    this.bucket = new s3.Bucket(this, 'Bucket');\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderSaml for AWS resource management", "output": "export class UserPoolIdentityProviderSaml extends UserPoolIdentityProviderBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderSaml';\n\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderSamlProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.validateName(props.name);\n\n    const { metadataType, metadataContent } = props.metadata;\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: this.getProviderName(props.name),\n      providerType: 'SAML',\n      providerDetails: {\n        IDPSignout: props.idpSignout ?? false,\n        MetadataURL: metadataType === UserPoolIdentityProviderSamlMetadataType.URL ? metadataContent : undefined,\n        MetadataFile: metadataType === UserPoolIdentityProviderSamlMetadataType.FILE ? metadataContent : undefined,\n        EncryptedResponses: props.encryptedResponses ?? undefined,\n        RequestSigningAlgorithm: props.requestSigningAlgorithm,\n        IDPInit: props.idpInitiated ?? undefined,\n      },\n      idpIdentifiers: props.identifiers,\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n\n  private getProviderName(name?: string): string {\n    if (name) {\n      this.validateName(name);\n      return name;\n    }\n\n    const uniqueName = Names.uniqueResourceName(this, {\n      maxLength: 32,\n    });\n\n    if (uniqueName.length < 3) {\n      return `${uniqueName}saml`;\n    }\n\n    return uniqueName;\n  }\n\n  private validateName(name?: string) {\n    if (name && !Token.isUnresolved(name) && (name.length < 3 || name.length > 32)) {\n      throw new ValidationError(`Expected provider name to be between 3 and 32 characters, received ${name} (${name.length} characters)`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "The parameter value for a component parameter", "output": "export class ComponentParameterValue {\n  /**\n   * The value of the parameter as a string\n   *\n   * @param value The string value of the parameter\n   */\n  public static fromString(value: string): ComponentParameterValue {\n    return new ComponentParameterValue([value]);\n  }\n\n  /**\n   * The rendered parameter value\n   */\n  public readonly value: string[];\n\n  protected constructor(value: string[]) {\n    this.value = value;\n  }\n}", "language": "typescript"}
{"input": "CDK Construct for WAF, Config infrastructure components", "output": "export class ConstructsDependency extends ValidationRule {\n  public readonly name = 'constructs/dependency';\n\n  public validate(pkg: PackageJson) {\n    const REQUIRED_VERSION = ConstructsVersion.VERSION;\n\n    // require a \"constructs\" dependency if there's a @aws-cdk/core dependency\n    const requiredDev = pkg.getDevDependency('@aws-cdk/core') && !pkg.getDevDependency('constructs');\n    if (requiredDev || (pkg.devDependencies?.constructs && pkg.devDependencies?.constructs !== REQUIRED_VERSION)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION}`,\n        fix: () => {\n          pkg.addDevDependency('constructs', REQUIRED_VERSION);\n        },\n      });\n    }\n\n    const requiredDep = pkg.dependencies?.['@aws-cdk/core'] && !pkg.dependencies?.constructs;\n    if (requiredDep || (pkg.dependencies.constructs && pkg.dependencies.constructs !== REQUIRED_VERSION)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION}`,\n        fix: () => {\n          pkg.addDependency('constructs', REQUIRED_VERSION);\n        },\n      });\n\n      if (!pkg.peerDependencies.constructs || pkg.peerDependencies.constructs !== REQUIRED_VERSION) {\n        pkg.report({\n          ruleName: this.name,\n          message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION} in peerDependencies`,\n          fix: () => {\n            pkg.addPeerDependency('constructs', REQUIRED_VERSION);\n          },\n        });\n      }\n    }\n  }\n}\n\n/**\n * Peer dependencies should be a range, not a point version, to maximize compatibility\n */\nexport class PeerDependencyRange extends ValidationRule {\n  public readonly name = 'peerdependency/range';\n\n  public validate(pkg: PackageJson) {\n    const packages = ['aws-cdk-lib'];\n    for (const [name, version] of Object.entries(pkg.peerDependencies)) {\n      if (packages.includes(name) && version.match(/^[0-9]/)) {\n        pkg.report({\n          ruleName: this.name,\n          message: `peerDependency on\" ${name}\" should be a range, not a point version: \"${version}\"`,\n          fix: () => {\n            pkg.addPeerDependency(name, '^' + version);\n          },\n        });\n      }\n    }\n  }\n}\n\n/**\n * Do not announce new versions of AWS CDK modules in awscdk.io because it is very very spammy\n * and actually causes the @awscdkio twitter account to be blocked.\n *\n * https://github.com/construct-catalog/catalog/issues/24\n * https://github.com/construct-catalog/catalog/pull/22\n */\nexport class DoNotAnnounceInCatalog extends ValidationRule {\n  public readonly name = 'catalog/no-announce';\n\n  public validate(pkg: PackageJson) {\n    if (!isJSII(pkg)) { return; }\n\n    if (pkg.json.awscdkio?.announce !== false) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'missing \"awscdkio.announce: false\" in package.json',\n        fix: () => {\n          pkg.json.awscdkio = pkg.json.awscdkio ?? { };\n          pkg.json.awscdkio.announce = false;\n        },\n      });\n    }\n  }\n}\n\nexport class EslintSetup extends ValidationRule {\n  public readonly name = 'package-info/eslint';\n\n  public validate(pkg: PackageJson) {\n    const eslintrcFilename = 'eslint.config.mjs';\n    if (!fs.existsSync(eslintrcFilename)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `There must be a ${eslintrcFilename} file at the root of the package`,\n        fix: () => {\n          fs.writeFileSync(\n            eslintrcFilename,\n            [\n              'import { makeConfig } from \\'@aws-cdk/eslint-config\\';',\n              'export default makeConfig(\\'tsconfig.json\\');',\n            ].join('\\n') + '\\n',\n          );\n        },\n      }", "language": "typescript"}
{"input": "The library builder for `aws-cdk-lib`. Contains the spec", "output": "export class AwsCdkLibBuilder extends LibraryBuilder<AwsCdkLibServiceSubmodule> {\n  private readonly inCdkLib: boolean;\n  private readonly filePatterns: AwsCdkLibFilePatterns;\n  private readonly interfacesEntry: LocatedModule<Module>;\n\n  public constructor(props: AwsCdkLibBuilderProps) {\n    super(props);\n    this.filePatterns = {\n      ...DEFAULT_FILE_PATTERNS,\n      ...noUndefined(props?.filePatterns ?? {}),\n    };\n    this.inCdkLib = props.inCdkLib ?? false;\n\n    if (this.filePatterns.interfacesEntry.includes('%')) {\n      throw new Error(`interfacesEntry may not contain placeholders, got: ${this.filePatterns.interfacesEntry}`);\n    }\n\n    this.interfacesEntry = this.rememberModule({\n      module: new Module('interfaces/index'),\n      filePath: this.filePatterns.interfacesEntry,\n    });\n  }\n\n  protected createServiceSubmodule(service: Service, submoduleName: string, grantsProps?: GrantsProps): AwsCdkLibServiceSubmodule {\n    const resourcesMod = this.rememberModule(this.createResourceModule(submoduleName, service));\n    const augmentations = this.rememberModule(this.createAugmentationsModule(submoduleName, service));\n    const cannedMetrics = this.rememberModule(this.createCannedMetricsModule(submoduleName, service));\n    const [interfaces, didCreateInterfaceModule] = this.obtainInterfaceModule(service);\n\n    const grants = grantsProps != null\n      ? this.rememberModule(this.createGrantsModule(submoduleName, service, grantsProps))\n      : undefined;\n\n    const createdSubmod: AwsCdkLibServiceSubmodule = new AwsCdkLibServiceSubmodule({\n      submoduleName,\n      service,\n      resourcesMod,\n      augmentations,\n      cannedMetrics,\n      interfaces,\n      didCreateInterfaceModule,\n      grants,\n    });\n\n    return createdSubmod;\n  }\n\n  private createGrantsModule(moduleName: string, service: Service, grantsProps: GrantsProps): LocatedModule<GrantsModule> {\n    const filePath = this.pathsFor(moduleName, service).grants;\n    const imports = this.resolveImportPaths(filePath);\n    return {\n      module: new GrantsModule(service, this.db, JSON.parse(grantsProps.config), imports.iam, grantsProps.isStable),\n      filePath,\n    };\n  }\n\n  protected addResourceToSubmodule(submodule: AwsCdkLibServiceSubmodule, resource: Resource, props?: AddServiceProps): void {\n    const resourceModule = submodule.resourcesMod.module;\n\n    const resourceClass = new ResourceClass(resourceModule, this.db, resource, {\n      suffix: props?.nameSuffix,\n      deprecated: props?.deprecated,\n      importPaths: this.resolveImportPaths(submodule.resourcesMod.filePath),\n      interfacesModule: {\n        module: submodule.interfaces.module,\n        importLocation: relativeImportPath(submodule.resourcesMod, submodule.interfaces),\n      },\n    });\n\n    resourceClass.build();\n\n    submodule.registerResource(resource.cloudFormationType, resourceClass);\n    submodule.augmentations?.module.augmentResource(resource, resourceClass);\n  }\n\n  private createResourceModule(moduleName: string, service: Service): LocatedModule<Module> {\n    const filePath = this.pathsFor(moduleName, service).resources;\n    const imports = this.resolveImportPaths(filePath);\n\n    const module = new Module(`@aws-cdk/${moduleName}/${service.name}`);\n\n    CDK_CORE.import(module, 'cdk', { fromLocation: imports.core });\n    CONSTRUCTS.import(module, 'constructs');\n    CDK_CORE.helpers.import(module, 'cfn_parse', { fromLocation: imports.coreHelpers });\n    CDK_CORE.errors.import(module, 'cdk_errors', { fromLocation: imports.coreErrors });\n\n    return { module, filePath };\n  }\n\n  private createAugmentationsModule(moduleName: string, service: Service): LocatedModule<AugmentationsModule> {\n    const filePath = this.pathsFor(moduleName, service).augmentations;\n    const imports = this.resolveImportPaths(filePath);\n    return {\n      module: new AugmentationsModule(this.db, service.shortName, imports.cloudwatch),\n      filePath,\n    };\n  }\n\n  private createCannedMetricsModule(moduleName: string, service: Service): LocatedModule<CannedMetricsModule> {\n    const filePath = this.pathsFor(moduleName, service).cannedMetrics;\n    return {\n      module: CannedMetricsModule.forService(this.db, service),\n      filePath,\n    };\n  }\n\n  /**\n   * Create or find the module where we should add the interfaces for these resources\n   *\n   * Complicated by the fact that we generate classes for some services in multiple places, but we should only generate the interfaces once.\n   */\n  private obtainInterfaceModule(service: Service): [LocatedModule<Module>, boolean] {\n    const filePath = this.pathsFor('$UNUSED$', service).interfaces;\n\n    return this.modules.has(filePath)\n      ? [{ module: this.modules.get(filePath)!, filePath }, false]\n      : [this.rememberModule(this.createInterfaceModule(service)), true];\n  }\n\n  private createInterfaceModule(service: Service): LocatedModule<Module> {\n    const filePath = this.pathsFor('$UNUSED$', service).interfaces;\n    const imports = this.resolveImportPaths(filePath);\n\n    const module = new Module(`@aws-cdk/interfaces/${service.name}`);\n    CDK_INTERFACES_ENVIRONMENT_AWARE.importSelective(module, ['IEnvironmentAware'], {\n      fromLocation: imports.interfacesEnvironmentAware,\n    });\n    CONSTRUCTS.import(module, 'constructs');\n\n    return { module, filePath };\n  }\n\n  /**\n   * Do whatever we need to do after a service has been rendered to a submodule\n   *\n   * (Mostly: create additional files that import generated files)\n   */\n  protected postprocessSubmodule(submodule: AwsCdkLibServiceSubmodule, props?: AddServiceProps) {\n    const grantModule = submodule.locatedModules\n      .map(lm => lm.module)\n      .find(m => m instanceof GrantsModule);\n\n    if (grantModule != null) {\n      grantModule.build(Object.fromEntries(submodule.resources), props?.nameSuffix);\n    }\n\n    // Add an import for the interfaces file to the entry point file (make sure not to do it twice)\n    if (!submodule.interfaces.module.isEmpty() && this.interfacesEntry && submodule.didCreateInterfaceModule) {\n      const exportName = submoduleSymbolFromName(submodule.service.name);\n      const importLocation = relativeImportPath(this.interfacesEntry, submodule.interfaces);\n\n      this.interfacesEntry.module.addInitialization(stmt.directCode(\n        `export * as ${exportName} from '${importLocation}'`,\n      ));\n    }\n  }\n\n  private resolveImportPaths(sourceModule: string): ImportPaths {\n    if (!this.inCdkLib) {\n      return {\n        core: 'aws-cdk-lib/core',\n        interfaces: 'aws-cdk-lib/interfaces',\n        interfacesEnvironmentAware: 'aws-cdk-lib/interfaces/environment-aware',\n        coreHelpers: 'aws-cdk-lib/core/lib/helpers-internal',\n        coreErrors: 'aws-cdk-lib/core/lib/errors',\n        cloudwatch: 'aws-cdk-lib/aws-cloudwatch',\n        iam: 'aws-cdk-lib/aws-iam',\n      };\n    }\n\n    return {\n      core: relativeImportPath(sourceModule, 'core/lib'),\n      interfaces: relativeImportPath(sourceModule, 'interfaces'),\n      interfacesEnvironmentAware: relativeImportPath(sourceModule, 'interfaces/environment-aware'),\n      coreHelpers: relativeImportPath(sourceModule, 'core/lib/helpers-internal'),\n      coreErrors: relativeImportPath(sourceModule, 'core/lib/errors'),\n      cloudwatch: relativeImportPath(sourceModule, 'aws-cloudwatch'),\n      iam: relativeImportPath(sourceModule, 'aws-iam'),\n    };\n  }\n\n  private pathsFor(submoduleName: string, service: Service): Record<keyof AwsCdkLibFilePatterns, string> {\n    return Object.fromEntries(Object.entries(this.filePatterns)\n      .map(([name, pattern]) => [name, this.pathFor(pattern, submoduleName, service)] as const)) as any;\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: -- aws cloudwatch describe-alarms --alarm-name-prefix aws-cdk-expose-metric-integ has Namespace of `MyApp` and Statistic of `Average`", "output": "class ExposeMetricIntegStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const logGroup = new LogGroup(this, 'LogGroup', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    /// !show\n    const mf = new MetricFilter(this, 'MetricFilter', {\n      logGroup,\n      metricNamespace: 'MyApp',\n      metricName: 'Latency',\n      filterPattern: FilterPattern.exists('$.latency'),\n      metricValue: '$.latency',\n    });\n\n    new Alarm(this, 'alarm from metric filter', {\n      metric: mf.metric(),\n      threshold: 100,\n      evaluationPeriods: 2,\n    });\n\n    /// !hide\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, Kinesis, CloudFormation resources", "output": "class KinesisWithS3OnFailureDestinationStack extends Stack {\n  constructor(scope: App, id: string) {\n    super(scope, id);\n\n    const fn = new lambda.Function(this, 'F', {\n      runtime: STANDARD_NODEJS_RUNTIME,\n      handler: 'index.handler',\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n    });\n    new CfnOutput(this, 'FunctionArn', { value: fn.functionArn });\n\n    const stream = new kinesis.Stream(this, 'S');\n    new CfnOutput(this, 'InputKinesisStreamName', { value: stream.streamName });\n\n    const bucket = new Bucket(this, 'B', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    fn.addEventSource(new KinesisEventSource(stream, {\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      onFailure: new S3OnFailureDestination(bucket),\n      retryAttempts: 0,\n    }));\n  }\n}", "language": "typescript"}
{"input": "EFS Replication Configuration", "output": "class ReplicationConfiguration {\n  /**\n   * Specify the existing destination file system for the replication.\n   *\n   * @param destinationFileSystem The existing destination file system for the replication\n   */\n  public static existingFileSystem(destinationFileSystem: IFileSystemRef): ReplicationConfiguration {\n    return new ExistingFileSystem({ destinationFileSystem });\n  }\n\n  /**\n   * Create a new regional destination file system for the replication.\n   *\n   * @param region The AWS Region in which the destination file system is located. Default is the region of the stack.\n   * @param kmsKey  AWS KMS key used to protect the encrypted file system. Default is service-managed KMS key for Amazon EFS.\n   */\n  public static regionalFileSystem(region?: string, kmsKey?: kms.IKey): ReplicationConfiguration {\n    return new RegionalFileSystem({ region, kmsKey });\n  }\n\n  /**\n   * Create a new one zone destination file system for the replication.\n   *\n   * @param region The AWS Region in which the specified availability zone belongs to.\n   * @param availabilityZone The availability zone name of the destination file system.\n   * @param kmsKey AWS KMS key used to protect the encrypted file system. Default is service-managed KMS key for Amazon EFS.\n   */\n  public static oneZoneFileSystem(region: string, availabilityZone: string, kmsKey?: kms.IKey): ReplicationConfiguration {\n    return new OneZoneFileSystem({ region, availabilityZone, kmsKey });\n  }\n\n  private readonly _destinationFileSystem?: IFileSystemRef;\n\n  /**\n   * The existing destination file system for the replication.\n   */\n  public get destinationFileSystem(): IFileSystem | undefined {\n    return this._destinationFileSystem ? toIFileSystem(this._destinationFileSystem) : undefined;\n  }\n\n  /**\n   * @internal\n   */\n  public get _destinationFileSystemRef(): IFileSystemRef | undefined {\n    return this._destinationFileSystem;\n  }\n\n  /**\n   * AWS KMS key used to protect the encrypted file system.\n   */\n  public readonly kmsKey?: kms.IKey;\n\n  /**\n   * The AWS Region in which the destination file system is located.\n   */\n  public readonly region?: string;\n\n  /**\n   * The availability zone name of the destination file system.\n   * One zone file system is used as the destination file system when this property is set.\n   */\n  public readonly availabilityZone?: string;\n\n  constructor(options: ReplicationConfigurationProps) {\n    this._destinationFileSystem = options.destinationFileSystem;\n    this.kmsKey = options.kmsKey;\n    this.region = options.region;\n    this.availabilityZone = options.availabilityZone;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function test_athena_workgroup_created", "output": "def test_athena_workgroup_created(template):\n    template.resource_count_is(type=\"AWS::Athena::WorkGroup\", count=1)\n\n    template.has_resource_properties(type=\"AWS::Athena::WorkGroup\",\n                                     props={\n                                         \"Name\": \"log-auditing\",\n                                         \"WorkGroupConfiguration\": {\n                                             \"ResultConfiguration\": {\n                                                 \"EncryptionConfiguration\": {\n                                                     \"EncryptionOption\": \"SSE_S3\"\n                                                 },\n                                                 \"OutputLocation\": {\n                                                     \"Fn::Join\": [\n                                                         \"\",\n                                                         [\n                                                             \"s3://\",\n                                                             {\"Ref\": \"queryoutputbucket3DDDB997\"}\n                                                         ]\n                                                     ]\n                                                 }\n                                             }\n                                         }\n                                     })", "language": "python"}
{"input": "Iot destination which points to the MSK VPC", "output": "class IotProducerDestination(NestedStack):\n    def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc_id,\n                role_arn,\n                subnet_ids,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Create Iot Messaging Destination for MSK Cluster\n        destination = iot.CfnTopicRuleDestination(self, \"TopicDestination\", \n            vpc_properties=iot.CfnTopicRuleDestination.VpcDestinationPropertiesProperty(\n                role_arn=role_arn,\n                vpc_id=vpc_id,\n                subnet_ids=subnet_ids\n            )\n        )\n        self.arn = destination.attr_arn", "language": "python"}
{"input": "CDK Stack that creates Lambda, KMS, Secrets Manager, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const key = new kms.Key(this, 'Key', { removalPolicy: cdk.RemovalPolicy.DESTROY });\n\n    const secret = new secretsmanager.Secret(this, 'Secret', {\n      encryptionKey: key,\n    });\n\n    secret.addRotationSchedule('Schedule', {\n      rotationLambda: new lambda.Function(this, 'Lambda', {\n        runtime: STANDARD_NODEJS_RUNTIME,\n        handler: 'index.handler',\n        code: lambda.Code.fromInline('NOOP'),\n      }),\n      automaticallyAfter: cdk.Duration.hours(4),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, SQS resources", "output": "class BatchEC2Stack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # This resource alone will create a private/public subnet in each AZ as well as nat/internet gateway(s)\n        vpc = ec2.Vpc(self, \"VPC\")\n\n        # To create number of Batch Compute Environment\n        count = 3\n\n        # Create AWS Batch Job Queue\n        self.batch_queue = batch.JobQueue(self, \"JobQueueArm64\")\n\n        # For loop to create Batch Compute Environments\n        for i in range(count):\n            name = \"MyBatchARM64Env\" + str(i)\n            batch_environment = batch.ManagedEc2EcsComputeEnvironment(self, name,\n                spot=True,\n                spot_bid_percentage=75,\n                instance_types=[ec2.InstanceType(\"c7g.medium\"),ec2.InstanceType(\"c7g.large\")],\n                use_optimal_instance_classes=False,\n                vpc_subnets=ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_NAT),\n                vpc=vpc\n            )\n\n            self.batch_queue.add_compute_environment(batch_environment, i)\n\n        # Create ECS Job Definition to submit job in batch job queue.\n        batch_jobDef = batch.EcsJobDefinition(self, \"MyJobDefArm64\",\n                                           container=batch.EcsEc2ContainerDefinition(self, \"CDKJobDefArm64\",\n                                               image=ecs.ContainerImage.from_registry(\"public.ecr.aws/amazonlinux/amazonlinux:latest\"),\n                                               command=[\"sleep\", \"60\"],\n                                               memory=Size.mebibytes(512),\n                                               cpu=1\n                                           )\n        )\n\n        # Output resources\n        CfnOutput(self, \"BatchJobQueue\",value=self.batch_queue.job_queue_name)\n        CfnOutput(self, \"EcsJobDefinition\",value=batch_jobDef.job_definition_name)", "language": "python"}
{"input": "Connection endpoint of a redshift cluster Consists of a combination of hostname and port.", "output": "export class Endpoint {\n  /**\n   * The hostname of the endpoint\n   */\n  public readonly hostname: string;\n\n  /**\n   * The port of the endpoint\n   */\n  public readonly port: number;\n\n  /**\n   * The combination of \"HOSTNAME:PORT\" for this endpoint\n   */\n  public readonly socketAddress: string;\n\n  constructor(address: string, port: number) {\n    this.hostname = address;\n    this.port = port;\n\n    const portDesc = Token.isUnresolved(port) ? Token.asString(port) : port;\n    this.socketAddress = `${address}:${portDesc}`;\n  }\n}", "language": "typescript"}
{"input": "Health check settings @deprecated Use HealthChecks instead", "output": "export class HealthCheck {\n  /**\n   * Use EC2 for health checks\n   *\n   * @param options EC2 health check options\n   */\n  public static ec2(options: Ec2HealthCheckOptions = {}): HealthCheck {\n    return new HealthCheck(HealthCheckType.EC2, options.grace);\n  }\n\n  /**\n   * Use ELB for health checks.\n   * It considers the instance unhealthy if it fails either the EC2 status checks or the load balancer health checks.\n   *\n   * @param options ELB health check options\n   */\n  public static elb(options: ElbHealthCheckOptions): HealthCheck {\n    return new HealthCheck(HealthCheckType.ELB, options.grace);\n  }\n\n  private constructor(public readonly type: string, public readonly gracePeriod?: Duration) { }\n}", "language": "typescript"}
{"input": "CDK class LambdaRestApi for AWS resource management", "output": "export class LambdaRestApi extends RestApi {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.LambdaRestApi';\n\n  constructor(scope: Construct, id: string, props: LambdaRestApiProps) {\n    if (props.options?.defaultIntegration || props.defaultIntegration) {\n      throw new ValidationError('Cannot specify \"defaultIntegration\" since Lambda integration is automatically defined', scope);\n    }\n\n    super(scope, id, {\n      defaultIntegration: new LambdaIntegration(props.handler, props.integrationOptions),\n      ...props.options, // deprecated, but we still support\n      ...props,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.proxy !== false) {\n      this.root.addProxy();\n\n      // Make sure users cannot call any other resource adding function\n      this.root.addResource = addResourceThrows;\n      this.root.addMethod = addMethodThrows;\n      this.root.addProxy = addProxyThrows;\n    }\n\n    this.node.addValidation({\n      validate() {\n        for (const value of Object.values(props.deployOptions?.variables ?? {})) {\n          // Checks that variable Stage values match regex\n          const regexp = /[A-Za-z0-9-._~:/?#&=,]+/;\n          if (value.match(regexp) === null) {\n            return ['Stage variable value ' + value + ' does not match the regex.'];\n          }\n        }\n        return [];\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "AWS Defined signatures for enabling certain capabilities in your agent.", "output": "export class ParentActionGroupSignature {\n  /**\n   * Signature that allows your agent to request the user for additional information when trying to complete a task.\n   */\n  public static readonly USER_INPUT = new ParentActionGroupSignature('AMAZON.UserInput');\n  /**\n   * Signature that allows your agent to generate, run, and troubleshoot code when trying to complete a task.\n   */\n  public static readonly CODE_INTERPRETER = new ParentActionGroupSignature('AMAZON.CodeInterpreter');\n  /**\n   * Constructor should be used as a temporary solution when a new signature is supported but its implementation in CDK hasn't been added yet.\n   */\n  constructor(\n    /**\n     * The AWS-defined signature value for this action group capability.\n     */\n    public readonly value: string,\n  ) {}\n\n  /**\n   * Returns the string representation of the signature value.\n   * Used when configuring the action group in CloudFormation.\n   */\n  public toString() {\n    return this.value;\n  }\n}\n/******************************************************************************\n *                         PROPS - Action Group Class\n *****************************************************************************/\nexport interface AgentActionGroupProps {\n  /**\n   * The name of the action group.\n   * @default - A unique name is generated in the format 'action_group_quick_start_UUID'\n   */\n  readonly name?: string;\n\n  /**\n   * A description of the action group.\n   *\n   * @default undefined - No description is provided\n   */\n  readonly description?: string;\n\n  /**\n   * The API Schema defining the functions available to the agent.\n   *\n   * @default undefined - No API Schema is provided\n   */\n  readonly apiSchema?: ApiSchema;\n\n  /**\n   * The action group executor that implements the API functions.\n   *\n   * @default undefined - No executor is provided\n   */\n  readonly executor?: ActionGroupExecutor;\n\n  /**\n   * Specifies whether the action group is available for the agent to invoke or\n   * not when sending an InvokeAgent request.\n   *\n   * @default true - The action group is enabled\n   */\n  readonly enabled?: boolean;\n\n  /**\n   * Specifies whether to delete the resource even if it's in use.\n   *\n   * @default false - The resource will not be deleted if it's in use\n   */\n  readonly forceDelete?: boolean;\n\n  /**\n   * Defines functions that each define parameters that the agent needs to invoke from the user.\n   * NO L2 yet as this doesn't make much sense IMHO.\n   *\n   * @default undefined - No function schema is provided\n   */\n  readonly functionSchema?: FunctionSchema;\n\n  /**\n   * The AWS Defined signature for enabling certain capabilities in your agent.\n   * When this property is specified, you must leave the description, apiSchema,\n   * and actionGroupExecutor fields blank for this action group.\n   *\n   * @default undefined - No parent action group signature is provided\n   */\n  readonly parentActionGroupSignature?: ParentActionGroupSignature;\n}", "language": "typescript"}
{"input": "CDK class LookedUpVpc for AWS resource management", "output": "class LookedUpVpc extends VpcBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.LookedUpVpc';\n  public readonly vpcId: string;\n  public readonly vpcArn: string;\n  public readonly internetConnectivityEstablished: IDependable = new DependencyGroup();\n  public readonly availabilityZones: string[];\n  public readonly publicSubnets: ISubnet[];\n  public readonly privateSubnets: ISubnet[];\n  public readonly isolatedSubnets: ISubnet[];\n  private readonly cidr?: string | undefined;\n\n  constructor(scope: Construct, id: string, props: cxapi.VpcContextResponse, isIncomplete: boolean) {\n    super(scope, id, {\n      region: props.region,\n      account: props.ownerAccountId,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.vpcId = props.vpcId;\n    this.vpcArn = Arn.format({\n      service: 'ec2',\n      resource: 'vpc',\n      resourceName: this.vpcId,\n      region: this.env.region,\n      account: this.env.account,\n    }, Stack.of(this));\n    this.cidr = props.vpcCidrBlock;\n    this._vpnGatewayId = props.vpnGatewayId;\n    this.incompleteSubnetDefinition = isIncomplete;\n\n    const subnetGroups = props.subnetGroups || [];\n    const availabilityZones = Array.from(new Set<string>(flatMap(subnetGroups, subnetGroup => {\n      return subnetGroup.subnets.map(subnet => subnet.availabilityZone);\n    })));\n    availabilityZones.sort((az1, az2) => az1.localeCompare(az2));\n    this.availabilityZones = availabilityZones;\n\n    this.publicSubnets = this.extractSubnetsOfType(subnetGroups, cxapi.VpcSubnetGroupType.PUBLIC);\n    this.privateSubnets = this.extractSubnetsOfType(subnetGroups, cxapi.VpcSubnetGroupType.PRIVATE);\n    this.isolatedSubnets = this.extractSubnetsOfType(subnetGroups, cxapi.VpcSubnetGroupType.ISOLATED);\n  }\n\n  public get vpcCidrBlock(): string {\n    if (this.cidr === undefined) {\n      // Value might be cached from an old CLI version, so bumping the CX API protocol to\n      // force the value to exist would not have helped.\n      throw new ValidationError('Cannot perform this operation: \\'vpcCidrBlock\\' was not found when looking up this VPC. Use a newer version of the CDK CLI and clear the old context value.', this);\n    }\n    return this.cidr;\n  }\n\n  private extractSubnetsOfType(subnetGroups: cxapi.VpcSubnetGroup[], subnetGroupType: cxapi.VpcSubnetGroupType): ISubnet[] {\n    return flatMap(subnetGroups.filter(subnetGroup => subnetGroup.type === subnetGroupType),\n      subnetGroup => this.subnetGroupToSubnets(subnetGroup));\n  }\n\n  private subnetGroupToSubnets(subnetGroup: cxapi.VpcSubnetGroup): ISubnet[] {\n    const ret = new Array<ISubnet>();\n    for (let i = 0; i < subnetGroup.subnets.length; i++) {\n      const vpcSubnet = subnetGroup.subnets[i];\n      ret.push(Subnet.fromSubnetAttributes(this, `${subnetGroup.name}Subnet${i + 1}`, {\n        availabilityZone: vpcSubnet.availabilityZone,\n        subnetId: vpcSubnet.subnetId,\n        routeTableId: vpcSubnet.routeTableId,\n        ipv4CidrBlock: vpcSubnet.cidr,\n      }));\n    }\n    return ret;\n  }\n}", "language": "typescript"}
{"input": "CDK class Oracle for AWS resource management", "output": "export class Oracle extends Stack {\n  constructor(scope: Construct, id: string, props: OracleProps) {\n    super(scope, id);\n\n    // default database username\n    let oracleUsername = \"dbadmin\";\n    if (typeof props.oracleUsername !== 'undefined') {\n      oracleUsername = \"dbadmin\";\n    }\n    let ingressSources = [];\n    if (typeof props.ingressSources !== 'undefined') {\n      ingressSources = props.ingressSources;\n    }\n    let engineVersion = rds.OracleEngineVersion.VER_19_0_0_0_2021_04_R1;\n    if (typeof props.engineVersion !== 'undefined') {\n      engineVersion = props.engineVersion;\n    }\n\n    const azs = Fn.getAzs();\n\n    // vpc\n    const vpc = ec2.Vpc.fromVpcAttributes(this, 'ExistingVPC', {\n      vpcId: props.vpcId!,\n      availabilityZones: azs,\n    });\n\n    // Subnets\n    const subnets: any[] = [];\n\n    for (let subnetId of props.subnetIds!) {\n      const subid = subnetId\n        .replace('_', '')\n        .replace(' ', '');\n      subnets.push(\n        ec2.Subnet.fromSubnetAttributes(this, subid, {\n          subnetId: subid,\n        }),\n      );\n    }\n\n    const vpcSubnets: ec2.SubnetSelection = {\n      subnets: subnets,\n    };\n\n    const allAll = ec2.Port.allTraffic();\n    const tcp1521 = ec2.Port.tcpRange(1521, 1521);\n    const tcp1526 = ec2.Port.tcpRange(1526, 1526);\n    const tcp1575 = ec2.Port.tcpRange(1575, 1575);\n\n    const dbsg = new ec2.SecurityGroup(this, 'DatabaseSecurityGroup', {\n      vpc: vpc,\n      allowAllOutbound: true,\n      description: id + 'Database',\n      securityGroupName: id + 'Database',\n    });\n\n    dbsg.addIngressRule(dbsg, allAll, 'all from self');\n    dbsg.addEgressRule(ec2.Peer.ipv4('0.0.0.0/0'), allAll, 'all out');\n\n    const oracleConnectionPorts = [\n      { port: tcp1521, description: 'tcp1521 Oracle' },\n      { port: tcp1526, description: 'tcp1526 Oracle' },\n      { port: tcp1575, description: 'tcp1575 Oracle' },\n    ];\n\n    for (let ingressSource of ingressSources!) {\n      for (let c of oracleConnectionPorts) {\n        dbsg.addIngressRule(ingressSource, c.port, c.description);\n      }\n    }\n\n    const dbSubnetGroup = new rds.SubnetGroup(this, 'DatabaseSubnetGroup', {\n      vpc: vpc,\n      description: id + 'subnet group',\n      vpcSubnets: vpcSubnets,\n      subnetGroupName: id + 'subnet group',\n    });\n\n    const oracleSecret = new secretsmanager.Secret(this, 'OracleCredentials', {\n      secretName: props.dbName + 'OracleCredentials',\n      description: props.dbName + 'Oracle Database Crendetials',\n      generateSecretString: {\n        excludeCharacters: \"\\\"@/\\\\ '\",\n        generateStringKey: 'password',\n        passwordLength: 30,\n        secretStringTemplate: JSON.stringify({username: oracleUsername}),\n      },\n    });\n\n    const oracleCredentials = rds.Credentials.fromSecret(\n      oracleSecret,\n      oracleUsername,\n    );\n\n    const dbParameterGroup = new rds.ParameterGroup(this, 'ParameterGroup', {\n      engine: rds.DatabaseInstanceEngine.oracleEe({\n        version: engineVersion,\n      }),\n      parameters: { open_cursors: '2500' },\n    });\n\n    const oracleInstance = new rds.DatabaseInstance(this, 'OracleDatabase', {\n      databaseName: props.dbName,\n      instanceIdentifier: props.dbName,\n      credentials: oracleCredentials,\n      engine: rds.DatabaseInstanceEngine.oracleEe({\n        version: engineVersion,\n      }),\n      backupRetention: Duration.days(7),\n      allocatedStorage: 20,\n      securityGroups: [dbsg],\n      licenseModel: rds.LicenseModel.BRING_YOUR_OWN_LICENSE,\n      allowMajorVersionUpgrade: true,\n      autoMinorVersionUpgrade: true,\n      instanceType: props.instanceType,\n      vpcSubnets: vpcSubnets,\n      vpc: vpc,\n      removalPolicy: RemovalPolicy.RETAIN,\n      multiAz: true,\n      storageEncrypted: true,\n      monitoringInterval: Duration.seconds(60),\n      enablePerformanceInsights: true,\n      cloudwatchLogsExports: ['trace', 'audit', 'alert', 'listener'],\n      cloudwatchLogsRetention: logs.RetentionDays.ONE_MONTH,\n      parameterGroup: dbParameterGroup,\n      subnetGroup: dbSubnetGroup,\n      preferredBackupWindow: props.backupWindow,\n      preferredMaintenanceWindow: props.preferredMaintenanceWindow,\n      publiclyAccessible: false,\n    });\n\n    oracleInstance.addRotationSingleUser();\n\n    // Tags\n    Tags.of(oracleInstance).add('Name', 'OracleDatabase', {\n      priority: 300,\n    });\n\n\n    new CfnOutput(this, 'OracleEndpoint', {\n      exportName: 'OracleEndPoint',\n      value: oracleInstance.dbInstanceEndpointAddress,\n    });\n\n    new CfnOutput(this, 'OracleUserName', {\n      exportName: 'OracleUserName',\n      value: oracleUsername,\n    });\n\n    new CfnOutput(this, 'OracleDbName', {\n      exportName: 'OracleDbName',\n      value: props.dbName!,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, Route 53 resources", "output": "class ParentStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const parentZone = new route53.PublicHostedZone(this, 'HostedZone', {\n      zoneName: parentZoneName,\n    });\n    const crossAccountRole = new iam.Role(this, 'CrossAccountRole', {\n      roleName: delegationRoleName,\n      assumedBy: new iam.AccountPrincipal(crossAccount),\n    });\n    parentZone.grantDelegation(crossAccountRole);\n  }\n}", "language": "typescript"}
{"input": "CDK class AssetModelData for AWS resource management", "output": "class AssetModelData extends ModelData {\n  private asset?: assets.Asset;\n\n  constructor(private readonly path: string, private readonly options: assets.AssetOptions) {\n    super();\n    if (!path.toLowerCase().endsWith(ARTIFACT_EXTENSION)) {\n      throw new Error(`Asset must be a gzipped tar file with extension ${ARTIFACT_EXTENSION} (${this.path})`);\n    }\n  }\n\n  public bind(scope: Construct, model: IModel): ModelDataConfig {\n    // Retain the first instantiation of this asset\n    if (!this.asset) {\n      this.asset = new assets.Asset(scope, `ModelData${hashcode(this.path)}`, {\n        path: this.path,\n        ...this.options,\n      });\n    }\n\n    this.asset.grantRead(model);\n\n    return {\n      uri: this.asset.httpUrl,\n    };\n  }\n}", "language": "typescript"}
{"input": "Stack with feature flag disabled (default) - client secret should not be logged", "output": "class TestStackSecretNotLogged extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const userpool = new UserPool(this, 'pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const client = userpool.addClient('client', { generateSecret: true });\n    const secret = new secretsmanager.Secret(this, 'secret', {\n      secretStringValue: client.userPoolClientSecret,\n    });\n\n    new CfnOutput(this, 'ClientSecretName', {\n      value: secret.secretName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3BucketOriginWithOAI for AWS resource management", "output": "class S3BucketOriginWithOAI extends S3BucketOrigin {\n  private readonly bucket: IBucket;\n  private originAccessIdentity?: cloudfront.ICloudFrontOriginAccessIdentityRef & iam.IGrantable;\n\n  constructor(bucket: IBucket, props?: S3BucketOriginWithOAIProps) {\n    super(bucket, { ...props });\n    this.bucket = bucket;\n    this.originAccessIdentity = props?.originAccessIdentity;\n  }\n\n  public bind(scope: Construct, options: cloudfront.OriginBindOptions): cloudfront.OriginBindConfig {\n    if (!this.originAccessIdentity) {\n      // Using a bucket from another stack creates a cyclic reference with\n      // the bucket taking a dependency on the generated S3CanonicalUserId for the grant principal,\n      // and the distribution having a dependency on the bucket's domain name.\n      // Fix this by parenting the OAI in the bucket's stack when cross-stack usage is detected.\n      const bucketStack = Stack.of(this.bucket);\n      const bucketInDifferentStack = bucketStack !== Stack.of(scope);\n      const oaiScope = bucketInDifferentStack ? bucketStack : scope;\n      const oaiId = bucketInDifferentStack ? `${Names.uniqueId(scope)}S3Origin` : 'S3Origin';\n\n      this.originAccessIdentity = new cloudfront.OriginAccessIdentity(oaiScope, oaiId, {\n        comment: `Identity for ${options.originId}`,\n      });\n    }\n    // Used rather than `grantRead` because `grantRead` will grant overly-permissive policies.\n    // Only GetObject is needed to retrieve objects for the distribution.\n    // This also excludes KMS permissions; OAI only supports SSE-S3 for buckets.\n    // Source: https://aws.amazon.com/blogs/networking-and-content-delivery/serving-sse-kms-encrypted-content-from-s3-using-cloudfront/\n    const result = this.bucket.addToResourcePolicy(new iam.PolicyStatement({\n      resources: [this.bucket.arnForObjects('*')],\n      actions: ['s3:GetObject'],\n      principals: [this.originAccessIdentity.grantPrincipal],\n    }));\n    if (!result.statementAdded) {\n      Annotations.of(scope).addWarningV2('@aws-cdk/aws-cloudfront-origins:updateImportedBucketPolicyOai',\n        'Cannot update bucket policy of an imported bucket. You will need to update the policy manually instead.\\n' +\n        'See the \"Setting up OAI with imported S3 buckets (legacy)\" section of module\\'s README for more info.');\n    }\n    return this._bind(scope, options);\n  }\n\n  protected renderS3OriginConfig(): cloudfront.CfnDistribution.S3OriginConfigProperty | undefined {\n    if (!this.originAccessIdentity) {\n      throw new UnscopedValidationError('Origin access identity cannot be undefined');\n    }\n    return { originAccessIdentity: `origin-access-identity/cloudfront/${this.originAccessIdentity.cloudFrontOriginAccessIdentityRef.cloudFrontOriginAccessIdentityId}` };\n  }\n}", "language": "typescript"}
{"input": "CDK class PrefixNamePart for AWS resource management", "output": "class PrefixNamePart extends NamePart {\n  constructor(bareStr: string, private readonly prefixLength: number) {\n    super(bareStr);\n  }\n\n  public generate(): string {\n    return this.bareStr.slice(0, this.prefixLength);\n  }\n}", "language": "typescript"}
{"input": "Represents the function's source code", "output": "class FunctionCode {\n  /**\n   * Inline code for function\n   * @returns code object with inline code.\n   * @param code The actual function code\n   */\n  public static fromInline(code: string): FunctionCode {\n    return new InlineCode(code);\n  }\n\n  /**\n   * Code from external file for function\n   * @returns code object with contents from file.\n   * @param options the options for the external file\n   */\n  public static fromFile(options: FileCodeOptions): FunctionCode {\n    return new FileCode(options);\n  }\n\n  /**\n   * renders the function code\n   */\n  public abstract render(): string;\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, IAM operations", "output": "def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        # Building Role\n        lambda_func_role = iam.Role(self, \"lambda-nag-func-role-example\",\n            assumed_by=iam.ServicePrincipal(\"lambda.amazonaws.com\"),\n            description=\"A simple role detached from self CDK built role\"\n        )\n        lambda_func_role_policy = iam.Policy(\n            self, \"lambda-nag-func-role-policy-example\",\n            statements=[\n                iam.PolicyStatement(\n                    actions=[\n                            \"logs:CreateLogStream\",\n                            \"logs:PutLogEvents\",\n                            \"logs:CreateLogGroup\"\n                    ],\n                    resources=[\n                        \"*\"\n                    ]\n                )\n            ],\n            roles=[lambda_func_role]\n        )\n\n        # In case of wildcard policy usage you must add a suppression in order to give a reason for that.\n        nag.NagSuppressions.add_resource_suppressions(\n            lambda_func_role_policy,\n            [{\n                \"id\": \"AwsSolutions-IAM5\",\n                \"reason\": \"A wildcard is necessary over this policy because <put your reason here>...\"\n            }]\n        )\n\n        with open(\"lambda-func/lambda-handler.py\", encoding=\"utf8\") as fcn_file:\n            handler_code = fcn_file.read()\n\n        # A non-container Lambda function is not configured to use the latest runtime version can raise a new error\n        lambda_func = lambda_.Function(\n            self, \"lambda-nag-func-example\",\n            code=lambda_.InlineCode(handler_code),\n            handler=\"index.handler\",\n            timeout=Duration.seconds(30),\n            role=lambda_func_role,\n            runtime=lambda_.Runtime.PYTHON_3_12,\n        )", "language": "python"}
{"input": "CDK class AlarmWithLabelIntegrationTest for AWS resource management", "output": "class AlarmWithLabelIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const testMetric = new Metric({\n      namespace: 'CDK/Test',\n      metricName: 'Metric',\n      label: 'Metric [AVG: ${AVG}]',\n    });\n\n    new Alarm(this, 'Alarm1', {\n      metric: testMetric,\n      threshold: 100,\n      evaluationPeriods: 3,\n    });\n\n    testMetric.createAlarm(this, 'Alarm2', {\n      threshold: 100,\n      evaluationPeriods: 3,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3ObjectsItemReaderTest for AWS resource management", "output": "class S3ObjectsItemReaderTest {\n  private readonly integTest: IntegTest;\n  private readonly testStack: S3ObjectsItemReaderTestStack;\n\n  constructor(app: App) {\n    this.testStack = new S3ObjectsItemReaderTestStack(app);\n    this.integTest = new IntegTest(app, 'IntegTest', {\n      testCases: [this.testStack],\n    });\n  }\n\n  test(): IApiCall {\n    const setupResources = this.setup();\n    const executionResult1 = this.executeForDynamic(setupResources);\n    const executionResult2 = this.executeForStatic(setupResources);\n    return this.assert(executionResult1).next(this.assert(executionResult2));\n  }\n\n  private setup(): IApiCall {\n    const putS3Object1 = this.integTest.assertions.awsApiCall('S3', 'putObject', {\n      Bucket: this.testStack.bucket.bucketName,\n      Key: 'testPrefixObject1',\n      Body: 'object1',\n    });\n    const putS3Object2 = this.integTest.assertions.awsApiCall('S3', 'putObject', {\n      Bucket: this.testStack.bucket.bucketName,\n      Key: 'testPrefixObject2',\n      Body: 'object2',\n    });\n    putS3Object1.next(putS3Object2);\n    const putS3Object3 = this.integTest.assertions.awsApiCall('S3', 'putObject', {\n      Bucket: this.testStack.bucket.bucketName,\n      Key: 'otherObject',\n      Body: 'object3',\n    });\n    putS3Object2.next(putS3Object3);\n    return putS3Object3;\n  }\n\n  private executeForDynamic(setupResources: IApiCall): IApiCall {\n    const startExecution = this.start(setupResources, this.testStack.dynamicStateMachine.stateMachineArn, JSON.stringify({\n      bucketName: this.testStack.bucket.bucketName,\n      prefix: 'testPrefix',\n    }));\n    return this.describe(startExecution);\n  }\n\n  private executeForStatic(setupResources: IApiCall): IApiCall {\n    const startExecution = this.start(setupResources, this.testStack.staticStateMachine.stateMachineArn, JSON.stringify({\n      prefix: 'testPrefix',\n    }));\n    return this.describe(startExecution);\n  }\n\n  private start(setupResources: IApiCall, stateMachineArn: string, input: string): IApiCall {\n    const startExecution = this.integTest.assertions.awsApiCall('StepFunctions', 'startExecution', {\n      input,\n      stateMachineArn,\n    });\n    setupResources.next(startExecution);\n    return startExecution;\n  }\n\n  private describe(startExecution: IApiCall): IApiCall {\n    const describeExecution = this.integTest.assertions.awsApiCall('StepFunctions', 'describeExecution', {\n      executionArn: startExecution.getAttString('executionArn'),\n    });\n    startExecution.next(describeExecution);\n    return describeExecution;\n  }\n\n  private assert(exeutionResult: IApiCall): IApiCall {\n    return exeutionResult.expect(ExpectedResult.objectLike({\n      status: 'SUCCEEDED',\n    })).waitForAssertions({\n      interval: Duration.seconds(10),\n      totalTimeout: Duration.minutes(2),\n    });\n  }\n}", "language": "typescript"}
{"input": "GitHub Source definition for a CodeBuild project.", "output": "class GitHubSource extends CommonGithubSource {\n  public readonly type = GITHUB_SOURCE_TYPE;\n  private readonly sourceLocation: string;\n  private readonly organization?: string;\n  protected readonly webhookFilters: FilterGroup[];\n  constructor(props: GitHubSourceProps) {\n    super(props);\n    this.organization = props.repo === undefined ? props.owner : undefined;\n    this.webhookFilters = props.webhookFilters ?? (this.organization ? [FilterGroup.inEventOf(EventAction.WORKFLOW_JOB_QUEUED)] : []);\n    this.sourceLocation = this.organization ? 'CODEBUILD_DEFAULT_WEBHOOK_SOURCE_LOCATION' : `https://github.com/${props.owner}/${props.repo}.git`;\n  }\n\n  public bind(_scope: Construct, project: IProject): SourceConfig {\n    const superConfig = super.bind(_scope, project);\n    return {\n      sourceProperty: {\n        ...superConfig.sourceProperty,\n        location: this.sourceLocation,\n      },\n      sourceVersion: superConfig.sourceVersion,\n      buildTriggers: this.organization\n        ? {\n          ...superConfig.buildTriggers,\n          scopeConfiguration: {\n            name: this.organization,\n          },\n        } : superConfig.buildTriggers,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, VPC, MSK (Kafka) resources", "output": "class FeatureFlagStack extends cdk.Stack {\n  public readonly bucketArn: string;\n  public readonly bucket: s3.IBucket;\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    this.bucket = new s3.Bucket(this, 'LoggingBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    const cluster = new msk.Cluster(this, 'Cluster', {\n      clusterName: 'integ-test',\n      kafkaVersion: msk.KafkaVersion.V2_8_1,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    this.bucketArn = this.exportValue(this.bucket.bucketArn);\n    // Test lazy instance of the AwsCustomResource\n    new cdk.CfnOutput(this, 'BootstrapBrokers', { value: cluster.bootstrapBrokersTls });\n    new cdk.CfnOutput(this, 'BootstrapBrokers2', { value: cluster.bootstrapBrokersTls });\n\n    // iam authenticated msk cluster integ test\n    const cluster2 = new msk.Cluster(this, 'ClusterIAM', {\n      clusterName: 'integ-test-iam-auth',\n      kafkaVersion: msk.KafkaVersion.V2_8_1,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      encryptionInTransit: {\n        clientBroker: msk.ClientBrokerEncryption.TLS,\n      },\n      clientAuthentication: msk.ClientAuthentication.sasl({\n        iam: true,\n      }),\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    // Test lazy instance of the AwsCustomResource\n    new cdk.CfnOutput(this, 'BootstrapBrokers3', { value: cluster2.bootstrapBrokersSaslIam });\n\n    const certSigningAlgorithm = 'SHA256WITHRSA';\n    const privateCA = new CfnCertificateAuthority(\n      this,\n      'CertificateAuthority',\n      {\n        keyAlgorithm: 'RSA_2048',\n        signingAlgorithm: certSigningAlgorithm,\n        keyStorageSecurityStandard: 'FIPS_140_2_LEVEL_3_OR_HIGHER',\n        type: 'ROOT',\n        subject: {\n          commonName: 'MSK Cluster Root CA',\n          organization: 'Amazon Web Services',\n          organizationalUnit: 'AWS-CDK',\n          country: 'DE',\n          state: 'Berlin',\n          locality: 'Berlin',\n        },\n      },\n    );\n\n    privateCA.node.addMetadata(\n      'Description',\n      'Signing authority for Certificates',\n    );\n\n    const cert = new CfnCertificate(this, 'Certificate', {\n      certificateAuthorityArn: privateCA.attrArn,\n      certificateSigningRequest: privateCA.attrCertificateSigningRequest,\n      signingAlgorithm: certSigningAlgorithm,\n      templateArn: 'arn:aws:acm-pca:::template/RootCACertificate/V1',\n      validity: {\n        type: 'YEARS',\n        value: 1,\n      },\n    });\n    cert.node.addMetadata(\n      'Description',\n      'Certificate for signing requests from MSK-Cluster',\n    );\n\n    // Activating the certificate using the signing cert authority\n    const certActivation = new CfnCertificateAuthorityActivation(\n      this,\n      'CertificateActivation',\n      {\n        certificateAuthorityArn: privateCA.attrArn,\n        certificate: cert.attrCertificate,\n      },\n    );\n\n    const cluster3 = new msk.Cluster(this, 'ClusterIAMTLS', {\n      clusterName: 'integ-test-iam-tls-auth',\n      kafkaVersion: msk.KafkaVersion.V2_8_1,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      encryptionInTransit: {\n        clientBroker: msk.ClientBrokerEncryption.TLS,\n      },\n      clientAuthentication: msk.ClientAuthentication.saslTls({\n        iam: true,\n        certificateAuthorities: [\n          CertificateAuthority.fromCertificateAuthorityArn(\n            this,\n            'PrivateCA',\n            privateCA.attrArn,\n          ),\n        ],\n      }),\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    cluster3.node.addDependency(certActivation);\n\n    // Test lazy instance of the AwsCustomResource\n    new cdk.CfnOutput(this, 'BootstrapBrokers4', { value: cluster3.bootstrapBrokersTls });\n    new cdk.CfnOutput(this, 'BootstrapBrokers5', { value: cluster3.bootstrapBrokersSaslIam });\n\n    const cluster4 = new msk.Cluster(this, 'Cluster_V3_1_1', {\n      clusterName: 'integ-test-v3-1-1',\n      kafkaVersion: msk.KafkaVersion.V3_1_1,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    new cdk.CfnOutput(this, 'BootstrapBrokers6', { value: cluster4.bootstrapBrokersTls });\n\n    const cluster5 = new msk.Cluster(this, 'Cluster_V3_2_0', {\n      clusterName: 'integ-test-v3-2-0',\n      kafkaVersion: msk.KafkaVersion.V3_2_0,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    new cdk.CfnOutput(this, 'BootstrapBrokers7', { value: cluster5.bootstrapBrokersTls });\n\n    const cluster6 = new msk.Cluster(this, 'Cluster_V3_3_1', {\n      clusterName: 'integ-test-v3-3-1',\n      kafkaVersion: msk.KafkaVersion.V3_3_1,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    new cdk.CfnOutput(this, 'BootstrapBrokers8', { value: cluster6.bootstrapBrokersTls });\n\n    const cluster7 = new msk.Cluster(this, 'Cluster_V3_3_2', {\n      clusterName: 'integ-test-v3-3-2',\n      kafkaVersion: msk.KafkaVersion.V3_3_2,\n      vpc,\n      logging: {\n        s3: {\n          bucket: this.bucket,\n        },\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    new cdk.CfnOutput(this, 'BootstrapBrokers9', { value: cluster7.bootstrapBrokersTls });\n  }\n}", "language": "typescript"}
{"input": "CDK class CfnPolicyConditional for AWS resource management", "output": "class CfnPolicyConditional extends CfnPolicy {\n      /**\n       * This function returns `true` if the CFN resource should be included in\n       * the cloudformation template unless `force` is `true`, if the policy\n       * document is empty, the resource will not be included.\n       */\n      protected shouldSynthesize() {\n        return self.force || self.referenceTaken || (!self.document.isEmpty && self.isAttached);\n      }\n    }", "language": "typescript"}
{"input": "CDK class ECSCluster for AWS resource management", "output": "class ECSCluster extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'MyVpc', { maxAzs: 2 });\n\n    const asg = new autoscaling.AutoScalingGroup(this, 'MyFleet', {\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE4_GRAVITON, ec2.InstanceSize.XLARGE),\n      machineImage: ec2.MachineImage.latestAmazonLinux2023({\n        cpuType: ec2.AmazonLinuxCpuType.ARM_64\n      }),\n      desiredCapacity: 3,\n      vpc,\n    });\n\n    const cluster = new ecs.Cluster(this, 'EcsCluster', { vpc });\n    const capacityProvider = new ecs.AsgCapacityProvider(this, 'AsgCapacityProvider', { autoScalingGroup: asg });\n    cluster.addAsgCapacityProvider(capacityProvider);\n  }\n}", "language": "typescript"}
{"input": "CDK class KinesisEventSourceTest for AWS resource management", "output": "class KinesisEventSourceTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const fn = new TestFunction(this, 'F');\n    const stream = new kinesis.Stream(this, 'Q');\n    const eventSource = new KinesisEventSource(stream, {\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      tumblingWindow: cdk.Duration.seconds(60),\n    });\n\n    fn.addEventSource(eventSource);\n\n    new cdk.CfnOutput(this, 'OutputEventSourceMappingArn', { value: eventSource.eventSourceMappingArn });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, VPC operations", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Create a portfolio\n        portfolio = sc.Portfolio(self, \"DevToolsPortfolio\", \n            display_name=\"DevTools\",\n            provider_name=\"IT\",\n        )\n\n        # Create an EC2 product from a Product Stack\n        product = sc.CloudFormationProduct(self, \"VpcEC2SampleStack\", \n            product_name=\"Ec2CdkStack\",\n            owner=\"IT\",\n            product_versions=[\n                sc.CloudFormationProductVersion(\n                    cloud_formation_template=sc.CloudFormationTemplate.from_product_stack(Ec2Product(self, \"EC2Product\")),\n                    product_version_name=\"FromProductStack\",\n                    description=\"A VPC containing an EC2 Instance\",\n                ),\n                sc.CloudFormationProductVersion(\n                    cloud_formation_template=sc.CloudFormationTemplate.from_asset(path=\"assets/ec2_vpc.json\"),\n                    product_version_name=\"FromAsset\",\n                    description=\"A VPC containing an EC2 Instance\",\n                ),\n            ],\n        )\n\n        # Add a launch template constraint\n        portfolio.constrain_cloud_formation_parameters(product,\n            rule=sc.TemplateRule(\n                rule_name=\"EC2InstanceTypes\",\n                assertions=[sc.TemplateRuleAssertion(\n                    assert_=Fn.condition_contains([\"t4g.micro\", \"t4g.small\"], Fn.ref(\"InstanceType\")),\n                    description=\"For test environment, valid instance types are t4g.micro or t4g.small\",\n                )],\n            ),\n        )\n\n        # Associate product to the portfolio\n        portfolio.add_product(product)\n\n        # Create SNS topics to listen to product events\n        stack_events_topic = sns.Topic(self, \"StackEventsTopic\")\n        # Add launch notification constraint\n        portfolio.notify_on_stack_events(product, stack_events_topic)\n\n        # Grant access to an end user\n        dev_role = iam.Role(self, \"SCRole\", \n            assumed_by=iam.AccountRootPrincipal(),\n            role_name=\"Developer\",\n        )\n        portfolio.give_access_to_role(dev_role)\n\n        # Grant access to an IAM Group\n        test_group = iam.Group(self, \"TestGroup\", \n            group_name=\"Testers\",\n        )\n        portfolio.give_access_to_group(test_group)", "language": "python"}
{"input": "CDK class ServerlessCluster for AWS resource management", "output": "export class ServerlessCluster extends ServerlessClusterNew {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.ServerlessCluster';\n\n  /**\n   * Import an existing DatabaseCluster from properties\n   */\n  public static fromServerlessClusterAttributes(\n    scope: Construct, id: string, attrs: ServerlessClusterAttributes,\n  ): IServerlessCluster {\n    return new ImportedServerlessCluster(scope, id, attrs);\n  }\n\n  public readonly clusterIdentifier: string;\n  public readonly clusterEndpoint: Endpoint;\n  public readonly clusterReadEndpoint: Endpoint;\n\n  public readonly secret?: secretsmanager.ISecret;\n\n  private readonly vpc?: ec2.IVpc;\n  private readonly vpcSubnets?: ec2.SubnetSelection;\n\n  private readonly singleUserRotationApplication: secretsmanager.SecretRotationApplication;\n  private readonly multiUserRotationApplication: secretsmanager.SecretRotationApplication;\n\n  constructor(scope: Construct, id: string, props: ServerlessClusterProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.vpc = props.vpc;\n    this.vpcSubnets = props.vpcSubnets;\n\n    this.singleUserRotationApplication = props.engine.singleUserRotationApplication;\n    this.multiUserRotationApplication = props.engine.multiUserRotationApplication;\n\n    this.enableDataApi = props.enableDataApi;\n\n    const credentials = renderCredentials(this, props.engine, props.credentials);\n    const secret = credentials.secret;\n\n    const cluster = new CfnDBCluster(this, 'Resource', {\n      ...this.newCfnProps,\n      masterUsername: credentials.username,\n      masterUserPassword: credentials.password?.unsafeUnwrap(),\n      kmsKeyId: props.storageEncryptionKey?.keyArn,\n    });\n\n    this.clusterIdentifier = cluster.ref;\n\n    // create a number token that represents the port of the cluster\n    const portAttribute = Token.asNumber(cluster.attrEndpointPort);\n    this.clusterEndpoint = new Endpoint(cluster.attrEndpointAddress, portAttribute);\n    this.clusterReadEndpoint = new Endpoint(cluster.attrReadEndpointAddress, portAttribute);\n\n    cluster.applyRemovalPolicy(props.removalPolicy ?? RemovalPolicy.SNAPSHOT);\n\n    if (secret) {\n      this.secret = secret.attach(this);\n    }\n  }\n\n  /**\n   * Adds the single user rotation of the master password to this cluster.\n   */\n  @MethodMetadata()\n  public addRotationSingleUser(options: RotationSingleUserOptions = {}): secretsmanager.SecretRotation {\n    if (!this.secret) {\n      throw new ValidationError('Cannot add single user rotation for a cluster without secret.', this);\n    }\n\n    if (this.vpc === undefined) {\n      throw new ValidationError('Cannot add single user rotation for a cluster without VPC.', this);\n    }\n\n    const id = 'RotationSingleUser';\n    const existing = this.node.tryFindChild(id);\n    if (existing) {\n      throw new ValidationError('A single user rotation was already added to this cluster.', this);\n    }\n\n    return new secretsmanager.SecretRotation(this, id, {\n      ...applyDefaultRotationOptions(options, this.vpcSubnets),\n      secret: this.secret,\n      application: this.singleUserRotationApplication,\n      vpc: this.vpc,\n      target: this,\n    });\n  }\n\n  /**\n   * Adds the multi user rotation to this cluster.\n   */\n  @MethodMetadata()\n  public addRotationMultiUser(id: string, options: RotationMultiUserOptions): secretsmanager.SecretRotation {\n    if (!this.secret) {\n      throw new ValidationError('Cannot add multi user rotation for a cluster without secret.', this);\n    }\n\n    if (this.vpc === undefined) {\n      throw new ValidationError('Cannot add multi user rotation for a cluster without VPC.', this);\n    }\n\n    return new secretsmanager.SecretRotation(this, id, {\n      ...applyDefaultRotationOptions(options, this.vpcSubnets),\n      secret: options.secret,\n      masterSecret: this.secret,\n      application: this.multiUserRotationApplication,\n      vpc: this.vpc,\n      target: this,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, IAM, SNS resources", "output": "export class Ec2CdkStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Create a portfolio\n    const portfolio = new sc.Portfolio(this, 'DevToolsPortfolio', {\n      displayName: 'DevTools',\n      providerName: 'IT',\n    });\n\n    // Create a an EC2 product from a Product Stack\n    const product = new sc.CloudFormationProduct(this, 'VpcEC2SampleStack', {\n      productName: 'Ec2CdkStack',\n      owner: 'IT',\n      productVersions: [\n        {\n          cloudFormationTemplate: sc.CloudFormationTemplate.fromProductStack(new Ec2CdkProductStack(this, 'VpcEc2Product')),\n          productVersionName: 'FromProductStack',\n          description: 'A VPC containing an EC2 Instance',\n        },\n        {\n          cloudFormationTemplate: sc.CloudFormationTemplate.fromAsset('assets/ec2_vpc.json'),\n          productVersionName: 'FromAsset',\n          description: 'A VPC containing an EC2 Instance',\n        },\n      ],\n    });\n\n    // Add a launch template constraint\n    portfolio.constrainCloudFormationParameters(product, {\n      rule: {\n        ruleName: 'EC2InstanceTypes',\n        assertions: [\n          {\n            assert: Fn.conditionContains(['t4g.micro', 't4g.small'], Fn.ref('InstanceType')),\n            description: 'For test environment, valid instance types are t4g.micro or t4g.small',\n          },\n        ],\n      }\n    });\n\n    // Associate product to the portfolio\n    portfolio.addProduct(product);\n\n    // Create SNS topics to listen to product events\n    const stackEventsTopic = new sns.Topic(this, 'StackEventsTopic');\n    // Add launch notification constraint\n    portfolio.notifyOnStackEvents(product, stackEventsTopic);\n\n    // Grant access to an end user\n    const devRole = new iam.Role(this, 'SCRole', {\n      assumedBy: new iam.AccountRootPrincipal(),\n      roleName: 'Developer',\n    });\n    portfolio.giveAccessToRole(devRole);\n\n    // Grant access to an IAM group\n    const testGroup = new iam.Group(this, 'TestGroup', {\n      groupName: 'Testers',\n    });\n    portfolio.giveAccessToGroup(testGroup);\n  }\n}", "language": "typescript"}
{"input": "CDK class S3Image for AWS resource management", "output": "class S3Image extends AgentRuntimeArtifact {\n  private bound = false;\n\n  constructor(private readonly s3Location: s3.Location, private readonly runtime: AgentCoreRuntime, private readonly entrypoint: string[]) {\n    super();\n  }\n\n  public bind(scope: Construct, runtime: Runtime): void {\n    // Handle permissions (only once)\n    if (!this.bound && runtime.role) {\n      if (!Token.isUnresolved(this.s3Location.bucketName)) {\n        Stack.of(scope).resolve(this.s3Location.bucketName);\n      }\n      const bucket = s3.Bucket.fromBucketName(\n        scope,\n        `${this.s3Location.bucketName}CodeArchive`,\n        this.s3Location.bucketName,\n      );\n      // Ensure the policy is applied before the browser resource is created\n      bucket.grantRead(runtime.role);\n      this.bound = true;\n    }\n  }\n\n  public _render(): CfnRuntime.AgentRuntimeArtifactProperty {\n    const s3Config: any = {\n      bucket: this.s3Location.bucketName,\n      prefix: this.s3Location.objectKey,\n    };\n    if (this.s3Location.objectVersion) {\n      s3Config.versionId = this.s3Location.objectVersion;\n    }\n    return {\n      code: {\n        s3: s3Config,\n      },\n      runtime: this.runtime,\n      entryPoint: this.entrypoint,\n    } as any;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, CloudWatch Logs, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    new lambda.Function(this, 'MyLambda', {\n      code: new lambda.InlineCode('foo'),\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n      logRetention: RetentionDays.ONE_DAY,\n    });\n    const logRetentionFunction = this.node.tryFindChild('LogRetentionaae0aa3c5b4d4f87b02d85b201efdd8a')!;\n    const serviceRole = logRetentionFunction.node.tryFindChild('ServiceRole') as iam.Role;\n    const defaultPolicy = serviceRole.node.tryFindChild('DefaultPolicy')!.node.defaultChild! as iam.CfnPolicy;\n    const customPolicy = new iam.CfnManagedPolicy(this, 'CustomPolicy', {\n      policyDocument: defaultPolicy.policyDocument,\n      roles: defaultPolicy.roles,\n    });\n    const logRetentionResource = logRetentionFunction.node.tryFindChild('Resource') as CfnResource;\n    // Without replacing the dependency, Cfn will reject the template because it references this non-existent logical id\n    logRetentionResource.replaceDependency(defaultPolicy, customPolicy);\n    serviceRole.node.tryRemoveChild('DefaultPolicy');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, RDS, VPC resources", "output": "class EventApiRdsStack extends cdk.Stack {\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new Vpc(this, 'Integ-VPC');\n\n    const credentialsBaseOptions: rds.CredentialsBaseOptions = {\n      secretName: 'integ-secretName-v2',\n    };\n\n    const databaseName = 'integdb';\n    const cluster = new rds.DatabaseCluster(this, 'Integ-Cluster', {\n      engine: rds.DatabaseClusterEngine.auroraPostgres({ version: rds.AuroraPostgresEngineVersion.VER_16_6 }),\n      writer: rds.ClusterInstance.serverlessV2('writer'),\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      vpc,\n      credentials: rds.Credentials.fromGeneratedSecret('clusteradmin', credentialsBaseOptions),\n      defaultDatabaseName: databaseName,\n      enableDataApi: true,\n    });\n\n    const secret = secretmanager.Secret.fromSecretNameV2(this, 'Secret', 'integ-secretName-v2');\n\n    // Create table in database\n    const schemaName = 'public';\n    const tableDefinition = 'event_id UUID PRIMARY KEY, message TEXT NOT NULL, ds_type VARCHAR(50) NOT NULL';\n    const tableName = 'events';\n\n    const createTableSql = `CREATE TABLE IF NOT EXISTS ${schemaName}.${tableName} (${tableDefinition})`;\n    const resourceId = `${cluster.clusterArn}/${databaseName}/${schemaName}/${tableName}`;\n\n    const parameters = {\n      resourceArn: cluster.clusterArn,\n      secretArn: secret.secretArn,\n      database: databaseName,\n    };\n\n    const tableResource = new cr.AwsCustomResource(this, 'PostgresTableResource', {\n      resourceType: 'Custom::PostgreSQLTable',\n      onCreate: {\n        service: 'RDSDataService',\n        action: 'executeStatement',\n        parameters: {\n          ...parameters,\n          sql: createTableSql,\n        },\n        physicalResourceId: cr.PhysicalResourceId.of(resourceId),\n      },\n      onUpdate: {\n        service: 'RDSDataService',\n        action: 'executeStatement',\n        parameters: {\n          ...parameters,\n          sql: createTableSql,\n        },\n        physicalResourceId: cr.PhysicalResourceId.of(resourceId),\n      },\n      onDelete: {\n        service: 'RDSDataService',\n        action: 'executeStatement',\n        parameters: {\n          ...parameters,\n          sql: `DROP TABLE IF EXISTS ${schemaName}.${tableName}`,\n        },\n      },\n      // Configure timeout for database operations (especially important for first connection)\n      timeout: cdk.Duration.minutes(5),\n      policy: cr.AwsCustomResourcePolicy.fromStatements([\n        new iam.PolicyStatement({\n          actions: [\n            'rds-data:ExecuteStatement',\n          ],\n          resources: [cluster.clusterArn],\n        }),\n        new iam.PolicyStatement({\n          actions: [\n            'secretsmanager:GetSecretValue',\n          ],\n          resources: [secret.secretArn],\n        }),\n      ]),\n    });\n    secret.grantRead(tableResource);\n    cluster.grantDataApiAccess(tableResource);\n    tableResource.node.addDependency(cluster);\n    tableResource.node.addDependency(secret);\n\n    const api = new appsync.EventApi(this, 'EventApiRds', {\n      apiName: 'RdsEventApi',\n    });\n\n    const dataSource = api.addRdsDataSource('rdsds', cluster, secret, databaseName);\n\n    api.addChannelNamespace('chat', {\n      code: appsync.Code.fromAsset(path.join(__dirname, 'integ-assets', 'eventapi-handlers', 'rds.js')),\n      publishHandlerConfig: {\n        dataSource: dataSource,\n      },\n    });\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: `wss://${api.realtimeDns}/event/realtime`,\n        EVENT_API_HTTP_URL: `https://${api.httpDns}/event`,\n        API_KEY: api.apiKeys.Default.attrApiKey,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets', 'eventapi-grant-assertion', 'index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.seconds(15),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'EventApiRdsTestFunction', lambdaConfig);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation resources", "output": "class CdkValidatorCfnguardStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)", "language": "python"}
{"input": "Helper class for S3-based workflow data references, containing additional permission grant methods on the S3 object", "output": "class S3WorkflowData extends WorkflowData {\n  protected readonly bucket: s3.IBucket;\n  protected readonly key: string;\n\n  protected constructor(bucket: s3.IBucket, key: string) {\n    super();\n\n    this.bucket = bucket;\n    this.key = key;\n  }\n\n  /**\n   * The rendered workflow data text, for use in CloudFormation\n   */\n  public render(): WorkflowDataConfig {\n    return { uri: this.bucket.s3UrlForObject(this.key) };\n  }\n\n  /**\n   * Grant put permissions to the given grantee for the workflow data in S3\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The principal\n   */\n  public grantPut(grantee: iam.IGrantable): iam.Grant {\n    return this.bucket.grantPut(grantee, this.key);\n  }\n\n  /**\n   * Grant read permissions to the given grantee for the workflow data in S3\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The principal\n   */\n  public grantRead(grantee: iam.IGrantable): iam.Grant {\n    return this.bucket.grantRead(grantee, this.key);\n  }\n}", "language": "typescript"}
{"input": "Templatizes grant tests across different test suites. @param withKMS whether to test for KMS policies @param keyName physical name of the KMS key to verify against", "output": "const grantTests = ({ withKMS, keyName }: { withKMS : boolean; keyName?: string }) => {\n    enum GrantType { READ = 'read', WRITE = 'write', READ_WRITE = 'read & write' }\n\n    const grantPermissions = (bucket: s3tables.TableBucket, grantType: GrantType, principal: iam.IGrantable, tableId: string) => {\n      switch (grantType) {\n        case GrantType.READ:\n          bucket.grantRead(principal, tableId);\n          return;\n        case GrantType.WRITE:\n          bucket.grantWrite(principal, tableId);\n          return;\n        case GrantType.READ_WRITE:\n          bucket.grantReadWrite(principal, tableId);\n      }\n    };\n\n    interface TestCase {\n      category: string;\n      grantType: GrantType;\n      actions: string | string[];\n      keyActions: string | string[];\n    }\n\n    const testCases: TestCase[] = [\n      {\n        category: 'grantRead',\n        grantType: GrantType.READ,\n        actions: stringIfSingle(perms.TABLE_BUCKET_READ_ACCESS),\n        keyActions: stringIfSingle(perms.KEY_READ_ACCESS),\n      },\n      {\n        category: 'grantWrite',\n        grantType: GrantType.WRITE,\n        actions: stringIfSingle(perms.TABLE_BUCKET_WRITE_ACCESS),\n        keyActions: stringIfSingle(perms.KEY_WRITE_ACCESS),\n      },\n      {\n        category: 'grantReadWrite',\n        grantType: GrantType.READ_WRITE,\n        actions: stringIfSingle(perms.TABLE_BUCKET_READ_WRITE_ACCESS),\n        keyActions: stringIfSingle(perms.KEY_READ_WRITE_ACCESS),\n      },\n    ];\n\n    testCases.forEach(({ category, grantType, actions, keyActions }) => {\n      describe(category, () => {\n        const verifyKeyPolicies = () => {\n          if (withKMS) {\n            Template.fromStack(stack).hasResourceProperties(KMS_KEY_CFN_RESOURCE, {\n              'KeyPolicy': {\n                'Statement': Match.arrayWith([\n                  {\n                    'Action': keyActions,\n                    'Effect': 'Allow',\n                    'Principal': {\n                      'Service': PRINCIPAL,\n                    },\n                    'Resource': '*',\n                  },\n                ]),\n              },\n            });\n          }\n        };\n\n        it(`provides ${grantType} permissions to the bucket ${withKMS && 'and key'}`, () => {\n          grantPermissions(tableBucket, grantType, new iam.ServicePrincipal(PRINCIPAL), '*');\n          Template.fromStack(stack).hasResourceProperties(TABLE_BUCKET_POLICY_CFN_RESOURCE, {\n            'ResourcePolicy': {\n              'Statement': [\n                {\n                  'Action': actions,\n                  'Effect': 'Allow',\n                  'Principal': {\n                    'Service': PRINCIPAL,\n                  },\n                  'Resource': RESOURCES_WITH_WILDCARD,\n                },\n              ],\n            },\n          });\n          verifyKeyPolicies();\n        });\n\n        it(`provides ${grantType} permissions for a specific table ${withKMS && 'and key'}`, () => {\n          grantPermissions(tableBucket, grantType, new iam.ServicePrincipal(PRINCIPAL), TABLE_UUID);\n          Template.fromStack(stack).hasResourceProperties(TABLE_BUCKET_POLICY_CFN_RESOURCE, {\n            'ResourcePolicy': {\n              'Statement': [\n                {\n                  'Action': actions,\n                  'Effect': 'Allow',\n                  'Principal': {\n                    'Service': PRINCIPAL,\n                  },\n                  'Resource': RESOURCES_WITH_TABLE_ARN,\n                },\n              ],\n            },\n          });\n          verifyKeyPolicies();\n        });\n\n        const expectedStatements : any = [{\n          'Action': actions,\n          'Effect': 'Allow',\n          'Resource': RESOURCES_WITH_TABLE_ARN,\n        }];\n        if (withKMS) {\n          expectedStatements.push({\n            'Action': keyActions,\n            'Effect': 'Allow',\n            'Resource': { 'Fn::GetAtt': [keyName, 'Arn'] },\n          });\n        }\n\n        it(`creates ${grantType} IAM policies for a role ${withKMS && 'and key'}`, () => {\n          grantPermissions(tableBucket, grantType, role, TABLE_UUID);\n          Template.fromStack(stack).hasResourceProperties('AWS::IAM::Policy', {\n            'PolicyDocument': {\n              'Statement': expectedStatements,\n              'Version': '2012-10-17',\n            },\n          });\n          Template.fromStack(stack).resourceCountIs(TABLE_BUCKET_POLICY_CFN_RESOURCE, 0);\n        });\n\n        it(`creates ${grantType} IAM policies for a user ${withKMS && 'and key'}`, () => {\n          grantPermissions(tableBucket, grantType, user, TABLE_UUID);\n          Template.fromStack(stack).hasResourceProperties('AWS::IAM::Policy', {\n            'PolicyDocument': {\n              'Statement': expectedStatements,\n              'Version': '2012-10-17',\n            },\n          });\n          Template.fromStack(stack).resourceCountIs(TABLE_BUCKET_POLICY_CFN_RESOURCE, 0);\n        });\n\n        it(`creates ${grantType} IAM policies for an imported role ${withKMS && 'and key'}`, () => {\n          grantPermissions(tableBucket, grantType, importedRole, TABLE_UUID);\n          Template.fromStack(stack).hasResourceProperties('AWS::IAM::Policy', {\n            'PolicyDocument': {\n              'Statement': expectedStatements,\n              'Version': '2012-10-17',\n            },\n          });\n          Template.fromStack(stack).hasResourceProperties(TABLE_BUCKET_POLICY_CFN_RESOURCE, {\n            'ResourcePolicy': {\n              'Statement': [\n                {\n                  'Action': actions,\n                  'Effect': 'Allow',\n                  'Principal': {\n                    'AWS': EXISTING_ROLE_ARN,\n                  },\n                  'Resource': RESOURCES_WITH_TABLE_ARN,\n                },\n              ],\n            },\n          });\n        });\n      });\n    });\n  }", "language": "typescript"}
{"input": "Defines an action for an extension.", "output": "export class Action {\n  /**\n   * The action points that will trigger the extension action.\n   */\n  public readonly actionPoints: ActionPoint[];\n\n  /**\n   * The event destination for the action.\n   */\n  public readonly eventDestination: IEventDestination;\n\n  /**\n   * The name for the action.\n   */\n  public readonly name?: string;\n\n  /**\n   * The execution role for the action.\n   */\n  public readonly executionRole?: iam.IRole;\n\n  /**\n   * The description for the action.\n   */\n  public readonly description?: string;\n\n  /**\n   * The flag that specifies whether to create the execution role.\n   */\n  readonly invokeWithoutExecutionRole?: boolean;\n\n  public constructor(props: ActionProps) {\n    this.actionPoints = props.actionPoints;\n    this.eventDestination = props.eventDestination;\n    this.name = props.name;\n    this.executionRole = props.executionRole;\n    this.description = props.description;\n    this.invokeWithoutExecutionRole = props.invokeWithoutExecutionRole || false;\n  }\n}", "language": "typescript"}
{"input": "CDK class FargateServiceWithEfs for AWS resource management", "output": "class FargateServiceWithEfs(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, *kwargs)\n\n        PREFIX      = 'efs-sample-'\n        APP_PATH    = '/var/www/'\n        VOLUME_NAME = 'cdk-ecs-sample-efs-volume'\n\n        vpc = ec2.Vpc(\n            self, PREFIX + 'Vpc',\n            max_azs=2\n        )\n\n        ecs_cluster = ecs.Cluster(\n            self, PREFIX + 'Cluster',\n            vpc=vpc,\n        )\n\n        # Create an Amazon Elastic File System (EFS), with the logical ID CDK-efs-sample-EFS\n        file_system = efs.FileSystem(\n            self, PREFIX + 'EFS',\n            vpc=vpc,\n            lifecycle_policy=efs.LifecyclePolicy.AFTER_14_DAYS,\n            performance_mode=efs.PerformanceMode.GENERAL_PURPOSE,\n        )\n\n        # Create an Access Point for the EFS, with the logical ID CDK-efs-sample-AccessPoint\n        access_point = efs.AccessPoint(\n            self, PREFIX + 'AccessPoint',\n            file_system=file_system,\n        )\n\n        # Create a new EFS volume configuration for the ECS Task\n        efs_volume_configuration = ecs.EfsVolumeConfiguration(\n            file_system_id=file_system.file_system_id,\n\n            # The logical ID of the Access Point to use.\n            # This is a string, not an ARN.\n            authorization_config=ecs.AuthorizationConfig(\n                access_point_id=access_point.access_point_id,\n                iam='ENABLED',\n            ),\n            transit_encryption='ENABLED',\n        )\n\n        # Create a new IAM Role for the ECS Task\n        task_role = iam.Role (\n            self, PREFIX + 'EcsTaskRole',\n            assumed_by=iam.ServicePrincipal('ecs-tasks.amazonaws.com').with_conditions({\n                \"StringEquals\": {\n                    \"aws:SourceAccount\": Stack.of(self).account\n                },\n                \"ArnLike\":{\n                    \"aws:SourceArn\":\"arn:aws:ecs:\" + Stack.of(self).region + \":\" + Stack.of(self).account + \":*\"\n                },\n            }),\n        )\n\n        # Attach a managed policy to the IAM Role\n        task_role.attach_inline_policy(\n            iam.Policy(self, PREFIX +'Policy',\n                statements=[\n                    iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        resources=['*'],\n                        actions=[\n                            \"ecr:GetAuthorizationToken\",\n                            \"ec2:DescribeAvailabilityZones\"\n                        ]\n                    ),\n                    iam.PolicyStatement(\n                        sid='AllowEfsAccess',\n                        effect=iam.Effect.ALLOW,\n                        resources=['*'],\n                        actions=[\n                            'elasticfilesystem:ClientRootAccess',\n                            'elasticfilesystem:ClientWrite',\n                            'elasticfilesystem:ClientMount',\n                            'elasticfilesystem:DescribeMountTargets'\n                        ]\n                    )\n                ]\n            )\n        )\n\n        # Create a new Fargate Task Definition\n        task_definition = ecs.FargateTaskDefinition(\n            self, PREFIX + 'FargateTaskDef',\n            task_role=task_role,\n        )\n\n        # Add a new volume to the Fargate Task Definition\n        task_definition.add_volume(\n            name=VOLUME_NAME,\n            efs_volume_configuration=efs_volume_configuration,\n        )\n\n        # Add a new container to the Fargate Task Definition\n        mount_point = ecs.MountPoint(\n            container_path=APP_PATH+VOLUME_NAME,\n            source_volume=VOLUME_NAME,\n            read_only=False,\n        )\n\n        # Add a new port mapping to the Fargate Task Definition\n        port_mapping = ecs.PortMapping(\n            container_port=80,\n            host_port=80,\n            protocol=ecs.Protocol.TCP,\n        )\n\n        # Add a new container to the Fargate Task Definition\n        container = ecs.ContainerDefinition(\n            self, 'ecs-cdk-sample-container',\n            task_definition=task_definition,\n            image=ecs.ContainerImage.from_registry('amazon/amazon-ecs-sample'),\n            logging=ecs.LogDrivers.aws_logs(\n                stream_prefix='cdk-ecs-sample', \n                log_retention=logs.RetentionDays.ONE_MONTH,\n            )\n        )\n\n        # Add a new volume to the Fargate Task Definition\n        container.add_mount_points(mount_point),\n\n        # Add a new port mapping to the Fargate Task Definition\n        container.add_port_mappings(port_mapping),\n\n        # Create a new Fargate Service with ALB\n        fargate_service = ecs_patterns.ApplicationLoadBalancedFargateService(\n            self, PREFIX + 'Service',\n            cluster=ecs_cluster,\n            desired_count=1,\n            task_definition=task_definition,\n            task_subnets=ec2.SubnetSelection(\n                subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS,\n            ),\n            platform_version=ecs.FargatePlatformVersion.LATEST,\n            public_load_balancer=True,\n            enable_execute_command=True,\n            enable_ecs_managed_tags=True,\n\n        )\n\n        # Allow the ECS Service to connect to the EFS\n        fargate_service.service.connections.allow_from(file_system, ec2.Port.tcp(2049)),\n\n        # Allow the EFS to connect to the ECS Service\n        fargate_service.service.connections.allow_to(file_system, ec2.Port.tcp(2049)),\n\n        # Create a new Auto Scaling Policy for the ECS Service\n        scalable_target = fargate_service.service.auto_scale_task_count(\n            min_capacity=1,\n            max_capacity=20,\n        )\n\n        # Create a new Auto Scaling Policy for the ECS Service\n        scalable_target.scale_on_cpu_utilization(\"CpuScaling\",\n            target_utilization_percent=50,\n        )\n\n        # Create a new Auto Scaling Policy for the ECS Service\n        scalable_target.scale_on_memory_utilization(\"MemoryScaling\",\n            target_utilization_percent=50,\n        )", "language": "python"}
{"input": "CDK class PySparkStreamingJob for AWS resource management", "output": "export class PySparkStreamingJob extends SparkJob {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.PySparkStreamingJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n\n  /**\n   * PySparkStreamingJob constructor\n   */\n  constructor(scope: Construct, id: string, props: PySparkStreamingJobProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...this.executableArguments(props),\n      ...this.nonExecutableCommonArguments(props),\n    };\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.STREAMING,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n        pythonVersion: PythonVersion.THREE,\n      },\n      glueVersion: props.glueVersion ? props.glueVersion : GlueVersion.V4_0,\n      workerType: props.workerType ? props.workerType : WorkerType.G_1X,\n      numberOfWorkers: props.numberOfWorkers ? props.numberOfWorkers : 10,\n      maxRetries: props.jobRunQueuingEnabled ? 0 : props.maxRetries,\n      jobRunQueuingEnabled: props.jobRunQueuingEnabled ? props.jobRunQueuingEnabled : false,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      defaultArguments,\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n\n  /**\n   * Set the executable arguments with best practices enabled by default\n   *\n   * @returns An array of arguments for Glue to use on execution\n   */\n  private executableArguments(props: PySparkStreamingJobProps) {\n    const args: { [key: string]: string } = {};\n    args['--job-language'] = JobLanguage.PYTHON;\n    this.setupExtraCodeArguments(args, props);\n    return args;\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedVpc for AWS resource management", "output": "class ImportedVpc extends VpcBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.ImportedVpc';\n  public readonly vpcId: string;\n  public readonly vpcArn: string;\n  public readonly publicSubnets: ISubnet[];\n  public readonly privateSubnets: ISubnet[];\n  public readonly isolatedSubnets: ISubnet[];\n  public readonly availabilityZones: string[];\n  public readonly internetConnectivityEstablished: IDependable = new DependencyGroup();\n  private readonly cidr?: string | undefined;\n\n  constructor(scope: Construct, id: string, props: VpcAttributes, isIncomplete: boolean) {\n    super(scope, id, {\n      region: props.region,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.vpcId = props.vpcId;\n    this.vpcArn = Arn.format({\n      service: 'ec2',\n      resource: 'vpc',\n      resourceName: this.vpcId,\n    }, Stack.of(this));\n    this.cidr = props.vpcCidrBlock;\n    this.availabilityZones = props.availabilityZones;\n    this._vpnGatewayId = props.vpnGatewayId;\n    this.incompleteSubnetDefinition = isIncomplete;\n\n    // None of the values may be unresolved list tokens\n    for (const k of Object.keys(props) as Array<keyof VpcAttributes>) {\n      if (Array.isArray(props[k]) && Token.isUnresolved(props[k])) {\n        Annotations.of(this).addWarningV2(`@aws-cdk/aws-ec2:vpcAttributeIsListToken${k}`, `fromVpcAttributes: '${k}' is a list token: the imported VPC will not work with constructs that require a list of subnets at synthesis time. Use 'Vpc.fromLookup()' or 'Fn.importListValue' instead.`);\n      }\n    }\n\n    const pub = new ImportSubnetGroup(props.publicSubnetIds, props.publicSubnetNames, props.publicSubnetRouteTableIds, props.publicSubnetIpv4CidrBlocks, SubnetType.PUBLIC, this.availabilityZones, 'publicSubnetIds', 'publicSubnetNames', 'publicSubnetRouteTableIds', 'publicSubnetIpv4CidrBlocks');\n    const priv = new ImportSubnetGroup(props.privateSubnetIds, props.privateSubnetNames, props.privateSubnetRouteTableIds, props.privateSubnetIpv4CidrBlocks, SubnetType.PRIVATE_WITH_EGRESS, this.availabilityZones, 'privateSubnetIds', 'privateSubnetNames', 'privateSubnetRouteTableIds', 'privateSubnetIpv4CidrBlocks');\n    const iso = new ImportSubnetGroup(props.isolatedSubnetIds, props.isolatedSubnetNames, props.isolatedSubnetRouteTableIds, props.isolatedSubnetIpv4CidrBlocks, SubnetType.PRIVATE_ISOLATED, this.availabilityZones, 'isolatedSubnetIds', 'isolatedSubnetNames', 'isolatedSubnetRouteTableIds', 'isolatedSubnetIpv4CidrBlocks');\n\n    this.publicSubnets = pub.import(this);\n    this.privateSubnets = priv.import(this);\n    this.isolatedSubnets = iso.import(this);\n  }\n\n  public get vpcCidrBlock(): string {\n    if (this.cidr === undefined) {\n      throw new ValidationError('Cannot perform this operation: \\'vpcCidrBlock\\' was not supplied when creating this VPC', this);\n    }\n    return this.cidr;\n  }\n}", "language": "typescript"}
{"input": "CDK class EcrImage for AWS resource management", "output": "class EcrImage extends ContainerImage {\n  constructor(private readonly repository: ecr.IRepository, private readonly tag: string) {\n    super();\n  }\n\n  public bind(_scope: Construct, model: Model): ContainerImageConfig {\n    this.repository.grantPull(model);\n\n    return {\n      imageName: this.repository.repositoryUriForTag(this.tag),\n    };\n  }\n}", "language": "typescript"}
{"input": "A SAML metadata document", "output": "class SamlMetadataDocument {\n  /**\n   * Create a SAML metadata document from a XML string\n   */\n  public static fromXml(xml: string): SamlMetadataDocument {\n    return { xml };\n  }\n\n  /**\n   * Create a SAML metadata document from a XML file\n   */\n  public static fromFile(path: string): SamlMetadataDocument {\n    return { xml: fs.readFileSync(path, 'utf-8') };\n  }\n\n  /**\n   * The XML content of the metadata document\n   */\n  public abstract readonly xml: string;\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, Cognito, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Adding required resources per https://docs.aws.amazon.com/opensearch-service/latest/developerguide/cognito-auth.html#cognito-auth-config\n    const identityPool = new cognito.CfnIdentityPool(this, 'IdentityPool', {\n      allowUnauthenticatedIdentities: true,\n    });\n\n    const userPool = new cognito.UserPool(this, 'UserPool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    userPool.addDomain('UserPoolDomain', {\n      cognitoDomain: {\n        domainPrefix: 'integ-test-domain-prefix',\n      },\n    });\n\n    const role = new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('opensearchservice.amazonaws.com'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonOpenSearchServiceCognitoAccess'),\n      ],\n    });\n\n    // Adding a domain with cognito dashboards auth configured\n    new opensearch.Domain(this, 'Domain', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      version: opensearch.EngineVersion.OPENSEARCH_1_0,\n      cognitoDashboardsAuth: {\n        role,\n        identityPoolId: identityPool.ref,\n        userPoolId: userPool.userPoolId,\n      },\n      capacity: {\n        multiAzWithStandbyEnabled: false,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Target for a client VPN route", "output": "class ClientVpnRouteTarget {\n  /**\n   * Subnet\n   *\n   * The specified subnet must be an existing target network of the client VPN\n   * endpoint.\n   */\n  public static subnet(subnet: ISubnetRef): ClientVpnRouteTarget {\n    return { subnetId: subnet.subnetRef.subnetId };\n  }\n\n  /**\n   * Local network\n   */\n  public static local(): ClientVpnRouteTarget {\n    return { subnetId: 'local' };\n  }\n\n  /** The subnet ID */\n  public abstract readonly subnetId: string;\n}", "language": "typescript"}
{"input": "Define a QueryString", "output": "export class QueryString {\n  private readonly fields?: string[];\n  private readonly parse: string[];\n  private readonly filter: string[];\n  private readonly stats: string[];\n  private readonly sort?: string;\n  private readonly limit?: Number;\n  private readonly display?: string;\n\n  /**\n   * Length of statsStatements\n   */\n  public readonly statsStatementsLength?: number;\n  /**\n   * If the props for the query string have both stats and statsStatements\n   */\n  public readonly hasStatsAndStatsStatements: boolean;\n\n  constructor(props: QueryStringProps = {}) {\n    this.fields = props.fields;\n    this.sort = props.sort;\n    this.limit = props.limit;\n    this.display = props.display;\n    this.statsStatementsLength = props.statsStatements?.length;\n    this.hasStatsAndStatsStatements = !!(props.statsStatements && props.stats);\n\n    // Determine parsing by either the parseStatements or parse properties, or default to empty array\n    if (props.parseStatements) {\n      this.parse = props.parseStatements;\n    } else if (props.parse) {\n      this.parse = [props.parse];\n    } else {\n      this.parse = [];\n    }\n\n    // Determine filtering by either the filterStatements or filter properties, or default to empty array\n    if (props.filterStatements) {\n      this.filter = props.filterStatements;\n    } else if (props.filter) {\n      this.filter = [props.filter];\n    } else {\n      this.filter = [];\n    }\n\n    if (props.statsStatements) {\n      this.stats = props.statsStatements;\n    } else if (props.stats) {\n      this.stats = [props.stats];\n    } else {\n      this.stats = [];\n    }\n  }\n\n  /**\n   * String representation of this QueryString.\n   */\n  public toString(): string {\n    return [\n      this.buildQueryLine('fields', this.fields?.join(', ')),\n      ...this.buildQueryLines('parse', this.parse),\n      ...this.buildQueryLines('filter', this.filter),\n      ...this.buildQueryLines('stats', this.stats),\n      this.buildQueryLine('sort', this.sort),\n      this.buildQueryLine('limit', this.limit?.toString()),\n      this.buildQueryLine('display', this.display),\n    ].filter(\n      (queryLine) => queryLine !== undefined && queryLine.length > 0,\n    ).join('\\n| ');\n  }\n\n  /**\n   * Build an array of query lines given a command and statement(s).\n   *\n   * @param command a query command\n   * @param statements one or more query statements for the specified command, or undefined\n   * @returns an array of the query string lines generated from the provided command and statements\n   */\n  private buildQueryLines(command: string, statements?: string[]): string[] {\n    if (statements === undefined) {\n      return [];\n    }\n\n    return statements.map(\n      (statement: string): string => this.buildQueryLine(command, statement),\n    );\n  }\n\n  /**\n   * Build a single query line given a command and statement.\n   *\n   * @param command a query command\n   * @param statement a single query statement\n   * @returns a single query string line generated from the provided command and statement\n   */\n  private buildQueryLine(command: string, statement?: string): string {\n    return statement ? `${command} ${statement}` : '';\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, DynamoDB, IAM resources", "output": "export class ApiGatewayAsyncLambdaStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: Properties) {\n    super(scope, id, props);\n\n    // DynamoDB table for job status\n    const jobTable = new Table(this, `${props.prefix}-table`, {\n      partitionKey: { name: 'jobId', type: AttributeType.STRING },\n      tableName: `${props.prefix}-job-table`,\n      removalPolicy: cdk.RemovalPolicy.DESTROY, // NOT recommended for production; Set `cdk.RemovalPolicy.RETAIN` for production\n    });\n\n    // Create a Log Group for API Gateway logs\n    const fnLogGroup = new LogGroup(this, `${props.prefix}-fn-log-group`, {\n      retention: RetentionDays.ONE_WEEK, // Customize the retention period as needed\n    });\n\n    //  create a lambda function\n    const jobHandler = new Function(this, `${props.prefix}-fn`, {\n      runtime: Runtime.NODEJS_20_X,\n      handler: 'job_handler.handler',\n      code: Code.fromAsset(path.join(__dirname, '../assets/lambda-functions')),\n      environment: {\n        JOB_TABLE: jobTable.tableName,\n      },\n      logGroup:     fnLogGroup,\n    });\n    // Grant Lambda permission to write to DynamoDB\n    jobTable.grantWriteData(jobHandler);\n\n    // Create a Log Group for API Gateway logs\n    const apiLogGroup = new LogGroup(this, `${props.prefix}-apigw-log-group`, {\n      retention: RetentionDays.ONE_WEEK, // Customize the retention period as needed\n    });\n\n    // API Gateway: Create a REST API with Lambda integration for POST /job\n    const api = new LambdaRestApi(this, `${props.prefix}-apigw`, {\n      restApiName:    `${props.prefix}-job-service`,\n      handler:        jobHandler,\n      proxy:          false,\n      cloudWatchRole: true,\n      deployOptions: {\n        metricsEnabled:   true,\n        dataTraceEnabled: true,\n        accessLogDestination: new LogGroupLogDestination(apiLogGroup),\n        accessLogFormat: AccessLogFormat.jsonWithStandardFields(),\n        loggingLevel:    MethodLoggingLevel.ERROR,\n      }\n    });\n\n    // POST /job method (Lambda integration)\n    const job = api.root.addResource('job')\n\n    // POST /job method with asynchronous invocation\n    job.addMethod(\"POST\", \n      new LambdaIntegration(jobHandler,{\n        proxy:false,\n        requestParameters:{\n          'integration.request.header.X-Amz-Invocation-Type': \"'Event'\",\n        },\n        requestTemplates: {\n          'application/json': `{\n            \"jobId\": \"$context.requestId\",\n            \"body\": $input.json('$')\n          }`,    \n        },\n        integrationResponses: [\n          {\n            statusCode: '200',\n            responseTemplates: {\n              'application/json': `{\"jobId\": \"$context.requestId\"}`\n            }\n          },\n          {\n            statusCode: '500',\n            responseTemplates: {\n              'application/json': `{\n                \"error\": \"An error occurred while processing the request.\",\n                \"details\": \"$context.integrationErrorMessage\"\n              }`\n            }\n          }\n        ]\n    }),\n  {\n    methodResponses: [\n      {\n        statusCode: '200',\n      },\n      {\n        statusCode: '500',\n      }\n    ]\n  }\n  );\n\n    // GET method to check the status of a job by jobId (direct DynamoDB integration)\n    const jobId = job.addResource('{jobId}');\n    jobId.addMethod(\"GET\",\n      new AwsIntegration({\n        service: 'dynamodb',\n        action:  'GetItem',\n        options: {\n          credentialsRole: new Role(this, 'ApiGatewayDynamoRole',{\n            assumedBy: new ServicePrincipal('apigateway.amazonaws.com'),\n            inlinePolicies: {\n              dynamoPolicy: new PolicyDocument({\n                statements: [\n                  new PolicyStatement({\n                    actions: ['dynamodb:GetItem'],\n                    resources: [jobTable.tableArn],\n                  }),\n                ],\n              })\n            }\n          }),\n          requestTemplates: {\n            'application/json': `{\n              \"TableName\": \"${jobTable.tableName}\",\n              \"Key\": {\n                \"jobId\": {\n                  \"S\": \"$input.params('jobId')\"\n                }\n              }\n            }`,  \n          },\n          integrationResponses: [{\n            statusCode: '200',\n            responseTemplates: {\n              'application/json': `{\n                \"jobId\": \"$input.path('$.Item.jobId.S')\",\n                \"status\": \"$input.path('$.Item.status.S')\",\n                \"createdAt\": \"$input.path('$.Item.createdAt.S')\"\n              }`\n            }\n          },\n          {\n            statusCode: '404',\n            selectionPattern: '.*\"Item\":null.*',\n            responseTemplates: {\n              'application/json': '{\"error\": \"Job not found\"}'\n            }\n          }\n        ]\n      }\n    }),\n    {\n      methodResponses:[\n        {\n          statusCode: '200'\n        },\n        {\n          statusCode: '404'\n        }\n      ]\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderAmazon for AWS resource management", "output": "export class UserPoolIdentityProviderAmazon extends UserPoolIdentityProviderBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderAmazon';\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderAmazonProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const scopes = props.scopes ?? ['profile'];\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: 'LoginWithAmazon', // must be 'LoginWithAmazon' when the type is 'LoginWithAmazon'\n      providerType: 'LoginWithAmazon',\n      providerDetails: {\n        client_id: props.clientId,\n        client_secret: props.clientSecret,\n        authorize_scopes: scopes.join(' '),\n      },\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n}", "language": "typescript"}
{"input": "CDK class GameSessionQueue for AWS resource management", "output": "export class GameSessionQueue extends GameSessionQueueBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-gamelift-alpha.GameSessionQueue';\n\n  /**\n   * Import an existing gameSessionQueue from its name.\n   */\n  static fromGameSessionQueueName(scope: Construct, id: string, gameSessionQueueName: string): IGameSessionQueue {\n    return this.fromGameSessionQueueAttributes(scope, id, { gameSessionQueueName });\n  }\n\n  /**\n   * Import an existing gameSessionQueue from its ARN.\n   */\n  static fromGameSessionQueueArn(scope: Construct, id: string, gameSessionQueueArn: string): IGameSessionQueue {\n    return this.fromGameSessionQueueAttributes(scope, id, { gameSessionQueueArn });\n  }\n\n  /**\n   * Import an existing gameSessionQueue from its attributes.\n   */\n  static fromGameSessionQueueAttributes(scope: Construct, id: string, attrs: GameSessionQueueAttributes): IGameSessionQueue {\n    if (!attrs.gameSessionQueueName && !attrs.gameSessionQueueArn) {\n      throw new Error('Either gameSessionQueueName or gameSessionQueueArn must be provided in GameSessionQueueAttributes');\n    }\n    const gameSessionQueueName = attrs.gameSessionQueueName ??\n      cdk.Stack.of(scope).splitArn(attrs.gameSessionQueueArn!, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n\n    if (!gameSessionQueueName) {\n      throw new Error(`No gameSessionQueue name found in ARN: '${attrs.gameSessionQueueArn}'`);\n    }\n\n    const gameSessionQueueArn = attrs.gameSessionQueueArn ?? cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'gamesessionqueue',\n      resourceName: attrs.gameSessionQueueName,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n    class Import extends GameSessionQueueBase {\n      public readonly gameSessionQueueName = gameSessionQueueName!;\n      public readonly gameSessionQueueArn = gameSessionQueueArn;\n\n      constructor(s: Construct, i: string) {\n        super(s, i, {\n          environmentFromArn: gameSessionQueueArn,\n        });\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * The Identifier of the gameSessionQueue.\n   */\n  public readonly gameSessionQueueName: string;\n\n  /**\n   * The ARN of the gameSessionQueue.\n   */\n  public readonly gameSessionQueueArn: string;\n\n  private readonly destinations: IGameSessionQueueDestination[] = [];\n\n  constructor(scope: Construct, id: string, props: GameSessionQueueProps) {\n    super(scope, id, {\n      physicalName: props.gameSessionQueueName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (!cdk.Token.isUnresolved(props.gameSessionQueueName)) {\n      if (props.gameSessionQueueName.length > 128) {\n        throw new Error(`GameSessionQueue name can not be longer than 128 characters but has ${props.gameSessionQueueName.length} characters.`);\n      }\n\n      if (!/^[a-zA-Z0-9-]+$/.test(props.gameSessionQueueName)) {\n        throw new Error(`GameSessionQueue name ${props.gameSessionQueueName} can contain only letters, numbers, hyphens with no spaces.`);\n      }\n    }\n\n    if (props.customEventData && props.customEventData.length > 256) {\n      throw new Error(`GameSessionQueue custom event data can not be longer than 256 characters but has ${props.customEventData.length} characters.`);\n    }\n\n    if (props.allowedLocations && props.allowedLocations.length > 100) {\n      throw new Error(`No more than 100 allowed locations are allowed per game session queue, given ${props.allowedLocations.length}`);\n    }\n\n    // Add all destinations\n    (props.destinations || []).forEach(this.addDestination.bind(this));\n\n    const resource = new CfnGameSessionQueue(this, 'Resource', {\n      name: this.physicalName,\n      customEventData: props.customEventData,\n      destinations: cdk.Lazy.any({ produce: () => this.parseDestinations() }),\n      filterConfiguration: this.parseFilterConfiguration(props),\n      notificationTarget: props.notificationTarget && props.notificationTarget.topicArn,\n      playerLatencyPolicies: this.parsePlayerLatencyPolicies(props),\n      priorityConfiguration: this.parsePriorityConfiguration(props),\n      timeoutInSeconds: props.timeout && props.timeout.toSeconds(),\n    });\n\n    this.gameSessionQueueName = this.getResourceNameAttribute(resource.ref);\n    this.gameSessionQueueArn = cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'gamesessionqueue',\n      resourceName: this.gameSessionQueueName,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n  }\n\n  /**\n   * Adds a destination to fulfill requests for new game sessions\n   *\n   * @param destination A destination to add\n   */\n  @MethodMetadata()\n  public addDestination(destination: IGameSessionQueueDestination) {\n    this.destinations.push(destination);\n  }\n\n  protected parsePriorityConfiguration(props: GameSessionQueueProps): CfnGameSessionQueue.PriorityConfigurationProperty | undefined {\n    if (!props.priorityConfiguration) {\n      return undefined;\n    }\n\n    if (props.priorityConfiguration.locationOrder.length > 100) {\n      throw new Error(`No more than 100 locations are allowed per priority configuration, given ${props.priorityConfiguration.locationOrder.length}`);\n    }\n\n    if (props.priorityConfiguration.priorityOrder.length > 4) {\n      throw new Error(`No more than 4 priorities are allowed per priority configuration, given ${props.priorityConfiguration.priorityOrder.length}`);\n    }\n\n    return {\n      priorityOrder: props.priorityConfiguration.priorityOrder,\n      locationOrder: props.priorityConfiguration.locationOrder,\n    };\n  }\n\n  protected parsePlayerLatencyPolicies(props: GameSessionQueueProps): CfnGameSessionQueue.PlayerLatencyPolicyProperty[] | undefined {\n    if (!props.playerLatencyPolicies) {\n      return undefined;\n    }\n\n    return props.playerLatencyPolicies.map(parsePlayerLatencyPolicy);\n\n    function parsePlayerLatencyPolicy(playerLatencyPolicy: PlayerLatencyPolicy): CfnGameSessionQueue.PlayerLatencyPolicyProperty {\n      return {\n        maximumIndividualPlayerLatencyMilliseconds: playerLatencyPolicy.maximumIndividualPlayerLatency.toMilliseconds(),\n        policyDurationSeconds: playerLatencyPolicy.policyDuration && playerLatencyPolicy.policyDuration.toSeconds(),\n      };\n    }\n  }\n\n  protected parseFilterConfiguration(props: GameSessionQueueProps): CfnGameSessionQueue.FilterConfigurationProperty | undefined {\n    if (!props.allowedLocations) {\n      return undefined;\n    }\n\n    return {\n      allowedLocations: props.allowedLocations,\n    };\n  }\n\n  private parseDestinations(): CfnGameSessionQueue.DestinationProperty[] | undefined {\n    if (!this.destinations || this.destinations.length === 0) {\n      return undefined;\n    }\n\n    return this.destinations.map(parseDestination);\n\n    function parseDestination(destination: IGameSessionQueueDestination): CfnGameSessionQueue.DestinationProperty {\n      return {\n        destinationArn: destination.resourceArnForDestination,\n      };\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class PythonFunction for AWS resource management", "output": "export class PythonFunction extends Function {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-lambda-python-alpha.PythonFunction';\n\n  constructor(scope: Construct, id: string, props: PythonFunctionProps) {\n    const { index = 'index.py', handler = 'handler', runtime } = props;\n    if (props.index && !/\\.py$/.test(props.index)) {\n      throw new Error('Only Python (.py) index files are supported.');\n    }\n\n    // Entry\n    const entry = path.resolve(props.entry);\n    const resolvedIndex = path.resolve(entry, index);\n    if (!fs.existsSync(resolvedIndex)) {\n      throw new Error(`Cannot find index file at ${resolvedIndex}`);\n    }\n\n    const resolvedHandler = `${index.slice(0, -3)}.${handler}`.replace(/\\//g, '.');\n\n    if (props.runtime && props.runtime.family !== RuntimeFamily.PYTHON) {\n      throw new Error('Only `PYTHON` runtimes are supported.');\n    }\n\n    super(scope, id, {\n      ...props,\n      runtime,\n      code: Bundling.bundle({\n        entry,\n        runtime,\n        skip: !Stack.of(scope).bundlingRequired,\n        // define architecture based on the target architecture of the function, possibly overridden in bundling options\n        architecture: props.architecture,\n        ...props.bundling,\n      }),\n      handler: resolvedHandler,\n    });\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedUserPool for AWS resource management", "output": "class ImportedUserPool extends UserPoolBase {\n      public readonly userPoolArn = userPoolArn;\n      public readonly userPoolId = userPoolId;\n      public readonly userPoolProviderName = providerName;\n\n      constructor() {\n        super(scope, id, {\n          account: arnParts.account,\n          region: arnParts.region,\n        });\n      }\n    }", "language": "typescript"}
{"input": "This test can only be run as a dry-run at this time due to requiring a certificate", "output": "class CognitoStack extends Stack {\n  public readonly userPool: cognito.UserPool;\n\n  constructor(scope: Construct, id: string, props: CognitoStackProps) {\n    super(scope, id);\n\n    const vpc = new ec2.Vpc(this, 'Stack', {\n      maxAzs: 2, restrictDefaultSecurityGroup: false,\n    });\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n    const certificate = new acm.Certificate(this, 'Certificate', {\n      domainName: props.domainName,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    const lb = new elbv2.ApplicationLoadBalancer(this, 'LB', {\n      vpc,\n      internetFacing: true,\n    });\n\n    this.userPool = new cognito.UserPool(this, 'UserPool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    const userPoolClient = new cognito.UserPoolClient(this, 'Client', {\n      userPool: this.userPool,\n\n      // Required minimal configuration for use with an ELB\n      generateSecret: true,\n      authFlows: {\n        userPassword: true,\n      },\n      oAuth: {\n        flows: {\n          authorizationCodeGrant: true,\n        },\n        scopes: [cognito.OAuthScope.EMAIL],\n        callbackUrls: [\n          `https://${props.domainName}/oauth2/idpresponse`,\n        ],\n      },\n    });\n    const cfnClient = userPoolClient.node.defaultChild as cognito.CfnUserPoolClient;\n    cfnClient.addPropertyOverride('RefreshTokenValidity', 1);\n    cfnClient.addPropertyOverride('SupportedIdentityProviders', ['COGNITO']);\n\n    const userPoolDomain = new cognito.UserPoolDomain(this, 'Domain', {\n      userPool: this.userPool,\n      cognitoDomain: {\n        domainPrefix: props.hostedZoneId.toLowerCase(),\n      },\n    });\n    const action = new actions.AuthenticateCognitoAction({\n      userPool: this.userPool,\n      userPoolClient,\n      userPoolDomain,\n      sessionTimeout: Duration.days(1),\n      next: elbv2.ListenerAction.fixedResponse(200, {\n        contentType: 'text/plain',\n        messageBody: 'Authenticated',\n      }),\n    });\n    const listener = lb.addListener('Listener', {\n      port: 443,\n      certificates: [certificate],\n      defaultAction: action,\n    });\n    listener.addAction('Action2', {\n      priority: 1,\n      conditions: [elbv2.ListenerCondition.pathPatterns(['action2*'])],\n      action,\n    });\n    new route53.ARecord(this, 'ARecord', {\n      target: route53.RecordTarget.fromAlias(new route53targets.LoadBalancerTarget(lb)),\n      zone: hostedZone,\n    });\n\n    new CfnOutput(this, 'DNS', {\n      value: props.domainName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Runtime for AWS resource management", "output": "export class Runtime {\n  /**\n   * CORRETTO 8\n   */\n  public static readonly CORRETTO_8 = Runtime.of('CORRETTO_8');\n\n  /**\n   * CORRETTO 11\n   */\n  public static readonly CORRETTO_11 = Runtime.of('CORRETTO_11');\n\n  /**\n   * .NET 6\n   */\n  public static readonly DOTNET_6 = Runtime.of('DOTNET_6');\n\n  /**\n   * Go 1.18\n   */\n  public static readonly GO_1 = Runtime.of('GO_1');\n\n  /**\n   * NodeJS 12\n   */\n  public static readonly NODEJS_12 = Runtime.of('NODEJS_12');\n\n  /**\n   * NodeJS 14\n   */\n  public static readonly NODEJS_14 = Runtime.of('NODEJS_14');\n\n  /**\n   * NodeJS 16\n   */\n  public static readonly NODEJS_16 = Runtime.of('NODEJS_16');\n\n  /**\n   * NodeJS 18\n   */\n  public static readonly NODEJS_18 = Runtime.of('NODEJS_18');\n\n  /**\n   * PHP 8.1\n   */\n  public static readonly PHP_81 = Runtime.of('PHP_81');\n\n  /**\n   * Python 3\n   */\n  public static readonly PYTHON_3 = Runtime.of('PYTHON_3');\n\n  /**\n   * Python 3.11\n   */\n  public static readonly PYTHON_311 = Runtime.of('PYTHON_311');\n\n  /**\n   * Ruby 3.1\n   */\n  public static readonly RUBY_31 = Runtime.of('RUBY_31');\n\n  /**\n   * NodeJS 22\n   */\n  public static readonly NODEJS_22 = Runtime.of('NODEJS_22');\n\n  /**\n   * Other runtimes\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-apprunner-service-codeconfigurationvalues.html#cfn-apprunner-service-codeconfigurationvalues-runtime for all available runtimes.\n   *\n   * @param name runtime name\n   *\n   */\n  public static of(name: string) { return new Runtime(name); }\n\n  /**\n   *\n   * @param name The runtime name.\n   */\n  private constructor(public readonly name: string) { }\n}", "language": "typescript"}
{"input": "CDK class Service for AWS resource management", "output": "export class Service extends ServiceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicediscovery.Service';\n\n  public static fromServiceAttributes(scope: Construct, id: string, attrs: ServiceAttributes): IService {\n    class Import extends ServiceBase {\n      public namespace: INamespace = attrs.namespace;\n      public serviceId = attrs.serviceId;\n      public serviceArn = attrs.serviceArn;\n      public dnsRecordType = attrs.dnsRecordType;\n      public routingPolicy = attrs.routingPolicy;\n      public serviceName = attrs.serviceName;\n      public discoveryType = attrs.discoveryType || defaultDiscoveryType(attrs.namespace);\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * A name for the Cloudmap Service.\n   */\n  public readonly serviceName: string;\n\n  /**\n   *  The namespace for the Cloudmap Service.\n   */\n  public readonly namespace: INamespace;\n\n  /**\n   * The ID of the namespace that you want to use for DNS configuration.\n   */\n  public readonly serviceId: string;\n\n  /**\n   * The Arn of the namespace that you want to use for DNS configuration.\n   */\n  public readonly serviceArn: string;\n\n  /**\n   * The DnsRecordType used by the service\n   */\n  public readonly dnsRecordType: DnsRecordType;\n\n  /**\n   * The Routing Policy used by the service\n   */\n  public readonly routingPolicy: RoutingPolicy;\n\n  /**\n   * The discovery type used by this service.\n   */\n  public readonly discoveryType: DiscoveryType;\n\n  constructor(scope: Construct, id: string, props: ServiceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const namespaceType = props.namespace.type;\n    const discoveryType = props.discoveryType || defaultDiscoveryType(props.namespace);\n\n    if (namespaceType == NamespaceType.HTTP && discoveryType == DiscoveryType.DNS_AND_API) {\n      throw new ValidationError(\n        'Cannot specify `discoveryType` of DNS_AND_API when using an HTTP namespace.', this,\n      );\n    }\n\n    // Validations\n    if (\n      discoveryType === DiscoveryType.API &&\n      (props.routingPolicy || props.dnsRecordType)\n    ) {\n      throw new ValidationError(\n        'Cannot specify `routingPolicy` or `dnsRecord` when using an HTTP namespace.', this,\n      );\n    }\n\n    if (props.healthCheck && props.customHealthCheck) {\n      throw new ValidationError('Cannot specify both `healthCheckConfig` and `healthCheckCustomConfig`.', this);\n    }\n\n    if (namespaceType === NamespaceType.DNS_PRIVATE && props.healthCheck) {\n      throw new ValidationError('Cannot specify `healthCheckConfig` for a Private DNS namespace.', this);\n    }\n\n    if (props.routingPolicy === RoutingPolicy.MULTIVALUE\n        && props.dnsRecordType === DnsRecordType.CNAME) {\n      throw new ValidationError('Cannot use `CNAME` record when routing policy is `Multivalue`.', this);\n    }\n\n    // Additional validation for eventual attachment of LBs\n    // The same validation happens later on during the actual attachment\n    // of LBs, but we need the property for the correct configuration of\n    // routingPolicy anyway, so might as well do the validation as well.\n    if (props.routingPolicy === RoutingPolicy.MULTIVALUE\n        && props.loadBalancer) {\n      throw new ValidationError('Cannot register loadbalancers when routing policy is `Multivalue`.', this);\n    }\n\n    if (props.healthCheck\n        && props.healthCheck.type === HealthCheckType.TCP\n        && props.healthCheck.resourcePath) {\n      throw new ValidationError('Cannot specify `resourcePath` when using a `TCP` health check.', this);\n    }\n\n    // Set defaults where necessary\n    const routingPolicy = (props.dnsRecordType === DnsRecordType.CNAME) || props.loadBalancer\n      ? RoutingPolicy.WEIGHTED\n      : RoutingPolicy.MULTIVALUE;\n\n    const dnsRecordType = props.dnsRecordType || DnsRecordType.A;\n\n    if (props.loadBalancer\n      && (!(dnsRecordType === DnsRecordType.A\n        || dnsRecordType === DnsRecordType.AAAA\n        || dnsRecordType === DnsRecordType.A_AAAA))) {\n      throw new ValidationError('Must support `A` or `AAAA` records to register loadbalancers.', this);\n    }\n\n    const dnsConfig: CfnService.DnsConfigProperty | undefined =\n      discoveryType === DiscoveryType.API\n        ? undefined\n        : {\n          dnsRecords: renderDnsRecords(dnsRecordType, props.dnsTtl),\n          namespaceId: props.namespace.namespaceId,\n          routingPolicy,\n        };\n\n    const healthCheckConfigDefaults = {\n      type: HealthCheckType.HTTP,\n      failureThreshold: 1,\n      resourcePath: props.healthCheck && props.healthCheck.type !== HealthCheckType.TCP\n        ? '/'\n        : undefined,\n    };\n\n    const healthCheckConfig = props.healthCheck && { ...healthCheckConfigDefaults, ...props.healthCheck };\n    const healthCheckCustomConfig = props.customHealthCheck;\n\n    // Create service\n    const service = new CfnService(this, 'Resource', {\n      name: props.name,\n      description: props.description,\n      dnsConfig,\n      healthCheckConfig,\n      healthCheckCustomConfig,\n      namespaceId: props.namespace.namespaceId,\n      type: props.discoveryType == DiscoveryType.API ? 'HTTP' : undefined,\n    });\n\n    this.serviceName = service.attrName;\n    this.serviceArn = service.attrArn;\n    this.serviceId = service.attrId;\n    this.namespace = props.namespace;\n    this.dnsRecordType = dnsRecordType;\n    this.routingPolicy = routingPolicy;\n    this.discoveryType = discoveryType;\n  }\n\n  /**\n   * Registers an ELB as a new instance with unique name instanceId in this service.\n   */\n  @MethodMetadata()\n  public registerLoadBalancer(id: string, loadBalancer: elbv2.ILoadBalancerV2, customAttributes?: { [key: string]: string }): IInstance {\n    return new AliasTargetInstance(this, id, {\n      service: this,\n      dnsName: loadBalancer.loadBalancerDnsName,\n      customAttributes,\n    });\n  }\n\n  /**\n   * Registers a resource that is accessible using values other than an IP address or a domain name (CNAME).\n   */\n  @MethodMetadata()\n  public registerNonIpInstance(id: string, props: NonIpInstanceBaseProps): IInstance {\n    return new NonIpInstance(this, id, {\n      service: this,\n      ...props,\n    });\n  }\n\n  /**\n   * Registers a resource that is accessible using an IP address.\n   */\n  @MethodMetadata()\n  public registerIpInstance(id: string, props: IpInstanceBaseProps): IInstance {\n    return new IpInstance(this, id, {\n      service: this,\n      ...props,\n    });\n  }\n\n  /**\n   * Registers a resource that is accessible using a CNAME.\n   */\n  @MethodMetadata()\n  public registerCnameInstance(id: string, props: CnameInstanceBaseProps): IInstance {\n    return new CnameInstance(this, id, {\n      service: this,\n      ...props,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class CdkErrors for AWS resource management", "output": "export class CdkErrors extends ExternalModule {\n  public readonly ValidationError = Type.fromName(this, 'ValidationError');\n\n  constructor(parent: CdkCore) {\n    super(`${parent.fqn}/core/lib/errors`);\n  }\n}", "language": "typescript"}
{"input": "Defines the deployment strategy ID's of AWS AppConfig deployment strategies. @see https://docs.aws.amazon.com/appconfig/latest/userguide/appconfig-creating-deployment-strategy.html", "output": "class DeploymentStrategyId {\n  /**\n   * **AWS Recommended**. This strategy processes the deployment exponentially using a 10% growth factor over 20 minutes.\n   * AWS AppConfig recommends using this strategy for production deployments because it aligns with AWS best practices\n   * for configuration deployments.\n   */\n  public static readonly CANARY_10_PERCENT_20_MINUTES = DeploymentStrategyId.fromString('AppConfig.Canary10Percent20Minutes');\n\n  /**\n   * **Testing/Demonstration**. This strategy deploys the configuration to half of all targets every 30 seconds for a\n   * one-minute deployment. AWS AppConfig recommends using this strategy only for testing or demonstration purposes because\n   * it has a short duration and bake time.\n   */\n  public static readonly LINEAR_50_PERCENT_EVERY_30_SECONDS = DeploymentStrategyId.fromString('AppConfig.Linear50PercentEvery30Seconds');\n\n  /**\n   * **AWS Recommended**. This strategy deploys the configuration to 20% of all targets every six minutes for a 30 minute deployment.\n   * AWS AppConfig recommends using this strategy for production deployments because it aligns with AWS best practices\n   * for configuration deployments.\n   */\n  public static readonly LINEAR_20_PERCENT_EVERY_6_MINUTES = DeploymentStrategyId.fromString('AppConfig.Linear20PercentEvery6Minutes');\n\n  /**\n   * **Quick**. This strategy deploys the configuration to all targets immediately.\n   */\n  public static readonly ALL_AT_ONCE = DeploymentStrategyId.fromString('AppConfig.AllAtOnce');\n\n  /**\n   * Builds a deployment strategy ID from a string.\n   *\n   * @param deploymentStrategyId The deployment strategy ID.\n   */\n  public static fromString(deploymentStrategyId: string): DeploymentStrategyId {\n    return {\n      id: deploymentStrategyId,\n    };\n  }\n\n  /**\n   * The deployment strategy ID.\n   */\n  public abstract readonly id: string;\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, KMS operations", "output": "def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        table_name: str,\n        key_replica_regions: List[str],\n        key_alias: str = None,\n        **kwargs,\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        key_id = kms.CfnKey(\n            self,\n            \"multi-region-cmk\",\n            key_policy={\n                \"Version\": \"2012-10-17\",\n                \"Statement\": [\n                    {\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                            \"AWS\": f\"arn:aws:iam::{self.account}:root\",\n                        },\n                        \"Action\": \"kms:*\",\n                        \"Resource\": \"*\",\n                    },\n                ],\n            },\n            description=f\"CMK for {table_name} in {self.region}\",\n            enable_key_rotation=True,\n            enabled=True,\n            multi_region=True,\n        ).attr_key_id\n\n        kms.CfnAlias(\n            self,\n            \"multi-region-cmk-alias\",\n            alias_name=key_alias\n            or f\"alias/multi-region-cmk-for-ddb-table-{table_name}\",\n            target_key_id=key_id,\n        )\n\n        self._create_cfn_output_key_arn(self.region, key_id)\n        for replica_region in key_replica_regions:\n            self._create_key_replica(replica_region, key_id)", "language": "python"}
{"input": "Base class for tokens that represent CloudFormation intrinsic functions.", "output": "class FnBase extends Intrinsic {\n  constructor(name: string, value: any) {\n    super({ [name]: value });\n\n    Object.defineProperty(this, FN_BASE_SYMBOL, { value: true });\n  }\n}", "language": "typescript"}
{"input": "Active Directory authentication", "output": "class ActiveDirectoryAuthentication extends ClientVpnUserBasedAuthentication {\n  constructor(private readonly directoryId: string) {\n    super();\n  }\n\n  render(): any {\n    return {\n      type: 'directory-service-authentication',\n      activeDirectory: { directoryId: this.directoryId },\n    };\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: * aws lambda invoke --function-name <deployed fn name> --invocation-type Event --payload '\"OK\"' response.json", "output": "class TestStack extends Stack {\n  public readonly functionNames: string[] = [];\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const defaultFunction = new lambda.PythonFunction(this, 'my_handler', {\n      entry: path.join(__dirname, 'lambda-handler'),\n      runtime: Runtime.PYTHON_3_9,\n    });\n    this.functionNames.push(defaultFunction.functionName);\n\n    new CfnOutput(this, 'DefaultFunctionArn', {\n      value: defaultFunction.functionArn,\n    });\n\n    const functionWithExcludes = new lambda.PythonFunction(this, 'my_handler_excludes', {\n      entry: path.join(__dirname, 'lambda-handler'),\n      runtime: Runtime.PYTHON_3_9,\n      bundling: {\n        assetExcludes: ['.ignorefiles'],\n      },\n    });\n    this.functionNames.push(functionWithExcludes.functionName);\n\n    new CfnOutput(this, 'FunctionArnWithExcludes', {\n      value: functionWithExcludes.functionArn,\n    });\n\n    const functionWithCustomPypi = new lambda.PythonFunction(this, 'my_handler_pypi', {\n      entry: path.join(__dirname, 'lambda-handler'),\n      runtime: Runtime.PYTHON_3_9,\n      bundling: {\n        environment: {\n          PIP_INDEX_URL: 'https://aws:SOME_SECRET_TOKEN@pypi.org/simple',\n        },\n      },\n    });\n    this.functionNames.push(functionWithCustomPypi.functionName);\n\n    new CfnOutput(this, 'functionWithCustomPypi', {\n      value: functionWithCustomPypi.functionArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "The number of CPU units reserved for each instance of your App Runner service.", "output": "export class Cpu {\n  /**\n   * 0.25 vCPU\n   */\n  public static readonly QUARTER_VCPU = Cpu.of('0.25 vCPU');\n\n  /**\n   * 0.5 vCPU\n   */\n  public static readonly HALF_VCPU = Cpu.of('0.5 vCPU');\n\n  /**\n   * 1 vCPU\n   */\n  public static readonly ONE_VCPU = Cpu.of('1 vCPU');\n\n  /**\n   * 2 vCPU\n   */\n  public static readonly TWO_VCPU = Cpu.of('2 vCPU');\n\n  /**\n   * 4 vCPU\n   */\n  public static readonly FOUR_VCPU = Cpu.of('4 vCPU');\n\n  /**\n   * Custom CPU unit\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-apprunner-service-instanceconfiguration.html#cfn-apprunner-service-instanceconfiguration-cpu\n   *\n   * @param unit custom CPU unit\n   */\n  public static of(unit: string): Cpu {\n    const numericPatterns = ['256', '512', '1024', '2048', '4096'];\n    const unitPatterns = ['0.25 vCPU', '0.5 vCPU', '1 vCPU', '2 vCPU', '4 vCPU'];\n    const allowedPatterns = numericPatterns.concat(unitPatterns);\n    const isValidValue = allowedPatterns.some(\n      (pattern) => pattern === unit,\n    );\n    if (!isValidValue) {\n      throw new cdk.UnscopedValidationError('CPU value is invalid');\n    }\n\n    return new Cpu(unit);\n  }\n\n  /**\n   *\n   * @param unit The unit of CPU.\n   */\n  private constructor(public readonly unit: string) { }\n}", "language": "typescript"}
{"input": "Defines monitors that will be associated with an AWS AppConfig environment.", "output": "class Monitor {\n  /**\n   * Creates a Monitor from a CloudWatch alarm. If the alarm role is not specified, a role will\n   * be generated.\n   *\n   * @param alarm The Amazon CloudWatch alarm.\n   * @param alarmRole The IAM role for AWS AppConfig to view the alarm state.\n   */\n  public static fromCloudWatchAlarm(alarm: IAlarmRef, alarmRole?: iam.IRoleRef): Monitor {\n    return {\n      alarmArn: alarm.alarmRef.alarmArn,\n      alarmRoleArn: alarmRole?.roleRef.roleArn,\n      monitorType: MonitorType.CLOUDWATCH,\n    };\n  }\n\n  /**\n   * Creates a Monitor from a CfnEnvironment.MonitorsProperty construct.\n   *\n   * @param monitorsProperty The monitors property.\n   */\n  public static fromCfnMonitorsProperty(monitorsProperty: CfnEnvironment.MonitorsProperty): Monitor {\n    if (monitorsProperty.alarmArn === undefined) {\n      throw new UnscopedValidationError('You must specify an alarmArn property to use \"fromCfnMonitorsProperty\".');\n    }\n    return {\n      alarmArn: monitorsProperty.alarmArn,\n      alarmRoleArn: monitorsProperty.alarmRoleArn,\n      monitorType: MonitorType.CFN_MONITORS_PROPERTY,\n    };\n  }\n\n  /**\n   * The alarm ARN for AWS AppConfig to monitor.\n   */\n  public abstract readonly alarmArn: string;\n\n  /**\n   * The type of monitor.\n   */\n  public abstract readonly monitorType: MonitorType;\n\n  /**\n   * The IAM role ARN for AWS AppConfig to view the alarm state.\n   */\n  public abstract readonly alarmRoleArn?: string;\n\n  /**\n   * Indicates whether a CloudWatch alarm is a composite alarm.\n   */\n  public abstract readonly isCompositeAlarm?: boolean;\n}", "language": "typescript"}
{"input": "Defines a CloudFormation Stack consisting of an EventBus, IAM Role,\nEventBus Rules, and a Lambda Function for producing test events to the\nEventBus.", "output": "class ProducerStack(Stack):\n    \"\"\"\n    Defines a CloudFormation Stack consisting of an EventBus, IAM Role,\n    EventBus Rules, and a Lambda Function for producing test events to the\n    EventBus.\n    \"\"\"\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        self.id = \"Producer\"\n        self.event_bus_name = self.node.try_get_context(\"event_bus_name\")\n\n        self.event_bus = events.EventBus(\n            self,\n            self.id + \"EB\" + self.event_bus_name,\n            event_bus_name=self.event_bus_name,\n        )\n\n        self.role = iam.Role(\n            self,\n            self.id + \"Role\",\n            assumed_by=iam.ServicePrincipal(\"events.amazonaws.com\"),\n        )\n\n        self.rules = self.deploy_rules(\n            self.event_bus, self.role, self.node.try_get_context(\"rules\")\n        )\n        self.producer = self.deploy_producer(self.event_bus)\n\n        # Adds CDK Nag check to stack resources\n        Aspects.of(self).add(AwsSolutionsChecks())\n\n    def deploy_rules(\n        self,\n        event_bus: events.EventBus,\n        role: iam.Role,\n        rule_definitions: List[dict]\n    ) -> List[events.Rule]:\n        \"\"\"\n        Creates an EventBridge Rule for each specified rule defintion.\n\n        Args:\n            * event_bus (events.EventBus): The EventBridge bus for the new\n                rules\n            * role (iam.Role): The IAM Role assigned to each rule\n            * rule_definitions (List[dict]): The list of EventBrige Rule\n                definitions\n\n        Returns:\n            * List[events.Rule]: The list of create EventBridge Rules\n\n        \"\"\"\n        rules = []\n        for rule_definition in rule_definitions:\n            rule = events.Rule(\n                self,\n                self.id + \"Rule\" + rule_definition[\"id\"],\n                event_bus=event_bus,\n                event_pattern=events.EventPattern(\n                    source=rule_definition[\"sources\"],\n                    detail_type=rule_definition[\"detail_types\"],\n                ),\n            )\n\n            for target in rule_definition[\"targets\"]:\n                rule.add_target(\n                    target=targets.EventBus(\n                        event_bus=events.EventBus.from_event_bus_arn(\n                            self, target[\"id\"], target[\"arn\"]\n                        ),\n                        role=role,\n                    ),\n                )\n\n            rules.append(rule)\n\n        return rules\n\n    def deploy_producer(self, event_bus: events.EventBus) -> _lambda.Function:\n        \"\"\"\n        Creates a Lambda function to produce test events on the provided\n        EventBus.\n\n        Args:\n            * event_bus (events.EventBus): The EventBridge bus to send test\n                events\n\n        Returns:\n            * _lambda.Function: The created Lambda function\n\n        \"\"\"\n        lambda_function = _lambda.Function(\n            self,\n            \"ProducerLambda\",\n            runtime=_lambda.Runtime.PYTHON_3_12,\n            handler=\"producer.handler\",\n            timeout=Duration.seconds(30),\n            code=_lambda.Code.from_asset(\"./lambda/producer\"),\n            environment={\n                \"LOG_LEVEL\": \"DEBUG\",\n                \"SOURCE\": \"Producer\",\n                \"DETAIL_TYPE\": \"TestType\",\n                \"EVENT_BUS_NAME\": event_bus.event_bus_name,\n            },\n        )\n\n        # This check ensures the usage of the role is not an optional (mypy)\n        if lambda_function.role is None:\n            raise ValueError(\"No Lambda function role was created\")\n\n        NagSuppressions.add_resource_suppressions(\n            construct=lambda_function.role,\n            suppressions=[\n                NagPackSuppression(\n                    id=\"AwsSolutions-IAM4\",\n                    reason=\"The default function role is an AWS managed role\",\n                )\n            ],\n        )\n\n        event_bus.grant_put_events_to(lambda_function.role)\n\n        return lambda_function", "language": "python"}
{"input": "CDK class BitBucketSourceCredentials for AWS resource management", "output": "export class BitBucketSourceCredentials extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codebuild.BitBucketSourceCredentials';\n\n  constructor(scope: Construct, id: string, props: BitBucketSourceCredentialsProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnSourceCredential(this, 'Resource', {\n      serverType: 'BITBUCKET',\n      authType: 'BASIC_AUTH',\n      username: props.username.unsafeUnwrap(), // Safe usage\n      token: props.password.unsafeUnwrap(), // Safe usage\n    });\n  }\n}", "language": "typescript"}
{"input": "non-nested non-parent stack consumes a resource from a nested stack", "output": "class ProducerNestedStack extends NestedStack {\n  public readonly topic: sns.Topic;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    this.topic = new sns.Topic(this, 'MyTopic');\n  }\n}", "language": "typescript"}
{"input": "CDK class RateLimitedApiKey for AWS resource management", "output": "export class RateLimitedApiKey extends ApiKeyBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.RateLimitedApiKey';\n  public readonly keyId: string;\n  public readonly keyArn: string;\n\n  constructor(scope: Construct, id: string, props: RateLimitedApiKeyProps = { }) {\n    super(scope, id, {\n      physicalName: props.apiKeyName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new ApiKey(this, 'Resource', props);\n\n    if (props.apiStages || props.quota || props.throttle) {\n      const usageplan = new UsagePlan(this, 'UsagePlanResource', {\n        apiStages: props.apiStages,\n        quota: props.quota,\n        throttle: props.throttle,\n      });\n      usageplan.addApiKey(resource);\n    }\n\n    this.keyId = resource.keyId;\n    this.keyArn = resource.keyArn;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Secrets Manager, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const secret = new secretsmanager.Secret(this, 'Secret');\n    secret.addRotationSchedule('Schedule', {\n      hostedRotation: secretsmanager.HostedRotation.mysqlSingleUser(),\n    });\n\n    const customSecret = new secretsmanager.Secret(this, 'CustomSecret', {\n      generateSecretString: {\n        excludeCharacters: '&@/',\n      },\n    });\n    customSecret.addRotationSchedule('Schedule', {\n      hostedRotation: secretsmanager.HostedRotation.mysqlSingleUser(),\n      rotateImmediatelyOnUpdate: false,\n    });\n\n    const mySecret = new secretsmanager.Secret(this, 'MySecret');\n    const importedSecret = secretsmanager.Secret.fromSecretNameV2(this, 'MasterSecretImported', 'MasterSecret');\n    mySecret.addRotationSchedule('RotationSchedule', {\n      hostedRotation: secretsmanager.HostedRotation.postgreSqlMultiUser({\n        masterSecret: importedSecret,\n      }),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Group for AWS resource management", "output": "export class Group extends GroupBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-iam.Group';\n\n  /**\n   * Import an external group by ARN.\n   *\n   * If the imported Group ARN is a Token (such as a\n   * `CfnParameter.valueAsString` or a `Fn.importValue()`) *and* the referenced\n   * group has a `path` (like `arn:...:group/AdminGroup/NetworkAdmin`), the\n   * `groupName` property will not resolve to the correct value. Instead it\n   * will resolve to the first path component. We unfortunately cannot express\n   * the correct calculation of the full path name as a CloudFormation\n   * expression. In this scenario the Group ARN should be supplied without the\n   * `path` in order to resolve the correct group resource.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param groupArn the ARN of the group to import (e.g. `arn:aws:iam::account-id:group/group-name`)\n   */\n  public static fromGroupArn(scope: Construct, id: string, groupArn: string): IGroup {\n    const arnComponents = Stack.of(scope).splitArn(groupArn, ArnFormat.SLASH_RESOURCE_NAME);\n    const groupName = arnComponents.resourceName!;\n    class Import extends GroupBase {\n      public groupName = groupName;\n      public groupArn = groupArn;\n      public principalAccount = arnComponents.account;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing group by given name (with path).\n   * This method has same caveats of `fromGroupArn`\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param groupName the groupName (path included) of the existing group to import\n   */\n  static fromGroupName(scope: Construct, id: string, groupName: string) {\n    const groupArn = Stack.of(scope).formatArn({\n      service: 'iam',\n      region: '',\n      resource: 'group',\n      resourceName: groupName,\n    });\n    return Group.fromGroupArn(scope, id, groupArn);\n  }\n\n  public readonly groupName: string;\n  public readonly groupArn: string;\n\n  private readonly managedPolicies: IManagedPolicy[] = [];\n\n  constructor(scope: Construct, id: string, props: GroupProps = {}) {\n    super(scope, id, {\n      physicalName: props.groupName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.managedPolicies.push(...props.managedPolicies || []);\n\n    const group = new CfnGroup(this, 'Resource', {\n      groupName: this.physicalName,\n      managedPolicyArns: Lazy.list({ produce: () => this.managedPolicies.map(p => p.managedPolicyArn) }, { omitEmpty: true }),\n      path: props.path,\n    });\n\n    this.groupName = this.getResourceNameAttribute(group.ref);\n    this.groupArn = this.getResourceArnAttribute(group.attrArn, {\n      region: '', // IAM is global in each partition\n      service: 'iam',\n      resource: 'group',\n      // Removes leading slash from path\n      resourceName: `${props.path ? props.path.substr(props.path.charAt(0) === '/' ? 1 : 0) : ''}${this.physicalName}`,\n    });\n\n    this.managedPoliciesExceededWarning();\n  }\n\n  /**\n   * Attaches a managed policy to this group. See [IAM and AWS STS quotas, name requirements, and character limits]\n   * (https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-quotas.html#reference_iam-quotas-entities)\n   * for quota of managed policies attached to an IAM group.\n   * @param policy The managed policy to attach.\n   */\n  @MethodMetadata()\n  public addManagedPolicy(policy: IManagedPolicy) {\n    if (this.managedPolicies.find(mp => mp === policy)) { return; }\n    this.managedPolicies.push(policy);\n    this.managedPoliciesExceededWarning();\n  }\n\n  private managedPoliciesExceededWarning() {\n    if (this.managedPolicies.length > 10) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-iam:groupMaxPoliciesExceeded', `You added ${this.managedPolicies.length} to IAM Group ${this.physicalName}. The maximum number of managed policies attached to an IAM group is 10.`);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class FargateEfs for AWS resource management", "output": "class FargateEfs extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'DefaultVpc', { maxAzs: 2});\n    const ecsCluster = new ecs.Cluster(this, 'DefaultEcsCluster', {vpc: vpc});\n\n    const fileSystem = new efs.FileSystem(this, 'MyEfsFileSystem', {\n      vpc: vpc,\n      encrypted: true,\n      lifecyclePolicy: efs.LifecyclePolicy.AFTER_14_DAYS,\n      performanceMode: efs.PerformanceMode.GENERAL_PURPOSE,\n      throughputMode: efs.ThroughputMode.BURSTING\n    });\n\n    fileSystem.addToResourcePolicy(\n      new iam.PolicyStatement({\n        actions: ['elasticfilesystem:ClientMount'],\n        principals: [new iam.AnyPrincipal()],\n        conditions: {\n          Bool: {\n            'elasticfilesystem:AccessedViaMountTarget': 'true'\n          }\n        }\n      })\n    )\n\n    const taskDef = new ecs.FargateTaskDefinition(this, \"MyTaskDefinition\", {\n        memoryLimitMiB: 512,\n        cpu: 256,\n        volumes: [\n            {\n                name: \"uploads\",\n                efsVolumeConfiguration: {\n                    fileSystemId: fileSystem.fileSystemId,\n                }\n            }\n        ]\n    });\n\n    const containerDef = new ecs.ContainerDefinition(this, \"MyContainerDefinition\", {\n      image: ecs.ContainerImage.fromRegistry(\"coderaiser/cloudcmd\"),\n      taskDefinition: taskDef\n    });\n\n    containerDef.addMountPoints(\n      {\n        sourceVolume: \"uploads\",\n        containerPath: \"/uploads\",\n        readOnly: false\n      }\n    )\n\n    containerDef.addPortMappings({\n      containerPort: 8000\n    });\n\n    const albFargateService = new ecs_patterns.ApplicationLoadBalancedFargateService(this, 'Service01', {\n      cluster: ecsCluster,\n      taskDefinition: taskDef,\n      desiredCount: 2\n    });\n\n    albFargateService.targetGroup.setAttribute('deregistration_delay.timeout_seconds', '30');\n\n    // Allow access to EFS from Fargate ECS\n    fileSystem.grantRootAccess(albFargateService.taskDefinition.taskRole.grantPrincipal);\n    fileSystem.connections.allowDefaultPortFrom(albFargateService.service.connections);\n  }\n}", "language": "typescript"}
{"input": "CDK class pipelineAppStage for AWS resource management", "output": "export class pipelineAppStage extends cdk.Stage {\n\n    constructor(scope: Construct, id: string, props?: cdk.StageProps) {\n      super(scope, id, props);\n\n    // \ud83d\udc47 vpc stack \ud83d\udc47\n    const vpc_stack = new vpcStack(this, 'VpcStack');\n    cdk.Tags.of(vpc_stack).add('managedBy',   'cdk');\n    cdk.Tags.of(vpc_stack).add('environment', 'dev');\n\n    // \ud83d\udc47 lambda api stack \ud83d\udc47\n    const lambda_api_stack = new lambdaApiStack(this, 'LambdaApisStack');\n    cdk.Tags.of(lambda_api_stack).add('managedBy',   'cdk');\n    cdk.Tags.of(lambda_api_stack).add('environment', 'dev');\n\n    // \ud83d\udc47 ecs fargate stack \ud83d\udc47\n    const ecs_fargate_stack = new ecsFargateStack(this, 'EcsFargateStack', {\n      vpc: vpc_stack.vpc,\n    });\n    cdk.Tags.of(ecs_fargate_stack).add('managedBy',   'cdk');\n    cdk.Tags.of(ecs_fargate_stack).add('environment', 'dev');\n\n    // \ud83d\udc47 async lambda stack \ud83d\udc47\n    const async_lambda_stack = new asyncLambdaStack(this, 'AsyncLambdasStack');\n    cdk.Tags.of(async_lambda_stack).add('managedBy',   'cdk');\n    cdk.Tags.of(async_lambda_stack).add('environment', 'dev');\n    \n    const rds_aurora_stack = new rdsAuroraStack(this, 'rdsAuroraStack', {\n      vpc: vpc_stack.vpc,\n    });\n    cdk.Tags.of(rds_aurora_stack).add('managedBy',   'cdk');\n    cdk.Tags.of(rds_aurora_stack).add('environment', 'dev');\n    }\n}", "language": "typescript"}
{"input": "CDK class S3BucketOrigin for AWS resource management", "output": "class S3BucketOrigin extends cloudfront.OriginBase {\n  /**\n   * Create a S3 Origin with Origin Access Control (OAC) configured\n   */\n  public static withOriginAccessControl(bucket: IBucket, props?: S3BucketOriginWithOACProps): cloudfront.IOrigin {\n    return new S3BucketOriginWithOAC(bucket, props);\n  }\n\n  /**\n   * Create a S3 Origin with Origin Access Identity (OAI) configured\n   * OAI is a legacy feature and we **strongly** recommend you to use OAC via `withOriginAccessControl()`\n   * unless it is not supported in your required region (e.g. China regions).\n   */\n  public static withOriginAccessIdentity(bucket: IBucket, props?: S3BucketOriginWithOAIProps): cloudfront.IOrigin {\n    return new S3BucketOriginWithOAI(bucket, props);\n  }\n\n  /**\n   * Create a S3 Origin with default S3 bucket settings (no origin access control)\n   */\n  public static withBucketDefaults(bucket: IBucket, props?: cloudfront.OriginProps): cloudfront.IOrigin {\n    return new class extends S3BucketOrigin {\n      constructor() {\n        super(bucket, { ...props });\n      }\n    }();\n  }\n\n  constructor(bucket: IBucket, props?: S3BucketOriginBaseProps) {\n    super(bucket.bucketRegionalDomainName, props);\n  }\n\n  /** @internal */\n  protected _bind(scope: Construct, options: cloudfront.OriginBindOptions): cloudfront.OriginBindConfig {\n    return super.bind(scope, options);\n  }\n\n  protected renderS3OriginConfig(): cloudfront.CfnDistribution.S3OriginConfigProperty | undefined {\n    return { originAccessIdentity: '' };\n  }\n}", "language": "typescript"}
{"input": "CDK Construct TestConstruct for reusable infrastructure components", "output": "class TestConstruct extends Construct {\n  // @ts-ignore\n  private static readonly [JSII_RUNTIME_SYMBOL] = { fqn: '@amzn/core.TestConstruct', version: 'FakeVersion.2.3' };\n}", "language": "typescript"}
{"input": "CDK class FileSystem for AWS resource management", "output": "export class FileSystem extends FileSystemBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-efs.FileSystem';\n\n  /**\n   * The default port File System listens on.\n   */\n  public static readonly DEFAULT_PORT: number = 2049;\n\n  /**\n   * Import an existing File System from the given properties.\n   */\n  public static fromFileSystemAttributes(scope: Construct, id: string, attrs: FileSystemAttributes): IFileSystem {\n    return new ImportedFileSystem(scope, id, attrs);\n  }\n\n  /**\n   * The security groups/rules used to allow network connections to the file system.\n   */\n  public readonly connections: ec2.Connections;\n\n  /**\n   * @attribute\n   */\n  public readonly fileSystemId: string;\n  /**\n   * @attribute\n   */\n  public readonly fileSystemArn: string;\n\n  public readonly mountTargetsAvailable: IDependable;\n\n  private readonly _mountTargetsAvailable = new DependencyGroup();\n\n  private readonly props: FileSystemProps;\n\n  /**\n   * Constructor for creating a new EFS FileSystem.\n   */\n  constructor(scope: Construct, id: string, props: FileSystemProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.props = props;\n\n    if (props.performanceMode === PerformanceMode.MAX_IO && props.oneZone) {\n      throw new ValidationError('performanceMode MAX_IO is not supported for One Zone file systems.', this);\n    }\n\n    if (props.oneZone) { this.oneZoneValidation(); }\n\n    if (props.throughputMode === ThroughputMode.PROVISIONED && props.provisionedThroughputPerSecond === undefined) {\n      throw new ValidationError('Property provisionedThroughputPerSecond is required when throughputMode is PROVISIONED', this);\n    }\n\n    if (props.throughputMode === ThroughputMode.ELASTIC && props.performanceMode === PerformanceMode.MAX_IO) {\n      throw new ValidationError('ThroughputMode ELASTIC is not supported for file systems with performanceMode MAX_IO', this);\n    }\n\n    if (props.replicationConfiguration && props.replicationOverwriteProtection === ReplicationOverwriteProtection.DISABLED) {\n      throw new ValidationError('Cannot configure \\'replicationConfiguration\\' when \\'replicationOverwriteProtection\\' is set to \\'DISABLED\\'', this);\n    }\n\n    // we explicitly use 'undefined' to represent 'false' to maintain backwards compatibility since\n    // its considered an actual change in CloudFormations eyes, even though they have the same meaning.\n    const encrypted = props.encrypted ?? (FeatureFlags.of(this).isEnabled(\n      cxapi.EFS_DEFAULT_ENCRYPTION_AT_REST) ? true : undefined);\n\n    // LifecyclePolicies must be an array of objects, each containing a single policy\n    const lifecyclePolicies: CfnFileSystem.LifecyclePolicyProperty[] = [];\n\n    if (props.lifecyclePolicy) {\n      lifecyclePolicies.push({ transitionToIa: props.lifecyclePolicy });\n    }\n\n    if (props.outOfInfrequentAccessPolicy) {\n      lifecyclePolicies.push({ transitionToPrimaryStorageClass: props.outOfInfrequentAccessPolicy });\n    }\n\n    if (props.transitionToArchivePolicy) {\n      lifecyclePolicies.push({ transitionToArchive: props.transitionToArchivePolicy });\n    }\n\n    // if props.vpcSubnets.availabilityZones is defined, select the first one as the zone otherwise\n    // the first AZ of the VPC.\n    const oneZoneAzName = props.vpcSubnets?.availabilityZones ?\n      props.vpcSubnets.availabilityZones[0] : props.vpc.availabilityZones[0];\n\n    const fileSystemProtection = props.replicationOverwriteProtection !== undefined ? {\n      replicationOverwriteProtection: props.replicationOverwriteProtection,\n    } : undefined;\n\n    const replicationConfiguration = props.replicationConfiguration ? {\n      destinations: [\n        {\n          fileSystemId: props.replicationConfiguration._destinationFileSystemRef?.fileSystemRef.fileSystemId,\n          kmsKeyId: props.replicationConfiguration.kmsKey?.keyArn,\n          region: props.replicationConfiguration._destinationFileSystemRef ?\n            props.replicationConfiguration._destinationFileSystemRef.env.region :\n            (props.replicationConfiguration.region ?? Stack.of(this).region),\n          availabilityZoneName: props.replicationConfiguration.availabilityZone,\n        },\n      ],\n    } : undefined;\n\n    this._resource = new CfnFileSystem(this, 'Resource', {\n      encrypted: encrypted,\n      kmsKeyId: props.kmsKey?.keyRef.keyArn,\n      lifecyclePolicies: lifecyclePolicies.length > 0 ? lifecyclePolicies : undefined,\n      performanceMode: props.performanceMode,\n      throughputMode: props.throughputMode,\n      provisionedThroughputInMibps: props.provisionedThroughputPerSecond?.toMebibytes(),\n      backupPolicy: props.enableAutomaticBackups ? { status: 'ENABLED' } : undefined,\n      fileSystemPolicy: Lazy.any({\n        produce: () => {\n          const denyAnonymousAccessFlag = FeatureFlags.of(this).isEnabled(cxapi.EFS_DENY_ANONYMOUS_ACCESS) ?? false;\n          const denyAnonymousAccessByDefault = denyAnonymousAccessFlag || this._grantedClient;\n          const allowAnonymousAccess = props.allowAnonymousAccess ?? !denyAnonymousAccessByDefault;\n          if (!allowAnonymousAccess) {\n            this.addToResourcePolicy(new iam.PolicyStatement({\n              principals: [new iam.AnyPrincipal()],\n              actions: [\n                ClientAction.WRITE,\n                ClientAction.ROOT_ACCESS,\n              ],\n              conditions: {\n                Bool: {\n                  'elasticfilesystem:AccessedViaMountTarget': 'true',\n                },\n              },\n            }));\n          }\n          return this._fileSystemPolicy;\n        },\n      }),\n      fileSystemProtection,\n      availabilityZoneName: props.oneZone ? oneZoneAzName : undefined,\n      replicationConfiguration,\n    });\n    this._resource.applyRemovalPolicy(props.removalPolicy);\n\n    this.fileSystemId = this._resource.ref;\n    this.fileSystemArn = this._resource.attrArn;\n    this._fileSystemPolicy = props.fileSystemPolicy;\n\n    Tags.of(this).add('Name', props.fileSystemName || this.node.path);\n\n    const securityGroup = (props.securityGroup || new ec2.SecurityGroup(this, 'EfsSecurityGroup', {\n      vpc: props.vpc,\n    }));\n\n    this.connections = new ec2.Connections({\n      securityGroups: [securityGroup],\n      defaultPort: ec2.Port.tcp(FileSystem.DEFAULT_PORT),\n    });\n\n    // When oneZone is specified, to avoid deployment failure, mountTarget should also be created only in the specified AZ.\n    let subnetSelection: ec2.SubnetSelection;\n    if (props.oneZone) {\n      subnetSelection = {\n        availabilityZones: [oneZoneAzName],\n      };\n    } else {\n      subnetSelection = props.vpcSubnets ?? { onePerAz: true };\n    }\n    const subnets = props.vpc.selectSubnets(subnetSelection);\n\n    // We now have to create the mount target for each of the mentioned subnet\n\n    // we explicitly use FeatureFlags to maintain backwards compatibility\n    const useMountTargetOrderInsensitiveLogicalID = FeatureFlags.of(this).isEnabled(cxapi.EFS_MOUNTTARGET_ORDERINSENSITIVE_LOGICAL_ID);\n    this.mountTargetsAvailable = [];\n    if (useMountTargetOrderInsensitiveLogicalID) {\n      subnets.subnets.forEach((subnet) => {\n        const subnetUniqueId = Token.isUnresolved(subnet.node.id) ? Names.uniqueResourceName(subnet, { maxLength: 16 }) : subnet.node.id;\n\n        const mountTarget = new CfnMountTarget(this,\n          `EfsMountTarget-${subnetUniqueId}`,\n          {\n            fileSystemId: this.fileSystemId,\n            securityGroups: Array.of(securityGroup.securityGroupId),\n            subnetId: subnet.subnetId,\n          });\n        this._mountTargetsAvailable.add(mountTarget);\n      });\n    } else {\n      let mountTargetCount = 0;\n      subnets.subnetIds.forEach((subnetId: string) => {\n        const mountTarget = new CfnMountTarget(this,\n          'EfsMountTarget' + (++mountTargetCount),\n          {\n            fileSystemId: this.fileSystemId,\n            securityGroups: Array.of(securityGroup.securityGroupId),\n            subnetId,\n          });\n        this._mountTargetsAvailable.add(mountTarget);\n      });\n    }\n    this.mountTargetsAvailable = this._mountTargetsAvailable;\n  }\n\n  private oneZoneValidation() {\n    // validate when props.oneZone is enabled\n    if (this.props.vpcSubnets && !this.props.vpcSubnets.availabilityZones) {\n      throw new ValidationError('When oneZone is enabled and vpcSubnets defined, vpcSubnets.availabilityZones can not be undefined.', this);\n    }\n    // when vpcSubnets.availabilityZones is defined\n    if (this.props.vpcSubnets && this.props.vpcSubnets.availabilityZones) {\n      // it has to be only one az\n      if (this.props.vpcSubnets.availabilityZones?.length !== 1) {\n        throw new ValidationError('When oneZone is enabled, vpcSubnets.availabilityZones should exactly have one zone.', this);\n      }\n      // it has to be in availabilityZones\n      // but we only check this when vpc.availabilityZones are valid(not dummy values nore unresolved tokens)\n      const isNotUnresolvedToken = (x: string) => !Token.isUnresolved(x);\n      const isNotDummy = (x: string) => !x.startsWith('dummy');\n      if (this.props.vpc.availabilityZones.every(isNotUnresolvedToken) &&\n      this.props.vpc.availabilityZones.every(isNotDummy) &&\n      !this.props.vpc.availabilityZones.includes(this.props.vpcSubnets.availabilityZones[0])) {\n        throw new ValidationError('vpcSubnets.availabilityZones specified is not in vpc.availabilityZones.', this);\n      }\n    }\n  }\n\n  /**\n   * create access point from this filesystem\n   */\n  @MethodMetadata()\n  public addAccessPoint(id: string, accessPointOptions: AccessPointOptions = {}): AccessPoint {\n    return new AccessPoint(this, id, {\n      fileSystem: this,\n      ...accessPointOptions,\n    });\n  }\n}", "language": "typescript"}
{"input": "Configuration for Smithy-based MCP targets This configuration exposes a Smithy-modeled API as MCP tools, allowing the gateway to transform Smithy operations into tool calls.", "output": "export class SmithyTargetConfiguration extends McpTargetConfiguration {\n  /**\n   * Create a Smithy target configuration\n   *\n   * @param smithyModel The Smithy model schema\n   * @returns A new SmithyTargetConfiguration instance\n   */\n  public static create(smithyModel: ApiSchema): SmithyTargetConfiguration {\n    return new SmithyTargetConfiguration(smithyModel);\n  }\n\n  public readonly targetType = McpTargetType.SMITHY_MODEL;\n\n  /**\n   * The Smithy model that defines the API\n   */\n  public readonly smithyModel: ApiSchema;\n\n  constructor(smithyModel: ApiSchema) {\n    super();\n    this.smithyModel = smithyModel;\n  }\n\n  /**\n   * Binds this configuration to a construct scope\n   * Sets up necessary permissions for the gateway to access the Smithy model\n   *\n   * @param scope The construct scope\n   * @param gateway The gateway that will use this target\n   */\n  public bind(scope: Construct, gateway: IGateway): TargetConfigurationConfig {\n    // Bind the Smithy model\n    this.smithyModel.bind(scope);\n    // Grant permissions to gateway role if schema is in S3\n    this.smithyModel.grantPermissionsToRole(gateway.role);\n\n    return { bound: true };\n  }\n\n  /**\n   * Renders the MCP-specific configuration\n   */\n  protected renderMcpConfiguration(): any {\n    return {\n      smithyModel: this.smithyModel._render(),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, WAF, EventBridge resources", "output": "export class asyncLambdaStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n        super(scope, id, props);\n\n        // EventBridge event as an event source for a SNS topic and a SQS queue\n        const rule = new events.Rule(this, 'Rule', {\n            eventPattern: {\n                source: ['aws.ecs']\n            }\n        });\n\n        // Shared code asset\n        const code = Code.fromAsset(path.join(__dirname, '../assets/lambda-functions'));\n\n        // Lambda Function that will be invoked asynchronously when there is any event that matches the rule\n        const eventsFunction = new Function(this, 'EventFunction', {\n            runtime: Runtime.NODEJS_20_X,\n            code,\n            handler: 'events_handler.handler'\n        });\n        const eventsDLQ = new sqs.Queue(this, 'LambdaDLQ');\n        rule.addTarget(new eventsTargets.LambdaFunction(eventsFunction, {\n            deadLetterQueue: eventsDLQ,\n            maxEventAge: cdk.Duration.minutes(2),\n            retryAttempts: 2\n        }));\n\n        // Lambda Function that will be invoked asynchronously by a SNS topic\n        const topic = new sns.Topic(this, 'Topic');\n        rule.addTarget(new eventsTargets.SnsTopic(topic, {\n            deadLetterQueue: eventsDLQ,\n            maxEventAge: cdk.Duration.minutes(2),\n            retryAttempts: 2\n        }));\n\n        const topicFunction = new Function(this, 'TopicLambdaFunction', {\n            runtime: Runtime.NODEJS_20_X,\n            code,\n            handler: 'topic_message_handler.handler'\n        });\n        const topicDLQ = new sqs.Queue(this, 'TopicDLQ');\n        topicFunction.addEventSource(new SnsEventSource(topic, {\n            deadLetterQueue: topicDLQ\n        }));\n\n        // Lambda Function that will be invoked asynchronously with the event source of a SQS queue\n        const queue = new sqs.Queue(this, 'JobQueue');\n        rule.addTarget(new eventsTargets.SqsQueue(queue, {\n            deadLetterQueue: eventsDLQ,\n            maxEventAge: cdk.Duration.minutes(2),\n            retryAttempts: 2\n        }));\n\n        const queueFunction = new Function(this, 'QueueLambdaFunction', {\n            runtime: Runtime.NODEJS_20_X,\n            code,\n            handler: 'queue_message_handler.handler'\n        });\n        queueFunction.addEventSource(new SqsEventSource(queue, {\n            batchSize: 5,\n            maxBatchingWindow: cdk.Duration.seconds(5),\n            reportBatchItemFailures: true\n        }));\n    }\n}", "language": "typescript"}
{"input": "CDK class ChatbotInteg for AWS resource management", "output": "class ChatbotInteg extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const slackChannel = new chatbot.SlackChannelConfiguration(this, 'MySlackChannel', {\n      slackChannelConfigurationName: 'test-channel',\n      slackWorkspaceId: 'T49239U4W', // modify to your slack workspace id\n      slackChannelId: 'C0187JABUE9', // modify to your slack channel id\n      loggingLevel: chatbot.LoggingLevel.NONE,\n    });\n\n    slackChannel.addToRolePolicy(new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      actions: [\n        's3:GetObject',\n      ],\n      resources: ['arn:aws:s3:::abc/xyz/123.txt'],\n    }));\n  }\n}", "language": "typescript"}
{"input": "Configuration options for scaling a capacity provider, including scaling mode and policies.", "output": "export class ScalingOptions {\n  /**\n   * Creates scaling options where the capacity provider manages scaling automatically.\n   */\n  public static auto(): ScalingOptions {\n    return new ScalingOptions('Auto');\n  }\n\n  /**\n   * Creates manual scaling options with custom target tracking scaling policies. At least one policy is required.\n   *\n   * @param scalingPolicies The target tracking scaling policies to use for manual scaling.\n   */\n  public static manual(scalingPolicies: TargetTrackingScalingPolicy[]): ScalingOptions {\n    return new ScalingOptions('Manual', scalingPolicies);\n  }\n\n  /**\n   * The scaling mode for the capacity provider.\n   */\n  public readonly scalingMode: string;\n\n  /**\n   * The target tracking scaling policies used when scaling mode is 'Manual'.\n   */\n  public readonly scalingPolicies?: TargetTrackingScalingPolicy[];\n\n  /**\n   * Creates a new ScalingOptions.\n   *\n   * @param scalingMode The scaling mode for the capacity provider\n   * @param scalingPolicies The target tracking scaling policies for manual scaling\n   */\n  private constructor(\n    scalingMode: string,\n    scalingPolicies?: TargetTrackingScalingPolicy[],\n  ) {\n    this.scalingMode = scalingMode;\n    this.scalingPolicies = scalingPolicies;\n  }\n}", "language": "typescript"}
{"input": "CDK class _Alias for AWS resource management", "output": "class _Alias extends AliasBase {\n      public get aliasName() { return attrs.aliasName; }\n      public get aliasTargetKey() { return attrs.aliasTargetKey; }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates WAF, CloudFormation, Config resources", "output": "export class CloudFormationStackNotificationCheck extends ManagedRule {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.CloudFormationStackNotificationCheck';\n\n  constructor(scope: Construct, id: string, props: CloudFormationStackNotificationCheckProps = {}) {\n    if (props.topics && props.topics.length > 5) {\n      throw new ValidationError('At most 5 topics can be specified.', scope);\n    }\n\n    super(scope, id, {\n      ...props,\n      identifier: ManagedRuleIdentifiers.CLOUDFORMATION_STACK_NOTIFICATION_CHECK,\n      inputParameters: props.topics && props.topics.reduce(\n        (params, topic, idx) => ({ ...params, [`snsTopic${idx + 1}`]: topic.topicArn }),\n        {},\n      ),\n      ruleScope: RuleScope.fromResources([ResourceType.CLOUDFORMATION_STACK]),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "NAT providers Determines what type of NAT provider to create, either NAT gateways or NAT instance.", "output": "class NatProvider {\n  /**\n   * Use NAT Gateways to provide NAT services for your VPC\n   *\n   * NAT gateways are managed by AWS.\n   *\n   * @see https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat-gateway.html\n   */\n  public static gateway(props: NatGatewayProps = {}): NatProvider {\n    return new NatGatewayProvider(props);\n  }\n\n  /**\n   * Use NAT instances to provide NAT services for your VPC\n   *\n   * NAT instances are managed by you, but in return allow more configuration.\n   *\n   * Be aware that instances created using this provider will not be\n   * automatically replaced if they are stopped for any reason. You should implement\n   * your own NatProvider based on AutoScaling groups if you need that.\n   *\n   * @see https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html\n   *\n   * @deprecated use instanceV2. 'instance' is deprecated since NatInstanceProvider\n   * uses a instance image that has reached EOL on Dec 31 2023\n   */\n  public static instance(props: NatInstanceProps): NatInstanceProvider {\n    return new NatInstanceProvider(props);\n  }\n\n  /**\n   * Use NAT instances to provide NAT services for your VPC\n   *\n   * NAT instances are managed by you, but in return allow more configuration.\n   *\n   * Be aware that instances created using this provider will not be\n   * automatically replaced if they are stopped for any reason. You should implement\n   * your own NatProvider based on AutoScaling groups if you need that.\n   *\n   * @see https://docs.aws.amazon.com/vpc/latest/userguide/VPC_NAT_Instance.html\n   */\n  public static instanceV2(props: NatInstanceProps): NatInstanceProviderV2 {\n    return new NatInstanceProviderV2(props);\n  }\n\n  /**\n   * Return list of gateways spawned by the provider\n   */\n  public abstract readonly configuredGateways: GatewayConfig[];\n\n  /**\n   * Called by the VPC to configure NAT\n   *\n   * Don't call this directly, the VPC will call it automatically.\n   */\n  public abstract configureNat(options: ConfigureNatOptions): void;\n\n  /**\n   * Configures subnet with the gateway\n   *\n   * Don't call this directly, the VPC will call it automatically.\n   */\n  public abstract configureSubnet(subnet: PrivateSubnet): void;\n}", "language": "typescript"}
{"input": "CDK class MetadataUpdater for AWS resource management", "output": "class MetadataUpdater {\n  protected project: Project;\n\n  constructor(dir: string) {\n    const projectDir = path.resolve(__dirname, dir);\n\n    // Initialize a ts-morph Project\n    this.project = new Project({\n      tsConfigFilePath: path.resolve(__dirname, \"../tsconfig.json\"),\n      manipulationSettings: {\n        quoteKind: QuoteKind.Single,\n        indentationText: IndentationText.TwoSpaces\n      },\n    });\n    this.project.addSourceFilesAtPaths(this.readTypescriptFiles(projectDir));\n\n    console.log(\"Transformation complete.\");\n  }\n\n  public abstract execute(): void;\n\n  /**\n   * Recursively collect all .ts files from a given directory.\n   */\n  private readTypescriptFiles(dir: string, filesList: string[] = []) {\n    const files = fs.readdirSync(dir);\n\n    files.forEach((file) => {\n      const filePath = path.join(dir, file);\n      if (fs.statSync(filePath).isDirectory()) {\n        // Check if this directory is in the list of directories to skip\n        if (!DIRECTORIES_TO_SKIP.includes(file)) {\n          this.readTypescriptFiles(filePath, filesList);\n        }\n      } else if (\n        filePath.endsWith(\".ts\") &&\n        !filePath.endsWith(\".generated.ts\") &&\n        !filePath.endsWith(\".d.ts\") &&\n        !file.includes(\"test\")\n      ) {\n        filesList.push(filePath);\n      }\n    });\n\n    return filesList;\n  }\n\n  /**\n   * Recursively checks if a given type is a descendant of 'Resource'.\n   */\n  private isDescendantOfResource(type: any): boolean {\n    // Check if the current type is 'Resource'\n    if (type.getSymbol().getName() === 'Resource') {\n      return true;\n    }\n\n    // Get the base types (parent types)\n    const baseTypes = type.getBaseTypes();\n    for (const baseType of baseTypes) {\n      if (this.isDescendantOfResource(baseType)) {\n        return true;\n      }\n    }\n\n    // If no base type is 'Resource', return false\n    return false;\n  }\n\n  /**\n   * Parse and transform a file using ts-morph.\n   */\n  protected getCdkResourceClasses(filePath: string): ResourceClass[] {\n    const sourceFile = this.project.getSourceFile(filePath);\n    if (!sourceFile) return [];\n\n    const resourceClasses: ResourceClass[] = [];\n\n    sourceFile.forEachChild((node) => {\n      if (node instanceof ClassDeclaration) {\n        const symbol = node.getSymbol();\n        if (symbol) {\n          const className = symbol.getName(); // Correct way to get the name\n          const fqnClassName = symbol.getFullyQualifiedName();\n\n          // Check if the class is abstract by inspecting modifiers\n          const isAbstract = node.getModifiers()?.some((mod) => mod.getText() === \"abstract\");\n          if (isAbstract) {\n            return;\n          }\n\n          // Check if the class or its subclasses extends Resource\n          const type = node.getType();\n          if (this.isDescendantOfResource(type)) {\n            resourceClasses.push({ sourceFile, filePath, node, className, fqnClassName });\n          }\n        }\n      }\n    });\n\n    return resourceClasses;\n  }\n\n  /**\n   * Write the file content for the enum metadats.\n   * @param outputPath The file to write to\n   * @param values The values, as a nested dictionary, to write.\n   */\n  protected writeFileContent(outputPath: string, values: Record<string, Record<string, (string | number)[]>> = {}) {\n    // Sort the keys of the enumlikes object\n    const sortedValues = Object.keys(values).sort().reduce<Record<string, Record<string, (string | number)[]>>>((acc, key) => {\n      acc[key] = values[key];\n      return acc;\n    }, {});\n    const content = JSON.stringify(sortedValues, null, 2);\n\n    // Write the generated file\n    fs.writeFileSync(outputPath, content);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Cognito, API Gateway, CloudFormation operations", "output": "const createApiTemplate = (userPoolId: string) => {\n      const stack = new Stack();\n      stack.node.setContext('@aws-cdk/aws-apigateway:authorizerChangeDeploymentLogicalId', true);\n\n      const userPool = new cognito.UserPool(stack, userPoolId);\n\n      const auth = new CognitoUserPoolsAuthorizer(stack, 'myauthorizer', {\n        resultsCacheTtl: Duration.seconds(0),\n        cognitoUserPools: [userPool],\n      });\n\n      const restApi = new RestApi(stack, 'myrestapi');\n      restApi.root.addMethod('ANY', undefined, {\n        authorizer: auth,\n        authorizationType: AuthorizationType.COGNITO,\n      });\n\n      return Template.fromStack(stack);\n    }", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, SNS, CloudFormation resources", "output": "class ImportedStack extends Stack {\n  constructor(scope: App, id: string, props: ImportedStackProps) {\n    super(scope, id);\n\n    const importedApi = GraphqlApi.fromGraphqlApiAttributes(originalStack, 'ImportedApi', {\n      graphqlApiId: `${props.apiId}`,\n    });\n\n    const lambdaRole = new Role(this, 'lambdaRole', {\n      assumedBy: new ServicePrincipal('lambda.amazonaws.com'),\n    });\n    importedApi.grant(lambdaRole, IamResource.custom('types/Query/fields/getPost'), 'appsync:GraphQL');\n\n    const mutationLambdaRole = new Role(this, 'mutatioLambdaRole', {\n      assumedBy: new ServicePrincipal('lambda.amazonaws.com'),\n    });\n    importedApi.grantMutation(mutationLambdaRole);\n\n    const queryLambdaRole = new Role(this, 'queryLambdaRole', {\n      assumedBy: new ServicePrincipal('lambda.amazonaws.com'),\n    });\n    importedApi.grantQuery(queryLambdaRole);\n\n    const subscriptionLambdaRole = new Role(this, 'subscriptionLambdaRole', {\n      assumedBy: new ServicePrincipal('lambda.amazonaws.com'),\n    });\n    importedApi.grantSubscription(subscriptionLambdaRole);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, WAF, EventBridge resources", "output": "class ConsumerStack(Stack):\n    def __init__(self, scope: Construct, id: str, *, \n                app_name: str, \n                producer_account_id: str, \n                 **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create or reference the consumer event bus\n        consumer_event_bus = events.EventBus(\n            self, f\"{app_name}-consumer-event-bus\"\n        )\n\n        # Add policy to allow producer account to put events\n        consumer_event_bus.add_to_resource_policy(iam.PolicyStatement(\n            sid=\"allowProducerAccount\",\n            effect=iam.Effect.ALLOW,\n            principals=[iam.AccountPrincipal(producer_account_id)],\n            actions=[\"events:PutEvents\"],\n            resources=[consumer_event_bus.event_bus_arn]\n        ))\n\n        # Create consumer rules\n        consumer_rule = events.Rule(\n            self, f\"{app_name}-consumer-rule\",\n            event_bus=consumer_event_bus,\n            event_pattern=events.EventPattern(\n                source=['com.myapp.events'],\n                detail_type=['specific-event-type']\n            )\n        )\n\n        # Add target (e.g., CloudWatch)\n        log_group = logs.LogGroup(self, f\"{app_name}-consumer-logs\")\n        consumer_rule.add_target(targets.CloudWatchLogGroup(log_group))", "language": "python"}
{"input": "CDK class MatchCreator for AWS resource management", "output": "class MatchCreator {\n  private readonly parsedObj: { [key: string]: any };\n  constructor(obj: { [key: string]: any }) {\n    this.parsedObj = {\n      matcher: obj,\n    };\n  }\n\n  /**\n   * Return a Matcher that can be tested against the actual results.\n   * This will convert the encoded matchers into their corresponding\n   * assertions matcher.\n   *\n   * For example:\n   *\n   * ExpectedResult.objectLike({\n   *   Messages: [{\n   *     Body: Match.objectLike({\n   *       Elements: Match.arrayWith([{ Asdf: 3 }]),\n   *       Payload: Match.serializedJson({ key: 'value' }),\n   *     }),\n   *   }],\n   * });\n   *\n   * Will be encoded as:\n   * {\n   *   $ObjectLike: {\n   *     Messages: [{\n   *       Body: {\n   *         $ObjectLike: {\n   *           Elements: {\n   *             $ArrayWith: [{ Asdf: 3 }],\n   *           },\n   *           Payload: {\n   *             $SerializedJson: { key: 'value' }\n   *           }\n   *         },\n   *       },\n   *     }],\n   *   },\n   * }\n   *\n   * Which can then be parsed by this function. For each key (recursively)\n   * the parser will check if the value has one of the encoded matchers as a key\n   * and if so, it will set the value as the Matcher. So,\n   *\n   * {\n   *   Body: {\n   *     $ObjectLike: {\n   *       Elements: {\n   *         $ArrayWith: [{ Asdf: 3 }],\n   *       },\n   *       Payload: {\n   *         $SerializedJson: { key: 'value' }\n   *       }\n   *     },\n   *   },\n   * }\n   *\n   * Will be converted to\n   * {\n   *   Body: Match.objectLike({\n   *     Elements: Match.arrayWith([{ Asdf: 3 }]),\n   *     Payload: Match.serializedJson({ key: 'value' }),\n   *   }),\n   * }\n   */\n  public getMatcher(): Matcher {\n    try {\n      const final = JSON.parse(JSON.stringify(this.parsedObj), function(_k, v) {\n        const nested = Object.keys(v)[0];\n        switch (nested) {\n          case '$ArrayWith':\n            return Match.arrayWith(v[nested]);\n          case '$ObjectLike':\n            return Match.objectLike(v[nested]);\n          case '$StringLike':\n            return Match.stringLikeRegexp(v[nested]);\n          case '$SerializedJson':\n            return Match.serializedJson(v[nested]);\n          default:\n            return v;\n        }\n      });\n      if (Matcher.isMatcher(final.matcher)) {\n        return final.matcher;\n      }\n      return Match.exact(final.matcher);\n    } catch {\n      return Match.exact(this.parsedObj.matcher);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ClientVpnAuthorizationRule for AWS resource management", "output": "export class ClientVpnAuthorizationRule extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.ClientVpnAuthorizationRule';\n\n  constructor(scope: Construct, id: string, props: ClientVpnAuthorizationRuleProps) {\n    if (!props.clientVpnEndoint && !props.clientVpnEndpoint) {\n      throw new ValidationError(\n        'ClientVpnAuthorizationRule: either clientVpnEndpoint or clientVpnEndoint (deprecated) must be specified',\n        scope,\n      );\n    }\n    if (props.clientVpnEndoint && props.clientVpnEndpoint) {\n      throw new ValidationError(\n        'ClientVpnAuthorizationRule: either clientVpnEndpoint or clientVpnEndoint (deprecated) must be specified' +\n          ', but not both',\n        scope,\n      );\n    }\n    const clientVpnEndpoint = props.clientVpnEndoint || props.clientVpnEndpoint;\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    new CfnClientVpnAuthorizationRule(this, 'Resource', {\n      clientVpnEndpointId: clientVpnEndpoint!.clientVpnEndpointRef.clientVpnEndpointId,\n      targetNetworkCidr: props.cidr,\n      accessGroupId: props.groupId,\n      authorizeAllGroups: !props.groupId,\n      description: props.description,\n    });\n  }\n}", "language": "typescript"}
{"input": "A collection of test cases. Each test case file should contain exactly one instance of this class.", "output": "export class IntegTest extends Construct {\n  /**\n   * Make assertions on resources in this test case\n   */\n  public readonly assertions: IDeployAssert;\n  private readonly testCases: IntegTestCase[];\n  private readonly enableLookups?: boolean;\n  constructor(scope: Construct, id: string, props: IntegTestProps) {\n    super(scope, id);\n\n    this.enableLookups = props.enableLookups;\n    const defaultTestCase = new IntegTestCase(this, 'DefaultTest', {\n      stacks: props.testCases.filter(stack => !IntegTestCaseStack.isIntegTestCaseStack(stack)),\n      hooks: props.hooks,\n      regions: props.regions,\n      diffAssets: props.diffAssets,\n      allowDestroy: props.allowDestroy,\n      cdkCommandOptions: props.cdkCommandOptions,\n      stackUpdateWorkflow: props.stackUpdateWorkflow,\n      assertionStack: props.assertionStack,\n    });\n    this.assertions = defaultTestCase.assertions;\n\n    this.testCases = [\n      defaultTestCase,\n      ...props.testCases\n        .filter(stack => IntegTestCaseStack.isIntegTestCaseStack(stack))\n        .map(stack => (stack as IntegTestCaseStack)._testCase),\n    ];\n\n    this.node.addValidation({\n      validate: () => {\n        attachCustomSynthesis(this, {\n          onSynthesize: (session: ISynthesisSession) => {\n            const synthesizer = new IntegManifestSynthesizer(this.testCases, this.enableLookups);\n            synthesizer.synthesize(session);\n          },\n        });\n        return [];\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "The amount of memory reserved for each instance of your App Runner service.", "output": "export class Memory {\n  /**\n   * 0.5 GB(for 0.25 vCPU)\n   */\n  public static readonly HALF_GB = Memory.of('0.5 GB');\n\n  /**\n   * 1 GB(for 0.25 or 0.5 vCPU)\n   */\n  public static readonly ONE_GB = Memory.of('1 GB');\n\n  /**\n   * 2 GB(for 1 vCPU)\n   */\n  public static readonly TWO_GB = Memory.of('2 GB');\n\n  /**\n   * 3 GB(for 1 vCPU)\n   */\n  public static readonly THREE_GB = Memory.of('3 GB');\n\n  /**\n   * 4 GB(for 1 or 2 vCPU)\n   */\n  public static readonly FOUR_GB = Memory.of('4 GB');\n\n  /**\n   * 6 GB(for 2 vCPU)\n   */\n  public static readonly SIX_GB = Memory.of('6 GB');\n\n  /**\n   * 8 GB(for 4 vCPU)\n   */\n  public static readonly EIGHT_GB = Memory.of('8 GB');\n\n  /**\n   * 10 GB(for 4 vCPU)\n   */\n  public static readonly TEN_GB = Memory.of('10 GB');\n\n  /**\n   * 12 GB(for 4 vCPU)\n   */\n  public static readonly TWELVE_GB = Memory.of('12 GB');\n\n  /**\n   * Custom Memory unit\n   *\n   * @param unit custom Memory unit\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-apprunner-service-instanceconfiguration.html#cfn-apprunner-service-instanceconfiguration-memory\n   */\n  public static of(unit: string): Memory {\n    const numericPatterns = ['512', '1024', '2048', '3072', '4096', '6144', '8192', '10240', '12288'];\n    const unitPatterns = ['0.5 GB', '1 GB', '2 GB', '3 GB', '4 GB', '6 GB', '8 GB', '10 GB', '12 GB'];\n    const allowedPatterns = numericPatterns.concat(unitPatterns);\n    const isValidValue = allowedPatterns.some(\n      (pattern) => pattern === unit,\n    );\n    if (!isValidValue) {\n      throw new cdk.UnscopedValidationError('Memory value is invalid');\n    }\n\n    return new Memory(unit);\n  }\n\n  /**\n   *\n   * @param unit The unit of memory.\n   */\n  private constructor(public readonly unit: string) { }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, Kinesis, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\n        \"SELECT * FROM 'device/+/data'\",\n      ),\n    });\n\n    const stream = new kinesis.Stream(this, 'MyStream', {\n      shardCount: 3,\n    });\n    topicRule.addAction(new actions.KinesisPutRecordAction(stream, {\n      partitionKey: '${timestamp()}',\n    }));\n  }\n}", "language": "typescript"}
{"input": "Creates reference to already existing s3 bucket and lambda code", "output": "class LambdaS3Code(Stack):\n    def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        lambda_code_bucket = s3.Bucket.from_bucket_attributes(\n            self, 'LambdaCodeBucket',\n            bucket_name='my-lambda-code-bucket'\n        )\n\n        lambdaFn = lambda_.Function(\n            self, 'Singleton',\n            handler='index.main',\n            code=lambda_.S3Code(\n                bucket=lambda_code_bucket,\n                key='my-lambda.py'\n            ),\n            runtime=lambda_.Runtime.PYTHON_3_7,\n            timeout=Duration.seconds(300)\n        )", "language": "python"}
{"input": "Configuration for OpenAPI-based MCP targets This configuration exposes an OpenAPI/REST API as MCP tools, allowing the gateway to transform API operations into tool calls.", "output": "export class OpenApiTargetConfiguration extends McpTargetConfiguration {\n  /**\n   * Create an OpenAPI target configuration\n   *\n   * @param apiSchema The OpenAPI schema\n   * @param validateSchema Whether to validate the OpenAPI schema (only applies to inline schemas)\n   * @returns A new OpenApiTargetConfiguration instance\n   */\n  public static create(apiSchema: ApiSchema, validateSchema?: boolean): OpenApiTargetConfiguration {\n    return new OpenApiTargetConfiguration(apiSchema, validateSchema);\n  }\n\n  public readonly targetType = McpTargetType.OPENAPI_SCHEMA;\n\n  /**\n   * The OpenAPI schema that defines the API\n   */\n  public readonly apiSchema: ApiSchema;\n\n  /**\n   * Whether to validate the OpenAPI schema\n   */\n  private readonly shouldValidateSchema: boolean;\n\n  constructor(apiSchema: ApiSchema, validateSchema?: boolean) {\n    super();\n    this.apiSchema = apiSchema;\n    this.shouldValidateSchema = validateSchema ?? true;\n  }\n\n  /**\n   * Binds this configuration to a construct scope\n   * Sets up necessary permissions for the gateway to access the API schema\n   *\n   * @param scope The construct scope\n   * @param gateway The gateway that will use this target\n   */\n  public bind(scope: Construct, gateway: IGateway): TargetConfigurationConfig {\n    if (this.shouldValidateSchema) {\n      // For inline schemas\n      if (this.apiSchema.inlineSchema) {\n        const errors = validateOpenApiSchema({\n          schema: this.apiSchema.inlineSchema,\n          schemaName: 'OpenAPI schema for target',\n        });\n        if (errors.length > 0) {\n          throw new ValidationError(`OpenAPI schema validation failed:\\n${errors.join('\\n')}`);\n        }\n      } else if (this.apiSchema instanceof AssetApiSchema) {\n        // For asset schemas (local files)\n        try {\n          const schemaContent = fs.readFileSync(this.apiSchema._getFilePath(), 'utf-8');\n          const errors = validateOpenApiSchema({\n            schema: schemaContent,\n            schemaName: `OpenAPI schema from file ${this.apiSchema._getFilePath()}`,\n          });\n          if (errors.length > 0) {\n            throw new ValidationError(`OpenAPI schema validation failed:\\n${errors.join('\\n')}`);\n          }\n        } catch (e) {\n          if (e instanceof ValidationError) {\n            throw e;\n          }\n          throw new ValidationError(\n            `Failed to read OpenAPI schema from ${this.apiSchema._getFilePath()}: ${e instanceof Error ? e.message : String(e)}`,\n          );\n        }\n      }\n      // S3 schemas cannot be validated at synthesis time\n    }\n\n    // Bind the API schema\n    this.apiSchema.bind(scope);\n    // Grant permissions to gateway role if schema is in S3\n    this.apiSchema.grantPermissionsToRole(gateway.role);\n\n    return { bound: true };\n  }\n\n  /**\n   * Renders the MCP-specific configuration\n   */\n  protected renderMcpConfiguration(): any {\n    return {\n      openApiSchema: this.apiSchema._render(),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class StreamSource for AWS resource management", "output": "class StreamSource extends SourceWithDeadLetterTarget {\n  /**\n   * The ARN of the source resource.\n   */\n  readonly sourceArn: string;\n  /**\n   * Base parameters for streaming sources.\n   */\n  readonly sourceParameters: StreamSourceParameters;\n\n  constructor(sourceArn: string, sourceParameters: StreamSourceParameters) {\n    super(sourceArn, sourceParameters.deadLetterTarget);\n    this.sourceArn = sourceArn;\n    this.sourceParameters = sourceParameters;\n\n    validateBatchSize(this.sourceParameters.batchSize);\n    validateMaximumBatchingWindow(this.sourceParameters.maximumBatchingWindow?.toSeconds());\n    validateMaximumRecordAge(this.sourceParameters.maximumRecordAge?.toSeconds());\n    validateMaximumRetryAttempts(this.sourceParameters.maximumRetryAttempts);\n    validateParallelizationFactor(this.sourceParameters.parallelizationFactor);\n  }\n}", "language": "typescript"}
{"input": "example tests. To run these tests, uncomment this file along with the example resource in cdk_iot_thing/cdk_iot_thing_stack.py", "output": "def test_sqs_queue_created():\n    app = core.App()\n    stack = CdkIotThingStack(app, \"cdk-iot-thing\")\n    template = assertions.Template.from_stack(stack)", "language": "python"}
{"input": "Event Input that is directly derived from the construct", "output": "class LiteralEventInput extends RuleTargetInput {\n  constructor(private readonly props: RuleTargetInputProperties) {\n    super();\n  }\n\n  /**\n   * Return the input properties for this input object\n   */\n  public bind(_rule: IRuleRef): RuleTargetInputProperties {\n    return this.props;\n  }\n}", "language": "typescript"}
{"input": "Class for building the FilterPolicy by avoiding union types", "output": "class FilterOrPolicy {\n  /**\n   * Filter of MessageBody\n   */\n  public static filter(filter: SubscriptionFilter) {\n    return new Filter(filter);\n  }\n\n  /**\n   * Policy of MessageBody\n   */\n  public static policy(policy: { [attribute: string]: FilterOrPolicy }) {\n    return new Policy(policy);\n  }\n\n  /**\n   * Type switch for disambiguating between subclasses\n   */\n  abstract readonly type: FilterOrPolicyType;\n\n  /**\n   * Check if instance is `Policy` type\n   */\n  public isPolicy(): this is Policy {\n    return this.type === FilterOrPolicyType.POLICY;\n  }\n\n  /**\n   * Check if instance is `Filter` type\n   */\n  public isFilter(): this is Filter {\n    return this.type === FilterOrPolicyType.FILTER;\n  }\n}", "language": "typescript"}
{"input": "CDK class MustIgnoreJunitXml for AWS resource management", "output": "export class MustIgnoreJunitXml extends ValidationRule {\n  public readonly name = 'ignore/junit';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldContain(this.name, pkg, '.npmignore', 'junit.xml');\n    fileShouldContain(this.name, pkg, '.gitignore', 'junit.xml');\n  }\n}", "language": "typescript"}
{"input": "JSII .NET packageId is required and must look sane", "output": "export class JSIIDotNetPackageIdIsRequired extends ValidationRule {\n  public readonly name = 'jsii/dotnet';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    const dotnet = deepGet(pkg.json, ['jsii', 'targets', 'dotnet', 'namespace']) as string | undefined;\n    const moduleName = cdkModuleName(pkg.json.name);\n    expectJSON(this.name, pkg, 'jsii.targets.dotnet.packageId', moduleName.dotnetPackageId, /\\./g, /* case insensitive*/ true);\n\n    if (dotnet) {\n      const actualPrefix = dotnet.split('.').slice(0, 2).join('.');\n      const expectedPrefix = moduleName.dotnetPackageId.split('.').slice(0, 2).join('.');\n      if (actualPrefix !== expectedPrefix) {\n        pkg.report({\n          ruleName: this.name,\n          message: `.NET packageId must share the first two segments of the default namespace, '${expectedPrefix}' vs '${actualPrefix}'`,\n          fix: () => deepSet(pkg.json, ['jsii', 'targets', 'dotnet', 'packageId'], moduleName.dotnetPackageId),\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class HiddenCfnResource for AWS resource management", "output": "class HiddenCfnResource extends core.CfnResource {\n      protected shouldSynthesize() {\n        return false;\n      }\n    }", "language": "typescript"}
{"input": "CDK class LustreFileSystem for AWS resource management", "output": "export class LustreFileSystem extends FileSystemBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-fsx.LustreFileSystem';\n\n  /**\n   * Import an existing FSx for Lustre file system from the given properties.\n   */\n  public static fromLustreFileSystemAttributes(scope: Construct, id: string, attrs: FileSystemAttributes): IFileSystem {\n    class Import extends FileSystemBase {\n      public readonly dnsName = attrs.dnsName;\n      public readonly fileSystemId = attrs.fileSystemId;\n      public readonly connections = LustreFileSystem.configureConnections(attrs.securityGroup);\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The default FSx file system type used by FSx for Lustre.\n   */\n  private static readonly DEFAULT_FILE_SYSTEM_TYPE: string = 'LUSTRE';\n\n  /**\n   * The default ports the file system listens on. Actual port list is: [988, 1021, 1022, 1023]\n   */\n  private static readonly DEFAULT_PORT_RANGE = { startPort: 988, endPort: 1023 };\n\n  /**\n   * Configures a Connections object with all the ports required by FSx for Lustre\n   */\n  private static configureConnections(securityGroup: ISecurityGroup): Connections {\n    const connections = new Connections({\n      securityGroups: [securityGroup],\n      defaultPort: Port.tcpRange(\n        LustreFileSystem.DEFAULT_PORT_RANGE.startPort,\n        LustreFileSystem.DEFAULT_PORT_RANGE.endPort),\n    });\n\n    return connections;\n  }\n\n  /**\n   * The security groups/rules used to allow network connections to the file system.\n   */\n  public readonly connections: Connections;\n\n  /**\n   * The DNS name assigned to this file system.\n   */\n  public readonly dnsName: string;\n\n  /**\n   * The ID that AWS assigns to the file system.\n   */\n  public readonly fileSystemId: string;\n\n  /**\n   * The mount name of the file system, generated by FSx\n   *\n   * @attribute LustreMountName\n   */\n  public readonly mountName: string;\n\n  /**\n   * The encapsulated L1 file system.\n   */\n  private readonly fileSystem: CfnFileSystem;\n\n  constructor(scope: Construct, id: string, props: LustreFileSystemProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.validateProps(props);\n\n    const updatedLustureProps = {\n      importedFileChunkSize: props.lustreConfiguration.importedFileChunkSizeMiB,\n      weeklyMaintenanceStartTime: props.lustreConfiguration.weeklyMaintenanceStartTime?.toTimestamp(),\n      automaticBackupRetentionDays: props.lustreConfiguration.automaticBackupRetention?.toDays(),\n      dailyAutomaticBackupStartTime: props.lustreConfiguration.dailyAutomaticBackupStartTime?.toTimestamp(),\n      driveCacheType: props.lustreConfiguration.driveCacheType ?? (props.storageType === StorageType.HDD ? DriveCacheType.NONE : undefined),\n    };\n    const lustreConfiguration = Object.assign({}, props.lustreConfiguration, updatedLustureProps);\n\n    const securityGroup = (props.securityGroup || new SecurityGroup(this, 'FsxLustreSecurityGroup', {\n      vpc: props.vpc,\n    }));\n    securityGroup.addIngressRule(\n      securityGroup,\n      Port.tcpRange(LustreFileSystem.DEFAULT_PORT_RANGE.startPort, LustreFileSystem.DEFAULT_PORT_RANGE.endPort));\n    this.connections = LustreFileSystem.configureConnections(securityGroup);\n\n    this.fileSystem = new CfnFileSystem(this, 'Resource', {\n      fileSystemType: LustreFileSystem.DEFAULT_FILE_SYSTEM_TYPE,\n      subnetIds: [props.vpcSubnet.subnetId],\n      backupId: props.backupId,\n      kmsKeyId: (props.kmsKey ? props.kmsKey.keyRef.keyId : undefined),\n      lustreConfiguration,\n      securityGroupIds: [securityGroup.securityGroupId],\n      storageCapacity: props.storageCapacityGiB,\n      fileSystemTypeVersion: props.fileSystemTypeVersion,\n      storageType: props.storageType,\n    });\n    this.fileSystem.applyRemovalPolicy(props.removalPolicy);\n\n    this.fileSystemId = this.fileSystem.ref;\n    this.dnsName = `${this.fileSystemId}.fsx.${this.env.region}.${Aws.URL_SUFFIX}`;\n    this.mountName = this.fileSystem.attrLustreMountName;\n  }\n\n  /**\n   * Validates the props provided for a new FSx for Lustre file system.\n   */\n  private validateProps(props: LustreFileSystemProps) {\n    const lustreConfiguration = props.lustreConfiguration;\n    const deploymentType = lustreConfiguration.deploymentType;\n    const perUnitStorageThroughput = lustreConfiguration.perUnitStorageThroughput;\n\n    // Make sure the import path is valid before validating the export path\n    this.validateImportPath(lustreConfiguration.importPath);\n    this.validateExportPath(lustreConfiguration.exportPath, lustreConfiguration.importPath);\n\n    this.validateImportedFileChunkSize(lustreConfiguration.importedFileChunkSizeMiB);\n    this.validateAutoImportPolicy(deploymentType, lustreConfiguration.importPath, lustreConfiguration.autoImportPolicy);\n\n    this.validateAutomaticBackupRetention(deploymentType, lustreConfiguration.automaticBackupRetention);\n\n    this.validateDailyAutomaticBackupStartTime(lustreConfiguration.automaticBackupRetention, lustreConfiguration.dailyAutomaticBackupStartTime);\n    this.validatePerUnitStorageThroughput(deploymentType, perUnitStorageThroughput, props.storageType);\n    this.validateStorageCapacity(deploymentType, props.storageCapacityGiB, props.storageType, perUnitStorageThroughput);\n    this.validateStorageType(deploymentType, props.storageType);\n    this.validateDriveCacheType(deploymentType, props.storageType, lustreConfiguration.driveCacheType);\n    this.validateFiileSystemTypeVersion(deploymentType, props.fileSystemTypeVersion);\n  }\n\n  /**\n   * Validates the drive cache type is only set for the PERSISTENT_1 deployment type and HDD storage type.\n   */\n  private validateDriveCacheType(deploymentType: LustreDeploymentType, storageType?: StorageType, driveCacheType?: DriveCacheType): void {\n    if (!driveCacheType) return;\n\n    if (deploymentType !== LustreDeploymentType.PERSISTENT_1 || storageType !== StorageType.HDD) {\n      throw new ValidationError(`driveCacheType can only be set for PERSISTENT_1 HDD storage type, got: ${deploymentType} and ${storageType}`, this);\n    }\n  }\n\n  /**\n   * Validates if the storage type corresponds to the appropriate deployment type.\n   */\n  private validateStorageType(deploymentType: LustreDeploymentType, storageType?: StorageType): void {\n    if (!storageType) return;\n\n    if (storageType === StorageType.HDD && deploymentType !== LustreDeploymentType.PERSISTENT_1) {\n      throw new ValidationError(`Storage type HDD is only supported for PERSISTENT_1 deployment type, got: ${deploymentType}`, this);\n    }\n  }\n\n  /**\n   * Validates the file system type version\n   */\n  private validateFiileSystemTypeVersion(deploymentType: LustreDeploymentType, fileSystemTypeVersion?: FileSystemTypeVersion): void {\n    if (fileSystemTypeVersion === undefined) {\n      return;\n    }\n\n    if (fileSystemTypeVersion === FileSystemTypeVersion.V_2_10) {\n      if (!deploymentType.startsWith('SCRATCH') && deploymentType !== LustreDeploymentType.PERSISTENT_1) {\n        throw new ValidationError('fileSystemTypeVersion V_2_10 is only supported for SCRATCH and PERSISTENT_1 deployment types', this);\n      }\n    }\n\n    // TODO: Add validation for V_2_12 with PERSISTENT_2 deployment mode and metadata configuration mode when metadata configuration is supported.\n  }\n\n  /**\n   * Validates the auto import policy\n   */\n  private validateAutoImportPolicy(deploymentType: LustreDeploymentType, importPath?: string, autoImportPolicy?: LustreAutoImportPolicy): void {\n    if (autoImportPolicy === undefined) { return; }\n    if (importPath === undefined) {\n      throw new ValidationError('autoImportPolicy requires importPath to be defined', this);\n    }\n    if (deploymentType === LustreDeploymentType.PERSISTENT_2) {\n      throw new ValidationError('autoImportPolicy is not supported with PERSISTENT_2 deployments', this);\n    }\n  }\n\n  /**\n   * Validates the export path is in the correct format and matches the import path.\n   */\n  private validateExportPath(exportPath?: string, importPath?: string): void {\n    if (exportPath === undefined) { return; }\n    if (importPath === undefined) {\n      throw new ValidationError('Cannot define an export path without also defining an import path', this);\n    }\n\n    if (Token.isUnresolved(exportPath) && Token.isUnresolved(importPath)) { return; }\n\n    if (Token.isUnresolved(importPath) !== Token.isUnresolved(exportPath)) {\n      throw new ValidationError('The importPath and exportPath must each be Tokens or not Tokens, you cannot use a mix', this);\n    }\n    if (!exportPath.startsWith(importPath)) {\n      throw new ValidationError(`The export path \"${exportPath}\" is invalid. Expecting the format: s3://{IMPORT_PATH}/optional-prefix`, this);\n    }\n    if (exportPath.length > 900) {\n      throw new ValidationError(`The export path \"${exportPath}\" exceeds the maximum length of 900 characters`, this);\n    }\n  }\n\n  /**\n   * Validates the importedFileChunkSize is in the correct range.\n   */\n  private validateImportedFileChunkSize(importedFileChunkSize?: number): void {\n    if (importedFileChunkSize === undefined) { return; }\n\n    if (importedFileChunkSize < 1 || importedFileChunkSize > 512000) {\n      throw new ValidationError(`importedFileChunkSize cannot be ${importedFileChunkSize} MiB. It must be a value from 1 to 512,000 MiB`, this);\n    }\n  }\n\n  /**\n   * Validates the import path is the correct format.\n   */\n  private validateImportPath(importPath?: string): void {\n    if (importPath === undefined || Token.isUnresolved(importPath)) { return; }\n\n    const regexp = /^s3:\\/\\//;\n\n    if (importPath.search(regexp) === -1) {\n      throw new ValidationError(`The import path \"${importPath}\" is invalid. Expecting the format: s3://{BUCKET_NAME}/optional-prefix`, this);\n    }\n    if (importPath.length > 900) {\n      throw new ValidationError(`The import path \"${importPath}\" exceeds the maximum length of 900 characters`, this);\n    }\n  }\n\n  /**\n   * Validates the perUnitStorageThroughput is defined correctly for the given deploymentType.\n   *\n   * @see https://docs.aws.amazon.com/fsx/latest/LustreGuide/managing-throughput-capacity.html\n   */\n  private validatePerUnitStorageThroughput(\n    deploymentType: LustreDeploymentType,\n    perUnitStorageThroughput?: number,\n    storageType?: StorageType,\n  ): void {\n    if (perUnitStorageThroughput === undefined) { return; }\n\n    if (deploymentType !== LustreDeploymentType.PERSISTENT_1 && deploymentType !== LustreDeploymentType.PERSISTENT_2) {\n      throw new ValidationError('perUnitStorageThroughput can only be set for the PERSISTENT_1/PERSISTENT_2 deployment types, received: ' + deploymentType, this);\n    }\n\n    if (deploymentType === LustreDeploymentType.PERSISTENT_1) {\n      if (storageType === StorageType.HDD && ![12, 40].includes(perUnitStorageThroughput)) {\n        throw new ValidationError(`perUnitStorageThroughput must be 12 or 40 MB/s/TiB for PERSISTENT_1 HDD storage, got: ${perUnitStorageThroughput}`, this);\n      }\n      if ((storageType === undefined || storageType === StorageType.SSD) && ![50, 100, 200].includes(perUnitStorageThroughput)) {\n        throw new ValidationError('perUnitStorageThroughput must be 50, 100, or 200 MB/s/TiB for PERSISTENT_1 SSD storage, got: ' + perUnitStorageThroughput, this);\n      }\n    }\n\n    if (deploymentType === LustreDeploymentType.PERSISTENT_2) {\n      if (![125, 250, 500, 1000].includes(perUnitStorageThroughput)) {\n        throw new ValidationError(`perUnitStorageThroughput must be 125, 250, 500 or 1000 MB/s/TiB for PERSISTENT_2 deployment type, got: ${perUnitStorageThroughput}`, this);\n      }\n    }\n  }\n\n  /**\n   * Validates the storage capacity is an acceptable value for the deployment type.\n   *\n   * @see https://docs.aws.amazon.com/fsx/latest/LustreGuide/increase-storage-capacity.html\n   */\n  private validateStorageCapacity(\n    deploymentType: LustreDeploymentType,\n    storageCapacity: number,\n    storageType?: StorageType,\n    perUnitStorageThroughput?: number,\n  ): void {\n    if (deploymentType === LustreDeploymentType.SCRATCH_1) {\n      if (![1200, 2400, 3600].includes(storageCapacity) && storageCapacity % 3600 !== 0) {\n        throw new ValidationError(`storageCapacity must be 1,200, 2,400, 3,600, or a multiple of 3,600 for SCRATCH_1 deployment type, got ${storageCapacity}.`, this);\n      }\n    }\n\n    if (\n      deploymentType === LustreDeploymentType.PERSISTENT_2\n      || deploymentType === LustreDeploymentType.SCRATCH_2\n    ) {\n      if (![1200, 2400].includes(storageCapacity) && storageCapacity % 2400 !== 0) {\n        throw new ValidationError(`storageCapacity must be 1,200, 2,400, or a multiple of 2,400 for SCRATCH_2 and PERSISTENT_2 deployment types, got ${storageCapacity}`, this);\n      }\n    }\n\n    if (deploymentType === LustreDeploymentType.PERSISTENT_1) {\n      if (storageType === StorageType.HDD) {\n        if (perUnitStorageThroughput === 12 && storageCapacity % 6000 !== 0) {\n          throw new ValidationError(`storageCapacity must be a multiple of 6,000 for PERSISTENT_1 HDD storage with 12 MB/s/TiB throughput, got ${storageCapacity}`, this);\n        }\n        if (perUnitStorageThroughput === 40 && storageCapacity % 1800 !== 0) {\n          throw new ValidationError(`storageCapacity must be a multiple of 1,800 for PERSISTENT_1 HDD storage with 40 MB/s/TiB throughput, got ${storageCapacity}`, this);\n        }\n      } else {\n        if (![1200, 2400].includes(storageCapacity) && storageCapacity % 2400 !== 0) {\n          throw new ValidationError(`storageCapacity must be 1,200, 2,400, or a multiple of 2,400 for PERSISTENT_1 SSD storage, got ${storageCapacity}`, this);\n        }\n      }\n    }\n  }\n\n  /**\n   * Validates the automaticBackupRetention with a non-scratch deployment class and an acceptable day value.\n   */\n  private validateAutomaticBackupRetention(deploymentType: LustreDeploymentType, automaticBackupRetention?: Duration): void {\n    if (automaticBackupRetention) {\n      const automaticBackupRetentionDays = automaticBackupRetention.toDays();\n\n      if ([LustreDeploymentType.SCRATCH_1, LustreDeploymentType.SCRATCH_2].includes(deploymentType) && automaticBackupRetentionDays > 0) {\n        throw new ValidationError('automatic backups is not supported on scratch file systems', this);\n      }\n\n      if (automaticBackupRetentionDays > 90) {\n        throw new ValidationError(`automaticBackupRetention period must be between 0 and 90 days. received: ${automaticBackupRetentionDays}`, this);\n      }\n    }\n  }\n\n  /**\n   * Validates the dailyAutomaticBackupStartTime is set with a non-zero day automaticBackupRetention.\n   */\n  private validateDailyAutomaticBackupStartTime(automaticBackupRetention?: Duration,\n    dailyAutomaticBackupStartTime?: DailyAutomaticBackupStartTime): void {\n    if (!dailyAutomaticBackupStartTime) return;\n\n    const automaticBackupDisabled = !automaticBackupRetention || automaticBackupRetention?.toDays() === Duration.days(0).toDays();\n\n    if (dailyAutomaticBackupStartTime && automaticBackupDisabled) {\n      throw new ValidationError('automaticBackupRetention period must be set a non-zero day when dailyAutomaticBackupStartTime is set', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Internal class to allow users to import VPC @internal", "output": "class ImportedVpcV2 extends VpcV2Base {\n      public readonly vpcId: string;\n      public readonly vpcArn: string;\n      public readonly publicSubnets: ISubnetV2[] = [];\n      public readonly privateSubnets: ISubnetV2[] = [];\n      public readonly isolatedSubnets: ISubnetV2[] = [];\n      public readonly internetConnectivityEstablished: IDependable = new DependencyGroup();\n      public readonly ipv4CidrBlock: string;\n      public readonly region: string;\n      public readonly ownerAccountId: string;\n      public readonly vpcName?: string;\n      private readonly _partition?: string;\n\n      /*\n      * Reference to all secondary blocks attached\n      */\n      public readonly secondaryCidrBlock?: IVPCCidrBlock[];\n\n      /**\n       * Refers to actual VPC Resource attribute in non-imported VPC\n       * Required to implement here due to extension from Base class\n       */\n      public readonly vpcCidrBlock: string;\n\n      // Required to do CIDR range test on imported VPCs to create new subnets\n      public readonly ipv4IpamProvisionedCidrs: string[] = [];\n\n      constructor(construct: Construct, constructId: string, props: VpcV2Attributes) {\n        super(construct, constructId);\n        this.vpcId = props.vpcId,\n        this.region = props.region ?? this.stack.region,\n        this.ownerAccountId = props.ownerAccountId ?? this.stack.account,\n        this._partition = region_info.RegionInfo.get(this.region).partition,\n        this.vpcArn = Arn.format({\n          service: 'ec2',\n          resource: 'vpc',\n          resourceName: this.vpcId,\n          region: this.region,\n          account: this.ownerAccountId,\n          partition: this._partition,\n        }, this.stack);\n\n        // Populate region and account fields that can be used to set up peering connection\n        // sample vpc Arn - arn:aws:ec2:us-west-2:123456789012:vpc/vpc-0123456789abcdef0\n        this.region = this.vpcArn.split(':')[3];\n        this.ownerAccountId = this.vpcArn.split(':')[4];\n        // Refers to actual VPC Resource attribute in non-imported VPC\n        this.vpcCidrBlock = props.vpcCidrBlock;\n        // Required for subnet range related checks\n        this.ipv4CidrBlock = props.vpcCidrBlock;\n        this._vpnGatewayId = props.vpnGatewayId;\n\n        if (props.subnets) {\n          for (const subnet of props.subnets) {\n            if (subnet.subnetType === SubnetType.PRIVATE_WITH_EGRESS || subnet.subnetType === SubnetType.PRIVATE_WITH_NAT ||\n              subnet.subnetType as string === 'Deprecated_Private') {\n              this.privateSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedPrivateSubnet', subnet));\n            } else if (subnet.subnetType === SubnetType.PUBLIC) {\n              this.publicSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedPublicSubnet', subnet));\n            } else if (subnet.subnetType as string === 'Deprecated_Isolated' || subnet.subnetType === SubnetType.PRIVATE_ISOLATED) {\n              this.isolatedSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedIsolatedSubnet', subnet));\n            }\n          }\n        }\n        this.secondaryCidrBlock = props.secondaryCidrBlocks?.map(cidrBlock => VPCCidrBlock.fromVPCCidrBlockattributes(scope, cidrBlock.cidrBlockName ?? 'ImportedSecondaryCidrBlock', { ...cidrBlock }));\n        if (props.secondaryCidrBlocks) {\n          for (const cidrBlock of props.secondaryCidrBlocks) {\n            if (cidrBlock.ipv4IpamProvisionedCidrs) {\n              this.ipv4IpamProvisionedCidrs.push(...cidrBlock.ipv4IpamProvisionedCidrs);\n            }\n          }\n        }\n      }\n    }", "language": "typescript"}
{"input": "Represents a function parameter in a function schema", "output": "export class FunctionParameter {\n  /**\n   * The type of the parameter\n   */\n  public readonly type: ParameterType;\n\n  /**\n   * Whether the parameter is required\n   */\n  public readonly required: boolean;\n\n  /**\n   * Description of the parameter\n   * @default undefined no description will be present\n   */\n  public readonly description?: string;\n\n  constructor(props: FunctionParameterProps) {\n    // Validate description if provided\n    if (props.description) {\n      const descErrors = validation.validateStringFieldLength({\n        fieldName: 'parameter description',\n        value: props.description,\n        minLength: 1,\n        maxLength: 500,\n      });\n\n      if (descErrors.length > 0) {\n        throw new validation.ValidationError(descErrors.join('\\n'));\n      }\n    }\n\n    this.type = props.type;\n    this.required = props.required ?? true;\n    this.description = props.description;\n  }\n\n  /**\n   * Render the parameter as a CloudFormation property\n   * @internal\n   */\n  public _render(): any {\n    return {\n      type: this.type,\n      required: this.required,\n      description: this.description,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, EC2 resources", "output": "class Ec2AlarmsToOpsitemStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        f = open('./ec2_alarms_to_opsitem/ssm_content.json')\n        data = json.load(f)\n\n        ssm_.CfnDocument(\n          self, 'ssmdoc',\n          content=data,\n          document_type=\"Command\",\n          name=\"Koi-TriggerAlarm\",\n        )\n\n        koitopic = sns_.Topic(self, \"Topic\",\n            display_name=\"koi-demo-topic\",\n        )\n\n        email = CfnParameter(self, \"emailparam\", type=\"String\",\n            description=\"Email to receive notifications\",\n        )\n        koitopic.add_subscription(Subscriptions.EmailSubscription(email.value_as_string))\n\n        y_lambda_role = iam_.Role(self, \"LambdaRole\",\n           assumed_by=iam_.ServicePrincipal(\"lambda.amazonaws.com\")\n        )\n        y_lambda_role.add_managed_policy(iam_.ManagedPolicy.from_aws_managed_policy_name(\"service-role/AWSLambdaBasicExecutionRole\"))\n        y_lambda_role.add_to_policy(\n            iam_.PolicyStatement(\n                effect = iam_.Effect.ALLOW,\n                resources=[\"*\"],\n                actions=[\"kms:Decrypt\",\n                    \"cloudwatch:SetAlarmState\",\"ssm:CreateOpsItem\",\n                    \"ssm:AddTagsToResource\",\n                    \"ec2:CreateTags\",\"ec2:DescribeInstances\",\n                    \"cloudwatch:PutMetricAlarm\",\"cloudwatch:DeleteAlarms\",\n                    \"cloudwatch:DescribeAlarms\",\"sns:Publish\"]\n            )    \n        )\n\n        # create lambda function\n        my_alarm = lambda_.Function(\n            self, 'AlarmHandler',\n            runtime= lambda_.Runtime.PYTHON_3_9,\n            #code= lambda.Code.asset('lambda',),\n            code = lambda_.Code.from_asset('lambda', exclude=['opsitem.py']),\n            handler= 'alarm.handler',\n            timeout=Duration.seconds(60),\n            role = y_lambda_role,\n            environment={\n                'acct': account_id,\n                'region': region,\n                'topic':koitopic.topic_name\n            }\n        )\n\n        pattern = events.EventPattern(\n            source=['aws.ec2'],\n            detail_type=[\"EC2 Instance State-change Notification\"],\n            detail={\"state\":[\"running\"]}\n        )\n\n        target1 = targets.LambdaFunction(handler=my_alarm)\n\n        rule = events.Rule(self, id='createAlarm', \n            description='Detect Running EC2', \n            event_pattern=pattern,\n            targets=[target1],\n        )\n\n        my_opsitem = lambda_.Function(\n            self, 'OpsItemHandler',\n            runtime= lambda_.Runtime.PYTHON_3_7,\n            code= lambda_.Code.from_asset('lambda',exclude=['alarm.py']),\n            handler= 'opsitem.handler',\n            timeout=Duration.seconds(60),\n            role = y_lambda_role,\n            environment={\n                'acct': account_id,\n                'region':region,\n                'topic':koitopic.topic_name\n            }\n        )\n\n        pattern2 = events.EventPattern(\n            source=[\"aws.cloudwatch\"],\n            detail_type=[\"CloudWatch Alarm State Change\"],\n            detail={\n                \"alarmName\":[{\"prefix\":\"StatusCheckFailed-\"}],\n                \"state\":{\"value\":[\"ALARM\"]}\n            }\n        )\n\n        target2 = targets.LambdaFunction(handler=my_opsitem)\n\n        rule2 = events.Rule(self, id='createOpsItem', \n            description='Detect StatusCheckFailed Alarm State', \n            event_pattern=pattern2,\n            targets=[target2],\n        )\n\n        #define AMI properties\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            edition=ec2.AmazonLinuxEdition.STANDARD,\n            virtualization=ec2.AmazonLinuxVirt.HVM,\n            storage=ec2.AmazonLinuxStorage.GENERAL_PURPOSE\n        )\n        \n        # Instance Role and SSM Managed Policy\n        role = iam_.Role(self, \"InstanceSSM\", assumed_by=iam_.ServicePrincipal(\"ec2.amazonaws.com\"))\n        role.add_managed_policy(iam_.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSSMManagedInstanceCore\"))\n        role.add_to_policy(\n            iam_.PolicyStatement(\n                effect = iam_.Effect.ALLOW,\n                resources=[\"*\"],\n                actions=[\"kms:Decrypt\",\"cloudwatch:SetAlarmState\"]\n                )    \n        )\n\n        #vpc = ec2.Vpc.from_lookup(\n        #    self, \"VPC\",\n        #    is_default=True,\n        #    region=region)\n        \n        vpc = ec2.Vpc(\n            self,\"LabVpc\",\n            cidr=\"10.10.0.0/24\"\n        )\n\n        #Instance\n        instance = ec2.Instance(self,\n            \"Instance\", \n            instance_type=ec2.InstanceType(\"t3.nano\"),\n            machine_image=amzn_linux,\n            vpc = vpc,\n            role=role,\n            vpc_subnets=ec2.SubnetSelection(\n                subnet_type=ec2.SubnetType.PUBLIC),\n        )\n\n        Tags.of(instance).add(\"OpsItemAlarm\",\"false\")\n\n        #s3asset = asset(self, \"Asset\", path=os.path.join(dirname, \"configure.sh\"))\n        s3asset = asset.Asset(\n            self, \"Asset\",\n            path=os.path.join(dirname, \"configure.sh\")\n        )\n\n        local_path = instance.user_data.add_s3_download_command(\n            bucket=s3asset.bucket,\n            bucket_key=s3asset.s3_object_key\n        )\n\n        instance.user_data.add_execute_file_command(\n            file_path=local_path\n        )\n        s3asset.grant_read(instance.role)", "language": "python"}
{"input": "CDK class ReceiptRuleSet for AWS resource management", "output": "export class ReceiptRuleSet extends ReceiptRuleSetBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ses.ReceiptRuleSet';\n\n  /**\n   * Import an exported receipt rule set.\n   */\n  public static fromReceiptRuleSetName(scope: Construct, id: string, receiptRuleSetName: string): IReceiptRuleSet {\n    class Import extends ReceiptRuleSetBase implements IReceiptRuleSet {\n      public readonly receiptRuleSetName = receiptRuleSetName;\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly receiptRuleSetName: string;\n\n  constructor(scope: Construct, id: string, props: ReceiptRuleSetProps = {}) {\n    super(scope, id, {\n      physicalName: props.receiptRuleSetName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnReceiptRuleSet(this, 'Resource', {\n      ruleSetName: this.physicalName,\n    });\n\n    this.receiptRuleSetName = resource.ref;\n\n    if (props) {\n      if (props.dropSpam) {\n        this.addDropSpamRule();\n      }\n\n      const rules = props.rules || [];\n      rules.forEach((ruleOption, idx) => this.addRule(`Rule${idx}`, ruleOption));\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ScheduledAction for AWS resource management", "output": "export class ScheduledAction extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-autoscaling.ScheduledAction';\n  /**\n   * The name of the scheduled action.\n   *\n   * @attribute\n   */\n  public readonly scheduledActionName: string;\n\n  constructor(scope: Construct, id: string, props: ScheduledActionProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.minCapacity === undefined && props.maxCapacity === undefined && props.desiredCapacity === undefined) {\n      throw new ValidationError('At least one of minCapacity, maxCapacity, or desiredCapacity is required', this);\n    }\n\n    // add a warning on synth when minute is not defined in a cron schedule\n    props.schedule._bind(this);\n\n    const resource = new CfnScheduledAction(this, 'Resource', {\n      autoScalingGroupName: props.autoScalingGroup.autoScalingGroupRef.autoScalingGroupName,\n      startTime: formatISO(props.startTime),\n      endTime: formatISO(props.endTime),\n      minSize: props.minCapacity,\n      maxSize: props.maxCapacity,\n      desiredCapacity: props.desiredCapacity,\n      recurrence: props.schedule.expressionString,\n      timeZone: props.timeZone,\n    });\n\n    this.scheduledActionName = resource.attrScheduledActionName;\n  }\n}", "language": "typescript"}
{"input": "CDK class AbstractCfnResource for AWS resource management", "output": "class AbstractCfnResource extends CfnResource {\n  constructor(scope: Construct, id: string) {\n    super(scope, id, {\n      type: 'CDK::UnitTest::MyCfnResource',\n    });\n  }\n\n  public inspect(inspector: TreeInspector) {\n    inspector.addAttribute('aws:cdk:cloudformation:type', 'CDK::UnitTest::MyCfnResource');\n    inspector.addAttribute('aws:cdk:cloudformation:props', this.cfnProperties);\n  }\n\n  protected abstract override get cfnProperties(): { [key: string]: any };\n}", "language": "typescript"}
{"input": "Integration test stack for SelfManagedKafka with KafkaDlq destination", "output": "class SelfManagedKafkaWithKafkaDlqStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\nMIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\ncmUuaAii9R0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\nc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n-----END CERTIFICATE-----`;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\nzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n-----END ENCRYPTED PRIVATE KEY-----`;\n\n    const fn = new TestFunction(this, 'SelfManagedKafkaFunction');\n\n    const rootCASecret = new secretsmanager.Secret(this, 'RootCASecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'ClientCertSecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n        privateKey: cdk.SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n\n    rootCASecret.grantRead(fn);\n    clientCertificatesSecret.grantRead(fn);\n\n    const bootstrapServers = [\n      'self-managed-kafka-broker-1:9092',\n      'self-managed-kafka-broker-2:9092',\n      'self-managed-kafka-broker-3:9092',\n    ];\n\n    // Create KafkaDlq destination\n    const kafkaDlq = new KafkaDlq('self-managed-kafka-failure-topic');\n\n    // Add SelfManagedKafka event source with KafkaDlq destination\n    fn.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'self-managed-test-topic',\n      consumerGroupId: 'self-managed-test-consumer-group',\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      onFailure: kafkaDlq,\n      provisionedPollerConfig: {\n        minimumPollers: 1,\n        maximumPollers: 1,\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class Input for AWS resource management", "output": "export class Input extends InputBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-iotevents-alpha.Input';\n\n  /**\n   * Import an existing input.\n   */\n  public static fromInputName(scope: Construct, id: string, inputName: string): IInput {\n    return new class Import extends InputBase {\n      public readonly inputName = inputName;\n      public readonly inputArn = this.stack.formatArn({\n        service: 'iotevents',\n        resource: 'input',\n        resourceName: inputName,\n      });\n    }(scope, id);\n  }\n\n  public readonly inputName: string;\n\n  public readonly inputArn: string;\n\n  constructor(scope: Construct, id: string, props: InputProps) {\n    super(scope, id, {\n      physicalName: props.inputName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.attributeJsonPaths.length === 0) {\n      throw new Error('attributeJsonPaths property cannot be empty');\n    }\n\n    const resource = new CfnInput(this, 'Resource', {\n      inputName: this.physicalName,\n      inputDefinition: {\n        attributes: props.attributeJsonPaths.map(path => ({ jsonPath: path })),\n      },\n    });\n\n    this.inputName = this.getResourceNameAttribute(resource.ref);\n    this.inputArn = this.getResourceArnAttribute(arnForInput(resource.ref), {\n      service: 'iotevents',\n      resource: 'input',\n      resourceName: this.physicalName,\n    });\n  }\n}", "language": "typescript"}
{"input": "Scripts that run integ tests must also have the individual 'integ' script to update them This commands comes from the dev-dependency cdk-integ-tools.", "output": "export class MustHaveIntegCommand extends ValidationRule {\n  public readonly name = 'package-info/scripts/integ';\n\n  public validate(pkg: PackageJson): void {\n    if (!hasIntegTests(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.integ', /integ-runner/, undefined, false, true);\n\n    // We can't ACTUALLY require cdk-build-tools/package.json here,\n    // because WE don't depend on cdk-build-tools and we don't know if\n    // the package does.\n    expectDevDependency(this.name,\n      pkg,\n      '@aws-cdk/integ-runner',\n      '*');\n  }\n}\n\n/**\n * Checks API backwards compatibility against the latest released version.\n */\nexport class CompatScript extends ValidationRule {\n  public readonly name = 'package-info/scripts/compat';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return ; }\n\n    expectJSON(this.name, pkg, 'scripts.compat', 'cdk-compat');\n  }\n}\n\nexport class PkgLintAsScript extends ValidationRule {\n  public readonly name = 'package-info/scripts/pkglint';\n\n  public validate(pkg: PackageJson): void {\n    const script = 'pkglint -f';\n\n    expectDevDependency(this.name, pkg, '@aws-cdk/pkglint', `${PKGLINT_VERSION}`);\n\n    if (!pkg.npmScript('pkglint')) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'a script called \"pkglint\" must be included to allow fixing package linting issues',\n        fix: () => pkg.changeNpmScript('pkglint', () => script),\n      });\n    }\n\n    if (pkg.npmScript('pkglint') !== script) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'the pkglint script should be: ' + script,\n        fix: () => pkg.changeNpmScript('pkglint', () => script),\n      });\n    }\n  }\n}\n\nexport class NoStarDeps extends ValidationRule {\n  public readonly name = 'dependencies/no-star';\n\n  public validate(pkg: PackageJson) {\n    reportStarDeps(this.name, pkg.json.depedencies);\n    reportStarDeps(this.name, pkg.json.devDependencies);\n\n    function reportStarDeps(ruleName: string, deps?: any) {\n      deps = deps || {};\n      Object.keys(deps).forEach(d => {\n        if (deps[d] === '*') {\n          pkg.report({\n            ruleName,\n            message: `star dependency not allowed for ${d}`,\n          });\n        }\n      });\n    }\n  }\n}\n\nexport class NoMixedDeps extends ValidationRule {\n  public readonly name = 'dependencies/no-mixed-deps';\n\n  public validate(pkg: PackageJson) {\n    const deps = Object.keys(pkg.json.dependencies ?? {});\n    const devDeps = Object.keys(pkg.json.devDependencies ?? {});\n\n    const shared = deps.filter((dep) => devDeps.includes(dep));\n    for (const dep of shared) {\n      pkg.report({\n        ruleName: this.name,\n        message: `dependency may not be both in dependencies and devDependencies: ${dep}`,\n        fix: () => pkg.removeDevDependency(dep),\n      });\n    }\n  }\n}\n\ninterface VersionCount {\n  version: string;\n  count: number;\n}\n\n/**\n * All consumed versions of dependencies must be the same\n *\n * NOTE: this rule will only be useful when validating multiple package.jsons at the same time\n */\nexport class AllVersionsTheSame extends ValidationRule {\n  public readonly name = 'dependencies/versions-consistent';\n\n  private readonly ourPackages: {[pkg: string]: string} = {};\n  private readonly usedDeps: {[pkg: string]: VersionCount[]} = {};\n\n  public prepare(pkg: PackageJson): void {\n    this.ourPackages[pkg.json.name] = pkg.json.version;\n    this.recordDeps(pkg.json.dependencies);\n    this.recordDeps(pkg.json.devDependencies);\n  }\n\n  public validate(pkg: PackageJson): void {\n    this.validateDeps(pkg, 'dependencies');\n    this.validateDeps(pkg, 'devDependencies');\n  }\n\n  private recordDeps(deps: {[pkg: string]: string} | undefined) {\n    if (!deps) { return; }\n\n    Object.keys(deps).forEach(dep => {\n      this.recordDep(dep, deps[dep]);\n    });\n  }\n\n  private validateDeps(pkg: PackageJson, section: string) {\n    if (!pkg.json[section]) { return; }\n\n    Object.keys(pkg.json[section]).forEach(dep => {\n      this.validateDep(pkg, section, dep);\n    });\n  }\n\n  private recordDep(dep: string, version: string) {\n    if (version === '*') {\n      // '*' does not give us info, so skip\n      return;\n    }\n\n    if (!(dep in this.usedDeps)) {\n      this.usedDeps[dep] = [];\n    }\n\n    const i = this.usedDeps[dep].findIndex(vc => vc.version === version);\n    if (i === -1) {\n      this.usedDeps[dep].push({ version, count: 1 });\n    } else {\n      this.usedDeps[dep][i].count += 1;\n    }\n  }\n\n  private validateDep(pkg: PackageJson, depField: string, dep: string) {\n    if (dep in this.ourPackages) {\n      expectJSON(this.name, pkg, [depField, dep], this.ourPackages[dep]);\n      return;\n    }\n\n    // Otherwise, must match the majority version declaration. Might be empty if we only\n    // have '*', in which case that's fine.\n    if (!(dep in this.usedDeps)) { return; }\n\n    const versions = this.usedDeps[dep];\n    versions.sort((a, b) => b.count - a.count);\n    expectJSON(this.name, pkg, [depField, dep], versions[0].version);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, CloudFormation, CodePipeline resources", "output": "export class StackSetPipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const pipeline = new codepipeline.Pipeline(this, 'Pipeline', {\n      artifactBucket: new s3.Bucket(this, 'ArtifactBucket', {\n        removalPolicy: RemovalPolicy.DESTROY,\n        autoDeleteObjects: true,\n      }),\n    });\n\n    const asset = new Asset(this, 'Asset', {\n      path: `${__dirname}/test-artifact`,\n    });\n\n    const sourceOutput = new codepipeline.Artifact('SourceArtifact');\n\n    pipeline.addStage({\n      stageName: 'Source',\n      actions: [\n        new cpactions.S3SourceAction({\n          actionName: 'Source',\n          output: sourceOutput,\n          bucket: asset.bucket,\n          bucketKey: asset.s3ObjectKey,\n        }),\n      ],\n    });\n\n    const accounts = process.env.STACKSET_ACCOUNTS?.split(',') ?? ['1111', '2222'];\n\n    pipeline.addStage({\n      stageName: 'Cfn',\n      actions: [\n        new cpactions.CloudFormationDeployStackSetAction({\n          actionName: 'StackSet',\n          stackSetName: 'TestStackSet',\n          template: cpactions.StackSetTemplate.fromArtifactPath(sourceOutput.atPath('template.yaml')),\n          stackInstances: cpactions.StackInstances.inAccounts(accounts, ['us-east-1', 'eu-west-1']),\n          runOrder: 1,\n        }),\n        new cpactions.CloudFormationDeployStackInstancesAction({\n          actionName: 'Instances',\n          stackSetName: 'TestStackSet',\n          stackInstances: cpactions.StackInstances.inAccounts(accounts, ['us-east-1', 'eu-west-1']),\n          runOrder: 2,\n        }),\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "Managed rules that are supported by AWS Config. @see https://docs.aws.amazon.com/config/latest/developerguide/managed-rules-by-aws-config.html", "output": "export class ManagedRuleIdentifiers {\n  /**\n   * Checks that the inline policies attached to your AWS Identity and Access Management users,\n   * roles, and groups do not allow blocked actions on all AWS Key Management Service keys.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-inline-policy-blocked-kms-actions.html\n   */\n  public static readonly IAM_INLINE_POLICY_BLOCKED_KMS_ACTIONS = 'IAM_INLINE_POLICY_BLOCKED_KMS_ACTIONS';\n  /**\n   * Checks that the managed AWS Identity and Access Management policies that you create do not\n   * allow blocked actions on all AWS AWS KMS keys.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-customer-policy-blocked-kms-actions.html\n   */\n  public static readonly IAM_CUSTOMER_POLICY_BLOCKED_KMS_ACTIONS = 'IAM_CUSTOMER_POLICY_BLOCKED_KMS_ACTIONS';\n  /**\n   * Checks whether the active access keys are rotated within the number of days specified in maxAccessKeyAge.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/access-keys-rotated.html\n   */\n  public static readonly ACCESS_KEYS_ROTATED = 'ACCESS_KEYS_ROTATED';\n  /**\n   * Checks whether AWS account is part of AWS Organizations.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/account-part-of-organizations.html\n   */\n  public static readonly ACCOUNT_PART_OF_ORGANIZATIONS = 'ACCOUNT_PART_OF_ORGANIZATIONS';\n  /**\n   * Checks whether ACM Certificates in your account are marked for expiration within the specified number of days.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/acm-certificate-expiration-check.html\n   */\n  public static readonly ACM_CERTIFICATE_EXPIRATION_CHECK = 'ACM_CERTIFICATE_EXPIRATION_CHECK';\n  /**\n   * Checks if an Application Load Balancer (ALB) is configured with a user defined desync mitigation mode.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/alb-desync-mode-check.html\n   */\n  public static readonly ALB_DESYNC_MODE_CHECK = 'ALB_DESYNC_MODE_CHECK';\n  /**\n   * Checks if rule evaluates Application Load Balancers (ALBs) to ensure they are configured to drop http headers.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/alb-http-drop-invalid-header-enabled.html\n   */\n  public static readonly ALB_HTTP_DROP_INVALID_HEADER_ENABLED = 'ALB_HTTP_DROP_INVALID_HEADER_ENABLED';\n  /**\n   * Checks whether HTTP to HTTPS redirection is configured on all HTTP listeners of Application Load Balancer.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/alb-http-to-https-redirection-check.html\n   */\n  public static readonly ALB_HTTP_TO_HTTPS_REDIRECTION_CHECK = 'ALB_HTTP_TO_HTTPS_REDIRECTION_CHECK';\n  /**\n   * Checks if Web Application Firewall (WAF) is enabled on Application Load Balancers (ALBs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/alb-waf-enabled.html\n   */\n  public static readonly ALB_WAF_ENABLED = 'ALB_WAF_ENABLED';\n  /**\n   * Checks if Amazon API Gateway V2 stages have access logging enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gwv2-access-logs-enabled.html\n   */\n  public static readonly API_GWV2_ACCESS_LOGS_ENABLED = 'API_GWV2_ACCESS_LOGS_ENABLED';\n  /**\n   * Checks if Amazon API Gatewayv2 API routes have an authorization type set.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gwv2-authorization-type-configured.html\n   */\n  public static readonly API_GWV2_AUTHORIZATION_TYPE_CONFIGURED = 'API_GWV2_AUTHORIZATION_TYPE_CONFIGURED';\n  /**\n   * Checks if an Amazon API Gateway API stage is using an AWS WAF Web ACL.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-associated-with-waf.html\n   */\n  public static readonly API_GW_ASSOCIATED_WITH_WAF = 'API_GW_ASSOCIATED_WITH_WAF';\n  /**\n   * Checks that all methods in Amazon API Gateway stages have caching enabled and encrypted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-cache-enabled-and-encrypted.html\n   */\n  public static readonly API_GW_CACHE_ENABLED_AND_ENCRYPTED = 'API_GW_CACHE_ENABLED_AND_ENCRYPTED';\n  /**\n   * Checks that Amazon API Gateway APIs are of the type specified in the rule parameter endpointConfigurationType.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-endpoint-type-check.html\n   */\n  public static readonly API_GW_ENDPOINT_TYPE_CHECK = 'API_GW_ENDPOINT_TYPE_CHECK';\n  /**\n   * Checks that all methods in Amazon API Gateway stage has logging enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-execution-logging-enabled.html\n   */\n  public static readonly API_GW_EXECUTION_LOGGING_ENABLED = 'API_GW_EXECUTION_LOGGING_ENABLED';\n  /**\n   * Checks if a REST API stage uses an Secure Sockets Layer (SSL) certificate.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-ssl-enabled.html\n   */\n  public static readonly API_GW_SSL_ENABLED = 'API_GW_SSL_ENABLED';\n  /**\n   * Checks if AWS X-Ray tracing is enabled on Amazon API Gateway REST APIs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/api-gw-xray-enabled.html\n   */\n  public static readonly API_GW_XRAY_ENABLED = 'API_GW_XRAY_ENABLED';\n  /**\n   * Checks whether running instances are using specified AMIs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/approved-amis-by-id.html\n   */\n  public static readonly APPROVED_AMIS_BY_ID = 'APPROVED_AMIS_BY_ID';\n  /**\n   * Checks whether running instances are using specified AMIs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/approved-amis-by-tag.html\n   */\n  public static readonly APPROVED_AMIS_BY_TAG = 'APPROVED_AMIS_BY_TAG';\n  /**\n   * Checks if a recovery point was created for Amazon Aurora DB clusters.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/aurora-last-backup-recovery-point-created.html\n   */\n  public static readonly AURORA_LAST_BACKUP_RECOVERY_POINT_CREATED = 'AURORA_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks if an Amazon Aurora MySQL cluster has backtracking enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/aurora-mysql-backtracking-enabled.html\n   */\n  public static readonly AURORA_MYSQL_BACKTRACKING_ENABLED = 'AURORA_MYSQL_BACKTRACKING_ENABLED';\n  /**\n   * Checks if Amazon Aurora DB clusters are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/aurora-resources-protected-by-backup-plan.html\n   */\n  public static readonly AURORA_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'AURORA_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks if Capacity Rebalancing is enabled for Amazon EC2 Auto Scaling groups that use multiple instance types.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-capacity-rebalancing.html\n   */\n  public static readonly AUTOSCALING_CAPACITY_REBALANCING = 'AUTOSCALING_CAPACITY_REBALANCING';\n  /**\n   * Checks whether your Auto Scaling groups that are associated with a load balancer are using\n   * Elastic Load Balancing health checks.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-group-elb-healthcheck-required.html\n   */\n  public static readonly AUTOSCALING_GROUP_ELB_HEALTHCHECK_REQUIRED = 'AUTOSCALING_GROUP_ELB_HEALTHCHECK_REQUIRED';\n  /**\n   * Checks whether only IMDSv2 is enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-launchconfig-requires-imdsv2.html\n   */\n  public static readonly AUTOSCALING_LAUNCHCONFIG_REQUIRES_IMDSV2 = 'AUTOSCALING_LAUNCHCONFIG_REQUIRES_IMDSV2';\n  /**\n   * Checks the number of network hops that the metadata token can travel.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-launch-config-hop-limit.html\n   */\n  public static readonly AUTOSCALING_LAUNCH_CONFIG_HOP_LIMIT = 'AUTOSCALING_LAUNCH_CONFIG_HOP_LIMIT';\n  /**\n   * Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled through Launch Configurations.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-launch-config-public-ip-disabled.html\n   */\n  public static readonly AUTOSCALING_LAUNCH_CONFIG_PUBLIC_IP_DISABLED = 'AUTOSCALING_LAUNCH_CONFIG_PUBLIC_IP_DISABLED';\n  /**\n   * Checks if an Amazon Elastic Compute Cloud (EC2) Auto Scaling group is created from an EC2 launch template.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-launch-template.html\n   */\n  public static readonly AUTOSCALING_LAUNCH_TEMPLATE = 'AUTOSCALING_LAUNCH_TEMPLATE';\n  /**\n   * Checks if the Auto Scaling group spans multiple Availability Zones.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-multiple-az.html\n   */\n  public static readonly AUTOSCALING_MULTIPLE_AZ = 'AUTOSCALING_MULTIPLE_AZ';\n  /**\n   * Checks if an Amazon Elastic Compute Cloud (Amazon EC2) Auto Scaling group uses multiple instance types.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/autoscaling-multiple-instance-types.html\n   */\n  public static readonly AUTOSCALING_MULTIPLE_INSTANCE_TYPES = 'AUTOSCALING_MULTIPLE_INSTANCE_TYPES';\n  /**\n   * Checks if a backup plan has a backup rule that satisfies the required frequency and retention period.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/backup-plan-min-frequency-and-min-retention-check.html\n   */\n  public static readonly BACKUP_PLAN_MIN_FREQUENCY_AND_MIN_RETENTION_CHECK = 'BACKUP_PLAN_MIN_FREQUENCY_AND_MIN_RETENTION_CHECK';\n  /**\n   * Checks if a recovery point is encrypted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/backup-recovery-point-encrypted.html\n   */\n  public static readonly BACKUP_RECOVERY_POINT_ENCRYPTED = 'BACKUP_RECOVERY_POINT_ENCRYPTED';\n  /**\n   * Checks if a backup vault has an attached resource-based policy which prevents deletion of recovery points.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/backup-recovery-point-manual-deletion-disabled.html\n   */\n  public static readonly BACKUP_RECOVERY_POINT_MANUAL_DELETION_DISABLED = 'BACKUP_RECOVERY_POINT_MANUAL_DELETION_DISABLED';\n  /**\n   * Checks if a recovery point expires no earlier than after the specified period.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/backup-recovery-point-minimum-retention-check.html\n   */\n  public static readonly BACKUP_RECOVERY_POINT_MINIMUM_RETENTION_CHECK = 'BACKUP_RECOVERY_POINT_MINIMUM_RETENTION_CHECK';\n  /**\n   * Checks if an AWS Elastic Beanstalk environment is configured for enhanced health reporting.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/beanstalk-enhanced-health-reporting-enabled.html\n   */\n  public static readonly BEANSTALK_ENHANCED_HEALTH_REPORTING_ENABLED = 'BEANSTALK_ENHANCED_HEALTH_REPORTING_ENABLED';\n  /**\n   * Checks if Classic Load Balancers (CLB) are configured with a user defined Desync mitigation mode.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/clb-desync-mode-check.html\n   */\n  public static readonly CLB_DESYNC_MODE_CHECK = 'CLB_DESYNC_MODE_CHECK';\n  /**\n   * Checks if a Classic Load Balancer spans multiple Availability Zones (AZs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/clb-multiple-az.html\n   */\n  public static readonly CLB_MULTIPLE_AZ = 'CLB_MULTIPLE_AZ';\n  /**\n   * Checks whether an AWS CloudFormation stack's actual configuration differs, or has drifted,\n   * from it's expected configuration.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudformation-stack-drift-detection-check.html\n   */\n  public static readonly CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK = 'CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK';\n  /**\n   * Checks whether your CloudFormation stacks are sending event notifications to an SNS topic.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudformation-stack-notification-check.html\n   */\n  public static readonly CLOUDFORMATION_STACK_NOTIFICATION_CHECK = 'CLOUDFORMATION_STACK_NOTIFICATION_CHECK';\n  /**\n   * Checks if Amazon CloudFront distributions are configured to capture information from\n   * Amazon Simple Storage Service (Amazon S3) server access logs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-accesslogs-enabled.html\n   */\n  public static readonly CLOUDFRONT_ACCESSLOGS_ENABLED = 'CLOUDFRONT_ACCESSLOGS_ENABLED';\n  /**\n   * Checks if Amazon CloudFront distributions are associated with either WAF or WAFv2 web access control lists (ACLs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-associated-with-waf.html\n   */\n  public static readonly CLOUDFRONT_ASSOCIATED_WITH_WAF = 'CLOUDFRONT_ASSOCIATED_WITH_WAF';\n  /**\n   * Checks if the certificate associated with an Amazon CloudFront distribution is the default Secure Sockets Layer (SSL) certificate.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-custom-ssl-certificate.html\n   */\n  public static readonly CLOUDFRONT_CUSTOM_SSL_CERTIFICATE = 'CLOUDFRONT_CUSTOM_SSL_CERTIFICATE';\n  /**\n   * Checks if an Amazon CloudFront distribution is configured to return a specific object that is the default root object.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-default-root-object-configured.html\n   */\n  public static readonly CLOUDFRONT_DEFAULT_ROOT_OBJECT_CONFIGURED = 'CLOUDFRONT_DEFAULT_ROOT_OBJECT_CONFIGURED';\n  /**\n   * Checks if CloudFront distributions are using deprecated SSL protocols for HTTPS communication between\n   * CloudFront edge locations and custom origins.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-no-deprecated-ssl-protocols.html\n   */\n  public static readonly CLOUDFRONT_NO_DEPRECATED_SSL_PROTOCOLS = 'CLOUDFRONT_NO_DEPRECATED_SSL_PROTOCOLS';\n  /**\n   * Checks that Amazon CloudFront distribution with Amazon S3 Origin type has Origin Access Identity (OAI) configured.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-origin-access-identity-enabled.html\n   */\n  public static readonly CLOUDFRONT_ORIGIN_ACCESS_IDENTITY_ENABLED = 'CLOUDFRONT_ORIGIN_ACCESS_IDENTITY_ENABLED';\n  /**\n   * Checks whether an origin group is configured for the distribution of at least 2 origins in the\n   * origin group for Amazon CloudFront.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-origin-failover-enabled.html\n   */\n  public static readonly CLOUDFRONT_ORIGIN_FAILOVER_ENABLED = 'CLOUDFRONT_ORIGIN_FAILOVER_ENABLED';\n  /**\n   * Checks if Amazon CloudFront distributions are using a minimum security policy and cipher suite of TLSv1.2 or\n   * greater for viewer connections.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-security-policy-check.html\n   */\n  public static readonly CLOUDFRONT_SECURITY_POLICY_CHECK = 'CLOUDFRONT_SECURITY_POLICY_CHECK';\n  /**\n   * Checks if Amazon CloudFront distributions are using a custom SSL certificate and are configured\n   * to use SNI to serve HTTPS requests.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-sni-enabled.html\n   */\n  public static readonly CLOUDFRONT_SNI_ENABLED = 'CLOUDFRONT_SNI_ENABLED';\n  /**\n   * Checks if Amazon CloudFront distributions are encrypting traffic to custom origins.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-traffic-to-origin-encrypted.html\n   */\n  public static readonly CLOUDFRONT_TRAFFIC_TO_ORIGIN_ENCRYPTED = 'CLOUDFRONT_TRAFFIC_TO_ORIGIN_ENCRYPTED';\n  /**\n   * Checks whether your Amazon CloudFront distributions use HTTPS (directly or via a redirection).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudfront-viewer-policy-https.html\n   */\n  public static readonly CLOUDFRONT_VIEWER_POLICY_HTTPS = 'CLOUDFRONT_VIEWER_POLICY_HTTPS';\n  /**\n   * Checks whether AWS CloudTrail trails are configured to send logs to Amazon CloudWatch Logs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloud-trail-cloud-watch-logs-enabled.html\n   */\n  public static readonly CLOUD_TRAIL_CLOUD_WATCH_LOGS_ENABLED = 'CLOUD_TRAIL_CLOUD_WATCH_LOGS_ENABLED';\n  /**\n   * Checks whether AWS CloudTrail is enabled in your AWS account.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudtrail-enabled.html\n   */\n  public static readonly CLOUD_TRAIL_ENABLED = 'CLOUD_TRAIL_ENABLED';\n  /**\n   * Checks whether AWS CloudTrail is configured to use the server side encryption (SSE)\n   * AWS Key Management Service (AWS KMS) customer master key (CMK) encryption.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloud-trail-encryption-enabled.html\n   */\n  public static readonly CLOUD_TRAIL_ENCRYPTION_ENABLED = 'CLOUD_TRAIL_ENCRYPTION_ENABLED';\n  /**\n   * Checks whether AWS CloudTrail creates a signed digest file with logs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloud-trail-log-file-validation-enabled.html\n   */\n  public static readonly CLOUD_TRAIL_LOG_FILE_VALIDATION_ENABLED = 'CLOUD_TRAIL_LOG_FILE_VALIDATION_ENABLED';\n  /**\n   * Checks whether at least one AWS CloudTrail trail is logging Amazon S3 data events for all S3 buckets.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudtrail-s3-dataevents-enabled.html\n   */\n  public static readonly CLOUDTRAIL_S3_DATAEVENTS_ENABLED = 'CLOUDTRAIL_S3_DATAEVENTS_ENABLED';\n  /**\n   * Checks that there is at least one AWS CloudTrail trail defined with security best practices.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudtrail-security-trail-enabled.html\n   */\n  public static readonly CLOUDTRAIL_SECURITY_TRAIL_ENABLED = 'CLOUDTRAIL_SECURITY_TRAIL_ENABLED';\n  /**\n   * Checks whether CloudWatch alarms have at least one alarm action, one INSUFFICIENT_DATA action,\n   * or one OK action enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudwatch-alarm-action-check.html\n   */\n  public static readonly CLOUDWATCH_ALARM_ACTION_CHECK = 'CLOUDWATCH_ALARM_ACTION_CHECK';\n  /**\n   * Checks if Amazon CloudWatch alarms actions are in enabled state.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudwatch-alarm-action-enabled-check.html\n   */\n  public static readonly CLOUDWATCH_ALARM_ACTION_ENABLED_CHECK = 'CLOUDWATCH_ALARM_ACTION_ENABLED_CHECK';\n  /**\n   * Checks whether the specified resource type has a CloudWatch alarm for the specified metric.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudwatch-alarm-resource-check.html\n   */\n  public static readonly CLOUDWATCH_ALARM_RESOURCE_CHECK = 'CLOUDWATCH_ALARM_RESOURCE_CHECK';\n  /**\n   * Checks whether CloudWatch alarms with the given metric name have the specified settings.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudwatch-alarm-settings-check.html\n   */\n  public static readonly CLOUDWATCH_ALARM_SETTINGS_CHECK = 'CLOUDWATCH_ALARM_SETTINGS_CHECK';\n  /**\n   * Checks whether a log group in Amazon CloudWatch Logs is encrypted with\n   * a AWS Key Management Service (KMS) managed Customer Master Keys (CMK).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cloudwatch-log-group-encrypted.html\n   */\n  public static readonly CLOUDWATCH_LOG_GROUP_ENCRYPTED = 'CLOUDWATCH_LOG_GROUP_ENCRYPTED';\n  /**\n   * Checks that key rotation is enabled for each key and matches to the key ID of the\n   * customer created customer master key (CMK).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cmk-backing-key-rotation-enabled.html\n   */\n  public static readonly CMK_BACKING_KEY_ROTATION_ENABLED = 'CMK_BACKING_KEY_ROTATION_ENABLED';\n  /**\n   * Checks if an AWS CodeBuild project has encryption enabled for all of its artifacts.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-artifact-encryption.html\n   */\n  public static readonly CODEBUILD_PROJECT_ARTIFACT_ENCRYPTION = 'CODEBUILD_PROJECT_ARTIFACT_ENCRYPTION';\n  /**\n   * Checks if an AWS CodeBuild project environment has privileged mode enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-environment-privileged-check.html\n   */\n  public static readonly CODEBUILD_PROJECT_ENVIRONMENT_PRIVILEGED_CHECK = 'CODEBUILD_PROJECT_ENVIRONMENT_PRIVILEGED_CHECK';\n  /**\n   * Checks whether the project contains environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-envvar-awscred-check.html\n   */\n  public static readonly CODEBUILD_PROJECT_ENVVAR_AWSCRED_CHECK = 'CODEBUILD_PROJECT_ENVVAR_AWSCRED_CHECK';\n  /**\n   * Checks if an AWS CodeBuild project environment has at least one log option enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-logging-enabled.html\n   */\n  public static readonly CODEBUILD_PROJECT_LOGGING_ENABLED = 'CODEBUILD_PROJECT_LOGGING_ENABLED';\n  /**\n   * Checks if a AWS CodeBuild project configured with Amazon S3 Logs has encryption enabled for its logs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-s3-logs-encrypted.html\n   */\n  public static readonly CODEBUILD_PROJECT_S3_LOGS_ENCRYPTED = 'CODEBUILD_PROJECT_S3_LOGS_ENCRYPTED';\n  /**\n   * Checks whether the GitHub or Bitbucket source repository URL contains either personal access tokens\n   * or user name and password.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codebuild-project-source-repo-url-check.html\n   */\n  public static readonly CODEBUILD_PROJECT_SOURCE_REPO_URL_CHECK = 'CODEBUILD_PROJECT_SOURCE_REPO_URL_CHECK';\n  /**\n   * Checks if the deployment group is configured with automatic deployment rollback and\n   * deployment monitoring with alarms attached.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codedeploy-auto-rollback-monitor-enabled.html\n   */\n  public static readonly CODEDEPLOY_AUTO_ROLLBACK_MONITOR_ENABLED = 'CODEDEPLOY_AUTO_ROLLBACK_MONITOR_ENABLED';\n  /**\n   * Checks if the deployment group for EC2/On-Premises Compute Platform is configured with\n   * a minimum healthy hosts fleet percentage or host count greater than or equal to the input threshold.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codedeploy-ec2-minimum-healthy-hosts-configured.html\n   */\n  public static readonly CODEDEPLOY_EC2_MINIMUM_HEALTHY_HOSTS_CONFIGURED = 'CODEDEPLOY_EC2_MINIMUM_HEALTHY_HOSTS_CONFIGURED';\n  /**\n   * Checks if the deployment group for Lambda Compute Platform is not using the default deployment configuration.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codedeploy-lambda-allatonce-traffic-shift-disabled.html\n   */\n  public static readonly CODEDEPLOY_LAMBDA_ALLATONCE_TRAFFIC_SHIFT_DISABLED = 'CODEDEPLOY_LAMBDA_ALLATONCE_TRAFFIC_SHIFT_DISABLED';\n  /**\n   * Checks whether the first deployment stage of the AWS CodePipeline performs more than one deployment.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codepipeline-deployment-count-check.html\n   */\n  public static readonly CODEPIPELINE_DEPLOYMENT_COUNT_CHECK = 'CODEPIPELINE_DEPLOYMENT_COUNT_CHECK';\n  /**\n   * Checks whether each stage in the AWS CodePipeline deploys to more than N times the number of\n   * the regions the AWS CodePipeline has deployed in all the previous combined stages,\n   * where N is the region fanout number.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/codepipeline-region-fanout-check.html\n   */\n  public static readonly CODEPIPELINE_REGION_FANOUT_CHECK = 'CODEPIPELINE_REGION_FANOUT_CHECK';\n  /**\n   * Checks whether Amazon CloudWatch LogGroup retention period is set to specific number of days.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/cw-loggroup-retention-period-check.html\n   */\n  public static readonly CW_LOGGROUP_RETENTION_PERIOD_CHECK = 'CW_LOGGROUP_RETENTION_PERIOD_CHECK';\n  /**\n   * Checks that DynamoDB Accelerator (DAX) clusters are encrypted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dax-encryption-enabled.html\n   */\n  public static readonly DAX_ENCRYPTION_ENABLED = 'DAX_ENCRYPTION_ENABLED';\n  /**\n   * Checks whether RDS DB instances have backups enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/db-instance-backup-enabled.html\n   */\n  public static readonly RDS_DB_INSTANCE_BACKUP_ENABLED = 'DB_INSTANCE_BACKUP_ENABLED';\n  /**\n   * Checks instances for specified tenancy.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/desired-instance-tenancy.html\n   */\n  public static readonly EC2_DESIRED_INSTANCE_TENANCY = 'DESIRED_INSTANCE_TENANCY';\n  /**\n   * Checks whether your EC2 instances are of the specified instance types.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/desired-instance-type.html\n   */\n  public static readonly EC2_DESIRED_INSTANCE_TYPE = 'DESIRED_INSTANCE_TYPE';\n  /**\n   * Checks whether AWS Database Migration Service replication instances are public.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dms-replication-not-public.html\n   */\n  public static readonly DMS_REPLICATION_NOT_PUBLIC = 'DMS_REPLICATION_NOT_PUBLIC';\n  /**\n   * Checks whether Auto Scaling or On-Demand is enabled on your DynamoDB tables and/or global secondary indexes.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-autoscaling-enabled.html\n   */\n  public static readonly DYNAMODB_AUTOSCALING_ENABLED = 'DYNAMODB_AUTOSCALING_ENABLED';\n  /**\n   * Checks whether Amazon DynamoDB table is present in AWS Backup plans.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-in-backup-plan.html\n   */\n  public static readonly DYNAMODB_IN_BACKUP_PLAN = 'DYNAMODB_IN_BACKUP_PLAN';\n  /**\n   * Checks if a recovery point was created for Amazon DynamoDB Tables within the specified period.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-last-backup-recovery-point-created.html\n   */\n  public static readonly DYNAMODB_LAST_BACKUP_RECOVERY_POINT_CREATED = 'DYNAMODB_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks that point in time recovery (PITR) is enabled for Amazon DynamoDB tables.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-pitr-enabled.html\n   */\n  public static readonly DYNAMODB_PITR_ENABLED = 'DYNAMODB_PITR_ENABLED';\n  /**\n   * Checks if Amazon DynamoDB tables are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-resources-protected-by-backup-plan.html\n   */\n  public static readonly DYNAMODB_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'DYNAMODB_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks whether Amazon DynamoDB table is encrypted with AWS Key Management Service (KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-table-encrypted-kms.html\n   */\n  public static readonly DYNAMODB_TABLE_ENCRYPTED_KMS = 'DYNAMODB_TABLE_ENCRYPTED_KMS';\n  /**\n   * Checks whether the Amazon DynamoDB tables are encrypted and checks their status.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-table-encryption-enabled.html\n   */\n  public static readonly DYNAMODB_TABLE_ENCRYPTION_ENABLED = 'DYNAMODB_TABLE_ENCRYPTION_ENABLED';\n  /**\n   * Checks whether provisioned DynamoDB throughput is approaching the maximum limit for your account.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/dynamodb-throughput-limit-check.html\n   */\n  public static readonly DYNAMODB_THROUGHPUT_LIMIT_CHECK = 'DYNAMODB_THROUGHPUT_LIMIT_CHECK';\n  /**\n   * Checks if Amazon Elastic Block Store (Amazon EBS) volumes are added in backup plans of AWS Backup.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ebs-in-backup-plan.html\n   */\n  public static readonly EBS_IN_BACKUP_PLAN = 'EBS_IN_BACKUP_PLAN';\n  /**\n   * Checks whether Amazon Elastic File System (Amazon EFS) file systems are added\n   * in the backup plans of AWS Backup.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/efs-in-backup-plan.html\n   */\n  public static readonly EFS_IN_BACKUP_PLAN = 'EFS_IN_BACKUP_PLAN';\n  /**\n   * Check that Amazon Elastic Block Store (EBS) encryption is enabled by default.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-ebs-encryption-by-default.html\n   */\n  public static readonly EC2_EBS_ENCRYPTION_BY_DEFAULT = 'EC2_EBS_ENCRYPTION_BY_DEFAULT';\n  /**\n   * Checks whether EBS optimization is enabled for your EC2 instances that can be EBS-optimized.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ebs-optimized-instance.html\n   */\n  public static readonly EBS_OPTIMIZED_INSTANCE = 'EBS_OPTIMIZED_INSTANCE';\n  /**\n   * Checks if Amazon Elastic Block Store (Amazon EBS) volumes are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ebs-resources-protected-by-backup-plan.html\n   */\n  public static readonly EBS_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'EBS_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks whether Amazon Elastic Block Store snapshots are not publicly restorable.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ebs-snapshot-public-restorable-check.html\n   */\n  public static readonly EBS_SNAPSHOT_PUBLIC_RESTORABLE_CHECK = 'EBS_SNAPSHOT_PUBLIC_RESTORABLE_CHECK';\n  /**\n   * Checks whether detailed monitoring is enabled for EC2 instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instance-detailed-monitoring-enabled.html\n   */\n  public static readonly EC2_INSTANCE_DETAILED_MONITORING_ENABLED = 'EC2_INSTANCE_DETAILED_MONITORING_ENABLED';\n  /**\n   * Checks whether the Amazon EC2 instances in your account are managed by AWS Systems Manager.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instance-managed-by-systems-manager.html\n   */\n  public static readonly EC2_INSTANCE_MANAGED_BY_SSM = 'EC2_INSTANCE_MANAGED_BY_SSM';\n  /**\n   * Checks if an Amazon Elastic Compute Cloud (Amazon EC2) instance has an Identity and Access\n   * Management (IAM) profile attached to it. This rule is NON_COMPLIANT if no IAM profile is\n   * attached to the Amazon EC2 instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instance-profile-attached.html\n   */\n  public static readonly EC2_INSTANCE_PROFILE_ATTACHED = 'EC2_INSTANCE_PROFILE_ATTACHED';\n  /**\n   * Checks if Amazon Elastic Compute Cloud (Amazon EC2) uses multiple ENIs (Elastic Network Interfaces)\n   * or Elastic Fabric Adapters (EFAs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instance-multiple-eni-check.html\n   */\n  public static readonly EC2_INSTANCE_MULTIPLE_ENI_CHECK = 'EC2_INSTANCE_MULTIPLE_ENI_CHECK';\n  /**\n   * Checks whether Amazon Elastic Compute Cloud (Amazon EC2) instances have a public IP association.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instance-no-public-ip.html\n   */\n  public static readonly EC2_INSTANCE_NO_PUBLIC_IP = 'EC2_INSTANCE_NO_PUBLIC_IP';\n  /**\n   * Checks if a recovery point was created for Amazon Elastic Compute Cloud (Amazon EC2) instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-last-backup-recovery-point-created.html\n   */\n  public static readonly EC2_LAST_BACKUP_RECOVERY_POINT_CREATED = 'EC2_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks whether your EC2 instances belong to a virtual private cloud (VPC).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instances-in-vpc.html\n   */\n  public static readonly EC2_INSTANCES_IN_VPC = 'INSTANCES_IN_VPC';\n  /**\n   * Checks that none of the specified applications are installed on the instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-applications-blacklisted.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_APPLICATIONS_BLOCKED = 'EC2_MANAGEDINSTANCE_APPLICATIONS_BLACKLISTED';\n  /**\n   * Checks whether all of the specified applications are installed on the instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-applications-required.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_APPLICATIONS_REQUIRED = 'EC2_MANAGEDINSTANCE_APPLICATIONS_REQUIRED';\n  /**\n   * Checks whether the compliance status of AWS Systems Manager association compliance is COMPLIANT\n   * or NON_COMPLIANT after the association execution on the instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-association-compliance-status-check.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_ASSOCIATION_COMPLIANCE_STATUS_CHECK = 'EC2_MANAGEDINSTANCE_ASSOCIATION_COMPLIANCE_STATUS_CHECK';\n  /**\n   * Checks whether instances managed by AWS Systems Manager are configured to collect blocked inventory types.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-inventory-blacklisted.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_INVENTORY_BLOCKED = 'EC2_MANAGEDINSTANCE_INVENTORY_BLACKLISTED';\n  /**\n   * Checks whether the compliance status of the Amazon EC2 Systems Manager patch compliance is\n   * COMPLIANT or NON_COMPLIANT after the patch installation on the instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-patch-compliance-status-check.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_PATCH_COMPLIANCE_STATUS_CHECK = 'EC2_MANAGEDINSTANCE_PATCH_COMPLIANCE_STATUS_CHECK';\n  /**\n   * Checks whether EC2 managed instances have the desired configurations.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-managedinstance-platform-check.html\n   */\n  public static readonly EC2_MANAGED_INSTANCE_PLATFORM_CHECK = 'EC2_MANAGEDINSTANCE_PLATFORM_CHECK';\n  /**\n   * Checks if running Amazon Elastic Compute Cloud (EC2) instances are launched using amazon key pairs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-no-amazon-key-pair.html\n   */\n  public static readonly EC2_NO_AMAZON_KEY_PAIR = 'EC2_NO_AMAZON_KEY_PAIR';\n  /**\n   * Checks if the virtualization type of an EC2 instance is paravirtual.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-paravirtual-instance-check.html\n   */\n  public static readonly EC2_PARAVIRTUAL_INSTANCE_CHECK = 'EC2_PARAVIRTUAL_INSTANCE_CHECK';\n  /**\n   * Checks if Amazon Elastic Compute Cloud (Amazon EC2) instances are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-resources-protected-by-backup-plan.html\n   */\n  public static readonly EC2_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'EC2_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks that security groups are attached to Amazon Elastic Compute Cloud (Amazon EC2) instances\n   * or to an elastic network interface.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-security-group-attached-to-eni.html\n   */\n  public static readonly EC2_SECURITY_GROUP_ATTACHED_TO_ENI = 'EC2_SECURITY_GROUP_ATTACHED_TO_ENI';\n  /**\n   * Checks if non-default security groups are attached to Elastic network interfaces (ENIs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-security-group-attached-to-eni-periodic.html\n   */\n  public static readonly EC2_SECURITY_GROUP_ATTACHED_TO_ENI_PERIODIC = 'EC2_SECURITY_GROUP_ATTACHED_TO_ENI_PERIODIC';\n  /**\n   * Checks whether there are instances stopped for more than the allowed number of days.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-stopped-instance.html\n   */\n  public static readonly EC2_STOPPED_INSTANCE = 'EC2_STOPPED_INSTANCE';\n  /**\n   * Checks if an Amazon Elastic Compute Cloud (EC2) instance metadata\n   * has a specified token hop limit that is below the desired limit.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-token-hop-limit-check.html\n   */\n  public static readonly EC2_TOKEN_HOP_LIMIT_CHECK = 'EC2_TOKEN_HOP_LIMIT_CHECK';\n  /**\n   * Checks if Amazon Elastic Compute Cloud (Amazon EC2) Transit Gateways have 'AutoAcceptSharedAttachments' enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-transit-gateway-auto-vpc-attach-disabled.html\n   */\n  public static readonly EC2_TRANSIT_GATEWAY_AUTO_VPC_ATTACH_DISABLED = 'EC2_TRANSIT_GATEWAY_AUTO_VPC_ATTACH_DISABLED';\n  /**\n   * Checks whether EBS volumes are attached to EC2 instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-volume-inuse-check.html\n   */\n  public static readonly EC2_VOLUME_INUSE_CHECK = 'EC2_VOLUME_INUSE_CHECK';\n  /**\n   * Checks if a private Amazon Elastic Container Registry (ECR) repository has image scanning enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecr-private-image-scanning-enabled.html\n   */\n  public static readonly ECR_PRIVATE_IMAGE_SCANNING_ENABLED = 'ECR_PRIVATE_IMAGE_SCANNING_ENABLED';\n  /**\n   * Checks if a private Amazon Elastic Container Registry (ECR) repository has at least one lifecycle policy configured.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecr-private-lifecycle-policy-configured.html\n   */\n  public static readonly ECR_PRIVATE_LIFECYCLE_POLICY_CONFIGURED = 'ECR_PRIVATE_LIFECYCLE_POLICY_CONFIGURED';\n  /**\n   * Checks if a private Amazon Elastic Container Registry (ECR) repository has tag immutability enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecr-private-tag-immutability-enabled.html\n   */\n  public static readonly ECR_PRIVATE_TAG_IMMUTABILITY_ENABLED = 'ECR_PRIVATE_TAG_IMMUTABILITY_ENABLED';\n  /**\n   * Checks if the networking mode for active ECSTaskDefinitions is set to \u2018awsvpc\u2019.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-awsvpc-networking-enabled.html\n   */\n  public static readonly ECS_AWSVPC_NETWORKING_ENABLED = 'ECS_AWSVPC_NETWORKING_ENABLED';\n  /**\n   * Checks if the privileged parameter in the container definition of ECSTaskDefinitions is set to \u2018true\u2019.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-instances-in-vpc.html\n   */\n  public static readonly ECS_CONTAINERS_NONPRIVILEGED = 'ECS_CONTAINERS_NONPRIVILEGED';\n  /**\n   * Checks if Amazon Elastic Container Service (Amazon ECS) Containers only have read-only access to its root filesystems.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-containers-readonly-access.html\n   */\n  public static readonly ECS_CONTAINERS_READONLY_ACCESS = 'ECS_CONTAINERS_READONLY_ACCESS';\n  /**\n   * Checks if Amazon Elastic Container Service clusters have container insights enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-container-insights-enabled.html\n   */\n  public static readonly ECS_CONTAINER_INSIGHTS_ENABLED = 'ECS_CONTAINER_INSIGHTS_ENABLED';\n  /**\n   * Checks if Amazon Elastic Container Service (ECS) Fargate Services\n   * is running on the latest Fargate platform version.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-fargate-latest-platform-version.html\n   */\n  public static readonly ECS_FARGATE_LATEST_PLATFORM_VERSION = 'ECS_FARGATE_LATEST_PLATFORM_VERSION';\n  /**\n   * Checks if secrets are passed as container environment variables.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-no-environment-secrets.html\n   */\n  public static readonly ECS_NO_ENVIRONMENT_SECRETS = 'ECS_NO_ENVIRONMENT_SECRETS';\n  /**\n   * Checks if logConfiguration is set on active ECS Task Definitions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-task-definition-log-configuration.html\n   */\n  public static readonly ECS_TASK_DEFINITION_LOG_CONFIGURATION = 'ECS_TASK_DEFINITION_LOG_CONFIGURATION';\n  /**\n   * Checks if Amazon Elastic Container Service (ECS) task definitions have a set memory limit for its container definitions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-task-definition-memory-hard-limit.html\n   */\n  public static readonly ECS_TASK_DEFINITION_MEMORY_HARD_LIMIT = 'ECS_TASK_DEFINITION_MEMORY_HARD_LIMIT';\n  /**\n   * Checks if ECSTaskDefinitions specify a user\n   * for Amazon Elastic Container Service (Amazon ECS) EC2 launch type containers to run on.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ecs-task-definition-nonroot-user.html\n   */\n  public static readonly ECS_TASK_DEFINITION_NONROOT_USER = 'ECS_TASK_DEFINITION_NONROOT_USER';\n  /**\n   * Checks if ECSTaskDefinitions are configured to share a host\u2019s process namespace\n   * with its Amazon Elastic Container Service (Amazon ECS) containers.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-stopped-instance.html\n   */\n  public static readonly ECS_TASK_DEFINITION_PID_MODE_CHECK = 'ECS_TASK_DEFINITION_PID_MODE_CHECK';\n  /**\n   * Checks if an Amazon Elastic Container Service (Amazon ECS) task definition\n   * with host networking mode has 'privileged' or 'user' container definitions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-volume-inuse-check.html\n   */\n  public static readonly EC2_VOLUME_IECS_TASK_DEFINITION_USER_FOR_HOST_MODE_CHECKNUSE_CHECK = 'ECS_TASK_DEFINITION_USER_FOR_HOST_MODE_CHECK';\n  /**\n   * Checks if Amazon Elastic File System (Amazon EFS) access points are configured to enforce a root directory.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/efs-access-point-enforce-root-directory.html\n   */\n  public static readonly EFS_ACCESS_POINT_ENFORCE_ROOT_DIRECTORY = 'EFS_ACCESS_POINT_ENFORCE_ROOT_DIRECTORY';\n  /**\n   * Checks if Amazon Elastic File System (Amazon EFS) access points are configured to enforce a user identity.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-volume-inuse-check.html\n   */\n  public static readonly EFS_ACCESS_POINT_ENFORCE_USER_IDENTITY = 'EFS_ACCESS_POINT_ENFORCE_USER_IDENTITY';\n  /**\n   * hecks whether Amazon Elastic File System (Amazon EFS) is configured to encrypt the file data\n   * using AWS Key Management Service (AWS KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/efs-encrypted-check.html\n   */\n  public static readonly EFS_ENCRYPTED_CHECK = 'EFS_ENCRYPTED_CHECK';\n  /**\n   * Checks if a recovery point was created for Amazon Elastic File System (Amazon EFS) File Systems.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/efs-last-backup-recovery-point-created.html\n   */\n  public static readonly EFS_LAST_BACKUP_RECOVERY_POINT_CREATED = 'EFS_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks if Amazon Elastic File System (Amazon EFS) File Systems are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/efs-resources-protected-by-backup-plan.html\n   */\n  public static readonly EFS_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'EFS_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks whether all Elastic IP addresses that are allocated to a VPC are attached to\n   * EC2 instances or in-use elastic network interfaces (ENIs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/eip-attached.html\n   */\n  public static readonly EIP_ATTACHED = 'EIP_ATTACHED';\n  /**\n   * Checks whether Amazon Elasticsearch Service (Amazon ES) domains have encryption\n   * at rest configuration enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elasticsearch-encrypted-at-rest.html\n   */\n  public static readonly ELASTICSEARCH_ENCRYPTED_AT_REST = 'ELASTICSEARCH_ENCRYPTED_AT_REST';\n  /**\n   * Checks whether Amazon Elasticsearch Service (Amazon ES) domains are in\n   * Amazon Virtual Private Cloud (Amazon VPC).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elasticsearch-in-vpc-only.html\n   */\n  public static readonly ELASTICSEARCH_IN_VPC_ONLY = 'ELASTICSEARCH_IN_VPC_ONLY';\n  /**\n   * Check if the Amazon ElastiCache Redis clusters have automatic backup turned on.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elasticache-redis-cluster-automatic-backup-check.html\n   */\n  public static readonly ELASTICACHE_REDIS_CLUSTER_AUTOMATIC_BACKUP_CHECK = 'ELASTICACHE_REDIS_CLUSTER_AUTOMATIC_BACKUP_CHECK';\n  /**\n   * Checks whether your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version\n   * is configured with Instance Metadata Service Version 2 (IMDSv2).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ec2-imdsv2-check.html\n   */\n  public static readonly EC2_IMDSV2_CHECK = 'EC2_IMDSV2_CHECK';\n  /**\n   * Checks if an Amazon Elastic Kubernetes Service (EKS) cluster is running the oldest supported version.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/eks-cluster-oldest-supported-version.html\n   */\n  public static readonly EKS_CLUSTER_OLDEST_SUPPORTED_VERSION = 'EKS_CLUSTER_OLDEST_SUPPORTED_VERSION';\n  /**\n   * Checks if an Amazon Elastic Kubernetes Service (EKS) cluster is running a supported Kubernetes version.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/eks-cluster-supported-version.html\n   */\n  public static readonly EKS_CLUSTER_SUPPORTED_VERSION = 'EKS_CLUSTER_SUPPORTED_VERSION';\n  /**\n   * Checks whether Amazon Elastic Kubernetes Service (Amazon EKS) endpoint is not publicly accessible.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/eks-endpoint-no-public-access.html\n   */\n  public static readonly EKS_ENDPOINT_NO_PUBLIC_ACCESS = 'EKS_ENDPOINT_NO_PUBLIC_ACCESS';\n  /**\n   * Checks whether Amazon Elastic Kubernetes Service clusters are configured to have Kubernetes\n   * secrets encrypted using AWS Key Management Service (KMS) keys.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/eks-secrets-encrypted.html\n   */\n  public static readonly EKS_SECRETS_ENCRYPTED = 'EKS_SECRETS_ENCRYPTED';\n  /**\n   * Check that Amazon ElasticSearch Service nodes are encrypted end to end.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elasticsearch-node-to-node-encryption-check.html\n   */\n  public static readonly ELASTICSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK = 'ELASTICSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK';\n  /**\n   * Checks if managed platform updates in an AWS Elastic Beanstalk environment is enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elastic-beanstalk-managed-updates-enabled.html\n   */\n  public static readonly ELASTIC_BEANSTALK_MANAGED_UPDATES_ENABLED = 'ELASTIC_BEANSTALK_MANAGED_UPDATES_ENABLED';\n  /**\n   * Checks if Application Load Balancers and Network Load Balancers\n   * have listeners that are configured to use certificates from AWS Certificate Manager (ACM).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elbv2-acm-certificate-required.html\n   */\n  public static readonly ELBV2_ACM_CERTIFICATE_REQUIRED = 'ELBV2_ACM_CERTIFICATE_REQUIRED';\n  /**\n   * Checks if an Elastic Load Balancer V2 (Application, Network, or Gateway Load Balancer)\n   * has registered instances from multiple Availability Zones (AZ's).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elbv2-multiple-az.html\n   */\n  public static readonly ELBV2_MULTIPLE_AZ = 'ELBV2_MULTIPLE_AZ';\n  /**\n   * Checks if cross-zone load balancing is enabled for the Classic Load Balancers (CLBs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-cross-zone-load-balancing-enabled.html\n   */\n  public static readonly ELB_CROSS_ZONE_LOAD_BALANCING_ENABLED = 'ELB_CROSS_ZONE_LOAD_BALANCING_ENABLED';\n  /**\n   * Checks whether your Classic Load Balancer is configured with SSL or HTTPS listeners.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-tls-https-listeners-only.html\n   */\n  public static readonly ELB_TLS_HTTPS_LISTENERS_ONLY = 'ELB_TLS_HTTPS_LISTENERS_ONLY';\n  /**\n   * Checks whether the Classic Load Balancers use SSL certificates provided by AWS Certificate Manager.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-acm-certificate-required.html\n   */\n  public static readonly ELB_ACM_CERTIFICATE_REQUIRED = 'ELB_ACM_CERTIFICATE_REQUIRED';\n  /**\n   * Checks whether your Classic Load Balancer SSL listeners are using a custom policy.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-custom-security-policy-ssl-check.html\n   */\n  public static readonly ELB_CUSTOM_SECURITY_POLICY_SSL_CHECK = 'ELB_CUSTOM_SECURITY_POLICY_SSL_CHECK';\n  /**\n   * Checks whether Elastic Load Balancing has deletion protection enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-deletion-protection-enabled.html\n   */\n  public static readonly ELB_DELETION_PROTECTION_ENABLED = 'ELB_DELETION_PROTECTION_ENABLED';\n  /**\n   * Checks whether the Application Load Balancer and the Classic Load Balancer have logging enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-logging-enabled.html\n   */\n  public static readonly ELB_LOGGING_ENABLED = 'ELB_LOGGING_ENABLED';\n  /**\n   * Checks whether your Classic Load Balancer SSL listeners are using a predefined policy.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/elb-predefined-security-policy-ssl-check.html\n   */\n  public static readonly ELB_PREDEFINED_SECURITY_POLICY_SSL_CHECK = 'ELB_PREDEFINED_SECURITY_POLICY_SSL_CHECK';\n  /**\n   * Checks that Amazon EMR clusters have Kerberos enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/emr-kerberos-enabled.html\n   */\n  public static readonly EMR_KERBEROS_ENABLED = 'EMR_KERBEROS_ENABLED';\n  /**\n   * Checks whether Amazon Elastic MapReduce (EMR) clusters' master nodes have public IPs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/emr-master-no-public-ip.html\n   */\n  public static readonly EMR_MASTER_NO_PUBLIC_IP = 'EMR_MASTER_NO_PUBLIC_IP';\n  /**\n   * Checks whether the EBS volumes that are in an attached state are encrypted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/encrypted-volumes.html\n   */\n  public static readonly EBS_ENCRYPTED_VOLUMES = 'ENCRYPTED_VOLUMES';\n  /**\n   * Checks whether the security groups associated inScope resources are compliant with the\n   * master security groups at each rule level based on allowSecurityGroup and denySecurityGroup flag.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-security-group-audit-policy-check.html\n   *\n   * @deprecated Inactive managed rule\n   *\n   */\n  public static readonly FMS_SECURITY_GROUP_AUDIT_POLICY_CHECK = 'FMS_SECURITY_GROUP_AUDIT_POLICY_CHECK';\n  /**\n   * Checks whether AWS Firewall Manager created security groups content is the same as the master security groups.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-security-group-content-check.html\n   *\n   * @deprecated Inactive managed rule\n   *\n   */\n  public static readonly FMS_SECURITY_GROUP_CONTENT_CHECK = 'FMS_SECURITY_GROUP_CONTENT_CHECK';\n  /**\n   * Checks whether Amazon EC2 or an elastic network interface is associated with AWS Firewall Manager security groups.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-security-group-resource-association-check.html\n   *\n   * @deprecated Inactive managed rule\n   *\n   */\n  public static readonly FMS_SECURITY_GROUP_RESOURCE_ASSOCIATION_CHECK = 'FMS_SECURITY_GROUP_RESOURCE_ASSOCIATION_CHECK';\n  /**\n   * Checks whether an Application Load Balancer, Amazon CloudFront distributions,\n   * Elastic Load Balancer or Elastic IP has AWS Shield protection.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-shield-resource-policy-check.html\n   */\n  public static readonly FMS_SHIELD_RESOURCE_POLICY_CHECK = 'FMS_SHIELD_RESOURCE_POLICY_CHECK';\n  /**\n   * Checks whether the web ACL is associated with an Application Load Balancer, API Gateway stage,\n   * or Amazon CloudFront distributions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-webacl-resource-policy-check.html\n   */\n  public static readonly FMS_WEBACL_RESOURCE_POLICY_CHECK = 'FMS_WEBACL_RESOURCE_POLICY_CHECK';\n  /**\n   * Checks that the rule groups associate with the web ACL at the correct priority.\n   * The correct priority is decided by the rank of the rule groups in the ruleGroups parameter.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fms-webacl-rulegroup-association-check.html\n   */\n  public static readonly FMS_WEBACL_RULEGROUP_ASSOCIATION_CHECK = 'FMS_WEBACL_RULEGROUP_ASSOCIATION_CHECK';\n  /**\n   * Checks if a recovery point was created for Amazon FSx File Systems.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fsx-last-backup-recovery-point-created.html\n   */\n  public static readonly FSX_LAST_BACKUP_RECOVERY_POINT_CREATED = 'FSX_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks if Amazon FSx File Systems are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/fsx-resources-protected-by-backup-plan.html\n   */\n  public static readonly FSX_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'FSX_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks whether Amazon GuardDuty is enabled in your AWS account and region. If you provide an AWS account for centralization,\n   * the rule evaluates the Amazon GuardDuty results in the centralized account.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/guardduty-enabled-centralized.html\n   */\n  public static readonly GUARDDUTY_ENABLED_CENTRALIZED = 'GUARDDUTY_ENABLED_CENTRALIZED';\n  /**\n   * Checks whether the Amazon GuardDuty has findings that are non archived.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/guardduty-non-archived-findings.html\n   */\n  public static readonly GUARDDUTY_NON_ARCHIVED_FINDINGS = 'GUARDDUTY_NON_ARCHIVED_FINDINGS';\n  /**\n   * Checks that inline policy feature is not in use.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-no-inline-policy-check.html\n   */\n  public static readonly IAM_NO_INLINE_POLICY_CHECK = 'IAM_NO_INLINE_POLICY_CHECK';\n  /**\n   * Checks whether IAM groups have at least one IAM user.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-group-has-users-check.html\n   */\n  public static readonly IAM_GROUP_HAS_USERS_CHECK = 'IAM_GROUP_HAS_USERS_CHECK';\n  /**\n   * Checks whether the account password policy for IAM users meets the specified requirements\n   * indicated in the parameters.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-password-policy.html\n   */\n  public static readonly IAM_PASSWORD_POLICY = 'IAM_PASSWORD_POLICY';\n  /**\n   * Checks whether for each IAM resource, a policy ARN in the input parameter is attached to the IAM resource.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-policy-blacklisted-check.html\n   */\n  public static readonly IAM_POLICY_BLOCKED_CHECK = 'IAM_POLICY_BLACKLISTED_CHECK';\n  /**\n   * Checks whether the IAM policy ARN is attached to an IAM user, or an IAM group with one or more IAM users,\n   * or an IAM role with one or more trusted entity.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-policy-in-use.html\n   */\n  public static readonly IAM_POLICY_IN_USE = 'IAM_POLICY_IN_USE';\n  /**\n   * Checks the IAM policies that you create for Allow statements that grant permissions to all actions on all resources.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-policy-no-statements-with-admin-access.html\n   */\n  public static readonly IAM_POLICY_NO_STATEMENTS_WITH_ADMIN_ACCESS = 'IAM_POLICY_NO_STATEMENTS_WITH_ADMIN_ACCESS';\n  /**\n   * Checks if AWS Identity and Access Management (IAM) policies that you create grant permissions to all actions on individual AWS resources.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-policy-no-statements-with-full-access.html\n   */\n  public static readonly IAM_POLICY_NO_STATEMENTS_WITH_FULL_ACCESS = 'IAM_POLICY_NO_STATEMENTS_WITH_FULL_ACCESS';\n  /**\n   * Checks that AWS Identity and Access Management (IAM) policies in a list of policies are attached to all AWS roles.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-role-managed-policy-check.html\n   */\n  public static readonly IAM_ROLE_MANAGED_POLICY_CHECK = 'IAM_ROLE_MANAGED_POLICY_CHECK';\n  /**\n   * Checks whether the root user access key is available.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-root-access-key-check.html\n   */\n  public static readonly IAM_ROOT_ACCESS_KEY_CHECK = 'IAM_ROOT_ACCESS_KEY_CHECK';\n  /**\n   * Checks whether IAM users are members of at least one IAM group.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-user-group-membership-check.html\n   */\n  public static readonly IAM_USER_GROUP_MEMBERSHIP_CHECK = 'IAM_USER_GROUP_MEMBERSHIP_CHECK';\n  /**\n   * Checks whether the AWS Identity and Access Management users have multi-factor authentication (MFA) enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-user-mfa-enabled.html\n   */\n  public static readonly IAM_USER_MFA_ENABLED = 'IAM_USER_MFA_ENABLED';\n  /**\n   * Checks that none of your IAM users have policies attached. IAM users must inherit permissions from IAM groups or roles.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-user-no-policies-check.html\n   */\n  public static readonly IAM_USER_NO_POLICIES_CHECK = 'IAM_USER_NO_POLICIES_CHECK';\n  /**\n   * Checks whether your AWS Identity and Access Management (IAM) users have passwords or\n   * active access keys that have not been used within the specified number of days you provided.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/iam-user-unused-credentials-check.html\n   */\n  public static readonly IAM_USER_UNUSED_CREDENTIALS_CHECK = 'IAM_USER_UNUSED_CREDENTIALS_CHECK';\n  /**\n   * Checks that Internet gateways (IGWs) are only attached to an authorized Amazon Virtual Private Cloud (VPCs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/internet-gateway-authorized-vpc-only.html\n   */\n  public static readonly INTERNET_GATEWAY_AUTHORIZED_VPC_ONLY = 'INTERNET_GATEWAY_AUTHORIZED_VPC_ONLY';\n  /**\n   * Checks if Amazon Kinesis streams are encrypted at rest with server-side encryption.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/kinesis-stream-encrypted.html\n   */\n  public static readonly KINESIS_STREAM_ENCRYPTED = 'KINESIS_STREAM_ENCRYPTED';\n  /**\n   * Checks whether customer master keys (CMKs) are not scheduled for deletion in AWS Key Management Service (KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/kms-cmk-not-scheduled-for-deletion.html\n   */\n  public static readonly KMS_CMK_NOT_SCHEDULED_FOR_DELETION = 'KMS_CMK_NOT_SCHEDULED_FOR_DELETION';\n  /**\n   * Checks whether the AWS Lambda function is configured with function-level concurrent execution limit.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-concurrency-check.html\n   */\n  public static readonly LAMBDA_CONCURRENCY_CHECK = 'LAMBDA_CONCURRENCY_CHECK';\n  /**\n   * Checks whether an AWS Lambda function is configured with a dead-letter queue.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-dlq-check.html\n   */\n  public static readonly LAMBDA_DLQ_CHECK = 'LAMBDA_DLQ_CHECK';\n  /**\n   * Checks whether the AWS Lambda function policy attached to the Lambda resource prohibits public access.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-function-public-access-prohibited.html\n   */\n  public static readonly LAMBDA_FUNCTION_PUBLIC_ACCESS_PROHIBITED = 'LAMBDA_FUNCTION_PUBLIC_ACCESS_PROHIBITED';\n  /**\n   * Checks that the lambda function settings for runtime, role, timeout, and memory size match the expected values.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-function-settings-check.html\n   */\n  public static readonly LAMBDA_FUNCTION_SETTINGS_CHECK = 'LAMBDA_FUNCTION_SETTINGS_CHECK';\n  /**\n   * Checks whether an AWS Lambda function is in an Amazon Virtual Private Cloud.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-inside-vpc.html\n   */\n  public static readonly LAMBDA_INSIDE_VPC = 'LAMBDA_INSIDE_VPC';\n  /**\n   * Checks if Lambda has more than 1 availability zone associated.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/lambda-vpc-multi-az-check.html\n   */\n  public static readonly LAMBDA_VPC_MULTI_AZ_CHECK = 'LAMBDA_VPC_MULTI_AZ_CHECK';\n  /**\n   * Checks whether AWS Multi-Factor Authentication (MFA) is enabled for all IAM users that use a console password.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/mfa-enabled-for-iam-console-access.html\n   */\n  public static readonly MFA_ENABLED_FOR_IAM_CONSOLE_ACCESS = 'MFA_ENABLED_FOR_IAM_CONSOLE_ACCESS';\n  /**\n   * Checks that there is at least one multi-region AWS CloudTrail.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/multi-region-cloudtrail-enabled.html\n   */\n  public static readonly CLOUDTRAIL_MULTI_REGION_ENABLED = 'MULTI_REGION_CLOUD_TRAIL_ENABLED';\n  /**\n   * Checks if default ports for SSH/RDP ingress traffic for network access control lists (NACLs) is unrestricted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/nacl-no-unrestricted-ssh-rdp.html\n   */\n  public static readonly NACL_NO_UNRESTRICTED_SSH_RDP = 'NACL_NO_UNRESTRICTED_SSH_RDP';\n  /**\n   * Checks if an AWS Network Firewall policy is configured with a user defined stateless default action for fragmented packets.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/netfw-policy-default-action-fragment-packets.html\n   */\n  public static readonly NETFW_POLICY_DEFAULT_ACTION_FRAGMENT_PACKETS = 'NETFW_POLICY_DEFAULT_ACTION_FRAGMENT_PACKETS';\n  /**\n   * Checks if an AWS Network Firewall policy is configured with a user defined default stateless action for full packets.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/netfw-policy-default-action-full-packets.html\n   */\n  public static readonly NETFW_POLICY_DEFAULT_ACTION_FULL_PACKETS = 'NETFW_POLICY_DEFAULT_ACTION_FULL_PACKETS';\n  /**\n   * Check AWS Network Firewall policy is associated with stateful OR stateless rule groups.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/netfw-policy-rule-group-associated.html\n   */\n  public static readonly NETFW_POLICY_RULE_GROUP_ASSOCIATED = 'NETFW_POLICY_RULE_GROUP_ASSOCIATED';\n  /**\n   * Checks if a Stateless Network Firewall Rule Group contains rules.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/netfw-stateless-rule-group-not-empty.html\n   */\n  public static readonly NETFW_STATELESS_RULE_GROUP_NOT_EMPTY = 'NETFW_STATELESS_RULE_GROUP_NOT_EMPTY';\n  /**\n   * Checks if cross-zone load balancing is enabled on Network Load Balancers (NLBs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/nlb-cross-zone-load-balancing-enabled.html\n   */\n  public static readonly NLB_CROSS_ZONE_LOAD_BALANCING_ENABLED = 'NLB_CROSS_ZONE_LOAD_BALANCING_ENABLED';\n  /**\n   * Checks if Amazon OpenSearch Service domains have fine-grained access control enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-access-control-enabled.html\n   */\n  public static readonly OPENSEARCH_ACCESS_CONTROL_ENABLED = 'OPENSEARCH_ACCESS_CONTROL_ENABLED';\n  /**\n   * Checks if Amazon OpenSearch Service domains have audit logging enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-audit-logging-enabled.html\n   */\n  public static readonly OPENSEARCH_AUDIT_LOGGING_ENABLED = 'OPENSEARCH_AUDIT_LOGGING_ENABLED';\n  /**\n   * Checks if Amazon OpenSearch Service domains are configured with at least three data nodes and zoneAwarenessEnabled is true.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-data-node-fault-tolerance.html\n   */\n  public static readonly OPENSEARCH_DATA_NODE_FAULT_TOLERANCE = 'OPENSEARCH_DATA_NODE_FAULT_TOLERANCE';\n  /**\n   * Checks if Amazon OpenSearch Service domains have encryption at rest configuration enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-encrypted-at-rest.html\n   */\n  public static readonly OPENSEARCH_ENCRYPTED_AT_REST = 'OPENSEARCH_ENCRYPTED_AT_REST';\n  /**\n   * Checks whether connections to OpenSearch domains are using HTTPS.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-https-required.html\n   */\n  public static readonly OPENSEARCH_HTTPS_REQUIRED = 'OPENSEARCH_HTTPS_REQUIRED';\n  /**\n   * Checks if Amazon OpenSearch Service domains are in an Amazon Virtual Private Cloud (VPC).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-in-vpc-only.html\n   */\n  public static readonly OPENSEARCH_IN_VPC_ONLY = 'OPENSEARCH_IN_VPC_ONLY';\n  /**\n   * Checks if Amazon OpenSearch Service domains are configured to send logs to Amazon CloudWatch Logs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-logs-to-cloudwatch.html\n   */\n  public static readonly OPENSEARCH_LOGS_TO_CLOUDWATCH = 'OPENSEARCH_LOGS_TO_CLOUDWATCH';\n  /**\n   * Check if Amazon OpenSearch Service nodes are encrypted end to end.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/opensearch-node-to-node-encryption-check.html\n   */\n  public static readonly OPENSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK = 'OPENSEARCH_NODE_TO_NODE_ENCRYPTION_CHECK';\n  /**\n   * Checks if Amazon Relational Database Service (RDS) database instances are configured for automatic minor version upgrades.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-automatic-minor-version-upgrade-enabled.html\n   */\n  public static readonly RDS_AUTOMATIC_MINOR_VERSION_UPGRADE_ENABLED = 'RDS_AUTOMATIC_MINOR_VERSION_UPGRADE_ENABLED';\n  /**\n   * Checks if an Amazon Relational Database Service (Amazon RDS) database cluster has changed the admin username from its default value.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-cluster-default-admin-check.html\n   */\n  public static readonly RDS_CLUSTER_DEFAULT_ADMIN_CHECK = 'RDS_CLUSTER_DEFAULT_ADMIN_CHECK';\n  /**\n   * Checks if an Amazon Relational Database Service (Amazon RDS) cluster has deletion protection enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-cluster-deletion-protection-enabled.html\n   */\n  public static readonly RDS_CLUSTER_DELETION_PROTECTION_ENABLED = 'RDS_CLUSTER_DELETION_PROTECTION_ENABLED';\n  /**\n   * Checks if an Amazon RDS Cluster has AWS Identity and Access Management (IAM) authentication enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-cluster-iam-authentication-enabled.html\n   */\n  public static readonly RDS_CLUSTER_IAM_AUTHENTICATION_ENABLED = 'RDS_CLUSTER_IAM_AUTHENTICATION_ENABLED';\n  /**\n   * Checks if Multi-AZ replication is enabled on Amazon Aurora and Hermes clusters managed by Amazon Relational Database Service (Amazon RDS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-cluster-multi-az-enabled.html\n   */\n  public static readonly RDS_CLUSTER_MULTI_AZ_ENABLED = 'RDS_CLUSTER_MULTI_AZ_ENABLED';\n  /**\n   * Checks if an Amazon Relational Database Service (Amazon RDS) database has changed the admin username from its default value.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-instance-default-admin-check.html\n   */\n  public static readonly RDS_INSTANCE_DEFAULT_ADMIN_CHECK = 'RDS_INSTANCE_DEFAULT_ADMIN_CHECK';\n  /**\n   *Checks if there are any Amazon Relational Database Service (RDS) DB security groups that are not the default DB security group.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-db-security-group-not-allowed.html\n   */\n  public static readonly RDS_DB_SECURITY_GROUP_NOT_ALLOWED = 'RDS_DB_SECURITY_GROUP_NOT_ALLOWED';\n  /**\n   * Checks if an Amazon Relational Database Service (Amazon RDS) instance has deletion protection enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-instance-deletion-protection-enabled.html\n   */\n  public static readonly RDS_INSTANCE_DELETION_PROTECTION_ENABLED = 'RDS_INSTANCE_DELETION_PROTECTION_ENABLED';\n  /**\n   * Checks if an Amazon RDS instance has AWS Identity and Access Management (IAM) authentication enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-instance-iam-authentication-enabled.html\n   */\n  public static readonly RDS_INSTANCE_IAM_AUTHENTICATION_ENABLED = 'RDS_INSTANCE_IAM_AUTHENTICATION_ENABLED';\n  /**\n   * Checks that respective logs of Amazon Relational Database Service (Amazon RDS) are enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-logging-enabled.html\n   */\n  public static readonly RDS_LOGGING_ENABLED = 'RDS_LOGGING_ENABLED';\n  /**\n   * Checks that Amazon Redshift automated snapshots are enabled for clusters.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-backup-enabled.html\n   */\n  public static readonly REDSHIFT_BACKUP_ENABLED = 'REDSHIFT_BACKUP_ENABLED';\n  /**\n   * Checks whether enhanced monitoring is enabled for Amazon Relational Database Service (Amazon RDS) instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-enhanced-monitoring-enabled.html\n   */\n  public static readonly RDS_ENHANCED_MONITORING_ENABLED = 'RDS_ENHANCED_MONITORING_ENABLED';\n  /**\n   * Checks whether Amazon Relational Database Service (Amazon RDS) DB snapshots are encrypted.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-snapshot-encrypted.html\n   */\n  public static readonly RDS_SNAPSHOT_ENCRYPTED = 'RDS_SNAPSHOT_ENCRYPTED';\n  /**\n   * Checks whether Amazon Redshift clusters require TLS/SSL encryption to connect to SQL clients.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-require-tls-ssl.html\n   */\n  public static readonly REDSHIFT_REQUIRE_TLS_SSL = 'REDSHIFT_REQUIRE_TLS_SSL';\n  /**\n   * Checks whether Amazon RDS database is present in back plans of AWS Backup.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-in-backup-plan.html\n   */\n  public static readonly RDS_IN_BACKUP_PLAN = 'RDS_IN_BACKUP_PLAN';\n  /**\n   * Checks if a recovery point was created for Amazon Relational Database Service (Amazon RDS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-last-backup-recovery-point-created.html\n   */\n  public static readonly RDS_LAST_BACKUP_RECOVERY_POINT_CREATED = 'RDS_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Check whether the Amazon Relational Database Service instances are not publicly accessible.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-instance-public-access-check.html\n   */\n  public static readonly RDS_INSTANCE_PUBLIC_ACCESS_CHECK = 'RDS_INSTANCE_PUBLIC_ACCESS_CHECK';\n  /**\n   * Checks whether high availability is enabled for your RDS DB instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-multi-az-support.html\n   */\n  public static readonly RDS_MULTI_AZ_SUPPORT = 'RDS_MULTI_AZ_SUPPORT';\n  /**\n   * Checks if Amazon Relational Database Service (Amazon RDS) instances are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-resources-protected-by-backup-plan.html\n   */\n  public static readonly RDS_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'RDS_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-snapshots-public-prohibited.html\n   */\n  public static readonly RDS_SNAPSHOTS_PUBLIC_PROHIBITED = 'RDS_SNAPSHOTS_PUBLIC_PROHIBITED';\n  /**\n   * Checks whether storage encryption is enabled for your RDS DB instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/rds-storage-encrypted.html\n   */\n  public static readonly RDS_STORAGE_ENCRYPTED = 'RDS_STORAGE_ENCRYPTED';\n  /**\n   * Checks if Amazon Redshift clusters are logging audits to a specific bucket.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-audit-logging-enabled.html\n   */\n  public static readonly REDSHIFT_AUDIT_LOGGING_ENABLED = 'REDSHIFT_AUDIT_LOGGING_ENABLED';\n  /**\n   * Checks whether Amazon Redshift clusters have the specified settings.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-cluster-configuration-check.html\n   */\n  public static readonly REDSHIFT_CLUSTER_CONFIGURATION_CHECK = 'REDSHIFT_CLUSTER_CONFIGURATION_CHECK';\n  /**\n   * Checks if Amazon Redshift clusters are using a specified AWS Key Management Service (AWS KMS) key for encryption.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-cluster-kms-enabled.html\n   */\n  public static readonly REDSHIFT_CLUSTER_KMS_ENABLED = 'REDSHIFT_CLUSTER_KMS_ENABLED';\n  /**\n   * Checks whether Amazon Redshift clusters have the specified maintenance settings.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-cluster-maintenancesettings-check.html\n   */\n  public static readonly REDSHIFT_CLUSTER_MAINTENANCE_SETTINGS_CHECK = 'REDSHIFT_CLUSTER_MAINTENANCESETTINGS_CHECK';\n  /**\n   * Checks whether Amazon Redshift clusters are not publicly accessible.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-cluster-public-access-check.html\n   */\n  public static readonly REDSHIFT_CLUSTER_PUBLIC_ACCESS_CHECK = 'REDSHIFT_CLUSTER_PUBLIC_ACCESS_CHECK';\n  /**\n   * Checks if an Amazon Redshift cluster has changed the admin username from its default value.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-default-admin-check.html\n   */\n  public static readonly REDSHIFT_DEFAULT_ADMIN_CHECK = 'REDSHIFT_DEFAULT_ADMIN_CHECK';\n  /**\n   * Checks if a Redshift cluster has changed its database name from the default value.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-default-db-name-check.html\n   */\n  public static readonly REDSHIFT_DEFAULT_DB_NAME_CHECK = 'REDSHIFT_DEFAULT_DB_NAME_CHECK';\n  /**\n   * Checks if Amazon Redshift cluster has 'enhancedVpcRouting' enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/redshift-enhanced-vpc-routing-enabled.html\n   */\n  public static readonly REDSHIFT_ENHANCED_VPC_ROUTING_ENABLED = 'REDSHIFT_ENHANCED_VPC_ROUTING_ENABLED';\n  /**\n   * Checks whether your resources have the tags that you specify.\n   * For example, you can check whether your Amazon EC2 instances have the CostCenter tag.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/required-tags.html\n   */\n  public static readonly REQUIRED_TAGS = 'REQUIRED_TAGS';\n  /**\n   * Checks whether the security groups in use do not allow unrestricted incoming TCP traffic to the specified ports.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/restricted-common-ports.html\n   */\n  public static readonly EC2_SECURITY_GROUPS_RESTRICTED_INCOMING_TRAFFIC = 'RESTRICTED_INCOMING_TRAFFIC';\n  /**\n   * Checks whether the incoming SSH traffic for the security groups is accessible.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/restricted-ssh.html\n   */\n  public static readonly EC2_SECURITY_GROUPS_INCOMING_SSH_DISABLED = 'INCOMING_SSH_DISABLED';\n  /**\n   * Checks whether your AWS account is enabled to use multi-factor authentication (MFA) hardware\n   * device to sign in with root credentials.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/root-account-hardware-mfa-enabled.html\n   */\n  public static readonly ROOT_ACCOUNT_HARDWARE_MFA_ENABLED = 'ROOT_ACCOUNT_HARDWARE_MFA_ENABLED';\n  /**\n   * Checks whether users of your AWS account require a multi-factor authentication (MFA) device\n   * to sign in with root credentials.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/root-account-mfa-enabled.html\n   */\n  public static readonly ROOT_ACCOUNT_MFA_ENABLED = 'ROOT_ACCOUNT_MFA_ENABLED';\n  /**\n   * Checks whether Amazon Simple Storage Service (Amazon S3) bucket has lock enabled, by default.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-default-lock-enabled.html\n   */\n  public static readonly S3_BUCKET_DEFAULT_LOCK_ENABLED = 'S3_BUCKET_DEFAULT_LOCK_ENABLED';\n  /**\n   * Checks whether the Amazon Simple Storage Service (Amazon S3) buckets are encrypted\n   * with AWS Key Management Service (AWS KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-default-encryption-kms.html\n   */\n  public static readonly S3_DEFAULT_ENCRYPTION_KMS = 'S3_DEFAULT_ENCRYPTION_KMS';\n  /**\n   * Checks that AWS Security Hub is enabled for an AWS account.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/securityhub-enabled.html\n   */\n  public static readonly SECURITYHUB_ENABLED = 'SECURITYHUB_ENABLED';\n  /**\n   * Checks whether Amazon SNS topic is encrypted with AWS Key Management Service (AWS KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/sns-encrypted-kms.html\n   */\n  public static readonly SNS_ENCRYPTED_KMS = 'SNS_ENCRYPTED_KMS';\n  /**\n   * Checks if Amazon Simple Notification Service (SNS) logging is enabled\n   * for the delivery status of notification messages sent to a topic for the endpoints.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/sns-topic-message-delivery-notification-enabled.html\n   */\n  public static readonly SNS_TOPIC_MESSAGE_DELIVERY_NOTIFICATION_ENABLED = 'SNS_TOPIC_MESSAGE_DELIVERY_NOTIFICATION_ENABLED';\n  /**\n   * Checks if AWS Systems Manager documents owned by the account are public.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/ssm-document-not-public.html\n   */\n  public static readonly SSM_DOCUMENT_NOT_PUBLIC = 'SSM_DOCUMENT_NOT_PUBLIC';\n  /**\n   * Checks if a recovery point was created for AWS Storage Gateway volumes.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/storagegateway-last-backup-recovery-point-created.html\n   */\n  public static readonly STORAGEGATEWAY_LAST_BACKUP_RECOVERY_POINT_CREATED = 'STORAGEGATEWAY_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * hecks if Amazon Virtual Private Cloud (Amazon VPC) subnets are assigned a public IP address.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/subnet-auto-assign-public-ip-disabled.html\n   */\n  public static readonly SUBNET_AUTO_ASSIGN_PUBLIC_IP_DISABLED = 'SUBNET_AUTO_ASSIGN_PUBLIC_IP_DISABLED';\n  /**\n   * Checks whether the required public access block settings are configured from account level.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-account-level-public-access-blocks.html\n   */\n  public static readonly S3_ACCOUNT_LEVEL_PUBLIC_ACCESS_BLOCKS = 'S3_ACCOUNT_LEVEL_PUBLIC_ACCESS_BLOCKS';\n  /**\n   * Checks if the required public access block settings are configured from account level.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-account-level-public-access-blocks-periodic.html\n   */\n  public static readonly S3_ACCOUNT_LEVEL_PUBLIC_ACCESS_BLOCKS_PERIODIC = 'S3_ACCOUNT_LEVEL_PUBLIC_ACCESS_BLOCKS_PERIODIC';\n  /**\n   * Checks if Amazon Simple Storage Service (Amazon S3) Buckets allow user permissions through access control lists (ACLs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-acl-prohibited.html\n   */\n  public static readonly S3_BUCKET_ACL_PROHIBITED = 'S3_BUCKET_ACL_PROHIBITED';\n  /**\n   * Checks if the Amazon Simple Storage Service bucket policy does not allow blacklisted bucket-level\n   * and object-level actions on resources in the bucket for principals from other AWS accounts.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-blacklisted-actions-prohibited.html\n   */\n  public static readonly S3_BUCKET_BLOCKED_ACTIONS_PROHIBITED = 'S3_BUCKET_BLACKLISTED_ACTIONS_PROHIBITED';\n  /**\n   * Checks if Amazon Simple Storage Service (Amazon S3) buckets are publicly accessible.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-level-public-access-prohibited.html\n   */\n  public static readonly S3_BUCKET_LEVEL_PUBLIC_ACCESS_PROHIBITED = 'S3_BUCKET_LEVEL_PUBLIC_ACCESS_PROHIBITED';\n  /**\n   * Checks whether logging is enabled for your S3 buckets.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-logging-enabled.html\n   */\n  public static readonly S3_BUCKET_LOGGING_ENABLED = 'S3_BUCKET_LOGGING_ENABLED';\n  /**\n   * Checks that the access granted by the Amazon S3 bucket is restricted by any of the AWS principals, federated users,\n   * service principals, IP addresses, or VPCs that you provide.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-policy-grantee-check.html\n   */\n  public static readonly S3_BUCKET_POLICY_GRANTEE_CHECK = 'S3_BUCKET_POLICY_GRANTEE_CHECK';\n  /**\n   * Checks if your Amazon Simple Storage Service bucket policies do not allow other inter-account permissions\n   * than the control Amazon S3 bucket policy that you provide.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-policy-not-more-permissive.html\n   */\n  public static readonly S3_BUCKET_POLICY_NOT_MORE_PERMISSIVE = 'S3_BUCKET_POLICY_NOT_MORE_PERMISSIVE';\n  /**\n   * Checks if your Amazon S3 buckets do not allow public read access.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-read-prohibited.html\n   */\n  public static readonly S3_BUCKET_PUBLIC_READ_PROHIBITED = 'S3_BUCKET_PUBLIC_READ_PROHIBITED';\n  /**\n   * Checks that your Amazon S3 buckets do not allow public write access.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-public-write-prohibited.html\n   */\n  public static readonly S3_BUCKET_PUBLIC_WRITE_PROHIBITED = 'S3_BUCKET_PUBLIC_WRITE_PROHIBITED';\n  /**\n   * Checks whether S3 buckets have cross-region replication enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-replication-enabled.html\n   */\n  public static readonly S3_BUCKET_REPLICATION_ENABLED = 'S3_BUCKET_REPLICATION_ENABLED';\n  /**\n   * Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the\n   * S3 bucket policy explicitly denies put-object requests without server side encryption that\n   * uses AES-256 or AWS Key Management Service.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-server-side-encryption-enabled.html\n   */\n  public static readonly S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED = 'S3_BUCKET_SERVER_SIDE_ENCRYPTION_ENABLED';\n  /**\n   * Checks whether S3 buckets have policies that require requests to use Secure Socket Layer (SSL).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-ssl-requests-only.html\n   */\n  public static readonly S3_BUCKET_SSL_REQUESTS_ONLY = 'S3_BUCKET_SSL_REQUESTS_ONLY';\n  /**\n   * Checks whether versioning is enabled for your S3 buckets.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-bucket-versioning-enabled.html\n   */\n  public static readonly S3_BUCKET_VERSIONING_ENABLED = 'S3_BUCKET_VERSIONING_ENABLED';\n  /**\n   * Checks if Amazon S3 Events Notifications are enabled on an S3 bucket.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-event-notifications-enabled.html\n   */\n  public static readonly S3_EVENT_NOTIFICATIONS_ENABLED = 'S3_EVENT_NOTIFICATIONS_ENABLED';\n  /**\n   * Checks if a recovery point was created for Amazon Simple Storage Service (Amazon S3).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-last-backup-recovery-point-created.html\n   */\n  public static readonly S3_LAST_BACKUP_RECOVERY_POINT_CREATED = 'S3_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks if a lifecycle rule is configured for an Amazon Simple Storage Service (Amazon S3) bucket.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-lifecycle-policy-check.html\n   */\n  public static readonly S3_LIFECYCLE_POLICY_CHECK = 'S3_LIFECYCLE_POLICY_CHECK';\n  /**\n   * Checks if Amazon Simple Storage Service (Amazon S3) buckets are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-resources-protected-by-backup-plan.html\n   */\n  public static readonly S3_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'S3_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks if Amazon Simple Storage Service (Amazon S3) version enabled buckets have lifecycle policy configured.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/s3-version-lifecycle-policy-check.html\n   */\n  public static readonly S3_VERSION_LIFECYCLE_POLICY_CHECK = 'S3_VERSION_LIFECYCLE_POLICY_CHECK';\n  /**\n   * Checks whether AWS Key Management Service (KMS) key is configured for an Amazon SageMaker endpoint configuration.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/sagemaker-endpoint-configuration-kms-key-configured.html\n   */\n  public static readonly SAGEMAKER_ENDPOINT_CONFIGURATION_KMS_KEY_CONFIGURED = 'SAGEMAKER_ENDPOINT_CONFIGURATION_KMS_KEY_CONFIGURED';\n  /**\n   * Check whether an AWS Key Management Service (KMS) key is configured for SageMaker notebook instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/sagemaker-notebook-instance-kms-key-configured.html\n   */\n  public static readonly SAGEMAKER_NOTEBOOK_INSTANCE_KMS_KEY_CONFIGURED = 'SAGEMAKER_NOTEBOOK_INSTANCE_KMS_KEY_CONFIGURED';\n  /**\n   * Checks whether direct internet access is disabled for an Amazon SageMaker notebook instance.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/sagemaker-notebook-no-direct-internet-access.html\n   */\n  public static readonly SAGEMAKER_NOTEBOOK_NO_DIRECT_INTERNET_ACCESS = 'SAGEMAKER_NOTEBOOK_NO_DIRECT_INTERNET_ACCESS';\n  /**\n   * Checks whether AWS Secrets Manager secret has rotation enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-rotation-enabled-check.html\n   */\n  public static readonly SECRETSMANAGER_ROTATION_ENABLED_CHECK = 'SECRETSMANAGER_ROTATION_ENABLED_CHECK';\n  /**\n   * Checks whether AWS Secrets Manager secret rotation has rotated successfully as per the rotation schedule.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-scheduled-rotation-success-check.html\n   */\n  public static readonly SECRETSMANAGER_SCHEDULED_ROTATION_SUCCESS_CHECK = 'SECRETSMANAGER_SCHEDULED_ROTATION_SUCCESS_CHECK';\n  /**\n   * Checks if AWS Secrets Manager secrets have been rotated in the past specified number of days.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-secret-periodic-rotation.html\n   */\n  public static readonly SECRETSMANAGER_SECRET_PERIODIC_ROTATION = 'SECRETSMANAGER_SECRET_PERIODIC_ROTATION';\n  /**\n   * Checks if AWS Secrets Manager secrets have been accessed within a specified number of days.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-secret-unused.html\n   */\n  public static readonly SECRETSMANAGER_SECRET_UNUSED = 'SECRETSMANAGER_SECRET_UNUSED';\n  /**\n   * Checks if all secrets in AWS Secrets Manager are encrypted using the AWS managed key (aws/secretsmanager)\n   * or a customer managed key that was created in AWS Key Management Service (AWS KMS).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/secretsmanager-using-cmk.html\n   */\n  public static readonly SECRETSMANAGER_USING_CMK = 'SECRETSMANAGER_USING_CMK';\n  /**\n   * Checks whether Service Endpoint for the service provided in rule parameter is created for each Amazon VPC.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/service-vpc-endpoint-enabled.html\n   */\n  public static readonly SERVICE_VPC_ENDPOINT_ENABLED = 'SERVICE_VPC_ENDPOINT_ENABLED';\n  /**\n   * Checks whether EBS volumes are attached to EC2 instances.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/shield-advanced-enabled-autorenew.html\n   */\n  public static readonly SHIELD_ADVANCED_ENABLED_AUTO_RENEW = 'SHIELD_ADVANCED_ENABLED_AUTORENEW';\n  /**\n   * Verify that DDoS response team (DRT) can access AWS account.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/shield-drt-access.html\n   */\n  public static readonly SHIELD_DRT_ACCESS = 'SHIELD_DRT_ACCESS';\n  /**\n   * Checks if a recovery point was created for AWS Backup-Gateway VirtualMachines.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/virtualmachine-last-backup-recovery-point-created.html\n   */\n  public static readonly VIRTUALMACHINE_LAST_BACKUP_RECOVERY_POINT_CREATED = 'VIRTUALMACHINE_LAST_BACKUP_RECOVERY_POINT_CREATED';\n  /**\n   * Checks if AWS Backup-Gateway VirtualMachines are protected by a backup plan.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/virtualmachine-resources-protected-by-backup-plan.html\n   */\n  public static readonly VIRTUALMACHINE_RESOURCES_PROTECTED_BY_BACKUP_PLAN = 'VIRTUALMACHINE_RESOURCES_PROTECTED_BY_BACKUP_PLAN';\n  /**\n   * Checks that the default security group of any Amazon Virtual Private Cloud (VPC) does not\n   * allow inbound or outbound traffic. The rule returns NOT_APPLICABLE if the security group\n   * is not default.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-default-security-group-closed.html\n   */\n  public static readonly VPC_DEFAULT_SECURITY_GROUP_CLOSED = 'VPC_DEFAULT_SECURITY_GROUP_CLOSED';\n  /**\n   * Checks whether Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPC.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-flow-logs-enabled.html\n   */\n  public static readonly VPC_FLOW_LOGS_ENABLED = 'VPC_FLOW_LOGS_ENABLED';\n  /**\n   * Checks if there are unused network access control lists (network ACLs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-network-acl-unused-check.html\n   */\n  public static readonly VPC_NETWORK_ACL_UNUSED_CHECK = 'VPC_NETWORK_ACL_UNUSED_CHECK';\n  /**\n   * Checks if DNS resolution from accepter/requester VPC to private IP is enabled.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-peering-dns-resolution-check.html\n   */\n  public static readonly VPC_PEERING_DNS_RESOLUTION_CHECK = 'VPC_PEERING_DNS_RESOLUTION_CHECK';\n  /**\n   * Checks whether the security group with 0.0.0.0/0 of any Amazon Virtual Private Cloud (Amazon VPC)\n   * allows only specific inbound TCP or UDP traffic.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-sg-open-only-to-authorized-ports.html\n   */\n  public static readonly VPC_SG_OPEN_ONLY_TO_AUTHORIZED_PORTS = 'VPC_SG_OPEN_ONLY_TO_AUTHORIZED_PORTS';\n  /**\n   * Checks that both AWS Virtual Private Network tunnels provided by AWS Site-to-Site VPN are in\n   * UP status.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/vpc-vpn-2-tunnels-up.html\n   */\n  public static readonly VPC_VPN_2_TUNNELS_UP = 'VPC_VPN_2_TUNNELS_UP';\n  /**\n   * Checks if logging is enabled on AWS Web Application Firewall (WAF) classic global web ACLs.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-classic-logging-enabled.html\n   */\n  public static readonly WAF_CLASSIC_LOGGING_ENABLED = 'WAF_CLASSIC_LOGGING_ENABLED';\n  /**\n   * Checks whether logging is enabled on AWS Web Application Firewall (WAFV2) regional and global\n   * web access control list (ACLs).\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/wafv2-logging-enabled.html\n   */\n  public static readonly WAFV2_LOGGING_ENABLED = 'WAFV2_LOGGING_ENABLED';\n  /**\n   * Checks if an AWS WAF Classic rule group contains any rules.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-global-rulegroup-not-empty.html\n   */\n  public static readonly WAF_GLOBAL_RULEGROUP_NOT_EMPTY = 'WAF_GLOBAL_RULEGROUP_NOT_EMPTY';\n  /**\n   * Checks if an AWS WAF global rule contains any conditions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-global-rule-not-empty.html\n   */\n  public static readonly WAF_GLOBAL_RULE_NOT_EMPTY = 'WAF_GLOBAL_RULE_NOT_EMPTY';\n  /**\n   * Checks whether a WAF Global Web ACL contains any WAF rules or rule groups.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-global-webacl-not-empty.html\n   */\n  public static readonly WAF_GLOBAL_WEBACL_NOT_EMPTY = 'WAF_GLOBAL_WEBACL_NOT_EMPTY';\n  /**\n   * Checks if WAF Regional rule groups contain any rules.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-regional-rulegroup-not-empty.html\n   */\n  public static readonly WAF_REGIONAL_RULEGROUP_NOT_EMPTY = 'WAF_REGIONAL_RULEGROUP_NOT_EMPTY';\n  /**\n   * Checks whether WAF regional rule contains conditions.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-regional-rule-not-empty.html\n   */\n  public static readonly WAF_REGIONAL_RULE_NOT_EMPTY = 'WAF_REGIONAL_RULE_NOT_EMPTY';\n  /**\n   * Checks if a WAF regional Web ACL contains any WAF rules or rule groups.\n   * @see https://docs.aws.amazon.com/config/latest/developerguide/waf-regional-webacl-not-empty.html\n   */\n  public static readonly WAF_REGIONAL_WEBACL_NOT_EMPTY = 'WAF_REGIONAL_WEBACL_NOT_EMPTY';\n\n  // utility class\n  private constructor() { }\n}", "language": "typescript"}
{"input": "Decide how properties get mapped between model types, Typescript types, and CloudFormation", "output": "export class TypeDefinitionDecider {\n  public readonly properties = new Array<TypeDefProperty>();\n  private readonly resolverBuilder: ResolverBuilder;\n\n  constructor(\n    private readonly resource: Resource,\n    private readonly typeDefinition: TypeDefinition,\n    private readonly converter: TypeConverter,\n    private readonly relationshipDecider: RelationshipDecider,\n  ) {\n    this.resolverBuilder = new ResolverBuilder(this.converter, this.relationshipDecider, this.converter.module);\n    this.convertProperties();\n    this.properties.sort((p1, p2) => p1.propertySpec.name.localeCompare(p2.propertySpec.name));\n  }\n\n  private convertProperties() {\n    for (const [name, prop] of Object.entries(this.typeDefinition.properties)) {\n      this.handlePropertyDefault(name, prop);\n    }\n  }\n\n  /**\n   * Default mapping for a property\n   */\n  private handlePropertyDefault(cfnName: string, prop: Property) {\n    const optional = !prop.required;\n\n    const resolverResult = this.resolverBuilder.buildResolver(prop, cfnName, true);\n\n    this.properties.push({\n      propertySpec: {\n        name: resolverResult.name,\n        type: resolverResult.propType,\n        optional,\n        docs: {\n          ...splitDocumentation(prop.documentation),\n          default: prop.defaultValue ?? undefined,\n          see: cloudFormationDocLink({\n            resourceType: this.resource.cloudFormationType,\n            propTypeName: this.typeDefinition.name,\n            propName: cfnName,\n          }),\n          deprecated: deprecationMessage(prop),\n        },\n      },\n      baseType: resolverResult.baseType,\n      cfnMapping: {\n        cfnName,\n        propName: resolverResult.name,\n        baseType: resolverResult.baseType,\n        optional,\n      },\n      resolver: resolverResult.resolver,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function expectTaskWithParameters", "output": "const expectTaskWithParameters = (task: lib.HttpInvoke, parameters: any, queryLanguage?: sfn.QueryLanguage) => {\n  expect(stack.resolve(task.toStateJson())).toEqual({\n    QueryLanguage: queryLanguage,\n    Type: 'Task',\n    Resource: {\n      'Fn::Join': [\n        '',\n        [\n          'arn:',\n          {\n            Ref: 'AWS::Partition',\n          },\n          ':states:::http:invoke',\n        ],\n      ],\n    },\n    End: true,\n    Parameters: queryLanguage === sfn.QueryLanguage.JSONATA ? undefined : parameters,\n    Arguments: queryLanguage === sfn.QueryLanguage.JSONATA ? parameters : undefined,\n  });\n}", "language": "typescript"}
{"input": "CDK class MetricsClass for AWS resource management", "output": "export class MetricsClass extends ClassType {\n  constructor(scope: IScope, namespace: string, private returnType: MetricsReturnType) {\n    super(scope, {\n      export: true,\n      name: metricsClassNameFromNamespace(namespace),\n    });\n  }\n\n  public addMetricWithDimensions(metric: Metric, dimensionSets: DimensionSet[]) {\n    const name = metricFunctionName(metric);\n\n    // Add a unique declaration for each dimension set\n    for (const set of dimensionSets) {\n      const dimensionsType = dimensionSetType(set);\n      this.addMetricMethodDeclaration(name, dimensionsType);\n    }\n\n    // If we have more than one dimension set, add a generic declaration\n    if (dimensionSets.length > 1) {\n      this.addMetricMethodDeclaration(name, Type.ANY);\n    }\n\n    // Add the implementation to the final declaration\n    this.methods.at(-1)?.addBody(\n      stmt.ret(\n        expr.object({\n          namespace: expr.lit(metric.namespace),\n          metricName: expr.lit(metric.name),\n          dimensionsMap: expr.ident('dimensions'),\n          statistic: expr.lit(metric.statistic),\n        }),\n      ),\n    );\n  }\n\n  private addMetricMethodDeclaration(name: string, dimensionsType: Type): Method {\n    return this.addMethod({\n      name,\n      static: true,\n      returnType: Type.fromName(this.scope, this.returnType.name, [dimensionsType]),\n      parameters: [\n        {\n          name: 'this',\n          type: Type.VOID,\n        },\n        {\n          name: 'dimensions',\n          type: dimensionsType,\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "Error thrown when validation fails @internal", "output": "export class ValidationError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'ValidationError';\n  }\n}", "language": "typescript"}
{"input": "Represents the \"expected\" results to compare", "output": "class ExpectedResult {\n  /**\n   * The actual results must match exactly. Missing data\n   * will result in a failure\n   *\n   * @example\n   * // actual results\n   * const actual = {\n   *   stringParam: 'hello',\n   *   numberParam: 3,\n   *   booleanParam: true,\n   * };\n   * // pass\n   * ExpectedResult.exact({\n   *   stringParam: 'hello',\n   *   numberParam: 3,\n   *   booleanParam: true,\n   * })\n   *\n   * // fail\n   * ExpectedResult.exact({\n   *   stringParam: 'hello',\n   * });\n   *\n   * @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.assertions.Match.html#static-exactpattern\n   */\n  public static exact(expected: any): ExpectedResult {\n    return {\n      result: JSON.stringify({\n        $Exact: expected,\n      }),\n    };\n  }\n\n  /**\n   * The expected results must be a subset of the\n   * actual results.\n   *\n   * @example\n   * // actual results\n   * const actual = {\n   *   stringParam: 'hello',\n   *   numberParam: 3,\n   *   booleanParam: true,\n   *   objectParam: { prop1: 'value', prop2: 'value' },\n   * };\n   * // pass\n   * ExpectedResult.objectLike({\n   *   stringParam: 'hello',\n   *   objectParam: { prop1: 'value' },\n   * });\n   *\n   * @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.assertions.Match.html#static-objectwbrlikepattern\n   */\n  public static objectLike(expected: { [key: string]: any }): ExpectedResult {\n    return {\n      result: JSON.stringify({\n        $ObjectLike: expected,\n      }),\n    };\n  }\n\n  /**\n   * The actual results must be a list and must contain\n   * an item with the expected results.\n   *\n   * @example\n   * // actual results\n   * const actual = [\n   *   {\n   *     stringParam: 'hello',\n   *   },\n   *   {\n   *     stringParam: 'world',\n   *   },\n   * ];\n   * // pass\n   * ExpectedResult.arrayWith([\n   *   {\n   *     stringParam: 'hello',\n   *   },\n   * ]);\n   *\n   * @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.assertions.Match.html#static-arraywbrwithpattern\n   */\n  public static arrayWith(expected: any[]): ExpectedResult {\n    return {\n      result: JSON.stringify({\n        $ArrayWith: expected,\n      }),\n    };\n  }\n  /**\n   * Actual results is a string that matches\n   * the Expected result regex\n   *\n   * @example\n   * // actual results\n   * const actual = 'some string value';\n   *\n   * // pass\n   * ExpectedResult.stringLikeRegexp('value');\n   *\n   * @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.assertions.Match.html#static-stringwbrlikewbrregexppattern\n   */\n  public static stringLikeRegexp(expected: string): ExpectedResult {\n    return {\n      result: JSON.stringify({\n        $StringLike: expected,\n      }),\n    };\n  }\n\n  /**\n   * The expected results encoded as a string\n   */\n  public abstract result: string;\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, EC2, CloudFormation resources", "output": "class VpcMigrationFeatureFlagEnabledStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create a VPC\n    const vpc = new ec2alpha.VpcV2(this, 'VpcWithFeatureFlagEnabled', {\n      primaryAddressBlock: ec2alpha.IpAddresses.ipv4('10.0.0.0/16'),\n    });\n\n    // Create a public subnet\n    const publicSubnet = new ec2alpha.SubnetV2(this, 'PublicSubnet', {\n      vpc,\n      availabilityZone: 'us-east-1a',\n      ipv4CidrBlock: new ec2alpha.IpCidr('10.0.0.0/24'),\n      subnetType: ec2.SubnetType.PUBLIC,\n    });\n\n    // Create an Internet Gateway\n    const igw = new ec2alpha.InternetGateway(this, 'InternetGateway', { vpc });\n\n    // Create a NAT Gateway\n    const natGateway = new ec2alpha.NatGateway(this, 'NatGateway', {\n      subnet: publicSubnet,\n      connectivityType: ec2alpha.NatConnectivityType.PRIVATE,\n    });\n\n    // Create a Route Table\n    const routeTable = new ec2alpha.RouteTable(this, 'RouteTable', { vpc });\n\n    // Add routes to verify functionality\n    routeTable.addRoute('RouteToIgw', '0.0.0.0/0',\n      { gateway: igw });\n\n    routeTable.addRoute('RouteToNat', '172.16.0.0/16', {\n      gateway: natGateway,\n    });\n\n    // Output the IDs to verify in the test\n    new cdk.CfnOutput(this, 'IgwRouterId', { value: igw.routerTargetId });\n    new cdk.CfnOutput(this, 'NatGatewayRouterId', { value: natGateway.routerTargetId });\n    new cdk.CfnOutput(this, 'RouteTableId', { value: routeTable.routeTableId });\n  }\n}", "language": "typescript"}
{"input": "Define a new listener rule", "output": "export class ApplicationListenerRule extends Construct {\n  /**\n   * The ARN of this rule\n   */\n  public readonly listenerRuleArn: string;\n\n  private readonly conditions: ListenerCondition[];\n  private readonly legacyConditions: {[key: string]: string[]} = {};\n\n  private readonly listener: IApplicationListener;\n  private action?: IListenerAction;\n\n  constructor(scope: Construct, id: string, props: ApplicationListenerRuleProps) {\n    super(scope, id);\n\n    this.conditions = props.conditions || [];\n\n    const hasPathPatterns = props.pathPatterns || props.pathPattern;\n    if (this.conditions.length === 0 && !props.hostHeader && !hasPathPatterns) {\n      throw new ValidationError('At least one of \\'conditions\\', \\'hostHeader\\', \\'pathPattern\\' or \\'pathPatterns\\' is required when defining a load balancing rule.', this);\n    }\n\n    const possibleActions: Array<keyof ApplicationListenerRuleProps> = ['action', 'targetGroups', 'fixedResponse', 'redirectResponse'];\n    const providedActions = possibleActions.filter(action => props[action] !== undefined);\n    if (providedActions.length > 1) {\n      throw new ValidationError(`'${providedActions}' specified together, specify only one`, this);\n    }\n\n    if (!cdk.Token.isUnresolved(props.priority) && props.priority <= 0) {\n      throw new ValidationError('Priority must have value greater than or equal to 1', this);\n    }\n\n    this.listener = props.listener;\n\n    const resource = new CfnListenerRule(this, 'Resource', {\n      listenerArn: props.listener.listenerArn,\n      priority: props.priority,\n      conditions: cdk.Lazy.any({ produce: () => this.renderConditions() }),\n      actions: cdk.Lazy.any({ produce: () => this.action ? this.action.renderRuleActions() : [] }),\n    });\n\n    if (props.hostHeader) {\n      this.setCondition('host-header', [props.hostHeader]);\n    }\n\n    if (hasPathPatterns) {\n      if (props.pathPattern && props.pathPatterns) {\n        throw new ValidationError('Both `pathPatterns` and `pathPattern` are specified, specify only one', this);\n      }\n      const pathPattern = props.pathPattern ? [props.pathPattern] : props.pathPatterns;\n      this.setCondition('path-pattern', pathPattern);\n    }\n\n    if (props.action) {\n      this.configureAction(props.action);\n    }\n\n    if (props.targetGroups) {\n      this.configureAction(ListenerAction.forward(props.targetGroups));\n    }\n\n    if (props.fixedResponse) {\n      this.addFixedResponse(props.fixedResponse);\n    } else if (props.redirectResponse) {\n      this.addRedirectResponse(props.redirectResponse);\n    }\n\n    this.listenerRuleArn = resource.ref;\n\n    this.node.addValidation({ validate: () => this.validateListenerRule() });\n  }\n\n  /**\n   * Add a non-standard condition to this rule\n   *\n   * If the condition conflicts with an already set condition, it will be overwritten by the one you specified.\n   *\n   * @deprecated use `addCondition` instead.\n   */\n  public setCondition(field: string, values: string[] | undefined) {\n    if (values === undefined) {\n      delete this.legacyConditions[field];\n      return;\n    }\n\n    this.legacyConditions[field] = values;\n  }\n\n  /**\n   * Add a non-standard condition to this rule\n   */\n  public addCondition(condition: ListenerCondition) {\n    this.conditions.push(condition);\n  }\n\n  /**\n   * Configure the action to perform for this rule\n   */\n  public configureAction(action: ListenerAction) {\n    // It might make sense to 'throw' here.\n    //\n    // However, programs may already exist out there which configured an action twice,\n    // in which case the second action accidentally overwrite the initial action, and in some\n    // way ended up with a program that did what the author intended. If we were to add throw now,\n    // the previously working program would be broken.\n    //\n    // Instead, signal this through a warning.\n    // @deprecate: upon the next major version bump, replace this with a `throw`\n    if (this.action) {\n      cdk.Annotations.of(this).addWarningV2('@aws-cdk/aws-elbv2:albListnerRuleDefaultActionReplaced', 'An Action already existed on this ListenerRule and was replaced. Configure exactly one default Action.');\n    }\n\n    action.bind(this, this.listener, this);\n    this.action = action;\n  }\n\n  /**\n   * Add a TargetGroup to load balance to\n   *\n   * @deprecated Use configureAction instead\n   */\n  public addTargetGroup(targetGroup: IApplicationTargetGroup) {\n    this.configureAction(ListenerAction.forward([targetGroup]));\n  }\n\n  /**\n   * Add a fixed response\n   *\n   * @deprecated Use configureAction instead\n   */\n  public addFixedResponse(fixedResponse: FixedResponse) {\n    validateFixedResponse(fixedResponse);\n\n    this.configureAction(ListenerAction.fixedResponse(cdk.Token.asNumber(fixedResponse.statusCode), {\n      contentType: fixedResponse.contentType,\n      messageBody: fixedResponse.messageBody,\n    }));\n  }\n\n  /**\n   * Add a redirect response\n   *\n   * @deprecated Use configureAction instead\n   */\n  public addRedirectResponse(redirectResponse: RedirectResponse) {\n    validateRedirectResponse(redirectResponse);\n\n    this.configureAction(ListenerAction.redirect({\n      host: redirectResponse.host,\n      path: redirectResponse.path,\n      permanent: redirectResponse.statusCode === 'HTTP_301',\n      port: redirectResponse.port,\n      protocol: redirectResponse.protocol,\n      query: redirectResponse.query,\n    }));\n  }\n\n  /**\n   * Validate the rule\n   */\n  private validateListenerRule() {\n    if (this.action === undefined) {\n      return ['Listener rule needs at least one action'];\n    }\n\n    const legacyConditionFields = Object.keys(this.legacyConditions);\n    if (legacyConditionFields.length === 0 && this.conditions.length === 0) {\n      return ['Listener rule needs at least one condition'];\n    }\n\n    return [];\n  }\n\n  /**\n   * Render the conditions for this rule\n   */\n  private renderConditions(): any {\n    const legacyConditions = Object.entries(this.legacyConditions).map(([field, values]) => {\n      return { field, values };\n    });\n    const conditions = this.conditions.map(condition => condition.renderRawCondition());\n\n    return [\n      ...legacyConditions,\n      ...conditions,\n    ];\n  }\n}", "language": "typescript"}
{"input": "Represents a value of a specific object deployed in the cluster. Use this to fetch any information available by the `kubectl get` command.", "output": "export class KubernetesObjectValue extends Construct {\n  /**\n   * The CloudFormation resource type.\n   */\n  public static readonly RESOURCE_TYPE = 'Custom::AWSCDK-EKS-KubernetesObjectValue';\n\n  private _resource: CustomResource;\n\n  constructor(scope: Construct, id: string, props: KubernetesObjectValueProps) {\n    super(scope, id);\n\n    const provider = KubectlProvider.getKubectlProvider(this, props.cluster);\n\n    if (!provider) {\n      throw new Error('Kubectl Provider is not defined in this cluster. Define it when creating the cluster');\n    }\n\n    this._resource = new CustomResource(this, 'Resource', {\n      resourceType: KubernetesObjectValue.RESOURCE_TYPE,\n      serviceToken: provider.serviceToken,\n      properties: {\n        ClusterName: props.cluster.clusterName,\n        ObjectType: props.objectType,\n        ObjectName: props.objectName,\n        ObjectNamespace: props.objectNamespace ?? 'default',\n        JsonPath: props.jsonPath,\n        TimeoutSeconds: (props?.timeout ?? Duration.minutes(5)).toSeconds(),\n      },\n    });\n  }\n\n  /**\n   * The value as a string token.\n   */\n  public get value(): string {\n    return Token.asString(this._resource.getAtt('Value'));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, SNS, CloudFormation resources", "output": "class MyStack extends BaseStack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new sns.Topic(this, 'MyTopic');\n    new s3.Bucket(this, 'MyBucket');\n  }\n}", "language": "typescript"}
{"input": "The replication time value used for S3 Replication Time Control (S3 RTC).", "output": "export class ReplicationTimeValue {\n  /**\n   * Fifteen minutes.\n   */\n  public static readonly FIFTEEN_MINUTES = new ReplicationTimeValue(15);\n\n  /**\n   * @param minutes the time in minutes\n   */\n  private constructor(public readonly minutes: number) {}\n}", "language": "typescript"}
{"input": "CDK class OpenIdConnectProvider for AWS resource management", "output": "export class OpenIdConnectProvider extends iam.OpenIdConnectProvider {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-eks.OpenIdConnectProvider';\n\n  /**\n   * Defines an OpenID Connect provider.\n   * @param scope The definition scope\n   * @param id Construct ID\n   * @param props Initialization properties\n   */\n  public constructor(scope: Construct, id: string, props: OpenIdConnectProviderProps) {\n    const clientIds = ['sts.amazonaws.com'];\n\n    super(scope, id, {\n      url: props.url,\n      clientIds,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class TestBucketDeploymentSubstitutionWithRole for AWS resource management", "output": "class TestBucketDeploymentSubstitutionWithRole extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const bucket = new Bucket(this, 'Bucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n    const executionRole = new iam.Role(this, 'ExecutionRole', {\n      assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n    });\n\n    new DeployTimeSubstitutedFile(this, 'DeployWithCustomRole', {\n      source: path.join(__dirname, 'sample-file.yaml'),\n      destinationBucket: bucket,\n      substitutions: { },\n      role: executionRole,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, KMS, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: App, id: string) {\n    super(scope, id);\n\n    const handler = new lambda.Function(this, 'MyLambda', {\n      code: lambda.Code.fromAsset(path.join(__dirname, 'layer-code')),\n      handler: 'index.main',\n      runtime: lambda.Runtime.PYTHON_3_8,\n      currentVersionOptions: {\n        removalPolicy: RemovalPolicy.RETAIN,\n        retryAttempts: 1,\n      },\n    });\n\n    handler.currentVersion.addAlias('live');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Cognito, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const userpool = new UserPool(this, 'pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    userpool.addClient('client', {\n      generateSecret: true,\n      enablePropagateAdditionalUserContextData: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class LogGroup for AWS resource management", "output": "export class LogGroup extends LogGroupBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-log.LogGroup';\n\n  /**\n   * Import an existing LogGroup given its ARN\n   */\n  public static fromLogGroupArn(scope: Construct, id: string, logGroupArn: string): ILogGroup {\n    const baseLogGroupArn = logGroupArn.replace(/:\\*$/, '');\n\n    class Import extends LogGroupBase {\n      public readonly logGroupArn = `${baseLogGroupArn}:*`;\n      public readonly logGroupName = Stack.of(scope).splitArn(baseLogGroupArn, ArnFormat.COLON_RESOURCE_NAME).resourceName!;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: baseLogGroupArn,\n    });\n  }\n\n  /**\n   * Import an existing LogGroup given its name\n   */\n  public static fromLogGroupName(scope: Construct, id: string, logGroupName: string): ILogGroup {\n    const baseLogGroupName = logGroupName.replace(/:\\*$/, '');\n\n    class Import extends LogGroupBase {\n      public readonly logGroupName = baseLogGroupName;\n      public readonly logGroupArn = Stack.of(scope).formatArn({\n        service: 'logs',\n        resource: 'log-group',\n        arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n        resourceName: baseLogGroupName + ':*',\n      });\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The ARN of this log group\n   */\n  public readonly logGroupArn: string;\n\n  /**\n   * The name of this log group\n   */\n  public readonly logGroupName: string;\n\n  constructor(scope: Construct, id: string, props: LogGroupProps = {}) {\n    super(scope, id, {\n      physicalName: props.logGroupName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    let retentionInDays = props.retention;\n    if (retentionInDays === undefined) { retentionInDays = RetentionDays.TWO_YEARS; }\n    if (retentionInDays === Infinity || retentionInDays === RetentionDays.INFINITE) { retentionInDays = undefined; }\n\n    if (retentionInDays !== undefined && !Token.isUnresolved(retentionInDays) && retentionInDays <= 0) {\n      throw new ValidationError(`retentionInDays must be positive, got ${retentionInDays}`, this);\n    }\n\n    let logGroupClass = props.logGroupClass;\n\n    const dataProtectionPolicy = props.dataProtectionPolicy?._bind(this);\n    const fieldIndexPolicies: any[] = [];\n    if (props.fieldIndexPolicies) {\n      props.fieldIndexPolicies.forEach((fieldIndexPolicy) => {\n        fieldIndexPolicies.push(fieldIndexPolicy._bind(this));\n      });\n    }\n\n    const resource = new CfnLogGroup(this, 'Resource', {\n      kmsKeyId: props.encryptionKey?.keyRef.keyArn,\n      logGroupClass,\n      logGroupName: this.physicalName,\n      retentionInDays,\n      dataProtectionPolicy: dataProtectionPolicy ? {\n        Name: dataProtectionPolicy?.name,\n        Description: dataProtectionPolicy?.description,\n        Version: dataProtectionPolicy?.version,\n        Statement: dataProtectionPolicy?.statement,\n        Configuration: dataProtectionPolicy?.configuration,\n      } : undefined,\n      ...(props.fieldIndexPolicies && { fieldIndexPolicies: fieldIndexPolicies }),\n    });\n\n    resource.applyRemovalPolicy(props.removalPolicy);\n\n    this.logGroupArn = this.getResourceArnAttribute(resource.attrArn, {\n      service: 'logs',\n      resource: 'log-group',\n      resourceName: this.physicalName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n    this.logGroupName = this.getResourceNameAttribute(resource.ref);\n  }\n}", "language": "typescript"}
{"input": "Static site infrastructure, which deploys site content to an S3 bucket. The site redirects from HTTP to HTTPS, using a CloudFront distribution, Route53 alias record, and ACM certificate.", "output": "export class StaticSite extends Construct {\n  constructor(parent: Stack, name: string, props: StaticSiteProps) {\n    super(parent, name);\n\n    const zone = route53.HostedZone.fromLookup(this, 'Zone', { domainName: props.domainName });\n    const siteDomain = props.siteSubDomain + '.' + props.domainName;\n\n    new CfnOutput(this, 'Site', { value: 'https://' + siteDomain });\n\n    // Content bucket\n    const siteBucket = new s3.Bucket(this, 'SiteBucket', {\n      bucketName: siteDomain,\n      publicReadAccess: false,\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n\n      /**\n       * The default removal policy is RETAIN, which means that cdk destroy will not attempt to delete\n       * the new bucket, and it will remain in your account until manually deleted. By setting the policy to\n       * DESTROY, cdk destroy will attempt to delete the bucket, but will error if the bucket is not empty.\n       */\n      removalPolicy: RemovalPolicy.DESTROY, // NOT recommended for production code\n\n      /**\n       * For sample purposes only, if you create an S3 bucket then populate it, stack destruction fails.  This\n       * setting will enable full cleanup of the demo.\n       */\n      autoDeleteObjects: true, // NOT recommended for production code\n    });\n\n    new CfnOutput(this, 'Bucket', { value: siteBucket.bucketName });\n\n    // TLS certificate\n    const certificate = new acm.Certificate(this, 'SiteCertificate', {\n      domainName: siteDomain,\n      validation: acm.CertificateValidation.fromDns(zone),\n    });\n\n    new CfnOutput(this, 'Certificate', { value: certificate.certificateArn });\n\n    // CloudFront distribution\n    const distribution = new cloudfront.Distribution(this, 'SiteDistribution', {\n      certificate: certificate,\n      defaultRootObject: \"index.html\",\n      domainNames: [siteDomain],\n      minimumProtocolVersion: cloudfront.SecurityPolicyProtocol.TLS_V1_2_2021,\n      errorResponses:[\n        {\n          httpStatus: 403,\n          responseHttpStatus: 403,\n          responsePagePath: '/error.html',\n          ttl: Duration.minutes(30),\n        }\n      ],\n      defaultBehavior: {\n        origin: cloudfront_origins.S3BucketOrigin.withOriginAccessControl(siteBucket),\n        compress: true,\n        allowedMethods: cloudfront.AllowedMethods.ALLOW_GET_HEAD_OPTIONS,\n        viewerProtocolPolicy: cloudfront.ViewerProtocolPolicy.REDIRECT_TO_HTTPS,\n      }\n    })\n\n    new CfnOutput(this, 'DistributionId', { value: distribution.distributionId });\n\n    // Route53 alias record for the CloudFront distribution\n    new route53.ARecord(this, 'SiteAliasRecord', {\n      recordName: siteDomain,\n      target: route53.RecordTarget.fromAlias(new targets.CloudFrontTarget(distribution)),\n      zone\n    });\n\n    // Deploy site contents to S3 bucket\n    new s3deploy.BucketDeployment(this, 'DeployWithInvalidation', {\n      sources: [s3deploy.Source.asset(path.join(__dirname, './site-contents'))],\n      destinationBucket: siteBucket,\n      distribution,\n      distributionPaths: ['/*'],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class MyCustomResource for AWS resource management", "output": "class MyCustomResource(Construct):\n\n    def __init__(self, scope: Construct, id: str, bucket_name):\n        super().__init__(scope, id)\n\n        res = AwsCustomResource(\n            scope=self,\n            id='AWSCustomResource',\n            policy=AwsCustomResourcePolicy.from_sdk_calls(resources=[f'arn:aws:s3:::{bucket_name}/*']),\n            log_retention=logs.RetentionDays.INFINITE,\n            on_create=self.create(bucket_name),\n            on_delete=self.delete(bucket_name),\n            resource_type='Custom::MyCustomResource'\n        )\n\n    def create(self, bucket_name):\n\n        create_params = {\n            \"Body\": \"Hello world\",\n            \"Bucket\": bucket_name,\n            \"Key\": \"helloWorld.txt\"\n        }\n\n        return AwsSdkCall(\n            action='putObject',\n            service='S3',\n            parameters=create_params,\n            physical_resource_id=PhysicalResourceId.of('myAutomationExecution')\n        )\n\n    def delete(self, bucket_name):\n\n        delete_params = {\n            \"Bucket\": bucket_name,\n            \"Key\": \"helloWorld.txt\"\n        }\n\n        return AwsSdkCall(\n            action='deleteObject',\n            service='S3',\n            parameters=delete_params,\n            physical_resource_id=PhysicalResourceId.of('myAutomationExecution')\n        )", "language": "python"}
{"input": "CDK class S3ComponentDataFromBucketKey for AWS resource management", "output": "class S3ComponentDataFromBucketKey extends S3ComponentData {\n  public constructor(bucket: s3.IBucket, key: string) {\n    super(bucket, key);\n  }\n}", "language": "typescript"}
{"input": "CDK class EventApi for AWS resource management", "output": "export class EventApi extends EventApiBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.EventApi';\n\n  /**\n   * Import a Event API through this function\n   *\n   * @param scope scope\n   * @param id id\n   * @param attrs Event API Attributes of an API\n   */\n  public static fromEventApiAttributes(scope: Construct, id: string, attrs: EventApiAttributes): IEventApi {\n    const arn =\n      attrs.apiArn ??\n      Stack.of(scope).formatArn({\n        service: 'appsync',\n        resource: 'apis',\n        resourceName: attrs.apiId,\n      });\n    class Import extends EventApiBase {\n      public readonly apiId = attrs.apiId;\n      public readonly apiArn = arn;\n      public readonly httpDns = attrs.httpDns;\n      public readonly realtimeDns = attrs.realtimeDns;\n      public readonly authProviderTypes = attrs.authProviderTypes ?? [];\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * an unique AWS AppSync Event API identifier\n   * i.e. 'lxz775lwdrgcndgz3nurvac7oa'\n   */\n  public readonly apiId: string;\n\n  /**\n   * the ARN of the API\n   */\n  public readonly apiArn: string;\n\n  /**\n   * the domain name of the Api's HTTP endpoint.\n   */\n  public readonly httpDns: string;\n\n  /**\n   * the domain name of the Api's real-time endpoint.\n   */\n  public readonly realtimeDns: string;\n\n  /**\n   * The Authorization Types for this Event Api\n   */\n  public readonly authProviderTypes: AppSyncAuthorizationType[];\n\n  /**\n   * The connection auth modes for this Event Api\n   */\n  public readonly connectionModeTypes: AppSyncAuthorizationType[];\n\n  /**\n   * The default publish auth modes for this Event Api\n   */\n  public readonly defaultPublishModeTypes: AppSyncAuthorizationType[];\n\n  /**\n   * The default subscribe auth modes for this Event Api\n   */\n  public readonly defaultSubscribeModeTypes: AppSyncAuthorizationType[];\n\n  /**\n   * The configured API keys, if present.\n   * The key of this object is an apiKey name (apiKeyConfig.name) if specified, `Default` otherwise.\n   *\n   * @default - no api key\n   * @attribute ApiKeys\n   */\n  public readonly apiKeys: { [key: string]: CfnApiKey } = {};\n\n  /**\n   * the CloudWatch Log Group for this API\n   */\n  public readonly logGroup: ILogGroup;\n\n  private api: CfnApi;\n  private eventConfig: CfnApi.EventConfigProperty;\n  private domainNameResource?: CfnDomainName;\n\n  constructor(scope: Construct, id: string, props: EventApiProps) {\n    if (props.apiName !== undefined && !Token.isUnresolved(props.apiName)) {\n      if (props.apiName.length < 1 || props.apiName.length > 50) {\n        throw new ValidationError(`\\`apiName\\` must be between 1 and 50 characters, got: ${props.apiName.length} characters.`, scope);\n      }\n    }\n\n    super(scope, id, {\n      physicalName: props.apiName ?? Lazy.string({\n        produce: () =>\n          Names.uniqueResourceName(this, {\n            maxLength: 50,\n            separator: '-',\n          }),\n      }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const defaultAuthType: AppSyncAuthorizationType = AppSyncAuthorizationType.API_KEY;\n    const defaultAuthProviders: AppSyncAuthProvider[] = [{ authorizationType: defaultAuthType }];\n    const authProviders = props.authorizationConfig?.authProviders ?? defaultAuthProviders;\n\n    this.authProviderTypes = this.setupAuthProviderTypes(authProviders);\n\n    const connectionAuthModeTypes: AppSyncAuthorizationType[] =\n      props.authorizationConfig?.connectionAuthModeTypes ?? this.authProviderTypes;\n    const defaultPublishAuthModeTypes: AppSyncAuthorizationType[] =\n      props.authorizationConfig?.defaultPublishAuthModeTypes ?? this.authProviderTypes;\n    const defaultSubscribeAuthModeTypes: AppSyncAuthorizationType[] =\n      props.authorizationConfig?.defaultSubscribeAuthModeTypes ?? this.authProviderTypes;\n\n    this.connectionModeTypes = connectionAuthModeTypes;\n    this.defaultPublishModeTypes = defaultPublishAuthModeTypes;\n    this.defaultSubscribeModeTypes = defaultSubscribeAuthModeTypes;\n\n    this.validateEventApiConfiguration(props, authProviders);\n\n    this.eventConfig = {\n      authProviders: this.mapAuthorizationProviders(authProviders),\n      connectionAuthModes: this.mapAuthorizationConfig(connectionAuthModeTypes),\n      defaultPublishAuthModes: this.mapAuthorizationConfig(defaultPublishAuthModeTypes),\n      defaultSubscribeAuthModes: this.mapAuthorizationConfig(defaultSubscribeAuthModeTypes),\n      logConfig: this.setupLogConfig(props.logConfig),\n    };\n\n    this.api = new CfnApi(this, 'Resource', {\n      name: this.physicalName,\n      ownerContact: props.ownerContact,\n      eventConfig: this.eventConfig,\n    });\n\n    this.apiId = this.api.attrApiId;\n    this.apiArn = this.api.attrApiArn;\n    this.httpDns = this.api.attrDnsHttp;\n    this.realtimeDns = this.api.attrDnsRealtime;\n\n    const apiKeyConfigs = authProviders.filter((mode) => mode.authorizationType === AppSyncAuthorizationType.API_KEY);\n    for (const mode of apiKeyConfigs) {\n      this.apiKeys[mode.apiKeyConfig?.name ?? 'Default'] = createAPIKey(this, this.apiId, mode.apiKeyConfig);\n    }\n\n    if (authProviders.some((mode) => mode.authorizationType === AppSyncAuthorizationType.LAMBDA)) {\n      const config = authProviders.find((mode: AppSyncAuthProvider) => {\n        return mode.authorizationType === AppSyncAuthorizationType.LAMBDA && mode.lambdaAuthorizerConfig;\n      })?.lambdaAuthorizerConfig;\n\n      config?.handler.addPermission(`${id}-appsync`, {\n        principal: new ServicePrincipal('appsync.amazonaws.com'),\n        action: 'lambda:InvokeFunction',\n        sourceArn: this.apiArn,\n      });\n    }\n\n    if (props.domainName) {\n      this.domainNameResource = new CfnDomainName(this, 'DomainName', {\n        domainName: props.domainName.domainName,\n        certificateArn: props.domainName.certificate.certificateRef.certificateId,\n        description: `domain for ${props.apiName} Event API`,\n      });\n      const domainNameAssociation = new CfnDomainNameApiAssociation(this, 'DomainAssociation', {\n        domainName: props.domainName.domainName,\n        apiId: this.apiId,\n      });\n\n      domainNameAssociation.addDependency(this.domainNameResource);\n    }\n\n    const logGroupName = `/aws/appsync/apis/${this.apiId}`;\n\n    if (props.logConfig) {\n      const logRetention = new LogRetention(this, 'LogRetention', {\n        logGroupName: logGroupName,\n        retention: props.logConfig?.retention ?? RetentionDays.INFINITE,\n      });\n      this.logGroup = LogGroup.fromLogGroupArn(this, 'LogGroup', logRetention.logGroupArn);\n    } else {\n      this.logGroup = LogGroup.fromLogGroupName(this, 'LogGroup', logGroupName);\n    }\n  }\n\n  /**\n   * Validate Event API configuration\n   */\n  private validateEventApiConfiguration(props: EventApiProps, authProviders: AppSyncAuthProvider[]) {\n    this.validateOwnerContact(props.ownerContact);\n    this.validateAuthorizationProps(authProviders);\n    this.validateAuthorizationConfig(authProviders, this.connectionModeTypes);\n    this.validateAuthorizationConfig(authProviders, this.defaultPublishModeTypes);\n    this.validateAuthorizationConfig(authProviders, this.defaultSubscribeModeTypes);\n  }\n\n  /**\n   * Validate ownerContact property\n   */\n  private validateOwnerContact(ownerContact?: string) {\n    if (ownerContact === undefined || Token.isUnresolved(ownerContact)) return;\n\n    if (ownerContact.length < 1 || ownerContact.length > 256) {\n      throw new ValidationError(`\\`ownerContact\\` must be between 1 and 256 characters, got: ${ownerContact.length} characters.`, this);\n    }\n\n    const ownerContactPattern = /^[A-Za-z0-9_\\-\\ \\.]+$/;\n\n    if (!ownerContactPattern.test(ownerContact)) {\n      throw new ValidationError(`\\`ownerContact\\` must contain only alphanumeric characters, underscores, hyphens, spaces, and periods, got: ${ownerContact}`, this);\n    }\n  }\n\n  private setupLogConfig(config?: AppSyncLogConfig) {\n    if (!config) return;\n    const logsRoleArn: string =\n      config.role?.roleRef.roleArn ??\n      new Role(this, 'ApiLogsRole', {\n        assumedBy: new ServicePrincipal('appsync.amazonaws.com'),\n        managedPolicies: [ManagedPolicy.fromAwsManagedPolicyName('service-role/AWSAppSyncPushToCloudWatchLogs')],\n      }).roleRef.roleArn;\n    const fieldLogLevel: AppSyncFieldLogLevel = config.fieldLogLevel ?? AppSyncFieldLogLevel.NONE;\n    return {\n      cloudWatchLogsRoleArn: logsRoleArn,\n      logLevel: fieldLogLevel,\n    };\n  }\n\n  private setupAuthProviderTypes(authProviders?: AppSyncAuthProvider[]) {\n    if (!authProviders || authProviders.length === 0) return [AppSyncAuthorizationType.API_KEY];\n    const modes = authProviders.map((mode) => mode.authorizationType);\n    return modes;\n  }\n\n  private mapAuthorizationProviders(authProviders: AppSyncAuthProvider[]) {\n    const authConfig: IAppSyncAuthConfig = new AppSyncEventApiAuthConfig();\n\n    return authProviders.reduce<CfnApi.AuthProviderProperty[]>((acc, mode) => {\n      acc.push({\n        authType: mode.authorizationType,\n        cognitoConfig: authConfig.setupCognitoConfig(mode.cognitoConfig),\n        openIdConnectConfig: authConfig.setupOpenIdConnectConfig(mode.openIdConnectConfig),\n        lambdaAuthorizerConfig: authConfig.setupLambdaAuthorizerConfig(mode.lambdaAuthorizerConfig),\n      });\n      return acc;\n    }, []);\n  }\n\n  private mapAuthorizationConfig(authModes: AppSyncAuthorizationType[]) {\n    return authModes.map((mode) => ({ authType: mode }));\n  }\n\n  private validateAuthorizationProps(authProviders: AppSyncAuthProvider[]) {\n    const keyConfigs = authProviders.filter((mode) => mode.authorizationType === AppSyncAuthorizationType.API_KEY);\n    const someWithNoNames = keyConfigs.some((config) => !config.apiKeyConfig?.name);\n    if (keyConfigs.length > 1 && someWithNoNames) {\n      throw new ValidationError('You must specify key names when configuring more than 1 API key.', this);\n    }\n\n    if (authProviders.filter((authProvider) => authProvider.authorizationType === AppSyncAuthorizationType.LAMBDA).length > 1) {\n      throw new ValidationError(\n        'You can only have a single AWS Lambda function configured to authorize your API. See https://docs.aws.amazon.com/appsync/latest/devguide/security.html',\n        this,\n      );\n    }\n\n    if (authProviders.filter((authProvider) => authProvider.authorizationType === AppSyncAuthorizationType.IAM).length > 1) {\n      throw new ValidationError(\"You can't duplicate IAM configuration. See https://docs.aws.amazon.com/appsync/latest/devguide/security.html\", this);\n    }\n\n    authProviders.map((authProvider) => {\n      if (authProvider.authorizationType === AppSyncAuthorizationType.OIDC && !authProvider.openIdConnectConfig) {\n        throw new ValidationError('OPENID_CONNECT authorization type is specified but OIDC Authorizer Configuration is missing in the AuthProvider', this);\n      }\n      if (authProvider.authorizationType === AppSyncAuthorizationType.USER_POOL && !authProvider.cognitoConfig) {\n        throw new ValidationError('AMAZON_COGNITO_USER_POOLS authorization type is specified but Cognito Authorizer Configuration is missing in the AuthProvider', this);\n      }\n      if (authProvider.authorizationType === AppSyncAuthorizationType.LAMBDA && !authProvider.lambdaAuthorizerConfig) {\n        throw new ValidationError('AWS_LAMBDA authorization type is specified but Lambda Authorizer Configuration is missing in the AuthProvider', this);\n      }\n    });\n  }\n\n  private validateAuthorizationConfig(authProviders: AppSyncAuthProvider[], authTypes: AppSyncAuthorizationType[]) {\n    for (const authType of authTypes) {\n      if (!authProviders.find((authProvider) => authProvider.authorizationType === authType)) {\n        throw new ValidationError(`Missing authorization configuration for ${authType}`, this);\n      }\n    }\n    if (authTypes.length === 0) {\n      throw new ValidationError('Empty AuthModeTypes array is not allowed, if specifying, you must specify a valid mode', this);\n    }\n  }\n\n  /**\n   * The AppSyncDomainName of the associated custom domain\n   */\n  public get appSyncDomainName(): string {\n    if (!this.domainNameResource) {\n      throw new ValidationError('Cannot retrieve the appSyncDomainName without a domainName configuration', this);\n    }\n    return this.domainNameResource.attrAppSyncDomainName;\n  }\n\n  /**\n   * The HTTP Endpoint of the associated custom domain\n   */\n  public get customHttpEndpoint(): string {\n    if (!this.domainNameResource) {\n      throw new ValidationError('Cannot retrieve the appSyncDomainName without a domainName configuration', this);\n    }\n    return `https://${this.domainNameResource.attrDomainName}/event`;\n  }\n\n  /**\n   * The Realtime Endpoint of the associated custom domain\n   */\n  public get customRealtimeEndpoint(): string {\n    if (!this.domainNameResource) {\n      throw new ValidationError('Cannot retrieve the appSyncDomainName without a domainName configuration', this);\n    }\n    return `wss://${this.domainNameResource.attrDomainName}/event/realtime`;\n  }\n}", "language": "typescript"}
{"input": "MSK Cluster and client", "output": "class MskBroker(NestedStack):\n    def __init__(self, scope: Construct, construct_id: str, vpc, client_subnet, **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # MSK cluster with SASL/SCRAM authentication\n        self.cluster = msk.Cluster(self, \"Cluster\",\n            cluster_name=\"iotCluster\",\n            kafka_version=msk.KafkaVersion.V2_8_1,\n            vpc=vpc,\n            encryption_in_transit=msk.EncryptionInTransitConfig(\n                client_broker=msk.ClientBrokerEncryption.TLS\n            ),\n            client_authentication=msk.ClientAuthentication.sasl(\n                scram=True\n            ),    \n        )\n\n        # Enable MSK cluster connection on ports 2181 and 9096 for SASL/SCRAM authentication \n        self.cluster.connections.allow_from(\n            ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            ec2.Port.tcp(2181))\n        self.cluster.connections.allow_from(\n            ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            ec2.Port.tcp(9096))\n        \n        # EC2 Instance in the public subnet used to create the topics\n        client = MSKClient(self, \"MskClient\", \n            vpc=vpc, \n            client_subnet=client_subnet, \n            zookeeper=self.cluster.zookeeper_connection_string)", "language": "python"}
{"input": "The following table describes all of the available fields for a flow log record.", "output": "export class LogFormat {\n  /**\n   * The VPC Flow Logs version.\n   */\n  public static readonly VERSION = LogFormat.field('version');\n\n  /**\n   * The AWS account ID of the owner of the source network interface for which traffic is recorded.\n   */\n  public static readonly ACCOUNT_ID = LogFormat.field('account-id');\n\n  /**\n   * The ID of the network interface for which the traffic is recorded.\n   */\n  public static readonly INTERFACE_ID = LogFormat.field('interface-id');\n\n  /**\n   * The source address for incoming traffic, or the IPv4 or IPv6 address of the network interface\n   * for outgoing traffic on the network interface.\n   */\n  public static readonly SRC_ADDR = LogFormat.field('srcaddr');\n\n  /**\n   * The destination address for outgoing traffic, or the IPv4 or IPv6 address of the network interface\n   * for incoming traffic on the network interface.\n   */\n  public static readonly DST_ADDR = LogFormat.field('dstaddr');\n\n  /**\n   * The source port of the traffic.\n   */\n  public static readonly SRC_PORT = LogFormat.field('srcport');\n\n  /**\n   * The destination port of the traffic.\n   */\n  public static readonly DST_PORT = LogFormat.field('dstport');\n\n  /**\n   * The IANA protocol number of the traffic.\n   */\n  public static readonly PROTOCOL = LogFormat.field('protocol');\n\n  /**\n   * The number of packets transferred during the flow.\n   */\n  public static readonly PACKETS = LogFormat.field('packets');\n\n  /**\n   * The number of bytes transferred during the flow.\n   */\n  public static readonly BYTES = LogFormat.field('bytes');\n\n  /**\n   * The time, in Unix seconds, when the first packet of the flow was received within\n   * the aggregation interval.\n   *\n   * This might be up to 60 seconds after the packet was transmitted or received on\n   * the network interface.\n   */\n  public static readonly START_TIMESTAMP = LogFormat.field('start');\n\n  /**\n   * The time, in Unix seconds, when the last packet of the flow was received within\n   * the aggregation interval.\n   *\n   * This might be up to 60 seconds after the packet was transmitted or received on\n   * the network interface.\n   */\n  public static readonly END_TIMESTAMP = LogFormat.field('end');\n\n  /**\n   * The action that is associated with the traffic.\n   */\n  public static readonly ACTION = LogFormat.field('action');\n\n  /**\n   * The logging status of the flow log.\n   */\n  public static readonly LOG_STATUS = LogFormat.field('log-status');\n\n  /**\n   * The ID of the VPC that contains the network interface for which the traffic is recorded.\n   */\n  public static readonly VPC_ID = LogFormat.field('vpc-id');\n\n  /**\n   * The ID of the subnet that contains the network interface for which the traffic is recorded.\n   */\n  public static readonly SUBNET_ID = LogFormat.field('subnet-id');\n\n  /**\n   * The ID of the instance that's associated with network interface for which the traffic is\n   * recorded, if the instance is owned by you.\n   *\n   * Returns a '-' symbol for a requester-managed network interface; for example, the\n   * network interface for a NAT gateway\n   */\n  public static readonly INSTANCE_ID = LogFormat.field('instance-id');\n\n  /**\n   * The bitmask value for TCP flags.\n   *\n   * - FIN -- 1\n   * - SYN -- 2\n   * - RST -- 4\n   * - SYN-ACK -- 18\n   *\n   * If no supported flags are recorded, the TCP flag value is 0.\n   *\n   * TCP flags can be OR-ed during the aggregation interval. For short connections,\n   * the flags might be set on the same line in the flow log record, for example,\n   * 19 for SYN-ACK and FIN, and 3 for SYN and FIN.\n   */\n  public static readonly TCP_FLAGS = LogFormat.field('tcp-flags');\n\n  /**\n   * The type of traffic.\n   *\n   * The possible values are IPv4, IPv6, or EFA.\n   */\n  public static readonly TRAFFIC_TYPE = LogFormat.field('type');\n\n  /**\n   * The packet-level (original) source IP address of the traffic.\n   */\n  public static readonly PKT_SRC_ADDR = LogFormat.field('pkt-srcaddr');\n\n  /**\n   * The packet-level (original) destination IP address for the traffic.\n   */\n  public static readonly PKT_DST_ADDR = LogFormat.field('pkt-dstaddr');\n\n  /**\n   * The Region that contains the network interface for which traffic is recorded.\n   */\n  public static readonly REGION = LogFormat.field('region');\n\n  /**\n   * The ID of the Availability Zone that contains the network interface for which traffic is recorded.\n   */\n  public static readonly AZ_ID = LogFormat.field('az-id');\n\n  /**\n   * The type of sublocation that's returned in the sublocation-id field.\n   */\n  public static readonly SUBLOCATION_TYPE = LogFormat.field('sublocation-type');\n\n  /**\n   * The ID of the sublocation that contains the network interface for which traffic is recorded.\n   */\n  public static readonly SUBLOCATION_ID = LogFormat.field('sublocation-id');\n\n  /**\n   * The name of the subset of IP address ranges for the pkt-srcaddr field,\n   * if the source IP address is for an AWS service.\n   */\n  public static readonly PKT_SRC_AWS_SERVICE = LogFormat.field('pkt-src-aws-service');\n\n  /**\n   * The name of the subset of IP address ranges for the pkt-dstaddr field,\n   * if the destination IP address is for an AWS service.\n   */\n  public static readonly PKT_DST_AWS_SERVICE = LogFormat.field('pkt-dst-aws-service');\n\n  /**\n   * The direction of the flow with respect to the interface where traffic is captured.\n   */\n  public static readonly FLOW_DIRECTION = LogFormat.field('flow-direction');\n\n  /**\n   * The path that egress traffic takes to the destination.\n   */\n  public static readonly TRAFFIC_PATH = LogFormat.field('traffic-path');\n\n  /**\n   * AWS Resource Name (ARN) of the ECS cluster if the traffic is from a running ECS task.\n   */\n  public static readonly ECS_CLUSTER_ARN = LogFormat.field('ecs-cluster-arn');\n\n  /**\n   * Name of the ECS cluster if the traffic is from a running ECS task.\n   */\n  public static readonly ECS_CLUSTER_NAME = LogFormat.field('ecs-cluster-name');\n\n  /**\n   * ARN of the ECS container instance if the traffic is from a running ECS task on an EC2 instance.\n   */\n  public static readonly ECS_CONTAINER_INSTANCE_ARN = LogFormat.field('ecs-container-instance-arn');\n\n  /**\n   * ID of the ECS container instance if the traffic is from a running ECS task on an EC2 instance.\n   */\n  public static readonly ECS_CONTAINER_INSTANCE_ID = LogFormat.field('ecs-container-instance-id');\n\n  /**\n   * Docker runtime ID of the container if the traffic is from a running ECS task.\n   * If there is one container or more in the ECS task, this will be the docker runtime ID of the first container.\n   */\n  public static readonly ECS_CONTAINER_ID = LogFormat.field('ecs-container-id');\n\n  /**\n   * Docker runtime ID of the container if the traffic is from a running ECS task.\n   * If there is more than one container in the ECS task, this will be the Docker runtime ID of the second container.\n   */\n  public static readonly ECS_SECOND_CONTAINER_ID = LogFormat.field('ecs-second-container-id');\n\n  /**\n   * Name of the ECS service if the traffic is from a running ECS task and the ECS task is started by an ECS service.\n   */\n  public static readonly ECS_SERVICE_NAME = LogFormat.field('ecs-service-name');\n\n  /**\n   * ARN of the ECS task definition if the traffic is from a running ECS task.\n   */\n  public static readonly ECS_TASK_DEFINITION_ARN = LogFormat.field('ecs-task-definition-arn');\n\n  /**\n   * ARN of the ECS task if the traffic is from a running ECS task.\n   */\n  public static readonly ECS_TASK_ARN = LogFormat.field('ecs-task-arn');\n\n  /**\n   * ID of the ECS task if the traffic is from a running ECS task.\n   */\n  public static readonly ECS_TASK_ID = LogFormat.field('ecs-task-id');\n\n  /**\n   * The default format.\n   */\n  public static readonly ALL_DEFAULT_FIELDS = new LogFormat('${version} ${account-id} ${interface-id} ${srcaddr} ${dstaddr} ${srcport} ${dstport} ${protocol} ${packets} ${bytes} ${start} ${end} ${action} ${log-status}');\n\n  /**\n   * A custom format string.\n   *\n   * Gives full control over the format string fragment.\n   */\n  public static custom(formatString: string): LogFormat {\n    return new LogFormat(formatString);\n  }\n\n  /**\n   * A custom field name.\n   *\n   * If there is no ready-made constant for a new field yet, you can use this.\n   * The field name will automatically be wrapped in `${ ... }`.\n   */\n  public static field(field: string): LogFormat {\n    return new LogFormat(`\\${${field}}`);\n  }\n\n  protected constructor(public readonly value: string) {}\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, EC2, VPC, CloudWatch Logs resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const vpc = new Vpc(this, 'Vpc');\n    const securityGroup = new SecurityGroup(this, 'SecurityGroup', { vpc });\n    const logGroup = new LogGroup(this, 'LogGroup');\n    const onEventHandler = new Function(this, 'OnEvent', {\n      code: Code.fromInline('foo'),\n      handler: 'index.onEvent',\n      runtime: Runtime.NODEJS_LATEST,\n    });\n    const isCompleteHandler = new Function(this, 'IsComplete', {\n      code: Code.fromInline('foo'),\n      handler: 'index.isComplete',\n      runtime: Runtime.NODEJS_LATEST,\n    });\n\n    new Provider(this, 'MyProvider', {\n      onEventHandler,\n      isCompleteHandler,\n      vpc: vpc,\n      vpcSubnets: { subnetType: SubnetType.PRIVATE_WITH_EGRESS },\n      securityGroups: [securityGroup],\n      waiterStateMachineLogOptions: {\n        destination: logGroup,\n        includeExecutionData: true,\n        level: LogLevel.ALL,\n      },\n    });\n\n    new Provider(this, 'MyProviderWithoutLogOptions', {\n      onEventHandler,\n      isCompleteHandler,\n      vpc: vpc,\n      vpcSubnets: { subnetType: SubnetType.PRIVATE_WITH_EGRESS },\n      securityGroups: [securityGroup],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, CloudWatch, CloudFormation resources", "output": "export class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const table = new Table(this, 'Table', {\n      partitionKey: { name: 'metric', type: AttributeType.STRING },\n    });\n    const metricTableThrottled = table.metricThrottledRequestsForOperations({\n      operations: [Operation.PUT_ITEM, Operation.SCAN],\n      period: Duration.minutes(1),\n    });\n    new Alarm(this, 'TableThrottleAlarm', {\n      metric: metricTableThrottled,\n      evaluationPeriods: 1,\n      threshold: 1,\n    });\n    const metricTableError = table.metricSystemErrorsForOperations({\n      operations: [Operation.PUT_ITEM, Operation.SCAN],\n      period: Duration.minutes(1),\n    });\n    new Alarm(this, 'TableErrorAlarm', {\n      metric: metricTableError,\n      evaluationPeriods: 1,\n      threshold: 1,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, Lake Formation resources", "output": "class BogusStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    new CfnResource(this, 'Resource', {\n      type: 'CDK::Test::Resource',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedFileSystem for AWS resource management", "output": "class ImportedFileSystem extends FileSystemBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-efs.ImportedFileSystem';\n  /**\n   * The security groups/rules used to allow network connections to the file system.\n   */\n  public readonly connections: ec2.Connections;\n\n  /**\n   * @attribute\n   */\n  public readonly fileSystemId: string;\n\n  /**\n   * @attribute\n   */\n  public readonly fileSystemArn: string;\n\n  /**\n   * Dependable that can be depended upon to ensure the mount targets of the filesystem are ready\n   */\n  public readonly mountTargetsAvailable: IDependable;\n\n  constructor(scope: Construct, id: string, attrs: FileSystemAttributes) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, attrs);\n\n    if (!!attrs.fileSystemId === !!attrs.fileSystemArn) {\n      throw new ValidationError('One of fileSystemId or fileSystemArn, but not both, must be provided.', this);\n    }\n\n    this.fileSystemArn = attrs.fileSystemArn ?? Stack.of(scope).formatArn({\n      service: 'elasticfilesystem',\n      resource: 'file-system',\n      resourceName: attrs.fileSystemId,\n    });\n\n    const parsedArn = Stack.of(scope).splitArn(this.fileSystemArn, ArnFormat.SLASH_RESOURCE_NAME);\n\n    if (!parsedArn.resourceName) {\n      throw new ValidationError(`Invalid FileSystem Arn ${this.fileSystemArn}`, this);\n    }\n\n    this.fileSystemId = attrs.fileSystemId ?? parsedArn.resourceName;\n\n    this.connections = new ec2.Connections({\n      securityGroups: [attrs.securityGroup],\n      defaultPort: ec2.Port.tcp(FileSystem.DEFAULT_PORT),\n    });\n\n    this.mountTargetsAvailable = new DependencyGroup();\n  }\n}", "language": "typescript"}
{"input": "CDK class Build for AWS resource management", "output": "export class Build extends BuildBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-gamelift-alpha.Build';\n\n  /**\n   * Create a new Build from s3 content\n   */\n  static fromBucket(scope: Construct, id: string, bucket: s3.IBucket, key: string, objectVersion?: string) {\n    return new Build(scope, id, {\n      content: Content.fromBucket(bucket, key, objectVersion),\n    });\n  }\n\n  /**\n   * Create a new Build from asset content\n   */\n  static fromAsset(scope: Construct, id: string, path: string, options?: s3_assets.AssetOptions) {\n    return new Build(scope, id, {\n      content: Content.fromAsset(path, options),\n    });\n  }\n\n  /**\n   * Import a build into CDK using its identifier\n   */\n  static fromBuildId(scope: Construct, id: string, buildId: string): IBuild {\n    return this.fromBuildAttributes(scope, id, { buildId });\n  }\n\n  /**\n   * Import a build into CDK using its ARN\n   */\n  static fromBuildArn(scope: Construct, id: string, buildArn: string): IBuild {\n    return this.fromBuildAttributes(scope, id, { buildArn });\n  }\n\n  /**\n   * Import an existing build from its attributes.\n   */\n  static fromBuildAttributes(scope: Construct, id: string, attrs: BuildAttributes): IBuild {\n    if (!attrs.buildId && !attrs.buildArn) {\n      throw new Error('Either buildId or buildArn must be provided in BuildAttributes');\n    }\n    const buildId = attrs.buildId ??\n      cdk.Stack.of(scope).splitArn(attrs.buildArn!, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName;\n\n    if (!buildId) {\n      throw new Error(`No build identifier found in ARN: '${attrs.buildArn}'`);\n    }\n\n    const buildArn = attrs.buildArn ?? cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'build',\n      resourceName: attrs.buildId,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n    class Import extends BuildBase {\n      public readonly buildId = buildId!;\n      public readonly buildArn = buildArn;\n      public readonly grantPrincipal = attrs.role ?? new iam.UnknownPrincipal({ resource: this });\n      public readonly role = attrs.role;\n\n      constructor(s: Construct, i: string) {\n        super(s, i, {\n          environmentFromArn: buildArn,\n        });\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * The Identifier of the build.\n   */\n  public readonly buildId: string;\n\n  /**\n   * The ARN of the build.\n   */\n  public readonly buildArn: string;\n\n  /**\n   * The IAM role GameLift assumes to acccess server build content.\n   */\n  public readonly role: iam.IRole;\n\n  /**\n   * The principal this GameLift Build is using.\n   */\n  public readonly grantPrincipal: iam.IPrincipal;\n\n  constructor(scope: Construct, id: string, props: BuildProps) {\n    super(scope, id, {\n      physicalName: props.buildName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.buildName && !cdk.Token.isUnresolved(props.buildName)) {\n      if (props.buildName.length > 1024) {\n        throw new Error(`Build name can not be longer than 1024 characters but has ${props.buildName.length} characters.`);\n      }\n    }\n\n    this.validateServerSdkVersion(props.serverSdkVersion);\n\n    this.role = props.role ?? new iam.Role(this, 'ServiceRole', {\n      assumedBy: new iam.ServicePrincipal('gamelift.amazonaws.com'),\n    });\n    this.grantPrincipal = this.role;\n    const content = props.content.bind(this, this.role);\n\n    const resource = new CfnBuild(this, 'Resource', {\n      name: props.buildName,\n      version: props.buildVersion,\n      operatingSystem: props.operatingSystem,\n      storageLocation: {\n        bucket: content.s3Location && content.s3Location.bucketName,\n        key: content.s3Location && content.s3Location.objectKey,\n        objectVersion: content.s3Location && content.s3Location.objectVersion,\n        roleArn: this.role.roleArn,\n      },\n      serverSdkVersion: props.serverSdkVersion,\n    });\n\n    resource.node.addDependency(this.role);\n\n    this.buildId = this.getResourceNameAttribute(resource.ref);\n    this.buildArn = cdk.Stack.of(scope).formatArn({\n      service: 'gamelift',\n      resource: 'build',\n      resourceName: this.buildId,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    });\n  }\n\n  private validateServerSdkVersion(serverSdkVersion?: string) {\n    if (serverSdkVersion === undefined || cdk.Token.isUnresolved(serverSdkVersion)) return;\n    if (!serverSdkVersion.match(/^\\d+\\.\\d+\\.\\d+$/)) {\n      throw new Error(`serverSdkVersion must be in the 0.0.0 format, got \\'${serverSdkVersion}\\'.`);\n    }\n    if (serverSdkVersion.length > 128) {\n      throw new Error(`serverSdkVersion length must be smaller than or equal to 128, got ${serverSdkVersion.length}.`);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class S3WorkflowDataFromBucketKey for AWS resource management", "output": "class S3WorkflowDataFromBucketKey extends S3WorkflowData {\n  public constructor(bucket: s3.IBucket, key: string) {\n    super(bucket, key);\n  }\n}", "language": "typescript"}
{"input": "Lambda function handler test_lambda_function_has_correct_properties", "output": "def test_lambda_function_has_correct_properties(self):\n    dependency_capture = Capture()\n    template.has_resource('AWS::Lambda::Function', {\n      'Properties':{\n        'Code': {\n          'ZipFile': \"def main(event, context):\\n    print(\\\"I'm running!\\\")\\n\",\n        },\n        'Handler': 'index.main',\n        'Runtime': 'python3.12',\n        'Timeout': 300,\n      },\n      'DependsOn':[dependency_capture]\n    })\n\n    assert 'SingletonServiceRole' in dependency_capture.as_string()", "language": "python"}
{"input": "CDK class Workflow for AWS resource management", "output": "export class Workflow extends WorkflowBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.Workflow';\n\n  /**\n   * Import an existing workflow given its ARN.\n   */\n  public static fromWorkflowArn(scope: Construct, id: string, workflowArn: string): IWorkflow {\n    return this.fromWorkflowAttributes(scope, id, { workflowArn });\n  }\n\n  /**\n   * Import an existing workflow by providing its attributes. The provided name must be normalized by converting\n   * all alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens. You may not\n   * provide a dynamic expression for the workflowArn or workflowType\n   */\n  public static fromWorkflowAttributes(scope: Construct, id: string, attrs: WorkflowAttributes): IWorkflow {\n    if (\n      attrs.workflowArn !== undefined &&\n      (attrs.workflowName !== undefined || attrs.workflowType !== undefined || attrs.workflowVersion !== undefined)\n    ) {\n      throw new cdk.ValidationError(\n        'a workflowName, workflowType, or workflowVersion cannot be provided when a workflowArn is provided',\n        scope,\n      );\n    }\n\n    if (attrs.workflowArn === undefined && (attrs.workflowName === undefined || attrs.workflowType === undefined)) {\n      throw new cdk.ValidationError('either workflowArn, or workflowName and workflowType is required', scope);\n    }\n\n    if (attrs.workflowType && cdk.Token.isUnresolved(attrs.workflowType)) {\n      throw new cdk.ValidationError('workflowType cannot be an unresolved token', scope);\n    }\n\n    const workflowArn = (() => {\n      if (attrs.workflowArn !== undefined) {\n        return attrs.workflowArn;\n      }\n\n      return cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'workflow',\n        resourceName: `${attrs.workflowType!.toLowerCase()}/${attrs.workflowName!}/${attrs.workflowVersion ?? LATEST_VERSION}`,\n      });\n    })();\n\n    const [workflowType, workflowName, workflowVersion] = (() => {\n      if (attrs.workflowName !== undefined) {\n        return [attrs.workflowType!.toUpperCase(), attrs.workflowName, attrs.workflowVersion ?? LATEST_VERSION];\n      }\n\n      const workflowNameTypeVersion = cdk.Stack.of(scope).splitArn(\n        workflowArn,\n        cdk.ArnFormat.SLASH_RESOURCE_NAME,\n      ).resourceName!;\n\n      if (cdk.Token.isUnresolved(workflowNameTypeVersion)) {\n        throw new cdk.ValidationError(\n          'the workflowName, workflowType, and workflowVersion in the workflowArn cannot be an unresolved token',\n          scope,\n        );\n      }\n\n      if (workflowNameTypeVersion.split('/').length < 3) {\n        throw new cdk.ValidationError(\n          'the workflow ARN must end with <workflow-type>/<workflow-name>/<workflow-version>',\n          scope,\n        );\n      }\n\n      const workflowNameTypeVersionSplit = workflowNameTypeVersion.split('/');\n      const [workflowTypeFromArn, workflowNameFromArn, workflowVersionFromArn] = workflowNameTypeVersionSplit.slice(\n        0,\n        3,\n      );\n\n      return [workflowTypeFromArn.toUpperCase(), workflowNameFromArn, workflowVersionFromArn];\n    })();\n\n    class Import extends WorkflowBase {\n      public readonly workflowArn = workflowArn;\n      public readonly workflowName = workflowName;\n      public readonly workflowType = workflowType;\n      public readonly workflowVersion = workflowVersion;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Return whether the given object is a Workflow.\n   */\n  public static isWorkflow(x: any): x is Workflow {\n    return x !== null && typeof x === 'object' && WORKFLOW_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the workflow\n   */\n  public readonly workflowArn: string;\n\n  /**\n   * The name of the workflow\n   */\n  public readonly workflowName: string;\n\n  /**\n   * The type of the workflow\n   */\n  public readonly workflowType: string;\n\n  /**\n   * The version of the workflow\n   */\n  public readonly workflowVersion: string;\n\n  public constructor(scope: Construct, id: string, props: WorkflowProps) {\n    super(scope, id, {\n      physicalName:\n        props.workflowName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, WORKFLOW_SYMBOL, { value: true });\n\n    this.validateWorkflowName();\n\n    const workflowVersion = props.workflowVersion ?? '1.0.0';\n    const workflow = new CfnWorkflow(this, 'Resource', {\n      name: this.physicalName,\n      version: workflowVersion,\n      type: props.workflowType,\n      changeDescription: props.changeDescription,\n      description: props.description,\n      kmsKeyId: props.kmsKey?.keyArn,\n      tags: props.tags,\n      ...props.data.render(),\n    });\n\n    this.workflowName = this.getResourceNameAttribute(workflow.getAtt('Name').toString());\n    this.workflowArn = workflow.attrArn;\n    this.workflowVersion = workflowVersion;\n    this.workflowType = props.workflowType;\n  }\n\n  private validateWorkflowName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError('the workflowName cannot be longer than 128 characters', this);\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError('the workflowName cannot contain spaces', this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError('the workflowName cannot contain underscores', this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError('the workflowName must be lowercase', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ChainDefinitionBody for AWS resource management", "output": "export class ChainDefinitionBody extends DefinitionBody {\n  constructor(public readonly chainable: IChainable) {\n    super();\n  }\n\n  public bind(scope: Construct, _sfnPrincipal: iam.IPrincipal, sfnProps: StateMachineProps, graph?: StateGraph): DefinitionConfig {\n    const graphJson = graph!.toGraphJson(sfnProps.queryLanguage);\n    return {\n      definitionString: Stack.of(scope).toJsonString({\n        ...graphJson,\n        Comment: sfnProps.comment,\n        QueryLanguage: sfnProps.queryLanguage,\n      }),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, RDS, EC2, VPC resources", "output": "class RedshiftDistKeyStack extends cdk.Stack {\n  constructor(scope: constructs.Construct, id: string, props: RedshiftDistKeyStackProps) {\n    super(scope, id, props);\n\n    const key = new kms.Key(this, 'custom-kms-key');\n    const vpc = new ec2.Vpc(this, 'Vpc', { restrictDefaultSecurityGroup: false });\n    const databaseName = 'my_db';\n\n    const cluster = new redshift.Cluster(this, 'Cluster', {\n      vpc: vpc,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PUBLIC,\n      },\n      masterUser: {\n        masterUsername: 'admin',\n      },\n      defaultDatabaseName: databaseName,\n      publiclyAccessible: true,\n      encryptionKey: key,\n    });\n\n    cluster.addToParameterGroup('enable_user_activity_logging', 'true');\n\n    const databaseOptions = {\n      cluster: cluster,\n      databaseName: databaseName,\n    };\n\n    const tableOptions = {\n      tableName: 'mytable',\n      sortStyle: redshift.TableSortStyle.AUTO,\n      tableComment: 'A test table',\n    };\n    new redshift.Table(this, 'Table', {\n      ...databaseOptions,\n      tableColumns: [\n        { name: 'col1', dataType: 'varchar(4)', distKey: props.hasDistKey, comment: 'A test column' },\n      ],\n      ...tableOptions,\n    });\n  }\n}", "language": "typescript"}
{"input": "Represents the service source from ECR.", "output": "export class EcrSource extends Source {\n  private readonly props: EcrProps;\n  constructor(props: EcrProps) {\n    super();\n    this.props = props;\n  }\n  public bind(_scope: Construct): SourceConfig {\n    return {\n      imageRepository: {\n        imageConfiguration: this.props.imageConfiguration,\n        imageIdentifier: this.props.repository.repositoryUriForTagOrDigest(\n          this.props.tagOrDigest || this.props.tag || 'latest',\n        ),\n        imageRepositoryType: ImageRepositoryType.ECR,\n      },\n      ecrRepository: this.props.repository,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Construct for EC2, VPC infrastructure components", "output": "class ConstructThatTakesAVpc extends Construct {\n  constructor(scope: Construct, id: string, _props: ConstructThatTakesAVpcProps) {\n    super(scope, id);\n\n    // new ec2.CfnInstance(this, 'Instance', {\n    //   subnetId: props.vpc.privateSubnets[0].subnetId,\n    //   imageId: new ec2.AmazonLinuxImage().getImage(this).imageId,\n    // });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3DockerfileDataFromAsset for AWS resource management", "output": "class S3DockerfileDataFromAsset extends S3DockerfileData {\n  public constructor(asset: s3assets.Asset) {\n    super(asset.bucket, asset.s3ObjectKey);\n  }\n}", "language": "typescript"}
{"input": "CDK class LogsDelivery for AWS resource management", "output": "class LogsDelivery {\n  public scope: Module;\n  public readonly mixin: LogsMixin;\n  private readonly helpers: LogsHelper[] = [];\n\n  constructor(\n    scope: Module,\n    public readonly db: SpecDatabase,\n    private readonly resource: Resource,\n    constructLibModule: ExternalModule,\n  ) {\n    this.scope = scope;\n\n    for (const log of this.resource.vendedLogs || []) {\n      const logClass = new LogsHelper(this.scope,\n        `${naming.classNameFromResource(this.resource)}${log.logType.split('_').map(word => word.charAt(0) + word.slice(1).toLowerCase()).join('')}`,\n        this.resource, log,\n      );\n      this.helpers.push(logClass);\n    }\n\n    this.mixin = new LogsMixin(scope, db, resource, constructLibModule);\n  }\n\n  public build() {\n    this.mixin.build();\n    for (const helper of this.helpers) {\n      helper.build(this.mixin);\n    }\n  }\n}", "language": "typescript"}
{"input": "Class to define an API Schema from an S3 object.", "output": "export class S3ApiSchema extends ApiSchema {\n  constructor(private readonly location: Location, public readonly bucketOwnerAccountId?: string) {\n    super(location, bucketOwnerAccountId, undefined);\n  }\n  /**\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): any {\n    return {\n      s3: {\n        uri: `s3://${this.location.bucketName}/${this.location.objectKey}`,\n        ...(this.bucketOwnerAccountId && { bucketOwnerAccountId: this.bucketOwnerAccountId }),\n      },\n    };\n  }\n\n  public bind(scope: Construct): void {\n    if (scope) {\n    }\n    // No-op\n  }\n\n  public grantPermissionsToRole(role: IRole): void {\n    Grant.addToPrincipal({\n      grantee: role,\n      actions: ['s3:GetObject'],\n      resourceArns: [`arn:${Aws.PARTITION}:s3:::${this.location.bucketName}/${this.location.objectKey}`],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3AssertProvider for AWS resource management", "output": "class S3AssertProvider extends Construct {\n  /**\n   * Returns the singleton provider.\n   */\n  public static getOrCreate(scope: Construct) {\n    const providerId = 'com.amazonaws.cdk.custom-resources.s3assert-provider';\n    const stack = Stack.of(scope);\n    const group = Node.of(stack).tryFindChild(providerId) as S3AssertProvider || new S3AssertProvider(stack, providerId);\n    return group.provider.serviceToken;\n  }\n\n  private readonly provider: cr.Provider;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const onEvent = new lambda.Function(this, 's3assert-on-event', {\n      code: lambda.Code.fromAsset(path.join(__dirname, 's3-assert-handler')),\n      runtime: lambda.Runtime.PYTHON_3_10,\n      handler: 'index.on_event',\n    });\n\n    const isComplete = new lambda.Function(this, 's3assert-is-complete', {\n      code: lambda.Code.fromAsset(path.join(__dirname, 's3-assert-handler')),\n      runtime: lambda.Runtime.PYTHON_3_10,\n      handler: 'index.is_complete',\n      initialPolicy: [\n        new iam.PolicyStatement({\n          resources: ['*'],\n          actions: [\n            's3:GetObject*',\n            's3:GetBucket*',\n            's3:List*',\n          ],\n        }),\n      ],\n    });\n\n    this.provider = new cr.Provider(this, 's3assert-provider', {\n      onEventHandler: onEvent,\n      isCompleteHandler: isComplete,\n      totalTimeout: Duration.minutes(5),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class CaaAmazonRecord for AWS resource management", "output": "export class CaaAmazonRecord extends CaaRecord {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.CaaAmazonRecord';\n\n  constructor(scope: Construct, id: string, props: CaaAmazonRecordProps) {\n    super(scope, id, {\n      ...props,\n      values: [\n        {\n          flag: 0,\n          tag: CaaTag.ISSUE,\n          value: 'amazon.com',\n        },\n      ],\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "Represents an SVCB record value.", "output": "export class SvcbRecordValue extends SvcbRecordValueBase {\n  /**\n   * An SVCB AliasMode record value.\n   *\n   * @param targetName The domain name of the alternative endpoint.\n   */\n  public static alias(targetName: string): SvcbRecordValue {\n    return new SvcbRecordValue({ priority: 0, targetName });\n  }\n\n  /**\n   * An SVCB ServiceMode record value.\n   */\n  public static service(props?: SvcbRecordServiceModeProps): SvcbRecordValue {\n    return new SvcbRecordValue({ priority: 1, targetName: '.', ...props });\n  }\n\n  private constructor(props: SvcbRecordValueBaseProps) {\n    super(props);\n  }\n}", "language": "typescript"}
{"input": "CDK class EventBridgeServiceModule for AWS resource management", "output": "class EventBridgeServiceModule extends BaseServiceSubmodule {\n  public readonly constructLibModule: ExternalModule;\n\n  public constructor(props: ServiceSubmoduleProps) {\n    super(props);\n    this.constructLibModule = new ExternalModule(`aws-cdk-lib/${props.submoduleName}`);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, CloudWatch resources", "output": "class LambdaCloudwatchDashboardStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        example_dashboard_name = \"ExampleLambdaDashboard\"\n\n        # Create Example Lambda function\n        lambda_function = aws_lambda.Function(self, \"lambda_function\",\n                                    runtime=aws_lambda.Runtime.PYTHON_3_7,\n                                    handler=\"lambda-handler.main\",\n                                    code=aws_lambda.Code.from_asset(\"./lambda\"))\n\n        assert lambda_function.role is not None\n        lambda_function.role.add_managed_policy(\n            aws_iam.ManagedPolicy.from_aws_managed_policy_name(\"service-role/AWSLambdaBasicExecutionRole\")\n        )\n\n        # Create CloudWatch Dashboard to view Lambda Function Metrics\n        cw_dashboard = aws_cloudwatch.Dashboard(self, \"Lambda Dashboard\",\n            dashboard_name=example_dashboard_name\n        )\n        # CloudWatch Dashboard Title\n        title_widget = aws_cloudwatch.TextWidget(\n            markdown=\"# Dashboard: {}\".format(lambda_function.function_name),\n            height=1,\n            width=24\n        )\n        # Create Widgets for CloudWatch Dashboard based on Lambda Function's CloudWatch Metrics\n        invocations_widget = aws_cloudwatch.GraphWidget(title= \"Invocations\",\n            left=[lambda_function.metric_invocations()],\n            width=24)\n\n        errors_widget = aws_cloudwatch.GraphWidget(title= \"Errors\",\n            left=[lambda_function.metric_errors()],\n            width=24)\n\n        duration_widget = aws_cloudwatch.GraphWidget(title= \"Duration\",\n            left=[lambda_function.metric_duration()],\n            width=24)\n\n        throttles_widget = aws_cloudwatch.GraphWidget(title= \"Throttles\",\n            left=[lambda_function.metric_throttles()],\n            width=24)\n\n        # Create Widget to show last 20 Log Entries\n        log_widget = aws_cloudwatch.LogQueryWidget(log_group_names=[lambda_function.log_group.log_group_name],\n            query_lines=[\"fields @timestamp, @message\", \"sort @timestamp desc\", \"limit 20\"], width=24)\n\n        # Add Widgets to CloudWatch Dashboard\n        cw_dashboard.add_widgets(title_widget,\n                                 invocations_widget,\n                                 errors_widget,\n                                 duration_widget,\n                                 throttles_widget,\n                                 log_widget)\n\n        # Output Dashboard URL\n        cloudwatch_dasboard_url = 'https://{}.console.aws.amazon.com/cloudwatch/home?region={}#dashboards:name={}'.format(\n            Aws.REGION,\n            Aws.REGION,\n            example_dashboard_name\n        )\n        CfnOutput(self,\"DashboardOutput\",\n            value=cloudwatch_dasboard_url,\n            description=\"URL of Sample CloudWatch Dashboard\",\n            export_name=\"SampleCloudWatchDashboardURL\")\n\n        CfnOutput(self,\"LambdaName\",\n            value=lambda_function.function_name,\n            description=\"Name of the sample Lambda Function\",\n            export_name=\"LambdaName\")", "language": "python"}
{"input": "CDK Stack that creates RDS, EC2, VPC, CloudFormation resources", "output": "class OptionGroupTestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const optionGroup = new OptionGroup(this, 'OptionGroup', {\n      engine: DatabaseInstanceEngine.oracleSe2({\n        version: OracleEngineVersion.VER_19,\n      }),\n      description: 'Custom Option Grouptest',\n      optionGroupName: 'custom-og-name',\n      configurations: [\n        {\n          name: 'OEM',\n          port: 1158,\n          vpc,\n        },\n      ],\n    });\n    optionGroup.optionConnections.OEM.connections.allowDefaultPortFrom(\n      ec2.Peer.ipv4('10.0.0.0/16'),\n    );\n  }\n}", "language": "typescript"}
{"input": "Function to create a S3 bucket using CDK", "output": "def create_bucket(self, name):\n        bucket = s3.Bucket(self, name, bucket_name = name)\n        return bucket", "language": "python"}
{"input": "CDK class AutoDeleteObjectsProvider for AWS resource management", "output": "export class AutoDeleteObjectsProvider extends CustomResourceProviderBase {\n  public static getOrCreate(scope: Construct, uniqueid: string, props?: CustomResourceProviderOptions): string {\n    return this.getOrCreateProvider(scope, uniqueid, props).serviceToken;\n  }\n\n  public static getOrCreateProvider(scope: Construct, uniqueid: string, props?: CustomResourceProviderOptions): AutoDeleteObjectsProvider {\n    const id = `${uniqueid}CustomResourceProvider`;\n    const stack = Stack.of(scope);\n    const existing = stack.node.tryFindChild(id) as AutoDeleteObjectsProvider;\n    return existing ?? new AutoDeleteObjectsProvider(stack, id, props);\n  }\n\n  private constructor(scope: Construct, id: string, props?: CustomResourceProviderOptions) {\n    super(scope, id, {\n      ...props,\n      codeDirectory: path.join(__dirname, '..', 'dist', 'aws-s3', 'auto-delete-objects-handler'),\n      runtimeName: determineLatestNodeRuntimeName(scope),\n    });\n    this.node.addMetadata('aws:cdk:is-custom-resource-handler-customResourceProvider', true);\n  }\n}", "language": "typescript"}
{"input": "This example will creates the detector model for Device HeartBeat Monitoring. @see https://docs.aws.amazon.com/iotevents/latest/developerguide/iotevents-examples-dhb.html", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const input = new iotevents.Input(this, 'MyInput', {\n      inputName: 'test_input',\n      attributeJsonPaths: ['payload.deviceId'],\n    });\n\n    const online = new iotevents.State({\n      stateName: 'Online',\n      onEnter: [{\n        eventName: 'enter-event',\n        condition: iotevents.Expression.currentInput(input),\n        actions: [\n          new actions.SetTimerAction('MyTimer', actions.TimerDuration.fromDuration(cdk.Duration.seconds(60))),\n        ],\n      }],\n      onInput: [{\n        eventName: 'input-event',\n        condition: iotevents.Expression.currentInput(input),\n        actions: [\n          new actions.ResetTimerAction('MyTimer'),\n        ],\n      }],\n      onExit: [{\n        eventName: 'exit-event',\n        actions: [\n          new actions.ClearTimerAction('MyTimer'),\n        ],\n      }],\n    });\n    const offline = new iotevents.State({ stateName: 'Offline' });\n\n    online.transitionTo(offline, { when: iotevents.Expression.timeout('MyTimer') });\n    offline.transitionTo(online, { when: iotevents.Expression.currentInput(input) });\n\n    new iotevents.DetectorModel(this, 'MyDetectorModel', {\n      detectorKey: 'payload.deviceId',\n      initialState: online,\n    });\n  }\n}", "language": "typescript"}
{"input": "Function to create Datasync S3 locations", "output": "def create_datasync_s3_locations(self, bucket_configs):\n        # Create the locations\n        i=0\n\n        s3_locations_dict = {}\n        for bc in bucket_configs:\n            role_name_export =\"CDKDataSyncS3Access-\" + bc[\"bucketName\"]\n            \n            location = datasync.CfnLocationS3(\n                self,\n                'DataSyncS3Location'+str(i),\n                s3_bucket_arn=bc[\"arn\"],\n                s3_config=datasync.CfnLocationS3.S3ConfigProperty(\n                    bucket_access_role_arn=Fn.import_value(role_name_export))\n                )\n                \n            # Add remaining configs if present\n            if \"subDirectory\" in bc:\n                location.subdirectory=bc[\"subDirectory\"]\n            if \"storageClass\" in bc:\n                location.s3_storage_class=bc[\"storageClass\"]\n\n            # TODO: Add tags support\n            #            if \"tags\" in bc and len(bc[\"tags\"]) > 0:\n            #                location.tags = bc[\"tags\"]\n            \n            # Add this location to the result dict\n            s3_locations_dict[bc[\"bucketName\"]] = location\n            i+=1\n        \n        return s3_locations_dict", "language": "python"}
{"input": "CDK class ReceiptFilter for AWS resource management", "output": "export class ReceiptFilter extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ses.ReceiptFilter';\n\n  constructor(scope: Construct, id: string, props: ReceiptFilterProps = {}) {\n    super(scope, id, {\n      physicalName: props.receiptFilterName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnReceiptFilter(this, 'Resource', {\n      filter: {\n        ipFilter: {\n          cidr: props.ip || '0.0.0.0/0',\n          policy: props.policy || ReceiptFilterPolicy.BLOCK,\n        },\n        name: this.physicalName,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Must use 'cdk-test' command", "output": "export class MustUseCDKTest extends ValidationRule {\n  public readonly name = 'package-info/scripts/test';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n    if (!hasTestDirectory(pkg)) { return; }\n\n    if (pkg.packageName !== '@aws-cdk/custom-resource-handlers') {\n      expectJSON(this.name, pkg, 'scripts.test', 'cdk-test');\n    }\n\n    // 'cdk-test' will calculate coverage, so have the appropriate\n    // files in .gitignore.\n    fileShouldContain(this.name, pkg, '.gitignore', '.nyc_output');\n    fileShouldContain(this.name, pkg, '.gitignore', 'coverage');\n    fileShouldContain(this.name, pkg, '.gitignore', 'nyc.config.js');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, SQS, CloudFormation resources", "output": "class MyStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const queue = new sqs.Queue(this, 'MyQueue');\n    const bucket = new s3.Bucket(this, 'MyBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    bucket.addEventNotification(\n      s3.EventType.OBJECT_CREATED_PUT,\n      new SqsDestination(queue),\n      {\n        prefix: 'foo/',\n        suffix: 'bar/',\n      },\n    );\n\n    // To test sorting in notification object is working properly,\n    // Make a deployment with following code commented out.\n    // Then uncomment the code and make a deployment again. The deployment should succeed.\n\n    // bucket.addEventNotification(\n    //   s3.EventType.OBJECT_CREATED_PUT,\n    //   new SqsDestination(queue),\n    //   {\n    //     prefix: 'fo1/',\n    //     suffix: 'ba2/',\n    //   },\n    // );\n  }\n}", "language": "typescript"}
{"input": "An additional HTTP parameter to send along with the OAuth request", "output": "class HttpParameter {\n  /**\n   * Make an OAuthParameter from a string value\n   *\n   * The value is not treated as a secret.\n   */\n  public static fromString(value: string): HttpParameter {\n    return new class extends HttpParameter {\n      public _render(name: string) {\n        return {\n          key: name,\n          value,\n          isValueSecret: false,\n        } as CfnConnection.ParameterProperty;\n      }\n    }();\n  }\n\n  /**\n   * Make an OAuthParameter from a secret\n   */\n  public static fromSecret(value: SecretValue): HttpParameter {\n    return new class extends HttpParameter {\n      public _render(name: string) {\n        return {\n          key: name,\n          value: value.unsafeUnwrap(), // Safe usage\n          isValueSecret: true,\n        } as CfnConnection.ParameterProperty;\n      }\n    }();\n  }\n\n  /**\n   * Render the paramter value\n   *\n   * @internal\n   */\n  public abstract _render(name: string): any;\n}", "language": "typescript"}
{"input": "Types of PII specific to the United Kingdom (UK).", "output": "export class UKSpecificPIIType extends PIIType {\n  /**\n   * A UK National Health Service Number is a 10-17 digit number, such as 485 777 3456.\n   */\n  public static readonly UK_NATIONAL_HEALTH_SERVICE_NUMBER = new UKSpecificPIIType('UK_NATIONAL_HEALTH_SERVICE_NUMBER');\n  /**\n   * A UK National Insurance Number (NINO) provides individuals with access to National\n   * Insurance (social security) benefits. It is also used for some purposes in the UK\n   * tax system.\n   */\n  public static readonly UK_NATIONAL_INSURANCE_NUMBER = new UKSpecificPIIType('UK_NATIONAL_INSURANCE_NUMBER');\n  /**\n   * A UK Unique Taxpayer Reference (UTR) is a 10-digit number that identifies a\n   * taxpayer or a business.\n   */\n  public static readonly UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER = new UKSpecificPIIType('UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER');\n\n  private constructor(value: string) { super(value); }\n}", "language": "typescript"}
{"input": "The IAM Policy that will be applied to the different calls.", "output": "export class AwsCustomResourcePolicy {\n  /**\n   * Use this constant to configure access to any resource.\n   */\n  public static readonly ANY_RESOURCE = ['*'];\n\n  /**\n   * Explicit IAM Policy Statements.\n   *\n   * @param statements the statements to propagate to the SDK calls.\n   */\n  public static fromStatements(statements: iam.PolicyStatement[]) {\n    return new AwsCustomResourcePolicy(statements, undefined);\n  }\n\n  /**\n   * Generate IAM Policy Statements from the configured SDK calls.\n   *\n   * Each SDK call with be translated to an IAM Policy Statement in the form of: `call.service:call.action` (e.g `s3:PutObject`).\n   *\n   * This policy generator assumes the IAM policy name has the same name as the API\n   * call. This is true in 99% of cases, but there are exceptions (for example,\n   * S3's `PutBucketLifecycleConfiguration` requires\n   * `s3:PutLifecycleConfiguration` permissions, Lambda's `Invoke` requires\n   * `lambda:InvokeFunction` permissions). Use `fromStatements` if you want to\n   * do a call that requires different IAM action names.\n   *\n   * @param options options for the policy generation\n   */\n  public static fromSdkCalls(options: SdkCallsPolicyOptions) {\n    return new AwsCustomResourcePolicy([], options.resources);\n  }\n\n  /**\n   * @param statements statements for explicit policy.\n   * @param resources resources for auto-generated from SDK calls.\n   */\n  private constructor(public readonly statements: iam.PolicyStatement[], public readonly resources?: string[]) { }\n}", "language": "typescript"}
{"input": "CDK class RestApiAccessLogFirehoseTest for AWS resource management", "output": "class RestApiAccessLogFirehoseTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const testFormat = apigateway.AccessLogFormat.custom(JSON.stringify({\n      requestId: apigateway.AccessLogField.contextRequestId(),\n      sourceIp: apigateway.AccessLogField.contextIdentitySourceIp(),\n      method: apigateway.AccessLogField.contextHttpMethod(),\n      callerAccountId: apigateway.AccessLogField.contextCallerAccountId(),\n      ownerAccountId: apigateway.AccessLogField.contextOwnerAccountId(),\n      userContext: {\n        sub: apigateway.AccessLogField.contextAuthorizerClaims('sub'),\n        email: apigateway.AccessLogField.contextAuthorizerClaims('email'),\n      },\n      clientCertPem: apigateway.AccessLogField.contextIdentityClientCertPem(),\n      subjectDN: apigateway.AccessLogField.contextIdentityClientCertSubjectDN(),\n      issunerDN: apigateway.AccessLogField.contextIdentityClientCertIssunerDN(),\n      serialNumber: apigateway.AccessLogField.contextIdentityClientCertSerialNumber(),\n      validityNotBefore: apigateway.AccessLogField.contextIdentityClientCertValidityNotBefore(),\n      validityNotAfter: apigateway.AccessLogField.contextIdentityClientCertValidityNotAfter(),\n    }));\n\n    const destinationBucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    const deliveryStreamRole = new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n    });\n\n    const stream = new firehose.CfnDeliveryStream(this, 'MyStream', {\n      deliveryStreamName: 'amazon-apigateway-delivery-stream',\n      s3DestinationConfiguration: {\n        bucketArn: destinationBucket.bucketArn,\n        roleArn: deliveryStreamRole.roleArn,\n      },\n    });\n\n    const api = new apigateway.RestApi(this, 'MyApi', {\n      cloudWatchRole: true,\n      deployOptions: {\n        accessLogDestination: new apigateway.FirehoseLogDestination(stream),\n        accessLogFormat: testFormat,\n      },\n    });\n    api.root.addMethod('GET');\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, DynamoDB operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # create dynamo table\n        demo_table = aws_dynamodb.Table(\n            self, \"demo_table\",\n            partition_key=aws_dynamodb.Attribute(\n                name=\"id\",\n                type=aws_dynamodb.AttributeType.STRING\n            )\n        )\n\n        # create producer lambda function\n        producer_lambda = aws_lambda.Function(self, \"producer_lambda_function\",\n                                              runtime=aws_lambda.Runtime.PYTHON_3_6,\n                                              handler=\"lambda_function.lambda_handler\",\n                                              code=aws_lambda.Code.from_asset(\"./lambda/producer\"))\n\n        producer_lambda.add_environment(\"TABLE_NAME\", demo_table.table_name)\n\n        # grant permission to lambda to write to demo table\n        demo_table.grant_write_data(producer_lambda)\n\n        # create consumer lambda function\n        consumer_lambda = aws_lambda.Function(self, \"consumer_lambda_function\",\n                                              runtime=aws_lambda.Runtime.PYTHON_3_6,\n                                              handler=\"lambda_function.lambda_handler\",\n                                              code=aws_lambda.Code.from_asset(\"./lambda/consumer\"))\n\n        consumer_lambda.add_environment(\"TABLE_NAME\", demo_table.table_name)\n\n        # grant permission to lambda to read from demo table\n        demo_table.grant_read_data(consumer_lambda)\n\n        # create a Cloudwatch Event rule\n        one_minute_rule = aws_events.Rule(\n            self, \"one_minute_rule\",\n            schedule=aws_events.Schedule.rate(Duration.minutes(1)),\n        )\n\n        # Add target to Cloudwatch Event\n        one_minute_rule.add_target(aws_events_targets.LambdaFunction(producer_lambda))\n        one_minute_rule.add_target(aws_events_targets.LambdaFunction(consumer_lambda))", "language": "python"}
{"input": "CDK class CnameRecord for AWS resource management", "output": "export class CnameRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.CnameRecord';\n\n  constructor(scope: Construct, id: string, props: CnameRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.CNAME,\n      target: RecordTarget.fromValues(props.domainName),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class LayerVersion for AWS resource management", "output": "export class LayerVersion extends LayerVersionBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-lambda.LayerVersion';\n\n  /**\n   * Imports a layer version by ARN. Assumes it is compatible with all Lambda runtimes.\n   */\n  public static fromLayerVersionArn(scope: Construct, id: string, layerVersionArn: string): ILayerVersion {\n    return LayerVersion.fromLayerVersionAttributes(scope, id, {\n      layerVersionArn,\n      compatibleRuntimes: Runtime.ALL,\n    });\n  }\n\n  /**\n   * Imports a Layer that has been defined externally.\n   *\n   * @param scope the parent Construct that will use the imported layer.\n   * @param id    the id of the imported layer in the construct tree.\n   * @param attrs the properties of the imported layer.\n   */\n  public static fromLayerVersionAttributes(scope: Construct, id: string, attrs: LayerVersionAttributes): ILayerVersion {\n    if (attrs.compatibleRuntimes && attrs.compatibleRuntimes.length === 0) {\n      throw new ValidationError('Attempted to import a Lambda layer that supports no runtime!', scope);\n    }\n\n    class Import extends LayerVersionBase {\n      public readonly layerVersionArn = attrs.layerVersionArn;\n      public readonly compatibleRuntimes = attrs.compatibleRuntimes;\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly layerVersionArn: string;\n  public readonly compatibleRuntimes?: Runtime[];\n\n  constructor(scope: Construct, id: string, props: LayerVersionProps) {\n    super(scope, id, {\n      physicalName: props.layerVersionName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.compatibleRuntimes && props.compatibleRuntimes.length === 0) {\n      throw new ValidationError('Attempted to define a Lambda layer that supports no runtime!', this);\n    }\n\n    // Allow usage of the code in this context...\n    const code = props.code.bind(this);\n    if (code.inlineCode) {\n      throw new ValidationError('Inline code is not supported for AWS Lambda layers', this);\n    }\n    if (!code.s3Location) {\n      throw new ValidationError('Code must define an S3 location', this);\n    }\n\n    const resource: CfnLayerVersion = new CfnLayerVersion(this, 'Resource', {\n      compatibleRuntimes: (props.compatibleRuntimes === Runtime.ALL)\n        ? undefined\n        : props.compatibleRuntimes?.map(r => r.name),\n      compatibleArchitectures: props.compatibleArchitectures?.map(a => a.name),\n      content: {\n        s3Bucket: code.s3Location.bucketName,\n        s3Key: code.s3Location.objectKey,\n        s3ObjectVersion: code.s3Location.objectVersion,\n      },\n      description: props.description,\n      layerName: this.physicalName,\n      licenseInfo: props.license,\n    });\n\n    if (props.removalPolicy) {\n      resource.applyRemovalPolicy(props.removalPolicy);\n    }\n\n    props.code.bindToResource(resource, {\n      resourceProperty: 'Content',\n    });\n\n    this.layerVersionArn = resource.ref;\n    this.compatibleRuntimes = props.compatibleRuntimes;\n  }\n}", "language": "typescript"}
{"input": "Self-Managed Kafka Stack with Schema Registry", "output": "export class SmkGlueSchemaRegistryStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Create a Lambda function\n    const testLambdaFunction = new TestFunction(this, 'GlueFunction');\n\n    // Create dummy certificates for authentication\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\n    MIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\n    cmUuiAii9R0=\n    -----END CERTIFICATE-----\n    -----BEGIN CERTIFICATE-----\n    MIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\n    c8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n    -----END CERTIFICATE-----\"\n    `;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\n    zp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n    -----END ENCRYPTED PRIVATE KEY-----`;\n\n    // Create secrets for Kafka authentication\n    const rootCASecret = new secretsmanager.Secret(this, 'GlueRootCASecret', {\n      secretObjectValue: {\n        certificate: SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'GlueClientCertSecret', {\n      secretObjectValue: {\n        certificate: SecretValue.unsafePlainText(dummyCertString),\n        privateKey: SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n\n    // Grant read permissions to the Lambda function\n    rootCASecret.grantRead(testLambdaFunction);\n    clientCertificatesSecret.grantRead(testLambdaFunction);\n\n    // Create a Glue Schema Registry\n    const glueRegistry = new CfnRegistry(this, 'SchemaRegistry', {\n      name: 'smk-glue-test-schema-registry',\n      description: 'Schema registry for SMK integration tests',\n    });\n\n    // Define Kafka bootstrap servers\n    const bootstrapServers = [\n      'kafka-broker-1:9092',\n      'kafka-broker-2:9092',\n      'kafka-broker-3:9092',\n    ];\n\n    // Common configuration for SMK event sources\n    const commonConfig = {\n      bootstrapServers,\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n    };\n\n    // SMK with Glue Schema Registry\n    testLambdaFunction.addEventSource(new SelfManagedKafkaEventSource({\n      ...commonConfig,\n      topic: 'test-topic-smk-glue',\n      consumerGroupId: 'test-consumer-group-smk-glue',\n      provisionedPollerConfig: {\n        minimumPollers: 1,\n        maximumPollers: 3,\n      },\n      schemaRegistryConfig: new GlueSchemaRegistry({\n        schemaRegistry: glueRegistry,\n        eventRecordFormat: lambda.EventRecordFormat.JSON,\n        schemaValidationConfigs: [{ attribute: lambda.KafkaSchemaValidationAttribute.KEY }],\n      }),\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, ECR operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n\n        image_name    = \"lambdaContainerFunction\"\n\n        ##\n        ## If use_pre_existing_image is True\n        ## then use an image that already exists in ECR.\n        ## Otherwise, build a new image\n        ##\n        use_pre_existing_image = False\n\n\n\n        ##\n        ## ECR\n        ##\n        if (use_pre_existing_image):\n\n            ##\n            ## Container was build previously, or elsewhere.\n            ## Use the pre-existing container\n            ##\n            ecr_repository = aws_ecr.Repository.from_repository_attributes(self,\n                id              = \"ECR\",\n                repository_arn  ='arn:aws:ecr:{0}:{1}:repository/{2}'.format(Aws.REGION, Aws.ACCOUNT_ID, image_name),\n                repository_name = image_name\n            ) ## aws_ecr.Repository.from_repository_attributes\n\n            ##\n            ## Container Image.\n            ## Pulled from the ECR repository.\n            ##\n            # ecr_image is expecting a `Code` type, so casting `EcrImageCode` to `Code` resolves mypy error\n            ecr_image = typing.cast(\"aws_lambda.Code\", aws_lambda.EcrImageCode(\n                repository = ecr_repository\n            )) ## aws_lambda.EcrImageCode\n\n        else:\n            ##\n            ## Create new Container Image.\n            ##\n            ecr_image = aws_lambda.EcrImageCode.from_asset_image(\n                directory = os.path.join(os.getcwd(), \"lambda-image\")\n            )\n\n\n\n\n        ##\n        ## Lambda Function\n        ##\n        aws_lambda.Function(self,\n          id            = \"lambdaContainerFunction\",\n          description   = \"Sample Lambda Container Function\",\n          code          = ecr_image,\n          ##\n          ## Handler and Runtime must be *FROM_IMAGE*\n          ## when provisioning Lambda from Container.\n          ##\n          handler       = aws_lambda.Handler.FROM_IMAGE,\n          runtime       = aws_lambda.Runtime.FROM_IMAGE,\n          environment   = {\"hello\":\"world\"},\n          function_name = \"sampleContainerFunction\",\n          memory_size   = 128,\n          reserved_concurrent_executions = 10,\n          timeout       = Duration.seconds(10),\n        ) ## aws_lambda.Function", "language": "python"}
{"input": "CDK class CustomJavaInjector for AWS resource management", "output": "class CustomJavaInjector extends appsignals.JavaInjector {\n  get containerPath(): string {\n    return '/otel-snapshot';\n  }\n}", "language": "typescript"}
{"input": "Model data represents the source of model artifacts, which will ultimately be loaded from an S3 location.", "output": "class ModelData {\n  /**\n   * Constructs model data which is already available within S3.\n   * @param bucket The S3 bucket within which the model artifacts are stored\n   * @param objectKey The S3 object key at which the model artifacts are stored\n   */\n  public static fromBucket(bucket: s3.IBucket, objectKey: string): ModelData {\n    return new S3ModelData(bucket, objectKey);\n  }\n\n  /**\n   * Constructs model data that will be uploaded to S3 as part of the CDK app deployment.\n   * @param path The local path to a model artifact file as a gzipped tar file\n   * @param options The options to further configure the selected asset\n   */\n  public static fromAsset(path: string, options: assets.AssetOptions = {}): ModelData {\n    return new AssetModelData(path, options);\n  }\n\n  /**\n   * This method is invoked by the SageMaker Model construct when it needs to resolve the model\n   * data to a URI.\n   * @param scope The scope within which the model data is resolved\n   * @param model The Model construct performing the URI resolution\n   */\n  public abstract bind(scope: Construct, model: IModel): ModelDataConfig;\n}", "language": "typescript"}
{"input": "Represents a helm chart within the Kubernetes system. Applies/deletes the resources using `kubectl` in sync with the resource.", "output": "export class HelmChart extends Construct {\n  /**\n   * The CloudFormation resource type.\n   */\n  public static readonly RESOURCE_TYPE = 'Custom::AWSCDK-EKS-HelmChart';\n  public readonly chart?: string;\n  public readonly repository?: string;\n  public readonly version?: string;\n  public readonly chartAsset?: Asset;\n  public readonly atomic?: boolean;\n\n  constructor(scope: Construct, id: string, props: HelmChartProps) {\n    super(scope, id);\n\n    // Exposing these properties is done for convenience\n    // For more details see issue #26678\n    this.chart = props.chart;\n    this.repository = props.repository;\n    this.version = props.version;\n    this.chartAsset = props.chartAsset;\n\n    const stack = Stack.of(this);\n\n    const provider = KubectlProvider.getKubectlProvider(this, props.cluster);\n    if (!provider) {\n      throw new Error('Kubectl Provider is not defined in this cluster. Define it when creating the cluster');\n    }\n\n    const timeout = props.timeout?.toSeconds();\n    if (timeout && timeout > 900) {\n      throw new Error('Helm chart timeout cannot be higher than 15 minutes.');\n    }\n\n    if (!this.chart && !this.chartAsset) {\n      throw new Error(\"Either 'chart' or 'chartAsset' must be specified to install a helm chart\");\n    }\n\n    if (this.chartAsset && (this.repository || this.version)) {\n      throw new Error(\n        \"Neither 'repository' nor 'version' can be used when configuring 'chartAsset'\",\n      );\n    }\n\n    // default not to wait\n    const wait = props.wait ?? false;\n    // default to create new namespace\n    const createNamespace = props.createNamespace ?? true;\n    // default to not skip crd installation\n    const skipCrds = props.skipCrds ?? false;\n    // default to set atomic as false\n    const atomic = props.atomic ?? false;\n\n    this.chartAsset?.grantRead(provider.role!);\n\n    new CustomResource(this, 'Resource', {\n      serviceToken: provider.serviceToken,\n      resourceType: HelmChart.RESOURCE_TYPE,\n      properties: {\n        ClusterName: props.cluster.clusterName,\n        Release: props.release ?? Names.uniqueId(this).slice(-53).toLowerCase(), // Helm has a 53 character limit for the name\n        Chart: this.chart,\n        ChartAssetURL: this.chartAsset?.s3ObjectUrl,\n        Version: this.version,\n        Wait: wait || undefined, // props are stringified so we encode \u201cfalse\u201d as undefined\n        Timeout: timeout ? `${timeout.toString()}s` : undefined, // Helm v3 expects duration instead of integer\n        Values: (props.values ? stack.toJsonString(props.values) : undefined),\n        Namespace: props.namespace ?? 'default',\n        Repository: this.repository,\n        CreateNamespace: createNamespace || undefined,\n        SkipCrds: skipCrds || undefined,\n        Atomic: atomic || undefined, // props are stringified so we encode \u201cfalse\u201d as undefined\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Identity providers supported by the UserPoolClient", "output": "export class UserPoolClientIdentityProvider {\n  /**\n   * Allow users to sign in using 'Sign In With Apple'.\n   * A `UserPoolIdentityProviderApple` must be attached to the user pool.\n   */\n  public static readonly APPLE = new UserPoolClientIdentityProvider('SignInWithApple');\n\n  /**\n   * Allow users to sign in using 'Facebook Login'.\n   * A `UserPoolIdentityProviderFacebook` must be attached to the user pool.\n   */\n  public static readonly FACEBOOK = new UserPoolClientIdentityProvider('Facebook');\n\n  /**\n   * Allow users to sign in using 'Google Login'.\n   * A `UserPoolIdentityProviderGoogle` must be attached to the user pool.\n   */\n  public static readonly GOOGLE = new UserPoolClientIdentityProvider('Google');\n\n  /**\n   * Allow users to sign in using 'Login With Amazon'.\n   * A `UserPoolIdentityProviderAmazon` must be attached to the user pool.\n   */\n  public static readonly AMAZON = new UserPoolClientIdentityProvider('LoginWithAmazon');\n\n  /**\n   * Allow users to sign in directly as a user of the User Pool\n   */\n  public static readonly COGNITO = new UserPoolClientIdentityProvider('COGNITO');\n\n  /**\n   * Specify a provider not yet supported by the CDK.\n   * @param name name of the identity provider as recognized by CloudFormation property `SupportedIdentityProviders`\n   */\n  public static custom(name: string) {\n    return new UserPoolClientIdentityProvider(name);\n  }\n\n  /** The name of the identity provider as recognized by CloudFormation property `SupportedIdentityProviders` */\n  public readonly name: string;\n\n  private constructor(name: string) {\n    this.name = name;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for IAM operations", "output": "export const deployIntegTests = async (props: {\n  atmosphereRoleArn: string;\n  endpoint: string;\n  pool: string;\n  batchSize?: number;\n}) => {\n  const batchSize = props.batchSize ?? 3;\n\n  const changedSnapshots = await getChangedSnapshots();\n\n  if (changedSnapshots.length === 0) {\n    throw new Error('No snapshots changed, skipping deployment integ test.');\n  }\n\n  let hasFailure = false;\n\n  for (let i = 0; i < changedSnapshots.length; i += batchSize) {\n    const batch = changedSnapshots.slice(i, i + batchSize);\n    const creds = await assumeAtmosphereRole(props.atmosphereRoleArn);\n    const allocation = await AtmosphereAllocation.acquire({\n      endpoint: props.endpoint,\n      pool: props.pool,\n      creds: {\n        accessKeyId: creds.AccessKeyId!,\n        secretAccessKey: creds.SecretAccessKey!,\n        sessionToken: creds.SessionToken!,\n      },\n    });\n    let outcome = 'failure';\n\n    try {\n      const env = {\n        PATH: process.env.PATH, // Allows the spawn process to find the yarn binary.\n        AWS_ACCESS_KEY_ID: allocation.allocation.credentials.accessKeyId,\n        AWS_SECRET_ACCESS_KEY: allocation.allocation.credentials.secretAccessKey,\n        AWS_SESSION_TOKEN: allocation.allocation.credentials.sessionToken,\n        AWS_REGION: allocation.allocation.environment.region,\n        AWS_ACCOUNT_ID: allocation.allocation.environment.account,\n        TARGET_BRANCH_COMMIT: process.env.TARGET_BRANCH_COMMIT,\n        SOURCE_BRANCH_COMMIT: process.env.SOURCE_BRANCH_COMMIT,\n      };\n\n      await bootstrap(env);\n      await deployIntegrationTest(env, batch);\n      outcome = 'success';\n    } catch (e) {\n      console.error(e);\n      hasFailure = true;\n    } finally {\n      try {\n        await allocation.release(outcome);\n      } catch (e) {\n        if (e instanceof Error && e.message.includes('The security token included in the request is expired')) {\n          // In case of timeouts, the expired security token error can occur. We can skip the release as it will automatically be deleted.\n          // Atmosphere will automatically release the resource if a timeout occurs on the backend.\n          //\n          // Log uses Github warning syntax, see: https://docs.github.com/en/actions/reference/workflows-and-actions/workflow-commands#setting-a-warning-message\n          console.warn(`::warning::Atmosphere allocation release failed: ${e}`);\n          console.warn('Skipping release request as we assume its caused by an integ test timing out.');\n        } else {\n          throw e;\n        }\n      }\n    }\n  }\n\n  if (hasFailure) {\n    throw Error('Deployment integration test did not pass');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation resources", "output": "class S3TriggerStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # create lambda function\n        function = _lambda.Function(self, \"lambda_function\",\n                                    runtime=_lambda.Runtime.PYTHON_3_7,\n                                    handler=\"lambda-handler.main\",\n                                    code=_lambda.Code.from_asset(\"./lambda\"))\n        # create s3 bucket\n        s3 = _s3.Bucket(self, \"s3bucket\")\n\n        # create s3 notification for lambda function\n        notification = aws_s3_notifications.LambdaDestination(function)\n\n        # assign notification for the s3 event type (ex: OBJECT_CREATED)\n        s3.add_event_notification(_s3.EventType.OBJECT_CREATED, notification)", "language": "python"}
{"input": "CDK Stack that creates S3, WAF, CloudFormation resources", "output": "class SourceBucketStack extends cdk.Stack {\n  public readonly bucket: s3.IBucket;\n  constructor(scope: Construct, id: string, props: SourceBucketStackProps) {\n    super(scope, id, props);\n    this.bucket = new s3.Bucket(this, 'SourceBucket', {\n      versioned: true,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      bucketName: cdk.PhysicalName.GENERATE_IF_NEEDED,\n      encryption: s3.BucketEncryption.S3_MANAGED,\n      replicationRules: [\n        {\n          destination: props.bucket,\n          priority: 1,\n          replicationTimeControl: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          metrics: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          storageClass: s3.StorageClass.INFREQUENT_ACCESS,\n          replicaModifications: true,\n          deleteMarkerReplication: true,\n          id: 'full-settings-rule',\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "Test for Lambdas created:\n    - Sample Lambda\n    - Bucket Notification Handler (automatically provisioned)\n    - Log Retention (automatically provisioned)", "output": "def test_lambdas_created(template):\n    \"\"\"\n    Test for Lambdas created:\n        - Sample Lambda\n        - Bucket Notification Handler (automatically provisioned)\n        - Log Retention (automatically provisioned)\n    \"\"\"\n    template.resource_count_is(\"AWS::Lambda::Function\", 3)\n    template.resource_count_is(\"AWS::Lambda::EventSourceMapping\", 1)", "language": "python"}
{"input": "CDK class SrvRecord for AWS resource management", "output": "export class SrvRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.SrvRecord';\n\n  constructor(scope: Construct, id: string, props: SrvRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.SRV,\n      target: RecordTarget.fromValues(...props.values.map(v => `${v.priority} ${v.weight} ${v.port} ${v.hostName}`)),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ContainerDefinition for AWS resource management", "output": "export class ContainerDefinition extends Construct {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs.ContainerDefinition';\n\n  public static readonly CONTAINER_PORT_USE_RANGE = 0;\n\n  /**\n   * The Linux-specific modifications that are applied to the container, such as Linux kernel capabilities.\n   */\n  public readonly linuxParameters?: LinuxParameters;\n\n  /**\n   * The mount points for data volumes in your container.\n   */\n  public readonly mountPoints = new Array<MountPoint>();\n\n  /**\n   * The list of port mappings for the container. Port mappings allow containers to access ports\n   * on the host container instance to send or receive traffic.\n   */\n  public readonly portMappings = new Array<PortMapping>();\n\n  /**\n   * The data volumes to mount from another container in the same task definition.\n   */\n  public readonly volumesFrom = new Array<VolumeFrom>();\n\n  /**\n   * An array of ulimits to set in the container.\n   */\n  public readonly ulimits = new Array<Ulimit>();\n\n  /**\n   * An array dependencies defined for container startup and shutdown.\n   */\n  public readonly containerDependencies = new Array<ContainerDependency>();\n\n  /**\n   * Specifies whether the container will be marked essential.\n   *\n   * If the essential parameter of a container is marked as true, and that container\n   * fails or stops for any reason, all other containers that are part of the task are\n   * stopped. If the essential parameter of a container is marked as false, then its\n   * failure does not affect the rest of the containers in a task.\n   *\n   * If this parameter is omitted, a container is assumed to be essential.\n   */\n  public readonly essential: boolean;\n\n  /**\n   * The name of this container\n   */\n  public readonly containerName: string;\n\n  /**\n   * Whether there was at least one memory limit specified in this definition\n   */\n  public readonly memoryLimitSpecified: boolean;\n\n  /**\n   * The name of the task definition that includes this container definition.\n   */\n  public readonly taskDefinition: TaskDefinition;\n\n  /**\n   * The environment files for this container\n   */\n  public readonly environmentFiles?: EnvironmentFileConfig[];\n\n  /**\n   * The log configuration specification for the container.\n   */\n  public readonly logDriverConfig?: LogDriverConfig;\n\n  /**\n   * The crdential specifications for this container.\n   */\n  public readonly credentialSpecs?: CredentialSpecConfig[];\n\n  /**\n   * The name of the image referenced by this container.\n   */\n  public readonly imageName: string;\n\n  /**\n   * The number of cpu units reserved for the container.\n   */\n  public readonly cpu?: number;\n\n  /**\n   * The inference accelerators referenced by this container.\n   */\n  private readonly inferenceAcceleratorResources: string[] = [];\n\n  /**\n   * Specifies whether a TTY must be allocated for this container.\n   */\n  public readonly pseudoTerminal?: boolean;\n\n  /**\n   * The configured container links\n   */\n  private readonly links = new Array<string>();\n\n  private readonly imageConfig: ContainerImageConfig;\n\n  private readonly secrets: CfnTaskDefinition.SecretProperty[] = [];\n\n  private readonly dockerLabels: { [key: string]: string };\n\n  private readonly environment: { [key: string]: string };\n\n  private _namedPorts: Map<string, PortMapping>;\n\n  private versionConsistency?: VersionConsistency;\n\n  /**\n   * Constructs a new instance of the ContainerDefinition class.\n   */\n  constructor(scope: Construct, id: string, private readonly props: ContainerDefinitionProps) {\n    super(scope, id);\n    if (props.memoryLimitMiB !== undefined && props.memoryReservationMiB !== undefined) {\n      if (props.memoryLimitMiB < props.memoryReservationMiB) {\n        throw new ValidationError('MemoryLimitMiB should not be less than MemoryReservationMiB.', this);\n      }\n    }\n    this.essential = props.essential ?? true;\n    this.taskDefinition = props.taskDefinition;\n    this.memoryLimitSpecified = props.memoryLimitMiB !== undefined || props.memoryReservationMiB !== undefined;\n    this.linuxParameters = props.linuxParameters;\n    this.containerName = props.containerName ?? this.node.id;\n\n    this.imageConfig = props.image.bind(this, this);\n    this.imageName = this.imageConfig.imageName;\n\n    this._namedPorts = new Map<string, PortMapping>();\n\n    this.versionConsistency = props.versionConsistency;\n\n    if (props.logging) {\n      this.logDriverConfig = props.logging.bind(this, this);\n    }\n\n    if (props.secrets) {\n      for (const [name, secret] of Object.entries(props.secrets)) {\n        this.addSecret(name, secret);\n      }\n    }\n\n    this.dockerLabels = { ...props.dockerLabels };\n\n    if (props.environment) {\n      this.environment = { ...props.environment };\n    } else {\n      this.environment = {};\n    }\n\n    if (props.environmentFiles) {\n      this.environmentFiles = [];\n\n      for (const environmentFile of props.environmentFiles) {\n        this.environmentFiles.push(environmentFile.bind(this));\n      }\n    }\n\n    if (props.credentialSpecs) {\n      this.credentialSpecs = [];\n\n      if (props.credentialSpecs.length > 1) {\n        throw new ValidationError('Only one credential spec is allowed per container definition.', this);\n      }\n\n      for (const credSpec of props.credentialSpecs) {\n        this.credentialSpecs.push(credSpec.bind());\n      }\n    }\n\n    if (props.cpu) {\n      this.cpu = props.cpu;\n    }\n\n    props.taskDefinition._linkContainer(this);\n\n    if (props.portMappings) {\n      this.addPortMappings(...props.portMappings);\n    }\n\n    if (props.inferenceAcceleratorResources) {\n      this.addInferenceAcceleratorResource(...props.inferenceAcceleratorResources);\n    }\n\n    this.pseudoTerminal = props.pseudoTerminal;\n\n    if (props.ulimits) {\n      this.addUlimits(...props.ulimits);\n    }\n\n    this.validateRestartPolicy(props.enableRestartPolicy, props.restartIgnoredExitCodes, props.restartAttemptPeriod);\n  }\n\n  /**\n   * This method adds a link which allows containers to communicate with each other without the need for port mappings.\n   *\n   * This parameter is only supported if the task definition is using the bridge network mode.\n   * Warning: The --link flag is a legacy feature of Docker. It may eventually be removed.\n   */\n  public addLink(container: ContainerDefinition, alias?: string) {\n    if (this.taskDefinition.networkMode !== NetworkMode.BRIDGE) {\n      throw new ValidationError('You must use network mode Bridge to add container links.', this);\n    }\n    if (alias !== undefined) {\n      this.links.push(`${container.containerName}:${alias}`);\n    } else {\n      this.links.push(`${container.containerName}`);\n    }\n  }\n\n  /**\n   * This method adds one or more mount points for data volumes to the container.\n   */\n  public addMountPoints(...mountPoints: MountPoint[]) {\n    this.mountPoints.push(...mountPoints);\n  }\n\n  /**\n   * This method mounts temporary disk space to the container.\n   *\n   * This adds the correct container mountPoint and task definition volume.\n   */\n  public addScratch(scratch: ScratchSpace) {\n    const mountPoint = {\n      containerPath: scratch.containerPath,\n      readOnly: scratch.readOnly,\n      sourceVolume: scratch.name,\n    };\n\n    const volume = {\n      host: {\n        sourcePath: scratch.sourcePath,\n      },\n      name: scratch.name,\n    };\n\n    this.taskDefinition.addVolume(volume);\n    this.addMountPoints(mountPoint);\n  }\n\n  /**\n   * This method adds one or more port mappings to the container.\n   */\n  public addPortMappings(...portMappings: PortMapping[]) {\n    this.portMappings.push(...portMappings.map(pm => {\n      const portMap = new PortMap(this.taskDefinition.networkMode, pm);\n      portMap.validate();\n      const serviceConnect = new ServiceConnect(this.taskDefinition.networkMode, pm);\n      if (serviceConnect.isServiceConnect()) {\n        serviceConnect.validate();\n        this.setNamedPort(pm);\n      }\n      const sanitizedPM = this.addHostPortIfNeeded(pm);\n      return sanitizedPM;\n    }));\n  }\n\n  /**\n   * This method adds an environment variable to the container.\n   */\n  public addEnvironment(name: string, value: string) {\n    this.environment[name] = value;\n  }\n\n  /**\n   * This method adds a Docker label to the container.\n   */\n  public addDockerLabel(name: string, value: string) {\n    this.dockerLabels[name] = value;\n  }\n\n  /**\n   * This method adds a secret as environment variable to the container.\n   */\n  public addSecret(name: string, secret: Secret) {\n    secret.grantRead(this.taskDefinition.obtainExecutionRole());\n\n    this.secrets.push({\n      name,\n      valueFrom: secret.arn,\n    });\n  }\n\n  /**\n   * This method adds one or more resources to the container.\n   */\n  public addInferenceAcceleratorResource(...inferenceAcceleratorResources: string[]) {\n    this.inferenceAcceleratorResources.push(...inferenceAcceleratorResources.map(resource => {\n      for (const inferenceAccelerator of this.taskDefinition.inferenceAccelerators) {\n        if (resource === inferenceAccelerator.deviceName) {\n          return resource;\n        }\n      }\n      throw new ValidationError(`Resource value ${resource} in container definition doesn't match any inference accelerator device name in the task definition.`, this);\n    }));\n  }\n\n  /**\n   * This method adds one or more ulimits to the container.\n   */\n  public addUlimits(...ulimits: Ulimit[]) {\n    this.ulimits.push(...ulimits);\n  }\n\n  /**\n   * This method adds one or more container dependencies to the container.\n   */\n  public addContainerDependencies(...containerDependencies: ContainerDependency[]) {\n    this.containerDependencies.push(...containerDependencies);\n  }\n\n  /**\n   * This method adds one or more volumes to the container.\n   */\n  public addVolumesFrom(...volumesFrom: VolumeFrom[]) {\n    this.volumesFrom.push(...volumesFrom);\n  }\n\n  /**\n   * This method adds the specified statement to the IAM task execution policy in the task definition.\n   */\n  public addToExecutionPolicy(statement: iam.PolicyStatement) {\n    this.taskDefinition.addToExecutionRolePolicy(statement);\n  }\n\n  /**\n   * Returns the host port for the requested container port if it exists\n   */\n  public findPortMapping(containerPort: number, protocol: Protocol): PortMapping | undefined {\n    for (const portMapping of this.portMappings) {\n      const p = portMapping.protocol || Protocol.TCP;\n      const c = portMapping.containerPort;\n      if (c === containerPort && p === protocol) {\n        return portMapping;\n      }\n    }\n    return undefined;\n  }\n\n  /**\n   * Returns the port mapping with the given name, if it exists.\n   */\n  public findPortMappingByName(name: string): PortMapping | undefined {\n    return this._namedPorts.get(name);\n  }\n\n  /**\n   * This method adds an namedPort\n   */\n  private setNamedPort(pm: PortMapping) :void {\n    if (!pm.name) return;\n    if (this._namedPorts.has(pm.name)) {\n      throw new ValidationError(`Port mapping name '${pm.name}' already exists on this container`, this);\n    }\n    this._namedPorts.set(pm.name, pm);\n  }\n\n  /**\n   * This method sets the host port to 0 if the network mode is Bridge and neither\n   * the host port nor the container port range is already set.\n   */\n  private addHostPortIfNeeded(pm: PortMapping) :PortMapping {\n    if (this.taskDefinition.networkMode !== NetworkMode.BRIDGE || pm.hostPort !== undefined || pm.containerPortRange !== undefined) {\n      return pm;\n    }\n\n    return {\n      ...pm,\n      hostPort: 0,\n    };\n  }\n\n  private validateRestartPolicy(enableRestartPolicy?: boolean, restartIgnoredExitCodes?: number[], restartAttemptPeriod?: cdk.Duration) {\n    if (enableRestartPolicy === false && (restartIgnoredExitCodes !== undefined || restartAttemptPeriod !== undefined)) {\n      throw new ValidationError('The restartIgnoredExitCodes and restartAttemptPeriod cannot be specified if enableRestartPolicy is false', this);\n    }\n    if (restartIgnoredExitCodes && restartIgnoredExitCodes.length > 50) {\n      throw new ValidationError(`Only up to 50 can be specified for restartIgnoredExitCodes, got: ${restartIgnoredExitCodes.length}`, this);\n    }\n    if (restartAttemptPeriod && (restartAttemptPeriod.toSeconds() < 60 || restartAttemptPeriod.toSeconds() > 1800)) {\n      throw new ValidationError(`The restartAttemptPeriod must be between 60 seconds and 1800 seconds, got ${restartAttemptPeriod.toSeconds()} seconds`, this);\n    }\n  }\n\n  /**\n   * Whether this container definition references a specific JSON field of a secret\n   * stored in Secrets Manager.\n   */\n  public get referencesSecretJsonField(): boolean | undefined {\n    for (const secret of this.secrets) {\n      if (secret.valueFrom.endsWith('::')) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * The inbound rules associated with the security group the task or service will use.\n   *\n   * This property is only used for tasks that use the awsvpc network mode.\n   */\n  public get ingressPort(): number {\n    if (this.portMappings.length === 0) {\n      throw new ValidationError(`Container ${this.containerName} hasn't defined any ports. Call addPortMappings().`, this);\n    }\n    const defaultPortMapping = this.portMappings[0];\n\n    if (defaultPortMapping.hostPort !== undefined && defaultPortMapping.hostPort !== 0) {\n      return defaultPortMapping.hostPort;\n    }\n\n    if (this.taskDefinition.networkMode === NetworkMode.BRIDGE) {\n      return 0;\n    }\n\n    if (defaultPortMapping.containerPortRange !== undefined) {\n      throw new ValidationError(`The first port mapping of the container ${this.containerName} must expose a single port.`, this);\n    }\n\n    return defaultPortMapping.containerPort;\n  }\n\n  /**\n   * The port the container will listen on.\n   */\n  public get containerPort(): number {\n    if (this.portMappings.length === 0) {\n      throw new ValidationError(`Container ${this.containerName} hasn't defined any ports. Call addPortMappings().`, this);\n    }\n    const defaultPortMapping = this.portMappings[0];\n\n    if (defaultPortMapping.containerPortRange !== undefined) {\n      throw new ValidationError(`The first port mapping of the container ${this.containerName} must expose a single port.`, this);\n    }\n\n    return defaultPortMapping.containerPort;\n  }\n\n  /**\n   * Allows disabling version consistency if the user did not specify a value.\n   *\n   * Intended for CDK asset images, as asset images are tagged based upon a hash\n   * of image inputs, meaning the image won't change if the tag didn't change,\n   * making version consistency for such containers a waste of time. Literally,\n   * as version consistency can only be achieved by slowing down deployments.\n   *\n   * @see https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-type-ecs.html#deployment-container-image-stability\n   * @internal\n   */\n  public _defaultDisableVersionConsistency() {\n    if (!this.versionConsistency) {\n      this.versionConsistency = VersionConsistency.DISABLED;\n    }\n  }\n\n  /**\n   * Render this container definition to a CloudFormation object\n   *\n   * @param _taskDefinition [disable-awslint:ref-via-interface] (unused but kept to avoid breaking change)\n   */\n  public renderContainerDefinition(_taskDefinition?: TaskDefinition): CfnTaskDefinition.ContainerDefinitionProperty {\n    return {\n      command: this.props.command,\n      credentialSpecs: this.credentialSpecs && this.credentialSpecs.map(renderCredentialSpec),\n      cpu: this.props.cpu,\n      disableNetworking: this.props.disableNetworking,\n      dependsOn: cdk.Lazy.any({ produce: () => this.containerDependencies.map(renderContainerDependency) }, { omitEmptyArray: true }),\n      dnsSearchDomains: this.props.dnsSearchDomains,\n      dnsServers: this.props.dnsServers,\n      dockerLabels: Object.keys(this.dockerLabels).length ? this.dockerLabels : undefined,\n      dockerSecurityOptions: this.props.dockerSecurityOptions,\n      entryPoint: this.props.entryPoint,\n      essential: this.essential,\n      hostname: this.props.hostname,\n      image: this.imageConfig.imageName,\n      interactive: this.props.interactive,\n      memory: this.props.memoryLimitMiB,\n      memoryReservation: this.props.memoryReservationMiB,\n      mountPoints: cdk.Lazy.any({ produce: () => this.mountPoints.map(renderMountPoint) }, { omitEmptyArray: true }),\n      name: this.containerName,\n      portMappings: cdk.Lazy.any({ produce: () => this.portMappings.map(renderPortMapping) }, { omitEmptyArray: true }),\n      privileged: this.props.privileged,\n      pseudoTerminal: this.props.pseudoTerminal,\n      readonlyRootFilesystem: this.props.readonlyRootFilesystem,\n      repositoryCredentials: this.imageConfig.repositoryCredentials,\n      startTimeout: this.props.startTimeout && this.props.startTimeout.toSeconds(),\n      stopTimeout: this.props.stopTimeout && this.props.stopTimeout.toSeconds(),\n      ulimits: cdk.Lazy.any({ produce: () => this.ulimits.map(renderUlimit) }, { omitEmptyArray: true }),\n      user: this.props.user,\n      versionConsistency: this.versionConsistency,\n      volumesFrom: cdk.Lazy.any({ produce: () => this.volumesFrom.map(renderVolumeFrom) }, { omitEmptyArray: true }),\n      workingDirectory: this.props.workingDirectory,\n      logConfiguration: this.logDriverConfig,\n      environment: this.environment && Object.keys(this.environment).length ? renderKV(this.environment, 'name', 'value') : undefined,\n      environmentFiles: this.environmentFiles && renderEnvironmentFiles(cdk.Stack.of(this).partition, this.environmentFiles),\n      secrets: this.secrets.length ? this.secrets : undefined,\n      extraHosts: this.props.extraHosts && renderKV(this.props.extraHosts, 'hostname', 'ipAddress'),\n      healthCheck: this.props.healthCheck && renderHealthCheck(this, this.props.healthCheck),\n      links: cdk.Lazy.list({ produce: () => this.links }, { omitEmpty: true }),\n      linuxParameters: this.linuxParameters && this.linuxParameters.renderLinuxParameters(),\n      resourceRequirements: (!this.props.gpuCount && this.inferenceAcceleratorResources.length == 0 ) ? undefined :\n        renderResourceRequirements(this.props.gpuCount, this.inferenceAcceleratorResources),\n      systemControls: this.props.systemControls && renderSystemControls(this.props.systemControls),\n      restartPolicy: renderRestartPolicy(this.props.enableRestartPolicy, this.props.restartIgnoredExitCodes, this.props.restartAttemptPeriod),\n    };\n  }\n}", "language": "typescript"}
{"input": "Passing L2 Bucket to L1 Events.Rule with object created/deleted pattern", "output": "class L2BucketOtherEventsWithL2Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l2Bucket = new s3.Bucket(this, 'bucketL2', { eventBridgeEnabled: true });\n    const l2BucketWithEvent = BucketEvents.fromBucket(l2Bucket);\n\n    const fn = new Function(this, 'MyFuncA', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n\n    const trail = new Trail(this, 'Trail', {});\n    trail.addS3EventSelector([{ bucket: l2Bucket }], { readWriteType: ReadWriteType.ALL });\n    const l2Rule = new Rule(this, 'L2RuleForL1', {\n      targets: [new LambdaFunction(fn)],\n    });\n\n    l2Rule.addEventPattern(l2BucketWithEvent.objectCreatedPattern({ reason: ['PutObject'] }));\n    l2Rule.addEventPattern(l2BucketWithEvent.objectDeletedPattern({ reason: ['DeleteObject'] }));\n  }\n}", "language": "typescript"}
{"input": "CDK class MixinsLogsDelivery for AWS resource management", "output": "class MixinsLogsDelivery extends ExternalModule {\n  public readonly S3LogsDelivery = Type.fromName(this, 'S3LogsDelivery');\n  public readonly LogGroupLogsDelivery = Type.fromName(this, 'LogGroupLogsDelivery');\n  public readonly FirehoseLogsDelivery = Type.fromName(this, 'FirehoseLogsDelivery');\n  public readonly XRayLogsDelivery = Type.fromName(this, 'XRayLogsDelivery');\n  public readonly ILogsDelivery = Type.fromName(this, 'ILogsDelivery');\n  public readonly S3LogsDeliveryPermissionsVersion = $T(Type.fromName(this, 'S3LogsDeliveryPermissionsVersion'));\n}", "language": "typescript"}
{"input": "CDK class IncludeJsiiInNpmTarball for AWS resource management", "output": "export class IncludeJsiiInNpmTarball extends ValidationRule {\n  public readonly name = 'npmignore/jsii-included';\n\n  public validate(pkg: PackageJson): void {\n    // only jsii modules\n    if (!isJSII(pkg)) { return; }\n\n    // skip private packages\n    if (pkg.json.private) { return; }\n\n    fileShouldNotContain(this.name, pkg, '.npmignore', '.jsii');\n    fileShouldContain(this.name, pkg, '.npmignore', '!.jsii'); // make sure .jsii is included\n  }\n}", "language": "typescript"}
{"input": "CDK class DeploymentGroupBase for AWS resource management", "output": "export class DeploymentGroupBase extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codedeploy.DeploymentGroupBase';\n  /**\n   * The name of the Deployment Group.\n   */\n  public readonly deploymentGroupName!: string;\n\n  /**\n   * The ARN of the Deployment Group.\n   */\n  public readonly deploymentGroupArn!: string;\n\n  /**\n   * A reference to a DeploymentGroup resource.\n   */\n  public get deploymentGroupRef(): DeploymentGroupReference {\n    return {\n      deploymentGroupName: this.deploymentGroupName,\n    };\n  }\n\n  /**\n   * The service Role of this Deployment Group.\n   *\n   * (Can't make `role` properly public here, as it's typed as optional in one\n   * interface and typing it here as definitely set interferes with that.)\n   *\n   * @internal\n   */\n  public readonly _role: iam.IRole;\n\n  constructor(scope: Construct, id: string, props: DeploymentGroupBaseProps) {\n    super(scope, id, {\n      physicalName: props.deploymentGroupName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this._role = props.role || new iam.Role(this, props.roleConstructId, {\n      assumedBy: new iam.ServicePrincipal('codedeploy.amazonaws.com'),\n    });\n\n    this.node.addValidation({ validate: () => validateName('Deployment group', this.physicalName) });\n  }\n\n  /**\n   * Bind DeploymentGroupConfig to the current group, if supported\n   *\n   * @internal\n   */\n  protected _bindDeploymentConfig(config: IDeploymentConfigRef): IDeploymentConfigRef {\n    return isIBindableDeploymentConfig(config) ? config.bindEnvironment(this) : config;\n  }\n\n  /**\n   * Set name and ARN properties.\n   *\n   * Must be called in the child constructor.\n   *\n   * @internal\n   */\n  protected _setNameAndArn(resource: CfnDeploymentGroup, application: IApplicationRef) {\n    (this as any).deploymentGroupName = this.getResourceNameAttribute(resource.ref);\n    (this as any).deploymentGroupArn = this.getResourceArnAttribute(this.stack.formatArn({\n      service: 'codedeploy',\n      resource: 'deploymentgroup',\n      resourceName: `${application.applicationRef.applicationName}/${resource.ref}`,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    }), {\n      service: 'codedeploy',\n      resource: 'deploymentgroup',\n      resourceName: `${application.applicationRef.applicationName}/${this.physicalName}`,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n  }\n}", "language": "typescript"}
{"input": "Represents the currently available API Key Selection Expressions", "output": "export class WebSocketApiKeySelectionExpression {\n  /**\n   * The API will extract the key value from the `x-api-key` header in the user request.\n   */\n  public static readonly HEADER_X_API_KEY = new WebSocketApiKeySelectionExpression('$request.header.x-api-key');\n\n  /**\n   * The API will extract the key value from the `usageIdentifierKey` attribute in the `context` map,\n   * returned by the Lambda Authorizer.\n   * See https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-lambda-authorizer-output.html\n   */\n  public static readonly AUTHORIZER_USAGE_IDENTIFIER_KEY = new WebSocketApiKeySelectionExpression('$context.authorizer.usageIdentifierKey');\n\n  /**\n   * @param customApiKeySelector The expression used by API Gateway\n   */\n  public constructor(public readonly customApiKeySelector: string) {}\n}", "language": "typescript"}
{"input": "Code configuration providing the location to a Flink application JAR file.", "output": "class ApplicationCode {\n  /**\n   * Reference code from an S3 bucket.\n   *\n   * @param bucket - an s3 bucket\n   * @param fileKey - a key pointing to a Flink JAR file\n   * @param objectVersion - an optional version string for the provided fileKey\n   */\n  public static fromBucket(bucket: s3.IBucket, fileKey: string, objectVersion?: string): ApplicationCode {\n    return new BucketApplicationCode({\n      bucket,\n      fileKey,\n      objectVersion,\n    });\n  }\n\n  /**\n   * Reference code from a local directory containing a Flink JAR file.\n   *\n   * @param path - a local directory path\n   * @parm options - standard s3 AssetOptions\n   */\n  public static fromAsset(path: string, options?: s3_assets.AssetOptions): ApplicationCode {\n    return new AssetApplicationCode(path, options);\n  }\n\n  /**\n   * A method to lazily bind asset resources to the parent FlinkApplication.\n   */\n  public abstract bind(scope: Construct): ApplicationCodeConfig;\n}", "language": "typescript"}
{"input": "CDK class OsCommand for AWS resource management", "output": "class OsCommand {\n  constructor(private readonly osPlatform: NodeJS.Platform) {}\n\n  public write(filePath: string, data: string): string {\n    if (this.osPlatform === 'win32') {\n      if (!data) { // if `data` is empty, echo a blank line, otherwise the file will contain a `^` character\n        return `echo. > \"${filePath}\"`;\n      }\n      return `echo ^${data}^ > \"${filePath}\"`;\n    }\n\n    return `echo '${data}' > \"${filePath}\"`;\n  }\n\n  public writeJson(filePath: string, data: any): string {\n    const stringifiedData = JSON.stringify(data);\n    return this.write(filePath, stringifiedData);\n  }\n\n  public copy(src: string, dest: string): string {\n    if (this.osPlatform === 'win32') {\n      return `copy \"${src}\" \"${dest}\"`;\n    }\n\n    return `cp \"${src}\" \"${dest}\"`;\n  }\n\n  public changeDirectory(dir: string): string {\n    return `cd \"${dir}\"`;\n  }\n\n  public remove(filePath: string, force: boolean = false): string {\n    if (this.osPlatform === 'win32') {\n      return `del \"${filePath}\"`;\n    }\n\n    const opts = force ? ['-f'] : [];\n    return `rm ${opts.join(' ')} \"${filePath}\"`;\n  }\n\n  public removeDir(dir: string): string {\n    if (this.osPlatform === 'win32') {\n      return `rmdir /s /q \"${dir}\"`;\n    }\n\n    return `rm -rf \"${dir}\"`;\n  }\n}", "language": "typescript"}
{"input": "A source that reads from an DynamoDB stream.", "output": "export class DynamoDBSource extends StreamSource {\n  private readonly table: ITableV2;\n  private readonly startingPosition: DynamoDBStartingPosition;\n  private readonly deadLetterTargetArn?: string;\n\n  constructor(table: ITableV2, parameters: DynamoDBSourceParameters) {\n    if (table.tableStreamArn === undefined) {\n      throw new Error('Table does not have a stream defined, cannot create pipes source');\n    }\n\n    super(table.tableStreamArn, parameters);\n    this.table = table;\n    this.startingPosition = parameters.startingPosition;\n    this.deadLetterTargetArn = this.getDeadLetterTargetArn(this.deadLetterTarget);\n  }\n\n  bind(_pipe: IPipe): SourceConfig {\n    return {\n      sourceParameters: {\n        dynamoDbStreamParameters: {\n          batchSize: this.sourceParameters.batchSize,\n          deadLetterConfig: this.deadLetterTargetArn ? { arn: this.deadLetterTargetArn } : undefined,\n          maximumBatchingWindowInSeconds: this.sourceParameters.maximumBatchingWindow?.toSeconds(),\n          maximumRecordAgeInSeconds: this.sourceParameters.maximumRecordAge?.toSeconds(),\n          maximumRetryAttempts: this.sourceParameters.maximumRetryAttempts,\n          onPartialBatchItemFailure: this.sourceParameters.onPartialBatchItemFailure,\n          parallelizationFactor: this.sourceParameters.parallelizationFactor,\n          startingPosition: this.startingPosition,\n        },\n      },\n    };\n  }\n\n  grantRead(grantee: IRole): void {\n    this.table.grantStreamRead(grantee);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, KMS, CloudFormation, Route 53 resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const zone = new route53.PublicHostedZone(this, 'HostedZone', {\n      zoneName: 'cdk-integ.com',\n    });\n\n    const www = new route53.ARecord(this, 'WWW', {\n      zone,\n      recordName: 'www.cdk-integ.com',\n      target: route53.RecordTarget.fromIpAddresses('1.2.3.4'),\n    });\n\n    new route53.ARecord(this, 'Alias', {\n      zone,\n      target: route53.RecordTarget.fromAlias(new targets.Route53RecordTarget(www)),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Alias for AWS resource management", "output": "export class Alias extends AliasBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-kms.Alias';\n\n  /**\n   * Import an existing KMS Alias defined outside the CDK app.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param attrs the properties of the referenced KMS Alias\n   */\n  public static fromAliasAttributes(scope: Construct, id: string, attrs: AliasAttributes): IAlias {\n    class _Alias extends AliasBase {\n      public get aliasName() { return attrs.aliasName; }\n      public get aliasTargetKey() { return attrs.aliasTargetKey; }\n    }\n    return new _Alias(scope, id);\n  }\n\n  /**\n   * Import an existing KMS Alias defined outside the CDK app, by the alias name. This method should be used\n   * instead of 'fromAliasAttributes' when the underlying KMS Key ARN is not available.\n   * This Alias will not have a direct reference to the KMS Key, so addAlias method is not supported.\n   *\n   * If the `@aws-cdk/aws-kms:applyImportedAliasPermissionsToPrincipal` feature flag is set to `true`,\n   * the grant* methods will use the kms:ResourceAliases condition to grant permissions to the specific alias name.\n   * They will only modify the principal policy, not the key resource policy.\n   * Without the feature flag `grant*` methods will be a no-op.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param aliasName The full name of the KMS Alias (e.g., 'alias/aws/s3', 'alias/myKeyAlias').\n   */\n  public static fromAliasName(scope: Construct, id: string, aliasName: string): IAlias {\n    class Import extends Resource implements IAlias {\n      public readonly keyArn = Stack.of(this).formatArn({ service: 'kms', resource: aliasName });\n      public readonly keyId = aliasName;\n      public readonly aliasName = aliasName;\n      public get aliasTargetKey(): IKey { throw new ValidationError('Cannot access aliasTargetKey on an Alias imported by Alias.fromAliasName().', this); }\n      public addAlias(_alias: string): Alias { throw new ValidationError('Cannot call addAlias on an Alias imported by Alias.fromAliasName().', this); }\n      public addToResourcePolicy(_statement: iam.PolicyStatement, _allowNoOp?: boolean): iam.AddToResourcePolicyResult {\n        return { statementAdded: false };\n      }\n\n      public get keyRef(): KeyReference {\n        return {\n          keyArn: this.keyArn,\n          keyId: this.keyId,\n        };\n      }\n\n      public grant(grantee: iam.IGrantable, ...actions: string[]): iam.Grant {\n        if (!FeatureFlags.of(this).isEnabled(KMS_APPLY_IMPORTED_ALIAS_PERMISSIONS_TO_PRINCIPAL)) {\n          return iam.Grant.drop(grantee, '');\n        }\n        return iam.Grant.addToPrincipal({\n          grantee,\n          actions,\n          resourceArns: [Stack.of(scope).formatArn({\n            service: 'kms',\n            resource: 'key',\n            resourceName: '*',\n          })],\n          conditions: {\n            'ForAnyValue:StringEquals': {\n              'kms:ResourceAliases': this.aliasName,\n            },\n          },\n        });\n      }\n\n      public get aliasRef(): AliasReference {\n        return {\n          aliasName: this.aliasName,\n        };\n      }\n\n      public grantDecrypt(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.DECRYPT_ACTIONS);\n      }\n\n      public grantEncrypt(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.ENCRYPT_ACTIONS);\n      }\n\n      public grantEncryptDecrypt(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.DECRYPT_ACTIONS, ...perms.ENCRYPT_ACTIONS);\n      }\n\n      public grantSign(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.SIGN_ACTIONS);\n      }\n\n      public grantVerify(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.VERIFY_ACTIONS);\n      }\n\n      public grantSignVerify(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.SIGN_ACTIONS, ...perms.VERIFY_ACTIONS);\n      }\n\n      public grantGenerateMac(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.GENERATE_HMAC_ACTIONS);\n      }\n\n      public grantVerifyMac(grantee: iam.IGrantable): iam.Grant {\n        return this.grant(grantee, ...perms.VERIFY_HMAC_ACTIONS);\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly aliasName: string;\n  public readonly aliasTargetKey: IKey;\n\n  constructor(scope: Construct, id: string, props: AliasProps) {\n    let aliasName = props.aliasName;\n\n    if (!Token.isUnresolved(aliasName)) {\n      if (!aliasName.startsWith(REQUIRED_ALIAS_PREFIX)) {\n        aliasName = REQUIRED_ALIAS_PREFIX + aliasName;\n      }\n\n      if (aliasName === REQUIRED_ALIAS_PREFIX) {\n        throw new ValidationError(`Alias must include a value after \"${REQUIRED_ALIAS_PREFIX}\": ${aliasName}`, scope);\n      }\n\n      if (aliasName.toLocaleLowerCase().startsWith(DISALLOWED_PREFIX)) {\n        throw new ValidationError(`Alias cannot start with ${DISALLOWED_PREFIX}: ${aliasName}`, scope);\n      }\n\n      if (!aliasName.match(/^[a-zA-Z0-9:/_-]{1,256}$/)) {\n        throw new ValidationError('Alias name must be between 1 and 256 characters in a-zA-Z0-9:/_-', scope);\n      }\n    } else if (Tokenization.reverseString(aliasName).firstValue && Tokenization.reverseString(aliasName).firstToken === undefined) {\n      const valueInToken = Tokenization.reverseString(aliasName).firstValue;\n\n      if (!valueInToken.startsWith(REQUIRED_ALIAS_PREFIX)) {\n        aliasName = REQUIRED_ALIAS_PREFIX + aliasName;\n      }\n\n      if (valueInToken.toLocaleLowerCase().startsWith(DISALLOWED_PREFIX)) {\n        throw new ValidationError(`Alias cannot start with ${DISALLOWED_PREFIX}: ${aliasName}`, scope);\n      }\n\n      if (!valueInToken.match(/^[a-zA-Z0-9:/_-]{1,256}$/)) {\n        throw new ValidationError('Alias name must be between 1 and 256 characters in a-zA-Z0-9:/_-', scope);\n      }\n    }\n\n    super(scope, id, {\n      physicalName: aliasName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.aliasTargetKey = props.targetKey;\n\n    const resource = new CfnAlias(this, 'Resource', {\n      aliasName: this.physicalName,\n      targetKeyId: this.aliasTargetKey.keyArn,\n    });\n\n    if (FeatureFlags.of(this).isEnabled(KMS_ALIAS_NAME_REF)) {\n      this.aliasName = this.getResourceNameAttribute(resource.ref);\n    } else {\n      this.aliasName = this.getResourceNameAttribute(resource.aliasName);\n    }\n\n    if (props.removalPolicy) {\n      resource.applyRemovalPolicy(props.removalPolicy);\n    }\n  }\n\n  protected generatePhysicalName(): string {\n    return REQUIRED_ALIAS_PREFIX + super.generatePhysicalName();\n  }\n}", "language": "typescript"}
{"input": "Represents revision of a task definition, either a specific numbered revision or the `latest` revision", "output": "export class TaskDefinitionRevision {\n  /**\n   * The most recent revision of a task\n   */\n  public static readonly LATEST = new TaskDefinitionRevision('latest');\n\n  /**\n   * Specific revision of a task\n   */\n  public static of(revision: number) {\n    if (revision < 1) {\n      throw new UnscopedValidationError(`A task definition revision must be 'latest' or a positive number, got ${revision}`);\n    }\n    return new TaskDefinitionRevision(revision.toString());\n  }\n\n  /**\n   * The string representation of this revision\n   */\n  public readonly revision: string;\n\n  private constructor(revision: string) {\n    this.revision = revision;\n  }\n}", "language": "typescript"}
{"input": "Supported instance types for SageMaker instance-based production variants.", "output": "export class InstanceType {\n  /**\n   * ml.c4.2xlarge\n   */\n  public static readonly C4_2XLARGE = InstanceType.of('ml.c4.2xlarge');\n\n  /**\n   * ml.c4.4xlarge\n   */\n  public static readonly C4_4XLARGE = InstanceType.of('ml.c4.4xlarge');\n\n  /**\n   * ml.c4.8xlarge\n   */\n  public static readonly C4_8XLARGE = InstanceType.of('ml.c4.8xlarge');\n\n  /**\n   * ml.c4.large\n   */\n  public static readonly C4_LARGE = InstanceType.of('ml.c4.large');\n\n  /**\n   * ml.c4.xlarge\n   */\n  public static readonly C4_XLARGE = InstanceType.of('ml.c4.xlarge');\n\n  /**\n   * ml.c5.18xlarge\n   */\n  public static readonly C5_18XLARGE = InstanceType.of('ml.c5.18xlarge');\n\n  /**\n   * ml.c5.2xlarge\n   */\n  public static readonly C5_2XLARGE = InstanceType.of('ml.c5.2xlarge');\n\n  /**\n   * ml.c5.4xlarge\n   */\n  public static readonly C5_4XLARGE = InstanceType.of('ml.c5.4xlarge');\n\n  /**\n   * ml.c5.9xlarge\n   */\n  public static readonly C5_9XLARGE = InstanceType.of('ml.c5.9xlarge');\n\n  /**\n   * ml.c5.large\n   */\n  public static readonly C5_LARGE = InstanceType.of('ml.c5.large');\n\n  /**\n   * ml.c5.xlarge\n   */\n  public static readonly C5_XLARGE = InstanceType.of('ml.c5.xlarge');\n\n  /**\n   * ml.c5d.18xlarge\n   */\n  public static readonly C5D_18XLARGE = InstanceType.of('ml.c5d.18xlarge');\n\n  /**\n   * ml.c5d.2xlarge\n   */\n  public static readonly C5D_2XLARGE = InstanceType.of('ml.c5d.2xlarge');\n\n  /**\n   * ml.c5d.4xlarge\n   */\n  public static readonly C5D_4XLARGE = InstanceType.of('ml.c5d.4xlarge');\n\n  /**\n   * ml.c5d.9xlarge\n   */\n  public static readonly C5D_9XLARGE = InstanceType.of('ml.c5d.9xlarge');\n\n  /**\n   * ml.c5d.large\n   */\n  public static readonly C5D_LARGE = InstanceType.of('ml.c5d.large');\n\n  /**\n   * ml.c5d.xlarge\n   */\n  public static readonly C5D_XLARGE = InstanceType.of('ml.c5d.xlarge');\n\n  /**\n   * ml.c6i.12xlarge\n   */\n  public static readonly C6I_12XLARGE = InstanceType.of('ml.c6i.12xlarge');\n\n  /**\n   * ml.c6i.16xlarge\n   */\n  public static readonly C6I_16XLARGE = InstanceType.of('ml.c6i.16xlarge');\n\n  /**\n   * ml.c6i.24xlarge\n   */\n  public static readonly C6I_24XLARGE = InstanceType.of('ml.c6i.24xlarge');\n\n  /**\n   * ml.c6i.2xlarge\n   */\n  public static readonly C6I_2XLARGE = InstanceType.of('ml.c6i.2xlarge');\n\n  /**\n   * ml.c6i.32xlarge\n   */\n  public static readonly C6I_32XLARGE = InstanceType.of('ml.c6i.32xlarge');\n\n  /**\n   * ml.c6i.4xlarge\n   */\n  public static readonly C6I_4XLARGE = InstanceType.of('ml.c6i.4xlarge');\n\n  /**\n   * ml.c6i.8xlarge\n   */\n  public static readonly C6I_8XLARGE = InstanceType.of('ml.c6i.8xlarge');\n\n  /**\n   * ml.c6i.large\n   */\n  public static readonly C6I_LARGE = InstanceType.of('ml.c6i.large');\n\n  /**\n   * ml.c6i.xlarge\n   */\n  public static readonly C6I_XLARGE = InstanceType.of('ml.c6i.xlarge');\n\n  /**\n   * ml.g4dn.12xlarge\n   */\n  public static readonly G4DN_12XLARGE = InstanceType.of('ml.g4dn.12xlarge');\n\n  /**\n   * ml.g4dn.16xlarge\n   */\n  public static readonly G4DN_16XLARGE = InstanceType.of('ml.g4dn.16xlarge');\n\n  /**\n   * ml.g4dn.2xlarge\n   */\n  public static readonly G4DN_2XLARGE = InstanceType.of('ml.g4dn.2xlarge');\n\n  /**\n   * ml.g4dn.4xlarge\n   */\n  public static readonly G4DN_4XLARGE = InstanceType.of('ml.g4dn.4xlarge');\n\n  /**\n   * ml.g4dn.8xlarge\n   */\n  public static readonly G4DN_8XLARGE = InstanceType.of('ml.g4dn.8xlarge');\n\n  /**\n   * ml.g4dn.xlarge\n   */\n  public static readonly G4DN_XLARGE = InstanceType.of('ml.g4dn.xlarge');\n\n  /**\n   * ml.g5.12xlarge\n   */\n  public static readonly G5_12XLARGE = InstanceType.of('ml.g5.12xlarge');\n\n  /**\n   * ml.g5.16xlarge\n   */\n  public static readonly G5_16XLARGE = InstanceType.of('ml.g5.16xlarge');\n\n  /**\n   * ml.g5.24xlarge\n   */\n  public static readonly G5_24XLARGE = InstanceType.of('ml.g5.24xlarge');\n\n  /**\n   * ml.g5.2xlarge\n   */\n  public static readonly G5_2XLARGE = InstanceType.of('ml.g5.2xlarge');\n\n  /**\n   * ml.g5.48xlarge\n   */\n  public static readonly G5_48XLARGE = InstanceType.of('ml.g5.48xlarge');\n\n  /**\n   * ml.g5.4xlarge\n   */\n  public static readonly G5_4XLARGE = InstanceType.of('ml.g5.4xlarge');\n\n  /**\n   * ml.g5.8xlarge\n   */\n  public static readonly G5_8XLARGE = InstanceType.of('ml.g5.8xlarge');\n\n  /**\n   * ml.g5.xlarge\n   */\n  public static readonly G5_XLARGE = InstanceType.of('ml.g5.xlarge');\n\n  /**\n   * ml.g6.12xlarge\n   */\n  public static readonly G6_12XLARGE = InstanceType.of('ml.g6.12xlarge');\n\n  /**\n   * ml.g6.16xlarge\n   */\n  public static readonly G6_16XLARGE = InstanceType.of('ml.g6.16xlarge');\n\n  /**\n   * ml.g6.24xlarge\n   */\n  public static readonly G6_24XLARGE = InstanceType.of('ml.g6.24xlarge');\n\n  /**\n   * ml.g6.2xlarge\n   */\n  public static readonly G6_2XLARGE = InstanceType.of('ml.g6.2xlarge');\n\n  /**\n   * ml.g6.48xlarge\n   */\n  public static readonly G6_48XLARGE = InstanceType.of('ml.g6.48xlarge');\n\n  /**\n   * ml.g6.4xlarge\n   */\n  public static readonly G6_4XLARGE = InstanceType.of('ml.g6.4xlarge');\n\n  /**\n   * ml.g6.8xlarge\n   */\n  public static readonly G6_8XLARGE = InstanceType.of('ml.g6.8xlarge');\n\n  /**\n   * ml.g6.xlarge\n   */\n  public static readonly G6_XLARGE = InstanceType.of('ml.g6.xlarge');\n\n  /**\n   * ml.inf1.24xlarge\n   */\n  public static readonly INF1_24XLARGE = InstanceType.of('ml.inf1.24xlarge');\n\n  /**\n   * ml.inf1.2xlarge\n   */\n  public static readonly INF1_2XLARGE = InstanceType.of('ml.inf1.2xlarge');\n\n  /**\n   * ml.inf1.6xlarge\n   */\n  public static readonly INF1_6XLARGE = InstanceType.of('ml.inf1.6xlarge');\n\n  /**\n   * ml.inf1.xlarge\n   */\n  public static readonly INF1_XLARGE = InstanceType.of('ml.inf1.xlarge');\n\n  /**\n   * ml.inf2.xlarge\n   */\n  public static readonly INF2_XLARGE = InstanceType.of('ml.inf2.xlarge');\n\n  /**\n   * ml.inf2.8xlarge\n   */\n  public static readonly INF2_8XLARGE = InstanceType.of('ml.inf2.8xlarge');\n\n  /**\n   * ml.inf2.24xlarge\n   */\n  public static readonly INF2_24XLARGE = InstanceType.of('ml.inf2.24xlarge');\n\n  /**\n   * ml.inf2.48xlarge\n   */\n  public static readonly INF2_48XLARGE = InstanceType.of('ml.inf2.48xlarge');\n\n  /**\n   * ml.m4.10xlarge\n   */\n  public static readonly M4_10XLARGE = InstanceType.of('ml.m4.10xlarge');\n\n  /**\n   * ml.m4.16xlarge\n   */\n  public static readonly M4_16XLARGE = InstanceType.of('ml.m4.16xlarge');\n\n  /**\n   * ml.m4.2xlarge\n   */\n  public static readonly M4_2XLARGE = InstanceType.of('ml.m4.2xlarge');\n\n  /**\n   * ml.m4.4xlarge\n   */\n  public static readonly M4_4XLARGE = InstanceType.of('ml.m4.4xlarge');\n\n  /**\n   * ml.m4.xlarge\n   */\n  public static readonly M4_XLARGE = InstanceType.of('ml.m4.xlarge');\n\n  /**\n   * ml.m5.12xlarge\n   */\n  public static readonly M5_12XLARGE = InstanceType.of('ml.m5.12xlarge');\n\n  /**\n   * ml.m5.24xlarge\n   */\n  public static readonly M5_24XLARGE = InstanceType.of('ml.m5.24xlarge');\n\n  /**\n   * ml.m5.2xlarge\n   */\n  public static readonly M5_2XLARGE = InstanceType.of('ml.m5.2xlarge');\n\n  /**\n   * ml.m5.4xlarge\n   */\n  public static readonly M5_4XLARGE = InstanceType.of('ml.m5.4xlarge');\n\n  /**\n   * ml.m5.large\n   */\n  public static readonly M5_LARGE = InstanceType.of('ml.m5.large');\n\n  /**\n   * ml.m5.xlarge\n   */\n  public static readonly M5_XLARGE = InstanceType.of('ml.m5.xlarge');\n\n  /**\n   * ml.m5d.12xlarge\n   */\n  public static readonly M5D_12XLARGE = InstanceType.of('ml.m5d.12xlarge');\n\n  /**\n   * ml.m5d.24xlarge\n   */\n  public static readonly M5D_24XLARGE = InstanceType.of('ml.m5d.24xlarge');\n\n  /**\n   * ml.m5d.2xlarge\n   */\n  public static readonly M5D_2XLARGE = InstanceType.of('ml.m5d.2xlarge');\n\n  /**\n   * ml.m5d.4xlarge\n   */\n  public static readonly M5D_4XLARGE = InstanceType.of('ml.m5d.4xlarge');\n\n  /**\n   * ml.m5d.large\n   */\n  public static readonly M5D_LARGE = InstanceType.of('ml.m5d.large');\n\n  /**\n   * ml.m5d.xlarge\n   */\n  public static readonly M5D_XLARGE = InstanceType.of('ml.m5d.xlarge');\n\n  /**\n   * ml.p2.16xlarge\n   */\n  public static readonly P2_16XLARGE = InstanceType.of('ml.p2.16xlarge');\n\n  /**\n   * ml.p2.8xlarge\n   */\n  public static readonly P2_8XLARGE = InstanceType.of('ml.p2.8xlarge');\n\n  /**\n   * ml.p2.xlarge\n   */\n  public static readonly P2_XLARGE = InstanceType.of('ml.p2.xlarge');\n\n  /**\n   * ml.p3.16xlarge\n   */\n  public static readonly P3_16XLARGE = InstanceType.of('ml.p3.16xlarge');\n\n  /**\n   * ml.p3.2xlarge\n   */\n  public static readonly P3_2XLARGE = InstanceType.of('ml.p3.2xlarge');\n\n  /**\n   * ml.p3.8xlarge\n   */\n  public static readonly P3_8XLARGE = InstanceType.of('ml.p3.8xlarge');\n\n  /**\n   * ml.p4d.24xlarge\n   */\n  public static readonly P4D_24XLARGE = InstanceType.of('ml.p4d.24xlarge');\n\n  /**\n   * ml.r5.12xlarge\n   */\n  public static readonly R5_12XLARGE = InstanceType.of('ml.r5.12xlarge');\n\n  /**\n   * ml.r5.24xlarge\n   */\n  public static readonly R5_24XLARGE = InstanceType.of('ml.r5.24xlarge');\n\n  /**\n   * ml.r5.2xlarge\n   */\n  public static readonly R5_2XLARGE = InstanceType.of('ml.r5.2xlarge');\n\n  /**\n   * ml.r5.4xlarge\n   */\n  public static readonly R5_4XLARGE = InstanceType.of('ml.r5.4xlarge');\n\n  /**\n   * ml.r5.large\n   */\n  public static readonly R5_LARGE = InstanceType.of('ml.r5.large');\n\n  /**\n   * ml.r5.xlarge\n   */\n  public static readonly R5_XLARGE = InstanceType.of('ml.r5.xlarge');\n\n  /**\n   * ml.r5d.12xlarge\n   */\n  public static readonly R5D_12XLARGE = InstanceType.of('ml.r5d.12xlarge');\n\n  /**\n   * ml.r5d.24xlarge\n   */\n  public static readonly R5D_24XLARGE = InstanceType.of('ml.r5d.24xlarge');\n\n  /**\n   * ml.r5d.2xlarge\n   */\n  public static readonly R5D_2XLARGE = InstanceType.of('ml.r5d.2xlarge');\n\n  /**\n   * ml.r5d.4xlarge\n   */\n  public static readonly R5D_4XLARGE = InstanceType.of('ml.r5d.4xlarge');\n\n  /**\n   * ml.r5d.large\n   */\n  public static readonly R5D_LARGE = InstanceType.of('ml.r5d.large');\n\n  /**\n   * ml.r5d.xlarge\n   */\n  public static readonly R5D_XLARGE = InstanceType.of('ml.r5d.xlarge');\n\n  /**\n   * ml.t2.2xlarge\n   */\n  public static readonly T2_2XLARGE = InstanceType.of('ml.t2.2xlarge');\n\n  /**\n   * ml.t2.large\n   */\n  public static readonly T2_LARGE = InstanceType.of('ml.t2.large');\n\n  /**\n   * ml.t2.medium\n   */\n  public static readonly T2_MEDIUM = InstanceType.of('ml.t2.medium');\n\n  /**\n   * ml.t2.xlarge\n   */\n  public static readonly T2_XLARGE = InstanceType.of('ml.t2.xlarge');\n\n  /**\n   * Builds an InstanceType from a given string or token (such as a CfnParameter).\n   * @param instanceType An instance type as string\n   * @returns A strongly typed InstanceType\n   */\n  public static of(instanceType: string): InstanceType {\n    return new InstanceType(instanceType);\n  }\n\n  private readonly instanceTypeIdentifier: string;\n\n  constructor(instanceType: string) {\n    if (cdk.Token.isUnresolved(instanceType) || instanceType.startsWith('ml.')) {\n      this.instanceTypeIdentifier = instanceType;\n    } else {\n      throw new Error(`instance type must start with 'ml.'; (got ${instanceType})`);\n    }\n  }\n\n  /**\n   * Return the instance type as a string\n   * @returns The instance type as a string\n   */\n  public toString(): string {\n    return this.instanceTypeIdentifier;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates KMS, Secrets Manager, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    // Create a default secret\n    const secret = new secretsmanager.Secret(this, 'Secret');\n\n    // Create a JSON secret containing cfnDynamicReferenceKey values extracted from the default secret\n    new secretsmanager.Secret(this, 'JSONSecret', {\n      secretObjectValue: {\n        cfnDynamicReferenceKeyWithDefaults: SecretValue.unsafePlainText(secret.cfnDynamicReferenceKey()),\n        cfnDynamicReferenceKeyWithJsonFieldAndVersionStage: SecretValue.unsafePlainText(secret.cfnDynamicReferenceKey({\n          jsonField: 'json-key',\n          versionStage: 'version-stage',\n        })),\n        cfnDynamicReferenceKeyWithJsonFieldAndVersionId: SecretValue.unsafePlainText(secret.cfnDynamicReferenceKey({\n          jsonField: 'json-key',\n          versionId: 'version-id',\n        })),\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, CloudFormation resources", "output": "class InfrastructureStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        my_main_func = lambda_.Function(\n            self,\n            \"myMainFunction\",\n            code=lambda_.InlineCode(\"def main(event, context)\\n  print('hello, world')\"),\n            handler='index.main',\n            runtime=lambda_.Runtime.PYTHON_3_7\n        )\n\n        # We assign the function to a local variable for the Object.\n        self._function = my_main_func\n\n    # Using the property decorator\n    @property\n    def main_function(self) -> lambda_.IFunction:\n        return self._function", "language": "python"}
{"input": "CDK class FileAssetApp for AWS resource management", "output": "export class FileAssetApp extends Stage {\n  constructor(scope: Construct, id: string, props?: FileAssetAppProps) {\n    super(scope, id, props);\n    const stack = new Stack(this, 'Stack');\n    new s3_assets.Asset(stack, 'Asset', {\n      path: path.join(__dirname, 'assets', 'test-file-asset.txt'),\n      displayName: props?.displayName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, API Gateway, CloudFormation resources", "output": "class NatInstanceStack extends cdk.Stack {\n  public readonly apiUrl: string;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    // Configure the `natGatewayProvider` when defining a Vpc\n    const natGatewayProvider = ec2.NatProvider.instanceV2({\n      instanceType: new ec2.InstanceType('t4g.nano'),\n    });\n\n    const vpc = new ec2.Vpc(this, 'MyVpc', {\n      natGatewayProvider,\n      // The 'natGateways' parameter now controls the number of NAT instances\n      natGateways: 1,\n    });\n\n    Array.isArray(vpc);\n    Array.isArray(natGatewayProvider.configuredGateways);\n\n    const loadBalancer = new elbv2.ApplicationLoadBalancer(this, 'ALB', { vpc });\n    const listener = loadBalancer.addListener('listener', { port: 80 });\n    listener.addTargets('target', { port: 80 });\n    listener.addAction('response', { action: elbv2.ListenerAction.fixedResponse(200) });\n\n    const httpApi = new apigwv2.HttpApi(this, 'HttpProxyPrivateApi', {\n      defaultIntegration: new integrations.HttpAlbIntegration('DefaultIntegration', listener),\n      createDefaultStage: true,\n    });\n\n    assert(httpApi.url, 'httpApi.url cannot be empty');\n    this.apiUrl = httpApi.url;\n  }\n}", "language": "typescript"}
{"input": "Remember all Tokens encountered while resolving", "output": "export class RememberingTokenResolver extends DefaultTokenResolver {\n  private readonly tokensSeen = new Set<IResolvable>();\n\n  public resolveToken(t: IResolvable, context: IResolveContext, postProcessor: IPostProcessor) {\n    this.tokensSeen.add(t);\n    return super.resolveToken(t, context, postProcessor);\n  }\n\n  public resolveString(s: TokenizedStringFragments, context: IResolveContext) {\n    const ret = super.resolveString(s, context);\n    return ret;\n  }\n\n  public get tokens(): IResolvable[] {\n    return Array.from(this.tokensSeen);\n  }\n}", "language": "typescript"}
{"input": "CDK class NoMixedDeps for AWS resource management", "output": "export class NoMixedDeps extends ValidationRule {\n  public readonly name = 'dependencies/no-mixed-deps';\n\n  public validate(pkg: PackageJson) {\n    const deps = Object.keys(pkg.json.dependencies ?? {});\n    const devDeps = Object.keys(pkg.json.devDependencies ?? {});\n\n    const shared = deps.filter((dep) => devDeps.includes(dep));\n    for (const dep of shared) {\n      pkg.report({\n        ruleName: this.name,\n        message: `dependency may not be both in dependencies and devDependencies: ${dep}`,\n        fix: () => pkg.removeDevDependency(dep),\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "Shared infrastructure -- VPC and Cluster", "output": "class SharedInfraStack extends Stack {\n  public readonly vpc: ec2.Vpc;\n  public readonly cluster: ecs.Cluster;\n\n  constructor(scope: Construct, id: string, props: StackProps = {}) {\n    super(scope, id, props);\n\n    this.vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 2 });\n    this.cluster = new ecs.Cluster(this, 'Cluster', {\n      vpc: this.vpc\n    });\n  }\n}", "language": "typescript"}
{"input": "Class for configuring network load balancer listener when registering targets.", "output": "class NetworkListenerConfig extends ListenerConfig {\n  constructor(private readonly listener: elbv2.NetworkListener, private readonly props?: elbv2.AddNetworkTargetsProps) {\n    super();\n  }\n\n  /**\n   * Create and attach a target group to listener.\n   */\n  public addTargets(id: string, target: LoadBalancerTargetOptions, service: BaseService) {\n    const port = this.props?.port ?? 80;\n    this.listener.addTargets(id, {\n      ... this.props,\n      targets: [\n        service.loadBalancerTarget({\n          ...target,\n        }),\n      ],\n      port,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedConnection for AWS resource management", "output": "class ImportedConnection extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-events.ImportedConnection';\n  public readonly connectionArn: string;\n  public readonly connectionName: string;\n  public readonly connectionSecretArn: string;\n\n  public get connectionRef(): ConnectionReference {\n    return {\n      connectionName: this.connectionName,\n      connectionArn: this.connectionArn,\n    };\n  }\n\n  constructor(scope: Construct, id: string, attrs: ConnectionAttributes) {\n    const arnParts = Stack.of(scope).parseArn(attrs.connectionArn);\n    super(scope, id, {\n      account: arnParts.account,\n      region: arnParts.region,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, attrs);\n\n    this.connectionArn = attrs.connectionArn;\n    this.connectionName = attrs.connectionName;\n    this.connectionSecretArn = attrs.connectionSecretArn;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function _create_cfn_output_key_arn", "output": "def _create_cfn_output_key_arn(self, key_region: str, key_id: str):\n        cdk.CfnOutput(\n            self,\n            f\"{key_region}-key-arn\",\n            value=f\"arn:aws:kms:{key_region}:{self.account}:key/{key_id}\",\n            export_name=f\"{self._key_arn_export_prefix}{key_region}\",\n        )", "language": "python"}
{"input": "CDK class ReuseStage for AWS resource management", "output": "class ReuseStage extends cdk.Stage {\n  public constructor(scope: Construct, id: string, props: ReuseStageProps) {\n    super(scope, id, props);\n    new ReuseStack(this, 'SampleStack', props.reuseStackProps ?? {});\n  }\n}", "language": "typescript"}
{"input": "CDK class S3ComponentDataFromAsset for AWS resource management", "output": "class S3ComponentDataFromAsset extends S3ComponentData {\n  public constructor(asset: s3assets.Asset) {\n    super(asset.bucket, asset.s3ObjectKey);\n  }\n}", "language": "typescript"}
{"input": "CDK class IntegTesting for AWS resource management", "output": "export class IntegTesting {\n  readonly stack: Stack[];\n  constructor() {\n    const app = new App();\n    const env = { region: process.env.CDK_DEFAULT_REGION, account: process.env.CDK_DEFAULT_ACCOUNT };\n    const stack = new Stack(app, 'integ-testing-eicendpoint', { env });\n\n    const vpc = new ec2.Vpc(stack, 'Vpc', { subnetConfiguration: [{ cidrMask: 24, name: 'rds', subnetType: ec2.SubnetType.PRIVATE_ISOLATED }] });\n\n    const instance = new ec2.Instance(stack, 'instance', {\n      vpc,\n      vpcSubnets: vpc.selectSubnets({ subnetType: ec2.SubnetType.PRIVATE_ISOLATED }),\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.LARGE),\n      machineImage: ec2.MachineImage.latestAmazonLinux2023(),\n    });\n\n    new CfnOutput(stack, 'InstanceId', { value: instance.instanceId });\n\n    // allow all traffic from within VPC\n    instance.connections.allowFrom(ec2.Peer.ipv4(vpc.vpcCidrBlock), ec2.Port.allTraffic());\n\n    new InstanceConnectEndpoint(stack, 'EICEndpoint', {\n      subnet: vpc.isolatedSubnets[0],\n      preserveClientIp: false,\n    });\n    this.stack = [stack];\n  }\n}", "language": "typescript"}
{"input": "CDK class NoTsBuildInfo for AWS resource management", "output": "export class NoTsBuildInfo extends ValidationRule {\n  public readonly name = 'npmignore/tsbuildinfo';\n\n  public validate(pkg: PackageJson): void {\n    // skip private packages\n    if (pkg.json.private) { return; }\n\n    // Stop 'tsconfig.tsbuildinfo' and regular '.tsbuildinfo' files from being\n    // published to NPM.\n    // We might at some point also want to strip tsconfig.json but for now,\n    // the TypeScript DOCS BUILD needs to it to load the typescript source.\n    fileShouldContain(this.name, pkg, '.npmignore', '*.tsbuildinfo');\n  }\n}", "language": "typescript"}
{"input": "Basic Auth configuration", "output": "export class BasicAuth {\n  /**\n   * Creates a Basic Auth configuration from a username and a password\n   *\n   * @param username The username\n   * @param password The password\n   */\n  public static fromCredentials(username: string, password: SecretValue) {\n    return new BasicAuth({ username, password });\n  }\n\n  /**\n   * Creates a Basic Auth configuration with a password generated in Secrets\n   * Manager.\n   *\n   * @param username The username\n   * @param encryptionKey The encryption key to use to encrypt the password in\n   * Secrets Manager\n   */\n  public static fromGeneratedPassword(username: string, encryptionKey?: kms.IKey) {\n    return new BasicAuth({ username, encryptionKey });\n  }\n\n  constructor(private readonly props: BasicAuthProps) {}\n\n  /**\n   * Binds this Basic Auth configuration to an App\n   */\n  public bind(scope: Construct, id: string): BasicAuthConfig {\n    const config = {\n      enableBasicAuth: true,\n      username: this.props.username,\n    };\n\n    if (this.props.password) {\n      return {\n        ...config,\n        password: this.props.password.unsafeUnwrap(), // Safe usage\n      };\n    }\n\n    const secret = new secretsmanager.Secret(scope, id, {\n      generateSecretString: {\n        secretStringTemplate: JSON.stringify({ username: this.props.username }),\n        generateStringKey: 'password',\n      },\n    });\n    return {\n      ...config,\n      password: secret.secretValueFromJson('password').unsafeUnwrap(),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for EC2, MSK (Kafka) operations", "output": "def __init__(self, scope: Construct, construct_id: str, vpc, client_subnet, **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # MSK cluster with SASL/SCRAM authentication\n        self.cluster = msk.Cluster(self, \"Cluster\",\n            cluster_name=\"iotCluster\",\n            kafka_version=msk.KafkaVersion.V2_8_1,\n            vpc=vpc,\n            encryption_in_transit=msk.EncryptionInTransitConfig(\n                client_broker=msk.ClientBrokerEncryption.TLS\n            ),\n            client_authentication=msk.ClientAuthentication.sasl(\n                scram=True\n            ),    \n        )\n\n        # Enable MSK cluster connection on ports 2181 and 9096 for SASL/SCRAM authentication \n        self.cluster.connections.allow_from(\n            ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            ec2.Port.tcp(2181))\n        self.cluster.connections.allow_from(\n            ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            ec2.Port.tcp(9096))\n        \n        # EC2 Instance in the public subnet used to create the topics\n        client = MSKClient(self, \"MskClient\", \n            vpc=vpc, \n            client_subnet=client_subnet, \n            zookeeper=self.cluster.zookeeper_connection_string)", "language": "python"}
{"input": "CDK class ServerlessClusterFromSnapshot for AWS resource management", "output": "export class ServerlessClusterFromSnapshot extends ServerlessClusterNew {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.ServerlessClusterFromSnapshot';\n\n  public readonly clusterIdentifier: string;\n  public readonly clusterEndpoint: Endpoint;\n  public readonly clusterReadEndpoint: Endpoint;\n  public readonly secret?: secretsmanager.ISecret;\n\n  constructor(scope: Construct, id: string, props: ServerlessClusterFromSnapshotProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.enableDataApi = props.enableDataApi;\n\n    let credentials = props.credentials;\n    let secret = credentials?.secret;\n    if (!secret && credentials?.generatePassword) {\n      if (!credentials.username) {\n        throw new ValidationError('`credentials` `username` must be specified when `generatePassword` is set to true', this);\n      }\n\n      secret = new DatabaseSecret(this, 'Secret', {\n        username: credentials.username,\n        encryptionKey: credentials.encryptionKey,\n        excludeCharacters: credentials.excludeCharacters,\n        replaceOnPasswordCriteriaChanges: credentials.replaceOnPasswordCriteriaChanges,\n        replicaRegions: credentials.replicaRegions,\n      });\n    }\n\n    const cluster = new CfnDBCluster(this, 'Resource', {\n      ...this.newCfnProps,\n      snapshotIdentifier: props.snapshotIdentifier,\n      masterUserPassword: secret?.secretValueFromJson('password')?.unsafeUnwrap() ?? credentials?.password?.unsafeUnwrap(), // Safe usage\n    });\n\n    this.clusterIdentifier = cluster.ref;\n\n    // create a number token that represents the port of the cluster\n    const portAttribute = Token.asNumber(cluster.attrEndpointPort);\n    this.clusterEndpoint = new Endpoint(cluster.attrEndpointAddress, portAttribute);\n    this.clusterReadEndpoint = new Endpoint(cluster.attrReadEndpointAddress, portAttribute);\n\n    cluster.applyRemovalPolicy(props.removalPolicy ?? RemovalPolicy.SNAPSHOT);\n\n    if (secret) {\n      this.secret = secret.attach(this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Manages AWS tags for all resources within a construct scope.", "output": "export class Tags {\n  /**\n   * Returns the tags API for this scope.\n   * @param scope The scope\n   */\n  public static of(scope: IConstruct): Tags {\n    return new Tags(scope);\n  }\n\n  private readonly explicitStackTags: boolean;\n\n  private constructor(private readonly scope: IConstruct) {\n    this.explicitStackTags = FeatureFlags.of(scope).isEnabled(cxapi.EXPLICIT_STACK_TAGS) ?? false;\n  }\n\n  /**\n   * Add tags to the node of a construct and all its the taggable children\n   *\n   * ## Tagging and CloudFormation Stacks\n   *\n   * If the feature flag `@aws-cdk/core:explicitStackTags` is set to `true`\n   * (recommended modern behavior), Stacks will not automatically be tagged.\n   * Stack tags should be configured on Stacks directly (preferred), or\n   * you must explicitly include the resource type `aws:cdk:stack` in the\n   * `includeResourceTypes` array.\n   *\n   * If the feature flag is set to `false` (legacy behavior) then both Stacks\n   * and resources in the indicated scope will both be tagged by default, which\n   * leads to tags being applied twice (once in the template, and then once\n   * again automatically by CloudFormation as part of the stack deployment).\n   * That behavior leads to loss of control as `excludeResourceTypes` will\n   * prevent tags from appearing in the template, but they will still be\n   * applied to the Stack and hence CloudFormation will still apply them\n   * to the resource.\n   */\n  public add(key: string, value: string, props: TagProps = {}) {\n    // Implicitly add `aws:cdk:stack` to the `excludeResourceTypes` array in modern behavior\n    if (this.explicitStackTags && !props.includeResourceTypes?.includes('aws:cdk:stack')) {\n      props = {\n        ...props,\n        excludeResourceTypes: [...props.excludeResourceTypes ?? [], 'aws:cdk:stack'],\n      };\n    }\n\n    const tag = new Tag(key, value, props);\n    const options: AspectOptions = { priority: mutatingAspectPrio32333(this.scope) };\n    Aspects.of(this.scope).add(tag, options);\n  }\n\n  /**\n   * remove tags to the node of a construct and all its the taggable children\n   */\n  public remove(key: string, props: TagProps = {}) {\n    const removeTag = new RemoveTag(key, props);\n    const options: AspectOptions = { priority: mutatingAspectPrio32333(this.scope) };\n    Aspects.of(this.scope).add(removeTag, options);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, Step Functions, CloudFormation resources", "output": "class S3JsonItemReaderTestStack extends Stack {\n  readonly bucket: Bucket;\n  readonly dynamicStateMachine: StateMachine;\n  readonly staticStateMachine: StateMachine;\n\n  constructor(scope: App, props?: StackProps) {\n    super(scope, `${TEST_NAME}Stack`, props);\n\n    this.bucket = this.createBucket();\n    const dynamicDistributedMap = this.createDynamicDistributedMap();\n    this.dynamicStateMachine = this.createStateMachine(dynamicDistributedMap, 'Dynamic');\n    const staticDistributedMap = this.createStaticDistributedMap();\n    this.staticStateMachine = this.createStateMachine(staticDistributedMap, 'Static');\n  }\n\n  private createBucket(): Bucket {\n    return new Bucket(this, `${TEST_NAME}Bucket`, {\n      autoDeleteObjects: true,\n      bucketName: `bucket-item-reader-path-${this.account}-${this.region}`,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n  }\n\n  private createDynamicDistributedMap(): DistributedMap {\n    const map = new DistributedMap(this, `${TEST_NAME}DynamicMap`, {\n      itemReader: new S3JsonItemReader({\n        bucketNamePath: JsonPath.stringAt('$.bucketName'),\n        key: JsonPath.stringAt('$.key'),\n      }),\n    });\n\n    const itemProcessor = new Pass(this, `${TEST_NAME}DynamicPass`);\n    map.itemProcessor(itemProcessor);\n    return map;\n  }\n\n  private createStaticDistributedMap(): DistributedMap {\n    const map = new DistributedMap(this, `${TEST_NAME}StaticMap`, {\n      itemReader: new S3JsonItemReader({\n        bucket: this.bucket,\n        key: JsonPath.stringAt('$.key'),\n      }),\n    });\n\n    const itemProcessor = new Pass(this, `${TEST_NAME}StaticPass`);\n    map.itemProcessor(itemProcessor);\n    return map;\n  }\n\n  private createStateMachine(distributedMap: DistributedMap, mapType: string): StateMachine {\n    const stateMachineName = `${TEST_NAME}StateMachine${mapType}`;\n    const stateMachine = new StateMachine(this, stateMachineName, {\n      definition: distributedMap,\n      stateMachineName,\n    });\n    stateMachine.addToRolePolicy(this.buildGetS3ObjectPolicyStatement());\n    stateMachine.addToRolePolicy(this.buildListS3ObjectsPolicyStatement());\n    return stateMachine;\n  }\n\n  private buildGetS3ObjectPolicyStatement(): PolicyStatement {\n    return new PolicyStatement({\n      actions: ['s3:GetObject'],\n      resources: [this.bucket.arnForObjects('*')],\n    });\n  }\n\n  private buildListS3ObjectsPolicyStatement(): PolicyStatement {\n    return new PolicyStatement({\n      actions: ['s3:ListBucket'],\n      resources: [this.bucket.bucketArn],\n    });\n  }\n}", "language": "typescript"}
{"input": "Error thrown when a ToolSchema is not properly initialized.", "output": "class ToolSchemaError extends Error {\n  constructor(message: string, public readonly cause?: string) {\n    super(message);\n    this.name = 'ToolSchemaError';\n  }\n}", "language": "typescript"}
{"input": "JSII .NET icon url is required and must look sane", "output": "export class JSIIDotNetIconUrlIsRequired extends ValidationRule {\n  public readonly name = 'jsii/dotnet/icon-url';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    const CDK_LOGO_URL = 'https://raw.githubusercontent.com/aws/aws-cdk/main/logo/default-256-dark.png';\n    expectJSON(this.name, pkg, 'jsii.targets.dotnet.iconUrl', CDK_LOGO_URL);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, DynamoDB, WAF resources", "output": "class DynamodbLambdaStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # create dynamo table\n        demo_table = aws_dynamodb.Table(\n            self, \"demo_table\",\n            partition_key=aws_dynamodb.Attribute(\n                name=\"id\",\n                type=aws_dynamodb.AttributeType.STRING\n            )\n        )\n\n        # create producer lambda function\n        producer_lambda = aws_lambda.Function(self, \"producer_lambda_function\",\n                                              runtime=aws_lambda.Runtime.PYTHON_3_6,\n                                              handler=\"lambda_function.lambda_handler\",\n                                              code=aws_lambda.Code.from_asset(\"./lambda/producer\"))\n\n        producer_lambda.add_environment(\"TABLE_NAME\", demo_table.table_name)\n\n        # grant permission to lambda to write to demo table\n        demo_table.grant_write_data(producer_lambda)\n\n        # create consumer lambda function\n        consumer_lambda = aws_lambda.Function(self, \"consumer_lambda_function\",\n                                              runtime=aws_lambda.Runtime.PYTHON_3_6,\n                                              handler=\"lambda_function.lambda_handler\",\n                                              code=aws_lambda.Code.from_asset(\"./lambda/consumer\"))\n\n        consumer_lambda.add_environment(\"TABLE_NAME\", demo_table.table_name)\n\n        # grant permission to lambda to read from demo table\n        demo_table.grant_read_data(consumer_lambda)\n\n        # create a Cloudwatch Event rule\n        one_minute_rule = aws_events.Rule(\n            self, \"one_minute_rule\",\n            schedule=aws_events.Schedule.rate(Duration.minutes(1)),\n        )\n\n        # Add target to Cloudwatch Event\n        one_minute_rule.add_target(aws_events_targets.LambdaFunction(producer_lambda))\n        one_minute_rule.add_target(aws_events_targets.LambdaFunction(consumer_lambda))", "language": "python"}
{"input": "CDK class InfrastructureConfiguration for AWS resource management", "output": "export class InfrastructureConfiguration extends InfrastructureConfigurationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.InfrastructureConfiguration';\n\n  /**\n   * Import an existing infrastructure configuration given its ARN.\n   */\n  public static fromInfrastructureConfigurationArn(\n    scope: Construct,\n    id: string,\n    infrastructureConfigurationArn: string,\n  ): IInfrastructureConfiguration {\n    const infrastructureConfigurationName = cdk.Stack.of(scope).splitArn(\n      infrastructureConfigurationArn,\n      cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    ).resourceName!;\n\n    class Import extends InfrastructureConfigurationBase {\n      public readonly infrastructureConfigurationArn = infrastructureConfigurationArn;\n      public readonly infrastructureConfigurationName = infrastructureConfigurationName;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing infrastructure configuration given its name. The provided name must be normalized by converting\n   * all alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromInfrastructureConfigurationName(\n    scope: Construct,\n    id: string,\n    infrastructureConfigurationName: string,\n  ): IInfrastructureConfiguration {\n    return InfrastructureConfiguration.fromInfrastructureConfigurationArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'infrastructure-configuration',\n        resourceName: infrastructureConfigurationName,\n      }),\n    );\n  }\n\n  /**\n   * Return whether the given object is an InfrastructureConfiguration.\n   */\n  public static isInfrastructureConfiguration(x: any): x is InfrastructureConfiguration {\n    return x !== null && typeof x === 'object' && INFRASTRUCTURE_CONFIGURATION_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the infrastructure configuration\n   */\n  public readonly infrastructureConfigurationArn: string;\n\n  /**\n   * The name of the infrastructure configuration\n   */\n  public readonly infrastructureConfigurationName: string;\n\n  /**\n   * The EC2 instance profile to use for the build\n   */\n  public readonly instanceProfile: iam.IInstanceProfile;\n\n  /**\n   * The role associated with the EC2 instance profile used for the build\n   */\n  public readonly role?: iam.IRole;\n\n  /**\n   * The bucket used to upload image build logs\n   */\n  public readonly logBucket?: s3.IBucket;\n\n  private readonly autoGeneratedInstanceProfileRole?: iam.IRole;\n\n  public constructor(scope: Construct, id: string, props: InfrastructureConfigurationProps = {}) {\n    super(scope, id, {\n      physicalName:\n        props.infrastructureConfigurationName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, INFRASTRUCTURE_CONFIGURATION_SYMBOL, { value: true });\n\n    this.validateInfrastructureConfigurationName();\n\n    if (props.subnetSelection && !props.vpc) {\n      throw new cdk.ValidationError('A vpc must be provided when using subnetSelection', this);\n    }\n\n    const selectedSubnets = props.vpc?.selectSubnets(props.subnetSelection);\n    if (props.vpc && selectedSubnets && selectedSubnets.subnetIds.length === 0) {\n      throw new cdk.ValidationError('No subnets matched the given subnetSelection for the provided VPC.', this);\n    }\n\n    if (props.instanceProfile && props.role) {\n      throw new cdk.ValidationError('Both an instance profile and a role cannot be provided', this);\n    }\n\n    if (!cdk.Token.isUnresolved(props.ec2InstanceTenancy)) {\n      if (props.ec2InstanceTenancy === Tenancy.HOST) {\n        if (props.ec2InstanceHostId === undefined && props.ec2InstanceHostResourceGroupArn === undefined) {\n          throw new cdk.ValidationError(\n            'ec2InstanceHostId or ec2InstanceHostResourceGroupArn must be specified when ec2InstanceTenancy is set to host',\n            this,\n          );\n        }\n      } else {\n        if (props.ec2InstanceHostId !== undefined) {\n          throw new cdk.ValidationError(\n            'ec2InstanceHostId cannot be specified unless ec2InstanceTenancy is set to host',\n            this,\n          );\n        }\n\n        if (props.ec2InstanceHostResourceGroupArn !== undefined) {\n          throw new cdk.ValidationError(\n            'ec2InstanceHostResourceGroupArn cannot be specified unless ec2InstanceTenancy is set to host',\n            this,\n          );\n        }\n      }\n    }\n\n    if (props.ec2InstanceHostId !== undefined && props.ec2InstanceHostResourceGroupArn !== undefined) {\n      throw new cdk.ValidationError(\n        'ec2InstanceHostId and ec2InstanceHostResourceGroupArn cannot be used together',\n        this,\n      );\n    }\n\n    if (props.httpPutResponseHopLimit !== undefined && props.httpPutResponseHopLimit < 1) {\n      throw new cdk.ValidationError('httpPutResponseHopLimit must be at least 1', this);\n    }\n\n    if (props.httpPutResponseHopLimit !== undefined && props.httpPutResponseHopLimit > 64) {\n      throw new cdk.ValidationError('httpPutResponseHopLimit must be at most 64', this);\n    }\n\n    if (!props.instanceProfile && !props.role) {\n      this.autoGeneratedInstanceProfileRole = new iam.Role(this, 'InstanceProfileRole', {\n        assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n        managedPolicies: [\n          iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonSSMManagedInstanceCore'),\n          iam.ManagedPolicy.fromAwsManagedPolicyName('EC2InstanceProfileForImageBuilder'),\n        ],\n      });\n      this.role = this.autoGeneratedInstanceProfileRole;\n    }\n\n    this.instanceProfile =\n      props.instanceProfile ||\n      new iam.InstanceProfile(this, 'InstanceProfile', { role: props.role ?? this.autoGeneratedInstanceProfileRole });\n\n    this.role = this.instanceProfile.role;\n    this.logBucket = props.logging?.s3Bucket;\n\n    if (this.logBucket && this.role) {\n      this.logBucket.grantPut(this.role, props.logging?.s3KeyPrefix ? `${props.logging.s3KeyPrefix}/*` : '*');\n    }\n\n    const hasPlacementOptions =\n      props.ec2InstanceAvailabilityZone !== undefined ||\n      props.ec2InstanceHostId !== undefined ||\n      props.ec2InstanceHostResourceGroupArn !== undefined ||\n      props.ec2InstanceTenancy !== undefined;\n    const placement: CfnInfrastructureConfiguration.PlacementProperty | undefined = hasPlacementOptions\n      ? {\n        ...(props.ec2InstanceAvailabilityZone !== undefined && {\n          availabilityZone: props.ec2InstanceAvailabilityZone,\n        }),\n        ...(props.ec2InstanceHostId !== undefined && { hostId: props.ec2InstanceHostId }),\n        ...(props.ec2InstanceHostResourceGroupArn !== undefined && {\n          hostResourceGroupArn: props.ec2InstanceHostResourceGroupArn,\n        }),\n        ...(props.ec2InstanceTenancy !== undefined && { tenancy: props.ec2InstanceTenancy }),\n      }\n      : undefined;\n\n    const infrastructureConfiguration = new CfnInfrastructureConfiguration(this, 'Resource', {\n      name: this.physicalName,\n      instanceProfileName: this.instanceProfile.instanceProfileName,\n      description: props.description,\n      instanceMetadataOptions: {\n        httpTokens: props.httpTokens ?? HttpTokens.REQUIRED,\n        httpPutResponseHopLimit: props.httpPutResponseHopLimit ?? 2,\n      },\n      instanceTypes: props.instanceTypes?.length\n        ? props.instanceTypes?.map((instanceType) => instanceType.toString())\n        : undefined,\n      keyPair: props.keyPair?.keyPairName,\n      ...(props.logging && {\n        logging: {\n          s3Logs: {\n            s3BucketName: props.logging?.s3Bucket.bucketName,\n            s3KeyPrefix: props.logging?.s3KeyPrefix,\n          },\n        },\n      }),\n      ...(placement && { placement }),\n      resourceTags: props.resourceTags,\n      securityGroupIds: props.securityGroups?.length\n        ? props.securityGroups?.map((securityGroup) => securityGroup.securityGroupId)\n        : undefined,\n      subnetId: props.vpc?.selectSubnets(props.subnetSelection).subnetIds[0],\n      snsTopicArn: props.notificationTopic?.topicArn,\n      tags: props.tags,\n      terminateInstanceOnFailure: props.terminateInstanceOnFailure,\n    });\n\n    this.infrastructureConfigurationName = this.getResourceNameAttribute(infrastructureConfiguration.attrName);\n    this.infrastructureConfigurationArn = this.getResourceArnAttribute(infrastructureConfiguration.attrArn, {\n      service: 'imagebuilder',\n      resource: 'infrastructure-configuration',\n      resourceName: this.physicalName,\n    });\n  }\n\n  private validateInfrastructureConfigurationName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError('The infrastructureConfigurationName cannot be longer than 128 characters', this);\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError('The infrastructureConfigurationName cannot contain spaces', this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError('The infrastructureConfigurationName cannot contain underscores', this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError('The infrastructureConfigurationName must be lowercase', this);\n    }\n  }\n\n  /**\n   * @internal\n   */\n  public _bind(options: InfrastructureConfigurationBindOptions) {\n    if (options.isContainerBuild) {\n      this.autoGeneratedInstanceProfileRole?.addManagedPolicy(\n        iam.ManagedPolicy.fromAwsManagedPolicyName('EC2InstanceProfileForImageBuilderECRContainerBuilds'),\n      );\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation, CodePipeline resources", "output": "export class CdkStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    //objects for access parameters\n    const node = this.node;\n\n    const blue_env = node.tryGetContext(\"blue_env\");\n    const green_env = node.tryGetContext(\"green_env\");\n    const app_name = node.tryGetContext(\"app_name\");\n\n    const bucket = new s3.Bucket(this, 'BlueGreenBucket', {\n      // The default removal policy is RETAIN, which means that cdk destroy will not attempt to delete\n      // the new bucket, and it will remain in your account until manually deleted. By setting the policy to\n      // DESTROY, cdk destroy will attempt to delete the bucket, but will error if the bucket is not empty.\n      removalPolicy: cdk.RemovalPolicy.DESTROY, // NOT recommended for production code\n    });\n\n    const handler = new lambda.Function(this, 'BlueGreenLambda', {\n      runtime: lambda.Runtime.PYTHON_3_6,\n      code: lambda.Code.fromAsset('resources'),\n      handler: 'blue_green.lambda_handler',\n      environment: {\n        BUCKET: bucket.bucketName\n      }\n    });\n\n    bucket.grantReadWrite(handler);\n\n    const repo = new cc.Repository(this, 'Repository', {\n      repositoryName: 'MyRepositoryName',\n    });\n\n    const pipeline = new cp.Pipeline(this, 'MyFirstPipeline');\n\n    const sourceStage = pipeline.addStage({\n      stageName: 'Source'\n    });\n\n    const sourceArtifact = new cp.Artifact('Source');\n\n    const sourceAction = new cpactions.CodeCommitSourceAction({\n      actionName: 'CodeCommit',\n      repository: repo,\n      output: sourceArtifact,\n    });\n\n    sourceStage.addAction(sourceAction);\n\n\n    const deployStage = pipeline.addStage({\n      stageName: 'Deploy'\n    });\n\n\n    const lambdaAction = new cpactions.LambdaInvokeAction({\n      actionName: 'InvokeAction',\n      lambda: handler,\n      userParameters: {\n        blueEnvironment: blue_env,\n        greenEnvironment: green_env,\n        application: app_name\n      },\n      inputs: [sourceArtifact]\n    });\n\n    deployStage.addAction(lambdaAction);\n\n\n  }\n}", "language": "typescript"}
{"input": "CDK helper function test_glue_database_created", "output": "def test_glue_database_created(template):\n    template.resource_count_is(type=\"AWS::Glue::Database\", count=1)\n\n    template.has_resource_properties(type=\"AWS::Glue::Database\",\n                                     props={\n                                         \"CatalogId\": {\n                                             \"Ref\": \"AWS::AccountId\"\n                                         },\n                                         \"DatabaseInput\": {\n                                             \"Name\": \"log-database\"\n                                         }\n                                     })", "language": "python"}
{"input": "CDK Stack that creates S3, CloudFormation, CodeBuild resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    new codebuild.Project(this, 'MyProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: ['ls'],\n          },\n        },\n      }),\n      grantReportGroupPermissions: false,\n      /// !show\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.fromAsset(this, 'MyImage', {\n          directory: path.join(__dirname, 'demo-image'),\n        }),\n      },\n      /// !hide\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, KMS resources", "output": "class CMKStack(cdk.NestedStack):\n    _key_arn_export_prefix = \"cmk-key-arn\"\n\n    def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        table_name: str,\n        key_replica_regions: List[str],\n        key_alias: str = None,\n        **kwargs,\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        key_id = kms.CfnKey(\n            self,\n            \"multi-region-cmk\",\n            key_policy={\n                \"Version\": \"2012-10-17\",\n                \"Statement\": [\n                    {\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                            \"AWS\": f\"arn:aws:iam::{self.account}:root\",\n                        },\n                        \"Action\": \"kms:*\",\n                        \"Resource\": \"*\",\n                    },\n                ],\n            },\n            description=f\"CMK for {table_name} in {self.region}\",\n            enable_key_rotation=True,\n            enabled=True,\n            multi_region=True,\n        ).attr_key_id\n\n        kms.CfnAlias(\n            self,\n            \"multi-region-cmk-alias\",\n            alias_name=key_alias\n            or f\"alias/multi-region-cmk-for-ddb-table-{table_name}\",\n            target_key_id=key_id,\n        )\n\n        self._create_cfn_output_key_arn(self.region, key_id)\n        for replica_region in key_replica_regions:\n            self._create_key_replica(replica_region, key_id)\n\n    def _create_cfn_output_key_arn(self, key_region: str, key_id: str):\n        cdk.CfnOutput(\n            self,\n            f\"{key_region}-key-arn\",\n            value=f\"arn:aws:kms:{key_region}:{self.account}:key/{key_id}\",\n            export_name=f\"{self._key_arn_export_prefix}{key_region}\",\n        )\n\n    def _create_key_replica(self, replica_region: str, key_id: str):\n        aws_sdk_call = cr.AwsSdkCall(\n            service=\"KMS\",\n            action=\"replicateKey\",\n            physical_resource_id=cr.PhysicalResourceId.of(\n                \"CustomResource::KeyReplicaCreation\"\n            ),\n            parameters={\"KeyId\": key_id, \"ReplicaRegion\": replica_region},\n        )\n\n        cr.AwsCustomResource(\n            self,\n            f\"{replica_region}-custom-resource\",\n            on_create=aws_sdk_call,\n            on_update=aws_sdk_call,\n            policy=cr.AwsCustomResourcePolicy.from_statements(\n                [\n                    iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        actions=[\"kms:*\"],\n                        resources=[\"*\"],\n                    )\n                ]\n            ),\n        )\n        self._create_cfn_output_key_arn(replica_region, key_id)\n\n    def get_key_replica_export_names(self, region: str):\n        return f\"{self._key_arn_export_prefix}{region}\"", "language": "python"}
{"input": "The data to be imported to the key value store.", "output": "class ImportSource {\n  /**\n   * An import source that exists as an object in an S3 bucket.\n   *\n   * @param bucket the S3 bucket that contains the data\n   * @param key the key within the S3 bucket that contains the data\n   */\n  public static fromBucket(bucket: s3.IBucket, key: string): ImportSource {\n    return new S3ImportSource(bucket, key);\n  }\n\n  /**\n   * An import source that exists as a local file.\n   *\n   * @param path the path to the local file\n   * @param options the configuration for the temporarily created S3 file\n   */\n  public static fromAsset(path: string, options?: s3_assets.AssetOptions): ImportSource {\n    return new AssetImportSource(path, options);\n  }\n\n  /**\n   * An import source that uses an inline string.\n   *\n   * @param data the contents of the KeyValueStore\n   */\n  public static fromInline(data: string): ImportSource {\n    return new InlineImportSource(data);\n  }\n\n  /**\n   * Called when the key value store is initialized to allow the import source to\n   * be bound to the stack.\n   *\n   * The method is primarily intended for internal use.\n   *\n   * @param scope the binding scope\n   * @internal\n   */\n  public abstract _bind(scope: Construct): CfnKeyValueStore.ImportSourceProperty;\n}", "language": "typescript"}
{"input": "An Appsync datasource backed by Elasticsearch @deprecated - use `OpenSearchDataSource`", "output": "export class ElasticsearchDataSource extends BackedDataSource {\n  constructor(scope: Construct, id: string, props: ElasticsearchDataSourceProps) {\n    super(scope, id, props, {\n      type: 'AMAZON_ELASTICSEARCH',\n      elasticsearchConfig: {\n        awsRegion: props.domain.env.region,\n        endpoint: `https://${props.domain.domainEndpoint}`,\n      },\n    });\n\n    props.domain.grantReadWrite(this);\n  }\n}", "language": "typescript"}
{"input": "CDK class SynthesizeMe for AWS resource management", "output": "class SynthesizeMe extends cdk.Stack {\n      public readonly templateFile = 'hey.json';\n\n      constructor() {\n        super(undefined as any, 'hey', {\n          synthesizer: new cdk.LegacyStackSynthesizer(),\n        });\n        this.node.addValidation({\n          validate: () => {\n            calls.push('validate');\n            return [];\n          },\n        });\n      }\n\n      public _synthesizeTemplate(session: cdk.ISynthesisSession) {\n        calls.push('synthesize');\n\n        session.assembly.addArtifact('art', {\n          type: cxschema.ArtifactType.AWS_CLOUDFORMATION_STACK,\n          properties: {\n            templateFile: 'hey.json',\n            parameters: {\n              paramId: 'paramValue',\n              paramId2: 'paramValue2',\n            },\n          },\n          environment: 'aws://unknown-account/us-east-1',\n        });\n\n        writeJson(session.assembly.outdir, 'hey.json', { hello: 123 });\n      }\n    }", "language": "typescript"}
{"input": "CDK helper function build", "output": "const build = () => {\n          if (Object.keys(typeDef.properties).length > 0) {\n            this.addPropertiesAndCreateConverter({\n              target: structType,\n              properties: typeDef.properties,\n              typeConverter: converter,\n              converterNamePrefix: `convert${eventNsName}${sanitizedName}ToEventPattern`,\n              eventNsName,\n              event,\n              typeDef,\n              addMetadata: false,\n            });\n          }\n        }", "language": "typescript"}
{"input": "SessionPinningFilter @see https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/rds-proxy.html#rds-proxy-pinning", "output": "export class SessionPinningFilter {\n  /**\n   * You can opt out of session pinning for the following kinds of application statements:\n   *\n   * - Setting session variables and configuration settings.\n   */\n  public static readonly EXCLUDE_VARIABLE_SETS = new SessionPinningFilter('EXCLUDE_VARIABLE_SETS');\n\n  /**\n   * custom filter\n   */\n  public static of(filterName: string): SessionPinningFilter {\n    return new SessionPinningFilter(filterName);\n  }\n\n  private constructor(\n    /**\n     * Filter name\n     */\n    public readonly filterName: string,\n  ) {}\n}", "language": "typescript"}
{"input": "CDK helper function httpsGet", "output": "const httpsGet = (url) => {\n            return new Promise((resolve, reject) => {\n              https.get(url, (res) => {\n                let data = '';\n  \n                res.on('data', (chunk) => {\n                  data += chunk;\n                });\n  \n                res.on('end', () => {\n                  resolve(data);\n                });\n  \n                res.on('error', (e) => {\n                  reject(e);\n                });\n              });\n            });\n          }", "language": "typescript"}
{"input": "CDK class EksMinimalCluster for AWS resource management", "output": "class EksMinimalCluster extends Construct {\n  constructor(scope: Construct, id: string, props: EksMinimalClusterProps) {\n    super(scope, id);\n\n    const clusterProps: any = {\n      vpc: props.vpc,\n      mastersRole: props.mastersRole,\n      version: eks.KubernetesVersion.V1_33,\n      kubectlProviderOptions: {\n        kubectlLayer: new KubectlV33Layer(this, 'kubectl'),\n      },\n      defaultCapacityType: eks.DefaultCapacityType.AUTOMODE,\n    };\n\n    // Add compute configuration if provided\n    if (props.compute) {\n      clusterProps.compute = props.compute;\n    }\n\n    new eks.Cluster(this, 'cluster', clusterProps);\n  }\n}", "language": "typescript"}
{"input": "CDK class Step3SourceAccount for AWS resource management", "output": "export class Step3SourceAccount extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const replicationRoleArn = new CfnParameter(this, \"replicationRoleArn\", {\n      type: \"String\",\n      description: \"The ARN of the replication role in the source account\",\n    });\n\n    const destinationKmsKeyArn = new CfnParameter(\n      this,\n      \"destinationKmsKeyArn\",\n      {\n        type: \"String\",\n        description:\n          \"The ARN of the destination KMS key in the destination account\",\n      }\n    );\n\n    const destinationS3BucketArn = new CfnParameter(\n      this,\n      \"destinationS3BucketArn\",\n      {\n        type: \"String\",\n        description: \"The ARN of the S3 bucket in the destination account\",\n      }\n    );\n\n    const sourceKmsKey = new Key(\n      this,\n      \"s3-cross-account-replication-source-key\",\n      {\n        alias: Config.sourceKmsKeyAlias,\n        description:\n          \"Key used for KMS Encryption for the source s3 bucket for cross account replication\",\n        policy: new PolicyDocument({\n          statements: [\n            new PolicyStatement({\n              sid: \"Enable IAM User Permissions\",\n              effect: Effect.ALLOW,\n              principals: [\n                new ArnPrincipal(\n                  `arn:aws:iam::${Config?.sourceAccountId}:root`\n                ),\n              ],\n              actions: [\"kms:*\"],\n              resources: [\"*\"],\n            }),\n            new PolicyStatement({\n              sid: \"Enable Replication Permissions\",\n              effect: Effect.ALLOW,\n              principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n              actions: [\"kms:Decrypt\", \"kms:DescribeKey\"],\n              resources: [\"*\"],\n            }),\n          ],\n        }),\n        enableKeyRotation: true,\n      }\n    );\n\n    // Create the source S3 bucket\n    const sourceS3Bucket = new Bucket(this, \"source-bucket-to-replicate-from\", {\n      bucketName: Config.sourceBucketName,\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n      versioned: true,\n      accessControl: BucketAccessControl.PRIVATE,\n      publicReadAccess: false,\n      blockPublicAccess: new BlockPublicAccess(BlockPublicAccess.BLOCK_ALL),\n      bucketKeyEnabled: true,\n      encryption: BucketEncryption.KMS,\n      encryptionKey: sourceKmsKey,\n      enforceSSL: true,\n    });\n\n    // allow the principal to have all admin access to bucket\n    sourceS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Set Admin Access\",\n        effect: Effect.ALLOW,\n        principals: [\n          new ArnPrincipal(`arn:aws:iam::${Config.sourceAccountId}:root`),\n        ],\n        actions: [\"s3:*\"],\n        resources: [\n          `${sourceS3Bucket.bucketArn}`,\n          `${sourceS3Bucket.bucketArn}/*`,\n        ],\n      })\n    );\n\n    sourceS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Replication Permission\",\n        effect: Effect.ALLOW,\n        principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n        actions: [\"s3:GetReplicationConfiguration\", \"s3:ListBucket\"],\n        resources: [`${sourceS3Bucket.bucketArn}`],\n      })\n    );\n\n    sourceS3Bucket.addToResourcePolicy(\n      new PolicyStatement({\n        sid: \"Get Object Versions\",\n        effect: Effect.ALLOW,\n        principals: [new ArnPrincipal(replicationRoleArn.valueAsString)],\n        actions: [\n          \"s3:GetObjectVersionForReplication\",\n          \"s3:GetObjectVersionAcl\",\n          \"s3:GetObjectVersionTagging\",\n        ],\n        resources: [`${sourceS3Bucket.bucketArn}/*`],\n      })\n    );\n\n    new CfnOutput(this, \"sourceS3BucketArn\", {\n      value: sourceS3Bucket.bucketArn,\n    });\n\n    // no high level construct for replication for S3 yet, use low level contruct for now\n    const lowLevelSourceS3Bucket = sourceS3Bucket.node\n      .defaultChild as CfnBucket;\n    lowLevelSourceS3Bucket.replicationConfiguration = {\n      role: replicationRoleArn.valueAsString,\n      rules: [\n        {\n          id: \"CrossAccountReplicationRule\",\n          status: \"Enabled\",\n          destination: {\n            bucket: destinationS3BucketArn.valueAsString,\n            accessControlTranslation: {\n              owner: \"Destination\",\n            },\n            account: Config?.destinationAccountId,\n            encryptionConfiguration: {\n              replicaKmsKeyId: destinationKmsKeyArn.valueAsString,\n            },\n          },\n          priority: 1,\n          deleteMarkerReplication: {\n            status: \"Disabled\",\n          },\n          filter: {\n            prefix: \"\",\n          },\n          sourceSelectionCriteria: {\n            sseKmsEncryptedObjects: {\n              status: \"Enabled\",\n            },\n          },\n        },\n      ],\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class EventInvokeConfig for AWS resource management", "output": "export class EventInvokeConfig extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-lambda.EventInvokeConfig';\n\n  constructor(scope: Construct, id: string, props: EventInvokeConfigProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.maxEventAge && (props.maxEventAge.toSeconds() < 60 || props.maxEventAge.toSeconds() > 21600)) {\n      throw new ValidationError('`maximumEventAge` must represent a `Duration` that is between 60 and 21600 seconds.', this);\n    }\n\n    if (props.retryAttempts && (props.retryAttempts < 0 || props.retryAttempts > 2)) {\n      throw new ValidationError('`retryAttempts` must be between 0 and 2.', this);\n    }\n\n    new CfnEventInvokeConfig(this, 'Resource', {\n      destinationConfig: props.onFailure || props.onSuccess\n        ? {\n          ...props.onFailure ? { onFailure: props.onFailure.bind(this, props.function, { type: DestinationType.FAILURE }) } : {},\n          ...props.onSuccess ? { onSuccess: props.onSuccess.bind(this, props.function, { type: DestinationType.SUCCESS }) } : {},\n        }\n        : undefined,\n      functionName: props.function.functionName,\n      maximumEventAgeInSeconds: props.maxEventAge && props.maxEventAge.toSeconds(),\n      maximumRetryAttempts: props.retryAttempts ?? undefined,\n      qualifier: props.qualifier || '$LATEST',\n    });\n  }\n}", "language": "typescript"}
{"input": "Factory class for instantiating Gateway Protocols", "output": "class GatewayProtocol {\n  /**\n   * Create an MCP protocol configuration\n   * @param props - Optional MCP configuration properties\n   * @returns IGatewayProtocolConfig configured for MCP\n   */\n  public static mcp(props?: McpConfiguration): IGatewayProtocolConfig {\n    return new McpProtocolConfiguration(props);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, Secrets Manager, CloudFormation operations", "output": "const checkRotationNotSet = (automaticallyAfter: Duration) => {\n        // GIVEN\n        const localStack = new cdk.Stack();\n        const secret = new secretsmanager.Secret(localStack, 'Secret');\n        const rotationLambda = new lambda.Function(localStack, 'Lambda', {\n          runtime: lambda.Runtime.NODEJS_LATEST,\n          code: lambda.Code.fromInline('export.handler = event => event;'),\n          handler: 'index.handler',\n        });\n\n        // WHEN\n        new secretsmanager.RotationSchedule(localStack, 'RotationSchedule', {\n          secret,\n          rotationLambda,\n          automaticallyAfter,\n        });\n\n        // THEN\n        Template.fromStack(localStack).hasResourceProperties('AWS::SecretsManager::RotationSchedule', Match.objectEquals({\n          SecretId: { Ref: 'SecretA720EF05' },\n          RotationLambdaARN: {\n            'Fn::GetAtt': [\n              'LambdaD247545B',\n              'Arn',\n            ],\n          },\n        }));\n      }", "language": "typescript"}
{"input": "CDK class S3DockerfileDataFromBucketKey for AWS resource management", "output": "class S3DockerfileDataFromBucketKey extends S3DockerfileData {\n  public constructor(bucket: s3.IBucket, key: string) {\n    super(bucket, key);\n  }\n}", "language": "typescript"}
{"input": "CDK class CnameInstance for AWS resource management", "output": "export class CnameInstance extends InstanceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicediscovery.CnameInstance';\n  /**\n   * The Id of the instance\n   */\n  public readonly instanceId: string;\n\n  /**\n   * The Cloudmap service to which the instance is registered.\n   */\n  public readonly service: IService;\n\n  /**\n   * The domain name returned by DNS queries for the instance\n   */\n  public readonly cname: string;\n\n  constructor(scope: Construct, id: string, props: CnameInstanceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.service.namespace.type === NamespaceType.HTTP) {\n      throw new ValidationError('Namespace associated with Service must be a DNS Namespace.', this);\n    }\n\n    if (props.service.dnsRecordType !== DnsRecordType.CNAME) {\n      throw new ValidationError('A `CnameIntance` can only be used with a service using a `CNAME` record.', this);\n    }\n\n    const resource = new CfnInstance(this, 'Resource', {\n      instanceId: props.instanceId || this.uniqueInstanceId(),\n      serviceId: props.service.serviceId,\n      instanceAttributes: {\n        AWS_INSTANCE_CNAME: props.instanceCname,\n        ...props.customAttributes,\n      },\n    });\n\n    this.service = props.service;\n    this.instanceId = resource.ref;\n    this.cname = props.instanceCname;\n  }\n}", "language": "typescript"}
{"input": "Specify a test that the canary should run", "output": "export class Test {\n  /**\n   * Specify a custom test with your own code\n   *\n   * @returns `Test` associated with the specified Code object\n   * @param options The configuration options\n   */\n  public static custom(options: CustomTestOptions): Test {\n    return new Test(options.code, options.handler);\n  }\n\n  /**\n   * Construct a Test property\n   *\n   * @param code The code that the canary should run\n   * @param handler The handler of the canary\n   */\n  private constructor(public readonly code: Code, public readonly handler: string) {\n  }\n}", "language": "typescript"}
{"input": "CDK class ResourceWithLBDependency for AWS resource management", "output": "class ResourceWithLBDependency extends cdk.CfnResource {\n  constructor(scope: constructs.Construct, id: string, targetGroup: elbv2.ITargetGroup) {\n    super(scope, id, { type: 'Test::Resource' });\n    this.node.addDependency(targetGroup.loadBalancerAttached);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, WAF resources", "output": "class S3SnsSqsLambdaChainStack(Stack):\n\n  def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n    super().__init__(scope, construct_id)\n\n    lambda_dir = kwargs[\"lambda_dir\"]\n    LAMBDA_TIMEOUT = 30\n    \n    # Note: A dead-letter queue is optional but it helps capture any failed messages\n    dlq = sqs.Queue(\n      self,\n      id=\"dead_letter_queue_id\",\n      retention_period=Duration.days(7)\n    )\n    dead_letter_queue = sqs.DeadLetterQueue(\n      max_receive_count=1,\n      queue=dlq\n    )\n\n    upload_queue = sqs.Queue(\n      self,\n      id=\"sample_queue_id\",\n      dead_letter_queue=dead_letter_queue,\n      visibility_timeout = Duration.seconds(LAMBDA_TIMEOUT * 6)\n    )\n\n    sqs_subscription = sns_subs.SqsSubscription(\n      upload_queue,\n      raw_message_delivery=True\n    )\n\n    upload_event_topic = sns.Topic(\n      self,\n      id=\"sample_sns_topic_id\"\n    )\n\n    # This binds the SNS Topic to the SQS Queue\n    upload_event_topic.add_subscription(sqs_subscription)\n\n    # Note: Lifecycle Rules are optional but are included here to keep costs\n    #       low by cleaning up old files or moving them to lower cost storage options\n    s3_bucket = s3.Bucket(\n      self,\n      id=\"sample_bucket_id\",\n      block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n      versioned=True,\n      lifecycle_rules=[\n        s3.LifecycleRule(\n          enabled=True,\n          expiration=Duration.days(365),\n          transitions=[\n            s3.Transition(\n              storage_class=s3.StorageClass.INFREQUENT_ACCESS,\n              transition_after=Duration.days(30)\n            ),\n            s3.Transition(\n              storage_class=s3.StorageClass.GLACIER,\n              transition_after=Duration.days(90)\n            ),\n          ]\n        )\n      ]\n    )\n\n    # Note: If you don't specify a filter all uploads will trigger an event.\n    #       Also, modifying the event type will handle other object operations\n    # This binds the S3 bucket to the SNS Topic\n    s3_bucket.add_event_notification(\n      s3.EventType.OBJECT_CREATED_PUT,\n      s3n.SnsDestination(upload_event_topic),\n      s3.NotificationKeyFilter(prefix=\"uploads\", suffix=\".csv\")\n    )\n\n    function = _lambda.Function(self, \"lambda_function\",\n                                runtime=_lambda.Runtime.PYTHON_3_9,\n                                handler=\"lambda_function.handler\",\n                                code=_lambda.Code.from_asset(path=lambda_dir),\n                                timeout = Duration.seconds(LAMBDA_TIMEOUT)\n                               )\n\n    # This binds the lambda to the SQS Queue\n    invoke_event_source = lambda_events.SqsEventSource(upload_queue)\n    function.add_event_source(invoke_event_source)\n\n    # Examples of CloudFormation outputs\n    CfnOutput(\n      self,\n      \"UploadFileToS3Example\",\n      value=\"aws s3 cp <local-path-to-file> s3://{}/\".format(s3_bucket.bucket_name),\n      description=\"Upload a file to S3 (using AWS CLI) to trigger the SQS chain\",\n    )\n    CfnOutput(\n      self,\n      \"UploadSqsQueueUrl\",\n      value=upload_queue.queue_url,\n      description=\"Link to the SQS Queue triggered on S3 uploads\",\n    )\n    CfnOutput(\n      self,\n      \"LambdaFunctionName\",\n      value=function.function_name,\n    )\n    CfnOutput(\n      self,\n      \"LambdaFunctionLogGroupName\",\n      value=function.log_group.log_group_name,\n    )", "language": "python"}
{"input": "Game content from an S3 archive.", "output": "export class S3Content extends Content {\n  constructor(private readonly bucket: s3.IBucket, private key: string, private objectVersion?: string) {\n    super();\n    if (!bucket.bucketName) {\n      throw new Error('bucketName is undefined for the provided bucket');\n    }\n  }\n\n  public bind(_scope: Construct, role: iam.IRole): ContentConfig {\n    // Adding permission to access specific content\n    role.addToPrincipalPolicy(new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      resources: [this.bucket.arnForObjects(this.key)],\n      actions: ['s3:GetObject', 's3:GetObjectVersion'],\n    }));\n\n    return {\n      s3Location: {\n        bucketName: this.bucket.bucketName,\n        objectKey: this.key,\n        objectVersion: this.objectVersion,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "To set analytics config to UserPoolClient with Application ID, External ID, and Role ARN", "output": "class TestStack2 extends Stack {\n  public readonly userPool: UserPool;\n  public readonly client: UserPoolClient;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const pinpointApp = new CfnApp(this, 'PinpointApp', {\n      name: 'SamplePinpointApp',\n    });\n    pinpointApp.applyRemovalPolicy(RemovalPolicy.DESTROY);\n\n    const role = new Role(this, 'Role', {\n      assumedBy: new ServicePrincipal('cognito-idp.amazonaws.com'),\n    });\n    role.addToPolicy(new PolicyStatement({\n      actions: ['mobiletargeting:*'],\n      resources: ['*'],\n    }));\n\n    this.userPool = new UserPool(this, 'Pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    this.client = this.userPool.addClient('client', {\n      generateSecret: true,\n      analytics: {\n        applicationId: pinpointApp.ref,\n        externalId: role.roleId,\n        role,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class OnlyS3ManagedEncryptionTest for AWS resource management", "output": "class OnlyS3ManagedEncryptionTest extends core.Stack {\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n    this.tableBucket = new s3tables.TableBucket(this, id, {\n      tableBucketName: 'integ-tb-s3-managed-encryption-type-only',\n      encryption: s3tables.TableBucketEncryption.S3_MANAGED,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n\n  public validateAssertions(integ: IntegTest) {\n    const encryptionConfig = integ.assertions.awsApiCall('@aws-sdk/client-s3tables', 'GetTableBucketEncryptionCommand', {\n      tableBucketARN: this.tableBucket.tableBucketArn,\n    });\n\n    encryptionConfig.expect(ExpectedResult.objectLike({\n      encryptionConfiguration: {\n        sseAlgorithm: 'AES256',\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "Helper function to validate a step's inference config", "output": "const validateStep = (step: PromptStepConfigBase | undefined, stepName: string) => {\n      if (step) {\n        // Check for foundation model in non-ROUTING_CLASSIFIER steps\n        if ('foundationModel' in step && step.stepType !== AgentStepType.ROUTING_CLASSIFIER) {\n          errors.push('Foundation model can only be specified for ROUTING_CLASSIFIER step type');\n        }\n\n        const inferenceErrors = this.validateInferenceConfig(step.inferenceConfig);\n        if (inferenceErrors.length > 0) {\n          errors.push(`${stepName} step: ${inferenceErrors.join(', ')}`);\n        }\n      }\n    }", "language": "typescript"}
{"input": "CDK class MutableImport for AWS resource management", "output": "class MutableImport extends SecurityGroupBase {\n      public securityGroupId = securityGroupId;\n      public allowAllOutbound = options.allowAllOutbound ?? true;\n      public allowAllIpv6Outbound = options.allowAllIpv6Outbound ?? false;\n\n      public addEgressRule(peer: IPeer, connection: Port, description?: string, remoteRule?: boolean) {\n        // Only if allowAllOutbound has been disabled\n        if (options.allowAllOutbound === false) {\n          super.addEgressRule(peer, connection, description, remoteRule);\n        }\n      }\n    }", "language": "typescript"}
{"input": "CDK class MustIgnoreSNK for AWS resource management", "output": "export class MustIgnoreSNK extends ValidationRule {\n  public readonly name = 'ignore/strong-name-key';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldContain(this.name, pkg, '.npmignore', '*.snk');\n    fileShouldContain(this.name, pkg, '.gitignore', '*.snk');\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for CloudFormation operations", "output": "def __init__(\n        self,\n        scope: Construct,\n        id: str,\n        table_name: str,\n        replication_regions: List[str],\n        key_alias: str = None,\n        **kwargs\n    ) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        cmk_stack = CMKStack(\n            self,\n            \"cmk-stack\",\n            table_name=table_name,\n            key_replica_regions=replication_regions,\n            key_alias=key_alias,\n        )\n\n        ddb_stack = DynamoDBStack(\n            self,\n            \"ddb-stack\",\n            table_name=table_name,\n            table_replica_regions=[\n                {\n                    \"region\": region,\n                    \"key_export_name\": cmk_stack.get_key_replica_export_names(region),\n                }\n                for region in [self.region, *replication_regions]\n            ],\n        )\n        ddb_stack.add_dependency(cmk_stack)", "language": "python"}
{"input": "CDK helper function for Lambda, EC2 operations", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        ################################################################################\n        # VPC\n        vpc = ec2.Vpc(self, \"SvlCTCWLVpc\")\n        es_sec_grp = ec2.SecurityGroup(\n            self,\n            \"SvlCTCWLOpenSearchSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"SvlCTCWLSecGrp\",\n        )\n        es_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(80))\n        es_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(443))\n\n        endpoint = opensearchserverless.CfnVpcEndpoint(\n            self,\n            \"SvlCTCWLEndpoint\",\n            name=\"svlctcwlendpoint\",\n            vpc_id=vpc.vpc_id,\n            security_group_ids=[es_sec_grp.security_group_id],\n            subnet_ids=[s.subnet_id for s in vpc.public_subnets],\n        )\n\n        ###############################################################################\n        # Amazon OpenSearch Serverless collection\n        network_policy = NETWORKPOLICY.replace(\"VPCENDPOINTID\", endpoint.attr_id)\n        net = opensearchserverless.CfnSecurityPolicy(\n            self,\n            \"SvlCTCWLNetwork\",\n            name=\"svlctcwlnetwork\",\n            description=f\"Open access for {COLLECTION_NAME}\",\n            type=\"network\",\n            policy=network_policy,\n        )\n        print(\"Network Policy attached to OpenSearch Collection\", net.name)\n        sec = opensearchserverless.CfnSecurityPolicy(\n            self,\n            \"SvlCTCWLEncryption\",\n            name=\"svlctcwlencryption\",\n            description=f\"AWS Owned key policy for {COLLECTION_NAME}\",\n            type=\"encryption\",\n            policy=ENCRYPTIONPOLICY,\n        )\n\n        col = opensearchserverless.CfnCollection(\n            self, COLLECTION_NAME, name=COLLECTION_NAME, type=\"TIMESERIES\"\n        )\n        col.add_dependency(sec)\n\n        ###################################################################\n        # Lambda for subscription filter\n        subscription_filter_lambda = lambda_.Function(\n            self,\n            \"StreamCTCWLtoOSSLambda\",\n            function_name=\"bulk_ingest_handler\",\n            runtime=lambda_.Runtime.PYTHON_3_9,\n            handler=\"index.handler\",\n            vpc=vpc,\n            memory_size=1024,\n            timeout=Duration.minutes(5),\n            code=lambda_.Code.from_asset('lambda')\n        )\n\n        # Load Amazon OpenSearch Service Collection to env variable\n        collection_endpoint = col.attr_collection_endpoint.replace(\"https://\", \"\")\n        print(f\"\\n\\nCollection endpoint: {collection_endpoint}\\n\")\n        subscription_filter_lambda.add_environment(\n            \"COLLECTION_ENDPOINT\", collection_endpoint\n        )\n        subscription_filter_lambda.add_environment(\"REGION\", self.region)\n        subscription_filter_lambda.add_to_role_policy(\n            iam.PolicyStatement(actions=[\"aoss:*\"], resources=[\"*\"])\n        )\n        subscription_filter_lambda.add_to_role_policy(\n            iam.PolicyStatement(actions=[\"logs:*\"], resources=[\"*\"])\n        )\n        subscription_filter_lambda.add_environment(\"INDEX_NAME\", INDEX_NAME)\n        #################################################################################\n        # The data access policy needs the lambda role ARN to allow writing.\n        dap = DATAPOLICY.replace(\n            \"LAMBDAROLEARN\", subscription_filter_lambda.role.role_arn\n        )\n        dat = opensearchserverless.CfnAccessPolicy(\n            self,\n            \"SvlCTCWLData\",\n            name=\"svlctcwldata\",\n            type=\"data\",\n            description=f\"Data access for {COLLECTION_NAME}\",\n            policy=dap,\n        )\n        print(\"Data access for collection is created\", dat.name)\n        ################################################################################\n        # CWL Log Group\n        log_group = cwl.LogGroup(\n            self,\n            \"SvlCTCWLLogGroup\",\n            log_group_name=LOG_GROUP_NAME,\n            retention=CWL_RETENTION,\n            removal_policy=RemovalPolicy.DESTROY,\n        )\n\n        ################################################################################\n        # CloudTrail trail\n        trail = ct.Trail(\n            self,\n            \"SvlCTCWLTrail\",\n            send_to_cloud_watch_logs=True,\n            cloud_watch_log_group=log_group,\n        )\n        print(\"CloudTrail is created\", trail._physical_name)\n\n        ################################################################################\n        # Set up subscription filter\n        subscription_filter = cwl.SubscriptionFilter(\n            self,\n            \"SvlCTCWLSubFilter\",\n            log_group=log_group,\n            destination=cwl_destinations.LambdaDestination(subscription_filter_lambda),\n            filter_pattern=cwl.FilterPattern.all_events(),\n        )\n        print(\n            \"Subscription Filter for CloudTrail is created\",\n            subscription_filter._physical_name,\n        )", "language": "python"}
{"input": "There must be a README.md file.", "output": "export class ReadmeFile extends ValidationRule {\n  public readonly name = 'package-info/README.md';\n\n  public validate(pkg: PackageJson): void {\n    const readmeFile = path.join(pkg.packageRoot, 'README.md');\n\n    const scopes = pkg.json['cdk-build'] && pkg.json['cdk-build'].cloudformation;\n    if (!scopes) {\n      return;\n    }\n    // elasticsearch is renamed to opensearch service, so its readme does not follow these rules\n    if (pkg.packageName === '@aws-cdk/core' || pkg.packageName === '@aws-cdk/aws-elasticsearch') {\n      return;\n    }\n    const scope: string = typeof scopes === 'string' ? scopes : scopes[0];\n    const serviceName = AWS_SERVICE_NAMES[scope];\n\n    // If this is a 'cfn-only' package, we fix the README to specific file contents, and\n    // don't do any other checks.\n    if (pkg.json.maturity === 'cfn-only') {\n      fileShouldBe(this.name, pkg, 'README.md', cfnOnlyReadmeContents({\n        cfnNamespace: scope,\n        packageName: pkg.packageName,\n      }));\n      return;\n    }\n\n    // Otherwise, the cfn-specific disclaimer in it MUST NOT exist.\n    const disclaimerRegex = beginEndRegex('CFNONLY DISCLAIMER');\n    const currentReadme = readIfExists(readmeFile);\n    if (currentReadme && disclaimerRegex.test(currentReadme)) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'README must not include CFNONLY DISCLAIMER section',\n        fix: () => fs.writeFileSync(readmeFile, currentReadme.replace(disclaimerRegex, '')),\n      });\n    }\n\n    const headline = serviceName && `${serviceName} Construct Library`;\n\n    if (!fs.existsSync(readmeFile)) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'There must be a README.md file at the root of the package',\n        fix: () => fs.writeFileSync(\n          readmeFile,\n          [\n            `# ${headline || pkg.json.description}`,\n            'This module is part of the[AWS Cloud Development Kit](https://github.com/aws/aws-cdk) project.',\n          ].join('\\n'),\n        ),\n      });\n    } else if (headline) {\n      const requiredFirstLine = `# ${headline}`;\n      const [firstLine, ...rest] = fs.readFileSync(readmeFile, { encoding: 'utf8' }).split('\\n');\n      if (firstLine !== requiredFirstLine) {\n        pkg.report({\n          ruleName: this.name,\n          message: `The title of the README.md file must be \"${headline}\"`,\n          fix: () => fs.writeFileSync(readmeFile, [requiredFirstLine, ...rest].join('\\n')),\n        });\n      }\n    }\n  }\n}\n\n/**\n * All packages must have a \"maturity\" declaration.\n *\n * The banner in the README must match the package maturity.\n *\n * As a way to seed the settings, if 'maturity' is missing but can\n * be auto-derived from 'stability', that will be the fix (otherwise\n * there is no fix).\n */\nexport class MaturitySetting extends ValidationRule {\n  public readonly name = 'package-info/maturity';\n\n  public validate(pkg: PackageJson): void {\n    if (pkg.json.private) {\n      // Does not apply to private packages!\n      return;\n    }\n\n    if (pkg.json.features) {\n      // Skip this in favour of the FeatureStabilityRule.\n      return;\n    }\n\n    let maturity = pkg.json.maturity as string | undefined;\n    const stability = pkg.json.stability as string | undefined;\n    if (!maturity) {\n      let fix;\n      if (stability && ['stable', 'deprecated'].includes(stability)) {\n        // We can autofix!\n        fix = () => pkg.json.maturity = stability;\n        maturity = stability;\n      }\n\n      pkg.report({\n        ruleName: this.name,\n        message: `Package is missing \"maturity\" setting (expected one of ${Object.keys(MATURITY_TO_STABILITY)})`,\n        fix,\n      });\n    }\n\n    if (pkg.json.deprecated && maturity !== 'deprecated') {\n      pkg.report({\n        ruleName: this.name,\n        message: `Package is deprecated, but is marked with maturity \"${maturity}\"`,\n        fix: () => pkg.json.maturity = 'deprecated',\n      });\n      maturity = 'deprecated';\n    }\n\n    const packageLevels = this.determinePackageLevels(pkg);\n\n    const hasL1s = packageLevels.some(level => level === 'l1');\n    const hasL2s = packageLevels.some(level => level === 'l2');\n    if (hasL2s) {\n      // validate that a package that contains L2s does not declare a 'cfn-only' maturity\n      if (maturity === 'cfn-only') {\n        pkg.report({\n          ruleName: this.name,\n          message: \"Package that contains any L2s cannot declare a 'cfn-only' maturity\",\n          fix: () => pkg.json.maturity = 'experimental',\n        });\n      }\n    } else if (hasL1s) {\n      // validate that a package that contains only L1s declares a 'cfn-only' maturity\n      if (maturity !== 'cfn-only') {\n        pkg.report({\n          ruleName: this.name,\n          message: \"Package that contains only L1s cannot declare a maturity other than 'cfn-only'\",\n          fix: () => pkg.json.maturity = 'cfn-only',\n        });\n      }\n    }\n\n    if (maturity) {\n      this.validateReadmeHasBanner(pkg, maturity, packageLevels);\n    }\n  }\n\n  private validateReadmeHasBanner(pkg: PackageJson, maturity: string, levelsPresent: string[]) {\n    if (pkg.packageName === '@aws-cdk/aws-elasticsearch') {\n      // Special case for elasticsearch, which is labeled as stable in package.json\n      // but all APIs are now marked 'deprecated'\n      return;\n    }\n\n    const badge = this.readmeBadge(maturity, levelsPresent);\n    if (!badge) {\n      // Somehow, we don't have a badge for this stability level\n      return;\n    }\n    const readmeFile = path.join(pkg.packageRoot, 'README.md');\n    if (!fs.existsSync(readmeFile)) {\n      // Presence of the file is asserted by another rule\n      return;\n    }\n\n    const readmeContent = fs.readFileSync(readmeFile, { encoding: 'utf8' });\n    const badgeRegex = toRegExp(badge);\n    if (!badgeRegex.test(readmeContent)) {\n      // Removing a possible old, now invalid stability indication from the README.md before adding a new one\n      const [title, ...body] = readmeContent.replace(/<!--BEGIN STABILITY BANNER-->(?:.|\\n)+<!--END STABILITY BANNER-->\\n+/m, '').split('\\n');\n      pkg.report({\n        ruleName: this.name,\n        message: `Missing stability banner for ${maturity} in README.md file`,\n        fix: () => fs.writeFileSync(readmeFile, [title, badge, ...body].join('\\n')),\n      });\n    }\n  }", "language": "typescript"}
{"input": "Abstract base class for tools that can be used by the model.", "output": "class Tool {\n  /**\n   * Creates a function tool.\n   */\n  public static function(props: FunctionToolProps): Tool {\n    return new FunctionTool(props);\n  }\n\n  /**\n   * Renders the tool as a CloudFormation property.\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public abstract _render(): CfnPrompt.ToolProperty;\n}", "language": "typescript"}
{"input": "Helper class for referencing and uploading component data", "output": "class ComponentData {\n  /**\n   * Uploads component data from a local file to S3 to use as the component data\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param path The local path to the component data file\n   * @param options S3 asset upload options\n   */\n  public static fromAsset(\n    scope: Construct,\n    id: string,\n    path: string,\n    options: s3assets.AssetOptions = {},\n  ): S3ComponentData {\n    const asset = new s3assets.Asset(scope, id, { ...options, path });\n    return new S3ComponentDataFromAsset(asset);\n  }\n\n  /**\n   * References component data from a pre-existing S3 object\n   *\n   * @param bucket The S3 bucket where the component data is stored\n   * @param key The S3 key of the component data file\n   */\n  public static fromS3(bucket: s3.IBucket, key: string): S3ComponentData {\n    return new S3ComponentDataFromBucketKey(bucket, key);\n  }\n\n  /**\n   * Uses an inline JSON object as the component data\n   *\n   * @param data An inline JSON object representing the component data\n   */\n  public static fromJsonObject(data: { [key: string]: any }): ComponentData {\n    const inlineData = yaml.stringify(data, { indent: 2 });\n    return new InlineComponentData(inlineData);\n  }\n\n  /**\n   * Uses an inline JSON object as the component data, using the ComponentDocument interface\n   *\n   * @param data An inline JSON object representing the component data\n   */\n  public static fromComponentDocumentJsonObject(data: ComponentDocument): ComponentData {\n    const { name, description, schemaVersion, constants, parameters, phases } = data;\n    return this.fromJsonObject({\n      ...(name !== undefined && { name }),\n      ...(description !== undefined && { description }),\n      schemaVersion: schemaVersion,\n      ...(constants !== undefined && {\n        constants: Object.entries(constants).map(([constantName, value]) => ({\n          [constantName]: { type: value.type, value: value.value },\n        })),\n      }),\n      ...(parameters !== undefined && {\n        parameters: Object.entries(parameters).map(([parameterName, value]) => ({ [parameterName]: value })),\n      }),\n      phases: phases.map((phase) => ({\n        name: phase.name,\n        steps: phase.steps.map((step) => ({\n          name: step.name,\n          action: step.action,\n          ...(step.onFailure !== undefined && { onFailure: step.onFailure }),\n          ...(step.timeout !== undefined && { timeoutSeconds: step.timeout.toSeconds() }),\n          ...(step.if !== undefined && { if: step.if.ifCondition }),\n          ...(step.loop !== undefined && { loop: step.loop }),\n          inputs: step.inputs.inputs,\n        })),\n      })),\n    });\n  }\n\n  /**\n   * Uses an inline JSON/YAML string as the component data\n   *\n   * @param data An inline JSON/YAML string representing the component data\n   */\n  public static fromInline(data: string): ComponentData {\n    return new InlineComponentData(data);\n  }\n\n  /**\n   * The rendered component data value, for use in CloudFormation.\n   * - For inline components, data is the component text\n   * - For S3-backed components, uri is the S3 URL\n   */\n  abstract render(): ComponentDataConfig;\n}", "language": "typescript"}
{"input": "CDK class NoStarDeps for AWS resource management", "output": "export class NoStarDeps extends ValidationRule {\n  public readonly name = 'dependencies/no-star';\n\n  public validate(pkg: PackageJson) {\n    reportStarDeps(this.name, pkg.json.depedencies);\n    reportStarDeps(this.name, pkg.json.devDependencies);\n\n    function reportStarDeps(ruleName: string, deps?: any) {\n      deps = deps || {};\n      Object.keys(deps).forEach(d => {\n        if (deps[d] === '*') {\n          pkg.report({\n            ruleName,\n            message: `star dependency not allowed for ${d}`,\n          });\n        }\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class EventBridgeDataSource for AWS resource management", "output": "export class EventBridgeDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.EventBridgeDataSource';\n\n  constructor(scope: Construct, id: string, props: EventBridgeDataSourceProps) {\n    super(scope, id, props, {\n      type: 'AMAZON_EVENTBRIDGE',\n      eventBridgeConfig: {\n        eventBusArn: props.eventBus.eventBusArn,\n      },\n    });\n    props.eventBus.grantPutEventsTo(this);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, VPC, IAM resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const params = new ParameterGroup(this, 'Params', {\n      engine: DatabaseClusterEngine.auroraMysql({\n        version: AuroraMysqlEngineVersion.VER_3_07_1,\n      }),\n      description: 'A nice parameter group',\n      parameters: {\n        character_set_database: 'utf8mb4',\n      },\n    });\n\n    const kmsKey = new kms.Key(this, 'DbSecurity');\n\n    const instanceProps = {\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.MEDIUM),\n      isFromLegacyInstanceProps: true,\n      preferredMaintenanceWindow: 'Sat:22:15-Sat:22:45',\n    };\n\n    const readers = featureFlag\n      ? [\n        ClusterInstance.provisioned('Instance2', {\n          ...instanceProps,\n          parameters: {},\n        }),\n        ClusterInstance.provisioned('Instance3', {\n          ...instanceProps,\n          parameters: {},\n        }),\n      ]\n      : [\n        ClusterInstance.provisioned('Instance2', {\n          ...instanceProps,\n          parameters: {},\n        }),\n      ];\n\n    const cluster = new DatabaseCluster(this, 'Database', {\n      engine: DatabaseClusterEngine.auroraMysql({\n        version: AuroraMysqlEngineVersion.VER_3_07_1,\n      }),\n      credentials: Credentials.fromUsername('admin', { password: cdk.SecretValue.unsafePlainText('7959866cacc02c2d243ecfe177464fe6') }),\n      vpcSubnets: { subnetType: ec2.SubnetType.PUBLIC },\n      vpc,\n      writer: ClusterInstance.provisioned('Instance1', {\n        ...instanceProps,\n      }),\n      readers: readers,\n      parameterGroup: params,\n      storageEncryptionKey: kmsKey,\n      autoMinorVersionUpgrade: false,\n      deleteAutomatedBackups: false,\n    });\n\n    cluster.connections.allowDefaultPortFromAnyIpv4('Open to the world');\n\n    const role = new iam.Role(this, 'ClusterIamAccess', {\n      assumedBy: new iam.ServicePrincipal('ecs-tasks.amazonaws.com'),\n    });\n    const clusterIamAuthArn = this.formatArn({\n      service: 'rds-db',\n      resource: `dbuser:${cluster.clusterResourceIdentifier}`,\n      resourceName: 'db_user',\n    });\n    role.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        actions: ['rds-db:connect'],\n        resources: [clusterIamAuthArn],\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, EC2, VPC, IAM resources", "output": "export class SecretsManagerCustomRotationStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const clusterId = \"redis-demo-cluster\";\n\n    const vpc = new ec2.Vpc(this, \"Vpc\", {\n      subnetConfiguration: [\n        {\n          cidrMask: 24,\n          name: \"Private\",\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n        }\n      ]\n    });\n\n    const privateSubnets = vpc.isolatedSubnets.map((subnet) => subnet.subnetId);\n\n    const ecSecurityGroup = new ec2.SecurityGroup(this, \"ElastiCacheSG\", {\n      vpc: vpc,\n      description:\n        \"SecurityGroup associated with the ElastiCache Redis Cluster\",\n    });\n\n    ecSecurityGroup.addIngressRule(\n      ec2.Peer.anyIpv4(),\n      ec2.Port.tcp(6379),\n      \"Redis ingress 6379\"\n    );\n\n    const rotatorSecurityGroup = new ec2.SecurityGroup(this, \"RotatorSG\", {\n      vpc: vpc,\n      description: \"SecurityGroup for rotator function\",\n    });\n\n    rotatorSecurityGroup.addIngressRule(\n      ec2.Peer.anyIpv4(),\n      ec2.Port.allTraffic(),\n      \"All port inbound\"\n    );\n\n    const elasticacheVpcEndpoint = new ec2.InterfaceVpcEndpoint(this, 'ElastiCache VPC Endpoint', {\n      vpc,\n      service: new ec2.InterfaceVpcEndpointService('com.amazonaws.'+Stack.of(this).region+'.elasticache', 443),\n      privateDnsEnabled: true,\n      open: true,\n      subnets: {\n        subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n      },\n      securityGroups:[rotatorSecurityGroup]\n    });\n\n    const secretsManagerVpcEndpoint = vpc.addInterfaceEndpoint('SecretsManagerEndpoint', {\n      service: ec2.InterfaceVpcEndpointAwsService.SECRETS_MANAGER\n    });\n\n    Tags.of(elasticacheVpcEndpoint).add('Name', 'elasticache')\n    \n    const ecSubnetGroup = new elasticache.CfnSubnetGroup(\n      this,\n      \"ElastiCacheSubnetGroup\",\n      {\n        description: \"Elasticache Subnet Group\",\n        subnetIds: privateSubnets,\n      }\n    );\n\n    const secret = new secretsmanager.Secret(this, \"RedisAuth\", {\n      generateSecretString: {\n        secretStringTemplate: JSON.stringify({ replicationGroupId: clusterId }),\n        generateStringKey: \"authToken\",\n        excludeCharacters: \"@%*()_+=`~{}|[]\\\\:\\\";'?,./\",\n      },\n    });\n\n    const ecClusterReplicationGroup = new elasticache.CfnReplicationGroup(\n      this,\n      \"RedisReplicationGroup\",\n      {\n        replicationGroupDescription: \"RedisReplicationGroup-RBAC-Demo\",\n        replicationGroupId: clusterId,\n        atRestEncryptionEnabled: true,\n        multiAzEnabled: true,\n        cacheNodeType: \"cache.m4.large\",\n        cacheSubnetGroupName: ecSubnetGroup.ref,\n        engine: \"Redis\",\n        engineVersion: \"6.x\",\n        numNodeGroups: 1,\n        replicasPerNodeGroup: 1,\n        securityGroupIds: [ecSecurityGroup.securityGroupId],\n        transitEncryptionEnabled: true,\n        authToken: secret.secretValueFromJson(\"authToken\").toString(),\n      }\n    );\n\n    const rotatorRole = new iam.Role(this, \"rotatorRole\", {\n      assumedBy: new iam.ServicePrincipal(\"lambda.amazonaws.com\"),\n      description: \"Role to be assumed by producer  lambda\",\n    });\n\n    rotatorRole.addManagedPolicy(\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"service-role/AWSLambdaBasicExecutionRole\"\n      )\n    );\n    rotatorRole.addManagedPolicy(\n      iam.ManagedPolicy.fromAwsManagedPolicyName(\n        \"service-role/AWSLambdaVPCAccessExecutionRole\"\n      )\n    );\n    rotatorRole.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [secret.secretArn],\n        actions: [\n          \"secretsmanager:DescribeSecret\",\n          \"secretsmanager:GetSecretValue\",\n          \"secretsmanager:PutSecretValue\",\n          \"secretsmanager:UpdateSecretVersionStage\",\n        ],\n      })\n    );\n\n    rotatorRole.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [\n          \"arn:aws:elasticache:\" +\n            Stack.of(this).region +\n            \":\" +\n            Stack.of(this).account +\n            \":replicationgroup:\" +\n            ecClusterReplicationGroup.replicationGroupId,\n        ],\n        actions: [\n          \"elasticache:ModifyReplicationGroup\",\n          \"elasticache:DescribeReplicationGroups\",\n        ],\n      })\n    );\n\n    rotatorRole.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [\"*\"],\n        actions: [\"secretsmanager:GetRandomPassword\"],\n      })\n    );\n\n    const redisPyLayer = new pyLambda.PythonLayerVersion(this, \"RedisPyLayer\", {\n      entry: path.join(__dirname, \"lambda\", \"layer\", \"redis-py\"),\n      compatibleRuntimes: [\n        lambda.Runtime.PYTHON_3_9,\n        lambda.Runtime.PYTHON_3_8,\n        lambda.Runtime.PYTHON_3_7,\n        lambda.Runtime.PYTHON_3_6,\n      ],\n      description: \"A layer that contains the redis-py module\",\n      license: \"MIT License\",\n    });\n\n    const fn = new pyLambda.PythonFunction(this, \"SecretRotationFunction\", {\n      runtime: lambda.Runtime.PYTHON_3_9,\n      entry: path.join(__dirname, \"lambda\"),\n      handler: \"lambda_handler\",\n      index: \"index.py\",\n      layers: [redisPyLayer],\n      role: rotatorRole,\n      timeout: Duration.seconds(30),\n      vpc: vpc,\n      vpcSubnets: { subnetType: ec2.SubnetType.PRIVATE_ISOLATED },\n      securityGroups: [ecSecurityGroup, rotatorSecurityGroup],\n      environment: {\n        replicationGroupId: ecClusterReplicationGroup.ref,\n        redis_endpoint: ecClusterReplicationGroup.attrPrimaryEndPointAddress,\n        redis_port: ecClusterReplicationGroup.attrPrimaryEndPointPort,\n        EXCLUDE_CHARACTERS: \"@%*()_+=`~{}|[]\\\\:\\\";'?,./\",\n        SECRETS_MANAGER_ENDPOINT:\n          \"https://secretsmanager.\" + Stack.of(this).region + \".amazonaws.com\",\n      },\n    });\n\n    secret.addRotationSchedule(\"RotationSchedule\", {\n      rotationLambda: fn,\n      automaticallyAfter: Duration.days(15),\n    });\n\n    secret.grantRead(fn);\n\n    fn.grantInvoke(new iam.ServicePrincipal(\"secretsmanager.amazonaws.com\"));\n\n    secretsManagerVpcEndpoint.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [\"*\"],\n        actions: [\"secretsmanager:GetRandomPassword\"],\n        principals: [rotatorRole]\n      })\n    )\n\n    secretsManagerVpcEndpoint.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [secret.secretArn],\n        actions: [\n          \"secretsmanager:DescribeSecret\",\n          \"secretsmanager:GetSecretValue\",\n          \"secretsmanager:PutSecretValue\",\n          \"secretsmanager:UpdateSecretVersionStage\",\n        ],\n        principals: [rotatorRole]\n      })\n    )\n\n    elasticacheVpcEndpoint.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: [\n          \"arn:aws:elasticache:\" +\n            Stack.of(this).region +\n            \":\" +\n            Stack.of(this).account +\n            \":replicationgroup:\" +\n            ecClusterReplicationGroup.replicationGroupId,\n        ],\n        actions: [\n          \"elasticache:ModifyReplicationGroup\",\n          \"elasticache:DescribeReplicationGroups\",\n        ],\n        principals: [rotatorRole]\n      })\n    )\n\n  }\n}", "language": "typescript"}
{"input": "Must have 'rosetta:extract' command if this package is JSII-enabled.", "output": "export class MustHaveRosettaExtract extends ValidationRule {\n  public readonly name = 'package-info/scripts/rosetta:extract';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.rosetta:extract', 'yarn --silent jsii-rosetta extract');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const amplifyApp = new amplify.App(this, 'App', {\n      basicAuth: amplify.BasicAuth.fromGeneratedPassword('aws'),\n      autoBranchCreation: {},\n      customResponseHeaders: [\n        {\n          pattern: '*.json',\n          headers: {\n            'custom-header-name-1': 'custom-header-value-1',\n            'custom-header-name-2': 'custom-header-value-2',\n          },\n        },\n        {\n          pattern: '/path/*',\n          headers: {\n            'custom-header-name-1': 'custom-header-value-2',\n            'x-aws-url-suffix': `this-is-the-suffix-${Stack.of(this).urlSuffix}`,\n          },\n        },\n      ],\n      platform: amplify.Platform.WEB_COMPUTE,\n    });\n\n    amplifyApp.addCustomRule({\n      source: '/source',\n      status: amplify.RedirectStatus.PERMANENT_REDIRECT,\n      target: '/target',\n    });\n\n    const mainBranch = amplifyApp.addBranch('main');\n    mainBranch.addEnvironment('key', 'value');\n  }\n}", "language": "typescript"}
{"input": "Class to define a Tool Schema from an S3 object.", "output": "export class S3ToolSchema extends ToolSchema {\n  constructor(private readonly location: Location, public readonly bucketOwnerAccountId?: string) {\n    super(location, bucketOwnerAccountId, undefined);\n  }\n  /**\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): any {\n    return {\n      s3: {\n        uri: `s3://${this.location.bucketName}/${this.location.objectKey}`,\n        ...(this.bucketOwnerAccountId && { bucketOwnerAccountId: this.bucketOwnerAccountId }),\n      },\n    };\n  }\n\n  public bind(scope: Construct): void {\n    if (scope) {\n    }\n    // No-op\n  }\n\n  public grantPermissionsToRole(role: IRole): void {\n    Grant.addToPrincipal({\n      grantee: role,\n      actions: ['s3:GetObject'],\n      resourceArns: [`arn:${Aws.PARTITION}:s3:::${this.location.bucketName}/${this.location.objectKey}`],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class NoTestsInNpmPackage for AWS resource management", "output": "export class NoTestsInNpmPackage extends ValidationRule {\n  public readonly name = 'npmignore/test';\n\n  public validate(pkg: PackageJson): void {\n    // skip private packages\n    if (pkg.json.private) { return; }\n\n    // Skip the CLI package, as its 'test' subdirectory is used at runtime.\n    if (pkg.packageName === 'aws-cdk') { return; }\n\n    // Exclude 'test/' directories from being packaged\n    fileShouldContain(this.name, pkg, '.npmignore', 'test/');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, WAF, EventBridge, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\n        \"SELECT topic(2) as device_id, year, month, day FROM 'device/+/data'\",\n      ),\n    });\n\n    const bucket = new s3.Bucket(this, 'MyBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    topicRule.addAction(\n      new actions.S3PutObjectAction(bucket, {\n        key: '${year}/${month}/${day}/${topic(2)}',\n        accessControl: s3.BucketAccessControl.BUCKET_OWNER_FULL_CONTROL,\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedApplicationListener for AWS resource management", "output": "class ImportedApplicationListener extends ExternalApplicationListener {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-elasticloadbalancingv2.ImportedApplicationListener';\n  public readonly isApplicationListener = true;\n  public readonly listenerArn: string;\n  public readonly connections: ec2.Connections;\n\n  constructor(scope: Construct, id: string, props: ApplicationListenerAttributes) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.listenerArn = props.listenerArn;\n    const defaultPort = props.defaultPort !== undefined ? ec2.Port.tcp(props.defaultPort) : undefined;\n\n    this.connections = new ec2.Connections({\n      securityGroups: [props.securityGroup],\n      defaultPort,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, VPC, MSK (Kafka) resources", "output": "export class NeptuneWithVpcStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create VPC for use with Neptune\n    const neptuneVpc = new ec2.Vpc(this, \"NeptuneVpc\", {\n      cidr: \"10.192.0.0/16\",\n      maxAzs: 2,\n      natGateways: 0,\n      enableDnsHostnames: true,\n      enableDnsSupport: true,\n      /**\n       * Each entry in this list configures a Subnet Group\n       *\n       * ISOLATED: Isolated Subnets do not route traffic to the Internet (in this VPC).\n       * PRIVATE.: Subnet that routes to the internet, but not vice versa.\n       * PUBLIC..: Subnet connected to the Internet.\n       */\n      subnetConfiguration: [{\n        cidrMask: 24,\n        name: 'db',\n        subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n      }, {\n        cidrMask: 24,\n        name: 'dmz',\n        subnetType: ec2.SubnetType.PUBLIC,\n      }],\n    });\n\n    // Output the VPC ID\n    new cdk.CfnOutput(this, \"VPCId\", {\n      value: neptuneVpc.vpcId,\n      description: \"Neptune VPC ID\",\n      exportName: \"NeptuneWithVpcStack:vpcId\"\n    });\n\n    // Get lists of Subnets by type\n    let neptunePublicSubnets = neptuneVpc.publicSubnets;\n    let neptunePrivateSubnets = neptuneVpc.privateSubnets;\n    let neptuneIsolatedSubnets = neptuneVpc.isolatedSubnets;\n\n    // Create Subnet group list to be used with Neptune.\n    const neptuneSubnets: ec2.SubnetSelection = { subnets: neptuneIsolatedSubnets };\n\n    // Create Neptune Cluster\n    const clusterParams = new neptune.ClusterParameterGroup(this, 'ClusterParams', {\n      description: 'Cluster parameter group',\n      parameters: {\n        neptune_enable_audit_log: '1'\n      },\n    });\n\n    const dbParams = new neptune.ParameterGroup(this, 'DbParams', {\n      description: 'Db parameter group',\n      parameters: {\n        neptune_query_timeout: '120000'\n      },\n    });\n\n    const neptuneCluster = new neptune.DatabaseCluster(this, \"NeptuneCluster\", {\n      dbClusterName: \"MyGraphDB\",\n      vpc: neptuneVpc,\n      vpcSubnets: neptuneSubnets,\n      instanceType: neptune.InstanceType.R5_LARGE,\n      clusterParameterGroup: clusterParams,\n      parameterGroup: dbParams,\n      deletionProtection: false, // Not recommended for production clusters. This is enabled to easily delete the example stack.\n      removalPolicy: cdk.RemovalPolicy.DESTROY, // Not recommended for production clusters. This is enabled to easily delete the example stack.\n    });\n\n    // Update Neptune Security Group to allow-all-in\n    neptuneCluster.connections.allowDefaultPortFromAnyIpv4('Allow From All');\n\n    // Add tags to all assets within this stack\n    cdk.Tags.of(this).add(\"CreatedBy\", \"CDK\", { priority: 300 })\n    cdk.Tags.of(this).add(\"Purpose\", \"Neptune Cluster\", { priority: 300 })\n    cdk.Tags.of(this).add('Owner', 'CDK', { priority: 300 });\n\n    // Output the Neptune read/write addresses\n    const neptuneClusterWriteAddress = neptuneCluster.clusterEndpoint.socketAddress;\n    const neptuneClusterReadAddress = neptuneCluster.clusterReadEndpoint.socketAddress;\n\n    new cdk.CfnOutput(this, 'NeptuneClusterReadAddress', {\n      value: neptuneClusterReadAddress,\n      description: \"Neptune Cluster Read Address\",\n      exportName: \"NeptuneWithVpcStack:NeptuneClusterReadAddress\"\n    });\n    new cdk.CfnOutput(this, 'NeptuneClusterWriteAddress', {\n      value: neptuneClusterWriteAddress,\n      description: \"Neptune Cluster Write Address\",\n      exportName: \"NeptuneWithVpcStack:NeptuneClusterWriteAddress\"\n    });\n  }\n}", "language": "typescript"}
{"input": "Lambda code from an inline string.", "output": "export class InlineCode extends Code {\n  public readonly isInline = true;\n\n  constructor(private code: string) {\n    super();\n\n    if (code.length === 0) {\n      throw new UnscopedValidationError('Lambda inline code cannot be empty');\n    }\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      inlineCode: this.code,\n    };\n  }\n}", "language": "typescript"}
{"input": "Types of PII specific to Canada.", "output": "export class CanadaSpecificPIIType extends PIIType {\n  /**\n   * A Canadian Health Service Number is a 10-digit unique identifier,\n   * required for individuals to access healthcare benefits.\n   */\n  public static readonly CA_HEALTH_NUMBER = new CanadaSpecificPIIType('CA_HEALTH_NUMBER');\n  /**\n   * A Canadian Social Insurance Number (SIN) is a nine-digit unique identifier,\n   * required for individuals to access government programs and benefits.\n   */\n  public static readonly CA_SOCIAL_INSURANCE_NUMBER = new CanadaSpecificPIIType('CA_SOCIAL_INSURANCE_NUMBER');\n\n  private constructor(value: string) { super(value); }\n}", "language": "typescript"}
{"input": "method to add a default route in the private subnet pointing to the NAT instance", "output": "def add_route_to_nat(self, vpc, nat_instance):\n        # select the private subnet created before\n        priv_subnet = ec2.SubnetFilter.availability_zones([LZ_NAME]).select_subnets(vpc.isolated_subnets)\n        # add the default route pointing to the nat instance\n        priv_subnet[0].add_route(\"DefRouteToNAT\",\n            router_id=nat_instance.instance_id,\n            router_type=ec2.RouterType.INSTANCE,\n            destination_cidr_block=\"0.0.0.0/0\",\n            enables_internet_connectivity=True)", "language": "python"}
{"input": "CDK class Endpoint for AWS resource management", "output": "export class Endpoint extends EndpointBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-sagemaker-alpha.Endpoint';\n\n  /**\n   * Imports an Endpoint defined either outside the CDK or in a different CDK stack.\n   * @param scope the Construct scope.\n   * @param id the resource id.\n   * @param endpointArn the ARN of the endpoint.\n   */\n  public static fromEndpointArn(scope: Construct, id: string, endpointArn: string): IEndpoint {\n    return Endpoint.fromEndpointAttributes(scope, id, { endpointArn });\n  }\n\n  /**\n   * Imports an Endpoint defined either outside the CDK or in a different CDK stack.\n   * @param scope the Construct scope.\n   * @param id the resource id.\n   * @param endpointName the name of the endpoint.\n   */\n  public static fromEndpointName(scope: Construct, id: string, endpointName: string): IEndpoint {\n    const endpointArn = cdk.Stack.of(scope).formatArn({\n      service: 'sagemaker',\n      resource: 'endpoint',\n      resourceName: endpointName,\n    });\n    return Endpoint.fromEndpointAttributes(scope, id, { endpointArn });\n  }\n\n  /**\n   * Imports an Endpoint defined either outside the CDK or in a different CDK stack.\n   * @param scope the Construct scope.\n   * @param id the resource id.\n   * @param attrs the attributes of the endpoint to import.\n   */\n  public static fromEndpointAttributes(scope: Construct, id: string, attrs: EndpointAttributes): IEndpoint {\n    const endpointArn = attrs.endpointArn;\n    const endpointName = cdk.Stack.of(scope).splitArn(endpointArn, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName!;\n\n    class Import extends EndpointBase {\n      public readonly endpointArn = endpointArn;\n      public readonly endpointName = endpointName;\n\n      constructor(s: Construct, i: string) {\n        super(s, i, {\n          environmentFromArn: endpointArn,\n        });\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The ARN of the endpoint.\n   *\n   * @attribute\n   */\n  public readonly endpointArn: string;\n  /**\n   * The name of the endpoint.\n   *\n   * @attribute\n   */\n  public readonly endpointName: string;\n  private readonly endpointConfig: IEndpointConfig;\n\n  constructor(scope: Construct, id: string, props: EndpointProps) {\n    super(scope, id, {\n      physicalName: props.endpointName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.validateEnvironmentCompatibility(props.endpointConfig);\n    this.endpointConfig = props.endpointConfig;\n\n    // create the endpoint resource\n    const endpoint = new CfnEndpoint(this, 'Endpoint', {\n      endpointConfigName: props.endpointConfig.endpointConfigName,\n      endpointName: this.physicalName,\n    });\n    this.endpointName = this.getResourceNameAttribute(endpoint.attrEndpointName);\n    this.endpointArn = this.getResourceArnAttribute(endpoint.ref, {\n      service: 'sagemaker',\n      resource: 'endpoint',\n      resourceName: this.physicalName,\n    });\n  }\n\n  private validateEnvironmentCompatibility(endpointConfig: IEndpointConfig): void {\n    if (!sameEnv(endpointConfig.env.account, this.env.account)) {\n      throw new Error(`Cannot use endpoint configuration in account ${endpointConfig.env.account} for endpoint in account ${this.env.account}`);\n    } else if (!sameEnv(endpointConfig.env.region, this.env.region)) {\n      throw new Error(`Cannot use endpoint configuration in region ${endpointConfig.env.region} for endpoint in region ${this.env.region}`);\n    }\n  }\n\n  /**\n   * Get instance production variants associated with endpoint.\n   */\n  public get instanceProductionVariants(): IEndpointInstanceProductionVariant[] {\n    if (this.endpointConfig instanceof EndpointConfig) {\n      return this.endpointConfig._instanceProductionVariants.map(v => new EndpointInstanceProductionVariant(this, v));\n    }\n\n    throw new Error('Production variant lookup is not supported for an imported IEndpointConfig');\n  }\n\n  /**\n   * Find instance production variant based on variant name\n   * @param name Variant name from production variant\n   */\n  @MethodMetadata()\n  public findInstanceProductionVariant(name: string): IEndpointInstanceProductionVariant {\n    if (this.endpointConfig instanceof EndpointConfig) {\n      const variant = this.endpointConfig._findInstanceProductionVariant(name);\n      return new EndpointInstanceProductionVariant(this, variant);\n    }\n\n    throw new Error('Production variant lookup is not supported for an imported IEndpointConfig');\n  }\n}", "language": "typescript"}
{"input": "Represents a Volume that can be mounted to a container that uses ECS", "output": "class EcsVolume {\n  /**\n   * Creates a Volume that uses an AWS Elastic File System (EFS); this volume can grow and shrink as needed\n   *\n   * @see https://docs.aws.amazon.com/batch/latest/userguide/efs-volumes.html\n   */\n  static efs(options: EfsVolumeOptions) {\n    return new EfsVolume(options);\n  }\n\n  /**\n   * Creates a Host volume. This volume will persist on the host at the specified `hostPath`.\n   * If the `hostPath` is not specified, Docker will choose the host path. In this case,\n   * the data may not persist after the containers that use it stop running.\n   */\n  static host(options: HostVolumeOptions) {\n    return new HostVolume(options);\n  }\n\n  /**\n   * The name of this volume\n   */\n  public readonly name: string;\n\n  /**\n   * The path on the container that this volume will be mounted to\n   */\n  public readonly containerPath: string;\n\n  /**\n   * Whether or not the container has readonly access to this volume\n   *\n   * @default false\n   */\n  public readonly readonly?: boolean;\n\n  constructor(options: EcsVolumeOptions) {\n    this.name = options.name;\n    this.containerPath = options.containerPath;\n    this.readonly = options.readonly;\n  }\n}", "language": "typescript"}
{"input": "Configuration properties for client authentication.", "output": "export class ClientAuthentication {\n  /**\n   * SASL authentication\n   */\n  public static sasl(props: SaslAuthProps): ClientAuthentication {\n    return new ClientAuthentication(props, undefined);\n  }\n\n  /**\n   * TLS authentication\n   */\n  public static tls(props: TlsAuthProps): ClientAuthentication {\n    return new ClientAuthentication(undefined, props);\n  }\n\n  /**\n   * SASL + TLS authentication\n   */\n  public static saslTls(saslTlsProps: SaslTlsAuthProps): ClientAuthentication {\n    return new ClientAuthentication(saslTlsProps, saslTlsProps);\n  }\n\n  /**\n   * @param saslProps - properties for SASL authentication\n   * @param tlsProps - properties for TLS authentication\n   */\n  private constructor(\n    public readonly saslProps?: SaslAuthProps,\n    public readonly tlsProps?: TlsAuthProps,\n  ) {}\n}", "language": "typescript"}
{"input": "CDK class Subscription for AWS resource management", "output": "export class Subscription extends Resource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-sns.Subscription';\n\n  /**\n   * The DLQ associated with this subscription if present.\n   */\n  public readonly deadLetterQueue?: IQueue;\n\n  private readonly filterPolicy?: { [attribute: string]: any[] };\n\n  private readonly filterPolicyWithMessageBody? : {[attribute: string]: FilterOrPolicy };\n\n  constructor(scope: Construct, id: string, props: SubscriptionProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.rawMessageDelivery &&\n      [\n        SubscriptionProtocol.HTTP,\n        SubscriptionProtocol.HTTPS,\n        SubscriptionProtocol.SQS,\n        SubscriptionProtocol.FIREHOSE,\n      ]\n        .indexOf(props.protocol) < 0) {\n      throw new ValidationError('Raw message delivery can only be enabled for HTTP, HTTPS, SQS, and Firehose subscriptions.', this);\n    }\n\n    if (props.filterPolicy) {\n      if (Object.keys(props.filterPolicy).length > 5) {\n        throw new ValidationError('A filter policy can have a maximum of 5 attribute names.', this);\n      }\n\n      this.filterPolicy = Object.entries(props.filterPolicy)\n        .reduce(\n          (acc, [k, v]) => ({ ...acc, [k]: v.conditions }),\n          {},\n        );\n\n      let total = 1;\n      Object.values(this.filterPolicy).forEach(filter => { total *= filter.length; });\n      if (total > 150) {\n        throw new ValidationError(`The total combination of values (${total}) must not exceed 150.`, this);\n      }\n    } else if (props.filterPolicyWithMessageBody) {\n      if (Object.keys(props.filterPolicyWithMessageBody).length > 5) {\n        throw new ValidationError('A filter policy can have a maximum of 5 attribute names.', this);\n      }\n      this.filterPolicyWithMessageBody = props.filterPolicyWithMessageBody;\n    }\n\n    if (props.protocol === SubscriptionProtocol.FIREHOSE && !props.subscriptionRoleArn) {\n      throw new ValidationError('Subscription role arn is required field for subscriptions with a firehose protocol.', this);\n    }\n\n    // Format filter policy\n    const filterPolicy = this.filterPolicyWithMessageBody\n      ? buildFilterPolicyWithMessageBody(this, this.filterPolicyWithMessageBody)\n      : this.filterPolicy;\n\n    this.deadLetterQueue = this.buildDeadLetterQueue(props);\n    new CfnSubscription(this, 'Resource', {\n      endpoint: props.endpoint,\n      protocol: props.protocol,\n      topicArn: props.topic.topicArn,\n      rawMessageDelivery: props.rawMessageDelivery,\n      filterPolicy,\n      filterPolicyScope: this.filterPolicyWithMessageBody ? 'MessageBody' : undefined,\n      region: props.region,\n      redrivePolicy: this.buildDeadLetterConfig(this.deadLetterQueue),\n      subscriptionRoleArn: props.subscriptionRoleArn,\n      deliveryPolicy: props.deliveryPolicy ? this.renderDeliveryPolicy(props.deliveryPolicy, props.protocol): undefined,\n    });\n  }\n\n  private renderDeliveryPolicy(deliveryPolicy: DeliveryPolicy, protocol: SubscriptionProtocol): any {\n    if (![SubscriptionProtocol.HTTP, SubscriptionProtocol.HTTPS].includes(protocol)) {\n      throw new ValidationError(`Delivery policy is only supported for HTTP and HTTPS subscriptions, got: ${protocol}`, this);\n    }\n    const { healthyRetryPolicy, throttlePolicy } = deliveryPolicy;\n    if (healthyRetryPolicy) {\n      const delayTargetLimitSecs = 3600;\n      const minDelayTarget = healthyRetryPolicy.minDelayTarget;\n      const maxDelayTarget = healthyRetryPolicy.maxDelayTarget;\n      if (minDelayTarget !== undefined) {\n        if (minDelayTarget.toMilliseconds() % 1000 !== 0) {\n          throw new ValidationError(`minDelayTarget must be a whole number of seconds, got: ${minDelayTarget}`, this);\n        }\n        const minDelayTargetSecs = minDelayTarget.toSeconds();\n        if (minDelayTargetSecs < 1 || minDelayTargetSecs > delayTargetLimitSecs) {\n          throw new ValidationError(`minDelayTarget must be between 1 and ${delayTargetLimitSecs} seconds inclusive, got: ${minDelayTargetSecs}s`, this);\n        }\n      }\n      if (maxDelayTarget !== undefined) {\n        if (maxDelayTarget.toMilliseconds() % 1000 !== 0) {\n          throw new ValidationError(`maxDelayTarget must be a whole number of seconds, got: ${maxDelayTarget}`, this);\n        }\n        const maxDelayTargetSecs = maxDelayTarget.toSeconds();\n        if (maxDelayTargetSecs < 1 || maxDelayTargetSecs > delayTargetLimitSecs) {\n          throw new ValidationError(`maxDelayTarget must be between 1 and ${delayTargetLimitSecs} seconds inclusive, got: ${maxDelayTargetSecs}s`, this);\n        }\n        if ((minDelayTarget !== undefined) && minDelayTarget.toSeconds() > maxDelayTargetSecs) {\n          throw new ValidationError('minDelayTarget must not exceed maxDelayTarget', this);\n        }\n      }\n\n      const numRetriesLimit = 100;\n      if (healthyRetryPolicy.numRetries && (healthyRetryPolicy.numRetries < 0 || healthyRetryPolicy.numRetries > numRetriesLimit)) {\n        throw new ValidationError(`numRetries must be between 0 and ${numRetriesLimit} inclusive, got: ${healthyRetryPolicy.numRetries}`, this);\n      }\n      const { numNoDelayRetries, numMinDelayRetries, numMaxDelayRetries } = healthyRetryPolicy;\n      if (numNoDelayRetries && (numNoDelayRetries < 0 || !Number.isInteger(numNoDelayRetries))) {\n        throw new ValidationError(`numNoDelayRetries must be an integer zero or greater, got: ${numNoDelayRetries}`, this);\n      }\n      if (numMinDelayRetries && (numMinDelayRetries < 0 || !Number.isInteger(numMinDelayRetries))) {\n        throw new ValidationError(`numMinDelayRetries must be an integer zero or greater, got: ${numMinDelayRetries}`, this);\n      }\n      if (numMaxDelayRetries && (numMaxDelayRetries < 0 || !Number.isInteger(numMaxDelayRetries))) {\n        throw new ValidationError(`numMaxDelayRetries must be an integer zero or greater, got: ${numMaxDelayRetries}`, this);\n      }\n    }\n    if (throttlePolicy) {\n      const maxReceivesPerSecond = throttlePolicy.maxReceivesPerSecond;\n      if (maxReceivesPerSecond !== undefined && (maxReceivesPerSecond < 1 || !Number.isInteger(maxReceivesPerSecond))) {\n        throw new ValidationError(`maxReceivesPerSecond must be an integer greater than zero, got: ${maxReceivesPerSecond}`, this);\n      }\n    }\n    return {\n      healthyRetryPolicy: healthyRetryPolicy ? {\n        // minDelayTarget, maxDelayTarget and numRetries are (empirically) mandatory when healthyRetryPolicy is specified,\n        // but for user-friendliness we allow them to be undefined and set them here instead.\n        // The defaults we use here are the same used in the event healthyRetryPolicy is not specified, see https://docs.aws.amazon.com/sns/latest/dg/creating-delivery-policy.html.\n        minDelayTarget: (healthyRetryPolicy.minDelayTarget === undefined) ? 20 : healthyRetryPolicy.minDelayTarget.toSeconds(),\n        maxDelayTarget: (healthyRetryPolicy.maxDelayTarget === undefined) ? 20 : healthyRetryPolicy.maxDelayTarget.toSeconds(),\n        numRetries: (healthyRetryPolicy.numRetries === undefined) ? 3: healthyRetryPolicy.numRetries,\n        numNoDelayRetries: healthyRetryPolicy.numNoDelayRetries,\n        numMinDelayRetries: healthyRetryPolicy.numMinDelayRetries,\n        numMaxDelayRetries: healthyRetryPolicy.numMaxDelayRetries,\n        backoffFunction: healthyRetryPolicy.backoffFunction,\n      }: undefined,\n      throttlePolicy: deliveryPolicy.throttlePolicy ? {\n        maxReceivesPerSecond: deliveryPolicy.throttlePolicy.maxReceivesPerSecond,\n      }: undefined,\n      requestPolicy: deliveryPolicy.requestPolicy ? {\n        headerContentType: deliveryPolicy.requestPolicy.headerContentType,\n      }: undefined,\n    };\n  }\n\n  private buildDeadLetterQueue(props: SubscriptionProps) {\n    if (!props.deadLetterQueue) {\n      return undefined;\n    }\n\n    const deadLetterQueue = props.deadLetterQueue;\n\n    deadLetterQueue.addToResourcePolicy(new PolicyStatement({\n      resources: [deadLetterQueue.queueArn],\n      actions: ['sqs:SendMessage'],\n      principals: [new ServicePrincipal('sns.amazonaws.com')],\n      conditions: {\n        ArnEquals: { 'aws:SourceArn': props.topic.topicArn },\n      },\n    }));\n\n    return deadLetterQueue;\n  }\n\n  private buildDeadLetterConfig(deadLetterQueue?: IQueue) {\n    if (deadLetterQueue) {\n      return {\n        deadLetterTargetArn: deadLetterQueue.queueArn,\n      };\n    } else {\n      return undefined;\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class FakeStreamSource for AWS resource management", "output": "class FakeStreamSource extends StreamSource {\n  private readonly startingPosition: DynamoDBStartingPosition;\n  private readonly deadLetterTargetArn?: string;\n\n  public grantRead = jest.fn();\n\n  constructor(table: ITableV2, parameters: DynamoDBSourceParameters) {\n    if (table.tableStreamArn === undefined) {\n      throw new Error('Table does not have a stream defined, cannot create pipes source');\n    }\n\n    super(table.tableStreamArn, parameters);\n    this.startingPosition = parameters.startingPosition;\n    this.deadLetterTargetArn = this.getDeadLetterTargetArn(this.deadLetterTarget);\n  }\n\n  bind(_pipe: IPipe): SourceConfig {\n    return {\n      sourceParameters: {\n        dynamoDbStreamParameters: {\n          batchSize: this.sourceParameters.batchSize,\n          deadLetterConfig: this.deadLetterTargetArn ? { arn: this.deadLetterTargetArn } : undefined,\n          maximumBatchingWindowInSeconds: this.sourceParameters.maximumBatchingWindow?.toSeconds(),\n          maximumRecordAgeInSeconds: this.sourceParameters.maximumRecordAge?.toSeconds(),\n          maximumRetryAttempts: this.sourceParameters.maximumRetryAttempts,\n          onPartialBatchItemFailure: this.sourceParameters.onPartialBatchItemFailure,\n          parallelizationFactor: this.sourceParameters.parallelizationFactor,\n          startingPosition: this.startingPosition,\n        },\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class KinesisEnv for AWS resource management", "output": "class KinesisEnv extends Stack {\n  constructor(scope: constructs.Construct, id: string) {\n    super(scope, id);\n\n    const stream = new kinesis.Stream(this, 'MyStream');\n    const logGroup = new logs.LogGroup(this, 'LogGroup', { removalPolicy: RemovalPolicy.DESTROY });\n    const kinesisDestination = new dests.KinesisDestination(stream);\n\n    new logs.SubscriptionFilter(this, 'Subscription', {\n      logGroup: logGroup,\n      destination: kinesisDestination,\n      filterPattern: logs.FilterPattern.allEvents(),\n    });\n  }\n}", "language": "typescript"}
{"input": "There must be a NOTICE file.", "output": "export class NoticeFile extends ValidationRule {\n  public readonly name = 'license/notice-file';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldBeginWith(this.name, pkg, 'NOTICE', ...NOTICE.split('\\n'));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation, CDK Pipelines resources", "output": "class PipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { restrictDefaultSecurityGroup: false });\n\n    const pipeline = new pipelines.CodePipeline(this, 'Pipeline', {\n      codeBuildDefaults: { vpc },\n      synth: new pipelines.ShellStep('Synth', {\n        input: pipelines.CodePipelineSource.gitHub('aws/aws-cdk', 'v2-main'),\n        commands: [\n          'npm ci',\n          'npm run build',\n          'npx cdk synth',\n        ],\n      }),\n    });\n\n    pipeline.addStage(new AppStage(this, 'Beta'));\n  }\n}", "language": "typescript"}
{"input": "Utility class to generate the construct stack trace for a report", "output": "export class ReportTrace {\n  constructor(private readonly tree: ConstructTree) {}\n\n  /**\n   * Return a JSON representation of the construct trace\n   */\n  public formatJson(constructPath: string): ConstructTrace | undefined {\n    return this.tree.traceFromPath(constructPath);\n  }\n\n  /**\n   * This will render something like this:\n   *\n   *   Creation Stack:\n   *     \u2514\u2500\u2500  MyStack (MyStack)\n   *          \u2502 Library: aws-cdk-lib.Stack\n   *          \u2502 Library Version: 2.50.0\n   *          \u2502 Location: Object.<anonymous> (/home/hallcor/tmp/cdk-tmp-app/src/main.ts:25:20)\n   *          \u2514\u2500\u2500  MyCustomL3Construct (MyStack/MyCustomL3Construct)\n   *               \u2502 Library: N/A - (Local Construct)\n   *               \u2502 Library Version: N/A\n   *               \u2502 Location: new MyStack (/home/hallcor/tmp/cdk-tmp-app/src/main.ts:15:20)\n   *               \u2514\u2500\u2500  Bucket (MyStack/MyCustomL3Construct/Bucket)\n   *                    \u2502 Library: aws-cdk-lib/aws-s3.Bucket\n   *                    \u2502 Library Version: 2.50.0\n   *                    \u2502 Location: new MyCustomL3Construct (/home/hallcor/tmp/cdk-tmp-app/src/main.ts:9:20)/\n   */\n  public formatPrettyPrinted(constructPath?: string): string {\n    const trace = constructPath ? this.formatJson(constructPath) : undefined;\n    return this.renderPrettyPrintedTraceInfo(trace);\n  }\n\n  private renderPrettyPrintedTraceInfo(info?: ConstructTrace, indent?: string, start: string = STARTER_LINE): string {\n    const notAvailableMessage = '\\tConstruct trace not available. Rerun with `--debug` to see trace information';\n    if (info) {\n      const indentation = indent ?? ' '.repeat(STARTER_LINE.length+1);\n      const result: string[] = [\n        `${start} ${info?.id} (${info?.path})`,\n        `${indentation}${VERTICAL_LINE} Construct: ${info?.construct}`,\n        `${indentation}${VERTICAL_LINE} Library Version: ${info?.libraryVersion}`,\n        `${indentation}${VERTICAL_LINE} Location: ${info?.location}`,\n        ...info?.child ? [this.renderPrettyPrintedTraceInfo(info?.child, ' '.repeat(indentation.length+STARTER_LINE.length+1), indentation+STARTER_LINE)] : [],\n      ];\n      return result.join('\\n\\t');\n    }\n    return notAvailableMessage;\n  }\n}", "language": "typescript"}
{"input": "CDK class AllProperties for AWS resource management", "output": "class AllProperties extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const publicKey = `-----BEGIN PUBLIC KEY-----\nMHYwEAYHKoZIzj0CAQYFK4EEACIDYgAEs6k8Xf6WyFq3yZXoup8G/gH6DntSATqD\nYfo83eX0GJCKxJ8fr09h9LP9HDGof8/bo66P+SGHeAARGF/O9WPAQVUgSlm/KMFX\nEPtPtOm1s0GR9k1ydU5hkI++f9CoZ5lM\n-----END PUBLIC KEY-----`;\n    const keypair = new ivs.PlaybackKeyPair(this, 'PlaybackKeyPair', {\n      publicKeyMaterial: publicKey,\n      playbackKeyPairName: 'IVSIntegrationTestPlaybackKeyPair',\n    });\n\n    const channel = new ivs.Channel(this, 'Channel', {\n      channelName: 'IVSIntegrationTestChannel',\n      authorized: true,\n      type: ivs.ChannelType.BASIC,\n      latencyMode: ivs.LatencyMode.NORMAL,\n    });\n\n    const streamKey = new ivs.StreamKey(this, 'StreamKey', {\n      channel: channel,\n    });\n\n    new CfnOutput(this, 'PlaybackKeyPairArn', { value: keypair.playbackKeyPairArn });\n    new CfnOutput(this, 'ChannelArn', { value: channel.channelArn });\n    new CfnOutput(this, 'StreamKeyArn', { value: streamKey.streamKeyArn });\n  }\n}", "language": "typescript"}
{"input": "Keys for Login Providers - each correspond to the client IDs of their respective federation Identity Providers", "output": "export class IdentityPoolProviderUrl {\n  /** Facebook Provider url */\n  public static readonly FACEBOOK = new IdentityPoolProviderUrl(IdentityPoolProviderType.FACEBOOK, 'graph.facebook.com');\n\n  /** Google Provider url */\n  public static readonly GOOGLE = new IdentityPoolProviderUrl(IdentityPoolProviderType.GOOGLE, 'accounts.google.com');\n\n  /** Amazon Provider url */\n  public static readonly AMAZON = new IdentityPoolProviderUrl(IdentityPoolProviderType.AMAZON, 'www.amazon.com');\n\n  /** Apple Provider url */\n  public static readonly APPLE = new IdentityPoolProviderUrl(IdentityPoolProviderType.APPLE, 'appleid.apple.com');\n\n  /** Twitter Provider url */\n  public static readonly TWITTER = new IdentityPoolProviderUrl(IdentityPoolProviderType.TWITTER, 'api.twitter.com');\n\n  /** OpenId Provider url */\n  public static openId(url: string): IdentityPoolProviderUrl {\n    return new IdentityPoolProviderUrl(IdentityPoolProviderType.OPEN_ID, url);\n  }\n\n  /** Saml Provider url */\n  public static saml(url: string): IdentityPoolProviderUrl {\n    return new IdentityPoolProviderUrl(IdentityPoolProviderType.SAML, url);\n  }\n\n  /** User Pool Provider Url */\n  public static userPool(userPool: IUserPool, userPoolClient: IUserPoolClient): IdentityPoolProviderUrl {\n    const url = `${userPool.userPoolProviderName}:${userPoolClient.userPoolClientId}`;\n    return new IdentityPoolProviderUrl(IdentityPoolProviderType.USER_POOL, url);\n  }\n\n  /** Custom Provider url */\n  public static custom(url: string): IdentityPoolProviderUrl {\n    return new IdentityPoolProviderUrl(IdentityPoolProviderType.CUSTOM, url);\n  }\n\n  constructor(\n    /**\n     * The type of Identity Pool Provider\n     */\n    public readonly type: IdentityPoolProviderType,\n\n    /**\n     * The value of the Identity Pool Provider\n     */\n    public readonly value: string,\n  ) {}\n}", "language": "typescript"}
{"input": "CDK class S3JsonItemReaderTest for AWS resource management", "output": "class S3JsonItemReaderTest {\n  private readonly integTest: IntegTest;\n  private readonly testStack: S3JsonItemReaderTestStack;\n\n  constructor(app: App) {\n    this.testStack = new S3JsonItemReaderTestStack(app);\n    this.integTest = new IntegTest(app, 'IntegTest', {\n      testCases: [this.testStack],\n    });\n  }\n\n  test(): IApiCall {\n    const setupResources = this.setup();\n    const executionResult1 = this.executeForDynamic(setupResources);\n    const executionResult2 = this.executeForStatic(setupResources);\n    return this.assert(executionResult1).next(this.assert(executionResult2));\n  }\n\n  private setup(): IApiCall {\n    const putS3Object1 = this.integTest.assertions.awsApiCall('S3', 'putObject', {\n      Bucket: this.testStack.bucket.bucketName,\n      Key: 'testFile.json',\n      Body: JSON.stringify([\n        { objectId: 1 },\n        { objectId: 2 },\n      ]),\n    });\n    const putS3Object2 = this.integTest.assertions.awsApiCall('S3', 'putObject', {\n      Bucket: this.testStack.bucket.bucketName,\n      Key: 'otherFile.json',\n      Body: JSON.stringify([\n        { objectId: 3 },\n        { objectId: 4 },\n      ]),\n    });\n    putS3Object1.next(putS3Object2);\n    return putS3Object2;\n  }\n\n  private executeForDynamic(setupResources: IApiCall): IApiCall {\n    const startExecution = this.start(setupResources, this.testStack.dynamicStateMachine.stateMachineArn, JSON.stringify({\n      bucketName: this.testStack.bucket.bucketName,\n      key: 'testFile.json',\n    }));\n    return this.describe(startExecution);\n  }\n\n  private executeForStatic(setupResources: IApiCall): IApiCall {\n    const startExecution = this.start(setupResources, this.testStack.staticStateMachine.stateMachineArn, JSON.stringify({\n      key: 'testFile.json',\n    }));\n    return this.describe(startExecution);\n  }\n\n  private start(setupResources: IApiCall, stateMachineArn: string, input: string): IApiCall {\n    const startExecution = this.integTest.assertions.awsApiCall('StepFunctions', 'startExecution', {\n      input,\n      stateMachineArn,\n    });\n    setupResources.next(startExecution);\n    return startExecution;\n  }\n\n  private describe(startExecution: IApiCall): IApiCall {\n    const describeExecution = this.integTest.assertions.awsApiCall('StepFunctions', 'describeExecution', {\n      executionArn: startExecution.getAttString('executionArn'),\n    });\n    startExecution.next(describeExecution);\n    return describeExecution;\n  }\n\n  private assert(exeutionResult: IApiCall): IApiCall {\n    return exeutionResult.expect(ExpectedResult.objectLike({\n      status: 'SUCCEEDED',\n    })).waitForAssertions({\n      interval: Duration.seconds(10),\n      totalTimeout: Duration.minutes(2),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class S3Destination for AWS resource management", "output": "class S3Destination extends FlowLogDestination {\n  constructor(private readonly props: FlowLogDestinationConfig) {\n    super();\n  }\n\n  public bind(scope: Construct, _flowLog: FlowLog): FlowLogDestinationConfig {\n    let s3Bucket: s3.IBucket;\n    if (this.props.s3Bucket === undefined) {\n      s3Bucket = new s3.Bucket(scope, 'Bucket', {\n        removalPolicy: RemovalPolicy.RETAIN,\n      });\n    } else {\n      s3Bucket = this.props.s3Bucket;\n    }\n\n    // https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-s3.html#flow-logs-s3-permissions\n    if (FeatureFlags.of(scope).isEnabled(S3_CREATE_DEFAULT_LOGGING_POLICY)) {\n      const stack = Stack.of(scope);\n      let keyPrefix = this.props.keyPrefix ?? '';\n      if (keyPrefix && !keyPrefix.endsWith('/')) {\n        keyPrefix = keyPrefix + '/';\n      }\n      const prefix = this.props.destinationOptions?.hiveCompatiblePartitions\n        ? s3Bucket.arnForObjects(`${keyPrefix}AWSLogs/aws-account-id=${stack.account}/*`)\n        : s3Bucket.arnForObjects(`${keyPrefix}AWSLogs/${stack.account}/*`);\n\n      s3Bucket.addToResourcePolicy(new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        principals: [\n          new iam.ServicePrincipal('delivery.logs.amazonaws.com'),\n        ],\n        resources: [\n          prefix,\n        ],\n        actions: ['s3:PutObject'],\n        conditions: {\n          StringEquals: {\n            's3:x-amz-acl': 'bucket-owner-full-control',\n            'aws:SourceAccount': stack.account,\n          },\n          ArnLike: {\n            'aws:SourceArn': stack.formatArn({\n              service: 'logs',\n              resource: '*',\n            }),\n          },\n        },\n      }));\n\n      s3Bucket.addToResourcePolicy(new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        principals: [\n          new iam.ServicePrincipal('delivery.logs.amazonaws.com'),\n        ],\n        resources: [s3Bucket.bucketArn],\n        actions: [\n          's3:GetBucketAcl',\n          's3:ListBucket',\n        ],\n        conditions: {\n          StringEquals: {\n            'aws:SourceAccount': stack.account,\n          },\n          ArnLike: {\n            'aws:SourceArn': stack.formatArn({\n              service: 'logs',\n              resource: '*',\n            }),\n          },\n        },\n      }));\n    }\n    return {\n      logDestinationType: FlowLogDestinationType.S3,\n      s3Bucket,\n      keyPrefix: this.props.keyPrefix,\n      destinationOptions: (this.props.destinationOptions?.fileFormat || this.props.destinationOptions?.perHourPartition\n      || this.props.destinationOptions?.hiveCompatiblePartitions)\n        ? {\n          fileFormat: this.props.destinationOptions.fileFormat ?? FlowLogFileFormat.PLAIN_TEXT,\n          perHourPartition: this.props.destinationOptions.perHourPartition ?? false,\n          hiveCompatiblePartitions: this.props.destinationOptions.hiveCompatiblePartitions ?? false,\n        } : undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "Represents a principal that has multiple types of principals. A composite principal cannot have conditions. i.e. multiple ServicePrincipals that form a composite principal", "output": "export class CompositePrincipal extends PrincipalBase {\n  public readonly assumeRoleAction: string;\n  private readonly _principals = new Array<IPrincipal>();\n\n  constructor(...principals: IPrincipal[]) {\n    super();\n    if (principals.length === 0) {\n      throw new UnscopedValidationError('CompositePrincipals must be constructed with at least 1 Principal but none were passed.');\n    }\n    this.assumeRoleAction = principals[0].assumeRoleAction;\n    this.addPrincipals(...principals);\n  }\n\n  /**\n   * Adds IAM principals to the composite principal. Composite principals cannot have\n   * conditions.\n   *\n   * @param principals IAM principals that will be added to the composite principal\n   */\n  public addPrincipals(...principals: IPrincipal[]): this {\n    this._principals.push(...principals);\n    return this;\n  }\n\n  public addToAssumeRolePolicy(doc: PolicyDocument) {\n    for (const p of this._principals) {\n      defaultAddPrincipalToAssumeRole(p, doc);\n    }\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    // We only have a problem with conditions if we are trying to render composite\n    // principals into a single statement (which is when `policyFragment` would get called)\n    for (const p of this._principals) {\n      const fragment = p.policyFragment;\n      if (fragment.conditions && Object.keys(fragment.conditions).length > 0) {\n        throw new UnscopedValidationError(\n          'Components of a CompositePrincipal must not have conditions. ' +\n          `Tried to add the following fragment: ${JSON.stringify(fragment)}`);\n      }\n    }\n\n    const principalJson: { [key: string]: string[] } = {};\n\n    for (const p of this._principals) {\n      mergePrincipal(principalJson, p.policyFragment.principalJson);\n    }\n\n    return new PrincipalPolicyFragment(principalJson);\n  }\n\n  public toString() {\n    return `CompositePrincipal(${this._principals})`;\n  }\n\n  public dedupeString(): string | undefined {\n    const inner = this._principals.map(ComparablePrincipal.dedupeStringFor);\n    if (inner.some(x => x === undefined)) { return undefined; }\n    return `CompositePrincipal[${inner.join(',')}]`;\n  }\n\n  /**\n   * Returns the principals that make up the CompositePrincipal\n   */\n  public get principals(): IPrincipal[] {\n    return this._principals;\n  }\n}", "language": "typescript"}
{"input": "The function's runtime environment version.", "output": "export class FunctionRuntime {\n  /**\n   * cloudfront-js-1.0\n   */\n  public static readonly JS_1_0 = new FunctionRuntime('cloudfront-js-1.0');\n\n  /**\n   * cloudfront-js-2.0\n   */\n  public static readonly JS_2_0 = new FunctionRuntime('cloudfront-js-2.0');\n\n  /**\n   * A custom runtime string.\n   *\n   * Gives full control over the runtime string fragment.\n   */\n  public static custom(runtimeString: string): FunctionRuntime {\n    return new FunctionRuntime(runtimeString);\n  }\n\n  private constructor(public readonly value: string) {}\n}", "language": "typescript"}
{"input": "Stack verification steps: -- the zookeeper string is returned as a cfnoutput to the console", "output": "class KafkaZookeeperTest extends Stack {\n  public readonly zookeeperConnection: string;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const vpc = new Vpc(this, 'Vpc', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const cluster = new msk.Cluster(this, 'ClusterZookeeper', {\n      clusterName: 'cluster-zookeeper',\n      kafkaVersion: msk.KafkaVersion.V3_5_1,\n      vpc,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    this.zookeeperConnection = cluster.zookeeperConnectionString;\n\n    new CfnOutput(this, 'Zookeeper', {\n      value: this.zookeeperConnection,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Method for AWS resource management", "output": "export class Method extends Resource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.Method';\n\n  /** @attribute */\n  public readonly methodId: string;\n\n  public readonly httpMethod: string;\n  public readonly resource: IResource;\n  /**\n   * The API Gateway RestApi associated with this method.\n   */\n  public readonly api: IRestApi;\n\n  private readonly methodResponses: MethodResponse[] = [];\n\n  constructor(scope: Construct, id: string, props: MethodProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.resource = props.resource;\n    this.api = props.resource.api;\n    this.httpMethod = props.httpMethod.toUpperCase();\n\n    validateHttpMethod(this.httpMethod);\n\n    const options = props.options || {};\n    const defaultMethodOptions = props.resource.defaultMethodOptions || {};\n\n    // do not use the default authorizer config in case if the provided authorizer type is None\n    const authorizer =\n      options.authorizationType === AuthorizationType.NONE\n        && options.authorizer == undefined ? undefined : options.authorizer || defaultMethodOptions.authorizer;\n    const authorizerId = authorizer?.authorizerId ? authorizer.authorizerId : undefined;\n\n    /**\n     * Get and validate authorization type from the values set by API resource and method.\n     *\n     * REST API Resource\n     * \u2514\u2500\u2500 defaultMethodOptions: Method options to use as a default for all methods created within this API unless custom options are specified.\n     *    \u251c\u2500\u2500 authorizationType: Specifies the default authorization type unless custom options are specified, recommended to not be specified.\n     *    \u2514\u2500\u2500 authorizer: Specifies the default authorizer for all methods created within this API unless custom options are specified.\n     *        \u2514\u2500\u2500 authorizerType: The default authorization type of this authorizer.\n     *\n     * REST API Method\n     * \u2514\u2500\u2500 options: Method options.\n     *    \u251c\u2500\u2500 authorizationType: Specifies the authorization type, recommended to not be specified.\n     *    \u2514\u2500\u2500 authorizer: Specifies an authorizer to use for this method.\n     *        \u2514\u2500\u2500 authorizerType: The authorization type of this authorizer.\n     *\n     * Authorization type is first set to \"authorizer.authorizerType\", falling back to method's \"authorizationType\",\n     * falling back to API resource's default \"authorizationType\", and lastly \"Authorizer.NONE\".\n     *\n     * Note that \"authorizer.authorizerType\" should match method or resource's \"authorizationType\" if exists.\n     */\n    const authorizationType = this.getMethodAuthorizationType(options, defaultMethodOptions, authorizer);\n\n    // AuthorizationScope should only be applied to COGNITO_USER_POOLS AuthorizationType.\n    const defaultScopes = options.authorizationScopes ?? defaultMethodOptions.authorizationScopes;\n    const authorizationScopes = authorizationType === AuthorizationType.COGNITO ? defaultScopes : undefined;\n    if (authorizationType !== AuthorizationType.COGNITO && defaultScopes) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-apigateway:invalidAuthScope', '\\'AuthorizationScopes\\' can only be set when \\'AuthorizationType\\' sets \\'COGNITO_USER_POOLS\\'. Default to ignore the values set in \\'AuthorizationScopes\\'.');\n    }\n\n    if (Authorizer.isAuthorizer(authorizer)) {\n      authorizer._attachToApi(this.api);\n    }\n\n    for (const mr of options.methodResponses ?? defaultMethodOptions.methodResponses ?? []) {\n      this.addMethodResponse(mr);\n    }\n\n    const integration = props.integration ?? this.resource.defaultIntegration ?? new MockIntegration();\n    const bindResult = integration.bind(this);\n\n    const methodProps: CfnMethodProps = {\n      resourceId: props.resource.resourceId,\n      restApiId: this.api.restApiId,\n      httpMethod: this.httpMethod,\n      operationName: options.operationName || defaultMethodOptions.operationName,\n      apiKeyRequired: options.apiKeyRequired ?? defaultMethodOptions.apiKeyRequired,\n      authorizationType,\n      authorizerId,\n      requestParameters: options.requestParameters || defaultMethodOptions.requestParameters,\n      integration: this.renderIntegration(bindResult),\n      methodResponses: Lazy.any({ produce: () => this.renderMethodResponses(this.methodResponses) }, { omitEmptyArray: true }),\n      requestModels: this.renderRequestModels(options.requestModels),\n      requestValidatorId: this.requestValidatorId(options),\n      authorizationScopes: authorizationScopes,\n    };\n\n    const resource = new CfnMethod(this, 'Resource', methodProps);\n\n    this.methodId = resource.ref;\n\n    if (RestApiBase._isRestApiBase(props.resource.api)) {\n      props.resource.api._attachMethod(this);\n    }\n\n    const deployment = props.resource.api.latestDeployment;\n    if (deployment) {\n      deployment.node.addDependency(resource);\n      deployment.addToLogicalId({\n        method: {\n          ...methodProps,\n          integrationToken: bindResult?.deploymentToken,\n        },\n      });\n    }\n  }", "language": "typescript"}
{"input": "CDK Stack that creates S3, WAF, EventBridge, Kinesis resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\n        \"SELECT * FROM 'device/+/data'\",\n      ),\n    });\n\n    const bucket = new s3.Bucket(this, 'MyBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    const stream = new firehose.DeliveryStream(this, 'MyStream', {\n      destination: new firehose.S3Bucket(bucket),\n    });\n    topicRule.addAction(\n      new actions.FirehosePutRecordAction(stream, {\n        batchMode: true,\n        recordSeparator: actions.FirehoseRecordSeparator.NEWLINE,\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, WAF, EventBridge resources", "output": "export class R53ResolverStack extends cdk.Stack {\n  protected targetVpc: Vpc;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    // Create a VPC for us to deploy into.\n    this.targetVpc = new R53ResolverVPC(this, \"R53ResolverTestVPC\").vpc;\n    this.createDnsFirewall();\n    this.createOutboundEndpoint();\n    this.createInboundEndpoint();\n  }\n\n  createDnsFirewall() {\n    // @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-route53resolver-alpha-readme.html\n    // Example of directly including domains in a list.\n    const directBlockList = new route53resolverAlpha.FirewallDomainList(\n      this,\n      \"BlockList\",\n      {\n        domains: route53resolverAlpha.FirewallDomains.fromList([\n          \"example.com\",\n          \"example.net\",\n        ]),\n      }\n    );\n\n    // Create a rule group to handle our list of blocked domains.\n    const ruleGroup = new route53resolverAlpha.FirewallRuleGroup(\n      this,\n      \"BlockListRuleGroup\",\n      {\n        rules: [\n          {\n            priority: 10,\n            firewallDomainList: directBlockList,\n            action: route53resolverAlpha.FirewallRuleAction.block(),\n          },\n        ],\n      }\n    );\n\n    ruleGroup.associate(\"DirectBlockListRuleGroupAssociation\", {\n      priority: 101,\n      vpc: this.targetVpc,\n    });\n\n    const consoleBaseUrl = `https://console.aws.amazon.com/`;\n    const region = cdk.Stack.of(this).region;\n    const vpcBaseUrl = `${consoleBaseUrl}vpc/home?region=${region}`;\n\n    // Output details of the VPC.\n    new cdk.CfnOutput(this, \"VPC-Id\", { value: this.targetVpc.vpcId });\n    new cdk.CfnOutput(this, \"VPC-Link\", {\n      value: `https://console.aws.amazon.com/vpcconsole/home/#VpcDetails:VpcId=${this.targetVpc.vpcId}`,\n    });\n\n    // Output details of the DNS firewall.\n    new cdk.CfnOutput(this, \"DNS-Firewall-Id\", {\n      value: ruleGroup.firewallRuleGroupId,\n    });\n    new cdk.CfnOutput(this, \"DNS-Firewall-Link\", {\n      value: `${vpcBaseUrl}#DNSFirewallRuleGroupDetails:RulegroupId=${ruleGroup.firewallRuleGroupId}`,\n    });\n  }\n\n  /**\n   * Creates an outbound endpoint, for resources inside the VPC to use as a DNS server.\n   */\n  createOutboundEndpoint() {\n    const sgOutboundEndpoint = new ec2.SecurityGroup(\n      this,\n      \"sg-outbound-endpoint\",\n      {\n        vpc: this.targetVpc,\n        allowAllOutbound: true,\n        description: \"Security group for outbound endpoint\",\n      }\n    );\n\n    sgOutboundEndpoint.addIngressRule(\n      ec2.Peer.ipv4(this.targetVpc.vpcCidrBlock),\n      ec2.Port.tcp(53)\n    );\n\n    sgOutboundEndpoint.addIngressRule(\n      ec2.Peer.ipv4(this.targetVpc.vpcCidrBlock),\n      ec2.Port.udp(53)\n    );\n\n    const subnets = this.targetVpc.selectSubnets({\n      subnetType: cdk.aws_ec2.SubnetType.PRIVATE_ISOLATED,\n    });\n    let subnetList = [];\n    for (const subnet of subnets.subnets) {\n      subnetList.push(subnet.subnetId);\n    }\n\n    // @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_route53resolver.CfnResolverEndpoint.html\n    // @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-route53resolver-resolverendpoint.html\n    const outboundEndpoint = new route53resolver.CfnResolverEndpoint(\n      this,\n      \"OutboundEndpoint\",\n      {\n        direction: \"OUTBOUND\",\n        // Two IP addresses for the endpoint are required.\n        ipAddresses: [{ subnetId: subnetList[0] }, { subnetId: subnetList[1] }],\n        securityGroupIds: [sgOutboundEndpoint.securityGroupId],\n      }\n    );\n\n    new cdk.CfnOutput(this, \"OutboundEndpointId\", {\n      value: outboundEndpoint.attrResolverEndpointId,\n    });\n\n    const region = cdk.Stack.of(this).region;\n    new cdk.CfnOutput(this, \"OutboundEndpointLink\", {\n      value: `https://${region}.console.aws.amazon.com/route53resolver/home?region=${region}#/endpoint/${outboundEndpoint.attrResolverEndpointId}`,\n    });\n  }\n\n  /**\n   * Creates an inbound endpoint, for resources outside the VPC to use as a DNS server.\n   */\n  createInboundEndpoint() {\n    const sgInboundEndpoint = new ec2.SecurityGroup(\n      this,\n      \"sg-inbound-endpoint\",\n      {\n        vpc: this.targetVpc,\n        allowAllOutbound: true,\n        description: \"Security group for inbound endpoint\",\n      }\n    );\n\n    // This VPC is not enabled for traffic from outside, either public\n    // or via a private VIF.\n    // We are using 203.0.113.0/24 from RFC5737 here just as an example value;\n    // you might use an external IP or peered VPC.\n    sgInboundEndpoint.addIngressRule(\n      ec2.Peer.ipv4(RFC5737_TEST_NET_3),\n      ec2.Port.tcp(53)\n    );\n\n    sgInboundEndpoint.addIngressRule(\n      ec2.Peer.ipv4(RFC5737_TEST_NET_3),\n      ec2.Port.udp(53)\n    );\n\n    const subnets = this.targetVpc.selectSubnets({\n      subnetType: cdk.aws_ec2.SubnetType.PRIVATE_ISOLATED,\n    });\n    let subnetList = [];\n    for (const subnet of subnets.subnets) {\n      subnetList.push(subnet.subnetId);\n    }\n\n    const inboundEndpoint = new route53resolver.CfnResolverEndpoint(\n      this,\n      \"InboundEndpoint\",\n      {\n        direction: \"INBOUND\",\n        ipAddresses: [{ subnetId: subnetList[0] }, { subnetId: subnetList[1] }],\n        securityGroupIds: [sgInboundEndpoint.securityGroupId],\n      }\n    );\n\n    new cdk.CfnOutput(this, \"InboundEndpointId\", {\n      value: inboundEndpoint.attrResolverEndpointId,\n    });\n\n    const region = cdk.Stack.of(this).region;\n    new cdk.CfnOutput(this, \"InboundEndpointLink\", {\n      value: `https://${region}.console.aws.amazon.com/route53resolver/home?region=${region}#/endpoint/${inboundEndpoint.attrResolverEndpointId}`,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class NpmIgnoreForJsiiModules for AWS resource management", "output": "export class NpmIgnoreForJsiiModules extends ValidationRule {\n  public readonly name = 'ignore/jsii';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    fileShouldContain(this.name, pkg, '.npmignore',\n      '*.ts',\n      '!*.d.ts',\n      '!*.js',\n      '!*.lit.ts', // <- This is part of the module's documentation!\n      'coverage',\n      '.nyc_output',\n      '*.tgz',\n    );\n  }\n}\n\n/**\n * Must use 'cdk-watch' command\n */\nexport class MustUseCDKWatch extends ValidationRule {\n  public readonly name = 'package-info/scripts/watch';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.watch', 'cdk-watch');\n  }\n}\n\n/**\n * Must have 'rosetta:extract' command if this package is JSII-enabled.\n */\nexport class MustHaveRosettaExtract extends ValidationRule {\n  public readonly name = 'package-info/scripts/rosetta:extract';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.rosetta:extract', 'yarn --silent jsii-rosetta extract');\n  }\n}\n\n/**\n * Must use 'cdk-test' command\n */\nexport class MustUseCDKTest extends ValidationRule {\n  public readonly name = 'package-info/scripts/test';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n    if (!hasTestDirectory(pkg)) { return; }\n\n    if (pkg.packageName !== '@aws-cdk/custom-resource-handlers') {\n      expectJSON(this.name, pkg, 'scripts.test', 'cdk-test');\n    }\n\n    // 'cdk-test' will calculate coverage, so have the appropriate\n    // files in .gitignore.\n    fileShouldContain(this.name, pkg, '.gitignore', '.nyc_output');\n    fileShouldContain(this.name, pkg, '.gitignore', 'coverage');\n    fileShouldContain(this.name, pkg, '.gitignore', 'nyc.config.js');\n  }\n}\n\n/**\n * Must declare minimum node version\n */\nexport class MustHaveNodeEnginesDeclaration extends ValidationRule {\n  public readonly name = 'package-info/engines';\n\n  public validate(pkg: PackageJson): void {\n    if (cdkMajorVersion() === 2) {\n      expectJSON(this.name, pkg, 'engines.node', '>= 18.0.0');\n    } else {\n      expectJSON(this.name, pkg, 'engines.node', '>= 10.13.0 <13 || >=13.7.0');\n    }\n  }\n}\n\n/**\n * Scripts that run integ tests must also have the individual 'integ' script to update them\n *\n * This commands comes from the dev-dependency cdk-integ-tools.\n */\nexport class MustHaveIntegCommand extends ValidationRule {\n  public readonly name = 'package-info/scripts/integ';\n\n  public validate(pkg: PackageJson): void {\n    if (!hasIntegTests(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.integ', /integ-runner/, undefined, false, true);\n\n    // We can't ACTUALLY require cdk-build-tools/package.json here,\n    // because WE don't depend on cdk-build-tools and we don't know if\n    // the package does.\n    expectDevDependency(this.name,\n      pkg,\n      '@aws-cdk/integ-runner',\n      '*');\n  }\n}", "language": "typescript"}
{"input": "A principal that represents a federated identity provider as from a OpenID Connect provider.", "output": "export class OpenIdConnectPrincipal extends WebIdentityPrincipal {\n  /**\n   *\n   * @param openIdConnectProvider OpenID Connect provider\n   * @param conditions The conditions under which the policy is in effect.\n   *   See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   */\n  constructor(openIdConnectProvider: IOIDCProviderRef, conditions: Conditions = {}) {\n    super(openIdConnectProvider.oidcProviderRef.oidcProviderArn, conditions ?? {});\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ Federated: [this.federated] }, this.conditions);\n  }\n\n  public toString() {\n    return `OpenIdConnectPrincipal(${this.federated})`;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for IAM, EventBridge operations", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        self.id = \"Consumer\"\n        self.event_bus_name = self.node.try_get_context(\"event_bus_name\")\n\n        self.event_bus = events.EventBus(\n            self,\n            self.id + \"EB\" + self.event_bus_name,\n            event_bus_name=self.event_bus_name,\n        )\n\n        self.event_bus_policy = events.CfnEventBusPolicy(\n            self,\n            self.id + \"EBPolicy\",\n            statement_id=\"AllowOrgToPutEvents\",\n            action=\"events:PutEvents\",\n            condition=events.CfnEventBusPolicy.ConditionProperty(\n                type=\"StringEquals\",\n                key=\"aws:PrincipalOrgID\",\n                value=self.node.try_get_context(\"organization_id\"),\n            ),\n            event_bus_name=self.event_bus.event_bus_name,\n            principal=\"*\",\n        )\n\n        self.deploy_consumer(self.event_bus)\n\n        # Adds CDK Nag check to stack resources\n        Aspects.of(self).add(AwsSolutionsChecks())", "language": "python"}
{"input": "CDK Stack that creates S3, CloudWatch Logs, CloudFormation, CDK Pipelines resources", "output": "class PipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const bucket = s3.Bucket.fromBucketName(this, 'LogBucket', 'bucket-name');\n    const logGroup = logs.LogGroup.fromLogGroupName(this, 'LogGroup', 'log-group-name');\n\n    const pipeline = new pipelines.CodePipeline(this, 'Pipeline', {\n      synth: new pipelines.ShellStep('Synth', {\n        input: pipelines.CodePipelineSource.gitHub('colifran/cdk-pipelines-demo', 'main'),\n        commands: [\n          'npm ci',\n          'npm run build',\n          'npx cdk synth',\n        ],\n      }),\n      codeBuildDefaults: {\n        logging: {\n          cloudWatch: {\n            logGroup,\n          },\n          s3: {\n            bucket,\n          },\n        },\n      },\n    });\n\n    pipeline.addStage(new AppStage(this, 'Beta'));\n\n    const group = pipeline.addWave('Wave1');\n    group.addStage(new AppStage(this, 'Prod1'));\n    group.addStage(new AppStage(this, 'Prod2'));\n\n    const group2 = pipeline.addWave('Wave2');\n    group2.addStage(new AppStage(this, 'Prod3'));\n    group2.addStage(new AppStage(this, 'Prod4'));\n    group2.addStage(new AppStage(this, 'Prod5'));\n    group2.addStage(new AppStage(this, 'Prod6'));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, SQS, CloudFormation resources", "output": "class EcsExecBatchStack extends cdk.Stack {\n  public readonly ec2ComputeEnvironment: batch.ManagedEc2EcsComputeEnvironment;\n  public readonly fargateComputeEnvironment: batch.FargateComputeEnvironment;\n  public readonly ec2JobQueue: batch.JobQueue;\n  public readonly fargateJobQueue: batch.JobQueue;\n  public readonly ec2JobDefinition: batch.EcsJobDefinition;\n  public readonly fargateJobDefinition: batch.EcsJobDefinition;\n\n  constructor(scope: cdk.App, id: string, props: cdk.StackProps = {}) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', {\n      maxAzs: 2,\n    });\n\n    this.ec2ComputeEnvironment = new batch.ManagedEc2EcsComputeEnvironment(this, 'ComputeEnv', {\n      vpc,\n      instanceTypes: [ec2.InstanceType.of(ec2.InstanceClass.M5, ec2.InstanceSize.LARGE)],\n      minvCpus: 0,\n      maxvCpus: 256,\n    });\n\n    this.ec2JobQueue = new batch.JobQueue(this, 'JobQueue', {\n      computeEnvironments: [\n        {\n          order: 1,\n          computeEnvironment: this.ec2ComputeEnvironment,\n        },\n      ],\n    });\n\n    this.ec2JobDefinition = new batch.EcsJobDefinition(this, 'EcsExecEc2JobDefinition', {\n      jobDefinitionName: 'EcsExecEc2TestJob',\n      container: new batch.EcsEc2ContainerDefinition(this, 'Ec2Container', {\n        image: ecs.ContainerImage.fromRegistry('public.ecr.aws/amazonlinux/amazonlinux:latest'),\n        cpu: 2,\n        memory: cdk.Size.mebibytes(2048),\n        enableExecuteCommand: true,\n        command: ['sh', '-c', 'echo \"Job started with ECS Exec enabled\"; sleep 300'], // Keep container running\n      }),\n    });\n\n    this.fargateJobDefinition = new batch.EcsJobDefinition(this, 'EcsExecFargateJobDefinition', {\n      container: new batch.EcsFargateContainerDefinition(this, 'FargateContainer', {\n        image: ecs.ContainerImage.fromRegistry('public.ecr.aws/amazonlinux/amazonlinux:latest'),\n        cpu: 0.25,\n        memory: cdk.Size.gibibytes(1),\n        enableExecuteCommand: true, // Enable ECS Exec\n        command: ['sh', '-c', 'echo \"Fargate Job started with ECS Exec enabled\"; sleep 300'], // Keep container running\n      }),\n    });\n\n    // Create Fargate compute environment\n    this.fargateComputeEnvironment = new batch.FargateComputeEnvironment(this, 'FargateComputeEnv', {\n      vpc,\n    });\n\n    this.fargateJobQueue = new batch.JobQueue(this, 'FargateJobQueue', {\n      computeEnvironments: [\n        {\n          order: 1,\n          computeEnvironment: this.fargateComputeEnvironment,\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "Helper class for S3-based dockerfile data references, containing additional permission grant methods on the S3 object", "output": "class S3DockerfileData extends DockerfileData {\n  protected readonly bucket: s3.IBucket;\n  protected readonly key: string;\n\n  protected constructor(bucket: s3.IBucket, key: string) {\n    super();\n\n    this.bucket = bucket;\n    this.key = key;\n  }\n\n  /**\n   * The rendered Dockerfile S3 URL, for use in CloudFormation\n   */\n  public render(): DockerfileTemplateConfig {\n    return { dockerfileTemplateUri: this.bucket.s3UrlForObject(this.key) };\n  }\n\n  /**\n   * Grant put permissions to the given grantee for the dockerfile data in S3\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The principal\n   */\n  public grantPut(grantee: iam.IGrantable): iam.Grant {\n    return this.bucket.grantPut(grantee, this.key);\n  }\n\n  /**\n   * Grant read permissions to the given grantee for the dockerfile data in S3\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The principal\n   */\n  public grantRead(grantee: iam.IGrantable): iam.Grant {\n    return this.bucket.grantRead(grantee, this.key);\n  }\n}", "language": "typescript"}
{"input": "CDK class PackageUpdateError for AWS resource management", "output": "class PackageUpdateError extends Error {\n  override cause?: Error;\n  constructor(message: string, options?: { cause: Error }) {\n    super(message);\n    this.name = 'PackageUpdateError';\n    this.cause = options?.cause;\n  }\n}", "language": "typescript"}
{"input": "Supported Elastic Inference (EI) instance types for SageMaker instance-based production variants. EI instances provide on-demand GPU computing for inference.", "output": "export class AcceleratorType {\n  /**\n   * ml.eia1.large\n   */\n  public static readonly EIA1_LARGE = AcceleratorType.of('ml.eia1.large');\n\n  /**\n   * ml.eia1.medium\n   */\n  public static readonly EIA1_MEDIUM = AcceleratorType.of('ml.eia1.medium');\n\n  /**\n   * ml.eia1.xlarge\n   */\n  public static readonly EIA1_XLARGE = AcceleratorType.of('ml.eia1.xlarge');\n\n  /**\n   * ml.eia2.large\n   */\n  public static readonly EIA2_LARGE = AcceleratorType.of('ml.eia2.large');\n\n  /**\n   * ml.eia2.medium\n   */\n  public static readonly EIA2_MEDIUM = AcceleratorType.of('ml.eia2.medium');\n\n  /**\n   * ml.eia2.xlarge\n   */\n  public static readonly EIA2_XLARGE = AcceleratorType.of('ml.eia2.xlarge');\n\n  /**\n   * Builds an AcceleratorType from a given string or token (such as a CfnParameter).\n   * @param acceleratorType An accelerator type as string\n   * @returns A strongly typed AcceleratorType\n   */\n  public static of(acceleratorType: string): AcceleratorType {\n    return new AcceleratorType(acceleratorType);\n  }\n\n  private readonly acceleratorTypeIdentifier: string;\n\n  constructor(acceleratorType: string) {\n    if (cdk.Token.isUnresolved(acceleratorType) || acceleratorType.startsWith('ml.')) {\n      this.acceleratorTypeIdentifier = acceleratorType;\n    } else {\n      throw new Error(`instance type must start with 'ml.'; (got ${acceleratorType})`);\n    }\n  }\n\n  /**\n   * Return the accelerator type as a string\n   * @returns The accelerator type as a string\n   */\n  public toString(): string {\n    return this.acceleratorTypeIdentifier;\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedDeploymentGroupBase for AWS resource management", "output": "export class ImportedDeploymentGroupBase extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codedeploy.ImportedDeploymentGroupBase';\n  public readonly deploymentGroupName: string;\n  public readonly deploymentGroupArn: string;\n\n  public get deploymentGroupRef(): DeploymentGroupReference {\n    return {\n      deploymentGroupName: this.deploymentGroupName,\n    };\n  }\n\n  constructor(scope: Construct, id: string, props: ImportedDeploymentGroupBaseProps) {\n    const deploymentGroupName = props.deploymentGroupName;\n    const deploymentGroupArn = Arn.format({\n      partition: Aws.PARTITION,\n      account: props.application.env.account,\n      region: props.application.env.region,\n      service: 'codedeploy',\n      resource: 'deploymentgroup',\n      resourceName: `${props.application.applicationRef.applicationName}/${deploymentGroupName}`,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    super(scope, id, { environmentFromArn: deploymentGroupArn });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    this.deploymentGroupName = deploymentGroupName;\n    this.deploymentGroupArn = deploymentGroupArn;\n  }\n\n  /**\n   * Bind DeploymentGroupConfig to the current group, if supported\n   *\n   * @internal\n   */\n  protected _bindDeploymentConfig(config: IDeploymentConfigRef): IDeploymentConfigRef {\n    return isIBindableDeploymentConfig(config) ? config.bindEnvironment(this) : config;\n  }\n}", "language": "typescript"}
{"input": "Helper class for working with Amazon-managed workflows", "output": "export class AmazonManagedWorkflow {\n  /**\n   * Imports the build-container Amazon-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static buildContainer(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'build-container',\n      workflowType: WorkflowType.BUILD,\n    });\n  }\n\n  /**\n   * Imports the build-image AWS-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static buildImage(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'build-image',\n      workflowType: WorkflowType.BUILD,\n    });\n  }\n\n  /**\n   * Imports the distribute-container AWS-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static distributeContainer(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'distribute-container',\n      workflowType: WorkflowType.DISTRIBUTION,\n    });\n  }\n\n  /**\n   * Imports the distribute-image AWS-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static distributeImage(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'distribute-image',\n      workflowType: WorkflowType.DISTRIBUTION,\n    });\n  }\n\n  /**\n   * Imports the test-container AWS-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static testContainer(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'test-container',\n      workflowType: WorkflowType.TEST,\n    });\n  }\n\n  /**\n   * Imports the test-image AWS-managed workflow\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   */\n  public static testImage(scope: Construct, id: string): IWorkflow {\n    return this.fromAmazonManagedWorkflowAttributes(scope, id, {\n      workflowName: 'test-image',\n      workflowType: WorkflowType.TEST,\n    });\n  }\n\n  /**\n   * Imports an AWS-managed workflow from its attributes\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param attrs The attributes of the AWS-managed workflow\n   */\n  public static fromAmazonManagedWorkflowAttributes(\n    scope: Construct,\n    id: string,\n    attrs: AmazonManagedWorkflowAttributes,\n  ): IWorkflow {\n    if (cdk.Token.isUnresolved(attrs.workflowType)) {\n      throw new cdk.ValidationError('workflowType cannot be a token', scope);\n    }\n\n    return Workflow.fromWorkflowArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        account: 'aws',\n        resource: 'workflow',\n        resourceName: `${attrs.workflowType.toLowerCase()}/${attrs.workflowName}/${LATEST_VERSION}`,\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK helper function delete", "output": "def delete(self, bucket_name):\n\n        delete_params = {\n            \"Bucket\": bucket_name,\n            \"Key\": \"helloWorld.txt\"\n        }\n\n        return AwsSdkCall(\n            action='deleteObject',\n            service='S3',\n            parameters=delete_params,\n            physical_resource_id=PhysicalResourceId.of('myAutomationExecution')\n        )", "language": "python"}
{"input": "CDK Stack that creates Lambda, KMS, CloudWatch, CloudFormation resources", "output": "export class LambdaPCScalingTargetStack extends Stack {\n  private lambdaFunction: Function\n  private lambdaFunctionName: string\n\n  constructor(scope: Construct, id: string, props: LambdaPCScalingTargetStackProps) {\n    super(scope, id, props);\n    this.lambdaFunctionName = props.functionName\n\n    // Create Sample Lambda Function which will create metrics\n    this.lambdaFunction = new NodejsFunction(this, 'LambdaFunction', {\n      functionName: this.lambdaFunctionName,\n      entry: `./lambda/lambda-handler.ts`,\n      runtime: Runtime.NODEJS_18_X,\n      memorySize: 512,\n      timeout: Duration.seconds(6),\n    });\n    // Enable Provisioned Concurrency\n    new Alias(this, `LambdaFunctionAlias`, {\n      aliasName: 'provisioned',\n      version: this.lambdaFunction.currentVersion,\n      provisionedConcurrentExecutions: 1,\n    });\n    // Create Metric of Lambda Provisioned Concurrency \n    const metrics = new Metric({\n      metricName: 'ProvisionedConcurrencyUtilization',\n      namespace: 'AWS/Lambda',\n      dimensionsMap: {\n        FunctionName: this.lambdaFunction.functionName,\n        Resource: `${this.lambdaFunction.functionName}:'provisioned`,\n      },\n      statistic: 'Maximum',\n      period: Duration.minutes(5),\n    });\n    // Enable AutoScaling Scalable Target when over target threshold(0.8)\n    new ScalableTarget(this, `${this.lambdaFunctionName}ScalableTarget`, {\n      serviceNamespace: ServiceNamespace.LAMBDA,\n      maxCapacity: 2,\n      minCapacity: 1,\n      resourceId: `function:${this.lambdaFunctionName}:provisioned`,\n      scalableDimension: 'lambda:function:ProvisionedConcurrency',\n    }).scaleToTrackMetric(`${this.lambdaFunctionName}PCScaleTracking`, {\n      targetValue: 0.8,\n      customMetric: metrics,\n    });\n  };\n}", "language": "typescript"}
{"input": "CDK class KinesisWithDLQTest for AWS resource management", "output": "class KinesisWithDLQTest extends Stack {\n  constructor(scope: App, id: string) {\n    super(scope, id);\n\n    const fn = new lambda.Function(this, 'F', {\n      runtime: STANDARD_NODEJS_RUNTIME,\n      handler: 'index.handler',\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n    });\n    new CfnOutput(this, 'FunctionArn', { value: fn.functionArn });\n\n    const stream = new kinesis.Stream(this, 'S');\n    new CfnOutput(this, 'InputKinesisStreamName', { value: stream.streamName });\n\n    const dlq = new sqs.Queue(this, 'Q');\n    new CfnOutput(this, 'DlqSqsQueueUrl', { value: dlq.queueUrl });\n\n    fn.addEventSource(new KinesisEventSource(stream, {\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      onFailure: new SqsDlq(dlq),\n      retryAttempts: 0,\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, CloudFormation, EFS resources", "output": "class StorageStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        elasticfilestore = efs.CfnFileSystem(\n                self, \"efs-storage\",\n                encrypted=False,\n                lifecycle_policies=None\n                )\n\n        sg_efs = ec2.SecurityGroup(\n                self,\n                id=\"sg_efs\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_efs\"\n                )\n\n        sg_efs.add_ingress_rule(\n                peer=ec2.Peer.ipv4(\"10.0.0.0/16\"),\n                connection=ec2.Port.tcp(2049)\n                )", "language": "python"}
{"input": "Keywords must contain CDK keywords and be sorted", "output": "export class CDKKeywords extends ValidationRule {\n  public readonly name = 'package-info/keywords';\n\n  public validate(pkg: PackageJson): void {\n    if (!pkg.json.keywords) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'Must have keywords',\n        fix: () => { pkg.json.keywords = []; },\n      });\n    }\n\n    const keywords = pkg.json.keywords || [];\n\n    if (keywords.indexOf('cdk') === -1) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'Keywords must mention CDK',\n        fix: () => { pkg.json.keywords.splice(0, 0, 'cdk'); },\n      });\n    }\n\n    if (keywords.indexOf('aws') === -1) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'Keywords must mention AWS',\n        fix: () => { pkg.json.keywords.splice(0, 0, 'aws'); },\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class JSIIPythonTarget for AWS resource management", "output": "export class JSIIPythonTarget extends ValidationRule {\n  public readonly name = 'jsii/python';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    const moduleName = cdkModuleName(pkg.json.name);\n\n    // See: https://aws.github.io/jsii/user-guides/lib-author/configuration/targets/python/\n\n    expectJSON(this.name, pkg, 'jsii.targets.python.distName', moduleName.python.distName);\n    expectJSON(this.name, pkg, 'jsii.targets.python.module', moduleName.python.module);\n    expectJSON(this.name, pkg, 'jsii.targets.python.classifiers', ['Framework :: AWS CDK', `Framework :: AWS CDK :: ${cdkMajorVersion()}`]);\n  }\n}", "language": "typescript"}
{"input": "CDK class KMSStateMachine for AWS resource management", "output": "class KMSStateMachine extends cdk.Stack {\n  readonly stateMachine: sfn.StateMachine;\n  readonly activity: sfn.Activity;\n  readonly stateMachineKmsKey: kms.Key;\n  readonly activityKmsKey: kms.Key;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.stateMachineKmsKey = new kms.Key(this, 'StateMachine Key', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    this.activityKmsKey = new kms.Key(this, 'Activity Key', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    this.activity = new sfn.Activity(this, 'ActivityWithCMKEncryptionConfiguration', {\n      activityName: 'ActivityWithCMKEncryptionConfiguration',\n      encryptionConfiguration: new sfn.CustomerManagedEncryptionConfiguration(this.activityKmsKey, cdk.Duration.seconds(75)),\n    });\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachineWithCMKEncryptionConfiguration', {\n      stateMachineName: 'StateMachineWithCMKEncryptionConfiguration',\n      definitionBody: sfn.DefinitionBody.fromChainable(sfn.Chain.start(new task.StepFunctionsInvokeActivity(this, 'Activity', {\n        activity: this.activity,\n        parameters: {\n          Hello: 'World',\n        },\n      }))),\n      stateMachineType: sfn.StateMachineType.STANDARD,\n      encryptionConfiguration: new sfn.CustomerManagedEncryptionConfiguration(this.stateMachineKmsKey, cdk.Duration.seconds(75)),\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Construct Constructs for reusable infrastructure components", "output": "export class Constructs extends ExternalModule {\n  public readonly Construct = Type.fromName(this, 'Construct');\n  public readonly IConstruct = Type.fromName(this, 'IConstruct');\n\n  constructor() {\n    super('constructs');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, RDS, EC2, VPC resources", "output": "class DatabaseInstanceStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    /// !show\n    // Set open cursors with parameter group\n    const parameterGroup = new rds.ParameterGroup(this, 'ParameterGroup', {\n      engine: rds.DatabaseInstanceEngine.oracleSe2({ version: rds.OracleEngineVersion.VER_19_0_0_0_2020_04_R1 }),\n      parameters: {\n        open_cursors: '2500',\n      },\n    });\n\n    /// Add XMLDB and OEM with option group\n    const optionGroup = new rds.OptionGroup(this, 'OptionGroup', {\n      engine: rds.DatabaseInstanceEngine.oracleSe2({ version: rds.OracleEngineVersion.VER_19_0_0_0_2020_04_R1 }),\n      configurations: [\n        {\n          name: 'LOCATOR',\n        },\n        {\n          name: 'OEM',\n          port: 1158,\n          vpc,\n        },\n      ],\n    });\n\n    // Allow connections to OEM\n    optionGroup.optionConnections.OEM.connections.allowDefaultPortFromAnyIpv4();\n\n    // Database instance with production values\n    const instance = new rds.DatabaseInstance(this, 'Instance', {\n      engine: rds.DatabaseInstanceEngine.oracleSe2({ version: rds.OracleEngineVersion.VER_19_0_0_0_2020_04_R1 }),\n      licenseModel: rds.LicenseModel.BRING_YOUR_OWN_LICENSE,\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.MEDIUM),\n      multiAz: true,\n      storageType: rds.StorageType.IO1,\n      credentials: rds.Credentials.fromUsername('syscdk'),\n      vpc,\n      databaseName: 'ORCL',\n      storageEncrypted: true,\n      backupRetention: cdk.Duration.days(7),\n      monitoringInterval: cdk.Duration.seconds(60),\n      enablePerformanceInsights: true,\n      cloudwatchLogsExports: [\n        'trace',\n        'audit',\n        'alert',\n        'listener',\n      ],\n      cloudwatchLogsRetention: logs.RetentionDays.ONE_MONTH,\n      autoMinorVersionUpgrade: true, // required to be true if LOCATOR is used in the option group\n      optionGroup,\n      parameterGroup,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    // Allow connections on default port from any IPV4\n    instance.connections.allowDefaultPortFromAnyIpv4();\n\n    // Rotate the master user password every 30 days\n    instance.addRotationSingleUser();\n\n    // Add alarm for high CPU\n    new cloudwatch.Alarm(this, 'HighCPU', {\n      metric: instance.metricCPUUtilization(),\n      threshold: 90,\n      evaluationPeriods: 1,\n    });\n\n    // Trigger Lambda function on instance availability events\n    const fn = new lambda.Function(this, 'Function', {\n      code: lambda.Code.fromInline('exports.handler = (event) => console.log(event);'),\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n    });\n\n    const availabilityRule = instance.onEvent('Availability', { target: new targets.LambdaFunction(fn) });\n    availabilityRule.addEventPattern({\n      detail: {\n        EventCategories: [\n          'availability',\n        ],\n      },\n    });\n    /// !hide\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, WAF, EventBridge resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new Vpc(this, 'Vpc', { maxAzs: 1, restrictDefaultSecurityGroup: false });\n\n    const blockList = new route53resolver.FirewallDomainList(this, 'BlockList', {\n      domains: route53resolver.FirewallDomains.fromList(['bad-domain.com', 'bot-domain.net']),\n    });\n    const overrideList = new route53resolver.FirewallDomainList(this, 'OverrideList', {\n      domains: route53resolver.FirewallDomains.fromList(['override-domain.com']),\n    });\n\n    new route53resolver.FirewallDomainList(this, 'OtherList', {\n      domains: route53resolver.FirewallDomains.fromAsset(path.join(__dirname, 'domains.txt')),\n    });\n\n    const ruleGroup = new route53resolver.FirewallRuleGroup(this, 'RuleGroup');\n\n    ruleGroup.addRule({\n      priority: 10,\n      firewallDomainList: blockList,\n      action: route53resolver.FirewallRuleAction.block(),\n    });\n    ruleGroup.addRule({\n      priority: 20,\n      firewallDomainList: overrideList,\n      action: route53resolver.FirewallRuleAction.block(route53resolver.DnsBlockResponse.override('amazon.com')),\n    });\n\n    ruleGroup.associate('Association', {\n      priority: 101,\n      vpc,\n    });\n  }\n}", "language": "typescript"}
{"input": "Helper class for working with AWS Marketplace components", "output": "export class AwsMarketplaceComponent {\n  /**\n   * Imports an AWS Marketplace component from its attributes\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param attrs The AWS-managed component attributes\n   */\n  public static fromAwsMarketplaceComponentAttributes(\n    scope: Construct,\n    id: string,\n    attrs: AwsMarketplaceComponentAttributes,\n  ): IComponent {\n    return Component.fromComponentArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        account: 'aws-marketplace',\n        resource: 'component',\n        resourceName: `${attrs.componentName}-${attrs.marketplaceProductId}/${attrs.componentVersion ?? LATEST_VERSION}`,\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "Class to keep track of acknowledgements There is a singleton instance for every `App` instance, which can be obtained by calling `Acknowledgements.of(...)`.", "output": "class Acknowledgements {\n  public static of(scope: IConstruct): Acknowledgements {\n    const app = App.of(scope);\n    if (!app) {\n      return new Acknowledgements();\n    }\n\n    const existing = (app as any)[Acknowledgements.ACKNOWLEDGEMENTS_SYM];\n    if (existing) {\n      return existing as Acknowledgements;\n    }\n\n    const fresh = new Acknowledgements();\n    (app as any)[Acknowledgements.ACKNOWLEDGEMENTS_SYM] = fresh;\n    return fresh;\n  }\n\n  private static ACKNOWLEDGEMENTS_SYM = Symbol.for('@aws-cdk/core.Acknowledgements');\n\n  private readonly acks = new Map<string, Set<string>>();\n\n  private constructor() {}\n\n  public add(node: string | IConstruct, ack: string) {\n    const nodePath = this.nodePath(node);\n\n    let arr = this.acks.get(nodePath);\n    if (!arr) {\n      arr = new Set();\n      this.acks.set(nodePath, arr);\n    }\n    arr.add(ack);\n  }\n\n  public has(node: string | IConstruct, ack: string): boolean {\n    for (const candidate of this.searchPaths(this.nodePath(node))) {\n      if (this.acks.get(candidate)?.has(ack)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  private nodePath(node: string | IConstruct) {\n    // Normalize, remove leading / if it exists\n    return (typeof node === 'string' ? node : node.node.path).replace(/^\\//, '');\n  }\n\n  /**\n   * Given 'a/b/c', return ['a/b/c', 'a/b', 'a']\n   */\n  private searchPaths(path: string) {\n    const ret = new Array<string>();\n    let start = 0;\n    while (start < path.length) {\n      let i = path.indexOf('/', start);\n      if (i !== -1) {\n        ret.push(path.substring(0, i));\n        start = i + 1;\n      } else {\n        start = path.length;\n      }\n    }\n    return ret.reverse();\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, IAM, CloudFormation resources", "output": "class TestStack extends Stack {\n  public constructor(scope: Construct, id: string, props: StackProps) {\n    super(scope, id, props);\n\n    Role.customizeRoles(this, {\n      usePrecreatedRoles: {\n        'cdk-table-with-customized-role/Role': 'my-precreated-role-name',\n      },\n    });\n\n    const table = new Table(this, 'Table', {\n      partitionKey: {\n        name: 'pk',\n        type: AttributeType.STRING,\n      },\n    });\n\n    // Add GSI will add a new Resource under IAM Policy\n    // i.e. `${this.tableArn}/index/*`. Test the Policy\n    // Synthesizer generation with concatenated value.\n    table.addGlobalSecondaryIndex({\n      indexName: 'gsi',\n      partitionKey: {\n        name: 'gsi-pk',\n        type: AttributeType.STRING,\n      },\n    });\n    const role = new Role(this, 'Role', {\n      assumedBy: new ServicePrincipal('dynamodb.amazonaws.com'),\n    });\n    table.grantReadData(role);\n  }\n}", "language": "typescript"}
{"input": "GitHub Enterprise Source definition for a CodeBuild project.", "output": "class GitHubEnterpriseSource extends CommonGithubSource {\n  public readonly type = GITHUB_ENTERPRISE_SOURCE_TYPE;\n  private readonly httpsCloneUrl: string;\n  private readonly ignoreSslErrors?: boolean;\n\n  constructor(props: GitHubEnterpriseSourceProps) {\n    super(props);\n    this.httpsCloneUrl = props.httpsCloneUrl;\n    this.ignoreSslErrors = props.ignoreSslErrors;\n  }\n\n  public bind(_scope: Construct, _project: IProject): SourceConfig {\n    if (this.hasCommitMessageFilterAndPrEvent()) {\n      throw new UnscopedValidationError('COMMIT_MESSAGE filters cannot be used with GitHub Enterprise Server pull request events');\n    }\n\n    if (this.hasFilePathFilterAndPrEvent()) {\n      throw new UnscopedValidationError('FILE_PATH filters cannot be used with GitHub Enterprise Server pull request events');\n    }\n\n    const superConfig = super.bind(_scope, _project);\n    return {\n      sourceProperty: {\n        ...superConfig.sourceProperty,\n        location: this.httpsCloneUrl,\n        insecureSsl: this.ignoreSslErrors,\n      },\n      sourceVersion: superConfig.sourceVersion,\n      buildTriggers: superConfig.buildTriggers,\n    };\n  }\n\n  private hasCommitMessageFilterAndPrEvent() {\n    return this.webhookFilters.some(fg => (\n      fg._filters.some(fp => fp.type === WebhookFilterTypes.COMMIT_MESSAGE) &&\n      this.hasPrEvent(fg._actions)));\n  }\n  private hasFilePathFilterAndPrEvent() {\n    return this.webhookFilters.some(fg => (\n      fg._filters.some(fp => fp.type === WebhookFilterTypes.FILE_PATH) &&\n      this.hasPrEvent(fg._actions)));\n  }\n  private hasPrEvent(actions: EventAction[]) {\n    return actions.includes(\n      EventAction.PULL_REQUEST_CREATED ||\n      EventAction.PULL_REQUEST_MERGED ||\n      EventAction.PULL_REQUEST_REOPENED ||\n      EventAction.PULL_REQUEST_UPDATED);\n  }\n}", "language": "typescript"}
{"input": "Returns true if each member in a list of strings matches at least one value in a second list of strings.", "output": "class FnEachMemberIn extends FnConditionBase {\n  /**\n   * Creates an ``Fn::EachMemberIn`` function.\n   * @param stringsToCheck A list of strings, such as \"A\", \"B\", \"C\". AWS CloudFormation checks whether each member in the strings_to_check parameter is in the strings_to_match parameter.\n   * @param stringsToMatch A list of strings, such as \"A\", \"B\", \"C\". Each member in the strings_to_match parameter is compared against the members of the strings_to_check parameter.\n   */\n  constructor(stringsToCheck: string[], stringsToMatch: string[]) {\n    super('Fn::EachMemberIn', [stringsToCheck, stringsToMatch]);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for AppSync operations", "output": "const when = () => {\n      new appsync.EventApi(stack, 'api', {\n        apiName: 'api',\n        authorizationConfig: {\n          authProviders: [iamProvider],\n          defaultPublishAuthModeTypes: [],\n        },\n      });\n    }", "language": "typescript"}
{"input": "CDK class RayJob for AWS resource management", "output": "export class RayJob extends Job {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.RayJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n  public readonly role: iam.IRole;\n  public readonly grantPrincipal: iam.IPrincipal;\n\n  /**\n   * RayJob constructor\n   */\n  constructor(scope: Construct, id: string, props: RayJobProps) {\n    super(scope, id, {\n      physicalName: props.jobName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.jobName = props.jobName ?? '';\n\n    // Set up role and permissions for principal\n    this.role = props.role;\n    this.grantPrincipal = this.role;\n\n    // Enable CloudWatch metrics and continuous logging by default as a best practice\n    const continuousLoggingArgs = this.setupContinuousLogging(this.role, props.continuousLogging);\n\n    // Conditionally include metrics arguments (default to enabled for backward compatibility)\n    const profilingMetricsArgs = (props.enableMetrics ?? true) ? { '--enable-metrics': '' } : {};\n    const observabilityMetricsArgs = (props.enableObservabilityMetrics ?? true) ? { '--enable-observability-metrics': 'true' } : {};\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...this.checkNoReservedArgs(props.defaultArguments),\n      ...continuousLoggingArgs,\n      ...profilingMetricsArgs,\n      ...observabilityMetricsArgs,\n    };\n\n    if (props.workerType && props.workerType !== WorkerType.Z_2X) {\n      throw new ValidationError('Ray jobs only support Z.2X worker type', this);\n    }\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.RAY,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n        runtime: props.runtime ? props.runtime : Runtime.RAY_TWO_FOUR,\n      },\n      glueVersion: GlueVersion.V4_0,\n      workerType: props.workerType ? props.workerType : WorkerType.Z_2X,\n      numberOfWorkers: props.numberOfWorkers ? props.numberOfWorkers: 3,\n      maxRetries: props.jobRunQueuingEnabled ? 0 : props.maxRetries,\n      jobRunQueuingEnabled: props.jobRunQueuingEnabled ? props.jobRunQueuingEnabled : false,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      defaultArguments,\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n}", "language": "typescript"}
{"input": "CDK class CompositeAlarm for AWS resource management", "output": "export class CompositeAlarm extends AlarmBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cloudwatch.CompositeAlarm';\n\n  /**\n   * Import an existing CloudWatch composite alarm provided an Name.\n   *\n   * @param scope The parent creating construct (usually `this`)\n   * @param id The construct's name\n   * @param compositeAlarmName Composite Alarm Name\n   */\n  public static fromCompositeAlarmName(scope: Construct, id: string, compositeAlarmName: string): IAlarm {\n    const stack = Stack.of(scope);\n\n    return this.fromCompositeAlarmArn(scope, id, stack.formatArn({\n      service: 'cloudwatch',\n      resource: 'alarm',\n      resourceName: compositeAlarmName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    }));\n  }\n\n  /**\n   * Import an existing CloudWatch composite alarm provided an ARN.\n   *\n   * @param scope The parent creating construct (usually `this`)\n   * @param id The construct's name\n   * @param compositeAlarmArn Composite Alarm ARN (i.e. arn:aws:cloudwatch:<region>:<account-id>:alarm:CompositeAlarmName)\n   */\n  public static fromCompositeAlarmArn(scope: Construct, id: string, compositeAlarmArn: string): IAlarm {\n    class Import extends AlarmBase implements IAlarm {\n      public readonly alarmArn = compositeAlarmArn;\n      public readonly alarmName = Stack.of(scope).splitArn(compositeAlarmArn, ArnFormat.COLON_RESOURCE_NAME).resourceName!;\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * ARN of this alarm\n   *\n   * @attribute\n   */\n  public readonly alarmArn: string;\n\n  /**\n   * Name of this alarm.\n   *\n   * @attribute\n   */\n  public readonly alarmName: string;\n\n  private readonly alarmRule: string;\n\n  constructor(scope: Construct, id: string, props: CompositeAlarmProps) {\n    super(scope, id, {\n      physicalName: props.compositeAlarmName ?? Lazy.string({ produce: () => this.generateUniqueId() }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.alarmRule.renderAlarmRule().length > 10240) {\n      throw new ValidationError('Alarm Rule expression cannot be greater than 10240 characters, please reduce the conditions in the Alarm Rule', this);\n    }\n\n    let extensionPeriod = props.actionsSuppressorExtensionPeriod;\n    let waitPeriod = props.actionsSuppressorWaitPeriod;\n    if (props.actionsSuppressor === undefined) {\n      if (extensionPeriod !== undefined || waitPeriod !== undefined) {\n        throw new ValidationError('ActionsSuppressor Extension/Wait Periods require an ActionsSuppressor to be set.', this);\n      }\n    } else {\n      extensionPeriod = extensionPeriod ?? Duration.minutes(1);\n      waitPeriod = waitPeriod ?? Duration.minutes(1);\n    }\n\n    this.alarmRule = props.alarmRule.renderAlarmRule();\n\n    const alarm = new CfnCompositeAlarm(this, 'Resource', {\n      alarmName: this.physicalName,\n      alarmRule: this.alarmRule,\n      alarmDescription: props.alarmDescription,\n      actionsEnabled: props.actionsEnabled,\n      alarmActions: Lazy.list({ produce: () => this.alarmActionArns }),\n      insufficientDataActions: Lazy.list({ produce: (() => this.insufficientDataActionArns) }),\n      okActions: Lazy.list({ produce: () => this.okActionArns }),\n      actionsSuppressor: props.actionsSuppressor?.alarmRef.alarmArn,\n      actionsSuppressorExtensionPeriod: extensionPeriod?.toSeconds(),\n      actionsSuppressorWaitPeriod: waitPeriod?.toSeconds(),\n    });\n\n    this.alarmName = this.getResourceNameAttribute(alarm.ref);\n    this.alarmArn = this.getResourceArnAttribute(alarm.attrArn, {\n      service: 'cloudwatch',\n      resource: 'alarm',\n      resourceName: this.physicalName,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n  }\n\n  private generateUniqueId(): string {\n    const name = Names.uniqueId(this);\n    if (name.length > 240) {\n      return name.substring(0, 120) + name.substring(name.length - 120);\n    }\n    return name;\n  }\n}", "language": "typescript"}
{"input": "Represents the \"actual\" results to compare", "output": "class ActualResult {\n  /**\n   * Get the actual results from a CustomResource\n   */\n  public static fromCustomResource(customResource: CustomResource, attribute: string): ActualResult {\n    return {\n      result: customResource.getAttString(attribute),\n    };\n  }\n\n  /**\n   * Get the actual results from a AwsApiCall\n   */\n  public static fromAwsApiCall(query: IApiCall, attribute: string): ActualResult {\n    return {\n      result: query.getAttString(attribute),\n    };\n  }\n\n  /**\n   * The actual results as a string\n   */\n  public abstract result: string;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, CloudFormation, CDK Pipelines, CodePipeline resources", "output": "class PipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const sourceBucket = new s3.Bucket(this, 'SourceBucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n    const pipeline = new pipelines.CodePipeline(this, 'Pipeline', {\n      synth: new pipelines.ShellStep('Synth', {\n        input: pipelines.CodePipelineSource.s3(sourceBucket, 'key'),\n        // input: pipelines.CodePipelineSource.gitHub('cdklabs/construct-hub-probe', 'main', {\n        //   trigger: GitHubTrigger.POLL,\n        // }),\n        commands: ['mkdir cdk.out', 'touch cdk.out/dummy'],\n      }),\n      selfMutation: false,\n      useChangeSets: false,\n    });\n\n    pipeline.addStage(new MyStage(this, 'MyStage', {}));\n  }\n}", "language": "typescript"}
{"input": "CDK class Transformer for AWS resource management", "output": "export class Transformer extends Resource {\n  /**\n   * The property injection ID for this resource class.\n   * Used by the CDK frameworks for managing resource lifecycle.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-logs.Transformer';\n\n  /** The Transformer L2 construct that represents AWS::Logs::Transformer CFN resource. */\n  constructor(scope: Construct, id: string, props: TransformerProps) {\n    super(scope, id, {\n      physicalName: props.transformerName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Validate the transformer configuration\n    this.validateProcessorCount(props.transformerConfig);\n    this.validateParserProcessors(props.transformerConfig);\n    this.validateUniqueProcessorTypes(props.transformerConfig);\n    this.validateLogGroupClass(props.logGroup);\n\n    // Map the transformer configuration to the L1 CloudFormation resource\n    new CfnTransformer(scope, 'ResourceTransformer', {\n      logGroupIdentifier: props.logGroup.logGroupRef.logGroupName,\n      transformerConfig: props.transformerConfig.map(processor => processor._render()),\n    });\n  }\n\n  /**\n   * @internal Validates that the number of processors doesn't exceed the AWS limit of 20 per transformer, and that at least\n   * one processor is provided.\n   */\n  private validateProcessorCount(processors: Array<IProcessor>): void {\n    // Skip validation if processors is a CDK token\n    if (Token.isUnresolved(processors)) {\n      return;\n    }\n\n    // Validate the number of processors is between 1 and 20 inclusive\n    if (processors.length === 0) {\n      throw new ValidationError('At least one processor is required in a transformer', this);\n    }\n\n    if (processors.length > 20) {\n      throw new ValidationError('A transformer cannot have more than 20 processors', this);\n    }\n  }\n  /**\n   * @internal Validates parser processor requirements: at least one parser-type processor is required, maximum of 5\n   * parser-type processors allowed, and if including a vended log parser, it must be the first processor.\n   */\n  private validateParserProcessors(processors: Array<IProcessor>): void {\n    // Skip validation if processors is a CDK token\n    if (Token.isUnresolved(processors)) {\n      return;\n    }\n    // Validate first processor is a parser\n    if (! (processors.at(0) instanceof ParserProcessor || processors.at(0) instanceof VendedLogParser)) {\n      throw new ValidationError('First processor in a transformer must be a parser', this);\n    }\n\n    // Identify parser-type processors (instances of ParserProcessor or VendedLogParser)\n    const parserProcessors = processors.filter(\n      p => p instanceof ParserProcessor || p instanceof VendedLogParser,\n    );\n\n    const vendedProcessors = processors.filter(\n      p => p instanceof VendedLogParser,\n    );\n\n    // Validate no more than 5 parser processors\n    if (parserProcessors.length > 5) {\n      throw new ValidationError('A transformer cannot have more than 5 parser-type processors', this);\n    }\n\n    // Validate at most one vended parser processor exists\n    if (vendedProcessors.length > 1) {\n      throw new ValidationError('Only one vended log parser is allowed in a transformer', this);\n    }\n\n    // Check if any vended log parser exists\n    const vendedLogParserIndex = processors.findIndex(p => p instanceof VendedLogParser);\n\n    // If a vended log parser exists, ensure it's the first processor\n    if (vendedLogParserIndex > 0) {\n      throw new ValidationError('AWS vended log parser must be the first processor in a transformer', this);\n    }\n  }", "language": "typescript"}
{"input": "Helper function to create a fresh stack for tests that need isolation", "output": "const createFreshStack = () => {\n    const freshApp = new App();\n    return new core.Stack(freshApp, `teststack${Date.now()}${Math.floor(Math.random() * 1000)}`);\n  }", "language": "typescript"}
{"input": "CDK class AugmentationsModule for AWS resource management", "output": "export class AugmentationsModule extends Module {\n  private _hasAugmentations: boolean = false;\n\n  /**\n   * Modules that contain classes that are normally handwritten\n   */\n  public readonly supportModules = new Array<Module>();\n\n  constructor(private readonly db: SpecDatabase, serviceName: string, cloudWatchModuleImport?: string) {\n    super(`${serviceName}.augmentations`);\n\n    this.documentation.push(\n      `Copyright 2012-${new Date().getFullYear()} Amazon.com, Inc. or its affiliates. All Rights Reserved.`,\n    );\n\n    CDK_CLOUDWATCH.import(this, 'cw', {\n      fromLocation: cloudWatchModuleImport,\n    });\n  }\n\n  public get hasAugmentations() {\n    return this._hasAugmentations;\n  }\n\n  public augmentResource(resource: Resource, resourceClass: ResourceClass) {\n    for (const { entity: aug } of this.db.follow('isAugmented', resource)) {\n      if (aug.metrics) {\n        this._hasAugmentations = true;\n        new ResourceGenerator(resource, resourceClass, aug, this.supportModules).emit(this);\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "Deployment identities are the class of roles to be assumed by the CDK when deploying the App.", "output": "export class DeploymentIdentities {\n  /**\n   * Use CLI credentials for all deployment identities.\n   */\n  public static cliCredentials(): DeploymentIdentities {\n    return new DeploymentIdentities({\n      cloudFormationExecutionRole: BootstrapRole.cliCredentials(),\n      deploymentRole: BootstrapRole.cliCredentials(),\n      lookupRole: BootstrapRole.cliCredentials(),\n    });\n  }\n\n  /**\n   * Specify your own roles for all deployment identities. These roles\n   * must already exist.\n   */\n  public static specifyRoles(roles: BootstrapRoles): DeploymentIdentities {\n    return new DeploymentIdentities(roles);\n  }\n\n  /**\n   * Use the Roles that have been created by the default bootstrap stack\n   */\n  public static defaultBootstrapRoles(options: DefaultBootstrapRolesOptions = {}): DeploymentIdentities {\n    function replacePlaceholders(x: string) {\n      if (options.bootstrapRegion !== undefined) {\n        x = x.replace(/\\$\\{AWS::Region\\}/g, options.bootstrapRegion);\n      }\n      return x;\n    }\n\n    return new DeploymentIdentities({\n      deploymentRole: BootstrapRole.fromRoleArn(replacePlaceholders(AppStagingSynthesizer.DEFAULT_DEPLOY_ROLE_ARN)),\n      cloudFormationExecutionRole: BootstrapRole.fromRoleArn(replacePlaceholders(AppStagingSynthesizer.DEFAULT_CLOUDFORMATION_ROLE_ARN)),\n      lookupRole: BootstrapRole.fromRoleArn(replacePlaceholders(AppStagingSynthesizer.DEFAULT_LOOKUP_ROLE_ARN)),\n    });\n  }\n\n  /**\n   * CloudFormation Execution Role\n   */\n  public readonly cloudFormationExecutionRole?: BootstrapRole;\n\n  /**\n   * Deployment Action Role\n   */\n  public readonly deploymentRole?: BootstrapRole;\n\n  /**\n   * Lookup Role\n    @default - use bootstrapped role\n   */\n  public readonly lookupRole?: BootstrapRole;\n\n  private constructor(\n    /** roles that are bootstrapped to your account. */\n    roles: BootstrapRoles,\n  ) {\n    this.cloudFormationExecutionRole = roles.cloudFormationExecutionRole;\n    this.deploymentRole = roles.deploymentRole;\n    this.lookupRole = roles.lookupRole;\n  }\n}", "language": "typescript"}
{"input": "Homepage must point to the GitHub repository page.", "output": "export class HomepageCorrect extends ValidationRule {\n  public readonly name = 'package-info/homepage';\n\n  public validate(pkg: PackageJson): void {\n    expectJSON(this.name, pkg, 'homepage', 'https://github.com/aws/aws-cdk');\n  }\n}", "language": "typescript"}
{"input": "CDK class Guardrail for AWS resource management", "output": "export class Guardrail extends GuardrailBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-alpha.Guardrail';\n\n  /**\n   * Import a guardrail given its attributes\n   */\n  public static fromGuardrailAttributes(scope: Construct, id: string, attrs: GuardrailAttributes): IGuardrail {\n    class Import extends GuardrailBase {\n      public readonly guardrailArn = attrs.guardrailArn;\n      public readonly guardrailId = Arn.split(attrs.guardrailArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName!;\n      public readonly kmsKey = attrs.kmsKey;\n      public readonly lastUpdated = undefined;\n\n      constructor() {\n        super(scope, id);\n        this.updateVersion(attrs.guardrailVersion ?? 'DRAFT');\n      }\n    }\n\n    return new Import();\n  }\n\n  /**\n   * Import a low-level L1 Cfn Guardrail\n   */\n  public static fromCfnGuardrail(cfnGuardrail: bedrock.CfnGuardrail): IGuardrail {\n    return new (class extends GuardrailBase {\n      public readonly guardrailArn = cfnGuardrail.attrGuardrailArn;\n      public readonly guardrailId = cfnGuardrail.attrGuardrailId;\n      public readonly kmsKey = cfnGuardrail.kmsKeyArn\n        ? Key.fromKeyArn(this, '@FromCfnGuardrailKey', cfnGuardrail.kmsKeyArn)\n        : undefined;\n      public readonly lastUpdated = cfnGuardrail.attrUpdatedAt;\n\n      constructor() {\n        super(cfnGuardrail, '@FromCfnGuardrail');\n        this.updateVersion(cfnGuardrail.attrVersion);\n      }\n    })();\n  }\n\n  /**\n   * The ARN of the guardrail.\n   * @attribute\n   */\n  public readonly guardrailArn: string;\n  /**\n   * The ID of the guardrail.\n   * @attribute\n   */\n  public readonly guardrailId: string;\n  /**\n   * The name of the guardrail.\n   */\n  public readonly name: string;\n  /**\n   * The KMS key used to encrypt data.\n   *\n   * @default undefined - \"Data is encrypted by default with a key that AWS owns and manages for you\"\n   */\n  public readonly kmsKey?: IKey;\n  /**\n   * The content filters applied by the guardrail.\n   */\n  public readonly contentFilters: filters.ContentFilter[];\n  /**\n   * The PII filters applied by the guardrail.\n   */\n  public readonly piiFilters: filters.PIIFilter[];\n  /**\n   * The regex filters applied by the guardrail.\n   */\n  public readonly regexFilters: filters.RegexFilter[];\n  /**\n   * The denied topic filters applied by the guardrail.\n   */\n  public readonly deniedTopics: filters.Topic[];\n  /**\n   * The contextual grounding filters applied by the guardrail.\n   */\n  public readonly contextualGroundingFilters: filters.ContextualGroundingFilter[];\n  /**\n   * The word filters applied by the guardrail.\n   */\n  public readonly wordFilters: filters.WordFilter[];\n  /**\n   * The managed word list filters applied by the guardrail.\n   */\n  public readonly managedWordListFilters: filters.ManagedWordFilter[];\n  /**\n   * When this guardrail was last updated\n   */\n  public readonly lastUpdated?: string;\n  /**\n   * The computed hash of the guardrail properties.\n   */\n  public readonly hash: string;\n  /**\n   * The L1 representation of the guardrail\n   */\n  private readonly __resource: bedrock.CfnGuardrail;\n\n  /**\n   * The tier that your guardrail uses for denied topic filters.\n   * @default filters.TierConfig.CLASSIC\n   */\n  public readonly topicsTierConfig: filters.TierConfig;\n\n  /**\n   * The tier that your guardrail uses for content filters.\n   * Consider using a tier that balances performance, accuracy, and compatibility with your existing generative AI workflows.\n   * @default filters.TierConfig.CLASSIC\n   */\n  public readonly contentFiltersTierConfig: filters.TierConfig;\n  /**\n   * The cross-region configuration for the guardrail.\n   */\n  public readonly crossRegionConfig?: GuardrailCrossRegionConfigProperty;\n\n  /**\n   * The message to return when the guardrail blocks a prompt.\n   * @default \"Sorry, your query violates our usage policy.\"\n   */\n  public readonly blockedInputMessaging: string;\n\n  /**\n   * The message to return when the guardrail blocks a model response.\n   * @default \"Sorry, I am unable to answer your question because of our usage policy.\"\n   */\n  public readonly blockedOutputsMessaging: string;\n\n  constructor(scope: Construct, id: string, props: GuardrailProps) {\n    super(scope, id, {\n      physicalName: props.guardrailName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // ------------------------------------------------------\n    // Set properties or defaults\n    // ------------------------------------------------------\n    this.name = this.physicalName;\n    this.contentFilters = props.contentFilters ?? [];\n    this.piiFilters = props.piiFilters ?? [];\n    this.regexFilters = props.regexFilters ?? [];\n    this.deniedTopics = props.deniedTopics ?? [];\n    this.contextualGroundingFilters = props.contextualGroundingFilters ?? [];\n    this.wordFilters = props.wordFilters ?? [];\n    this.managedWordListFilters = props.managedWordListFilters ?? [];\n    this.topicsTierConfig = props.topicsTierConfig ?? filters.TierConfig.CLASSIC;\n    this.contentFiltersTierConfig = props.contentFiltersTierConfig ?? filters.TierConfig.CLASSIC;\n    this.crossRegionConfig = props.crossRegionConfig;\n    this.blockedInputMessaging = props.blockedInputMessaging ?? 'Sorry, your query violates our usage policy.';\n    this.blockedOutputsMessaging = props.blockedOutputsMessaging ?? 'Sorry, I am unable to answer your question because of our usage policy.';\n\n    // ------------------------------------------------------\n    // Validate all filter arrays\n    // ------------------------------------------------------\n    this.validateContentFilters(this.contentFilters);\n    this.validatePiiFilters(this.piiFilters);\n    this.validateRegexFilters(this.regexFilters);\n    this.validateDeniedTopics(this.deniedTopics);\n    this.validateContextualGroundingFilters(this.contextualGroundingFilters);\n    this.validateWordFilters(this.wordFilters);\n    this.validateManagedWordListFilters(this.managedWordListFilters);\n\n    // ------------------------------------------------------\n    // Validate messaging properties\n    // ------------------------------------------------------\n    this.validateMessagingProperty(this.blockedInputMessaging, 'blockedInputMessaging');\n    this.validateMessagingProperty(this.blockedOutputsMessaging, 'blockedOutputsMessaging');\n\n    // ------------------------------------------------------\n    // Validate tier configuration requirements\n    // ------------------------------------------------------\n    this.validateTierConfiguration(props);\n\n    // ------------------------------------------------------\n    // CFN Props - With Lazy support\n    // ------------------------------------------------------\n    let cfnProps: bedrock.CfnGuardrailProps = {\n      name: props.guardrailName,\n      description: props.description,\n      kmsKeyArn: props.kmsKey?.keyArn,\n      blockedInputMessaging: this.blockedInputMessaging,\n      blockedOutputsMessaging: this.blockedOutputsMessaging,\n      // Lazy props\n      crossRegionConfig: this.generateCfnCrossRegionConfig(),\n      contentPolicyConfig: this.generateCfnContentPolicyConfig(),\n      contextualGroundingPolicyConfig: this.generateCfnContextualPolicyConfig(),\n      topicPolicyConfig: this.generateCfnTopicPolicy(),\n      wordPolicyConfig: this.generateCfnWordPolicyConfig(),\n      sensitiveInformationPolicyConfig: this.generateCfnSensitiveInformationPolicyConfig(),\n    };\n\n    // Hash calculation useful for versioning of the guardrail\n    this.hash = md5hash(JSON.stringify(cfnProps));\n\n    // ------------------------------------------------------\n    // L1 Instantiation\n    // ------------------------------------------------------\n    this.__resource = new bedrock.CfnGuardrail(this, 'MyGuardrail', cfnProps);\n\n    this.guardrailId = this.__resource.attrGuardrailId;\n    this.guardrailArn = this.__resource.attrGuardrailArn;\n    this.updateVersion(this.__resource.attrVersion);\n    this.lastUpdated = this.__resource.attrUpdatedAt;\n  }\n\n  // ------------------------------------------------------\n  // METHODS\n  // ------------------------------------------------------\n  /**\n   * Adds a content filter to the guardrail.\n   * @param filter The content filter to add.\n   */\n  @MethodMetadata()\n  public addContentFilter(filter: filters.ContentFilter): void {\n    this.validateSingleContentFilter(filter);\n    this.contentFilters.push(filter);\n  }\n\n  /**\n   * Adds a PII filter to the guardrail.\n   * @param filter The PII filter to add.\n   */\n  @MethodMetadata()\n  public addPIIFilter(filter: filters.PIIFilter): void {\n    this.validateSinglePiiFilter(filter);\n    this.piiFilters.push(filter);\n  }\n\n  /**\n   * Adds a regex filter to the guardrail.\n   * @param filter The regex filter to add.\n   */\n  @MethodMetadata()\n  public addRegexFilter(filter: filters.RegexFilter): void {\n    this.validateSingleRegexFilter(filter);\n    this.regexFilters.push(filter);\n  }\n\n  /**\n   * Adds a denied topic filter to the guardrail.\n   * @param filter The denied topic filter to add.\n   */\n  @MethodMetadata()\n  public addDeniedTopicFilter(filter: filters.Topic): void {\n    this.validateSingleDeniedTopic(filter);\n    this.deniedTopics.push(filter);\n  }\n\n  /**\n   * Adds a contextual grounding filter to the guardrail.\n   * @param filter The contextual grounding filter to add.\n   */\n  @MethodMetadata()\n  public addContextualGroundingFilter(filter: filters.ContextualGroundingFilter): void {\n    this.validateSingleContextualGroundingFilter(filter);\n    this.contextualGroundingFilters.push(filter);\n  }\n\n  /**\n   * Adds a word filter to the guardrail.\n   * @param filter The word filter to add.\n   */\n  @MethodMetadata()\n  public addWordFilter(filter: filters.WordFilter): void {\n    this.validateSingleWordFilter(filter);\n    this.wordFilters.push(filter);\n  }\n\n  /**\n   * Adds a word filter to the guardrail.\n   * @param filePath The location of the word filter file.\n   */\n  @MethodMetadata()\n  public addWordFilterFromFile(filePath: string,\n    inputAction?: filters.GuardrailAction,\n    outputAction?: filters.GuardrailAction,\n    inputEnabled?: boolean,\n    outputEnabled?: boolean): void {\n    const fileContents = fs.readFileSync(filePath, 'utf8');\n    const words = fileContents.trim().split(',');\n    for (const word of words) this.addWordFilter({ text: word, inputAction, outputAction, inputEnabled, outputEnabled });\n  }\n\n  /**\n   * Adds a managed word list filter to the guardrail.\n   * @param filter The managed word list filter to add.\n   */\n  @MethodMetadata()\n  public addManagedWordListFilter(filter: filters.ManagedWordFilter): void {\n    this.validateSingleManagedWordListFilter(filter);\n    this.managedWordListFilters.push(filter);\n  }\n\n  /**\n   * Create a version for the guardrail.\n   * @param description The description of the version.\n   * @returns The guardrail version.\n   */\n  @MethodMetadata()\n  public createVersion(description?: string): string {\n    const cfnVersion = new GuardrailVersion(this, `GuardrailVersion-${this.hash.slice(0, 16)}`, {\n      description: description,\n      guardrail: this,\n    });\n\n    this.updateVersion(cfnVersion.guardrailVersion);\n    return this.guardrailVersion;\n  }\n\n  // ------------------------------------------------------\n  // CFN Generators\n  // ------------------------------------------------------\n  /**\n   * Returns the content filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnContentPolicyConfig(): IResolvable {\n    return Lazy.any({\n      produce: () => {\n        if (this.contentFilters.length > 0) {\n          const contentPolicyConfig: bedrock.CfnGuardrail.ContentPolicyConfigProperty = {\n            filtersConfig: this.contentFilters,\n            ...(this.contentFiltersTierConfig && {\n              contentFiltersTierConfig: {\n                tierName: this.contentFiltersTierConfig,\n              } as bedrock.CfnGuardrail.ContentFiltersTierConfigProperty,\n            }),\n          };\n\n          return contentPolicyConfig;\n        } else {\n          return undefined;\n        }\n      },\n    });\n  }\n\n  /**\n   * Returns the topic filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnTopicPolicy(): IResolvable {\n    return Lazy.any({\n      produce: () => {\n        if (this.deniedTopics.length > 0) {\n          const topicPolicyConfig: bedrock.CfnGuardrail.TopicPolicyConfigProperty = {\n            topicsConfig: this.deniedTopics.flatMap((topic: filters.Topic) => {\n              return {\n                definition: topic.definition,\n                name: topic.name,\n                examples: topic.examples,\n                type: 'DENY',\n                inputAction: topic.inputAction,\n                inputEnabled: topic.inputEnabled,\n                outputAction: topic.outputAction,\n                outputEnabled: topic.outputEnabled,\n              } as bedrock.CfnGuardrail.TopicConfigProperty;\n            }),\n            ...(this.topicsTierConfig && {\n              topicsTierConfig: {\n                tierName: this.topicsTierConfig,\n              } as bedrock.CfnGuardrail.TopicsTierConfigProperty,\n            }),\n          };\n\n          return topicPolicyConfig;\n        } else {\n          return undefined;\n        }\n      },\n    });\n  }\n\n  /**\n   * Returns the contectual filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnContextualPolicyConfig(): IResolvable {\n    return Lazy.any({\n      produce: () => {\n        if (this.contextualGroundingFilters.length > 0) {\n          return {\n            filtersConfig: this.contextualGroundingFilters.flatMap((filter: filters.ContextualGroundingFilter) => {\n              return {\n                type: filter.type,\n                threshold: filter.threshold,\n                action: filter.action,\n                enabled: filter.enabled,\n              } as bedrock.CfnGuardrail.ContextualGroundingFilterConfigProperty;\n            }),\n          };\n        } else {\n          return undefined;\n        }\n      },\n    });\n  }\n\n  /**\n   * Returns the word config applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnWordPolicyConfig(): IResolvable {\n    return Lazy.any({\n      produce: () => {\n        if (this.wordFilters.length > 0 || this.managedWordListFilters.length > 0) {\n          return {\n            wordsConfig: this.generateCfnWordConfig(),\n            managedWordListsConfig: this.generateCfnManagedWordListsConfig(),\n          } as bedrock.CfnGuardrail.WordPolicyConfigProperty;\n        } else {\n          return undefined;\n        }\n      },\n    });\n  }\n\n  /**\n   * Returns the word filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnWordConfig(): IResolvable {\n    return Lazy.any(\n      {\n        produce: () => {\n          return this.wordFilters.flatMap((word: filters.WordFilter) => {\n            return {\n              text: word.text,\n              inputAction: word.inputAction,\n              inputEnabled: word.inputEnabled,\n              outputAction: word.outputAction,\n              outputEnabled: word.outputEnabled,\n            } as bedrock.CfnGuardrail.WordConfigProperty;\n          });\n        },\n      },\n      { omitEmptyArray: true },\n    );\n  }\n\n  /**\n   * Returns the word filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnManagedWordListsConfig(): IResolvable {\n    return Lazy.any(\n      {\n        produce: () => {\n          return this.managedWordListFilters.flatMap((filter: filters.ManagedWordFilter) => {\n            return {\n              type: filter.type,\n              inputAction: filter.inputAction,\n              inputEnabled: filter.inputEnabled,\n              outputAction: filter.outputAction,\n              outputEnabled: filter.outputEnabled,\n            } as bedrock.CfnGuardrail.ManagedWordsConfigProperty;\n          });\n        },\n      },\n      { omitEmptyArray: true },\n    );\n  }\n\n  /**\n   * Returns the sensitive information config applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnSensitiveInformationPolicyConfig(): IResolvable {\n    return Lazy.any(\n      {\n        produce: () => {\n          if (this.regexFilters.length > 0 || this.piiFilters.length > 0) {\n            return {\n              regexesConfig: this.generateCfnRegexesConfig(),\n              piiEntitiesConfig: this.generateCfnPiiEntitiesConfig(),\n            };\n          } else {\n            return undefined;\n          }\n        },\n      },\n      { omitEmptyArray: true },\n    );\n  }\n\n  /**\n   * Returns the regex filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnRegexesConfig(): IResolvable {\n    return Lazy.any(\n      {\n        produce: () => {\n          return this.regexFilters.flatMap((regex: filters.RegexFilter) => {\n            return {\n              name: regex.name,\n              description: regex.description,\n              pattern: regex.pattern,\n              action: regex.action,\n              inputAction: regex.inputAction,\n              inputEnabled: regex.inputEnabled,\n              outputAction: regex.outputAction,\n              outputEnabled: regex.outputEnabled,\n            } as bedrock.CfnGuardrail.RegexConfigProperty;\n          });\n        },\n      },\n      { omitEmptyArray: true },\n    );\n  }\n\n  /**\n   * Returns the Pii filters applied to the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnPiiEntitiesConfig(): IResolvable {\n    return Lazy.any(\n      {\n        produce: () => {\n          return this.piiFilters.flatMap((filter: filters.PIIFilter) => {\n            return {\n              type: filter.type.value,\n              action: filter.action,\n              inputAction: filter.inputAction,\n              inputEnabled: filter.inputEnabled,\n              outputAction: filter.outputAction,\n              outputEnabled: filter.outputEnabled,\n            } as bedrock.CfnGuardrail.PiiEntityConfigProperty;\n          });\n        },\n      },\n      { omitEmptyArray: true },\n    );\n  }\n\n  /**\n   * Returns the cross-region configuration for the guardrail. This method defers the computation\n   * to synth time.\n   */\n  private generateCfnCrossRegionConfig(): IResolvable {\n    return Lazy.any({\n      produce: () => {\n        if (this.crossRegionConfig) {\n          return {\n            guardrailProfileArn: this.crossRegionConfig.guardrailProfileArn,\n          } as bedrock.CfnGuardrail.GuardrailCrossRegionConfigProperty;\n        } else {\n          return undefined;\n        }\n      },\n    });\n  }\n\n  /**\n   * Validates a RegexFilter object and applies default values for optional properties.\n   * @param filter The regex filter to validate.\n   * @param index Optional index for error messages when validating arrays.\n   */\n  private validateRegexFilter(filter: filters.RegexFilter, index?: number): void {\n    const prefix = index !== undefined ? `Invalid RegexFilter at index ${index}` : 'Invalid RegexFilter';\n\n    // Validate name: between 1 and 100 characters\n    if (filter.name !== undefined && !Token.isUnresolved(filter.name)) {\n      if (filter.name.length < 1) {\n        throw new ValidationError(`${prefix}: The field name is ${filter.name.length} characters long but must be at least 1 characters`, this);\n      }\n      if (filter.name.length > 100) {\n        throw new ValidationError(`${prefix}: The field name is ${filter.name.length} characters long but must be less than or equal to 100 characters`, this);\n      }\n    }\n\n    // Validate description: between 1 and 1000 characters (if provided)\n    if (filter.description !== undefined && !Token.isUnresolved(filter.description)) {\n      if (filter.description.length < 1) {\n        throw new ValidationError(`${prefix}: The field description is ${filter.description.length} characters long but must be at least 1 characters`, this);\n      }\n      if (filter.description.length > 1000) {\n        throw new ValidationError(`${prefix}: The field description is ${filter.description.length} characters long but must be less than or equal to 1000 characters`, this);\n      }\n    }\n\n    // Validate pattern: at least one character\n    if (filter.pattern !== undefined && !Token.isUnresolved(filter.pattern)) {\n      if (filter.pattern.length < 1) {\n        throw new ValidationError(`${prefix}: The field pattern is ${filter.pattern.length} characters long but must be at least 1 characters`, this);\n      }\n    }\n\n    // Validate action: must be a valid GuardrailAction value\n    if (filter.action !== undefined && !Token.isUnresolved(filter.action) && !Object.values(filters.GuardrailAction).includes(filter.action)) {\n      throw new ValidationError(`${prefix}: action must be a valid GuardrailAction value`, this);\n    }\n\n    // Validate inputAction: must be a valid GuardrailAction value (if provided)\n    if (filter.inputAction !== undefined &&\n        !Token.isUnresolved(filter.inputAction) &&\n        !Object.values(filters.GuardrailAction).includes(filter.inputAction)) {\n      throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n    }\n\n    // Validate outputAction: must be a valid GuardrailAction value (if provided)\n    if (filter.outputAction !== undefined &&\n        !Token.isUnresolved(filter.outputAction) &&\n        !Object.values(filters.GuardrailAction).includes(filter.outputAction)) {\n      throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n    }\n\n    // Validate inputEnabled: must be a boolean (if provided)\n    if (filter.inputEnabled !== undefined &&\n        !Token.isUnresolved(filter.inputEnabled) &&\n        typeof filter.inputEnabled !== 'boolean') {\n      throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n    }\n\n    // Validate outputEnabled: must be a boolean (if provided)\n    if (filter.outputEnabled !== undefined &&\n        !Token.isUnresolved(filter.outputEnabled) &&\n        typeof filter.outputEnabled !== 'boolean') {\n      throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n    }\n\n    // Apply default values for optional properties if not provided\n    if (filter.inputAction === undefined) {\n      (filter as any).inputAction = filters.GuardrailAction.BLOCK;\n    }\n    if (filter.inputEnabled === undefined) {\n      (filter as any).inputEnabled = true;\n    }\n    if (filter.outputAction === undefined) {\n      (filter as any).outputAction = filters.GuardrailAction.BLOCK;\n    }\n    if (filter.outputEnabled === undefined) {\n      (filter as any).outputEnabled = true;\n    }\n  }\n\n  /**\n   * Validates a messaging property (blockedInputMessaging or blockedOutputsMessaging).\n   * @param value The messaging value to validate.\n   * @param propertyName The name of the property being validated.\n   */\n  private validateMessagingProperty(value: string | undefined, propertyName: string): void {\n    if (value !== undefined && !Token.isUnresolved(value)) {\n      if (value.length < 1) {\n        throw new ValidationError(`Invalid ${propertyName}: The field ${propertyName} is ${value.length} characters long but must be at least 1 characters`, this);\n      }\n      if (value.length > 500) {\n        throw new ValidationError(`Invalid ${propertyName}: The field ${propertyName} is ${value.length} characters long but must be less than or equal to 500 characters`, this);\n      }\n    }\n  }\n\n  /**\n   * Validates that cross-region configuration is provided when STANDARD tier is used.\n   * @param props The guardrail properties to validate.\n   */\n  private validateTierConfiguration(props: GuardrailProps): void {\n    const contentTierConfig = props.contentFiltersTierConfig ?? filters.TierConfig.CLASSIC;\n    const topicsTierConfig = props.topicsTierConfig ?? filters.TierConfig.CLASSIC;\n    const hasCrossRegionConfig = props.crossRegionConfig !== undefined;\n\n    // Check if STANDARD tier is used for content filters\n    if (contentTierConfig === filters.TierConfig.STANDARD && !hasCrossRegionConfig) {\n      throw new ValidationError(\n        'Cross-region configuration is required when using STANDARD tier for content filters. ' +\n        'Please provide a crossRegionConfig property with a valid guardrailProfileArn.',\n        this,\n      );\n    }\n\n    // Check if STANDARD tier is used for topic filters\n    if (topicsTierConfig === filters.TierConfig.STANDARD && !hasCrossRegionConfig) {\n      throw new ValidationError(\n        'Cross-region configuration is required when using STANDARD tier for topic filters. ' +\n        'Please provide a crossRegionConfig property with a valid guardrailProfileArn.',\n        this,\n      );\n    }\n  }\n\n  /**\n   * Validates content filters array and applies default values for optional properties.\n   * @param contentFilters The content filters to validate.\n   */\n  private validateContentFilters(contentFilters?: filters.ContentFilter[]): void {\n    if (!contentFilters) return;\n\n    contentFilters.forEach((filter, index) => {\n      const prefix = `Invalid ContentFilter at index ${index}`;\n\n      // Validate that the filter has required properties\n      if (!filter.type) {\n        throw new ValidationError(`${prefix}: type is required`, this);\n      }\n\n      // Validate input strength\n      if (filter.inputStrength !== undefined && !Token.isUnresolved(filter.inputStrength)) {\n        if (!Object.values(filters.ContentFilterStrength).includes(filter.inputStrength)) {\n          throw new ValidationError(`${prefix}: inputStrength must be a valid ContentFilterStrength value`, this);\n        }\n      }\n\n      // Validate output strength\n      if (filter.outputStrength !== undefined && !Token.isUnresolved(filter.outputStrength)) {\n        if (!Object.values(filters.ContentFilterStrength).includes(filter.outputStrength)) {\n          throw new ValidationError(`${prefix}: outputStrength must be a valid ContentFilterStrength value`, this);\n        }\n      }\n\n      // Validate input modalities\n      if (filter.inputModalities) {\n        filter.inputModalities.forEach((modality, modalityIndex) => {\n          if (!Object.values(filters.ModalityType).includes(modality)) {\n            throw new ValidationError(`${prefix}: inputModalities[${modalityIndex}] must be a valid ModalityType value`, this);\n          }\n        });\n      }\n\n      // Validate output modalities\n      if (filter.outputModalities) {\n        filter.outputModalities.forEach((modality, modalityIndex) => {\n          if (!Object.values(filters.ModalityType).includes(modality)) {\n            throw new ValidationError(`${prefix}: outputModalities[${modalityIndex}] must be a valid ModalityType value`, this);\n          }\n        });\n      }\n\n      // Validate inputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.inputAction !== undefined &&\n          !Token.isUnresolved(filter.inputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.inputAction)) {\n        throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate outputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.outputAction !== undefined &&\n          !Token.isUnresolved(filter.outputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.outputAction)) {\n        throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate inputEnabled: must be a boolean (if provided)\n      if (filter.inputEnabled !== undefined &&\n          !Token.isUnresolved(filter.inputEnabled) &&\n          typeof filter.inputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n      }\n\n      // Validate outputEnabled: must be a boolean (if provided)\n      if (filter.outputEnabled !== undefined &&\n          !Token.isUnresolved(filter.outputEnabled) &&\n          typeof filter.outputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (filter.inputAction === undefined) {\n        (filter as any).inputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.inputEnabled === undefined) {\n        (filter as any).inputEnabled = true;\n      }\n      if (filter.outputAction === undefined) {\n        (filter as any).outputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.outputEnabled === undefined) {\n        (filter as any).outputEnabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates PII filters array and applies default values for optional properties.\n   * @param piiFilters The PII filters to validate.\n   */\n  private validatePiiFilters(piiFilters?: filters.PIIFilter[]): void {\n    if (!piiFilters) return;\n\n    piiFilters.forEach((filter, index) => {\n      const prefix = `Invalid PIIFilter at index ${index}`;\n\n      // Validate that the filter has required properties\n      if (!filter.type) {\n        throw new ValidationError(`${prefix}: type is required`, this);\n      }\n\n      if (!filter.action) {\n        throw new ValidationError(`${prefix}: action is required`, this);\n      }\n\n      // Validate action values\n      if (!Token.isUnresolved(filter.action) && !Object.values(filters.GuardrailAction).includes(filter.action)) {\n        throw new ValidationError(`${prefix}: action must be a valid GuardrailAction value`, this);\n      }\n\n      if (filter.inputAction &&\n          !Token.isUnresolved(filter.inputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.inputAction)) {\n        throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n      }\n\n      if (filter.outputAction &&\n          !Token.isUnresolved(filter.outputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.outputAction)) {\n        throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate inputEnabled: must be a boolean (if provided)\n      if (filter.inputEnabled !== undefined &&\n          !Token.isUnresolved(filter.inputEnabled) &&\n          typeof filter.inputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n      }\n\n      // Validate outputEnabled: must be a boolean (if provided)\n      if (filter.outputEnabled !== undefined &&\n          !Token.isUnresolved(filter.outputEnabled) &&\n          typeof filter.outputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (filter.inputAction === undefined) {\n        (filter as any).inputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.inputEnabled === undefined) {\n        (filter as any).inputEnabled = true;\n      }\n      if (filter.outputAction === undefined) {\n        (filter as any).outputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.outputEnabled === undefined) {\n        (filter as any).outputEnabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates regex filters array.\n   * @param regexFilters The regex filters to validate.\n   */\n  private validateRegexFilters(regexFilters?: filters.RegexFilter[]): void {\n    if (!regexFilters) return;\n\n    regexFilters.forEach((filter, index) => {\n      this.validateRegexFilter(filter, index);\n    });\n  }\n\n  /**\n   * Validates denied topics array and applies default values for optional properties.\n   * @param deniedTopics The denied topics to validate.\n   */\n  private validateDeniedTopics(deniedTopics?: filters.Topic[]): void {\n    if (!deniedTopics) return;\n\n    deniedTopics.forEach((topic, index) => {\n      const prefix = `Invalid Topic at index ${index}`;\n\n      // Validate that the topic has required properties\n      if (!topic.name) {\n        throw new ValidationError(`${prefix}: name is required`, this);\n      }\n\n      if (!topic.definition) {\n        throw new ValidationError(`${prefix}: definition is required`, this);\n      }\n\n      // Validate name length\n      if (!Token.isUnresolved(topic.name) && topic.name.length > 100) {\n        throw new ValidationError(`${prefix}: name must be 100 characters or less`, this);\n      }\n\n      // Validate definition length\n      if (!Token.isUnresolved(topic.definition) && topic.definition.length > 1000) {\n        throw new ValidationError(`${prefix}: definition must be 1000 characters or less`, this);\n      }\n\n      // Validate examples if provided\n      if (topic.examples) {\n        if (topic.examples.length > 100) {\n          throw new ValidationError(`${prefix}: examples array cannot contain more than 100 examples`, this);\n        }\n\n        topic.examples.forEach((example, exampleIndex) => {\n          if (!Token.isUnresolved(example) && example.length > 100) {\n            throw new ValidationError(`${prefix}: examples[${exampleIndex}] must be 100 characters or less`, this);\n          }\n        });\n      }\n\n      // Validate inputAction: must be a valid GuardrailAction value (if provided)\n      if (topic.inputAction !== undefined &&\n          !Token.isUnresolved(topic.inputAction) &&\n          !Object.values(filters.GuardrailAction).includes(topic.inputAction)) {\n        throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate outputAction: must be a valid GuardrailAction value (if provided)\n      if (topic.outputAction !== undefined &&\n          !Token.isUnresolved(topic.outputAction) &&\n          !Object.values(filters.GuardrailAction).includes(topic.outputAction)) {\n        throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate inputEnabled: must be a boolean (if provided)\n      if (topic.inputEnabled !== undefined &&\n          !Token.isUnresolved(topic.inputEnabled) &&\n          typeof topic.inputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n      }\n\n      // Validate outputEnabled: must be a boolean (if provided)\n      if (topic.outputEnabled !== undefined &&\n          !Token.isUnresolved(topic.outputEnabled) &&\n          typeof topic.outputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (topic.inputAction === undefined) {\n        (topic as any).inputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (topic.inputEnabled === undefined) {\n        (topic as any).inputEnabled = true;\n      }\n      if (topic.outputAction === undefined) {\n        (topic as any).outputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (topic.outputEnabled === undefined) {\n        (topic as any).outputEnabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates contextual grounding filters array and applies default values for optional properties.\n   * @param contextualGroundingFilters The contextual grounding filters to validate.\n   */\n  private validateContextualGroundingFilters(contextualGroundingFilters?: filters.ContextualGroundingFilter[]): void {\n    if (!contextualGroundingFilters) return;\n\n    contextualGroundingFilters.forEach((filter, index) => {\n      const prefix = `Invalid ContextualGroundingFilter at index ${index}`;\n\n      // Validate that the filter has required properties\n      if (!filter.type) {\n        throw new ValidationError(`${prefix}: type is required`, this);\n      }\n\n      if (filter.threshold === undefined) {\n        throw new ValidationError(`${prefix}: threshold is required`, this);\n      }\n\n      // Validate type\n      if (!Object.values(filters.ContextualGroundingFilterType).includes(filter.type)) {\n        throw new ValidationError(`${prefix}: type must be a valid ContextualGroundingFilterType value`, this);\n      }\n\n      // Validate threshold range\n      if (!Token.isUnresolved(filter.threshold)) {\n        if (filter.threshold < 0 || filter.threshold > 0.99) {\n          throw new ValidationError(`${prefix}: threshold must be between 0 and 0.99`, this);\n        }\n      }\n\n      // Validate action: must be a valid GuardrailAction value (if provided)\n      if (filter.action !== undefined &&\n          !Token.isUnresolved(filter.action) &&\n          !Object.values(filters.GuardrailAction).includes(filter.action)) {\n        throw new ValidationError(`${prefix}: action must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate enabled: must be a boolean (if provided)\n      if (filter.enabled !== undefined &&\n          !Token.isUnresolved(filter.enabled) &&\n          typeof filter.enabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: enabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (filter.action === undefined) {\n        (filter as any).action = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.enabled === undefined) {\n        (filter as any).enabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates word filters array and applies default values for optional properties.\n   * @param wordFilters The word filters to validate.\n   */\n  private validateWordFilters(wordFilters?: filters.WordFilter[]): void {\n    if (!wordFilters) return;\n\n    wordFilters.forEach((filter, index) => {\n      const prefix = `Invalid WordFilter at index ${index}`;\n\n      // Validate that the filter has required properties\n      if (!filter.text) {\n        throw new ValidationError(`${prefix}: text is required`, this);\n      }\n\n      // Validate text length\n      if (!Token.isUnresolved(filter.text) && filter.text.length > 100) {\n        throw new ValidationError(`${prefix}: text must be 100 characters or less`, this);\n      }\n\n      // Validate inputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.inputAction !== undefined &&\n          !Token.isUnresolved(filter.inputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.inputAction)) {\n        throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate outputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.outputAction !== undefined &&\n          !Token.isUnresolved(filter.outputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.outputAction)) {\n        throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate inputEnabled: must be a boolean (if provided)\n      if (filter.inputEnabled !== undefined &&\n          !Token.isUnresolved(filter.inputEnabled) &&\n          typeof filter.inputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n      }\n\n      // Validate outputEnabled: must be a boolean (if provided)\n      if (filter.outputEnabled !== undefined &&\n          !Token.isUnresolved(filter.outputEnabled) &&\n          typeof filter.outputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (filter.inputAction === undefined) {\n        (filter as any).inputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.inputEnabled === undefined) {\n        (filter as any).inputEnabled = true;\n      }\n      if (filter.outputAction === undefined) {\n        (filter as any).outputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.outputEnabled === undefined) {\n        (filter as any).outputEnabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates managed word list filters array and applies default values for optional properties.\n   * @param managedWordListFilters The managed word list filters to validate.\n   */\n  private validateManagedWordListFilters(managedWordListFilters?: filters.ManagedWordFilter[]): void {\n    if (!managedWordListFilters) return;\n\n    managedWordListFilters.forEach((filter, index) => {\n      const prefix = `Invalid ManagedWordFilter at index ${index}`;\n\n      // Validate type: must be a valid ManagedWordFilterType value (if provided)\n      if (filter.type !== undefined && !Object.values(filters.ManagedWordFilterType).includes(filter.type)) {\n        throw new ValidationError(`${prefix}: type must be a valid ManagedWordFilterType value`, this);\n      }\n\n      // Validate inputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.inputAction !== undefined &&\n          !Token.isUnresolved(filter.inputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.inputAction)) {\n        throw new ValidationError(`${prefix}: inputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate outputAction: must be a valid GuardrailAction value (if provided)\n      if (filter.outputAction !== undefined &&\n          !Token.isUnresolved(filter.outputAction) &&\n          !Object.values(filters.GuardrailAction).includes(filter.outputAction)) {\n        throw new ValidationError(`${prefix}: outputAction must be a valid GuardrailAction value`, this);\n      }\n\n      // Validate inputEnabled: must be a boolean (if provided)\n      if (filter.inputEnabled !== undefined &&\n          !Token.isUnresolved(filter.inputEnabled) &&\n          typeof filter.inputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: inputEnabled must be a boolean value`, this);\n      }\n\n      // Validate outputEnabled: must be a boolean (if provided)\n      if (filter.outputEnabled !== undefined &&\n          !Token.isUnresolved(filter.outputEnabled) &&\n          typeof filter.outputEnabled !== 'boolean') {\n        throw new ValidationError(`${prefix}: outputEnabled must be a boolean value`, this);\n      }\n\n      // Apply default values for optional properties if not provided\n      if (filter.type === undefined) {\n        (filter as any).type = filters.ManagedWordFilterType.PROFANITY;\n      }\n      if (filter.inputAction === undefined) {\n        (filter as any).inputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.inputEnabled === undefined) {\n        (filter as any).inputEnabled = true;\n      }\n      if (filter.outputAction === undefined) {\n        (filter as any).outputAction = filters.GuardrailAction.BLOCK;\n      }\n      if (filter.outputEnabled === undefined) {\n        (filter as any).outputEnabled = true;\n      }\n    });\n  }\n\n  /**\n   * Validates a single content filter and applies default values for optional properties.\n   * @param filter The content filter to validate.\n   */\n  private validateSingleContentFilter(filter: filters.ContentFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateContentFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single PII filter and applies default values for optional properties.\n   * @param filter The PII filter to validate.\n   */\n  private validateSinglePiiFilter(filter: filters.PIIFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validatePiiFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single regex filter and applies default values for optional properties.\n   * @param filter The regex filter to validate.\n   */\n  private validateSingleRegexFilter(filter: filters.RegexFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateRegexFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single denied topic and applies default values for optional properties.\n   * @param filter The denied topic to validate.\n   */\n  private validateSingleDeniedTopic(filter: filters.Topic): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateDeniedTopics([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single contextual grounding filter and applies default values for optional properties.\n   * @param filter The contextual grounding filter to validate.\n   */\n  private validateSingleContextualGroundingFilter(filter: filters.ContextualGroundingFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateContextualGroundingFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single word filter and applies default values for optional properties.\n   * @param filter The word filter to validate.\n   */\n  private validateSingleWordFilter(filter: filters.WordFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateWordFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Validates a single managed word list filter and applies default values for optional properties.\n   * @param filter The managed word list filter to validate.\n   */\n  private validateSingleManagedWordListFilter(filter: filters.ManagedWordFilter): void {\n    // Use the existing validation logic but catch and re-throw with a clearer error message\n    try {\n      this.validateManagedWordListFilters([filter]);\n    } catch (error) {\n      if (error instanceof ValidationError) {\n        // Replace \"at index 0\" with a clearer message for single filter validation\n        const message = error.message.replace(' at index 0', '');\n        throw new ValidationError(message, this);\n      }\n      throw error;\n    }\n  }\n}", "language": "typescript"}
{"input": "Determines whether any HTTP headers are included in the cache key and automatically included in requests that CloudFront sends to the origin.", "output": "export class CacheHeaderBehavior {\n  /** HTTP headers are not included in the cache key and are not automatically included in requests that CloudFront sends to the origin. */\n  public static none() { return new CacheHeaderBehavior('none'); }\n  /** Listed headers are included in the cache key and are automatically included in requests that CloudFront sends to the origin. */\n  public static allowList(...headers: string[]) {\n    if (headers.length === 0) {\n      throw new UnscopedValidationError('At least one header to allow must be provided');\n    }\n    return new CacheHeaderBehavior('whitelist', headers);\n  }\n\n  /** If no headers will be passed, or an allow list of headers. */\n  public readonly behavior: string;\n  /** The headers for the allow/deny list, if applicable. */\n  public readonly headers?: string[];\n\n  private constructor(behavior: string, headers?: string[]) {\n    this.behavior = behavior;\n    this.headers = headers;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, API Gateway, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const api = new apigw.RestApi(this, 'cors-api-test', {\n      cloudWatchRole: true,\n    });\n\n    const handler = new lambda.Function(this, 'handler', {\n      runtime: STANDARD_NODEJS_RUNTIME,\n      handler: 'index.handler',\n      code: lambda.Code.fromAsset(path.join(__dirname, 'integ.cors.handler'), { exclude: ['*.ts'] }),\n    });\n\n    const twitch = api.root.addResource('twitch');\n    const backend = new apigw.LambdaIntegration(handler);\n\n    twitch.addMethod('GET', backend); // GET /twitch\n    twitch.addMethod('POST', backend); // POST /twitch\n    twitch.addMethod('DELETE', backend); // DELETE /twitch\n    twitch.addCorsPreflight({ allowOrigins: ['https://google.com', 'https://www.test-cors.org'] });\n  }\n}", "language": "typescript"}
{"input": "CDK class GrantReadTest for AWS resource management", "output": "class GrantReadTest extends GrantTestBase {\n  actions = perms.TABLE_READ_ACCESS;\n  getTableName() {\n    return 'grant_read_table';\n  }\n  grantAccess() {\n    this.table.grantRead(new iam.ServicePrincipal(PRINCIPAL));\n  }\n}", "language": "typescript"}
{"input": "There must be a license file that corresponds to the Apache-2.0 license.", "output": "export class LicenseFile extends ValidationRule {\n  public readonly name = 'license/license-file';\n\n  public validate(pkg: PackageJson): void {\n    fileShouldBe(this.name, pkg, 'LICENSE', LICENSE);\n  }\n}", "language": "typescript"}
{"input": "Cognito authorizer configuration", "output": "class CognitoAuthorizerConfiguration extends RuntimeAuthorizerConfiguration {\n  constructor(\n    private readonly userPool: IUserPool,\n    private readonly userPoolClients: IUserPoolClient[],\n    private readonly allowedAudience?: string[],\n  ) {\n    super();\n  }\n\n  public _render(): CfnRuntime.AuthorizerConfigurationProperty {\n    const discoveryUrl = `https://cognito-idp.${this.userPool.env.region}.amazonaws.com/${this.userPool.userPoolId}/.well-known/openid-configuration`;\n\n    // Use JWT format for Cognito (CloudFormation expects JWT format)\n    return {\n      customJwtAuthorizer: {\n        discoveryUrl: discoveryUrl,\n        allowedClients: this.userPoolClients.map(client => client.userPoolClientId),\n        allowedAudience: this.allowedAudience,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "A principal that represents a federated identity provider as Web Identity such as Cognito, Amazon, Facebook, Google, etc.", "output": "export class WebIdentityPrincipal extends FederatedPrincipal {\n  /**\n   *\n   * @param identityProvider identity provider (i.e. 'cognito-identity.amazonaws.com' for users authenticated through Cognito)\n   * @param conditions The conditions under which the policy is in effect.\n   *   See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   * @param sessionTags Whether to enable session tagging (see https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html)\n   */\n  constructor(identityProvider: string, conditions: Conditions = {}) {\n    super(identityProvider, conditions ?? {}, 'sts:AssumeRoleWithWebIdentity');\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ Federated: [this.federated] }, this.conditions);\n  }\n\n  public toString() {\n    return `WebIdentityPrincipal(${this.federated})`;\n  }\n}", "language": "typescript"}
{"input": "Factory class for creating different Gateway Credential Providers", "output": "class GatewayCredentialProvider {\n  /**\n   * Create an API key credential provider from Identity ARN\n   * Use this method when you have the Identity ARN as a string\n   * @param props - The configuration properties for the API key credential provider\n   * @returns ICredentialProviderConfig configured for API key authentication\n   */\n  public static fromApiKeyIdentityArn(props: ApiKeyCredentialProviderProps): ICredentialProviderConfig {\n    return new ApiKeyCredentialProviderConfiguration(props);\n  }\n\n  /**\n   * Create an OAuth credential provider from Identity ARN\n   * Use this method when you have the Identity ARN as a string\n   * @param props - The configuration properties for the OAuth credential provider\n   * @returns ICredentialProviderConfig configured for OAuth authentication\n   */\n  public static fromOauthIdentityArn(props: OAuthConfiguration): ICredentialProviderConfig {\n    return new OAuthCredentialProviderConfiguration(props);\n  }\n\n  /**\n   * Create an IAM role credential provider\n   * @returns IIamRoleCredentialProvider configured for IAM role authentication\n   */\n  public static fromIamRole(): ICredentialProviderConfig {\n    return new GatewayIamRoleCredentialProviderConfig();\n  }\n}", "language": "typescript"}
{"input": "An import source from an S3 object.", "output": "export class S3ImportSource extends ImportSource {\n  /**\n   * @param bucket the S3 bucket that contains the data\n   * @param key the key within the S3 bucket that contains the data\n   */\n  constructor(public readonly bucket: s3.IBucket, public readonly key: string) {\n    super();\n  }\n\n  /**\n   * @internal\n   */\n  public _bind(_scope: Construct): CfnKeyValueStore.ImportSourceProperty {\n    return {\n      sourceType: 'S3',\n      sourceArn: `${this.bucket.arnForObjects(this.key)}`,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class CompositeAlarmImportIntegrationTest for AWS resource management", "output": "class CompositeAlarmImportIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const alarm = CompositeAlarm.fromCompositeAlarmName(this, 'alarm', 'TestAlarm');\n\n    new CfnOutput(this, 'AlarmName', { value: alarm.alarmName });\n    new CfnOutput(this, 'AlarmArn', { value: alarm.alarmArn });\n  }\n}", "language": "typescript"}
{"input": "CDK class ClusterSnapshoter for AWS resource management", "output": "export class ClusterSnapshoter extends Construct {\n  public readonly snapshotArn: string;\n\n  constructor(scope: Construct, id: string, props: ClusterSnapshoterProps) {\n    super(scope, id);\n\n    const clusterArn = Stack.of(this).formatArn({\n      service: 'rds',\n      resource: 'cluster',\n      resourceName: props.cluster.clusterIdentifier,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    const snapshotArn = Stack.of(this).formatArn({\n      service: 'rds',\n      resource: 'cluster-snapshot',\n      resourceName: props.snapshotIdentifier,\n      arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n    });\n\n    const code = lambda.Code.fromAsset(path.join(__dirname, 'snapshot-handler'), { exclude: ['*.ts'] });\n    const onEventHandler = new lambda.Function(this, 'OnEventHandler', {\n      code,\n      runtime: lambda.Runtime.NODEJS_22_X,\n      handler: 'index.onEventHandler',\n      initialPolicy: [\n        new iam.PolicyStatement({\n          actions: ['rds:CreateDBClusterSnapshot', 'rds:AddTagsToResource', 'rds:DeleteDBClusterSnapshot'],\n          resources: [clusterArn, snapshotArn],\n        }),\n      ],\n    });\n\n    const isCompleteHandler = new lambda.Function(this, 'IsCompleteHandler', {\n      code,\n      runtime: lambda.Runtime.NODEJS_22_X,\n      handler: 'index.isCompleteHandler',\n      initialPolicy: [\n        new iam.PolicyStatement({\n          actions: ['rds:DescribeDBClusterSnapshots'],\n          resources: [clusterArn, snapshotArn],\n        }),\n      ],\n    });\n\n    const provider = new cr.Provider(this, 'SnapshotProvider', {\n      onEventHandler,\n      isCompleteHandler,\n    });\n\n    const customResource = new CustomResource(this, 'Snapshot', {\n      resourceType: 'Custom::Snapshoter',\n      serviceToken: provider.serviceToken,\n      properties: {\n        DBClusterIdentifier: props.cluster.clusterIdentifier,\n        DBClusterSnapshotIdentifier: props.snapshotIdentifier,\n      },\n    });\n    this.snapshotArn = customResource.getAttString('DBClusterSnapshotArn');\n  }\n}", "language": "typescript"}
{"input": "CDK class Chart for AWS resource management", "output": "class Chart extends cdk8s.Chart {\n      constructor(scope: constructs.Construct, ns: string, cluster: eks.ICluster) {\n        super(scope, ns);\n\n        new kplus.ConfigMap(this, 'config-map', {\n          data: {\n            clusterName: cluster.clusterName,\n          },\n        });\n      }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates WAF, CloudFormation, Config resources", "output": "class WafCloudFrontStack(Stack):\n\n  def make_rules(self, list_of_rules={}):\n    rules = list()\n    for r in list_of_rules:\n      rule = wafv2.CfnWebACL.RuleProperty(\n        name             = r[\"name\"],\n        priority         = r[\"priority\"],\n        override_action  = wafv2.CfnWebACL.OverrideActionProperty(none={}),\n        statement        = wafv2.CfnWebACL.StatementProperty(\n          managed_rule_group_statement = wafv2.CfnWebACL.ManagedRuleGroupStatementProperty(\n            name           = r[\"name\"],\n            vendor_name    = \"AWS\",\n            excluded_rules = []\n          ) ## managed_rule_group_statement\n        ), ## statement\n        visibility_config=wafv2.CfnWebACL.VisibilityConfigProperty(\n          cloud_watch_metrics_enabled = True,\n          metric_name                 = r[\"name\"],\n          sampled_requests_enabled    = True\n        ) ## visibility_config\n      ) ## wafv2.CfnWebACL.RuleProperty\n      rules.append(rule)\n\n    ##\n    ## Allowed country list\n    ##\n    ruleGeoMatch = wafv2.CfnWebACL.RuleProperty(\n      name     = 'GeoMatch',\n      priority =  0,\n      action   = wafv2.CfnWebACL.RuleActionProperty(\n        block={} ## To disable, change to *count*\n      ),\n      statement = wafv2.CfnWebACL.StatementProperty(\n        not_statement = wafv2.CfnWebACL.NotStatementProperty(\n          statement = wafv2.CfnWebACL.StatementProperty(\n            geo_match_statement = wafv2.CfnWebACL.GeoMatchStatementProperty(\n              ##\n              ## block connection if source not in the below country list\n              ##\n              country_codes = [\n                \"AR\", ## Argentina\n                \"BO\", ## Bolivia\n                \"BR\", ## Brazil\n                \"CL\", ## Chile\n                \"CO\", ## Colombia\n                \"EC\", ## Ecuador\n                \"FK\", ## Falkland Islands\n                \"GF\", ## French Guiana\n                \"GY\", ## Guiana\n                \"GY\", ## Guyana\n                \"PY\", ## Paraguay\n                \"PE\", ## Peru\n                \"SR\", ## Suriname\n                \"UY\", ## Uruguay\n                \"VE\", ## Venezuela\n              ] ## country_codes\n            ) ## geo_match_statement\n          ) ## statement\n        ) ## not_statement\n      ), ## statement\n      visibility_config = wafv2.CfnWebACL.VisibilityConfigProperty(\n        cloud_watch_metrics_enabled = True,\n        metric_name                 = 'GeoMatch',\n        sampled_requests_enabled    = True\n      ) ## visibility_config\n    ) ## GeoMatch\n    rules.append(ruleGeoMatch)\n\n    ##\n    ## The rate limit is the maximum number of requests from a\n    ## single IP address that are allowed in a five-minute period.\n    ## This value is continually evaluated,\n    ## and requests will be blocked once this limit is reached.\n    ## The IP address is automatically unblocked after it falls below the limit.\n    ##\n    ruleLimitRequests100 = wafv2.CfnWebACL.RuleProperty(\n          name     = 'LimitRequests100',\n          priority = 1,\n          action   = wafv2.CfnWebACL.RuleActionProperty(\n            block = {} ## To disable, change to *count*\n          ), ## action\n          statement= wafv2.CfnWebACL.StatementProperty(\n            rate_based_statement = wafv2.CfnWebACL.RateBasedStatementProperty(\n              limit              = 100,\n              aggregate_key_type = \"IP\"\n            ) ## rate_based_statement\n          ), ## statement\n          visibility_config= wafv2.CfnWebACL.VisibilityConfigProperty(\n            cloud_watch_metrics_enabled = True,\n            metric_name                 = 'LimitRequests100',\n            sampled_requests_enabled    = True\n          )\n        ) ## limit requests to 100\n    rules.append(ruleLimitRequests100);\n\n    return rules\n\n\n\n  def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n    ##\n    ## List available Managed Rule Groups using AWS CLI\n    ## aws wafv2 list-available-managed-rule-groups --scope CLOUDFRONT\n    ##\n    managed_rules = [{\n      \"name\"            : \"AWSManagedRulesCommonRuleSet\",\n      \"priority\"        : 10,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesAmazonIpReputationList\",\n      \"priority\"        : 20,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesKnownBadInputsRuleSet\",\n      \"priority\"        : 30,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesSQLiRuleSet\",\n      \"priority\"        : 40,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesLinuxRuleSet\",\n      \"priority\"        : 50,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesUnixRuleSet\",\n      \"priority\"        : 60,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    }]\n\n\n    #############################################################\n    ##\n    ## WAF - CloudFront\n    ##\n    #############################################################\n\n    wafacl = wafv2.CfnWebACL(self, id=\"WAF\",\n      default_action=wafv2.CfnWebACL.DefaultActionProperty(allow=wafv2.CfnWebACL.AllowActionProperty(), block=None),\n      ##\n      ## The scope of this Web ACL.\n      ## Valid options: CLOUDFRONT, REGIONAL.\n      ## For CLOUDFRONT, you must create your WAFv2 resources\n      ## in the US East (N. Virginia) Region, us-east-1\n      ## https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-wafv2-webacl.html#cfn-wafv2-webacl-scope\n      ##\n      scope=\"CLOUDFRONT\",\n      ##\n      ## Defines and enables Amazon CloudWatch metrics and web request sample collection.\n      ##\n      visibility_config=wafv2.CfnWebACL.VisibilityConfigProperty(\n        cloud_watch_metrics_enabled=True,\n        metric_name                =\"waf-cloudfront\",\n        sampled_requests_enabled   =True\n      ),\n      description = \"WAFv2 ACL for CloudFront\",\n      name        = \"waf-cloudfront\",\n      rules       = self.make_rules(managed_rules),\n    ) ## wafv2.CfnWebACL\n\n    Tags.of(wafacl).add(\"Name\",      \"waf-cloudfront\",     priority=300)\n    Tags.of(wafacl).add(\"Purpose\",   \"WAF for CloudFront\", priority=300)\n    Tags.of(wafacl).add(\"CreatedBy\", \"Cloudformation\",     priority=300)\n\n\n    CfnOutput(self, \"WafAclArn\", export_name=\"WafCloudFrontStack:WafAclCloudFrontArn\", value=wafacl.attr_arn)", "language": "python"}
{"input": "Windows-specific implementation of the .NET SDK injector. Handles CoreCLR profiler setup and paths for Windows environments.", "output": "export class DotNetWindowsInjector extends DotNetInjector {\n  protected static readonly DOTNET_WINDOWS_ENVS: EnvironmentExtension[] = [\n    {\n      name: constants.DotnetInstrumentation.CORECLR_ENABLE_PROFILING,\n      value: constants.DotnetInstrumentation.CORECLR_ENABLE_PROFILING_ENABLED,\n    },\n    {\n      name: constants.DotnetInstrumentation.CORECLR_PROFILER,\n      value: constants.DotnetInstrumentation.CORECLR_PROFILER_OTEL,\n    },\n  ];\n\n  get command(): string[] {\n    return ['CMD',\n      '/c',\n      'xcopy',\n      '/e',\n      'C:\\\\autoinstrumentation\\\\*',\n      'C:\\\\otel-auto-instrumentation-dotnet',\n      '&&',\n      'icacls',\n      'C:\\\\otel-auto-instrumentation-dotnet',\n      '/grant',\n      '*S-1-1-0:R',\n      '/T'];\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, envsFromTaskDef: { [key: string]: string }): void {\n    if (envsFromTaskDef[constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_HOME]) {\n      // If OTEL_DOTNET_AUTO_HOME env var is already set, we will assume that .NET Auto-instrumentation is already configured.\n      return;\n    }\n    for (const env of DotNetInjector.DOTNET_COMMON_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n    for (const env of DotNetWindowsInjector.DOTNET_WINDOWS_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n    envsToInject[constants.DotnetInstrumentation.CORECLR_PROFILER_PATH] = `${this.containerPath}\\\\win-x64\\\\OpenTelemetry.AutoInstrumentation.Native.dll`;\n    envsToInject[constants.DotnetInstrumentation.DOTNET_STARTUP_HOOKS] = `${this.containerPath}\\\\net\\\\OpenTelemetry.AutoInstrumentation.StartupHook.dll`;\n    envsToInject[constants.DotnetInstrumentation.DOTNET_ADDITIONAL_DEPS] = `${this.containerPath}\\\\AdditionalDeps`;\n    envsToInject[constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_HOME] = `${this.containerPath}`;\n    envsToInject[constants.DotnetInstrumentation.DOTNET_SHARED_STORE] = `${this.containerPath}\\\\store`;\n  }\n\n  get containerPath(): string {\n    return 'C:\\\\otel-auto-instrumentation-dotnet';\n  }\n\n  protected overrideAdditionalEnvironments(_envsToOverride: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    // No additional overrides needed for .NET on Windows\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPool for AWS resource management", "output": "export class UserPool extends UserPoolBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPool';\n\n  /**\n   * Import an existing user pool based on its id.\n   */\n  public static fromUserPoolId(scope: Construct, id: string, userPoolId: string): IUserPool {\n    let userPoolArn = Stack.of(scope).formatArn({\n      service: 'cognito-idp',\n      resource: 'userpool',\n      resourceName: userPoolId,\n    });\n\n    return UserPool.fromUserPoolArn(scope, id, userPoolArn);\n  }\n\n  /**\n   * Import an existing user pool based on its ARN.\n   */\n  public static fromUserPoolArn(scope: Construct, id: string, userPoolArn: string): IUserPool {\n    const arnParts = Stack.of(scope).splitArn(userPoolArn, ArnFormat.SLASH_RESOURCE_NAME);\n\n    if (!arnParts.resourceName) {\n      throw new ValidationError('invalid user pool ARN', scope);\n    }\n\n    const userPoolId = arnParts.resourceName;\n    // ex) cognito-idp.us-east-1.amazonaws.com/us-east-1_abcdefghi\n    const providerName = `cognito-idp.${arnParts.region}.${Stack.of(scope).urlSuffix}/${userPoolId}`;\n\n    class ImportedUserPool extends UserPoolBase {\n      public readonly userPoolArn = userPoolArn;\n      public readonly userPoolId = userPoolId;\n      public readonly userPoolProviderName = providerName;\n\n      constructor() {\n        super(scope, id, {\n          account: arnParts.account,\n          region: arnParts.region,\n        });\n      }\n    }\n\n    return new ImportedUserPool();\n  }\n\n  /**\n   * The physical ID of this user pool resource\n   */\n  public readonly userPoolId: string;\n\n  /**\n   * The ARN of the user pool\n   */\n  public readonly userPoolArn: string;\n\n  /**\n   * User pool provider name\n   * @attribute\n   */\n  public readonly userPoolProviderName: string;\n\n  /**\n   * User pool provider URL\n   * @attribute\n   */\n  public readonly userPoolProviderUrl: string;\n\n  private triggers: CfnUserPool.LambdaConfigProperty = {};\n  private emailConfiguration: UserPoolEmailConfig | undefined;\n\n  constructor(scope: Construct, id: string, props: UserPoolProps = {}) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const signIn = this.signInConfiguration(props);\n\n    if (props.customSenderKmsKey) {\n      const kmsKey = props.customSenderKmsKey;\n      (this.triggers as any).kmsKeyId = kmsKey.keyRef.keyArn;\n    }\n\n    if (props.lambdaTriggers) {\n      for (const t of Object.keys(props.lambdaTriggers)) {\n        let trigger: lambda.IFunction | undefined;\n        switch (t) {\n          case 'customSmsSender':\n          case 'customEmailSender':\n            if (!this.triggers.kmsKeyId) {\n              throw new ValidationError('you must specify a KMS key if you are using customSmsSender or customEmailSender.', this);\n            }\n            trigger = props.lambdaTriggers[t];\n            const version = 'V1_0';\n            if (trigger !== undefined) {\n              this.addLambdaPermission(trigger as lambda.IFunction, t);\n              (this.triggers as any)[t] = {\n                lambdaArn: trigger.functionArn,\n                lambdaVersion: version,\n              };\n            }\n            break;\n          default:\n            trigger = props.lambdaTriggers[t] as lambda.IFunction | undefined;\n            if (trigger !== undefined) {\n              this.addLambdaPermission(trigger as lambda.IFunction, t);\n              (this.triggers as any)[t] = (trigger as lambda.IFunction).functionArn;\n            }\n            break;\n        }\n      }\n    }\n\n    const verificationMessageTemplate = this.verificationMessageConfiguration(props);\n    let emailVerificationMessage;\n    let emailVerificationSubject;\n    if (verificationMessageTemplate.defaultEmailOption === VerificationEmailStyle.CODE) {\n      emailVerificationMessage = verificationMessageTemplate.emailMessage;\n      emailVerificationSubject = verificationMessageTemplate.emailSubject;\n    }\n    const smsVerificationMessage = verificationMessageTemplate.smsMessage;\n    const inviteMessageTemplate: CfnUserPool.InviteMessageTemplateProperty = {\n      emailMessage: props.userInvitation?.emailBody,\n      emailSubject: props.userInvitation?.emailSubject,\n      smsMessage: props.userInvitation?.smsMessage,\n    };\n    const selfSignUpEnabled = props.selfSignUpEnabled ?? false;\n    const adminCreateUserConfig: CfnUserPool.AdminCreateUserConfigProperty = {\n      allowAdminCreateUserOnly: !selfSignUpEnabled,\n      inviteMessageTemplate: props.userInvitation !== undefined ? inviteMessageTemplate : undefined,\n    };\n\n    const passwordPolicy = this.configurePasswordPolicy(props);\n    const signInPolicy = this.configureSignInPolicy(props);\n\n    if (props.passkeyRelyingPartyId !== undefined && !Token.isUnresolved(props.passkeyRelyingPartyId)) {\n      if (props.passkeyRelyingPartyId.length < 1 || props.passkeyRelyingPartyId.length > 63) {\n        throw new ValidationError(`passkeyRelyingPartyId length must be (inclusively) between 1 and 63, got ${props.passkeyRelyingPartyId.length}`, this);\n      }\n    }\n\n    if (props.email && props.emailSettings) {\n      throw new ValidationError('you must either provide \"email\" or \"emailSettings\", but not both', this);\n    }\n    const emailConfiguration = props.email ? props.email._bind(this) : undefinedIfNoKeys({\n      from: encodePuny(props.emailSettings?.from),\n      replyToEmailAddress: encodePuny(props.emailSettings?.replyTo),\n    });\n    this.emailConfiguration = emailConfiguration;\n\n    // Note: We do not validate feature plan requirements for threat protection at CDK synthesis time.\n    // CloudFormation will validate these requirements at deployment time, which allows existing user pools\n    // that are grandfathered on LITE plan with threat protection to continue working.\n\n    const advancedSecurityAdditionalFlows = undefinedIfNoKeys({\n      customAuthMode: props.customThreatProtectionMode,\n    });\n\n    if (\n      props.advancedSecurityMode &&\n      (props.standardThreatProtectionMode || advancedSecurityAdditionalFlows)\n    ) {\n      throw new ValidationError('you cannot set Threat Protection and Advanced Security Mode at the same time. Advanced Security Mode is deprecated and should be replaced with Threat Protection instead.', this);\n    }\n\n    let chosenSecurityMode = props.advancedSecurityMode ?? props.standardThreatProtectionMode;\n    if (advancedSecurityAdditionalFlows) {\n      chosenSecurityMode = props.advancedSecurityMode ?? props.standardThreatProtectionMode ?? StandardThreatProtectionMode.NO_ENFORCEMENT;\n    }\n\n    const userPool = new CfnUserPool(this, 'Resource', {\n      userPoolName: props.userPoolName,\n      usernameAttributes: signIn.usernameAttrs,\n      aliasAttributes: signIn.aliasAttrs,\n      autoVerifiedAttributes: signIn.autoVerifyAttrs,\n      lambdaConfig: Lazy.any({ produce: () => undefinedIfNoKeys(this.triggers) }),\n      smsAuthenticationMessage: this.mfaMessage(props),\n      smsConfiguration: this.smsConfiguration(props),\n      adminCreateUserConfig,\n      emailVerificationMessage,\n      emailVerificationSubject,\n      smsVerificationMessage,\n      verificationMessageTemplate,\n      userPoolAddOns: undefinedIfNoKeys({\n        advancedSecurityAdditionalFlows: advancedSecurityAdditionalFlows,\n        advancedSecurityMode: chosenSecurityMode,\n      }),\n      schema: this.schemaConfiguration(props),\n      mfaConfiguration: props.mfa,\n      enabledMfas: this.mfaConfiguration(props),\n      policies: undefinedIfNoKeys({ passwordPolicy, signInPolicy }),\n      webAuthnRelyingPartyId: props.passkeyRelyingPartyId,\n      webAuthnUserVerification: props.passkeyUserVerification,\n      emailConfiguration,\n      usernameConfiguration: undefinedIfNoKeys({\n        caseSensitive: props.signInCaseSensitive,\n      }),\n      accountRecoverySetting: this.accountRecovery(props),\n      deviceConfiguration: props.deviceTracking,\n      userAttributeUpdateSettings: this.configureUserAttributeChanges(props),\n      userPoolTier: props.featurePlan,\n      deletionProtection: defaultDeletionProtection(props.deletionProtection),\n    });\n    userPool.applyRemovalPolicy(props.removalPolicy);\n\n    this.userPoolId = userPool.ref;\n    this.userPoolArn = userPool.attrArn;\n\n    this.userPoolProviderName = userPool.attrProviderName;\n    this.userPoolProviderUrl = userPool.attrProviderUrl;\n  }\n\n  /**\n   * Add a lambda trigger to a user pool operation\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools-working-with-aws-lambda-triggers.html\n   */\n  @MethodMetadata()\n  public addTrigger(operation: UserPoolOperation, fn: lambda.IFunction, lambdaVersion?: LambdaVersion): void {\n    if (operation.operationName in this.triggers) {\n      throw new ValidationError(`A trigger for the operation ${operation.operationName} already exists.`, this);\n    }\n    if (\n      operation !== UserPoolOperation.PRE_TOKEN_GENERATION_CONFIG &&\n      lambdaVersion !== undefined &&\n      [LambdaVersion.V2_0, LambdaVersion.V3_0].includes(lambdaVersion)\n    ) {\n      throw new ValidationError('Only the `PRE_TOKEN_GENERATION_CONFIG` operation supports V2_0 and V3_0 lambda version.', this);\n    }\n\n    this.addLambdaPermission(fn, operation.operationName);\n    switch (operation.operationName) {\n      case 'customEmailSender':\n      case 'customSmsSender':\n        if (!this.triggers.kmsKeyId) {\n          throw new ValidationError('you must specify a KMS key if you are using customSmsSender or customEmailSender.', this);\n        }\n        (this.triggers as any)[operation.operationName] = {\n          lambdaArn: fn.functionArn,\n          lambdaVersion: LambdaVersion.V1_0,\n        };\n        break;\n      case 'preTokenGenerationConfig':\n        (this.triggers as any)[operation.operationName] = {\n          lambdaArn: fn.functionArn,\n          lambdaVersion: lambdaVersion ?? LambdaVersion.V1_0,\n        };\n        break;\n      default:\n        (this.triggers as any)[operation.operationName] = fn.functionArn;\n    }\n  }\n\n  private addLambdaPermission(fn: lambda.IFunction, name: string): void {\n    const capitalize = name.charAt(0).toUpperCase() + name.slice(1);\n    fn.addPermission(`${capitalize}Cognito`, {\n      principal: new ServicePrincipal('cognito-idp.amazonaws.com'),\n      sourceArn: Lazy.string({ produce: () => this.userPoolArn }),\n      scope: this,\n    });\n  }\n\n  private mfaMessage(props: UserPoolProps): string | undefined {\n    const CODE_TEMPLATE = '{####}';\n    const MAX_LENGTH = 140;\n    const message = props.mfaMessage;\n\n    if (message && !Token.isUnresolved(message)) {\n      if (!message.includes(CODE_TEMPLATE)) {\n        throw new ValidationError(`MFA message must contain the template string '${CODE_TEMPLATE}'`, this);\n      }\n\n      if (message.length > MAX_LENGTH) {\n        throw new ValidationError(`MFA message must be between ${CODE_TEMPLATE.length} and ${MAX_LENGTH} characters`, this);\n      }\n    }\n\n    return message;\n  }\n\n  private verificationMessageConfiguration(props: UserPoolProps): CfnUserPool.VerificationMessageTemplateProperty {\n    const CODE_TEMPLATE = '{####}';\n    const VERIFY_EMAIL_TEMPLATE = '{##Verify Email##}';\n    /**\n     * Email message placeholder regex\n     * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cognito-userpool-verificationmessagetemplate.html#cfn-cognito-userpool-verificationmessagetemplate-emailmessagebylink\n     */\n    const VERIFY_EMAIL_REGEX = /\\{##[\\p{L}\\p{M}\\p{S}\\p{N}\\p{P}\\s*]*##\\}/u;\n\n    const emailStyle = props.userVerification?.emailStyle ?? VerificationEmailStyle.CODE;\n    const emailSubject = props.userVerification?.emailSubject ?? 'Verify your new account';\n    const smsMessage = props.userVerification?.smsMessage ?? `The verification code to your new account is ${CODE_TEMPLATE}`;\n\n    if (emailStyle === VerificationEmailStyle.CODE) {\n      const emailMessage = props.userVerification?.emailBody ?? `The verification code to your new account is ${CODE_TEMPLATE}`;\n      if (!Token.isUnresolved(emailMessage) && emailMessage.indexOf(CODE_TEMPLATE) < 0) {\n        throw new ValidationError(`Verification email body must contain the template string '${CODE_TEMPLATE}'`, this);\n      }\n      if (!Token.isUnresolved(smsMessage) && smsMessage.indexOf(CODE_TEMPLATE) < 0) {\n        throw new ValidationError(`SMS message must contain the template string '${CODE_TEMPLATE}'`, this);\n      }\n      return {\n        defaultEmailOption: VerificationEmailStyle.CODE,\n        emailMessage,\n        emailSubject,\n        smsMessage,\n      };\n    } else {\n      const emailMessage = props.userVerification?.emailBody ??\n        `Verify your account by clicking on ${VERIFY_EMAIL_TEMPLATE}`;\n      if (!Token.isUnresolved(emailMessage) && !VERIFY_EMAIL_REGEX.test(emailMessage)) {\n        throw new ValidationError(`Verification email body must contain the template string '${VERIFY_EMAIL_TEMPLATE}'`, this);\n      }\n      return {\n        defaultEmailOption: VerificationEmailStyle.LINK,\n        emailMessageByLink: emailMessage,\n        emailSubjectByLink: emailSubject,\n        smsMessage,\n      };\n    }\n  }\n\n  private signInConfiguration(props: UserPoolProps) {\n    let aliasAttrs: string[] | undefined;\n    let usernameAttrs: string[] | undefined;\n    let autoVerifyAttrs: string[] | undefined;\n\n    const signIn: SignInAliases = props.signInAliases ?? { username: true };\n\n    if (signIn.preferredUsername && !signIn.username) {\n      throw new ValidationError('username signIn must be enabled if preferredUsername is enabled', this);\n    }\n\n    if (signIn.username) {\n      aliasAttrs = [];\n      if (signIn.email) { aliasAttrs.push(StandardAttributeNames.email); }\n      if (signIn.phone) { aliasAttrs.push(StandardAttributeNames.phoneNumber); }\n      if (signIn.preferredUsername) { aliasAttrs.push(StandardAttributeNames.preferredUsername); }\n      if (aliasAttrs.length === 0) { aliasAttrs = undefined; }\n    } else {\n      usernameAttrs = [];\n      if (signIn.email) { usernameAttrs.push(StandardAttributeNames.email); }\n      if (signIn.phone) { usernameAttrs.push(StandardAttributeNames.phoneNumber); }\n    }\n\n    if (props.autoVerify) {\n      autoVerifyAttrs = [];\n      if (props.autoVerify.email) { autoVerifyAttrs.push(StandardAttributeNames.email); }\n      if (props.autoVerify.phone) { autoVerifyAttrs.push(StandardAttributeNames.phoneNumber); }\n    } else if (signIn.email || signIn.phone) {\n      autoVerifyAttrs = [];\n      if (signIn.email) { autoVerifyAttrs.push(StandardAttributeNames.email); }\n      if (signIn.phone) { autoVerifyAttrs.push(StandardAttributeNames.phoneNumber); }\n    }\n\n    return { usernameAttrs, aliasAttrs, autoVerifyAttrs };\n  }\n\n  private smsConfiguration(props: UserPoolProps): CfnUserPool.SmsConfigurationProperty | undefined {\n    if (props.enableSmsRole === false && props.smsRole) {\n      throw new ValidationError('enableSmsRole cannot be disabled when smsRole is specified', this);\n    }\n\n    if (props.smsRole) {\n      return {\n        snsCallerArn: props.smsRole.roleRef.roleArn,\n        externalId: props.smsRoleExternalId,\n        snsRegion: props.snsRegion,\n      };\n    }\n\n    if (props.enableSmsRole === false) {\n      return undefined;\n    }\n\n    const mfaConfiguration = this.mfaConfiguration(props);\n    const phoneVerification = props.signInAliases?.phone === true || props.autoVerify?.phone === true;\n    const roleRequired = mfaConfiguration?.includes('SMS_MFA') || phoneVerification;\n    if (!roleRequired && props.enableSmsRole === undefined) {\n      return undefined;\n    }\n\n    const smsRoleExternalId = Names.uniqueId(this).slice(0, 1223); // sts:ExternalId max length of 1224\n    const smsRole = props.smsRole ?? new Role(this, 'smsRole', {\n      assumedBy: new ServicePrincipal('cognito-idp.amazonaws.com', {\n        conditions: {\n          StringEquals: { 'sts:ExternalId': smsRoleExternalId },\n        },\n      }),\n      inlinePolicies: {\n        /*\n          * The UserPool is very particular that it must contain an 'sns:Publish' action as an inline policy.\n          * Ideally, a conditional that restricts this action to 'sms' protocol needs to be attached, but the UserPool deployment fails validation.\n          * Seems like a case of being excessively strict.\n          */\n        'sns-publish': new PolicyDocument({\n          statements: [\n            new PolicyStatement({\n              actions: ['sns:Publish'],\n              resources: ['*'],\n            }),\n          ],\n        }),\n      },\n    });\n    return {\n      externalId: smsRoleExternalId,\n      snsCallerArn: smsRole.roleRef.roleArn,\n      snsRegion: props.snsRegion,\n    };\n  }\n\n  private mfaConfiguration(props: UserPoolProps): string[] | undefined {\n    if (props.mfa === undefined || props.mfa === Mfa.OFF) {\n      // since default is OFF, treat undefined and OFF the same way\n      return undefined;\n    } else if (props.mfaSecondFactor === undefined &&\n      (props.mfa === Mfa.OPTIONAL || props.mfa === Mfa.REQUIRED)) {\n      return ['SMS_MFA'];\n    } else {\n      const enabledMfas = [];\n      if (props.mfaSecondFactor!.sms) {\n        enabledMfas.push('SMS_MFA');\n      }\n      if (props.mfaSecondFactor!.otp) {\n        enabledMfas.push('SOFTWARE_TOKEN_MFA');\n      } if (props.mfaSecondFactor!.email) {\n        this.validateEmailMfa(props);\n        enabledMfas.push('EMAIL_OTP');\n      }\n      return enabledMfas;\n    }\n  }\n\n  private configurePasswordPolicy(props: UserPoolProps): CfnUserPool.PasswordPolicyProperty | undefined {\n    const tempPasswordValidity = props.passwordPolicy?.tempPasswordValidity;\n    if (tempPasswordValidity !== undefined && tempPasswordValidity.toDays() > Duration.days(365).toDays()) {\n      throw new ValidationError(`tempPasswordValidity cannot be greater than 365 days (received: ${tempPasswordValidity.toDays()})`, this);\n    }\n    const minLength = props.passwordPolicy ? props.passwordPolicy.minLength ?? 8 : undefined;\n    if (minLength !== undefined && (minLength < 6 || minLength > 99)) {\n      throw new ValidationError(`minLength for password must be between 6 and 99 (received: ${minLength})`, this);\n    }\n    const passwordHistorySize = props.passwordPolicy?.passwordHistorySize;\n    if (passwordHistorySize !== undefined) {\n      if (props.featurePlan === FeaturePlan.LITE) {\n        throw new ValidationError('`passwordHistorySize` can not be set when `featurePlan` is `FeaturePlan.LITE`.', this);\n      }\n      if (passwordHistorySize < 0 || passwordHistorySize > 24) {\n        throw new ValidationError(`\\`passwordHistorySize\\` must be between 0 and 24 (received: ${passwordHistorySize}).`, this);\n      }\n    }\n    return undefinedIfNoKeys({\n      temporaryPasswordValidityDays: tempPasswordValidity?.toDays({ integral: true }),\n      minimumLength: minLength,\n      requireLowercase: props.passwordPolicy?.requireLowercase,\n      requireUppercase: props.passwordPolicy?.requireUppercase,\n      requireNumbers: props.passwordPolicy?.requireDigits,\n      requireSymbols: props.passwordPolicy?.requireSymbols,\n      passwordHistorySize: props.passwordPolicy?.passwordHistorySize,\n    });\n  }\n\n  private configureSignInPolicy(props: UserPoolProps): CfnUserPool.SignInPolicyProperty | undefined {\n    let allowedFirstAuthFactors: string[] | undefined = undefined;\n    if (props.signInPolicy?.allowedFirstAuthFactors) {\n      // As of writing, from testing, CFN deployment will fail if `PASSWORD` is not enabled.\n      if (!props.signInPolicy.allowedFirstAuthFactors.password) {\n        throw new ValidationError('The password authentication cannot be disabled.', this);\n      }\n\n      allowedFirstAuthFactors = [];\n      if (props.signInPolicy.allowedFirstAuthFactors.password) {\n        allowedFirstAuthFactors.push('PASSWORD');\n      }\n      if (props.signInPolicy.allowedFirstAuthFactors.emailOtp) {\n        allowedFirstAuthFactors.push('EMAIL_OTP');\n      }\n      if (props.signInPolicy.allowedFirstAuthFactors.smsOtp) {\n        allowedFirstAuthFactors.push('SMS_OTP');\n      }\n      if (props.signInPolicy.allowedFirstAuthFactors.passkey) {\n        allowedFirstAuthFactors.push('WEB_AUTHN');\n      }\n    }\n\n    /*\n     * Choice-based authentication is enabled when built allowedFirstAuthFactors contains any factor but PASSWORD.\n     * This check should be placed here to supply the way to disable choice-based authentication explicitly\n     * by specifying `allowedFirstAuthFactors: { password: true }`.\n     */\n    const isChoiceBasedAuthenticationEnabled = allowedFirstAuthFactors?.some((auth) => auth !== 'PASSWORD');\n    if (isChoiceBasedAuthenticationEnabled && props.featurePlan === FeaturePlan.LITE) {\n      throw new ValidationError('To enable choice-based authentication, set `featurePlan` to `FeaturePlan.ESSENTIALS` or `FeaturePlan.PLUS`.', this);\n    }\n\n    return undefinedIfNoKeys({ allowedFirstAuthFactors });\n  }\n\n  private schemaConfiguration(props: UserPoolProps): CfnUserPool.SchemaAttributeProperty[] | undefined {\n    const schema: CfnUserPool.SchemaAttributeProperty[] = [];\n\n    if (props.standardAttributes) {\n      const stdAttributes = (Object.entries(props.standardAttributes) as Array<[keyof StandardAttributes, StandardAttribute]>)\n        .filter(([, attr]) => !!attr)\n        .map(([attrName, attr]) => ({\n          name: StandardAttributeNames[attrName],\n          mutable: attr.mutable ?? true,\n          required: attr.required ?? false,\n        }));\n\n      schema.push(...stdAttributes);\n    }\n\n    if (props.customAttributes) {\n      const customAttrs = Object.keys(props.customAttributes).map((attrName) => {\n        const attrConfig = props.customAttributes![attrName].bind();\n        const numberConstraints: CfnUserPool.NumberAttributeConstraintsProperty = {\n          minValue: attrConfig.numberConstraints?.min?.toString(),\n          maxValue: attrConfig.numberConstraints?.max?.toString(),\n        };\n        const stringConstraints: CfnUserPool.StringAttributeConstraintsProperty = {\n          minLength: attrConfig.stringConstraints?.minLen?.toString(),\n          maxLength: attrConfig.stringConstraints?.maxLen?.toString(),\n        };\n\n        return {\n          name: attrName,\n          attributeDataType: attrConfig.dataType,\n          numberAttributeConstraints: attrConfig.numberConstraints\n            ? numberConstraints\n            : undefined,\n          stringAttributeConstraints: attrConfig.stringConstraints\n            ? stringConstraints\n            : undefined,\n          mutable: attrConfig.mutable,\n        };\n      });\n      schema.push(...customAttrs);\n    }\n\n    if (schema.length === 0) {\n      return undefined;\n    }\n    return schema;\n  }\n\n  private accountRecovery(props: UserPoolProps): undefined | CfnUserPool.AccountRecoverySettingProperty {\n    const accountRecovery = props.accountRecovery ?? AccountRecovery.PHONE_WITHOUT_MFA_AND_EMAIL;\n    switch (accountRecovery) {\n      case AccountRecovery.EMAIL_AND_PHONE_WITHOUT_MFA:\n        return {\n          recoveryMechanisms: [\n            { name: 'verified_email', priority: 1 },\n            { name: 'verified_phone_number', priority: 2 },\n          ],\n        };\n      case AccountRecovery.PHONE_WITHOUT_MFA_AND_EMAIL:\n        return {\n          recoveryMechanisms: [\n            { name: 'verified_phone_number', priority: 1 },\n            { name: 'verified_email', priority: 2 },\n          ],\n        };\n      case AccountRecovery.EMAIL_ONLY:\n        return {\n          recoveryMechanisms: [{ name: 'verified_email', priority: 1 }],\n        };\n      case AccountRecovery.PHONE_ONLY_WITHOUT_MFA:\n        return {\n          recoveryMechanisms: [{ name: 'verified_phone_number', priority: 1 }],\n        };\n      case AccountRecovery.NONE:\n        return {\n          recoveryMechanisms: [{ name: 'admin_only', priority: 1 }],\n        };\n      case AccountRecovery.PHONE_AND_EMAIL:\n        return undefined;\n      default:\n        throw new ValidationError(`Unsupported AccountRecovery type - ${accountRecovery}`, this);\n    }\n  }\n\n  private configureUserAttributeChanges(props: UserPoolProps): CfnUserPool.UserAttributeUpdateSettingsProperty | undefined {\n    if (!props.keepOriginal) {\n      return undefined;\n    }\n\n    const attributesRequireVerificationBeforeUpdate: string[] = [];\n\n    if (props.keepOriginal.email) {\n      attributesRequireVerificationBeforeUpdate.push(StandardAttributeNames.email);\n    }\n\n    if (props.keepOriginal.phone) {\n      attributesRequireVerificationBeforeUpdate.push(StandardAttributeNames.phoneNumber);\n    }\n\n    return {\n      attributesRequireVerificationBeforeUpdate,\n    };\n  }\n\n  private validateEmailMfa(props: UserPoolProps) {\n    if (props.email === undefined || this.emailConfiguration?.emailSendingAccount !== 'DEVELOPER') {\n      throw new ValidationError('To enable email-based MFA, set `email` property to the Amazon SES email-sending configuration.', this);\n    }\n\n    if (props.featurePlan === FeaturePlan.LITE) {\n      throw new ValidationError('To enable email-based MFA, set `featurePlan` to `FeaturePlan.ESSENTIALS` or `FeaturePlan.PLUS`.', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation resources", "output": "class NetworkStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Subnet configurations for a public and private tier\n        subnet1 = SubnetConfiguration(\n                name=\"Public\",\n                subnet_type=SubnetType.PUBLIC,\n                cidr_mask=24)\n        subnet2 = SubnetConfiguration(\n                name=\"Private\",\n                subnet_type=SubnetType.PRIVATE_WITH_NAT,\n                cidr_mask=24)\n\n        vpc = Vpc(self,\n                  \"TheVPC\",\n                  cidr=\"10.0.0.0/16\",\n                  enable_dns_hostnames=True,\n                  enable_dns_support=True,\n                  max_azs=2,\n                  nat_gateway_provider=NatProvider.gateway(),\n                  nat_gateways=1,\n                  subnet_configuration=[subnet1, subnet2]\n                  )\n\n        # This will export the VPC's ID in CloudFormation under the key\n        # 'vpcid'\n        CfnOutput(self, \"vpcid\", value=vpc.vpc_id)\n\n        # Prepares output attributes to be passed into other stacks\n        # In this case, it is our VPC and subnets.\n        self.output_props = props.copy()\n        self.output_props['vpc'] = vpc\n        self.output_props['subnets'] = vpc.public_subnets\n\n    @property\n    def outputs(self):\n        return self.output_props", "language": "python"}
{"input": "CDK Stack that creates Step Functions, CloudFormation resources", "output": "class DistributedMapStack extends cdk.Stack {\n  readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const distributedMap = new sfn.DistributedMap(this, 'DistributedMap', {\n      mapExecutionType: sfn.StateMachineType.EXPRESS,\n    });\n    distributedMap.itemProcessor(new sfn.Pass(this, 'Pass'), {\n      mode: sfn.ProcessorMode.DISTRIBUTED,\n      executionType: sfn.ProcessorType.STANDARD,\n    });\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definition: distributedMap,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, API Gateway, AppSync resources", "output": "class EventApiHttpStack extends cdk.Stack {\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const api = new appsync.EventApi(this, 'EventApiHttp', {\n      apiName: 'HttpEventApi',\n    });\n\n    const randomApi = new apigw.RestApi(this, 'RandomApi');\n    const randomRoute = randomApi.root.addResource('random');\n    randomRoute.addMethod('GET', new apigw.MockIntegration({\n      integrationResponses: [{\n        statusCode: '200',\n        responseTemplates: {\n          'application/json': 'my-random-value',\n        },\n      }],\n      passthroughBehavior: apigw.PassthroughBehavior.NEVER,\n      requestTemplates: {\n        'application/json': '{ \"statusCode\": 200 }',\n      },\n    }), {\n      methodResponses: [{ statusCode: '200' }],\n    });\n\n    const dataSource = api.addHttpDataSource('httpsource', `https://${randomApi.restApiId}.execute-api.${this.region}.amazonaws.com`);\n\n    api.addChannelNamespace('chat', {\n      code: appsync.Code.fromAsset(path.join(__dirname, 'integ-assets', 'eventapi-handlers', 'http.js')),\n      publishHandlerConfig: {\n        dataSource: dataSource,\n      },\n    });\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: `wss://${api.realtimeDns}/event/realtime`,\n        EVENT_API_HTTP_URL: `https://${api.httpDns}/event`,\n        API_KEY: api.apiKeys.Default.attrApiKey,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets', 'eventapi-grant-assertion', 'index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.seconds(15),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'EventApiHttpTestFunction', lambdaConfig);\n  }\n}", "language": "typescript"}
{"input": "Abstract base class for network configuration.", "output": "class NetworkConfiguration {\n  /**\n   * The network mode to use.\n   * Configure the security level for agent\n   * execution to control access, isolate resources, and protect sensitive data.\n   */\n  readonly networkMode: string;\n  /**\n   * The connections object to the network.\n   */\n  readonly connections: ec2.Connections | undefined;\n  /**\n   * The scope to create the resource in.\n   */\n  readonly scope?: Construct | undefined;\n  /**\n   * The VPC subnets to use.\n   */\n  readonly vpcSubnets?: ec2.SubnetSelection;\n  /**\n   * Creates a new network configuration.\n   * @param mode - the network mode to use for the tool.\n   */\n  protected constructor (mode: string, scope?: Construct, vpcConfig?: VpcConfigProps) {\n    this.scope = scope;\n    this.networkMode = mode;\n\n    // Validate vpc config and configure connections\n    const networkConfig = this._validateAndConfigureVpcConfig(vpcConfig);\n    this.connections = networkConfig?.connections;\n    this.vpcSubnets = networkConfig?.vpcSubnets;\n  }\n\n  /**\n   * Validates the vpc config.\n   */\n  private _validateAndConfigureVpcConfig = (vpcConfig?: VpcConfigProps): NetworkConfig | undefined => {\n    if ((vpcConfig?.securityGroups || vpcConfig?.allowAllOutbound !== undefined) && !vpcConfig?.vpc) {\n      throw new Error('Cannot configure \\'securityGroups\\' or \\'allowAllOutbound\\' without configuring a VPC');\n    }\n\n    if (!vpcConfig?.vpc) {\n      return undefined;\n    }\n\n    if ((vpcConfig?.securityGroups && vpcConfig?.securityGroups.length > 0) && vpcConfig?.allowAllOutbound !== undefined) {\n      throw new Error('Configure \\'allowAllOutbound\\' directly on the supplied SecurityGroups');\n    }\n\n    if (!this.scope) {\n      throw new Error('Scope is required to create the security group');\n    }\n\n    let securityGroups: ec2.ISecurityGroup[];\n    if (vpcConfig.securityGroups && vpcConfig.securityGroups.length > 0) {\n      securityGroups = vpcConfig.securityGroups;\n    } else {\n      const securityGroup = new ec2.SecurityGroup(this.scope!, 'SecurityGroup', {\n        vpc: vpcConfig.vpc,\n        allowAllOutbound: vpcConfig.allowAllOutbound ?? true,\n      });\n      securityGroups = [securityGroup];\n    }\n\n    const vpcSubnets = vpcConfig.vpcSubnets ? vpcConfig.vpc.selectSubnets(vpcConfig.vpcSubnets) : vpcConfig.vpc.selectSubnets();\n\n    return {\n      connections: new ec2.Connections({ securityGroups: securityGroups }),\n      vpcSubnets: vpcSubnets,\n    };\n  };\n}", "language": "typescript"}
{"input": "CDK class MySecondResource for AWS resource management", "output": "class MySecondResource extends AbstractCfnResource {\n      public readonly myprop: string;\n\n      constructor(scope: Construct, id: string, myprop: string) {\n        super(scope, id);\n        this.myprop = myprop;\n      }\n\n      protected get cfnProperties(): { [key: string]: any } {\n        return {\n          myprop: this.myprop,\n        };\n      }\n    }", "language": "typescript"}
{"input": "CDK class ImportedCluster for AWS resource management", "output": "class ImportedCluster extends ClusterBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-eks.ImportedCluster';\n  public readonly clusterName: string;\n  public readonly clusterArn: string;\n  public readonly connections = new ec2.Connections();\n  public readonly kubectlRole?: iam.IRole;\n  public readonly kubectlLambdaRole?: iam.IRole;\n  public readonly kubectlEnvironment?: { [key: string]: string } | undefined;\n  public readonly kubectlSecurityGroup?: ec2.ISecurityGroup | undefined;\n  public readonly kubectlPrivateSubnets?: ec2.ISubnet[] | undefined;\n  public readonly kubectlLayer?: lambda.ILayerVersion;\n  public readonly ipFamily?: IpFamily;\n  public readonly awscliLayer?: lambda.ILayerVersion;\n  public readonly kubectlProvider?: IKubectlProvider;\n  public readonly onEventLayer?: lambda.ILayerVersion;\n  public readonly kubectlMemory?: Size;\n  public readonly clusterHandlerSecurityGroup?: ec2.ISecurityGroup | undefined;\n  public readonly prune: boolean;\n\n  // so that `clusterSecurityGroup` on `ICluster` can be configured without optionality, avoiding users from having\n  // to null check on an instance of `Cluster`, which will always have this configured.\n  private readonly _clusterSecurityGroup?: ec2.ISecurityGroup;\n\n  constructor(scope: Construct, id: string, private readonly props: ClusterAttributes) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.clusterName = props.clusterName;\n    this.clusterArn = this.stack.formatArn(clusterArnComponents(props.clusterName));\n    this.kubectlRole = props.kubectlRoleArn ? iam.Role.fromRoleArn(this, 'KubectlRole', props.kubectlRoleArn) : undefined;\n    this.kubectlLambdaRole = props.kubectlLambdaRole;\n    this.kubectlSecurityGroup = props.kubectlSecurityGroupId ? ec2.SecurityGroup.fromSecurityGroupId(this, 'KubectlSecurityGroup', props.kubectlSecurityGroupId) : undefined;\n    this.kubectlEnvironment = props.kubectlEnvironment;\n    this.kubectlPrivateSubnets = props.kubectlPrivateSubnetIds ? props.kubectlPrivateSubnetIds.map((subnetid, index) => ec2.Subnet.fromSubnetId(this, `KubectlSubnet${index}`, subnetid)) : undefined;\n    this.kubectlLayer = props.kubectlLayer;\n    this.ipFamily = props.ipFamily;\n    this.awscliLayer = props.awscliLayer;\n    this.kubectlMemory = props.kubectlMemory;\n    this.clusterHandlerSecurityGroup = props.clusterHandlerSecurityGroupId ? ec2.SecurityGroup.fromSecurityGroupId(this, 'ClusterHandlerSecurityGroup', props.clusterHandlerSecurityGroupId) : undefined;\n    this.kubectlProvider = props.kubectlProvider;\n    this.onEventLayer = props.onEventLayer;\n    this.prune = props.prune ?? true;\n\n    let i = 1;\n    for (const sgid of props.securityGroupIds ?? []) {\n      this.connections.addSecurityGroup(ec2.SecurityGroup.fromSecurityGroupId(this, `SecurityGroup${i}`, sgid));\n      i++;\n    }\n\n    if (props.clusterSecurityGroupId) {\n      this._clusterSecurityGroup = ec2.SecurityGroup.fromSecurityGroupId(this, 'ClusterSecurityGroup', this.clusterSecurityGroupId);\n      this.connections.addSecurityGroup(this._clusterSecurityGroup);\n    }\n  }\n\n  public get vpc() {\n    if (!this.props.vpc) {\n      throw new ValidationError('\"vpc\" is not defined for this imported cluster', this);\n    }\n    return this.props.vpc;\n  }\n\n  public get clusterSecurityGroup(): ec2.ISecurityGroup {\n    if (!this._clusterSecurityGroup) {\n      throw new ValidationError('\"clusterSecurityGroup\" is not defined for this imported cluster', this);\n    }\n    return this._clusterSecurityGroup;\n  }\n\n  public get clusterSecurityGroupId(): string {\n    if (!this.props.clusterSecurityGroupId) {\n      throw new ValidationError('\"clusterSecurityGroupId\" is not defined for this imported cluster', this);\n    }\n    return this.props.clusterSecurityGroupId;\n  }\n\n  public get clusterEndpoint(): string {\n    if (!this.props.clusterEndpoint) {\n      throw new ValidationError('\"clusterEndpoint\" is not defined for this imported cluster', this);\n    }\n    return this.props.clusterEndpoint;\n  }\n\n  public get clusterCertificateAuthorityData(): string {\n    if (!this.props.clusterCertificateAuthorityData) {\n      throw new ValidationError('\"clusterCertificateAuthorityData\" is not defined for this imported cluster', this);\n    }\n    return this.props.clusterCertificateAuthorityData;\n  }\n\n  public get clusterEncryptionConfigKeyArn(): string {\n    if (!this.props.clusterEncryptionConfigKeyArn) {\n      throw new ValidationError('\"clusterEncryptionConfigKeyArn\" is not defined for this imported cluster', this);\n    }\n    return this.props.clusterEncryptionConfigKeyArn;\n  }\n\n  public get openIdConnectProvider(): iam.IOpenIdConnectProvider {\n    if (!this.props.openIdConnectProvider) {\n      throw new ValidationError('\"openIdConnectProvider\" is not defined for this imported cluster', this);\n    }\n    return this.props.openIdConnectProvider;\n  }\n\n  public get awsAuth(): AwsAuth {\n    throw new ValidationError('\"awsAuth\" is not supported on imported clusters', this);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates VPC, SSM Parameter Store, SQS, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  public readonly queueUrl: string;\n  public readonly groupName: string;\n  public readonly hookName: string;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const queue = new Queue(this, 'HookQueue');\n    this.queueUrl = queue.queueUrl;\n    const group = new scaling.AutoScalingGroup(this, 'Group', {\n      vpc: new Vpc(this, 'Vpc', { restrictDefaultSecurityGroup: false }),\n      maxCapacity: 1,\n      minCapacity: 0,\n      instanceType: InstanceType.of(InstanceClass.T3, InstanceSize.SMALL),\n      machineImage: {\n        getImage: () => {\n          return {\n            osType: OperatingSystemType.LINUX,\n            userData: UserData.forLinux(),\n            imageId: StringParameter.fromStringParameterName(\n              this,\n              'al2023AMI',\n              '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-6.1-x86_64',\n            ).stringValue,\n          };\n        },\n      },\n    });\n    this.groupName = group.autoScalingGroupName;\n    const hook = group.addLifecycleHook('scaleout', {\n      lifecycleTransition: scaling.LifecycleTransition.INSTANCE_LAUNCHING,\n      notificationTarget: new QueueHook(queue),\n    });\n    this.hookName = hook.lifecycleHookName;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Step Functions, CloudFormation, CloudMap (Service Discovery) resources", "output": "class DistributedMapRedriveStack extends cdk.Stack {\n  readonly bucket: s3.Bucket;\n  readonly stateMachine: sfn.StateMachine;\n\n  constructor(scope: cdk.App, id: string, props?: DistributedMapRedriveStackProps) {\n    super(scope, id, props);\n\n    this.bucket = new s3.Bucket(this, 'Bucket', {\n      autoDeleteObjects: true,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const distributedMap = new sfn.DistributedMap(this, 'DistributedMap', {\n      label: props?.mapRunLabel,\n      itemReader: new sfn.S3CsvItemReader({\n        bucket: this.bucket,\n        key: CSV_KEY,\n        csvHeaders: sfn.CsvHeaders.useFirstRow(),\n      }),\n    });\n\n    // Existence of the success marker object determines if the distributed map succeeds or fails\n    const getSuccessMarker = new aws_stepfunction_tasks.CallAwsService(this, 'GetData', {\n      action: 'getObject',\n      iamResources: [this.bucket.arnForObjects('*')],\n      parameters: {\n        Bucket: this.bucket.bucketName,\n        Key: SUCCESS_MARKER_KEY,\n      },\n      service: 's3',\n    });\n\n    distributedMap.itemProcessor(getSuccessMarker);\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definitionBody: sfn.ChainDefinitionBody.fromChainable(distributedMap),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ScalaSparkFlexEtlJob for AWS resource management", "output": "export class ScalaSparkFlexEtlJob extends SparkJob {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.ScalaSparkFlexEtlJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n\n  /**\n   * ScalaSparkFlexEtlJob constructor\n   */\n  constructor(scope: Construct, id: string, props: ScalaSparkFlexEtlJobProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...this.executableArguments(props),\n      ...this.nonExecutableCommonArguments(props),\n    };\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.ETL,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n      },\n      glueVersion: props.glueVersion ? props.glueVersion : GlueVersion.V3_0,\n      workerType: props.workerType ? props.workerType : WorkerType.G_1X,\n      numberOfWorkers: props.numberOfWorkers ? props.numberOfWorkers : 10,\n      maxRetries: props.maxRetries,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      notificationProperty: props.notifyDelayAfter ? { notifyDelayAfter: props.notifyDelayAfter.toMinutes() } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      executionClass: ExecutionClass.FLEX,\n      jobRunQueuingEnabled: false,\n      defaultArguments,\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n\n  /**\n   * Set the executable arguments with best practices enabled by default\n   *\n   * @returns An array of arguments for Glue to use on execution\n   */\n  private executableArguments(props: ScalaSparkFlexEtlJobProps) {\n    const args: { [key: string]: string } = {};\n    args['--job-language'] = JobLanguage.SCALA;\n    args['--class'] = props.className;\n    this.setupExtraCodeArguments(args, props);\n    return args;\n  }\n}", "language": "typescript"}
{"input": "Authorization type for an API Destination Connection", "output": "class Authorization {\n  /**\n   * Use API key authorization\n   *\n   * API key authorization has two components: an API key name and an API key value.\n   * What these are depends on the target of your connection.\n   */\n  public static apiKey(apiKeyName: string, apiKeyValue: SecretValue): Authorization {\n    return new class extends Authorization {\n      public _bind() {\n        return {\n          authorizationType: AuthorizationType.API_KEY,\n          authParameters: {\n            apiKeyAuthParameters: {\n              apiKeyName: apiKeyName,\n              apiKeyValue: apiKeyValue.unsafeUnwrap(), // Safe usage\n            },\n          } as CfnConnection.AuthParametersProperty,\n        };\n      }\n    }();\n  }\n\n  /**\n   * Use username and password authorization\n   */\n  public static basic(username: string, password: SecretValue): Authorization {\n    return new class extends Authorization {\n      public _bind() {\n        return {\n          authorizationType: AuthorizationType.BASIC,\n          authParameters: {\n            basicAuthParameters: {\n              username: username,\n              password: password.unsafeUnwrap(), // Safe usage\n            },\n          } as CfnConnection.AuthParametersProperty,\n        };\n      }\n    }();\n  }\n\n  /**\n   * Use OAuth authorization\n   */\n  public static oauth(props: OAuthAuthorizationProps): Authorization {\n    if (![HttpMethod.POST, HttpMethod.GET, HttpMethod.PUT].includes(props.httpMethod)) {\n      throw new UnscopedValidationError('httpMethod must be one of GET, POST, PUT');\n    }\n\n    return new class extends Authorization {\n      public _bind() {\n        return {\n          authorizationType: AuthorizationType.OAUTH_CLIENT_CREDENTIALS,\n          authParameters: {\n            oAuthParameters: {\n              authorizationEndpoint: props.authorizationEndpoint,\n              clientParameters: {\n                clientId: props.clientId,\n                clientSecret: props.clientSecret.unsafeUnwrap(), // Safe usage\n              },\n              httpMethod: props.httpMethod,\n              oAuthHttpParameters: {\n                bodyParameters: renderHttpParameters(props.bodyParameters),\n                headerParameters: renderHttpParameters(props.headerParameters),\n                queryStringParameters: renderHttpParameters(props.queryStringParameters),\n              },\n            },\n          } as CfnConnection.AuthParametersProperty,\n        };\n      }\n    }();\n  }\n\n  /**\n   * Bind the authorization to the construct and return the authorization properties\n   *\n   * @internal\n   */\n  public abstract _bind(): AuthorizationBindResult;\n}", "language": "typescript"}
{"input": "method to add the Security Group attached to the NAT instance", "output": "def create_nat_SG(self, vpc):\n        sg = ec2.SecurityGroup(\n            self,\n            id=\"NatInstanceSG\",\n            vpc=vpc,\n            allow_all_outbound=False,\n            description=\"Nat Instance Security Group\"\n        )\n        sg.add_ingress_rule(\n            peer=ec2.Peer.ipv4(VPC_CIDR),\n            connection=ec2.Port.tcp(80),\n            description=\"HTTP ingress\",\n        )\n        sg.add_ingress_rule(\n            peer=ec2.Peer.ipv4(VPC_CIDR),\n            connection=ec2.Port.tcp(443),\n            description=\"HTTPS ingress\",\n        )\n        sg.add_egress_rule(\n            peer=ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            connection=ec2.Port.tcp(80),\n            description=\"HTTP egress\",\n        )\n        sg.add_egress_rule(\n            peer=ec2.Peer.ipv4(\"0.0.0.0/0\"),\n            connection=ec2.Port.tcp(443),\n            description=\"HTTPS egress\",\n        )\n        return sg", "language": "python"}
{"input": "CDK class Function for AWS resource management", "output": "export class Function extends FunctionBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-lambda.Function';\n\n  /**\n   * Returns a `lambda.Version` which represents the current version of this\n   * Lambda function. A new version will be created every time the function's\n   * configuration changes.\n   *\n   * You can specify options for this version using the `currentVersionOptions`\n   * prop when initializing the `lambda.Function`.\n   */\n  public get currentVersion(): Version {\n    if (this._currentVersion) {\n      return this._currentVersion;\n    }\n\n    if (this._warnIfCurrentVersionCalled) {\n      this.warnInvokeFunctionPermissions(this);\n    }\n\n    this._currentVersion = new Version(this, 'CurrentVersion', {\n      lambda: this,\n      ...this.currentVersionOptions,\n    });\n\n    // override the version's logical ID with a lazy string which includes the\n    // hash of the function itself, so a new version resource is created when\n    // the function configuration changes.\n    const cfn = this._currentVersion.node.defaultChild as CfnResource;\n    const originalLogicalId = this.stack.resolve(cfn.logicalId) as string;\n\n    cfn.overrideLogicalId(Lazy.uncachedString({\n      produce: () => {\n        const hash = calculateFunctionHash(this, this.hashMixins.join(''));\n        const logicalId = trimFromStart(originalLogicalId, 255 - 32);\n        return `${logicalId}${hash}`;\n      },\n    }));\n\n    return this._currentVersion;\n  }", "language": "typescript"}
{"input": "CDK class VpcV2 for AWS resource management", "output": "export class VpcV2 extends VpcV2Base {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.VpcV2';\n\n  /**\n   * Create a VPC from existing attributes\n   */\n  public static fromVpcV2Attributes(scope: Construct, id: string, attrs: VpcV2Attributes): IVpcV2 {\n    /**\n     * Internal class to allow users to import VPC\n     * @internal\n     */\n    class ImportedVpcV2 extends VpcV2Base {\n      public readonly vpcId: string;\n      public readonly vpcArn: string;\n      public readonly publicSubnets: ISubnetV2[] = [];\n      public readonly privateSubnets: ISubnetV2[] = [];\n      public readonly isolatedSubnets: ISubnetV2[] = [];\n      public readonly internetConnectivityEstablished: IDependable = new DependencyGroup();\n      public readonly ipv4CidrBlock: string;\n      public readonly region: string;\n      public readonly ownerAccountId: string;\n      public readonly vpcName?: string;\n      private readonly _partition?: string;\n\n      /*\n      * Reference to all secondary blocks attached\n      */\n      public readonly secondaryCidrBlock?: IVPCCidrBlock[];\n\n      /**\n       * Refers to actual VPC Resource attribute in non-imported VPC\n       * Required to implement here due to extension from Base class\n       */\n      public readonly vpcCidrBlock: string;\n\n      // Required to do CIDR range test on imported VPCs to create new subnets\n      public readonly ipv4IpamProvisionedCidrs: string[] = [];\n\n      constructor(construct: Construct, constructId: string, props: VpcV2Attributes) {\n        super(construct, constructId);\n        this.vpcId = props.vpcId,\n        this.region = props.region ?? this.stack.region,\n        this.ownerAccountId = props.ownerAccountId ?? this.stack.account,\n        this._partition = region_info.RegionInfo.get(this.region).partition,\n        this.vpcArn = Arn.format({\n          service: 'ec2',\n          resource: 'vpc',\n          resourceName: this.vpcId,\n          region: this.region,\n          account: this.ownerAccountId,\n          partition: this._partition,\n        }, this.stack);\n\n        // Populate region and account fields that can be used to set up peering connection\n        // sample vpc Arn - arn:aws:ec2:us-west-2:123456789012:vpc/vpc-0123456789abcdef0\n        this.region = this.vpcArn.split(':')[3];\n        this.ownerAccountId = this.vpcArn.split(':')[4];\n        // Refers to actual VPC Resource attribute in non-imported VPC\n        this.vpcCidrBlock = props.vpcCidrBlock;\n        // Required for subnet range related checks\n        this.ipv4CidrBlock = props.vpcCidrBlock;\n        this._vpnGatewayId = props.vpnGatewayId;\n\n        if (props.subnets) {\n          for (const subnet of props.subnets) {\n            if (subnet.subnetType === SubnetType.PRIVATE_WITH_EGRESS || subnet.subnetType === SubnetType.PRIVATE_WITH_NAT ||\n              subnet.subnetType as string === 'Deprecated_Private') {\n              this.privateSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedPrivateSubnet', subnet));\n            } else if (subnet.subnetType === SubnetType.PUBLIC) {\n              this.publicSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedPublicSubnet', subnet));\n            } else if (subnet.subnetType as string === 'Deprecated_Isolated' || subnet.subnetType === SubnetType.PRIVATE_ISOLATED) {\n              this.isolatedSubnets.push(SubnetV2.fromSubnetV2Attributes(scope, subnet.subnetName?? 'ImportedIsolatedSubnet', subnet));\n            }\n          }\n        }\n        this.secondaryCidrBlock = props.secondaryCidrBlocks?.map(cidrBlock => VPCCidrBlock.fromVPCCidrBlockattributes(scope, cidrBlock.cidrBlockName ?? 'ImportedSecondaryCidrBlock', { ...cidrBlock }));\n        if (props.secondaryCidrBlocks) {\n          for (const cidrBlock of props.secondaryCidrBlocks) {\n            if (cidrBlock.ipv4IpamProvisionedCidrs) {\n              this.ipv4IpamProvisionedCidrs.push(...cidrBlock.ipv4IpamProvisionedCidrs);\n            }\n          }\n        }\n      }\n    }\n    return new ImportedVpcV2(scope, id, attrs);\n  }\n\n  /**\n   * Identifier for this VPC\n   */\n  public readonly vpcId: string;\n\n  /**\n   * @attribute\n   */\n  public readonly vpcArn: string;\n\n  /**\n   * @attribute\n   */\n  public readonly vpcCidrBlock: string;\n  /**\n   * The IPv6 CIDR blocks for the VPC.\n   *\n   * See https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-vpc.html#aws-resource-ec2-vpc-return-values\n   */\n  public readonly ipv6CidrBlocks: string[];\n\n  /**\n   * The provider of ipv4 addresses\n   */\n  public readonly ipAddresses: IIpAddresses;\n\n  /**\n   * The AWS CloudFormation resource representing the VPC.\n   */\n  public readonly resource: CfnVPC;\n\n  /**\n   * Indicates if instances launched in this VPC will have public DNS hostnames.\n   */\n  public readonly dnsHostnamesEnabled: boolean;\n\n  /**\n   * Indicates if DNS support is enabled for this VPC.\n   */\n  public readonly dnsSupportEnabled: boolean;\n\n  /**\n   * Isolated Subnets that are part of this VPC.\n   */\n  public readonly isolatedSubnets: ISubnet[];\n\n  /**\n   * Public Subnets that are part of this VPC.\n   */\n  public readonly publicSubnets: ISubnet[];\n\n  /**\n   * Public Subnets that are part of this VPC.\n   */\n  public readonly privateSubnets: ISubnet[];\n\n  /**\n   * To define dependency on internet connectivity\n   */\n  public readonly internetConnectivityEstablished: IDependable;\n\n  /**\n   * reference to all secondary blocks attached\n   */\n  public readonly secondaryCidrBlock?: IVPCCidrBlock[] = new Array<IVPCCidrBlock>;\n\n  /**\n   * IPv4 CIDR provisioned using IPAM pool\n   * Required to check for overlapping CIDRs after provisioning\n   * is complete under IPAM\n   */\n  public readonly ipv4IpamProvisionedCidrs?: string[];\n\n  /**\n   * Region for this VPC\n   */\n  public readonly region: string;\n\n  /**\n   * Identifier of the owner for this VPC\n   */\n  public readonly ownerAccountId: string;\n\n  /**\n   * For validation to define IPv6 subnets, set to true in case of\n   * Amazon Provided IPv6 cidr range\n   * if true, IPv6 addresses can be attached to the subnets.\n   *\n   * @default false\n   */\n  public readonly useIpv6: boolean = false;\n\n  /**\n   * VpcName to be used for tagging its components\n   * @attribute\n   */\n  public readonly vpcName?: string;\n\n  public readonly ipv4CidrBlock: string = '';\n\n  constructor(scope: Construct, id: string, props: VpcV2Props = {}) {\n    super(scope, id, {\n      physicalName: props.vpcName ?? Lazy.string({\n        produce: () => Names.uniqueResourceName(this, { maxLength: 128, allowedSpecialCharacters: '_' }),\n      }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    this.vpcName = props.vpcName;\n    this.ipAddresses = props.primaryAddressBlock ?? IpAddresses.ipv4('10.0.0.0/16');\n    const vpcOptions = this.ipAddresses.allocateVpcCidr();\n\n    this.dnsHostnamesEnabled = props.enableDnsHostnames == null ? true : props.enableDnsHostnames;\n    this.dnsSupportEnabled = props.enableDnsSupport == null ? true : props.enableDnsSupport;\n    const instanceTenancy = props.defaultInstanceTenancy || 'default';\n    this.resource = new CfnVPC(this, 'Resource', {\n      cidrBlock: vpcOptions.ipv4CidrBlock, // for Ipv4 addresses CIDR block\n      enableDnsHostnames: this.dnsHostnamesEnabled,\n      enableDnsSupport: this.dnsSupportEnabled,\n      ipv4IpamPoolId: vpcOptions.ipv4IpamPool?.ipamPoolId, // for Ipv4 ipam option\n      ipv4NetmaskLength: vpcOptions.ipv4NetmaskLength, // for Ipv4 ipam option\n      instanceTenancy: instanceTenancy,\n    });\n\n    this.node.defaultChild = this.resource;\n    this.vpcCidrBlock = this.resource.attrCidrBlock;\n    if (vpcOptions.ipv4CidrBlock) {\n      this.ipv4CidrBlock = vpcOptions.ipv4CidrBlock;\n    }\n    this.ipv6CidrBlocks = this.resource.attrIpv6CidrBlocks;\n    this.vpcId = FeatureFlags.of(this).isEnabled(cx_api.USE_RESOURCEID_FOR_VPCV2_MIGRATION) ?\n      this.resource.ref : this.resource.attrVpcId;\n    this.vpcArn = Arn.format({\n      service: 'ec2',\n      resource: 'vpc',\n      resourceName: this.vpcId,\n    }, this.stack);\n    this.region = this.stack.region;\n    this.ownerAccountId = this.stack.account;\n    // Add tag to the VPC with the name provided in properties\n    Tags.of(this).add(NAME_TAG, props.vpcName || this.node.path);\n    if (props.secondaryAddressBlocks) {\n      const secondaryAddressBlocks: IIpAddresses[] = props.secondaryAddressBlocks;\n\n      for (const secondaryAddressBlock of secondaryAddressBlocks) {\n        const secondaryVpcOptions: VpcCidrOptions = secondaryAddressBlock.allocateVpcCidr();\n        if (!secondaryVpcOptions.cidrBlockName) {\n          throw new Error('Cidr Block Name is required to create secondary IP address');\n        }\n\n        if (secondaryVpcOptions.amazonProvided || secondaryVpcOptions.ipv6IpamPool || secondaryVpcOptions.ipv6PoolId) {\n          this.useIpv6 = true;\n        }\n        // validate CIDR ranges per RFC 1918\n        if (secondaryVpcOptions.ipv4CidrBlock!) {\n          const ret = validateIpv4address(secondaryVpcOptions.ipv4CidrBlock, this.resource.cidrBlock);\n          if (ret === false) {\n            throw new Error('CIDR block should be in the same RFC 1918 range in the VPC');\n          }\n        }\n        if (secondaryVpcOptions.ipv4IpamProvisionedCidrs!) {\n          this.ipv4IpamProvisionedCidrs?.push(...secondaryVpcOptions.ipv4IpamProvisionedCidrs);\n        }\n        const vpcCidrBlock = new VPCCidrBlock(this, secondaryVpcOptions.cidrBlockName, {\n          vpcId: this.vpcId,\n          cidrBlock: secondaryVpcOptions.ipv4CidrBlock,\n          ipv4IpamPoolId: secondaryVpcOptions.ipv4IpamPool?.ipamPoolId,\n          ipv4NetmaskLength: secondaryVpcOptions.ipv4NetmaskLength,\n          ipv6NetmaskLength: secondaryVpcOptions.ipv6NetmaskLength,\n          ipv6IpamPoolId: secondaryVpcOptions.ipv6IpamPool?.ipamPoolId,\n          amazonProvidedIpv6CidrBlock: secondaryVpcOptions.amazonProvided,\n          // BYOIP IPv6 Address\n          ipv6CidrBlock: secondaryVpcOptions?.ipv6CidrBlock,\n          // BYOIP Pool for IPv6 address\n          ipv6Pool: secondaryVpcOptions?.ipv6PoolId,\n        });\n        if (secondaryVpcOptions.dependencies) {\n          for (const dep of secondaryVpcOptions.dependencies) {\n            vpcCidrBlock.node.addDependency(dep);\n          }\n        }\n        // Create secondary blocks for Ipv4 and Ipv6\n        this.secondaryCidrBlock?.push(vpcCidrBlock);\n      }\n    }\n\n    /**\n     * Empty array for isolated subnets\n     */\n    this.isolatedSubnets = new Array<ISubnet>;\n\n    /**\n     * Empty array for public subnets\n     */\n    this.publicSubnets = new Array<ISubnet>;\n\n    /**\n     * Empty array for private subnets\n     */\n    this.privateSubnets = new Array<ISubnet>;\n\n    /**\n     * Dependable that can be depended upon to force internet connectivity established on the VPC\n     * Add igw to this if its a public subnet\n     */\n    this.internetConnectivityEstablished = this._internetConnectivityEstablished;\n  }\n}", "language": "typescript"}
{"input": "CDK class TestRenderer for AWS resource management", "output": "export class TestRenderer extends TypeScriptRenderer {\n  public renderMethod(method: Method) {\n    this.withScope(method.scope.scope, () => {\n      super.renderMethod(method, 'class');\n    });\n    // @ts-ignore\n    return this.emitter.toString();\n  }\n}", "language": "typescript"}
{"input": "A Volume that uses an AWS Elastic File System (EFS); this volume can grow and shrink as needed", "output": "export class EfsVolume extends EcsVolume {\n  /**\n   * Returns true if x is an EfsVolume, false otherwise\n   */\n  public static isEfsVolume(x: any) : x is EfsVolume {\n    return x !== null && typeof(x) === 'object' && EFS_VOLUME_SYMBOL in x;\n  }\n\n  private readonly _fileSystem: IFileSystemRef;\n\n  /**\n   * The EFS File System that supports this volume\n   */\n  public get fileSystem(): IFileSystem {\n    return toIFileSystem(this._fileSystem);\n  }\n\n  /**\n   * @internal\n   */\n  public get _fileSystemRef(): IFileSystemRef {\n    return this._fileSystem;\n  }\n\n  /**\n   * The directory within the Amazon EFS file system to mount as the root directory inside the host.\n   * If this parameter is omitted, the root of the Amazon EFS volume is used instead.\n   * Specifying `/` has the same effect as omitting this parameter.\n   * The maximum length is 4,096 characters.\n   *\n   * @default - root of the EFS File System\n   */\n  public readonly rootDirectory?: string;\n\n  /**\n   * Enables encryption for Amazon EFS data in transit between the Amazon ECS host and the Amazon EFS server\n   *\n   * @see https://docs.aws.amazon.com/efs/latest/ug/encryption-in-transit.html\n   *\n   * @default false\n   */\n  public readonly enableTransitEncryption?: boolean;\n\n  /**\n   * The port to use when sending encrypted data between the Amazon ECS host and the Amazon EFS server.\n   * The value must be between 0 and 65,535.\n   *\n   * @see https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html\n   *\n   * @default - chosen by the EFS Mount Helper\n   */\n  public readonly transitEncryptionPort?: number;\n\n  /**\n   * The Amazon EFS access point ID to use.\n   * If an access point is specified, `rootDirectory` must either be omitted or set to `/`\n   * which enforces the path set on the EFS access point.\n   * If an access point is used, `enableTransitEncryption` must be `true`.\n   *\n   * @see https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html\n   *\n   * @default - no accessPointId\n   */\n  public readonly accessPointId?: string;\n\n  /**\n   * Whether or not to use the AWS Batch job IAM role defined in a job definition when mounting the Amazon EFS file system.\n   * If specified, `enableTransitEncryption` must be `true`.\n   *\n   * @see https://docs.aws.amazon.com/batch/latest/userguide/efs-volumes.html#efs-volume-accesspoints\n   *\n   * @default false\n   */\n  public readonly useJobRole?: boolean;\n\n  constructor(options: EfsVolumeOptions) {\n    super(options);\n\n    this._fileSystem = options.fileSystem;\n    this.rootDirectory = options.rootDirectory;\n    this.enableTransitEncryption = options.enableTransitEncryption;\n    this.transitEncryptionPort = options.transitEncryptionPort;\n    this.accessPointId = options.accessPointId;\n    this.useJobRole = options.useJobRole;\n  }\n}", "language": "typescript"}
{"input": "CDK class FirewallDomains for AWS resource management", "output": "class FirewallDomains {\n  /**\n   * Firewall domains created from a list of domains\n   *\n   * @param list the list of domains\n   */\n  public static fromList(list: string[]): FirewallDomains {\n    for (const domain of list) {\n      if (!/^([\\w-.]{1,255}|\\*[\\w-.]{1,254})$/.test(domain)) {\n        throw new UnscopedValidationError(`Invalid domain: ${domain}. Domain can optionally start with *. Max length of 255. Valid characters: A-Z, a-z, 0-9, _, -, .`);\n      }\n    }\n\n    return {\n      bind(_scope: Construct): DomainsConfig {\n        return { domains: list };\n      },\n    };\n  }\n\n  /**\n   * Firewall domains created from the URL of a file stored in Amazon S3.\n   * The file must be a text file and must contain a single domain per line.\n   * The content type of the S3 object must be `plain/text`.\n   *\n   * @param url S3 bucket url (s3://bucket/prefix/objet).\n   */\n  public static fromS3Url(url: string): FirewallDomains {\n    if (!Token.isUnresolved(url) && !url.startsWith('s3://')) {\n      throw new UnscopedValidationError(`The S3 URL must start with s3://, got ${url}`);\n    }\n\n    return {\n      bind(_scope: Construct): DomainsConfig {\n        return { domainFileUrl: url };\n      },\n    };\n  }\n\n  /**\n   * Firewall domains created from a file stored in Amazon S3.\n   * The file must be a text file and must contain a single domain per line.\n   * The content type of the S3 object must be `plain/text`.\n   *\n   * @param bucket S3 bucket\n   * @param key S3 key\n   */\n  public static fromS3(bucket: IBucket, key: string): FirewallDomains {\n    return this.fromS3Url(bucket.s3UrlForObject(key));\n  }\n\n  /**\n   * Firewall domains created from a local disk path to a text file.\n   * The file must be a text file (`.txt` extension) and must contain a single\n   * domain per line. It will be uploaded to S3.\n   *\n   * @param assetPath path to the text file\n   */\n  public static fromAsset(assetPath: string): FirewallDomains {\n    // cdk-assets will correctly set the content type for the S3 object\n    // if the file has the correct extension\n    if (path.extname(assetPath) !== '.txt') {\n      throw new UnscopedValidationError(`FirewallDomains.fromAsset() expects a file with the .txt extension, got ${assetPath}`);\n    }\n\n    return {\n      bind(scope: Construct): DomainsConfig {\n        const asset = new Asset(scope, 'Domains', { path: assetPath });\n\n        if (!asset.isFile) {\n          throw new UnscopedValidationError('FirewallDomains.fromAsset() expects a file');\n        }\n\n        return { domainFileUrl: asset.s3ObjectUrl };\n      },\n    };\n  }\n\n  /** Binds the domains to a domain list */\n  public abstract bind(scope: Construct): DomainsConfig;\n}", "language": "typescript"}
{"input": "Enables session tags on role assumptions from a principal For more information on session tags, see: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html", "output": "export class SessionTagsPrincipal extends PrincipalAdapter {\n  constructor(principal: IPrincipal) {\n    super(principal);\n  }\n\n  public addToAssumeRolePolicy(doc: PolicyDocument) {\n    // Lazy import to avoid circular import dependencies during startup\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const adapter: typeof import('./private/policydoc-adapter') = require('./private/policydoc-adapter');\n\n    defaultAddPrincipalToAssumeRole(this.wrapped, new adapter.MutatingPolicyDocumentAdapter(doc, (statement) => {\n      statement.addActions('sts:TagSession');\n      return statement;\n    }));\n  }\n\n  public dedupeString(): string | undefined {\n    return this.appendDedupe('');\n  }\n}", "language": "typescript"}
{"input": "Stack1 creates the VPC", "output": "class Stack1 extends cdk.Stack {\n  public readonly vpc: ec2.Vpc;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n    this.vpc = new ec2.Vpc(this, 'VPC');\n  }\n}", "language": "typescript"}
{"input": "To set analytics config to UserPoolClient with Application ARN", "output": "class TestStack extends Stack {\n  public readonly userPool: UserPool;\n  public readonly client: UserPoolClient;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const pinpointApp = new CfnApp(this, 'PinpointApp', {\n      name: 'SamplePinpointApp',\n    });\n    pinpointApp.applyRemovalPolicy(RemovalPolicy.DESTROY);\n\n    this.userPool = new UserPool(this, 'Pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    this.client = this.userPool.addClient('Client', {\n      generateSecret: true,\n      analytics: {\n        application: pinpointApp,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class SingletonFunction for AWS resource management", "output": "class SingletonFunction extends HandlerFrameworkClass {\n      public constructor() {\n        super(scope, {\n          name: props.name,\n          extends: LAMBDA_MODULE.SingletonFunction,\n          export: true,\n        });\n\n        if (scope.isAlphaModule) {\n          scope.registerImport(LAMBDA_MODULE, { fromLocation: ALPHA_MODULE_LAMBDA_IMPORT_PATH });\n        } else {\n          scope.registerImport(LAMBDA_MODULE);\n        }\n\n        const isEvalNodejsProvider = this.fqn.includes('eval-nodejs-provider');\n\n        scope.registerImport(LAMBDA_MODULE);\n\n        const uuid: PropertySpec = {\n          name: 'uuid',\n          type: Type.STRING,\n          immutable: true,\n          docs: {\n            summary: 'A unique identifier to identify this Lambda.\\n\\nThe identifier should be unique across all custom resource providers.\\nWe recommend generating a UUID per provider.',\n          },\n        };\n        const lambdaPurpose: PropertySpec = {\n          name: 'lambdaPurpose',\n          type: Type.STRING,\n          immutable: true,\n          optional: true,\n          docs: {\n            summary: 'A descriptive name for the purpose of this Lambda.\\n\\nIf the Lambda does not have a physical name, this string will be\\nreflected in its generated name. The combination of lambdaPurpose\\nand uuid must be unique.',\n            docTags: {\n              default: 'SingletonLambda',\n            },\n          },\n        };\n        const properties = [uuid, lambdaPurpose];\n        // eval nodejs provider is a one off scenario where the provider makes its runtime property configurable - to maintain this\n        // functionality we need to expose it as well\n        if (isEvalNodejsProvider) {\n          const runtime: PropertySpec = {\n            name: 'runtime',\n            type: LAMBDA_MODULE.Runtime,\n            immutable: true,\n            optional: true,\n            docs: {\n              summary: 'The runtime that this Lambda will use.',\n              docTags: {\n                default: '- the latest Lambda node runtime available in your region.',\n              },\n            },\n          };\n          properties.push(runtime);\n        }\n        const _interface = this.getOrCreateInterface(scope, {\n          name: `${this.name}Props`,\n          export: true,\n          extends: [LAMBDA_MODULE.FunctionOptions],\n          properties,\n          docs: {\n            summary: `Initialization properties for ${this.name}`,\n          },\n        });\n\n        const superProps = new ObjectLiteral([\n          new Splat(expr.ident('props')),\n          ['code', $T(LAMBDA_MODULE.Code).fromAsset(\n            PATH_MODULE.join.call(expr.directCode(`__dirname, '${props.codeDirectory}'`)),\n          )],\n          ['handler', expr.lit(props.handler)],\n          ['runtime', this.buildRuntimeProperty(scope, { runtime: props.runtime, isEvalNodejsProvider })],\n        ]);\n        const metadataStatements: Statement[] = [\n          stmt.directCode(`this.addMetadata('${CUSTOM_RESOURCE_SINGLETON}', true)`),\n          stmt.directCode(`this.addMetadata('${CUSTOM_RESOURCE_RUNTIME_FAMILY}', this.runtime.family)`),\n          stmt.directCode(`if (props?.logGroup) { this.logGroup.node.addMetadata('${CUSTOM_RESOURCE_SINGLETON_LOG_GROUP}', true) }`),\n          // We need to access the private `_logRetention` custom resource, the only public property - `logGroup` - provides an ARN reference to the resource, instead of the resource itself.\n          stmt.directCode(`if (props?.logRetention) { ((this as any).lambdaFunction as lambda.Function)._logRetention?.node.addMetadata('${CUSTOM_RESOURCE_SINGLETON_LOG_RETENTION}', true) }`),\n        ];\n        this.buildConstructor({\n          constructorPropsType: _interface.type,\n          superProps,\n          constructorVisibility: MemberVisibility.Public,\n          statements: metadataStatements,\n        });\n      }\n    }", "language": "typescript"}
{"input": "Enforces that the aws-cdk's package.json on the V2 branch does not have the \"main\" and \"types\" keys filled.", "output": "export class CdkCliV2MissesMainAndTypes extends ValidationRule {\n  public readonly name = 'aws-cdk/cli/v2/package.json/main';\n\n  public validate(pkg: PackageJson): void {\n    // this rule only applies to the CLI\n    if (pkg.json.name !== 'aws-cdk') { return; }\n    // this only applies to V2\n    if (cdkMajorVersion() === 1) { return; }\n\n    if (pkg.json.main || pkg.json.types) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'The package.json file for the aws-cdk CLI package in V2 cannot have \"main\" and \"types\" keys',\n        fix: () => {\n          delete pkg.json.main;\n          delete pkg.json.types;\n        },\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Route 53 operations", "output": "def __init__(self, scope: Construct, construct_id: str, zone: route53.HostedZone, primaryLoadBalancer: elbv2.ILoadBalancerV2, secondaryLoadBalancer: elbv2.ILoadBalancerV2, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # primary record\n        primary = route53.ARecord(self, \"PrimaryRecordSet\",\n            zone = zone,\n            record_name=\"alias\",\n            target = route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(primaryLoadBalancer)),\n        )\n        primaryRecordSet = primary.node.default_child\n        primaryRecordSet.failover = \"PRIMARY\"\n        primaryRecordSet.add_property_override('AliasTarget.EvaluateTargetHealth', True)\n        primaryRecordSet.set_identifier = \"Primary\"\n\n        # secondary record\n        secondary = route53.ARecord(self, \"SecondaryRecordSet\",\n            zone = zone,\n            record_name=\"alias\",\n            target= route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(secondaryLoadBalancer)),\n        )\n        secondaryRecordSet = secondary.node.default_child\n        secondaryRecordSet.failover = \"SECONDARY\"\n        secondaryRecordSet.add_property_override('AliasTarget.EvaluateTargetHealth', True)\n        secondaryRecordSet.set_identifier = \"Secondary\"", "language": "python"}
{"input": "Construct that creates a custom resource that will perform a query using the AWS SDK", "output": "export class AwsApiCall extends ApiCallBase {\n  public readonly provider: AssertionsProvider;\n\n  /**\n   * access the AssertionsProvider for the waiter state machine.\n   * This can be used to add additional IAM policies\n   * the the provider role policy\n   *\n   * @example\n   * declare const apiCall: AwsApiCall;\n   * apiCall.waiterProvider?.addToRolePolicy({\n   *   Effect: 'Allow',\n   *   Action: ['s3:GetObject'],\n   *   Resource: ['*'],\n   * });\n   */\n  public waiterProvider?: AssertionsProvider;\n\n  protected readonly apiCallResource: CustomResource;\n  private readonly name: string;\n\n  private _assertAtPath?: string;\n  private readonly api: string;\n  private readonly service: string;\n\n  constructor(scope: Construct, id: string, props: AwsApiCallProps) {\n    super(scope, id);\n\n    this.provider = new AssertionsProvider(this, 'SdkProvider', {\n      logRetention: props.parameters?.RetentionDays,\n    });\n    this.provider.addPolicyStatementFromSdkCall(props.service, props.api);\n    this.name = `${props.service}${props.api}`;\n    this.api = props.api;\n    this.service = props.service;\n    if (props.outputPaths) {\n      this.outputPaths = [...props.outputPaths];\n    }\n\n    this.apiCallResource = new CustomResource(this, 'Default', {\n      serviceToken: this.provider.serviceToken,\n      properties: {\n        service: props.service,\n        api: props.api,\n        expected: Lazy.any({ produce: () => this.expectedResult }),\n        actualPath: Lazy.string({ produce: () => this._assertAtPath }),\n        stateMachineArn: Lazy.string({ produce: () => this.stateMachineArn }),\n        parameters: this.provider.encode(props.parameters),\n        flattenResponse: Lazy.string({ produce: () => this.flattenResponse }),\n        outputPaths: Lazy.list({ produce: () => this.outputPaths }),\n        salt: Date.now().toString(),\n      },\n      // Remove the slash from the resource type because when using the v3 package name as the service name,\n      // the `service` props includes the slash, but the resource type name cannot contain the slash\n      // See https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cloudformation-customresource.html#aws-resource-cloudformation-customresource--remarks\n      resourceType: `${SDK_RESOURCE_TYPE_PREFIX}${this.name}`.substring(0, 60).replace(/[\\/]/g, ''),\n    });\n    // Needed so that all the policies set up by the provider should be available before the custom resource is provisioned.\n    this.apiCallResource.node.addDependency(this.provider);\n\n    // if expectedResult has been configured then that means\n    // we are making assertions and we should output the results\n    Aspects.of(this).add({\n      visit(node: IConstruct) {\n        if (node instanceof AwsApiCall) {\n          if (node.expectedResult) {\n            const result = node.apiCallResource.getAttString('assertion');\n\n            new CfnOutput(node, 'AssertionResults', {\n              value: result,\n              // Remove the at sign, slash, and hyphen because when using the v3 package name or client name as the service name,\n              // the `id` includes them, but they are not allowed in the `CfnOutput` logical id\n              // See https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/outputs-section-structure.html#outputs-section-syntax\n            }).overrideLogicalId(`AssertionResults${id}`.replace(/[\\@\\/\\-]/g, ''));\n          }\n        }\n      },\n    }, { priority: AspectPriority.MUTATING });\n  }\n\n  public assertAtPath(path: string, expected: ExpectedResult): IApiCall {\n    this._assertAtPath = path;\n    (this.outputPaths ??= []).push(path);\n    this.expectedResult = expected.result;\n    this.flattenResponse = 'true';\n    return this;\n  }\n\n  public waitForAssertions(options?: WaiterStateMachineOptions): IApiCall {\n    const waiter = new WaiterStateMachine(this, 'WaitFor', {\n      ...options,\n    });\n    this.stateMachineArn = waiter.stateMachineArn;\n    this.provider.addPolicyStatementFromSdkCall('states', 'StartExecution');\n    waiter.isCompleteProvider.addPolicyStatementFromSdkCall(this.service, this.api);\n    this.waiterProvider = waiter.isCompleteProvider;\n    return this;\n  }\n}", "language": "typescript"}
{"input": "The built-in container instance attributes", "output": "export class BuiltInAttributes {\n  /**\n   * The id of the instance.\n   */\n  public static readonly INSTANCE_ID = 'instanceId';\n\n  /**\n   * The AvailabilityZone where the instance is running in.\n   */\n  public static readonly AVAILABILITY_ZONE = 'attribute:ecs.availability-zone';\n\n  /**\n   * The AMI id the instance is using.\n   */\n  public static readonly AMI_ID = 'attribute:ecs.ami-id';\n\n  /**\n   * The EC2 instance type.\n   */\n  public static readonly INSTANCE_TYPE = 'attribute:ecs.instance-type';\n\n  /**\n   * The operating system of the instance.\n   *\n   * Either 'linux' or 'windows'.\n   */\n  public static readonly OS_TYPE = 'attribute:ecs.os-type';\n}", "language": "typescript"}
{"input": "Exported class from VPC to support subnet filtering and CIDR validation", "output": "export class CidrBlock {\n  /**\n   * Calculates the netmask for a given CIDR mask\n   *\n   * The netmask is a 32-bit binary value used to separate the network portion from the host portion of an IPv4 address.\n   * It is calculated based on the CIDR prefix length (the number of bits used to represent the network portion).\n   *\n   * For example:\n   * CidrBlock.calculateNetmask(24) returns '255.255.255.0'\n   *\n   * @param mask The CIDR prefix length (between 0 and 32) for which to calculate the netmask.\n    // Calculate the netmask by performing a bitwise NOT on the result of (2^32 - 2^(32 - mask))\n   * @returns The netmask string in IPv4 address format.\n   */\n  public static calculateNetmask(mask: number): string {\n    return NetworkUtils.numToIp(2 ** 32 - 2 ** (32 - mask));\n  }\n\n  /**\n   * Calculates the number IP addresses in a CIDR Mask\n   *\n   * For example:\n   * CidrBlock.calculateNetsize(16) returns 65536\n   *\n   * @param mask The CIDR prefix length (between 0 and 32) for which to calculate the network size.\n   * CidrBlock.calculateNetsize(24) returns 256\n   */\n  public static calculateNetsize(mask: number): number {\n    return 2 ** (32 - mask);\n  }\n\n  /**\n   * IP address in the CIDR block.\n   */\n  public readonly cidr: string;\n\n  /*\n   * The CIDR mask e.g. for CIDR '10.0.0.0/21' returns 21\n   */\n  public readonly mask: number;\n\n  /*\n   * The total number of IP addresses in the CIDR\n   */\n  public readonly networkSize: number;\n\n  /*\n   * The network address provided in CIDR creation offset by the Netsize -1\n   */\n  private readonly networkAddress: number;\n\n  /*\n   * Parses either CIDR notation String or two numbers representing the IP\n   * space\n   *\n   * cidr expects a string '10.0.0.0/16'\n   * ipAddress expects a number\n   * mask expects a number\n   *\n   * If the given `cidr` or `ipAddress` is not the beginning of the block,\n   * then the next available block will be returned. For example, if\n   * `10.0.3.1/28` is given the returned block will represent `10.0.3.16/28`.\n   */\n  constructor(cidr: string);\n  constructor(ipAddress: number, mask: number);\n  constructor(ipAddressOrCidr: string | number, mask?: number) {\n    if (typeof ipAddressOrCidr === 'string') {\n      this.mask = parseInt(ipAddressOrCidr.split('/')[1], 10);\n      this.networkAddress = NetworkUtils.ipToNum(ipAddressOrCidr.split('/')[0]) +\n        CidrBlock.calculateNetsize(this.mask) - 1;\n    } else {\n      if (typeof mask === 'number') {\n        this.mask = mask;\n      } else {\n        // this should be impossible\n        this.mask = 16;\n      }\n      this.networkAddress = ipAddressOrCidr + CidrBlock.calculateNetsize(this.mask) - 1;\n      this.networkSize = 2 ** (32 - this.mask);\n    }\n    this.networkSize = 2 ** (32 - this.mask);\n    this.cidr = `${this.minIp()}/${this.mask}`;\n  }\n\n  /*\n   * The maximum IP in the CIDR Block e.g. '10.0.8.255'\n   */\n  public maxIp(): string {\n    // min + (2^(32-mask)) - 1 [zero needs to count]\n    return NetworkUtils.numToIp(this.maxAddress());\n  }\n\n  /*\n   * Checks if this CIDR block fully contains the provided CIDR block.\n   *\n   * @param other The CIDR block to check for containment.\n   * @returns True if this CIDR block fully contains the provided CIDR block, false otherwise.\n   *\n   * The minimum IP in the CIDR Block e.g. '10.0.0.0'\n   */\n  public minIp(): string {\n    return NetworkUtils.numToIp(this.minAddress());\n  }\n\n  /*\n   * Returns the number representation for the minimum IPv4 address\n   */\n  public minAddress(): number {\n    const div = this.networkAddress % this.networkSize;\n    return this.networkAddress - div;\n  }\n\n  /*\n   * Returns the number representation for the maximum IPv4 address\n   */\n  public maxAddress(): number {\n    /**\n     * The maximum IP address in the CIDR block is calculated as the minimum address + (2^(32-mask)) - 1.\n     * This is because the minimum address represents the network address, and the maximum address is the broadcast address.\n     */\n    // min + (2^(32-mask)) - 1 [zero needs to count]\n    return this.minAddress() + this.networkSize - 1;\n  }\n\n  /*\n   * Returns the next consecutive CIDR block of the same mask size following this CIDR block.\n   *\n   * For example, if this CIDR block is '10.0.0.0/24', the next block would be '10.0.1.0/24'.\n   *\n   * Returns the next CIDR Block of the same mask size\n   */\n  public nextBlock(): CidrBlock {\n    return new CidrBlock(this.maxAddress() + 1, this.mask);\n  }\n\n  /*\n   * Returns true if this CidrBlock fully contains the provided CidrBlock\n   */\n  public containsCidr(other: CidrBlock): boolean {\n    return (this.maxAddress() >= other.maxAddress()) &&\n      (this.minAddress() <= other.minAddress());\n  }\n\n  /**\n   * Checks if two IPv4 address ranges overlap.\n   *\n   * @param range1 The first IP address range represented as an array [start, end].\n   * @param range2 The second IP address range represented as an array [start, end].\n   * @returns True if the two IP address ranges overlap, false otherwise.\n   *\n   * Note: This method assumes that the start and end addresses are valid IPv4 addresses.\n   */\n  public rangesOverlap(range1: [string, string], range2: [string, string]): boolean {\n    const [start1, end1] = range1.map(ip => NetworkUtils.ipToNum(ip));\n    const [start2, end2] = range2.map(ip => NetworkUtils.ipToNum(ip));\n    // Check if ranges overlap\n    return start1 <= end2 && start2 <= end1;\n  }\n}", "language": "typescript"}
{"input": "Abstract base class for agent runtime artifacts. Provides methods to reference container images from ECR repositories or local assets.", "output": "class AgentRuntimeArtifact {\n  /**\n   * Reference an image in an ECR repository\n   */\n  public static fromEcrRepository(repository: ecr.IRepository, tag: string = 'latest'): AgentRuntimeArtifact {\n    return new EcrImage(repository, tag);\n  }\n\n  /**\n   * Reference an agent runtime artifact that's constructed directly from sources on disk\n   * @param directory The directory where the Dockerfile is stored\n   * @param options The options to further configure the selected image\n   */\n  public static fromAsset(directory: string, options: assets.DockerImageAssetOptions = {}): AgentRuntimeArtifact {\n    return new AssetImage(directory, options);\n  }\n\n  /**\n   * Reference an agent runtime artifact that's constructed directly from an S3 object\n   * @param s3Location The source code location and configuration details.\n   * @param runtime The runtime environment for executing the code. Allowed values: PYTHON_3_10 | PYTHON_3_11 | PYTHON_3_12 | PYTHON_3_13\n   * @param entrypoint The entry point for the code execution, specifying the function or method that should be invoked when the code runs.\n   */\n  public static fromS3(s3Location: s3.Location, runtime: AgentCoreRuntime, entrypoint: string[]): AgentRuntimeArtifact {\n    return new S3Image(s3Location, runtime, entrypoint);\n  }\n\n  /**\n   * Reference an image using an ECR container URI\n   *\n   * Use this when referencing ECR images from CloudFormation parameters or cross-stack references.\n   *\n   * **Note:** No IAM permissions are automatically granted. You must ensure the runtime has\n   * ECR pull permissions for the repository.\n   *\n   * @param containerUri The ECR container image URI (format: {account}.dkr.ecr.{region}.amazonaws.com/{repository}:{tag})\n   */\n  public static fromImageUri(containerUri: string): AgentRuntimeArtifact {\n    return new ImageUriArtifact(containerUri);\n  }\n\n  /**\n   * Called when the image is used by a Runtime to handle side effects like permissions\n   */\n  public abstract bind(scope: Construct, runtime: Runtime): void;\n\n  /**\n   * Render the artifact configuration for CloudFormation\n   * @internal\n   */\n  public abstract _render(): CfnRuntime.AgentRuntimeArtifactProperty;\n}", "language": "typescript"}
{"input": "Creates a mix of file and image assets, up to a specified count", "output": "export class MegaAssetsApp extends Stage {\n  constructor(scope: Construct, id: string, props: MegaAssetsAppProps) {\n    super(scope, id, props);\n    const stack = new Stack(this, 'Stack');\n\n    let assetCount = 0;\n    for (; assetCount < props.numAssets / 2; assetCount++) {\n      new s3_assets.Asset(stack, `Asset${assetCount}`, {\n        path: path.join(__dirname, 'assets', 'test-file-asset.txt'),\n        assetHash: `FileAsset${assetCount}`,\n      });\n    }\n    for (; assetCount < props.numAssets; assetCount++) {\n      new ecr_assets.DockerImageAsset(stack, `Asset${assetCount}`, {\n        directory: path.join(__dirname, 'assets', 'test-docker-asset'),\n        extraHash: `FileAsset${assetCount}`,\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ResourceHandler for AWS resource management", "output": "class ResourceHandler {\n  protected readonly requestId: string;\n  protected readonly logicalResourceId: string;\n  protected readonly requestType: 'Create' | 'Update' | 'Delete';\n  protected readonly physicalResourceId?: string;\n  protected readonly event: ResourceEvent;\n\n  constructor(protected readonly eks: EksClient, event: ResourceEvent) {\n    this.requestType = event.RequestType;\n    this.requestId = event.RequestId;\n    this.logicalResourceId = event.LogicalResourceId;\n    this.physicalResourceId = (event as any).PhysicalResourceId;\n    this.event = event;\n\n    const roleToAssume = event.ResourceProperties.AssumeRoleArn;\n    if (!roleToAssume) {\n      throw new Error('AssumeRoleArn must be provided');\n    }\n\n    eks.configureAssumeRole({\n      RoleArn: roleToAssume,\n      RoleSessionName: `AWSCDK.EKSCluster.${this.requestType}.${this.requestId}`,\n    });\n  }\n\n  public onEvent() {\n    switch (this.requestType) {\n      case 'Create': return this.onCreate();\n      case 'Update': return this.onUpdate();\n      case 'Delete': return this.onDelete();\n    }\n\n    throw new Error(`Invalid request type ${this.requestType}`);\n  }\n\n  public isComplete() {\n    switch (this.requestType) {\n      case 'Create': return this.isCreateComplete();\n      case 'Update': return this.isUpdateComplete();\n      case 'Delete': return this.isDeleteComplete();\n    }\n\n    throw new Error(`Invalid request type ${this.requestType}`);\n  }\n\n  protected log(x: any) {\n    console.log(JSON.stringify(x, undefined, 2));\n  }\n\n  protected abstract onCreate(): Promise<OnEventResponse>;\n  protected abstract onDelete(): Promise<OnEventResponse | void>;\n  protected abstract onUpdate(): Promise<(OnEventResponse & EksUpdateId) | void>;\n  protected abstract isCreateComplete(): Promise<IsCompleteResponse>;\n  protected abstract isDeleteComplete(): Promise<IsCompleteResponse>;\n  protected abstract isUpdateComplete(): Promise<IsCompleteResponse>;\n}", "language": "typescript"}
{"input": "CDK helper function when", "output": "const when = () => {\n        api.addElasticsearchDataSource('ds', domain);\n        api.addElasticsearchDataSource('ds', domain);\n      }", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, DynamoDB, SNS resources", "output": "export class DdbStreamStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    const aws_sns_kms_key = kms.Alias.fromAliasName(\n      this,\n      \"aws-managed-sns-kms-key\",\n      \"alias/aws/sns\",\n    )\n\n    const snsTopic = new sns.Topic(this, 'ddb-stream-topic', {\n      topicName: 'ddb-stream-topic',\n      displayName: 'SNS Topic for DDB streams',\n      enforceSSL: true,\n      masterKey: aws_sns_kms_key,\n    });\n\n    //L2 CDK Construct\n    const deadLetterQueueL2 = new sqs.Queue(this, 'ddb-stream-l2-dlq', {\n      queueName: 'ddb-stream-l2-dlq',\n      encryption: sqs.QueueEncryption.KMS_MANAGED,\n      retentionPeriod: cdk.Duration.days(4), // Adjust retention period as needed\n    });\n\n    const itemL2Table = new dynamodb.Table(this, 'itemL2Table', {\n      partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING },\n      stream: dynamodb.StreamViewType.NEW_AND_OLD_IMAGES,\n      billingMode: dynamodb.BillingMode.PAY_PER_REQUEST,\n      encryption: dynamodb.TableEncryption.AWS_MANAGED,\n      //If you wish to retain the table after running cdk destroy, comment out the line below\n      removalPolicy: cdk.RemovalPolicy.DESTROY\n    });\n\n    const itemL2TableLambdaFunction = new lambda.Function(this, 'itemL2TableLambdaFunction', {\n      runtime: lambda.Runtime.NODEJS_20_X,\n      handler: 'index.handler',\n      tracing: lambda.Tracing.ACTIVE,\n      code: lambda.Code.fromAsset('resources/lambda'),\n      environment: {\n        SNS_TOPIC_ARN: snsTopic.topicArn,\n        AWS_NODEJS_CONNECTION_REUSE_ENABLED: '1'\n      },\n    });\n    itemL2TableLambdaFunction.addEventSource(new lambdaEventSources.DynamoEventSource(itemL2Table, {\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      onFailure: new lambdaEventSources.SqsDlq(deadLetterQueueL2),\n      bisectBatchOnError: true,\n      maxRecordAge: cdk.Duration.hours(24),\n      retryAttempts: 500,\n    }));\n\n    deadLetterQueueL2.grantSendMessages(itemL2TableLambdaFunction);\n\n    itemL2Table.grantStreamRead(itemL2TableLambdaFunction);\n\n    //L3 CDK Construct\n    const itemL3Table = new DynamoDBStreamsToLambda(this, 'itemL3Table', {\n      dynamoTableProps: {\n        partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING },\n        stream: dynamodb.StreamViewType.NEW_AND_OLD_IMAGES,\n        //If you wish to retain the table after running cdk destroy, comment out the line below\n        removalPolicy: cdk.RemovalPolicy.DESTROY\n      },\n      lambdaFunctionProps: {\n        code: lambda.Code.fromAsset('resources/lambda'),\n        runtime: lambda.Runtime.NODEJS_20_X,\n        handler: 'index.handler',\n        environment: {\n          SNS_TOPIC_ARN: snsTopic.topicArn,\n        },\n      },\n    });\n\n    snsTopic.grantPublish(itemL2TableLambdaFunction);\n    snsTopic.grantPublish(itemL3Table.lambdaFunction);\n\n    new cdk.CfnOutput(this, 'itemL2TableLambdaFunctionArn', { value: itemL2TableLambdaFunction.functionArn });\n    new cdk.CfnOutput(this, 'itemL3TableLambdaFunctionArn', { value: itemL3Table.lambdaFunction.functionArn });\n    new cdk.CfnOutput(this, 'l3TableArn', { value: itemL3Table.dynamoTableInterface.tableArn });\n    new cdk.CfnOutput(this, 'l2TableArn', { value: itemL2Table.tableArn });\n    new cdk.CfnOutput(this, 'topicArn', { value: snsTopic.topicArn });\n    new cdk.CfnOutput(this, 'l2DLQArn', { value: deadLetterQueueL2.queueArn })\n  }\n}", "language": "typescript"}
{"input": "CDK class MyCfnResource for AWS resource management", "output": "class MyCfnResource extends AbstractCfnResource {\n      protected get cfnProperties(): { [key: string]: any } {\n        return {\n          mystringpropkey: 'mystringpropval',\n          mylistpropkey: ['listitem1'],\n          mystructpropkey: {\n            myboolpropkey: true,\n            mynumpropkey: 50,\n          },\n        };\n      }\n    }", "language": "typescript"}
{"input": "CDK class LifecyclePolicy for AWS resource management", "output": "export class LifecyclePolicy extends LifecyclePolicyBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.LifecyclePolicy';\n\n  /**\n   * Import an existing lifecycle policy given its ARN.\n   */\n  public static fromLifecyclePolicyArn(scope: Construct, id: string, lifecyclePolicyArn: string): ILifecyclePolicy {\n    const lifecyclePolicyName = cdk.Stack.of(scope).splitArn(\n      lifecyclePolicyArn,\n      cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    ).resourceName!;\n\n    class Import extends LifecyclePolicyBase {\n      public readonly lifecyclePolicyArn = lifecyclePolicyArn;\n      public readonly lifecyclePolicyName = lifecyclePolicyName;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing lifecycle policy given its name. If the name is a token representing a dynamic CloudFormation\n   * expression, you must ensure all alphabetic characters in the expression are already lowercased\n   */\n  public static fromLifecyclePolicyName(scope: Construct, id: string, lifecyclePolicyName: string): ILifecyclePolicy {\n    return LifecyclePolicy.fromLifecyclePolicyArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'lifecycle-policy',\n        resourceName: lifecyclePolicyName,\n      }),\n    );\n  }\n\n  /**\n   * Return whether the given object is a LifecyclePolicy.\n   */\n  public static isLifecyclePolicy(x: any): x is LifecyclePolicy {\n    return x !== null && typeof x === 'object' && LIFECYCLE_POLICY_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the lifecycle policy\n   */\n  public readonly lifecyclePolicyArn: string;\n\n  /**\n   * The name of the lifecycle policy\n   */\n  public readonly lifecyclePolicyName: string;\n\n  /**\n   * The execution role used for lifecycle policy executions\n   */\n  public readonly executionRole: iam.IRole;\n\n  public constructor(scope: Construct, id: string, props: LifecyclePolicyProps) {\n    super(scope, id, {\n      physicalName:\n        props.lifecyclePolicyName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(),\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, LIFECYCLE_POLICY_SYMBOL, { value: true });\n\n    this.validateLifecyclePolicyName();\n    this.validatePolicy(props);\n\n    this.executionRole =\n      props.executionRole ??\n      new iam.Role(this, 'ExecutionRole', {\n        assumedBy: new iam.ServicePrincipal('imagebuilder.amazonaws.com'),\n        managedPolicies: [\n          iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/EC2ImageBuilderLifecycleExecutionPolicy'),\n        ],\n      });\n\n    const lifecyclePolicy = new CfnLifecyclePolicy(this, 'Resource', {\n      name: this.physicalName,\n      description: props.description,\n      resourceType: props.resourceType,\n      executionRole: this.executionRole.roleArn,\n      policyDetails: this.buildPolicyDetails(props.resourceType, props.details),\n      resourceSelection: {\n        ...(props.resourceSelection.recipes !== undefined && {\n          recipes: this.buildRecipes(props.resourceType, props.resourceSelection.recipes),\n        }),\n        tagMap: props.resourceSelection.tags,\n      },\n      status: props.status,\n      tags: props.tags,\n    });\n\n    this.lifecyclePolicyName = this.getResourceNameAttribute(lifecyclePolicy.ref);\n    this.lifecyclePolicyArn = this.getResourceArnAttribute(lifecyclePolicy.attrArn, {\n      service: 'imagebuilder',\n      resource: 'lifecycle-policy',\n      resourceName: this.physicalName,\n    });\n  }\n\n  /**\n   * Generates the policy details property into the `PolicyDetail` type in the CloudFormation L1 definition.\n   *\n   * @param resourceType The resource type of the lifecycle policy\n   * @param details The lifecycle policy rules\n   * @private\n   */\n  private buildPolicyDetails(\n    resourceType: LifecyclePolicyResourceType,\n    details: LifecyclePolicyDetail[],\n  ): CfnLifecyclePolicy.PolicyDetailProperty[] {\n    return details.map((detail): CfnLifecyclePolicy.PolicyDetailProperty => {\n      const action = this.buildAction(resourceType, detail.action);\n      const exclusionRules =\n        detail.exclusionRules !== undefined ? this.buildExclusionRules(detail.exclusionRules) : undefined;\n\n      this.validatePolicyDetailAction(resourceType, detail.action, exclusionRules?.amis);\n      this.validatePolicyDetailFilter(detail.filter);\n\n      return {\n        action: action,\n        filter: {\n          retainAtLeast: detail.filter.ageFilter?.retainAtLeast,\n          type: detail.filter.ageFilter !== undefined ? 'AGE' : 'COUNT',\n          ...(detail.filter.ageFilter !== undefined\n            ? this.convertDurationToTimeUnitValue(detail.filter.ageFilter.age)\n            : { value: detail.filter.countFilter!.count }),\n        },\n        ...(exclusionRules !== undefined && { exclusionRules }),\n      };\n    });\n  }\n\n  /**\n   * Generates the recipes property in the resource selection into the `RecipeSelection` type in the CloudFormation L1\n   * definition.\n   *\n   * @param resourceType The resource type of the lifecycle policy\n   * @param recipes The recipes passed in the props\n   * @private\n   */\n  private buildRecipes(\n    resourceType: LifecyclePolicyResourceType,\n    recipes: IRecipeBase[],\n  ): CfnLifecyclePolicy.RecipeSelectionProperty[] | undefined {\n    return recipes?.map((recipe): CfnLifecyclePolicy.RecipeSelectionProperty => {\n      if (recipe._isImageRecipe()) {\n        if (resourceType === LifecyclePolicyResourceType.CONTAINER_IMAGE) {\n          throw new cdk.ValidationError(\n            `recipes in the resource selection must all be container recipes for policy type ${LifecyclePolicyResourceType.CONTAINER_IMAGE}`,\n            this,\n          );\n        }\n\n        return {\n          name: recipe.imageRecipeName,\n          semanticVersion: recipe.imageRecipeVersion,\n        };\n      }\n\n      if (recipe._isContainerRecipe()) {\n        if (resourceType === LifecyclePolicyResourceType.AMI_IMAGE) {\n          throw new cdk.ValidationError(\n            `recipes in the resource selection must all be image recipes for policy type ${LifecyclePolicyResourceType.AMI_IMAGE}`,\n            this,\n          );\n        }\n\n        return {\n          name: recipe.containerRecipeName,\n          semanticVersion: recipe.containerRecipeVersion,\n        };\n      }\n\n      throw new cdk.ValidationError(\n        'recipes in the resource selection must either be an IImageRecipe or IContainerRecipe',\n        this,\n      );\n    });\n  }\n\n  /**\n   * Generates the exclusion rules property into the `ExclusionRules` type in the CloudFormation L1 definition.\n   *\n   * @param exclusionRules The exclusion rules for resources applied in the lifecycle policy rule\n   * @private\n   */\n  private buildExclusionRules(\n    exclusionRules: LifecyclePolicyExclusionRules,\n  ): CfnLifecyclePolicy.ExclusionRulesProperty | undefined {\n    const amiExclusionRules: CfnLifecyclePolicy.AmiExclusionRulesProperty = {\n      ...(exclusionRules.amiExclusionRules?.isPublic && { isPublic: exclusionRules.amiExclusionRules.isPublic }),\n      ...(exclusionRules.amiExclusionRules?.lastLaunched !== undefined && {\n        lastLaunched: this.convertDurationToTimeUnitValue(exclusionRules.amiExclusionRules.lastLaunched, 365),\n      }),\n      ...(exclusionRules.amiExclusionRules?.regions?.length && { regions: exclusionRules.amiExclusionRules.regions }),\n      ...(exclusionRules.amiExclusionRules?.sharedAccounts?.length && {\n        sharedAccounts: exclusionRules.amiExclusionRules.sharedAccounts,\n      }),\n      ...(exclusionRules.amiExclusionRules?.tags && { tagMap: exclusionRules.amiExclusionRules.tags }),\n    };\n\n    const cfnExclusionRules: CfnLifecyclePolicy.ExclusionRulesProperty = {\n      ...(Object.keys(amiExclusionRules).length && { amis: amiExclusionRules }),\n      ...(exclusionRules.imageExclusionRules !== undefined && { tagMap: exclusionRules.imageExclusionRules.tags }),\n    };\n\n    return Object.keys(exclusionRules).length ? cfnExclusionRules : undefined;\n  }\n\n  /**\n   * Generates the action property into the `Action` type in the CloudFormation L1 definition.\n   *\n   * @param resourceType The resource type of the lifecycle policy\n   * @param action The action being taken in the lifecycle policy rule\n   * @private\n   */\n  private buildAction(\n    resourceType: LifecyclePolicyResourceType,\n    action: LifecyclePolicyAction,\n  ): CfnLifecyclePolicy.ActionProperty {\n    const isContainerPolicy =\n      !cdk.Token.isUnresolved(resourceType) && resourceType === LifecyclePolicyResourceType.CONTAINER_IMAGE;\n    const isAmiPolicy = !cdk.Token.isUnresolved(resourceType) && resourceType === LifecyclePolicyResourceType.AMI_IMAGE;\n\n    const amis = action.includeAmis ?? (isAmiPolicy ? true : undefined);\n    const snapshots = action.includeSnapshots ?? (isAmiPolicy ? true : undefined);\n    const containers = action.includeContainers ?? (isContainerPolicy ? true : undefined);\n    const includeResources: CfnLifecyclePolicy.IncludeResourcesProperty = {\n      ...(amis !== undefined && { amis }),\n      ...(snapshots !== undefined && { snapshots }),\n      ...(containers !== undefined && { containers }),\n    };\n\n    return {\n      type: action.type,\n      ...(Object.keys(includeResources).length && { includeResources }),\n    };\n  }\n\n  /**\n   * Validates the top-level properties of the policy\n   *\n   * @param props The props passed as input to the construct\n   * @private\n   */\n  private validatePolicy(props: LifecyclePolicyProps): void {\n    if (props.resourceSelection.recipes?.length && Object.keys(props.resourceSelection.tags || {}).length) {\n      throw new cdk.ValidationError('resource selection cannot contain both recipes and tags', this);\n    }\n\n    if (!props.resourceSelection.recipes?.length && !Object.keys(props.resourceSelection.tags || {}).length) {\n      throw new cdk.ValidationError('resource selection must contain either recipes or tags', this);\n    }\n\n    if (props.details.length === 0) {\n      throw new cdk.ValidationError('a lifecycle policy must have at least 1 rule', this);\n    }\n\n    if (props.details.length > 3) {\n      throw new cdk.ValidationError('a lifecycle policy can only have up to 3 rules', this);\n    }\n\n    const actions = props.details.map((detail) => detail.action.type);\n    if (new Set(actions).size != actions.length) {\n      throw new cdk.ValidationError('lifecycle policy rules may not have duplicate actions', this);\n    }\n  }\n\n  /**\n   * Validates a policy detail filter within a lifecycle policy rule\n   *\n   * @param resourceType The resource type of the lifecycle policy\n   * @param action The action being taken in the lifecycle policy rule\n   * @param amiExclusionRules The AMI exclusion rules in the lifecycle policy rule\n   * @private\n   */\n  private validatePolicyDetailAction(\n    resourceType: LifecyclePolicyResourceType,\n    action: LifecyclePolicyAction,\n    amiExclusionRules: CfnLifecyclePolicy.AmiExclusionRulesProperty | cdk.IResolvable | undefined,\n  ) {\n    if (!cdk.Token.isUnresolved(resourceType) && resourceType === LifecyclePolicyResourceType.CONTAINER_IMAGE) {\n      if (!cdk.Token.isUnresolved(action.type) && action.type !== LifecyclePolicyActionType.DELETE) {\n        throw new cdk.ValidationError('you may only specify DELETE rules for container policies', this);\n      }\n\n      if (action.includeAmis) {\n        throw new cdk.ValidationError('you cannot include AMIs in a container policy', this);\n      }\n\n      if (action.includeSnapshots) {\n        throw new cdk.ValidationError('you cannot include snapshots in a container policy', this);\n      }\n\n      if (amiExclusionRules !== undefined) {\n        throw new cdk.ValidationError('you cannot exclude AMIs in a container policy', this);\n      }\n    }\n\n    if (\n      !cdk.Token.isUnresolved(resourceType) &&\n      resourceType === LifecyclePolicyResourceType.AMI_IMAGE &&\n      action.includeContainers\n    ) {\n      throw new cdk.ValidationError('you cannot include containers in an AMI policy', this);\n    }\n  }\n\n  /**\n   * Validates a policy detail filter\n   *\n   * @param filter The lifecycle policy resource filter applied in the rule\n   * @private\n   */\n  private validatePolicyDetailFilter(filter: LifecyclePolicyFilter) {\n    if (filter.ageFilter !== undefined && filter.countFilter !== undefined) {\n      throw new cdk.ValidationError('either age count can be specified in a policy filter, but not both', this);\n    }\n\n    if (filter.ageFilter === undefined && filter.countFilter === undefined) {\n      throw new cdk.ValidationError('you must provide an age or count filter in the policy', this);\n    }\n\n    const retainAtLeast = filter.ageFilter?.retainAtLeast;\n    if (retainAtLeast !== undefined) {\n      if (retainAtLeast < 1) {\n        throw new cdk.ValidationError('the retainAtLeast filter value must be at least 1', this);\n      }\n      if (retainAtLeast > 10) {\n        throw new cdk.ValidationError('the retainAtLeast filter value must be at most 10', this);\n      }\n    }\n  }\n\n  /**\n   * Converts a `cdk.Duration` into the value and unit which is accepted as filter age and last launched age in the\n   * lifecycle policy. The value is rounded up to the nearest whole number.\n   *\n   * @param duration The duration to convert\n   * @param valueLimit The maximum value that can be specified\n   * @private\n   */\n  private convertDurationToTimeUnitValue(\n    duration: cdk.Duration,\n    valueLimit: number = 1000,\n  ): { value: number; unit: 'DAYS' | 'WEEKS' | 'MONTHS' | 'YEARS' } {\n    const DAYS_PER_WEEK = 7;\n    const DAYS_PER_MONTH = 30;\n    const DAYS_PER_YEAR = 365;\n\n    const valueInDays = Math.ceil(duration.toDays());\n    if (valueInDays < 1) {\n      throw new cdk.ValidationError('the provided duration must be at least 1 day', this);\n    }\n\n    if (valueInDays <= valueLimit) {\n      return { value: valueInDays, unit: 'DAYS' };\n    }\n\n    const valueInWeeks = Math.ceil(valueInDays / DAYS_PER_WEEK);\n    if (valueInWeeks <= valueLimit) {\n      return { value: valueInWeeks, unit: 'WEEKS' };\n    }\n\n    const valueInMonths = Math.ceil(valueInDays / DAYS_PER_MONTH);\n    if (valueInMonths <= valueLimit) {\n      return { value: valueInMonths, unit: 'MONTHS' };\n    }\n\n    const valueInYears = Math.ceil(valueInDays / DAYS_PER_YEAR);\n    if (valueInYears <= valueLimit) {\n      return { value: valueInYears, unit: 'YEARS' };\n    }\n\n    throw new cdk.ValidationError(`the provided duration must be less than ${valueLimit} years`, this);\n  }\n\n  private validateLifecyclePolicyName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError('The lifecyclePolicyName cannot be longer than 128 characters', this);\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError('The lifecyclePolicyName cannot contain spaces', this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError('The lifecyclePolicyName cannot contain underscores', this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError('The lifecyclePolicyName must be lowercase', this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, AppSync operations", "output": "const when = () => {\n      new appsync.GraphqlApi(stack, 'API', {\n        name: 'apiKeyUnitTest',\n        schema: appsync.SchemaFile.fromAsset(path.join(__dirname, 'appsync.auth.graphql')),\n        authorizationConfig: {\n          defaultAuthorization: {\n            authorizationType: appsync.AuthorizationType.API_KEY,\n            apiKeyConfig: {\n              expires: cdk.Expiration.after(cdk.Duration.hours(1)),\n            },\n          },\n        },\n      });\n    }", "language": "typescript"}
{"input": "CDK class LogsHelper for AWS resource management", "output": "class LogsHelper extends ClassType {\n  private readonly log: VendedLogs;\n\n  constructor(\n    scope: Module,\n    name: string,\n    resource: Resource,\n    log: VendedLogs,\n  ) {\n    super(scope, {\n      export: true,\n      name: name,\n      docs: {\n        summary: `Builder for ${naming.classNameFromResource(resource)}LogsMixin to generate ${log.logType} for ${naming.classNameFromResource(resource)}`,\n        stability: Stability.External,\n        docTags: {\n          cloudformationResource: resource.cloudFormationType,\n          logType: log.logType,\n        },\n      },\n    });\n    this.log = log;\n  }\n\n  public build(mixin: LogsMixin) {\n    for (const dest of this.log.destinations) {\n      switch (dest.destinationType) {\n        case 'S3':\n          const toS3 = this.addMethod({\n            name: `to${dest.destinationType}`,\n            returnType: mixin.type,\n            docs: {\n              summary: 'Send logs to an S3 Bucket',\n            },\n          });\n\n          const paramS3 = toS3.addParameter({\n            name: 'bucket',\n            type: CDK_INTERFACES.IBucketRef,\n          });\n\n          const permissions = this.log.permissionsVersion === 'V2' ? MIXINS_LOGS_DELIVERY.S3LogsDeliveryPermissionsVersion.V2 : MIXINS_LOGS_DELIVERY.S3LogsDeliveryPermissionsVersion.V1;\n          toS3.addBody(stmt.block(\n            stmt.ret(\n              mixin.newInstance(expr.str(this.log.logType), new NewExpression(MIXINS_LOGS_DELIVERY.S3LogsDelivery, paramS3,\n                expr.object({ permissionsVersion: permissions }))),\n            ),\n          ));\n          break;\n        case 'CWL':\n          const toCWL = this.addMethod({\n            name: 'toLogGroup',\n            returnType: mixin.type,\n            docs: {\n              summary: 'Send logs to a CloudWatch Log Group',\n            },\n          });\n\n          const paramCWL = toCWL.addParameter({\n            name: 'logGroup',\n            type: CDK_INTERFACES.ILogGroupRef,\n          });\n\n          toCWL.addBody(stmt.block(\n            stmt.ret(\n              mixin.newInstance(expr.str(this.log.logType), new NewExpression(MIXINS_LOGS_DELIVERY.LogGroupLogsDelivery, paramCWL)),\n            ),\n          ));\n          break;\n        case 'FH':\n          const toFH = this.addMethod({\n            name: 'toFirehose',\n            returnType: mixin.type,\n            docs: {\n              summary: 'Send logs to a Firehose Delivery Stream',\n            },\n          });\n\n          const paramFH = toFH.addParameter({\n            name: 'deliveryStream',\n            type: CDK_INTERFACES.IDeliveryStreamRef,\n          });\n\n          toFH.addBody(stmt.block(\n            stmt.ret(\n              mixin.newInstance(expr.str(this.log.logType), new NewExpression(MIXINS_LOGS_DELIVERY.FirehoseLogsDelivery, paramFH)),\n            ),\n          ));\n          break;\n        default:\n          const toXRAY = this.addMethod({\n            name: 'toXRay',\n            returnType: mixin.type,\n            docs: {\n              summary: 'Send traces to X-Ray',\n            },\n          });\n\n          toXRAY.addBody(stmt.block(\n            stmt.ret(\n              mixin.newInstance(expr.str(this.log.logType), new NewExpression(MIXINS_LOGS_DELIVERY.XRayLogsDelivery)),\n            ),\n          ));\n          break;\n      }\n    }\n\n    mixin.addProperty({\n      name: this.log.logType,\n      type: this.type,\n      static: true,\n      immutable: true,\n      initializer: expr.directCode(`new ${this.name}()`),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, EKS operations", "output": "const t = () => {\n        const chartAsset = new Asset(stack, 'ChartAsset', {\n          path: path.join(__dirname, 'test-chart'),\n        });\n        new eks.HelmChart(stack, 'MyChart', {\n          cluster,\n          chartAsset,\n          repository: 'repository',\n        });\n      }", "language": "typescript"}
{"input": "Error thrown when an ApiSchema is not properly initialized.", "output": "class ApiSchemaError extends Error {\n  constructor(message: string, public readonly cause?: string) {\n    super(message);\n    this.name = 'ApiSchemaError';\n  }\n}", "language": "typescript"}
{"input": "Resources types that are supported by AWS Config @see https://docs.aws.amazon.com/config/latest/developerguide/resource-config-reference.html", "output": "export class ResourceType {\n  /** API Gateway Stage */\n  public static readonly APIGATEWAY_STAGE = new ResourceType('AWS::ApiGateway::Stage');\n  /** API Gatewayv2 Stage */\n  public static readonly APIGATEWAYV2_STAGE = new ResourceType('AWS::ApiGatewayV2::Stage');\n  /** API Gateway REST API */\n  public static readonly APIGATEWAY_REST_API = new ResourceType('AWS::ApiGateway::RestApi');\n  /** API Gatewayv2 API */\n  public static readonly APIGATEWAYV2_API = new ResourceType('AWS::ApiGatewayV2::Api');\n  /** Amazon CloudFront Distribution */\n  public static readonly CLOUDFRONT_DISTRIBUTION = new ResourceType('AWS::CloudFront::Distribution');\n  /** Amazon CloudFront streaming distribution */\n  public static readonly CLOUDFRONT_STREAMING_DISTRIBUTION = new ResourceType('AWS::CloudFront::StreamingDistribution');\n  /** Amazon CloudWatch Alarm */\n  public static readonly CLOUDWATCH_ALARM = new ResourceType('AWS::CloudWatch::Alarm');\n  /** Amazon CloudWatch RUM */\n  public static readonly CLOUDWATCH_RUM_APP_MONITOR = new ResourceType('AWS::RUM::AppMonitor');\n  /** Amazon DynamoDB Table */\n  public static readonly DYNAMODB_TABLE = new ResourceType('AWS::DynamoDB::Table');\n  /** Elastic Block Store (EBS) volume */\n  public static readonly EBS_VOLUME = new ResourceType('AWS::EC2::Volume');\n  /** EC2 host */\n  public static readonly EC2_HOST = new ResourceType('AWS::EC2::Host');\n  /** EC2 Elastic IP */\n  public static readonly EC2_EIP = new ResourceType('AWS::EC2::EIP');\n  /** EC2 instance */\n  public static readonly EC2_INSTANCE = new ResourceType('AWS::EC2::Instance');\n  /** EC2 Network Interface */\n  public static readonly EC2_NETWORK_INTERFACE = new ResourceType('AWS::EC2::NetworkInterface');\n  /** EC2 security group */\n  public static readonly EC2_SECURITY_GROUP = new ResourceType('AWS::EC2::SecurityGroup');\n  /** EC2 NAT gateway */\n  public static readonly EC2_NAT_GATEWAY = new ResourceType('AWS::EC2::NatGateway');\n  /** EC2 Egress only internet gateway */\n  public static readonly EC2_EGRESS_ONLY_INTERNET_GATEWAY = new ResourceType('AWS::EC2::EgressOnlyInternetGateway');\n  /** EC2 flow log */\n  public static readonly EC2_FLOW_LOG = new ResourceType('AWS::EC2::FlowLog');\n  /** EC2 transit gateway */\n  public static readonly EC2_TRANSIT_GATEWAY = new ResourceType('AWS::EC2::TransitGateway');\n  /** EC2 transit gateway attachment */\n  public static readonly EC2_TRANSIT_GATEWAY_ATTACHMENT = new ResourceType('AWS::EC2::TransitGatewayAttachment');\n  /** EC2 transit gateway route table */\n  public static readonly EC2_TRANSIT_GATEWAY_ROUTE_TABLE = new ResourceType('AWS::EC2::TransitGatewayRouteTable');\n  /** EC2 VPC endpoint */\n  public static readonly EC2_VPC_ENDPOINT = new ResourceType('AWS::EC2::VPCEndpoint');\n  /** EC2 VPC endpoint service */\n  public static readonly EC2_VPC_ENDPOINT_SERVICE = new ResourceType('AWS::EC2::VPCEndpointService');\n  /** EC2 VPC peering connection */\n  public static readonly EC2_VPC_PEERING_CONNECTION = new ResourceType('AWS::EC2::VPCPeeringConnection');\n  /** EC2 registered HA instance */\n  public static readonly EC2_REGISTERED_HA_INSTANCE = new ResourceType('AWS::EC2::RegisteredHAInstance');\n  /** EC2 launch template */\n  public static readonly EC2_LAUNCH_TEMPLATE = new ResourceType('AWS::EC2::LaunchTemplate');\n  /** EC2 Network Insights Access Scope Analysis */\n  public static readonly EC2_NETWORK_INSIGHTS_ACCESS_SCOPE_ANALYSIS = new ResourceType('AWS::EC2::NetworkInsightsAccessScopeAnalysis');\n  /** EC2 Image Builder ContainerRecipe */\n  public static readonly IMAGEBUILDER_CONTAINER_RECIPE = new ResourceType('AWS::ImageBuilder::ContainerRecipe');\n  /** EC2 Image Builder DistributionConfiguration */\n  public static readonly IMAGEBUILDER_DISTRIBUTION_CONFIGURATION = new ResourceType('AWS::ImageBuilder::DistributionConfiguration');\n  /** EC2 Image Builder InfrastructureConfiguration */\n  public static readonly IMAGEBUILDER_INFRASTRUCTURE_CONFIGURATION = new ResourceType('AWS::ImageBuilder::InfrastructureConfiguration');\n  /** Amazon ECR repository */\n  public static readonly ECR_REPOSITORY = new ResourceType('AWS::ECR::Repository');\n  /** Amazon ECR registry policy */\n  public static readonly ECR_REGISTRY_POLICY = new ResourceType('AWS::ECR::RegistryPolicy');\n  /** Amazon ECR public repository */\n  public static readonly ECR_PUBLIC_REPOSITORY = new ResourceType('AWS::ECR::PublicRepository');\n  /** Amazon ECS cluster */\n  public static readonly ECS_CLUSTER = new ResourceType('AWS::ECS::Cluster');\n  /** Amazon ECS task definition */\n  public static readonly ECS_TASK_DEFINITION = new ResourceType('AWS::ECS::TaskDefinition');\n  /** Amazon ECS service */\n  public static readonly ECS_SERVICE = new ResourceType('AWS::ECS::Service');\n  /** Amazon EFS file system */\n  public static readonly EFS_FILE_SYSTEM = new ResourceType('AWS::EFS::FileSystem');\n  /** Amazon EFS access point */\n  public static readonly EFS_ACCESS_POINT = new ResourceType('AWS::EFS::AccessPoint');\n  /** Amazon Elastic Kubernetes Service cluster */\n  public static readonly EKS_CLUSTER = new ResourceType('AWS::EKS::Cluster');\n  /** Amazon Elastic Kubernetes Service identity provider config */\n  public static readonly EKS_IDENTITY_PROVIDER_CONFIG = new ResourceType('AWS::EKS::IdentityProviderConfig');\n  /** Amazon Elastic Kubernetes Service addon */\n  public static readonly EKS_ADDON = new ResourceType('AWS::EKS::Addon');\n  /** Amazon EMR security configuration */\n  public static readonly EMR_SECURITY_CONFIGURATION = new ResourceType('AWS::EMR::SecurityConfiguration');\n  /** Amazon EventBridge EventBus */\n  public static readonly EVENTBRIDGE_EVENTBUS = new ResourceType('AWS::Events::EventBus');\n  /** Amazon EventBridge Api Destination */\n  public static readonly EVENTBRIDGE_API_DESTINATION = new ResourceType('AWS::Events::ApiDestination');\n  /** Amazon EventBridge Archive */\n  public static readonly EVENTBRIDGE_ARCHIVE = new ResourceType('AWS::Events::Archive');\n  /** Amazon EventBridge Endpoint */\n  public static readonly EVENTBRIDGE_ENDPOINT = new ResourceType('AWS::Events::Endpoint');\n  /** Amazon EventBridge EventSchemas registry */\n  public static readonly EVENTSCHEMAS_REGISTRY = new ResourceType('AWS::EventSchemas::Registry');\n  /** Amazon EventBridge EventSchemas registry policy */\n  public static readonly EVENTSCHEMAS_REGISTRY_POLICY = new ResourceType('AWS::EventSchemas::RegistryPolicy');\n  /** Amazon EventBridge EventSchemas discoverer */\n  public static readonly EVENTSCHEMAS_DISCOVERER = new ResourceType('AWS::EventSchemas::Discoverer');\n  /** AWS FraudDetector label */\n  public static readonly FRAUDDETECTOR_LABEL = new ResourceType('AWS::FraudDetector::Label');\n  /** AWS FraudDetector entity type */\n  public static readonly FRAUDDETECTOR_ENTITY_TYPE = new ResourceType('AWS::FraudDetector::EntityType');\n  /** AWS FraudDetector variable */\n  public static readonly FRAUDDETECTOR_VARIABLE = new ResourceType('AWS::FraudDetector::Variable');\n  /** AWS FraudDetector outcome */\n  public static readonly FRAUDDETECTOR_OUTCOME = new ResourceType('AWS::FraudDetector::Outcome');\n  /** Amazon GuardDuty detector */\n  public static readonly GUARDDUTY_DETECTOR = new ResourceType('AWS::GuardDuty::Detector');\n  /** Amazon GuardDuty Threat Intel Set */\n  public static readonly GUARDDUTY_THREAT_INTEL_SET = new ResourceType('AWS::GuardDuty::ThreatIntelSet');\n  /** Amazon GuardDuty IP Set */\n  public static readonly GUARDDUTY_IP_SET = new ResourceType(' AWS::GuardDuty::IPSet');\n  /** Amazon GuardDuty Filter */\n  public static readonly GUARDDUTY_FILTER = new ResourceType('AWS::GuardDuty::Filter');\n  /** Amazon ElasticSearch domain */\n  public static readonly ELASTICSEARCH_DOMAIN = new ResourceType('AWS::Elasticsearch::Domain');\n  /** Amazon Interactive Video Service (IVS) channel */\n  public static readonly IVS_CHANNEL = new ResourceType('AWS::IVS::Channel');\n  /** Amazon Interactive Video Service (IVS) recording configuration */\n  public static readonly IVS_RECORDING_CONFIGURATION = new ResourceType('AWS::IVS::RecordingConfiguration');\n  /** Amazon Interactive Video Service (IVS) playback key pair */\n  public static readonly IVS_PLAYBACK_KEYPAIR = new ResourceType('AWS::IVS::PlaybackKeyPair');\n  /** Amazon OpenSearch domain */\n  public static readonly OPENSEARCH_DOMAIN = new ResourceType('AWS::OpenSearch::Domain');\n  /** Amazon QLDB ledger */\n  public static readonly QLDB_LEDGER = new ResourceType('AWS::QLDB::Ledger');\n  /** Amazon Kinesis stream */\n  public static readonly KINESIS_STREAM = new ResourceType('AWS::Kinesis::Stream');\n  /** Amazon Kinesis stream consumer */\n  public static readonly KINESIS_STREAM_CONSUMER = new ResourceType('AWS::Kinesis::StreamConsumer');\n  /** Amazon Kinesis Analytics V2 application */\n  public static readonly KINESIS_ANALYTICS_V2_APPLICATION = new ResourceType('AWS::KinesisAnalyticsV2::Application');\n  /** Amazon Lightsail Certificate */\n  public static readonly LIGHTSAIL_CERTIFICATE = new ResourceType('AWS::Lightsail::Certificate');\n  /** Amazon Lightsail Disk */\n  public static readonly LIGHTSAIL_DISK = new ResourceType('AWS::Lightsail::Disk');\n  /** AWS Lightsail bucket */\n  public static readonly LIGHTSAIL_BUCKET = new ResourceType('AWS::Lightsail::Bucket');\n  /** AWS Lightsail static IP */\n  public static readonly LIGHTSAIL_STATIC_IP = new ResourceType('AWS::Lightsail::StaticIp');\n  /** Amazon MQ broker */\n  public static readonly AMAZON_MQ_BROKER = new ResourceType('AWS::AmazonMQ::Broker');\n  /** Amazon MSK cluster */\n  public static readonly MSK_CLUSTER = new ResourceType('AWS::MSK::Cluster');\n  /** Amazon Redshift cluster */\n  public static readonly REDSHIFT_CLUSTER = new ResourceType('AWS::Redshift::Cluster');\n  /** Amazon Redshift cluster parameter group */\n  public static readonly REDSHIFT_CLUSTER_PARAMETER_GROUP = new ResourceType('AWS::Redshift::ClusterParameterGroup');\n  /** Amazon Redshift cluster security group */\n  public static readonly REDSHIFT_CLUSTER_SECURITY_GROUP = new ResourceType('AWS::Redshift::ClusterSecurityGroup');\n  /** Amazon Redshift cluster snapshot */\n  public static readonly REDSHIFT_CLUSTER_SNAPSHOT = new ResourceType('AWS::Redshift::ClusterSnapshot');\n  /** Amazon Redshift cluster subnet group */\n  public static readonly REDSHIFT_CLUSTER_SUBNET_GROUP = new ResourceType('AWS::Redshift::ClusterSubnetGroup');\n  /** Amazon Redshift event subscription */\n  public static readonly REDSHIFT_EVENT_SUBSCRIPTION = new ResourceType('AWS::Redshift::EventSubscription');\n  /** Amazon RDS database instance */\n  public static readonly RDS_DB_INSTANCE = new ResourceType('AWS::RDS::DBInstance');\n  /** Amazon RDS database security group */\n  public static readonly RDS_DB_SECURITY_GROUP = new ResourceType('AWS::RDS::DBSecurityGroup');\n  /** Amazon RDS database snapshot */\n  public static readonly RDS_DB_SNAPSHOT = new ResourceType('AWS::RDS::DBSnapshot');\n  /** Amazon RDS database subnet group */\n  public static readonly RDS_DB_SUBNET_GROUP = new ResourceType('AWS::RDS::DBSubnetGroup');\n  /** Amazon RDS event subscription */\n  public static readonly RDS_EVENT_SUBSCRIPTION = new ResourceType('AWS::RDS::EventSubscription');\n  /** Amazon RDS database cluster */\n  public static readonly RDS_DB_CLUSTER = new ResourceType('AWS::RDS::DBCluster');\n  /** Amazon RDS database cluster snapshot */\n  public static readonly RDS_DB_CLUSTER_SNAPSHOT = new ResourceType('AWS::RDS::DBClusterSnapshot');\n  /** Amazon RDS global cluster */\n  public static readonly RDS_GLOBAL_CLUSTER = new ResourceType('AWS::RDS::GlobalCluster');\n  /** Amazon Route53 Hosted Zone */\n  public static readonly ROUTE53_HOSTED_ZONE = new ResourceType('AWS::Route53::HostedZone');\n  /** Amazon Route53 Health Check */\n  public static readonly ROUTE53_HEALTH_CHECK = new ResourceType('AWS::Route53::HealthCheck');\n  /** Amazon Route53 resolver resolver endpoint */\n  public static readonly ROUTE53_RESOLVER_RESOLVER_ENDPOINT = new ResourceType('AWS::Route53Resolver::ResolverEndpoint');\n  /** Amazon Route53 resolver resolver rule */\n  public static readonly ROUTE53_RESOLVER_RESOLVER_RULE = new ResourceType('AWS::Route53Resolver::ResolverRule');\n  /** Amazon Route53 resolver resolver rule association */\n  public static readonly ROUTE53_RESOLVER_RESOLVER_RULE_ASSOCIATION = new ResourceType('AWS::Route53Resolver::ResolverRuleAssociation');\n  /** Amazon Route 53 Application Recovery Controller Cell */\n  public static readonly ROUTE53_RECOVERY_READINESS_CELL = new ResourceType('AWS::Route53RecoveryReadiness::Cell');\n  /** Amazon Route 53 Application Recovery Controller Readiness Check */\n  public static readonly ROUTE53_RECOVERY_READINESS_READINESS_CHECK = new ResourceType('AWS::Route53RecoveryReadiness::ReadinessCheck');\n  /** Amazon Route53 recovery readiness recovery group */\n  public static readonly ROUTE53_RECOVERY_READINESS_RECOVERY_GROUP = new ResourceType('AWS::Route53RecoveryReadiness::RecoveryGroup');\n  /** Amazon SQS queue */\n  public static readonly SQS_QUEUE = new ResourceType('AWS::SQS::Queue');\n  /** Amazon SNS topic */\n  public static readonly SNS_TOPIC = new ResourceType('AWS::SNS::Topic');\n  /** Amazon S3 bucket */\n  public static readonly S3_BUCKET = new ResourceType('AWS::S3::Bucket');\n  /** Amazon S3 Multi-Region Access Point */\n  public static readonly S3_MULTIREGION_ACCESS_POINT = new ResourceType('AWS::S3::MultiRegionAccessPoint');\n  /** Amazon SageMaker code repository */\n  public static readonly SAGEMAKER_CODE_REPOSITORY = new ResourceType('AWS::SageMaker::CodeRepository');\n  /** Amazon SageMaker model */\n  public static readonly SAGEMAKER_MODEL = new ResourceType('AWS::SageMaker::Model');\n  /** Amazon SageMaker notebook instance */\n  public static readonly SAGEMAKER_NOTEBOOK_INSTANCE = new ResourceType('AWS::SageMaker::NotebookInstance');\n  /** Amazon SageMaker workteam */\n  public static readonly SAGEMAKER_WORKTEAM = new ResourceType('AWS::SageMaker::Workteam');\n  /** Amazon SES Configuration Set */\n  public static readonly SES_CONFIGURATION_SET = new ResourceType('AWS::SES::ConfigurationSet');\n  /** Amazon SES Contact List */\n  public static readonly SES_CONTACT_LIST = new ResourceType('AWS::SES::ContactList');\n  /** Amazon SES Template */\n  public static readonly SES_TEMPLATE = new ResourceType('AWS::SES::Template');\n  /** Amazon SES ReceiptFilter */\n  public static readonly SES_RECEIPT_FILTER = new ResourceType('AWS::SES::ReceiptFilter');\n  /** Amazon SES ReceiptRuleSet */\n  public static readonly SES_RECEIPT_RECEIPT_RULE_SET = new ResourceType('AWS::SES::ReceiptRuleSet');\n  /** Amazon S3 account public access block */\n  public static readonly S3_ACCOUNT_PUBLIC_ACCESS_BLOCK = new ResourceType('AWS::S3::AccountPublicAccessBlock');\n  /** Amazon EC2 customer gateway */\n  public static readonly EC2_CUSTOMER_GATEWAY = new ResourceType('AWS::EC2::CustomerGateway');\n  /** Amazon EC2 internet gateway */\n  public static readonly EC2_INTERNET_GATEWAY = new ResourceType('AWS::EC2::InternetGateway');\n  /** Amazon EC2 network ACL */\n  public static readonly EC2_NETWORK_ACL = new ResourceType('AWS::EC2::NetworkAcl');\n  /** Amazon EC2 route table */\n  public static readonly EC2_ROUTE_TABLE = new ResourceType('AWS::EC2::RouteTable');\n  /** Amazon EC2 subnet table */\n  public static readonly EC2_SUBNET = new ResourceType('AWS::EC2::Subnet');\n  /** Amazon EC2 VPC */\n  public static readonly EC2_VPC = new ResourceType('AWS::EC2::VPC');\n  /** Amazon EC2 VPN connection */\n  public static readonly EC2_VPN_CONNECTION = new ResourceType('AWS::EC2::VPNConnection');\n  /** Amazon EC2 VPN gateway */\n  public static readonly EC2_VPN_GATEWAY = new ResourceType('AWS::EC2::VPNGateway');\n  /** AWS Auto Scaling group */\n  public static readonly AUTO_SCALING_GROUP = new ResourceType('AWS::AutoScaling::AutoScalingGroup');\n  /** AWS Auto Scaling launch configuration */\n  public static readonly AUTO_SCALING_LAUNCH_CONFIGURATION = new ResourceType('AWS::AutoScaling::LaunchConfiguration');\n  /** AWS Auto Scaling policy */\n  public static readonly AUTO_SCALING_POLICY = new ResourceType('AWS::AutoScaling::ScalingPolicy');\n  /** AWS Auto Scaling scheduled action */\n  public static readonly AUTO_SCALING_SCHEDULED_ACTION = new ResourceType('AWS::AutoScaling::ScheduledAction');\n  /** Amazon WorkSpaces connection alias */\n  public static readonly WORKSPACES_CONNECTION_ALIAS = new ResourceType('AWS::WorkSpaces::ConnectionAlias');\n  /** Amazon WorkSpaces workSpace */\n  public static readonly WORKSPACES_WORKSPACE = new ResourceType('AWS::WorkSpaces::Workspace');\n  /** AWS AppConfig application */\n  public static readonly APPCONFIG_APPLICATION = new ResourceType('AWS::AppConfig::Application');\n  /** AWS AppConfig environment */\n  public static readonly APPCONFIG_ENVIRONMENT = new ResourceType('AWS::AppConfig::Environment');\n  /** AWS AppConfig configuration profile */\n  public static readonly APPCONFIG_CONFIGURATION_PROFILE = new ResourceType('AWS::AppConfig::ConfigurationProfile');\n  /** AWS AppSync GraphQL Api */\n  public static readonly APPSYNC_GRAPHQL_API = new ResourceType('AWS::AppSync::GraphQLApi');\n  /** AWS Backup backup plan */\n  public static readonly BACKUP_BACKUP_PLAN = new ResourceType('AWS::Backup::BackupPlan');\n  /** AWS Backup backup selection */\n  public static readonly BACKUP_BACKUP_SELECTION = new ResourceType('AWS::Backup::BackupSelection');\n  /** AWS Backup backup vault */\n  public static readonly BACKUP_BACKUP_VAULT = new ResourceType('AWS::Backup::BackupVault');\n  /** AWS Backup recovery point */\n  public static readonly BACKUP_RECOVERY_POINT = new ResourceType('AWS::Backup::RecoveryPoint');\n  /** AWS Backup report plan */\n  public static readonly BACKUP_REPORT_PLAN = new ResourceType('AWS::Backup::ReportPlan');\n  /** AWS Batch job queue */\n  public static readonly BATCH_JOB_QUEUE = new ResourceType('AWS::Batch::JobQueue');\n  /** AWS Batch compute environment */\n  public static readonly BATCH_COMPUTE_ENVIRONMENT = new ResourceType('AWS::Batch::ComputeEnvironment');\n  /** AWS Certificate manager certificate */\n  public static readonly ACM_CERTIFICATE = new ResourceType('AWS::ACM::Certificate');\n  /** AWS CloudFormation stack */\n  public static readonly CLOUDFORMATION_STACK = new ResourceType('AWS::CloudFormation::Stack');\n  /** AWS CloudTrail trail */\n  public static readonly CLOUDTRAIL_TRAIL = new ResourceType('AWS::CloudTrail::Trail');\n  /** AWS Cloud9 environment EC2 */\n  public static readonly CLOUD9_ENVIRONMENT_EC2 = new ResourceType('AWS::Cloud9::EnvironmentEC2');\n  /** AWS Cloud Map(ServiceDiscovery) service */\n  public static readonly SERVICEDISCOVERY_SERVICE = new ResourceType('AWS::ServiceDiscovery::Service');\n  /** AWS Cloud Map(ServiceDiscovery) Public Dns Namespace */\n  public static readonly SERVICEDISCOVERY_PUBLIC_DNS_NAMESPACE = new ResourceType('AWS::ServiceDiscovery::PublicDnsNamespace');\n  /** AWS Cloud Map(ServiceDiscovery) Http Namespace */\n  public static readonly SERVICEDISCOVERY_HTTP_NAMESPACE = new ResourceType('AWS::ServiceDiscovery::HttpNamespace');\n  /** AWS CodeBuild project */\n  public static readonly CODEBUILD_PROJECT = new ResourceType('AWS::CodeBuild::Project');\n  /** AWS CodeDeploy application */\n  public static readonly CODEDEPLOY_APPLICATION = new ResourceType('AWS::CodeDeploy::Application');\n  /** AWS CodeDeploy deployment config */\n  public static readonly CODEDEPLOY_DEPLOYMENT_CONFIG = new ResourceType('AWS::CodeDeploy::DeploymentConfig');\n  /** AWS CodeDeploy deployment group */\n  public static readonly CODEDEPLOY_DEPLOYMENT_GROUP = new ResourceType('AWS::CodeDeploy::DeploymentGroup');\n  /** AWS CodePipeline pipeline */\n  public static readonly CODEPIPELINE_PIPELINE = new ResourceType('AWS::CodePipeline::Pipeline');\n  /** AWS Config resource compliance */\n  public static readonly CONFIG_RESOURCE_COMPLIANCE = new ResourceType('AWS::Config::ResourceCompliance');\n  /** AWS Config conformance pack compliance */\n  public static readonly CONFIG_CONFORMANCE_PACK_COMPLIANCE = new ResourceType('AWS::Config::ConformancePackCompliance');\n  /** AWS DMS event subscription */\n  public static readonly DMS_EVENT_SUBSCRIPTION = new ResourceType('AWS::DMS::EventSubscription');\n  /** AWS DMS replication subnet group */\n  public static readonly DMS_REPLICATION_SUBNET_GROUP = new ResourceType('AWS::DMS::ReplicationSubnetGroup');\n  /** AWS DataSync location SMB */\n  public static readonly DATASYNC_LOCATION_SMB = new ResourceType('AWS::DataSync::LocationSMB');\n  /** AWS DataSync location FSx Lustre */\n  public static readonly DATASYNC_LOCATION_FSX_LUSTRE = new ResourceType('AWS::DataSync::LocationFSxLustre');\n  /** AWS DataSync location FSx Windows */\n  public static readonly DATASYNC_LOCATION_FSX_WINDOWS = new ResourceType('AWS::DataSync::LocationFSxWindows');\n  /** AWS DataSync location S3 */\n  public static readonly DATASYNC_LOCATION_S3 = new ResourceType('AWS::DataSync::LocationS3');\n  /** AWS DataSync location EFS */\n  public static readonly DATASYNC_LOCATION_EFS = new ResourceType('AWS::DataSync::LocationEFS');\n  /** AWS DataSync task */\n  public static readonly DATASYNC_TASK = new ResourceType('AWS::DataSync::Task');\n  /** AWS DataSync location NFS */\n  public static readonly DATASYNC_LOCATION_NFS = new ResourceType('AWS::DataSync::LocationNFS');\n  /** AWS DataSync location object storage */\n  public static readonly DATASYNC_LOCATION_OBJECT_STORAGE = new ResourceType('AWS::DataSync::LocationObjectStorage');\n  /** AWS DataSync location HDFS */\n  public static readonly DATASYNC_LOCATION_HDFS = new ResourceType('AWS::DataSync::LocationHDFS');\n  /** AWS Elastic Beanstalk (EB) application */\n  public static readonly ELASTIC_BEANSTALK_APPLICATION = new ResourceType('AWS::ElasticBeanstalk::Application');\n  /** AWS Elastic Beanstalk (EB) application version */\n  public static readonly ELASTIC_BEANSTALK_APPLICATION_VERSION = new ResourceType('AWS::ElasticBeanstalk::ApplicationVersion');\n  /** AWS Elastic Beanstalk (EB) environment */\n  public static readonly ELASTIC_BEANSTALK_ENVIRONMENT = new ResourceType('AWS::ElasticBeanstalk::Environment');\n  /** AWS Fault Injection Simulator Experiment_Template */\n  public static readonly FIS_EXPERIMENT_TEMPLATE = new ResourceType('AWS::FIS::ExperimentTemplate');\n  /** AWS GlobalAccelerator listener */\n  public static readonly GLOBALACCELERATOR_LISTENER = new ResourceType('AWS::GlobalAccelerator::Listener');\n  /** AWS GlobalAccelerator endpoint group */\n  public static readonly GLOBALACCELERATOR_ENDPOINT_GROUP = new ResourceType('AWS::GlobalAccelerator::EndpointGroup');\n  /** AWS GlobalAccelerator accelerator */\n  public static readonly GLOBALACCELERATOR_ACCELERATOR = new ResourceType('AWS::GlobalAccelerator::Accelerator');\n  /** AWS Glue Job */\n  public static readonly GLUE_JOB = new ResourceType('AWS::Glue::Job');\n  /** AWS Glue Classifier */\n  public static readonly GLUE_CLASSIFIER = new ResourceType('AWS::Glue::Classifier');\n  /** AWS Glue machine learning transform */\n  public static readonly GLUE_ML_TRANSFORM = new ResourceType('AWS::Glue::MLTransform');\n  /** AWS IAM user */\n  public static readonly IAM_USER = new ResourceType('AWS::IAM::User');\n  /** AWS IAM group */\n  public static readonly IAM_GROUP = new ResourceType('AWS::IAM::Group');\n  /** AWS IAM role */\n  public static readonly IAM_ROLE = new ResourceType('AWS::IAM::Role');\n  /** AWS IAM policy */\n  public static readonly IAM_POLICY = new ResourceType('AWS::IAM::Policy');\n  /** AWS IAM AccessAnalyzer analyzer */\n  public static readonly IAM_ACCESSANALYZER_ANALYZER = new ResourceType('AWS::AccessAnalyzer::Analyzer');\n  /** AWS IoT authorizer */\n  public static readonly IOT_AUTHORIZER = new ResourceType('AWS::IoT::Authorizer');\n  /** AWS IoT security profile */\n  public static readonly IOT_SECURITY_PROFILE = new ResourceType('AWS::IoT::SecurityProfile');\n  /** AWS IoT role alias */\n  public static readonly IOT_ROLE_ALIAS = new ResourceType('AWS::IoT::RoleAlias');\n  /** AWS IoT dimension */\n  public static readonly IOT_DIMENSION = new ResourceType('AWS::IoT::Dimension');\n  /** AWS IoT policy */\n  public static readonly IOT_POLICY = new ResourceType('AWS::IoT::Policy');\n  /** AWS IoT mitigation action */\n  public static readonly IOT_MITIGATION_ACTION = new ResourceType('AWS::IoT::MitigationAction');\n  /** AWS IoT TwinMaker workspace */\n  public static readonly IOT_TWINMAKER_WORKSPACE = new ResourceType('AWS::IoTTwinMaker::Workspace');\n  /** AWS IoT TwinMaker entity */\n  public static readonly IOT_TWINMAKER_ENTITY = new ResourceType('AWS::IoTTwinMaker::Entity');\n  /** AWS IoT Analytics datastore */\n  public static readonly IOT_ANALYTICS_DATASTORE = new ResourceType('AWS::IoTAnalytics::Datastore');\n  /** AWS IoT Analytics dataset */\n  public static readonly IOT_ANALYTICS_DATASET = new ResourceType('AWS::IoTAnalytics::Dataset');\n  /** AWS IoT Analytics pipeline */\n  public static readonly IOT_ANALYTICS_PIPELINE = new ResourceType('AWS::IoTAnalytics::Pipeline');\n  /** AWS IoT Analytics channel */\n  public static readonly IOT_ANALYTICS_CHANNEL = new ResourceType('AWS::IoTAnalytics::Channel');\n  /** AWS IoT Events Input */\n  public static readonly IOT_EVENTS_INPUT = new ResourceType('AWS::IoTEvents::Input');\n  /** AWS IoT Events Detector Model */\n  public static readonly IOT_EVENTS_DETECTOR_MODEL = new ResourceType('AWS::IoTEvents::DetectorModel');\n  /** AWS IoT Events Alarm Model */\n  public static readonly IOT_EVENTS_ALARM_MODEL = new ResourceType('AWS::IoTEvents::AlarmModel');\n  /** AWS IoT SiteWise dashboard */\n  public static readonly IOT_SITEWISE_DASHBOARD = new ResourceType('AWS::IoTSiteWise::Dashboard');\n  /** AWS IoT SiteWise project */\n  public static readonly IOT_SITEWISE_PROJECT = new ResourceType('AWS::IoTSiteWise::Project');\n  /** AWS IoT SiteWise portal */\n  public static readonly IOT_SITEWISE_PORTAL = new ResourceType('AWS::IoTSiteWise::Portal');\n  /** AWS IoT SiteWise asset model */\n  public static readonly IOT_SITEWISE_ASSETMODEL = new ResourceType('AWS::IoTSiteWise::AssetModel');\n  /** AWS KMS Key */\n  public static readonly KMS_KEY = new ResourceType('AWS::KMS::Key');\n  /** AWS Lambda function */\n  public static readonly LAMBDA_FUNCTION = new ResourceType('AWS::Lambda::Function');\n  /** AWS Network Firewall Firewall */\n  public static readonly NETWORK_FIREWALL_FIREWALL = new ResourceType('AWS::NetworkFirewall::Firewall');\n  /** AWS Network Firewall Firewall Policy */\n  public static readonly NETWORK_FIREWALL_FIREWALL_POLICY = new ResourceType('AWS::NetworkFirewall::FirewallPolicy');\n  /** AWS Network Firewall Rule Group */\n  public static readonly NETWORK_FIREWALL_RULE_GROUP = new ResourceType('AWS::NetworkFirewall::RuleGroup');\n  /** AWS ResilienceHub resiliency policy */\n  public static readonly RESILIENCEHUB_RESILIENCY_POLICY = new ResourceType('AWS::ResilienceHub::ResiliencyPolicy');\n  /** AWS Secrets Manager secret */\n  public static readonly SECRETS_MANAGER_SECRET = new ResourceType('AWS::SecretsManager::Secret');\n  /** AWS Service Catalog CloudFormation product */\n  public static readonly SERVICE_CATALOG_CLOUDFORMATION_PRODUCT = new ResourceType('AWS::ServiceCatalog::CloudFormationProduct');\n  /** AWS Service Catalog CloudFormation provisioned product */\n  public static readonly SERVICE_CATALOG_CLOUDFORMATION_PROVISIONED_PRODUCT = new ResourceType(\n    'AWS::ServiceCatalog::CloudFormationProvisionedProduct');\n  /** AWS Service Catalog portfolio */\n  public static readonly SERVICE_CATALOG_PORTFOLIO = new ResourceType('AWS::ServiceCatalog::Portfolio');\n  /** AWS Shield protection */\n  public static readonly SHIELD_PROTECTION = new ResourceType('AWS::Shield::Protection');\n  /** AWS Shield regional protection */\n  public static readonly SHIELD_REGIONAL_PROTECTION = new ResourceType('AWS::ShieldRegional::Protection');\n  /** AWS StepFunctions activity */\n  public static readonly STEPFUNCTIONS_ACTIVITY = new ResourceType('AWS::StepFunctions::Activity');\n  /** AWS StepFunctions state machine */\n  public static readonly STEPFUNCTIONS_STATE_MACHINE = new ResourceType('AWS::StepFunctions::StateMachine');\n  /** AWS Systems Manager managed instance inventory */\n  public static readonly SYSTEMS_MANAGER_MANAGED_INSTANCE_INVENTORY = new ResourceType('AWS::SSM::ManagedInstanceInventory');\n  /** AWS Systems Manager patch compliance */\n  public static readonly SYSTEMS_MANAGER_PATCH_COMPLIANCE = new ResourceType('AWS::SSM::PatchCompliance');\n  /** AWS Systems Manager association compliance */\n  public static readonly SYSTEMS_MANAGER_ASSOCIATION_COMPLIANCE = new ResourceType('AWS::SSM::AssociationCompliance');\n  /** AWS Systems Manager file data */\n  public static readonly SYSTEMS_MANAGER_FILE_DATA = new ResourceType('AWS::SSM::FileData');\n  /** AWS Transfer workflow */\n  public static readonly TRANSFER_WORKFLOW = new ResourceType('AWS::Transfer::Workflow');\n  /** AWS WAF rate based rule */\n  public static readonly WAF_RATE_BASED_RULE = new ResourceType('AWS::WAF::RateBasedRule');\n  /** AWS WAF rule */\n  public static readonly WAF_RULE = new ResourceType('AWS::WAF::Rule');\n  /** AWS WAF web ACL */\n  public static readonly WAF_WEB_ACL = new ResourceType('AWS::WAF::WebACL');\n  /** AWS WAF rule group */\n  public static readonly WAF_RULE_GROUP = new ResourceType('AWS::WAF::RuleGroup');\n  /** AWS WAF regional rate based rule */\n  public static readonly WAF_REGIONAL_RATE_BASED_RULE = new ResourceType('AWS::WAFRegional::RateBasedRule');\n  /** AWS WAF regional rule */\n  public static readonly WAF_REGIONAL_RULE = new ResourceType('AWS::WAFRegional::Rule');\n  /** AWS WAF web ACL */\n  public static readonly WAF_REGIONAL_WEB_ACL = new ResourceType('AWS::WAFRegional::WebACL');\n  /** AWS WAF regional rule group */\n  public static readonly WAF_REGIONAL_RULE_GROUP = new ResourceType('AWS::WAFRegional::RuleGroup');\n  /** AWS WAFv2 web ACL */\n  public static readonly WAFV2_WEB_ACL = new ResourceType('AWS::WAFv2::WebACL');\n  /** AWS WAFv2 rule group */\n  public static readonly WAFV2_RULE_GROUP = new ResourceType('AWS::WAFv2::RuleGroup');\n  /** AWS WAFv2 managed rule set */\n  public static readonly WAFV2_MANAGED_RULE_SET = new ResourceType('AWS::WAFv2::ManagedRuleSet');\n  /** AWS WAFv2 ip set */\n  public static readonly WAFV2_IP_SET = new ResourceType('AWS::WAFv2::IPSet');\n  /** AWS WAFv2 regex pattern set */\n  public static readonly WAFV2_REGEX_PATTERN_SET = new ResourceType('AWS::WAFv2::RegexPatternSet');\n  /** AWS X-Ray encryption configuration */\n  public static readonly XRAY_ENCRYPTION_CONFIGURATION = new ResourceType('AWS::XRay::EncryptionConfig');\n  /** AWS ELB classic load balancer */\n  public static readonly ELB_LOAD_BALANCER = new ResourceType('AWS::ElasticLoadBalancing::LoadBalancer');\n  /** AWS ELBv2 network load balancer or AWS ELBv2 application load balancer */\n  public static readonly ELBV2_LOAD_BALANCER = new ResourceType('AWS::ElasticLoadBalancingV2::LoadBalancer');\n  /** AWS ELBv2 application load balancer listener */\n  public static readonly ELBV2_LISTENER = new ResourceType('AWS::ElasticLoadBalancingV2::Listener');\n  /** AWS Elemental MediaPackage packaging group */\n  public static readonly MEDIAPACKAGE_PACKAGING_GROUP = new ResourceType('AWS::MediaPackage::PackagingGroup');\n  /** AWS Device Farm Test Grid Project */\n  public static readonly DEVICE_FARM_TEST_GRID_PROJECT = new ResourceType('AWS::DeviceFarm::TestGridProject');\n  /** AWS Budgets Budgets Action */\n  public static readonly BUDGETS_BUDGETS_ACTION = new ResourceType('AWS::Budgets::BudgetsAction');\n  /** Amazon Lex Bot */\n  public static readonly LEX_BOT = new ResourceType('AWS::Lex::Bot');\n  /** Amazon Lex Bot Alias */\n  public static readonly LEX_BOT_ALIAS = new ResourceType('AWS::Lex::BotAlias');\n  /** Amazon CodeGuru Reviewer Repository Association */\n  public static readonly CODE_GURU_REVIEWER_REPOSITORY_ASSOCIATION = new ResourceType('AWS::CodeGuruReviewer::RepositoryAssociation');\n  /** AWS IoT Custom Metric */\n  public static readonly IOT_CUSTOM_METRIC = new ResourceType('AWS::IoT::CustomMetric');\n  /** AWS IoT Account Audit Configuration */\n  public static readonly IOT_ACCOUNT_AUDIT_CONFIGURATION = new ResourceType('AWS::IoT::AccountAuditConfiguration');\n  /** AWS IoT Scheduled Audit */\n  public static readonly IOT_SCHEDULED_AUDIT = new ResourceType('AWS::IoT::ScheduledAudit');\n  /** Amazon Route53 Resolver Firewall Domain List */\n  public static readonly ROUTE53_RESOLVER_FIREWALL_DOMAIN_LIST = new ResourceType('AWS::Route53Resolver::FirewallDomainList');\n  /** AWS RoboMaker Robot Application Version */\n  public static readonly ROBO_MAKER_ROBOT_APPLICATION_VERSION = new ResourceType('AWS::RoboMaker::RobotApplicationVersion');\n  /** EC2 Traffic Mirror Session */\n  public static readonly EC2_TRAFFIC_MIRROR_SESSION = new ResourceType('AWS::EC2::TrafficMirrorSession');\n  /** EC2 Traffic Mirror Target */\n  public static readonly EC2_TRAFFIC_MIRROR_TARGET = new ResourceType('AWS::EC2::TrafficMirrorTarget');\n  /** AWS IoT SiteWise Gateway */\n  public static readonly IOT_SITEWISE_GATEWAY = new ResourceType('AWS::IoTSiteWise::Gateway');\n  /** AWS Lookout Metrics Alert */\n  public static readonly LOOKOUT_METRICS_ALERT = new ResourceType('AWS::LookoutMetrics::Alert');\n  /** Amazon S3 Storage Lens */\n  public static readonly S3_STORAGE_LENS = new ResourceType('AWS::S3::StorageLens');\n  /** Amazon EventBridge Connection */\n  public static readonly EVENTS_CONNECTION = new ResourceType('AWS::Events::Connection');\n  /** Amazon EventBridge Schemas Schema */\n  public static readonly EVENT_SCHEMAS_SCHEMA = new ResourceType('AWS::EventSchemas::Schema');\n  /** AWS Elemental MediaPackage Packaging Configuration */\n  public static readonly MEDIA_PACKAGE_PACKAGING_CONFIGURATION = new ResourceType('AWS::MediaPackage::PackagingConfiguration');\n  /** Amazon AppStream Directory Config */\n  public static readonly APP_STREAM_DIRECTORY_CONFIG = new ResourceType('AWS::AppStream::DirectoryConfig');\n  /** EC2 Auto Scaling Warm Pool */\n  public static readonly AUTO_SCALING_WARM_POOL = new ResourceType('AWS::AutoScaling::WarmPool');\n  /** Amazon Connect Phone Number */\n  public static readonly CONNECT_PHONE_NUMBER = new ResourceType('AWS::Connect::PhoneNumber');\n  /** Amazon Connect Customer Profiles Domain */\n  public static readonly CUSTOMER_PROFILES_DOMAIN = new ResourceType('AWS::CustomerProfiles::Domain');\n  /** EC2 DHCP Options */\n  public static readonly EC2_DHCP_OPTIONS = new ResourceType('AWS::EC2::DHCPOptions');\n  /** EC2 IPAM */\n  public static readonly EC2_IPAM = new ResourceType('AWS::EC2::IPAM');\n  /** EC2 Network Insights Path */\n  public static readonly EC2_NETWORK_INSIGHTS_PATH = new ResourceType('AWS::EC2::NetworkInsightsPath');\n  /** EC2 Traffic Mirror Filter */\n  public static readonly EC2_TRAFFIC_MIRROR_FILTER = new ResourceType('AWS::EC2::TrafficMirrorFilter');\n  /** Amazon EventBridge Events Rule */\n  public static readonly EVENTS_RULE = new ResourceType('AWS::Events::Rule');\n  /** AWS HealthLake FHIR Datastore */\n  public static readonly HEALTH_LAKE_FHIR_DATASTORE = new ResourceType('AWS::HealthLake::FHIRDatastore');\n  /** AWS IoT Twin Maker Scene */\n  public static readonly IOT_TWIN_MAKER_SCENE = new ResourceType('AWS::IoTTwinMaker::Scene');\n  /** Amazon Kinesis Video Streams Signaling Channel */\n  public static readonly KINESIS_VIDEO_SIGNALING_CHANNEL = new ResourceType('AWS::KinesisVideo::SignalingChannel');\n  /** Amazon Lookout Vision Project */\n  public static readonly LOOKOUT_VISION_PROJECT = new ResourceType('AWS::LookoutVision::Project');\n  /** AWS Network Manager Transit Gateway Registration */\n  public static readonly NETWORK_MANAGER_TRANSIT_GATEWAY_REGISTRATION = new ResourceType('AWS::NetworkManager::TransitGatewayRegistration');\n  /** Amazon Pinpoint Application Settings */\n  public static readonly PINPOINT_APPLICATION_SETTINGS = new ResourceType('AWS::Pinpoint::ApplicationSettings');\n  /** Amazon Pinpoint Segment */\n  public static readonly PINPOINT_SEGMENT = new ResourceType('AWS::Pinpoint::Segment');\n  /** AWS RoboMaker Robot Application */\n  public static readonly ROBO_MAKER_ROBOT_APPLICATION = new ResourceType('AWS::RoboMaker::RobotApplication');\n  /** AWS RoboMaker Simulation Application */\n  public static readonly ROBO_MAKER_SIMULATION_APPLICATION = new ResourceType('AWS::RoboMaker::SimulationApplication');\n  /** Amazon Route53 Recovery Control Cluster */\n  public static readonly ROUTE53_RECOVERY_CONTROL_CLUSTER = new ResourceType('AWS::Route53RecoveryControl::Cluster');\n  /** Amazon Route53 Recovery Control Control Panel */\n  public static readonly ROUTE53_RECOVERY_CONTROL_CONTROL_PANEL = new ResourceType('AWS::Route53RecoveryControl::ControlPanel');\n  /** Amazon Route53 Recovery Control Routing Control */\n  public static readonly ROUTE53_RECOVERY_CONTROL_ROUTING_CONTROL = new ResourceType('AWS::Route53RecoveryControl::RoutingControl');\n  /** Amazon Route53 Recovery Control Safety Rule */\n  public static readonly ROUTE53_RECOVERY_CONTROL_SAFETY_RULE = new ResourceType('AWS::Route53RecoveryControl::SafetyRule');\n  /** Amazon Route53 Recovery Readiness Resource Set */\n  public static readonly ROUTE53_RECOVERY_READINESS_RESOURCE_SET = new ResourceType('AWS::Route53RecoveryReadiness::ResourceSet');\n  /** Amazon Route53 Resolver Firewall Rule Group Association */\n  public static readonly ROUTE53_RESOLVER_FIREWALL_RULE_GROUP_ASSOCIATION = new ResourceType('AWS::Route53Resolver::FirewallRuleGroupAssociation');\n  /** EC2 EC2 Fleet */\n  public static readonly EC2_EC2_FLEET = new ResourceType('AWS::EC2::EC2Fleet');\n  /** AWS IoTWireless Service Profile */\n  public static readonly IOT_WIRELESS_SERVICE_PROFILE = new ResourceType('AWS::IoTWireless::ServiceProfile');\n  /** EC2 Subnet Route Table Association */\n  public static readonly EC2_SUBNET_ROUTE_TABLE_ASSOCIATION = new ResourceType('AWS::EC2::SubnetRouteTableAssociation');\n  /** AWS Network Manager Global Network */\n  public static readonly NETWORK_MANAGER_GLOBAL_NETWORK = new ResourceType('AWS::NetworkManager::GlobalNetwork');\n  /** AWS DeviceFarm Instance Profile */\n  public static readonly DEVICE_FARM_INSTANCE_PROFILE = new ResourceType('AWS::DeviceFarm::InstanceProfile');\n  /** AWS GroundStation Config */\n  public static readonly GROUND_STATION_CONFIG = new ResourceType('AWS::GroundStation::Config');\n  /** Amazon AppFlow Flow */\n  public static readonly APP_FLOW_FLOW = new ResourceType('AWS::AppFlow::Flow');\n  /** Amazon Redshift Scheduled Action */\n  public static readonly REDSHIFT_SCHEDULED_ACTION = new ResourceType('AWS::Redshift::ScheduledAction');\n  /** Amazon Pinpoint App */\n  public static readonly PINPOINT_APP = new ResourceType('AWS::Pinpoint::App');\n  /** AWS IoT Fleet Metric */\n  public static readonly IOT_FLEET_METRIC = new ResourceType('AWS::IoT::FleetMetric');\n  /** AWS AppConfig Deployment Strategy */\n  public static readonly APP_CONFIG_DEPLOYMENT_STRATEGY = new ResourceType('AWS::AppConfig::DeploymentStrategy');\n  /** AWS Network Manager Device */\n  public static readonly NETWORK_MANAGER_DEVICE = new ResourceType('AWS::NetworkManager::Device');\n  /** EC2 Image Builder Image Pipeline */\n  public static readonly IMAGE_BUILDER_IMAGE_PIPELINE = new ResourceType('AWS::ImageBuilder::ImagePipeline');\n  /** Amazon CloudWatch Metric Stream */\n  public static readonly CLOUD_WATCH_METRIC_STREAM = new ResourceType('AWS::CloudWatch::MetricStream');\n  /** AWS Panorama Package */\n  public static readonly PANORAMA_PACKAGE = new ResourceType('AWS::Panorama::Package');\n  /** Amazon SageMaker Image */\n  public static readonly SAGE_MAKER_IMAGE = new ResourceType('AWS::SageMaker::Image');\n  /** Amazon ECR PullThrough Cache Rule */\n  public static readonly ECR_PULL_THROUGH_CACHE_RULE = new ResourceType('AWS::ECR::PullThroughCacheRule');\n  /** AWS AuditManager Assessment */\n  public static readonly AUDIT_MANAGER_ASSESSMENT = new ResourceType('AWS::AuditManager::Assessment');\n  /** AWS NetworkManager Site */\n  public static readonly NETWORK_MANAGER_SITE = new ResourceType('AWS::NetworkManager::Site');\n  /** Amazon SageMaker AppImageConfig */\n  public static readonly SAGE_MAKER_APP_IMAGE_CONFIG = new ResourceType('AWS::SageMaker::AppImageConfig');\n  /** AWS DeviceFarm Project */\n  public static readonly DEVICE_FARM_PROJECT = new ResourceType('AWS::DeviceFarm::Project');\n  /** AWS NetworkManager Link */\n  public static readonly NETWORK_MANAGER_LINK = new ResourceType('AWS::NetworkManager::Link');\n  /** AWS NetworkFirewall TLSInspectionConfiguration */\n  public static readonly NETWORK_FIREWALL_TLS_INSPECTION_CONFIGURATION = new ResourceType('AWS::NetworkFirewall::TLSInspectionConfiguration');\n  /** AWS Amplify App */\n  public static readonly AMPLIFY_APP = new ResourceType('AWS::Amplify::App');\n  /** AWS AppMesh VirtualNode */\n  public static readonly APP_MESH_VIRTUAL_NODE = new ResourceType('AWS::AppMesh::VirtualNode');\n  /** AWS AppMesh VirtualService */\n  public static readonly APP_MESH_VIRTUAL_SERVICE = new ResourceType('AWS::AppMesh::VirtualService');\n  /** AWS AppRunner VpcConnector */\n  public static readonly APP_RUNNER_VPC_CONNECTOR = new ResourceType('AWS::AppRunner::VpcConnector');\n  /** Amazon AppStream Application */\n  public static readonly APP_STREAM_APPLICATION = new ResourceType('AWS::AppStream::Application');\n  /** Amazon KeySpaces Cassandra Keyspace */\n  public static readonly CASSANDRA_KEYSPACE = new ResourceType('AWS::Cassandra::Keyspace');\n  /** AWS CodeArtifact Repository */\n  public static readonly CODE_ARTIFACT_REPOSITORY = new ResourceType('AWS::CodeArtifact::Repository');\n  /** EC2 PrefixList */\n  public static readonly EC2_PREFIX_LIST = new ResourceType('AWS::EC2::PrefixList');\n  /** EC2 SpotFleet */\n  public static readonly EC2_SPOT_FLEET = new ResourceType('AWS::EC2::SpotFleet');\n  /** Amazon ECS TaskSet */\n  public static readonly ECS_TASK_SET = new ResourceType('AWS::ECS::TaskSet');\n  /** Amazon CloudWatch Evidently Project */\n  public static readonly EVIDENTLY_PROJECT = new ResourceType('AWS::Evidently::Project');\n  /** Amazon Forecast Dataset */\n  public static readonly FORECAST_DATASET = new ResourceType('AWS::Forecast::Dataset');\n  /** AWS IAM SAMLProvider */\n  public static readonly IAM_SAML_PROVIDER = new ResourceType('AWS::IAM::SAMLProvider');\n  /** AWS IAM ServerCertificate */\n  public static readonly IAM_SERVER_CERTIFICATE = new ResourceType('AWS::IAM::ServerCertificate');\n  /** Amazon Data Firehose DeliveryStream */\n  public static readonly KINESIS_FIREHOSE_DELIVERY_STREAM = new ResourceType('AWS::KinesisFirehose::DeliveryStream');\n  /** Amazon Pinpoint Campaign */\n  public static readonly PINPOINT_CAMPAIGN = new ResourceType('AWS::Pinpoint::Campaign');\n  /** Amazon Pinpoint InAppTemplate */\n  public static readonly PINPOINT_IN_APP_TEMPLATE = new ResourceType('AWS::Pinpoint::InAppTemplate');\n  /** AWS Signer SigningProfile */\n  public static readonly SIGNER_SIGNING_PROFILE = new ResourceType('AWS::Signer::SigningProfile');\n  /** Amazon SageMaker Domain */\n  public static readonly SAGEMAKER_DOMAIN = new ResourceType('AWS::SageMaker::Domain');\n  /** AWS Transfer Agreement */\n  public static readonly TRANSFER_AGREEMENT = new ResourceType('AWS::Transfer::Agreement');\n  /** AWS Transfer Connector */\n  public static readonly TRANSFER_CONNECTOR = new ResourceType('AWS::Transfer::Connector');\n  /** AWS Private Certificate Authority CertificateAuthority */\n  public static readonly ACMPCA_CERTIFICATE_AUTHORITY = new ResourceType('AWS::ACMPCA::CertificateAuthority');\n  /** AWS AppConfig HostedConfigurationVersion */\n  public static readonly APP_CONFIG_HOSTED_CONFIGURATION_VERSION = new ResourceType('AWS::AppConfig::HostedConfigurationVersion');\n  /** AWS AppMesh VirtualGateway */\n  public static readonly APP_MESH_VIRTUAL_GATEWAY = new ResourceType('AWS::AppMesh::VirtualGateway');\n  /** AWS AppMesh VirtualRouter */\n  public static readonly APP_MESH_VIRTUAL_ROUTER = new ResourceType('AWS::AppMesh::VirtualRouter');\n  /** AWS AppRunner Service */\n  public static readonly APP_RUNNER_SERVICE = new ResourceType('AWS::AppRunner::Service');\n  /** Amazon Connect CustomerProfiles ObjectType */\n  public static readonly CUSTOMER_PROFILES_OBJECT_TYPE = new ResourceType('AWS::CustomerProfiles::ObjectType');\n  /** AWS DMS Endpoint */\n  public static readonly DMS_ENDPOINT = new ResourceType('AWS::DMS::Endpoint');\n  /** EC2 CapacityReservation */\n  public static readonly EC2_CAPACITY_RESERVATION = new ResourceType('AWS::EC2::CapacityReservation');\n  /** EC2 ClientVpnEndpoint */\n  public static readonly EC2_CLIENT_VPN_ENDPOINT = new ResourceType('AWS::EC2::ClientVpnEndpoint');\n  /** Amazon Kendra Index */\n  public static readonly KENDRA_INDEX = new ResourceType('AWS::Kendra::Index');\n  /** Amazon Kinesis Video Stream */\n  public static readonly KINESIS_VIDEO_STREAM = new ResourceType('AWS::KinesisVideo::Stream');\n  /** Amazon CloudWatch Logs Destination */\n  public static readonly LOGS_DESTINATION = new ResourceType('AWS::Logs::Destination');\n  /** AWS NetworkManager CustomerGatewayAssociation */\n  public static readonly NETWORK_MANAGER_CUSTOMER_GATEWAY_ASSOCIATION = new ResourceType('AWS::NetworkManager::CustomerGatewayAssociation');\n  /** AWS NetworkManager LinkAssociation */\n  public static readonly NETWORK_MANAGER_LINK_ASSOCIATION = new ResourceType('AWS::NetworkManager::LinkAssociation');\n  /** Amazon Pinpoint EmailChannel */\n  public static readonly PINPOINT_EMAIL_CHANNEL = new ResourceType('AWS::Pinpoint::EmailChannel');\n  /** Amazon S3 AccessPoint */\n  public static readonly S3_ACCESS_POINT = new ResourceType('AWS::S3::AccessPoint');\n  /** AWS Amplify Branch */\n  public static readonly AMPLIFY_BRANCH = new ResourceType('AWS::Amplify::Branch');\n  /** Amazon AppIntegrations EventIntegration */\n  public static readonly APP_INTEGRATIONS_EVENT_INTEGRATION = new ResourceType('AWS::AppIntegrations::EventIntegration');\n  /** AWS AppMesh Route */\n  public static readonly APP_MESH_ROUTE = new ResourceType('AWS::AppMesh::Route');\n  /** Amazon Athena PreparedStatement */\n  public static readonly ATHENA_PREPARED_STATEMENT = new ResourceType('AWS::Athena::PreparedStatement');\n  /** EC2 IPAMScope */\n  public static readonly EC2_IPAM_SCOPE = new ResourceType('AWS::EC2::IPAMScope');\n  /** Amazon CloudWatch Evidently Launch */\n  public static readonly EVIDENTLY_LAUNCH = new ResourceType('AWS::Evidently::Launch');\n  /** Amazon Forecast DatasetGroup */\n  public static readonly FORECAST_DATASET_GROUP = new ResourceType('AWS::Forecast::DatasetGroup');\n  /** AWS IoT Greengrass Version2 ComponentVersion */\n  public static readonly GREENGRASSV2_COMPONENT_VERSION = new ResourceType('AWS::GreengrassV2::ComponentVersion');\n  /** AWS GroundStation MissionProfile */\n  public static readonly GROUNDSTATION_MISSION_PROFILE = new ResourceType('AWS::GroundStation::MissionProfile');\n  /** AWS Elemental MediaConnect FlowEntitlement */\n  public static readonly MEDIACONNECT_FLOW_ENTITLEMENT = new ResourceType('AWS::MediaConnect::FlowEntitlement');\n  /** AWS Elemental MediaConnect FlowVpcInterface */\n  public static readonly MEDIACONNECT_FLOW_VPC_INTERFACE = new ResourceType('AWS::MediaConnect::FlowVpcInterface');\n  /** AWS Elemental MediaTailor PlaybackConfiguration */\n  public static readonly MEDIATAILOR_PLAYBACK_CONFIGURATION = new ResourceType('AWS::MediaTailor::PlaybackConfiguration');\n  /** Amazon MSK Configuration */\n  public static readonly MSK_CONFIGURATION = new ResourceType('AWS::MSK::Configuration');\n  /** Amazon Personalize Dataset */\n  public static readonly PERSONALIZE_DATASET = new ResourceType('AWS::Personalize::Dataset');\n  /** Amazon Personalize Schema */\n  public static readonly PERSONALIZE_SCHEMA = new ResourceType('AWS::Personalize::Schema');\n  /** Amazon Personalize Solution */\n  public static readonly PERSONALIZE_SOLUTION = new ResourceType('AWS::Personalize::Solution');\n  /** Amazon Pinpoint EmailTemplate */\n  public static readonly PINPOINT_EMAIL_TEMPLATE = new ResourceType('AWS::Pinpoint::EmailTemplate');\n  /** Amazon Pinpoint EventStream */\n  public static readonly PINPOINT_EVENT_STREAM = new ResourceType('AWS::Pinpoint::EventStream');\n  /** AWS ResilienceHub App */\n  public static readonly RESILIENCEHUB_APP = new ResourceType('AWS::ResilienceHub::App');\n  /** Amazon CodeGuruP rofiler ProfilingGroup */\n  public static readonly CODE_GURU_PROFILER_PROFILING_GROUP = new ResourceType('AWS::CodeGuruProfiler::ProfilingGroup');\n  /** AWS Elemental MediaConnect FlowSource */\n  public static readonly MEDIA_CONNECT_FLOW_SOURCE = new ResourceType('AWS::MediaConnect::FlowSource');\n  /** AWS Transfer Family Certificate */\n  public static readonly TRANSFER_CERTIFICATE = new ResourceType('AWS::Transfer::Certificate');\n  /** Amazon Managed Service for Prometheus RuleGroupsNamespace */\n  public static readonly APS_RULE_GROUPS_NAMESPACE = new ResourceType('AWS::APS::RuleGroupsNamespace');\n  /** AWS Batch SchedulingPolicy */\n  public static readonly BATCH_SCHEDULING_POLICY = new ResourceType('AWS::Batch::SchedulingPolicy');\n  /** AWS Cloud Map Instance */\n  public static readonly SERVICE_DISCOVERY_INSTANCE = new ResourceType('AWS::ServiceDiscovery::Instance');\n  /** Amazon Route53 Resolver ResolverQueryLoggingConfig */\n  public static readonly ROUTE53_RESOLVER_QUERY_LOGGING_CONFIG = new ResourceType('AWS::Route53Resolver::ResolverQueryLoggingConfig');\n  /** Amazon Route53 Resolver ResolverQueryLoggingConfigAssociation */\n  public static readonly ROUTE53_RESOLVER_QUERY_LOGGING_CONFIG_ASSOCIATION = new ResourceType('AWS::Route53Resolver::ResolverQueryLoggingConfigAssociation');\n  /** AWS IoT JobTemplate */\n  public static readonly IOT_JOB_TEMPLATE = new ResourceType('AWS::IoT::JobTemplate');\n  /** AWS IoT TwinMaker ComponentType */\n  public static readonly IOT_TWIN_MAKER_COMPONENT_TYPE = new ResourceType('AWS::IoTTwinMaker::ComponentType');\n  /** AWS IoT Wireless MulticastGroup */\n  public static readonly IOT_WIRELESS_MULTICAST_GROUP = new ResourceType('AWS::IoTWireless::MulticastGroup');\n  /** Amazon Personalize DatasetGroup */\n  public static readonly PERSONALIZE_DATASET_GROUP = new ResourceType('AWS::Personalize::DatasetGroup');\n  /** AWS IoT ProvisioningTemplate */\n  public static readonly IOT_PROVISIONING_TEMPLATE = new ResourceType('AWS::IoT::ProvisioningTemplate');\n  /** AWS IoT Wireless FuotaTask */\n  public static readonly IOT_WIRELESS_FUOTA_TASK = new ResourceType('AWS::IoTWireless::FuotaTask');\n  /** Amazon MSK BatchScramSecret */\n  public static readonly MSK_BATCH_SCRAM_SECRET = new ResourceType('AWS::MSK::BatchScramSecret');\n  /** Amazon SageMaker FeatureGroup */\n  public static readonly SAGEMAKER_FEATURE_GROUP = new ResourceType('AWS::SageMaker::FeatureGroup');\n  /** AWS CodeBuild ReportGroup */\n  public static readonly CODE_BUILD_REPORT_GROUP = new ResourceType('AWS::CodeBuild::ReportGroup');\n  /** Amazon AppStream Stack */\n  public static readonly APP_STREAM_STACK = new ResourceType('AWS::AppStream::Stack');\n  /** Amazon Inspector Filter */\n  public static readonly INSPECTORV2_FILTER = new ResourceType('AWS::InspectorV2::Filter');\n  /** Amazon AppStream Fleet */\n  public static readonly APP_STREAM_FLEET = new ResourceType('AWS::AppStream::Fleet');\n  /** Amazon Managed Grafana Workspace */\n  public static readonly GRAFANA_WORKSPACE = new ResourceType('AWS::Grafana::Workspace');\n  /** AWS KMS Alias */\n  public static readonly KMS_ALIAS = new ResourceType('AWS::KMS::Alias');\n  /** Amazon RDS OptionGroup */\n  public static readonly RDS_OPTION_GROUP = new ResourceType('AWS::RDS::OptionGroup');\n  /** AWS Route53 Resolver FirewallRuleGroup */\n  public static readonly ROUTE53_RESOLVER_FIREWALL_RULE_GROUP = new ResourceType('AWS::Route53Resolver::FirewallRuleGroup');\n  /** AWS IAM InstanceProfile */\n  public static readonly IAM_INSTANCE_PROFILE = new ResourceType('AWS::IAM::InstanceProfile');\n  /** AWS NetworkManager ConnectPeer */\n  public static readonly NETWORK_MANAGER_CONNECT_PEER = new ResourceType('AWS::NetworkManager::ConnectPeer');\n  /** AWS Private Certificate Authority CertificateAuthorityActivation */\n  public static readonly ACMPCA_CERTIFICATE_AUTHORITY_ACTIVATION = new ResourceType('AWS::ACMPCA::CertificateAuthorityActivation');\n  /** AWS AppMesh GatewayRoute */\n  public static readonly APP_MESH_GATEWAY_ROUTE = new ResourceType('AWS::AppMesh::GatewayRoute');\n  /** AWS AppMesh Mesh */\n  public static readonly APP_MESH_MESH = new ResourceType('AWS::AppMesh::Mesh');\n  /** Amazon Connect QuickConnect */\n  public static readonly CONNECT_QUICK_CONNECT = new ResourceType('AWS::Connect::QuickConnect');\n  /** EC2 CarrierGateway */\n  public static readonly EC2_CARRIER_GATEWAY = new ResourceType('AWS::EC2::CarrierGateway');\n  /** EC2 TransitGatewayConnect */\n  public static readonly EC2_TRANSIT_GATEWAY_CONNECT = new ResourceType('AWS::EC2::TransitGatewayConnect');\n  /** Amazon ECS CapacityProvider */\n  public static readonly ECS_CAPACITY_PROVIDER = new ResourceType('AWS::ECS::CapacityProvider');\n  /** AWS IoT CACertificate */\n  public static readonly IOT_CA_CERTIFICATE = new ResourceType('AWS::IoT::CACertificate');\n  /** AWS IoT TwinMaker SyncJob */\n  public static readonly IOT_TWIN_MAKER_SYNC_JOB = new ResourceType('AWS::IoTTwinMaker::SyncJob');\n  /** Amazon Managed Streaming for Apache Kafka Connect Connector */\n  public static readonly KAFKA_CONNECT_CONNECTOR = new ResourceType('AWS::KafkaConnect::Connector');\n  /** AWS Lambda CodeSigningConfig */\n  public static readonly LAMBDA_CODE_SIGNING_CONFIG = new ResourceType('AWS::Lambda::CodeSigningConfig');\n  /** AWS Resource Explorer Index */\n  public static readonly RESOURCE_EXPLORER2_INDEX = new ResourceType('AWS::ResourceExplorer2::Index');\n  /** Amazon Connect Instance */\n  public static readonly CONNECT_INSTANCE = new ResourceType('AWS::Connect::Instance');\n  /** EC2 IPAMPool */\n  public static readonly EC2_IPAM_POOL = new ResourceType('AWS::EC2::IPAMPool');\n  /** EC2 TransitGatewayMulticastDomain */\n  public static readonly EC2_TRANSIT_GATEWAY_MULTICAST_DOMAIN = new ResourceType('AWS::EC2::TransitGatewayMulticastDomain');\n\n  /** A custom resource type to support future cases. */\n  public static of(type: string): ResourceType {\n    return new ResourceType(type);\n  }\n\n  /**\n   * Valid value of resource type.\n   */\n  public readonly complianceResourceType: string;\n\n  private constructor(type: string) {\n    this.complianceResourceType = type;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, CloudFormation, ECR resources", "output": "class EcrStack(NestedStack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs, ) -> None:\n        super().__init__(scope, id,  **kwargs )\n        # Creates two ecr repositories that will host the docker images for the color teller gateway app and color teller app\n        FrontendRepository = ecr.Repository(self, \"FrontendRepository\", repository_name=\"frontend\")\n        BackendDataRepository = ecr.Repository(self, \"BackendDataRepository\", repository_name=\"backend_data\")\n\n        # The docker images were built on a M1 Macbook Pro, you may have to rebuild your images\n        frontendAsset = DockerImageAsset(self, \"frontendAsset\",\n            directory=\"./services/frontend\",\n            build_args={\n                \"SERVICE_B_URL_BUILD_ARG\": \"data.scapp.local\" # This argument will be passed to the dockerfile and is the URL that the frontend app will use to call the backend\n            },\n            \n            platform=Platform.LINUX_AMD64\n        )\n        dataAsset = DockerImageAsset(self, \"dataAsset\",\n            directory=\"./services/data\",\n\n        )\n        # Deploying images to ECR\n        ecrdeploy.ECRDeployment(self, \"DeployFrontendImage\",\n            src=ecrdeploy.DockerImageName(frontendAsset.image_uri),\n            dest=ecrdeploy.DockerImageName(f\"{Aws.ACCOUNT_ID}.dkr.ecr.{Aws.REGION}.amazonaws.com/frontend:latest\")\n        )\n\n       \n\n        ecrdeploy.ECRDeployment(self, \"DeployBackendImage\",\n            src=ecrdeploy.DockerImageName(dataAsset.image_uri),\n            dest=ecrdeploy.DockerImageName(f\"{Aws.ACCOUNT_ID}.dkr.ecr.{Aws.REGION}.amazonaws.com/backend_data:latest\")\n        )\n\n        # Exporting values to be used in other stacks\n        self.frontend_docker_asset = frontendAsset\n        self.backend_data_docker_asset = dataAsset", "language": "python"}
{"input": "CDK class ImmutableImport for AWS resource management", "output": "class ImmutableImport extends SecurityGroupBase {\n      public securityGroupId = securityGroupId;\n      public allowAllOutbound = options.allowAllOutbound ?? true;\n      public allowAllIpv6Outbound = options.allowAllIpv6Outbound ?? false;\n\n      public addEgressRule(_peer: IPeer, _connection: Port, _description?: string, _remoteRule?: boolean) {\n        // do nothing\n      }\n\n      public addIngressRule(_peer: IPeer, _connection: Port, _description?: string, _remoteRule?: boolean) {\n        // do nothing\n      }\n    }", "language": "typescript"}
{"input": "The key format for the log object.", "output": "class TargetObjectKeyFormat {\n  /**\n   * Use partitioned prefix for log objects.\n   * If you do not specify the dateSource argument, the default is EventTime.\n   *\n   * The partitioned prefix format as follow:\n   * [DestinationPrefix][SourceAccountId]/\u200b[SourceRegion]/\u200b[SourceBucket]/\u200b[YYYY]/\u200b[MM]/\u200b[DD]/\u200b[YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]\n   */\n  public static partitionedPrefix(dateSource?: PartitionDateSource): TargetObjectKeyFormat {\n    return new class extends TargetObjectKeyFormat {\n      public _render(): CfnBucket.LoggingConfigurationProperty['targetObjectKeyFormat'] {\n        return {\n          partitionedPrefix: {\n            partitionDateSource: dateSource,\n          },\n        };\n      }\n    }();\n  }\n\n  /**\n   * Use the simple prefix for log objects.\n   *\n   * The simple prefix format as follow:\n   * [DestinationPrefix][YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]\n   */\n  public static simplePrefix(): TargetObjectKeyFormat {\n    return new class extends TargetObjectKeyFormat {\n      public _render(): CfnBucket.LoggingConfigurationProperty['targetObjectKeyFormat'] {\n        return {\n          simplePrefix: {},\n        };\n      }\n    }();\n  }\n\n  /**\n   * Render the log object key format.\n   *\n   * @internal\n   */\n  public abstract _render(): CfnBucket.LoggingConfigurationProperty['targetObjectKeyFormat'];\n}", "language": "typescript"}
{"input": "CDK class OriginAccessIdentityBase for AWS resource management", "output": "class OriginAccessIdentityBase extends cdk.Resource {\n  /**\n   * The Origin Access Identity Id (physical id)\n   * It is misnamed and superseded by the correctly named originAccessIdentityId\n   *\n   * @deprecated use originAccessIdentityId instead\n   */\n  public abstract readonly originAccessIdentityName: string;\n\n  /**\n   * The Origin Access Identity Id (physical id)\n   * This was called originAccessIdentityName before\n   */\n  public abstract readonly originAccessIdentityId: string;\n\n  /**\n   * Derived principal value for bucket access\n   */\n  public abstract readonly grantPrincipal: iam.IPrincipal;\n\n  /**\n   * The ARN to include in S3 bucket policy to allow CloudFront access\n   */\n  protected arn(): string {\n    return cdk.Stack.of(this).formatArn(\n      {\n        service: 'iam',\n        region: '', // global\n        account: 'cloudfront',\n        resource: 'user',\n        resourceName: `CloudFront Origin Access Identity ${this.originAccessIdentityId}`,\n      },\n    );\n  }\n}", "language": "typescript"}
{"input": "OAuth scopes that are allowed with this client. @see https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-app-idp-settings.html", "output": "export class OAuthScope {\n  /**\n   * Grants access to the 'phone_number' and 'phone_number_verified' claims.\n   * Automatically includes access to `OAuthScope.OPENID`.\n   */\n  public static readonly PHONE = new OAuthScope('phone');\n\n  /**\n   * Grants access to the 'email' and 'email_verified' claims.\n   * Automatically includes access to `OAuthScope.OPENID`.\n   */\n  public static readonly EMAIL = new OAuthScope('email');\n\n  /**\n   * Returns all user attributes in the ID token that are readable by the client\n   */\n  public static readonly OPENID = new OAuthScope('openid');\n\n  /**\n   * Grants access to all user attributes that are readable by the client\n   * Automatically includes access to `OAuthScope.OPENID`.\n   */\n  public static readonly PROFILE = new OAuthScope('profile');\n\n  /**\n   * Grants access to Amazon Cognito User Pool API operations that require access tokens,\n   * such as UpdateUserAttributes and VerifyUserAttribute.\n   */\n  public static readonly COGNITO_ADMIN = new OAuthScope('aws.cognito.signin.user.admin');\n\n  /**\n   * Custom scope is one that you define for your own resource server in the Resource Servers.\n   * The format is 'resource-server-identifier/scope'.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-define-resource-servers.html\n   */\n  public static custom(name: string) {\n    return new OAuthScope(name);\n  }\n\n  /**\n   * Adds a custom scope that's tied to a resource server in your stack\n   */\n  public static resourceServer(server: IUserPoolResourceServer, scope: ResourceServerScope) {\n    return new OAuthScope(`${server.userPoolResourceServerId}/${scope.scopeName}`);\n  }\n\n  /**\n   * The name of this scope as recognized by CloudFormation.\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolclient.html#cfn-cognito-userpoolclient-allowedoauthscopes\n   */\n  public readonly scopeName: string;\n\n  private constructor(scopeName: string) {\n    this.scopeName = scopeName;\n  }\n}\n\n/**\n * Identity providers supported by the UserPoolClient\n */\nexport class UserPoolClientIdentityProvider {\n  /**\n   * Allow users to sign in using 'Sign In With Apple'.\n   * A `UserPoolIdentityProviderApple` must be attached to the user pool.\n   */\n  public static readonly APPLE = new UserPoolClientIdentityProvider('SignInWithApple');\n\n  /**\n   * Allow users to sign in using 'Facebook Login'.\n   * A `UserPoolIdentityProviderFacebook` must be attached to the user pool.\n   */\n  public static readonly FACEBOOK = new UserPoolClientIdentityProvider('Facebook');\n\n  /**\n   * Allow users to sign in using 'Google Login'.\n   * A `UserPoolIdentityProviderGoogle` must be attached to the user pool.\n   */\n  public static readonly GOOGLE = new UserPoolClientIdentityProvider('Google');\n\n  /**\n   * Allow users to sign in using 'Login With Amazon'.\n   * A `UserPoolIdentityProviderAmazon` must be attached to the user pool.\n   */\n  public static readonly AMAZON = new UserPoolClientIdentityProvider('LoginWithAmazon');\n\n  /**\n   * Allow users to sign in directly as a user of the User Pool\n   */\n  public static readonly COGNITO = new UserPoolClientIdentityProvider('COGNITO');\n\n  /**\n   * Specify a provider not yet supported by the CDK.\n   * @param name name of the identity provider as recognized by CloudFormation property `SupportedIdentityProviders`\n   */\n  public static custom(name: string) {\n    return new UserPoolClientIdentityProvider(name);\n  }\n\n  /** The name of the identity provider as recognized by CloudFormation property `SupportedIdentityProviders` */\n  public readonly name: string;\n\n  private constructor(name: string) {\n    this.name = name;\n  }\n}\n\n/**\n * Options to create a UserPoolClient\n */\nexport interface UserPoolClientOptions {\n  /**\n   * Name of the application client\n   * @default - cloudformation generated name\n   */\n  readonly userPoolClientName?: string;\n\n  /**\n   * Whether to generate a client secret\n   * @default false\n   */\n  readonly generateSecret?: boolean;\n\n  /**\n   * The set of OAuth authentication flows to enable on the client\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-authentication-flow.html\n   * @default - If you don't specify a value, your user client supports ALLOW_REFRESH_TOKEN_AUTH, ALLOW_USER_SRP_AUTH, and ALLOW_CUSTOM_AUTH.\n   */\n  readonly authFlows?: AuthFlow;\n\n  /**\n   * Turns off all OAuth interactions for this client.\n   * @default false\n   */\n  readonly disableOAuth?: boolean;\n\n  /**\n   * OAuth settings for this client to interact with the app.\n   * An error is thrown when this is specified and `disableOAuth` is set.\n   * @default - see defaults in `OAuthSettings`. meaningless if `disableOAuth` is set.\n   */\n  readonly oAuth?: OAuthSettings;\n\n  /**\n   * Cognito creates a session token for each API request in an authentication flow.\n   * AuthSessionValidity is the duration, in minutes, of that session token.\n   * see defaults in `AuthSessionValidity`. Valid duration is from 3 to 15 minutes.\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpoolclient.html#cfn-cognito-userpoolclient-authsessionvalidity\n   * @default - Duration.minutes(3)\n   */\n  readonly authSessionValidity?: Duration;\n\n  /**\n   * Whether Cognito returns a UserNotFoundException exception when the\n   * user does not exist in the user pool (false), or whether it returns\n   * another type of error that doesn't reveal the user's absence.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-managing-errors.html\n   * @default false\n   */\n  readonly preventUserExistenceErrors?: boolean;\n\n  /**\n   * The list of identity providers that users should be able to use to sign in using this client.\n   *\n   * @default - supports all identity providers that are registered with the user pool. If the user pool and/or\n   * identity providers are imported, either specify this option explicitly or ensure that the identity providers are\n   * registered with the user pool using the `UserPool.registerIdentityProvider()` API.\n   */\n  readonly supportedIdentityProviders?: UserPoolClientIdentityProvider[];\n\n  /**\n   * Validity of the ID token.\n   * Values between 5 minutes and 1 day are valid. The duration can not be longer than the refresh token validity.\n   * @see https://docs.aws.amazon.com/en_us/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-id-token\n   * @default Duration.minutes(60)\n   */\n  readonly idTokenValidity?: Duration;\n\n  /**\n   * Validity of the refresh token.\n   * Values between 60 minutes and 10 years are valid.\n   * @see https://docs.aws.amazon.com/en_us/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-refresh-token\n   * @default Duration.days(30)\n   */\n  readonly refreshTokenValidity?: Duration;\n\n  /**\n   * Validity of the access token.\n   * Values between 5 minutes and 1 day are valid. The duration can not be longer than the refresh token validity.\n   * @see https://docs.aws.amazon.com/en_us/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-access-token\n   * @default Duration.minutes(60)\n   */\n  readonly accessTokenValidity?: Duration;\n\n  /**\n   * Enables refresh token rotation when set.\n   * Defines the grace period for the original refresh token (0-60 seconds).\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-using-the-refresh-token.html#using-the-refresh-token-rotation\n   * @default - undefined (refresh token rotation is disabled)\n   */\n  readonly refreshTokenRotationGracePeriod?: Duration;\n\n  /**\n   * The set of attributes this client will be able to read.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#user-pool-settings-attribute-permissions-and-scopes\n   * @default - all standard and custom attributes\n   */\n  readonly readAttributes?: ClientAttributes;\n\n  /**\n   * The set of attributes this client will be able to write.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-attributes.html#user-pool-settings-attribute-permissions-and-scopes\n   * @default - all standard and custom attributes\n   */\n  readonly writeAttributes?: ClientAttributes;\n\n  /**\n   * Enable token revocation for this client.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/token-revocation.html#enable-token-revocation\n   * @default true for new user pool clients\n   */\n  readonly enableTokenRevocation?: boolean;\n\n  /**\n   * Enable the propagation of additional user context data.\n   * You can only activate enablePropagateAdditionalUserContextData in an app client that has a client secret.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pool-settings-adaptive-authentication.html#user-pool-settings-adaptive-authentication-device-fingerprint\n   * @default false for new user pool clients\n   */\n  readonly enablePropagateAdditionalUserContextData?: boolean;\n\n  /**\n   * The analytics configuration for this client.\n   * @default - no analytics configuration\n   */\n  readonly analytics?: AnalyticsConfiguration;\n}", "language": "typescript"}
{"input": "CDK class FirelensLogRouter for AWS resource management", "output": "export class FirelensLogRouter extends ContainerDefinition {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs.FirelensLogRouter';\n\n  /**\n   * Firelens configuration\n   */\n  public readonly firelensConfig: FirelensConfig;\n\n  /**\n   * Constructs a new instance of the FirelensLogRouter class.\n   */\n  constructor(scope: Construct, id: string, props: FirelensLogRouterProps) {\n    super(scope, id, props);\n    const options = props.firelensConfig.options;\n    if (options) {\n      if ((options.configFileValue && options.configFileType === undefined) || (options.configFileValue === undefined && options.configFileType)) {\n        throw new cdk.ValidationError('configFileValue and configFileType must be set together to define a custom config source', this);\n      }\n\n      const hasConfig = (options.configFileValue !== undefined);\n      const enableECSLogMetadata = options.enableECSLogMetadata || options.enableECSLogMetadata === undefined;\n      const configFileType = (options.configFileType === undefined || options.configFileType === FirelensConfigFileType.S3) &&\n        (cdk.Token.isUnresolved(options.configFileValue) || /arn:aws[a-zA-Z-]*:s3:::.+/.test(options.configFileValue || ''))\n        ? FirelensConfigFileType.S3 : FirelensConfigFileType.FILE;\n\n      this.firelensConfig = {\n        type: props.firelensConfig.type,\n        options: {\n          enableECSLogMetadata,\n          ...(hasConfig ? {\n            configFileType,\n            configFileValue: options.configFileValue,\n          } : {}),\n        },\n      };\n\n      if (hasConfig) {\n        // grant s3 access permissions\n        if (configFileType === FirelensConfigFileType.S3) {\n          props.taskDefinition.addToExecutionRolePolicy(new iam.PolicyStatement({\n            actions: [\n              's3:GetObject',\n            ],\n            resources: [(options.configFileValue ?? '')],\n          }));\n          props.taskDefinition.addToExecutionRolePolicy(new iam.PolicyStatement({\n            actions: [\n              's3:GetBucketLocation',\n            ],\n            resources: [(options.configFileValue ?? '').split('/')[0]],\n          }));\n        }\n      }\n    } else {\n      this.firelensConfig = props.firelensConfig;\n    }\n  }\n\n  /**\n   * Render this container definition to a CloudFormation object\n   */\n  public renderContainerDefinition(_taskDefinition?: TaskDefinition): CfnTaskDefinition.ContainerDefinitionProperty {\n    return {\n      ...(super.renderContainerDefinition()),\n      firelensConfiguration: this.firelensConfig && renderFirelensConfig(this.firelensConfig),\n    };\n  }\n}", "language": "typescript"}
{"input": "Describes a block device mapping for an EC2 instance or Auto Scaling group.", "output": "export class BlockDeviceVolume {\n  /**\n   * Creates a new Elastic Block Storage device\n   *\n   * @param volumeSize The volume size, in Gibibytes (GiB)\n   * @param options additional device options\n   */\n  public static ebs(volumeSize: number, options: EbsDeviceOptions = {}): BlockDeviceVolume {\n    return new this({ ...options, volumeSize });\n  }\n\n  /**\n   * Creates a new Elastic Block Storage device from an existing snapshot\n   *\n   * @param snapshotId The snapshot ID of the volume to use\n   * @param options additional device options\n   */\n  public static ebsFromSnapshot(snapshotId: string, options: EbsDeviceSnapshotOptions = {}): BlockDeviceVolume {\n    return new this({ ...options, snapshotId });\n  }\n\n  /**\n   * Creates a virtual, ephemeral device.\n   * The name will be in the form ephemeral{volumeIndex}.\n   *\n   * @param volumeIndex the volume index. Must be equal or greater than 0\n   */\n  public static ephemeral(volumeIndex: number) {\n    if (volumeIndex < 0) {\n      throw new UnscopedValidationError(`volumeIndex must be a number starting from 0, got \"${volumeIndex}\"`);\n    }\n\n    return new this(undefined, `ephemeral${volumeIndex}`);\n  }\n\n  /**\n   * @param ebsDevice EBS device info\n   * @param virtualName Virtual device name\n   */\n  protected constructor(public readonly ebsDevice?: EbsDeviceProps, public readonly virtualName?: string) {\n  }\n}", "language": "typescript"}
{"input": "Generate a mock stack that embeds the orchestrator construct for testing", "output": "def template():\n    \"\"\"\n      Generate a mock stack that embeds the orchestrator construct for testing\n      \"\"\"\n    app = cdk.App()\n    stack = AthenaS3GlueStack(app, \"demo-athena-s3-glue\")\n\n    return cdk.assertions.Template.from_stack(stack)", "language": "python"}
{"input": "CDK helper function for IAM operations", "output": "def collection_pipeline_policy_doc(self, collection_arn):\n    collection_pipeline_policy_doc = iam.PolicyDocument()\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [\"*\"],\n      \"actions\": [\n        \"aoss:BatchGetCollection\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [collection_arn],\n      \"actions\": [\n        \"aoss:APIAccessAll\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [\"*\"],\n      \"actions\": [\n        \"aoss:CreateSecurityPolicy\",\n        \"aoss:GetSecurityPolicy\",\n        \"aoss:UpdateSecurityPolicy\"\n      ],\n      \"conditions\": {\n        \"StringEquals\": {\n          \"aoss:collection\": COLLECTION_NAME\n        }\n      }\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}/export/*'],\n      \"actions\": [\n        \"dynamodb:DescribeExport\",\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}/stream/*'],\n      \"actions\": [\n        \"dynamodb:DescribeStream\",\n        \"dynamodb:GetRecords\",\n        \"dynamodb:GetShardIterator\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}'],\n      \"actions\": [\n        \"dynamodb:DescribeTable\",\n        \"dynamodb:DescribeContinuousBackups\",\n        \"dynamodb:ExportTableToPointInTime\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:s3:::{S3_EXPORT_BUCKET_FOR_DDB}/{DYNAMO_TABLE_NAME}/*'],\n      \"actions\": [\n        \"s3:GetObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ]\n    }))\n    return collection_pipeline_policy_doc", "language": "python"}
{"input": "Iot producer that routes messages to the MSK cluster topic created by the client", "output": "class IotProducer(NestedStack):\n    def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc_id,\n                role_arn,\n                subnet_ids,\n                bootstrap_brokers_sasl_scram,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Iot destination \n        destination = IotProducerDestination(self, \"IotProducerTopicDestination\", \n            role_arn=role_arn,\n            vpc_id=vpc_id,\n            subnet_ids=subnet_ids\n        )\n        \n        # Create Iot Messaging Rule for MSK Cluster using the destination ARN\n        rule = iot.CfnTopicRule(self, \"TopicRule\",\n            topic_rule_payload=iot.CfnTopicRule.TopicRulePayloadProperty(\n                actions=[iot.CfnTopicRule.ActionProperty(\n                    kafka=iot.CfnTopicRule.KafkaActionProperty(\n                        destination_arn=destination.arn,\n                        topic=constants[\"MSK_TOPIC\"],\n                        client_properties= {\n                            'bootstrap.servers': bootstrap_brokers_sasl_scram,\n                            'sasl.mechanism': 'SCRAM-SHA-512',\n                            'security.protocol': 'SASL_SSL',\n                            'sasl.scram.username': \"${get_secret('AmazonMSK_iotCluster_demo', 'SecretString', 'username', '\" + role_arn + \"')}\",\n                            'sasl.scram.password': \"${get_secret('AmazonMSK_iotCluster_demo', 'SecretString', 'password', '\" + role_arn + \"')}\"\n                        }\n                    )\n                )],\n                sql='SELECT * FROM \"' + constants[\"IOT_TOPIC\"] + '\"'\n            )\n        )", "language": "python"}
{"input": "CDK class AssetApplicationCode for AWS resource management", "output": "class AssetApplicationCode extends ApplicationCode {\n  private readonly path: string;\n  private readonly options?: s3_assets.AssetOptions;\n  private _asset?: s3_assets.Asset;\n\n  constructor(path: string, options?: s3_assets.AssetOptions) {\n    super();\n    this.path = path;\n    this.options = options;\n  }\n\n  public bind(scope: Construct): ApplicationCodeConfig {\n    this._asset = new s3_assets.Asset(scope, 'Code', {\n      path: this.path,\n      ...this.options,\n    });\n\n    if (!this._asset.isZipArchive) {\n      throw new Error(`Asset must be a .zip file or a directory (${this.path})`);\n    }\n\n    return {\n      applicationCodeConfigurationProperty: {\n        applicationCodeConfiguration: {\n          codeContent: {\n            s3ContentLocation: {\n              bucketArn: this._asset.bucket.bucketArn,\n              fileKey: this._asset.s3ObjectKey,\n            },\n          },\n          codeContentType: 'ZIPFILE',\n        },\n      },\n      bucket: this._asset.bucket,\n    };\n  }\n\n  get asset(): s3_assets.Asset | undefined {\n    return this._asset;\n  }\n\n  get bucket(): s3.IBucket | undefined {\n    return this._asset?.bucket;\n  }\n}", "language": "typescript"}
{"input": "Helper class for referencing and uploading workflow data", "output": "class WorkflowData {\n  /**\n   * Uploads workflow data from a local file to S3 to use as the workflow data\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param path The local path to the workflow data file\n   * @param options S3 asset upload options\n   */\n  public static fromAsset(\n    scope: Construct,\n    id: string,\n    path: string,\n    options: s3assets.AssetOptions = {},\n  ): S3WorkflowData {\n    const asset = new s3assets.Asset(scope, id, { ...options, path });\n    return new S3WorkflowDataFromAsset(asset);\n  }\n\n  /**\n   * References workflow data from a pre-existing S3 object\n   *\n   * @param bucket The S3 bucket where the workflow data is stored\n   * @param key The S3 key of the workflow data file\n   */\n  public static fromS3(bucket: s3.IBucket, key: string): S3WorkflowData {\n    return new S3WorkflowDataFromBucketKey(bucket, key);\n  }\n\n  /**\n   * Uses an inline JSON object as the workflow data\n   *\n   * @param data An inline JSON object representing the workflow data\n   */\n  public static fromJsonObject(data: { [key: string]: any }): WorkflowData {\n    const inlineData = yaml.stringify(data, { indent: 2 });\n    return new InlineWorkflowData(inlineData);\n  }\n\n  /**\n   * Uses an inline JSON or YAML string as the workflow data\n   *\n   * @param data An inline JSON or YAML string representing the workflow data\n   */\n  public static fromInline(data: string): WorkflowData {\n    return new InlineWorkflowData(data);\n  }\n\n  /**\n   * The rendered workflow data value, for use in CloudFormation.\n   * - For inline workflows, data is the workflow text\n   * - For S3-backed workflows, uri is the S3 URL\n   */\n  abstract render(): WorkflowDataConfig;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, WAF resources", "output": "class BackupS3Stack(Stack):\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        bucket = aws_s3.Bucket(\n            self,\n            \"example-bucket\",\n            access_control=aws_s3.BucketAccessControl.BUCKET_OWNER_FULL_CONTROL,\n            encryption=aws_s3.BucketEncryption.S3_MANAGED,\n            block_public_access=aws_s3.BlockPublicAccess.BLOCK_ALL,\n            versioned=True,\n        )\n        Tags.of(bucket).add(\"daily-backup\", \"true\")\n\n        backupRole = self.createBackupRole()\n\n        vault = aws_backup.BackupVault(\n            self,\n            \"Vault\",\n        )\n        plan = aws_backup.BackupPlan.daily35_day_retention(\n            self, \"demo-backup-plan\", vault\n        )\n\n        plan.add_selection(\n            \"Selection\",\n            role=backupRole,\n            resources=[aws_backup.BackupResource.from_tag(\"daily-backup\", \"true\")],\n        )\n\n    def createBackupRole(self):\n        backupRole = aws_iam.Role(\n            self, \"Role\", assumed_by=aws_iam.ServicePrincipal(\"backup.amazonaws.com\")\n        )\n\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\n                    \"s3:GetInventoryConfiguration\",\n                    \"s3:PutInventoryConfiguration\",\n                    \"s3:ListBucketVersions\",\n                    \"s3:ListBucket\",\n                    \"s3:GetBucketVersioning\",\n                    \"s3:GetBucketNotification\",\n                    \"s3:PutBucketNotification\",\n                    \"s3:GetBucketLocation\",\n                    \"s3:GetBucketTagging\",\n                ],\n                resources=[\"arn:aws:s3:::*\"],\n                sid=\"S3BucketBackupPermissions\",\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\n                    \"s3:GetObjectAcl\",\n                    \"s3:GetObject\",\n                    \"s3:GetObjectVersionTagging\",\n                    \"s3:GetObjectVersionAcl\",\n                    \"s3:GetObjectTagging\",\n                    \"s3:GetObjectVersion\",\n                ],\n                resources=[\"arn:aws:s3:::*/*\"],\n                sid=\"S3ObjectBackupPermissions\",\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\"s3:ListAllMyBuckets\"],\n                resources=[\"*\"],\n                sid=\"S3GlobalPermissions\",\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\"s3:ListAllMyBuckets\"],\n                resources=[\"*\"],\n                sid=\"S3GlobalPermissions\",\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\"kms:Decrypt\", \"kms:DescribeKey\"],\n                resources=[\"*\"],\n                sid=\"KMSBackupPermissions\",\n                conditions={\"StringEquals\": {\"kms:ViaService\": \"s3.*.amazonaws.com\"}},\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\n                    \"events:DescribeRule\",\n                    \"events:EnableRule\",\n                    \"events:PutRule\",\n                    \"events:DeleteRule\",\n                    \"events:PutTargets\",\n                    \"events:RemoveTargets\",\n                    \"events:ListTargetsByRule\",\n                    \"events:DisableRule\",\n                ],\n                resources=[\"arn:aws:events:*:*:rule/AwsBackupManagedRule*\"],\n                sid=\"EventsPermissions\",\n            )\n        )\n        backupRole.add_to_policy(\n            aws_iam.PolicyStatement(\n                actions=[\"cloudwatch:GetMetricData\", \"events:ListRules\"],\n                resources=[\"*\"],\n                sid=\"EventsMetricsGlobalPermissions\",\n            )\n        )", "language": "python"}
{"input": "Java-specific implementation of the SDK injector. Handles Java agent configuration and environment setup.", "output": "export class JavaInjector extends Injector {\n  get command(): string[] {\n    return ['cp', '/javaagent.jar', `${this.containerPath}/javaagent.jar`];\n  }\n\n  get containerPath(): string {\n    return '/otel-auto-instrumentation';\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    envsToInject[constants.JavaInstrumentation.JAVA_TOOL_OPTIONS] = ` -javaagent:${this.containerPath}/javaagent.jar`;\n  }\n\n  protected overrideAdditionalEnvironments(_envsToOverride: { [key: string]: string }, _overrideEnvironments: { [key: string]: string }): void {\n    // No additional overrides needed for Java\n  }\n}", "language": "typescript"}
{"input": "CDK class BrowserCustom for AWS resource management", "output": "export class BrowserCustom extends BrowserCustomBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-agentcore-alpha.BrowserCustom';\n\n  /**\n   * Static Method for importing an existing Bedrock AgentCore Browser Custom.\n   */\n  /**\n   * Creates an Browser Custom reference from an existing browser's attributes.\n   *\n   * @param scope - The construct scope\n   * @param id - Identifier of the construct\n   * @param attrs - Attributes of the existing browser custom\n   * @returns An IBrowserCustom reference to the existing browser\n   */\n  public static fromBrowserCustomAttributes(scope: Construct, id: string, attrs: BrowserCustomAttributes): IBrowserCustom {\n    class Import extends BrowserCustomBase {\n      public readonly browserArn = attrs.browserArn;\n      public readonly browserId = Arn.split(attrs.browserArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName!;\n      public readonly executionRole = iam.Role.fromRoleArn(scope, `${id}Role`, attrs.roleArn);\n      public readonly lastUpdatedAt = attrs.lastUpdatedAt;\n      public readonly grantPrincipal = this.executionRole;\n      public readonly status = attrs.status;\n      public readonly createdAt = attrs.createdAt;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n\n        this.grantPrincipal = this.executionRole || new iam.UnknownPrincipal({ resource: this });\n        if (attrs.securityGroups) {\n          this._connections = new ec2.Connections({\n            securityGroups: attrs.securityGroups,\n          });\n        }\n      }\n    }\n\n    // Return new Browser Custom\n    return new Import(scope, id);\n  }\n  // ------------------------------------------------------\n  // Attributes\n  // ------------------------------------------------------\n  /**\n   * The ARN of the browser resource.\n   * @attribute\n   */\n  public readonly browserArn: string;\n  /**\n   * The id of the browser\n   * @attribute\n   */\n  public readonly browserId: string;\n  /**\n   * The name of the browser\n   */\n  public readonly name: string;\n  /**\n   * The description of the browser\n   */\n  public readonly description?: string;\n  /**\n   * The last updated timestamp of the browser\n   * @attribute\n   */\n  public readonly lastUpdatedAt?: string;\n  /**\n   * The status of the browser\n   * @attribute\n   */\n  public readonly status?: string;\n  /**\n   * The created timestamp of the browser\n   * @attribute\n   */\n  public readonly createdAt?: string;\n  /**\n   * The failure reason of the browser\n   * @attribute\n   */\n  public readonly failureReason?: string;\n  /**\n   * The IAM role associated to the browser.\n   */\n  public readonly executionRole: iam.IRole;\n  /**\n   * Tags applied to this browser resource\n   * A map of key-value pairs for resource tagging\n   * @default - No tags applied\n   */\n  public readonly tags?: { [key: string]: string };\n  /**\n   * The principal to grant permissions to\n   */\n  public readonly grantPrincipal: iam.IPrincipal;\n  /**\n   * The network configuration of the browser\n   */\n  public readonly networkConfiguration: BrowserNetworkConfiguration;\n  /**\n   * The recording configuration of the browser\n   */\n  public readonly recordingConfig?: RecordingConfig;\n  /**\n   * The browser signing configuration of the browser\n   */\n  public readonly browserSigning?: BrowserSigning;\n  // ------------------------------------------------------\n  // Internal Only\n  // ------------------------------------------------------\n  private readonly __resource: agent_core.CfnBrowserCustom;\n\n  // ------------------------------------------------------\n  // CONSTRUCTOR\n  // ------------------------------------------------------\n  constructor(scope: Construct, id: string, props: BrowserCustomProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // ------------------------------------------------------\n    // Set properties and defaults\n    // ------------------------------------------------------\n    this.name = props.browserCustomName;\n    this.description = props.description;\n    this.networkConfiguration = props.networkConfiguration ?? BrowserNetworkConfiguration.usingPublicNetwork();\n    this.recordingConfig = props.recordingConfig ?? { enabled: false };\n    this.executionRole = props.executionRole ?? this._createBrowserRole();\n    this.grantPrincipal = this.executionRole;\n    this.tags = props.tags;\n    this.browserSigning = props.browserSigning ?? BrowserSigning.DISABLED;\n\n    // Validate browser name\n    throwIfInvalid(this._validateBrowserName, this.name);\n\n    // Validate browser tags\n    throwIfInvalid(this._validateBrowserTags, this.tags);\n\n    // Validate recording configuration\n    throwIfInvalid(this._validateRecordingConfig, this.recordingConfig);\n\n    // Network configuration and validation is done in the network configuration class\n    // So we don't need to validate it here\n\n    // Set connections - create a shared connections object\n    if (this.networkConfiguration.connections) {\n      // Use the network configuration's connections as the shared object\n      this._connections = this.networkConfiguration.connections;\n    }\n\n    // ------------------------------------------------------\n    // CFN Props - With Lazy support\n    // ------------------------------------------------------\n    const cfnProps: agent_core.CfnBrowserCustomProps = {\n      name: this.name,\n      description: this.description,\n      networkConfiguration: Lazy.any({ produce: () => this.networkConfiguration._render(this._connections) }),\n      recordingConfig: this._renderRecordingConfig(),\n      executionRoleArn: this.executionRole?.roleArn,\n      tags: this.tags,\n      browserSigning: this._renderBrowserSigning(),\n    };\n\n    // L1 instantiation\n    this.__resource = new agent_core.CfnBrowserCustom(this, 'Resource', cfnProps);\n\n    // Get attributes directly from the CloudFormation resource\n    this.browserId = this.__resource.attrBrowserId;\n    this.browserArn = this.__resource.attrBrowserArn;\n    this.status = this.__resource.attrStatus;\n    this.createdAt = this.__resource.attrCreatedAt;\n    this.lastUpdatedAt = this.__resource.attrLastUpdatedAt;\n    this.failureReason = this.__resource.attrFailureReason;\n\n    // if recording is configured, add permissions to the execution role\n    if (this.recordingConfig && this.recordingConfig.s3Location) {\n      if (!Token.isUnresolved(this.recordingConfig.s3Location.bucketName)) {\n        Stack.of(this).resolve(this.recordingConfig.s3Location.bucketName);\n      }\n      const bucket = s3.Bucket.fromBucketName(\n        this,\n        `${this.name}RecordingBucket`,\n        this.recordingConfig.s3Location.bucketName,\n      );\n      // Ensure the policy is applied before the browser resource is created\n      const grant = bucket.grantReadWrite(this.executionRole);\n      grant.applyBefore(this.__resource);\n    }\n  }\n\n  /**\n   * Render the recording configuration.\n   *\n   * @returns RecordingConfigProperty object in CloudFormation format, or undefined if no recording configuration is defined\n   * @default - undefined if no recording configuration is provided\n   * @internal This is an internal core function and should not be called directly.\n   */\n  private _renderRecordingConfig(): agent_core.CfnBrowserCustom.RecordingConfigProperty | undefined {\n    return this.recordingConfig ? {\n      enabled: this.recordingConfig.enabled,\n      s3Location: this.recordingConfig.s3Location ? {\n        bucket: this.recordingConfig.s3Location.bucketName,\n        prefix: this.recordingConfig.s3Location.objectKey,\n      } : undefined,\n    } : undefined;\n  }\n\n  /**\n   * Render the browser signing configuration.\n   *\n   * @returns BrowserSigningProperty object in CloudFormation format, or undefined if no browser signing configuration is defined\n   * @default - undefined if no browser signing configuration is provided\n   * @internal This is an internal core function and should not be called directly.\n   */\n  private _renderBrowserSigning(): agent_core.CfnBrowserCustom.BrowserSigningProperty {\n    return this.browserSigning === BrowserSigning.ENABLED ? {\n      enabled: true,\n    } : {\n      enabled: false,\n    };\n  }\n\n  /**\n   * Creates execution role needed for the browser to access AWS services\n   * @returns The created role\n   * @internal This is an internal core function and should not be called directly.\n   */\n  private _createBrowserRole(): iam.IRole {\n    const role = new iam.Role(this, 'ServiceRole', {\n      assumedBy: new iam.ServicePrincipal('bedrock-agentcore.amazonaws.com'),\n    });\n\n    return role;\n  }\n\n  // ------------------------------------------------------\n  // Validators\n  // ------------------------------------------------------\n  /**\n   * Validates the browser name format\n   * @param name The browser name to validate\n   * @returns Array of validation error messages, empty if valid\n   */\n  private _validateBrowserName = (name: string): string[] => {\n    let errors: string[] = [];\n\n    errors.push(...validateStringFieldLength({\n      value: name,\n      fieldName: 'Browser name',\n      minLength: BROWSER_NAME_MIN_LENGTH,\n      maxLength: BROWSER_NAME_MAX_LENGTH,\n    }));\n\n    // Check if name matches the AWS API pattern: [a-zA-Z][a-zA-Z0-9_]{0,47}\n    // Must start with a letter, followed by up to 47 letters, numbers, or underscores\n    const validNamePattern = /^[a-zA-Z][a-zA-Z0-9_]{0,47}$/;\n    errors.push(...validateFieldPattern(name, 'Browser name', validNamePattern));\n\n    return errors;\n  };\n\n  /**\n   * Validates the browser tags format\n   * @param tags The tags object to validate\n   * @returns Array of validation error messages, empty if valid\n   */\n  private _validateBrowserTags = (tags?: { [key: string]: string }): string[] => {\n    let errors: string[] = [];\n    if (!tags) {\n      return errors; // Tags are optional\n    }\n\n    // Validate each tag key and value\n    for (const [key, value] of Object.entries(tags)) {\n      errors.push(...validateStringFieldLength({\n        value: key,\n        fieldName: 'Tag key',\n        minLength: BROWSER_TAG_MIN_LENGTH,\n        maxLength: BROWSER_TAG_MAX_LENGTH,\n      }));\n\n      // Validate tag key pattern: ^[a-zA-Z0-9\\s._:/=+@-]*$\n      const validKeyPattern = /^[a-zA-Z0-9\\s._:/=+@-]*$/;\n      errors.push(...validateFieldPattern(key, 'Tag key', validKeyPattern));\n\n      // Validate tag value\n      errors.push(...validateStringFieldLength({\n        value: value,\n        fieldName: 'Tag value',\n        minLength: BROWSER_TAG_MIN_LENGTH,\n        maxLength: BROWSER_TAG_MAX_LENGTH,\n      }));\n\n      // Validate tag value pattern: ^[a-zA-Z0-9\\s._:/=+@-]*$\n      const validValuePattern = /^[a-zA-Z0-9\\s._:/=+@-]*$/;\n      errors.push(...validateFieldPattern(value, 'Tag value', validValuePattern));\n    }\n\n    return errors;\n  };\n\n  /**\n   * Validates the recording configuration\n   * @param recordingConfig The recording configuration to validate\n   * @returns Array of validation error messages, empty if valid\n   */\n  private _validateRecordingConfig = (recordingConfig?: RecordingConfig): string[] => {\n    let errors: string[] = [];\n    if (!recordingConfig) {\n      return errors; // No validation needed if no recording config is provided\n    }\n\n    const s3Location = recordingConfig.s3Location;\n\n    // Only validate S3 location if it's actually provided\n    if (s3Location) {\n      // Both bucket name and object key are required when S3 location is provided\n      if (!s3Location.bucketName) {\n        errors.push('S3 bucket name is required when S3 location is provided for recording configuration');\n      } else {\n        // Validate bucket name pattern: ^[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$\n        const bucketNamePattern = /^[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$/;\n        errors.push(...validateFieldPattern(s3Location.bucketName, 'S3 bucket name', bucketNamePattern));\n      }\n\n      if (!s3Location.objectKey) {\n        errors.push('S3 object key (prefix) is required when S3 location is provided for recording configuration');\n      }\n    }\n\n    return errors;\n  };\n}", "language": "typescript"}
{"input": "CDK class OnlyKMSEncryptionTypeTest for AWS resource management", "output": "class OnlyKMSEncryptionTypeTest extends core.Stack {\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n    this.tableBucket = new s3tables.TableBucket(this, id, {\n      tableBucketName: 'integ-tb-kms-encryption-type-only',\n      encryption: s3tables.TableBucketEncryption.KMS,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n\n  public validateAssertions(integ: IntegTest) {\n    const encryptionConfig = integ.assertions.awsApiCall('@aws-sdk/client-s3tables', 'GetTableBucketEncryptionCommand', {\n      tableBucketARN: this.tableBucket.tableBucketArn,\n    });\n\n    encryptionConfig.expect(ExpectedResult.objectLike({\n      encryptionConfiguration: {\n        sseAlgorithm: 'aws:kms',\n        kmsKeyArn: Match.stringLikeRegexp('arn:aws:kms:.*:key/[\\w-]+'),\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3 operations", "output": "def __init__(self, scope: App, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create s3 bucket\n        bucket = s3.Bucket(self, \"CustomResourceTestBucket\",\n                           encryption=s3.BucketEncryption.S3_MANAGED, block_public_access=s3.BlockPublicAccess.BLOCK_ALL)\n\n        resource = MyCustomResource(\n            self, \"MyCustomResource\",\n            bucket_name=bucket.bucket_name\n        )", "language": "python"}
{"input": "CDK class AwsCdkLibServiceSubmodule for AWS resource management", "output": "class AwsCdkLibServiceSubmodule extends BaseServiceSubmodule {\n  public readonly resourcesMod: LocatedModule<Module>;\n  public readonly augmentations: LocatedModule<AugmentationsModule>;\n  public readonly cannedMetrics: LocatedModule<CannedMetricsModule>;\n  public readonly interfaces: LocatedModule<Module>;\n  public readonly grants?: LocatedModule<GrantsModule>;\n  public readonly didCreateInterfaceModule: boolean;\n  public readonly resources: Map<string, ResourceClass> = new Map();\n\n  public constructor(props: {\n    readonly submoduleName: string;\n    readonly service: Service;\n    readonly resourcesMod: LocatedModule<Module>;\n    readonly augmentations: LocatedModule<AugmentationsModule>;\n    readonly cannedMetrics: LocatedModule<CannedMetricsModule>;\n    readonly interfaces: LocatedModule<Module>;\n    readonly grants?: LocatedModule<GrantsModule>;\n    readonly didCreateInterfaceModule: boolean;\n  }) {\n    super(props);\n    this.resourcesMod = props.resourcesMod;\n    this.augmentations = props.augmentations;\n    this.cannedMetrics = props.cannedMetrics;\n    this.interfaces = props.interfaces;\n    this.didCreateInterfaceModule = props.didCreateInterfaceModule;\n    this.grants = props.grants;\n\n    this.registerModule(this.resourcesMod);\n    this.registerModule(this.cannedMetrics);\n    this.registerModule(this.augmentations);\n    this.registerModule(this.interfaces);\n\n    if (this.grants) {\n      this.registerModule(this.grants);\n    }\n  }\n}", "language": "typescript"}
{"input": "TOOL SCHEMA CLASS ***************************************************************************", "output": "class ToolSchema extends TargetSchema {\n  /**\n   * Creates a tool Schema from a local file.\n   * @param path - the path to the local file containing the function schema for the tool\n   */\n  public static fromLocalAsset(path: string): ToolSchema {\n    return new AssetToolSchema(path);\n  }\n\n  /**\n   * Creates a Tool Schema from an inline string.\n   * @param schema - the JSON or YAML payload defining the OpenAPI schema for the action group\n   */\n  public static fromInline(schema: ToolDefinition[]): InlineToolSchema {\n    return new InlineToolSchema(schema);\n  }\n\n  /**\n   * Creates a Tool Schema from an S3 File\n   * @param bucket - the bucket containing the local file containing the OpenAPI schema for the action group\n   * @param objectKey - object key in the bucket\n   * @param bucketOwnerAccountId - optional The account ID of the Amazon S3 bucket owner. This ID is used for cross-account access to the bucket.\n   */\n  public static fromS3File(bucket: IBucket, objectKey: string, bucketOwnerAccountId?: string): S3ToolSchema {\n    return new S3ToolSchema(\n      {\n        bucketName: bucket.bucketName,\n        objectKey: objectKey,\n      },\n      bucketOwnerAccountId,\n    );\n  }\n\n  /**\n   * The S3 location of the tool schema file, if using an S3-based schema.\n   * Contains the bucket name and object key information.\n   */\n  public readonly s3File?: Location;\n\n  /**\n   * The inline tool schema definition as a string, if using an inline schema.\n   * Can be in JSON or YAML format.\n   */\n  public readonly inlineSchema?: ToolDefinition[];\n\n  /**\n   * The account ID of the S3 bucket owner for cross-account access\n   */\n  public readonly bucketOwnerAccountId?: string;\n\n  protected constructor(s3File?: Location, bucketOwnerAccountId?: string, inlineSchema?: ToolDefinition[]) {\n    super();\n    this.s3File = s3File;\n    this.inlineSchema = inlineSchema;\n    this.bucketOwnerAccountId = bucketOwnerAccountId;\n  }\n\n  /**\n   * Format as CFN properties\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public abstract _render(): any;\n}", "language": "typescript"}
{"input": "CDK class NoPeerDependenciesAwsCdkLib for AWS resource management", "output": "export class NoPeerDependenciesAwsCdkLib extends ValidationRule {\n  public readonly name = 'aws-cdk-lib/no-peer';\n  private readonly allowedPeer = ['constructs'];\n  private readonly modules = ['aws-cdk-lib'];\n\n  public validate(pkg: PackageJson): void {\n    if (!this.modules.includes(pkg.packageName)) {\n      return;\n    }\n\n    const peers = Object.keys(pkg.peerDependencies).filter(peer => !this.allowedPeer.includes(peer));\n    if (peers.length > 0) {\n      pkg.report({\n        ruleName: this.name,\n        message: `Adding a peer dependency to the monolithic package ${pkg.packageName} is a breaking change, and thus not allowed.\n         Added ${peers.join(' ')}`,\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ECS resources", "output": "class CloudWatchAgentStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: ApplicationSignalsStackProps) {\n    super(scope, id, props);\n\n    // Define Task Definition for CloudWatch agent (Daemon)\n    const taskDefinition = new ecs.Ec2TaskDefinition(this, 'CloudWatchAgentTaskDefinition', {\n      networkMode: ecs.NetworkMode.HOST,\n      taskRole: props.taskRole,\n      executionRole: props.taskExecutionRole,\n    });\n\n    new appsignals.CloudWatchAgentIntegration(this, 'CloudWatchAgentECSIntegration', {\n      taskDefinition: taskDefinition,\n      containerName: 'ecs-cwagent',\n      enableLogging: false,\n      cpu: 128,\n      memoryLimitMiB: 64,\n      portMappings: [\n        {\n          containerPort: 4316,\n          hostPort: 4316,\n        },\n        {\n          containerPort: 2000,\n          hostPort: 2000,\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const domainProps: es.DomainProps = {\n      removalPolicy: RemovalPolicy.DESTROY,\n      version: es.ElasticsearchVersion.V7_1,\n      ebs: {\n        volumeSize: 10,\n        volumeType: EbsDeviceVolumeType.GENERAL_PURPOSE_SSD,\n      },\n      logging: {\n        slowSearchLogEnabled: true,\n        appLogEnabled: true,\n      },\n      nodeToNodeEncryption: true,\n      encryptionAtRest: {\n        enabled: true,\n      },\n      advancedOptions: {\n        'rest.action.multi.allow_explicit_index': 'false',\n        'indices.fielddata.cache.size': '25',\n        'indices.query.bool.max_clause_count': '2048',\n      },\n      // test the access policies custom resource works\n      accessPolicies: [\n        new iam.PolicyStatement({\n          effect: iam.Effect.ALLOW,\n          actions: ['es:ESHttp*'],\n          principals: [new iam.AccountRootPrincipal()],\n          resources: ['*'],\n        }),\n      ],\n    };\n\n    // create 2 elasticsearch domains to ensure that Cloudwatch Log Group policy names dont conflict\n    new es.Domain(this, 'Domain1', domainProps);\n    new es.Domain(this, 'Domain2', domainProps);\n  }\n}", "language": "typescript"}
{"input": "The DB parameter group family that a DB parameter group is compatible with", "output": "export class ParameterGroupFamily {\n  /**\n   * Family used by Neptune engine versions before 1.2.0.0\n   */\n  public static readonly NEPTUNE_1 = new ParameterGroupFamily('neptune1');\n  /**\n   * Family used by Neptune engine versions 1.2.0.0 and later\n   */\n  public static readonly NEPTUNE_1_2 = new ParameterGroupFamily('neptune1.2');\n  /**\n   * Family used by Neptune engine versions 1.3.0.0 and later\n   */\n  public static readonly NEPTUNE_1_3 = new ParameterGroupFamily('neptune1.3');\n  /**\n   * Family used by Neptune engine versions 1.4.0.0 and later\n   */\n  public static readonly NEPTUNE_1_4 = new ParameterGroupFamily('neptune1.4');\n\n  /**\n   * Constructor for specifying a custom parameter group family\n   * @param family the family of the parameter group Neptune\n   */\n  public constructor(public readonly family: string) {}\n}", "language": "typescript"}
{"input": "A stack that defines an SQS queue.", "output": "class ProdStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new sqs.Queue(this, 'MyQueue', {\n      queueName: 'prod-queue',\n      visibilityTimeout: cdk.Duration.seconds(300),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class WillkommenECS for AWS resource management", "output": "class WillkommenECS extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'MyVpc', { maxAzs: 2 });\n\n    const cluster = new ecs.Cluster(this, 'Ec2Cluster', { vpc });\n    cluster.addCapacity('DefaultAutoScalingGroup', {\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.MICRO)\n    });\n\n    // create a task definition with CloudWatch Logs\n    const logging = new ecs.AwsLogDriver({ streamPrefix: \"myapp\" })\n\n    const taskDef = new ecs.Ec2TaskDefinition(this, \"MyTaskDefinition\");\n    taskDef.addContainer(\"AppContainer\", {\n      image: ecs.ContainerImage.fromRegistry(\"amazon/amazon-ecs-sample\"),\n      memoryLimitMiB: 512,\n      logging,\n    })\n\n    // Instantiate ECS Service with just cluster and image\n    new ecs.Ec2Service(this, \"Ec2Service\", {\n      cluster,\n      taskDefinition: taskDef,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, IAM, SSM Parameter Store, WAF resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new dynamodb.Table(this, 'Table', {\n      partitionKey: {\n        name: 'id',\n        type: dynamodb.AttributeType.STRING,\n      },\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const fs = new efs.CfnFileSystem(this, 'FileSystem');\n    fs.applyRemovalPolicy(RemovalPolicy.DESTROY);\n\n    const vault = new backup.BackupVault(this, 'Vault', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      lockConfiguration: {\n        minRetention: Duration.days(5),\n      },\n    });\n    const secondaryVault = new backup.BackupVault(this, 'SecondaryVault', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      lockConfiguration: {\n        minRetention: Duration.days(5),\n      },\n    });\n\n    const env = new CfnParameter(this, 'Env', { type: 'String', description: 'Env', default: 'test' });\n\n    new backup.BackupVault(this, 'ThirdVault', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      backupVaultName: `backupVault-${env.valueAsString}`,\n      lockConfiguration: {\n        minRetention: Duration.days(5),\n      },\n    });\n\n    const plan = backup.BackupPlan.dailyWeeklyMonthly5YearRetention(this, 'Plan', vault);\n\n    plan.addSelection('Selection', {\n      resources: [\n        backup.BackupResource.fromConstruct(this), // All backupable resources in this construct\n        backup.BackupResource.fromTag('stage', 'prod'), // Resources that are tagged stage=prod\n      ],\n    });\n\n    plan.addRule(new backup.BackupPlanRule({\n      copyActions: [{\n        destinationBackupVault: secondaryVault,\n        moveToColdStorageAfter: Duration.days(30),\n        deleteAfter: Duration.days(120),\n      }],\n      recoveryPointTags: {\n        stage: 'prod',\n      },\n    }));\n\n    plan.addRule(new backup.BackupPlanRule({\n      backupVault: vault,\n      scheduleExpression: events.Schedule.cron({\n        day: '15',\n        hour: '3',\n        minute: '30',\n      }),\n      scheduleExpressionTimezone: TimeZone.ETC_UTC,\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class ApplicationLoadBalancedFargateService for AWS resource management", "output": "export class ApplicationLoadBalancedFargateService extends ApplicationLoadBalancedServiceBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs-patterns.ApplicationLoadBalancedFargateService';\n\n  /**\n   * Determines whether the service will be assigned a public IP address.\n   */\n  public readonly assignPublicIp: boolean;\n\n  /**\n   * The Fargate service in this construct.\n   */\n  public readonly service: FargateService;\n  /**\n   * The Fargate task definition in this construct.\n   */\n  public readonly taskDefinition: FargateTaskDefinition;\n\n  /**\n   * Constructs a new instance of the ApplicationLoadBalancedFargateService class.\n   */\n  constructor(scope: Construct, id: string, props: ApplicationLoadBalancedFargateServiceProps = {}) {\n    super(scope, id, props);\n\n    this.assignPublicIp = props.assignPublicIp ?? false;\n\n    if (props.taskDefinition && props.taskImageOptions) {\n      throw new ValidationError('You must specify either a taskDefinition or an image, not both.', this);\n    } else if (props.taskDefinition) {\n      this.taskDefinition = props.taskDefinition;\n    } else if (props.taskImageOptions) {\n      const taskImageOptions = props.taskImageOptions;\n      this.taskDefinition = new FargateTaskDefinition(this, 'TaskDef', {\n        memoryLimitMiB: props.memoryLimitMiB,\n        cpu: props.cpu,\n        ephemeralStorageGiB: props.ephemeralStorageGiB,\n        executionRole: taskImageOptions.executionRole,\n        taskRole: taskImageOptions.taskRole,\n        family: taskImageOptions.family,\n        runtimePlatform: props.runtimePlatform,\n      });\n\n      // Create log driver if logging is enabled\n      const enableLogging = taskImageOptions.enableLogging ?? true;\n      const logDriver = taskImageOptions.logDriver !== undefined\n        ? taskImageOptions.logDriver : enableLogging\n          ? this.createAWSLogDriver(this.node.id) : undefined;\n\n      this.validateContainerCpu(this.taskDefinition.cpu, props.containerCpu);\n      this.validateContainerMemoryLimitMiB(this.taskDefinition.memoryMiB, props.containerMemoryLimitMiB);\n\n      const containerName = taskImageOptions.containerName ?? 'web';\n      const container = this.taskDefinition.addContainer(containerName, {\n        image: taskImageOptions.image,\n        healthCheck: props.healthCheck,\n        logging: logDriver,\n        environment: taskImageOptions.environment,\n        secrets: taskImageOptions.secrets,\n        dockerLabels: taskImageOptions.dockerLabels,\n        command: taskImageOptions.command,\n        entryPoint: taskImageOptions.entryPoint,\n        cpu: props.containerCpu,\n        memoryLimitMiB: props.containerMemoryLimitMiB,\n      });\n      container.addPortMappings({\n        containerPort: taskImageOptions.containerPort || 80,\n      });\n    } else {\n      throw new ValidationError('You must specify one of: taskDefinition or image', this);\n    }\n\n    this.validateHealthyPercentage('minHealthyPercent', props.minHealthyPercent);\n    this.validateHealthyPercentage('maxHealthyPercent', props.maxHealthyPercent);\n\n    if (\n      props.minHealthyPercent &&\n      !Token.isUnresolved(props.minHealthyPercent) &&\n      props.maxHealthyPercent &&\n      !Token.isUnresolved(props.maxHealthyPercent) &&\n      props.minHealthyPercent >= props.maxHealthyPercent\n    ) {\n      throw new ValidationError('Minimum healthy percent must be less than maximum healthy percent.', this);\n    }\n\n    const desiredCount = FeatureFlags.of(this).isEnabled(cxapi.ECS_REMOVE_DEFAULT_DESIRED_COUNT) ? this.internalDesiredCount : this.desiredCount;\n\n    this.service = new FargateService(this, 'Service', {\n      cluster: this.cluster,\n      desiredCount: desiredCount,\n      taskDefinition: this.taskDefinition,\n      assignPublicIp: this.assignPublicIp,\n      serviceName: props.serviceName,\n      healthCheckGracePeriod: props.healthCheckGracePeriod,\n      minHealthyPercent: props.minHealthyPercent,\n      maxHealthyPercent: props.maxHealthyPercent,\n      propagateTags: props.propagateTags,\n      enableECSManagedTags: props.enableECSManagedTags,\n      cloudMapOptions: props.cloudMapOptions,\n      platformVersion: props.platformVersion,\n      deploymentController: props.deploymentController,\n      circuitBreaker: props.circuitBreaker,\n      securityGroups: props.securityGroups,\n      vpcSubnets: props.taskSubnets,\n      enableExecuteCommand: props.enableExecuteCommand,\n      capacityProviderStrategies: props.capacityProviderStrategies,\n    });\n    this.addServiceAsTarget(this.service);\n  }\n\n  /**\n   * Throws an error if the specified percent is not an integer or negative.\n   */\n  private validateHealthyPercentage(name: string, value?: number) {\n    if (value === undefined || Token.isUnresolved(value)) { return; }\n    if (!Number.isInteger(value) || value < 0) {\n      throw new ValidationError(`${name}: Must be a non-negative integer; received ${value}`, this);\n    }\n  }\n\n  private validateContainerCpu(cpu: number, containerCpu?: number) {\n    if (containerCpu === undefined || Token.isUnresolved(containerCpu) || Token.isUnresolved(cpu)) {\n      return;\n    }\n    if (containerCpu > cpu) {\n      throw new ValidationError(`containerCpu must be less than to cpu; received containerCpu: ${containerCpu}, cpu: ${cpu}`, this);\n    }\n    // If containerCPU is 0, it is not an error.\n    if (containerCpu < 0 || !Number.isInteger(containerCpu)) {\n      throw new ValidationError(`containerCpu must be a non-negative integer; received ${containerCpu}`, this);\n    }\n  }\n\n  private validateContainerMemoryLimitMiB(memoryLimitMiB: number, containerMemoryLimitMiB?: number) {\n    if (containerMemoryLimitMiB === undefined || Token.isUnresolved(containerMemoryLimitMiB) || Token.isUnresolved(memoryLimitMiB)) {\n      return;\n    }\n    if (containerMemoryLimitMiB > memoryLimitMiB) {\n      throw new ValidationError(`containerMemoryLimitMiB must be less than to memoryLimitMiB; received containerMemoryLimitMiB: ${containerMemoryLimitMiB}, memoryLimitMiB: ${memoryLimitMiB}`, this);\n    }\n    if (containerMemoryLimitMiB <= 0 || !Number.isInteger(containerMemoryLimitMiB)) {\n      throw new ValidationError(`containerMemoryLimitMiB must be a positive integer; received ${containerMemoryLimitMiB}`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Converts types from the spec model to typewriter Converts types in the scope of a single resource.", "output": "export class TypeConverter {\n  /**\n   * Make a type converter for a resource that uses a default TypeDefinition builder for this resource scope\n   */\n  public static forResource(opts: TypeConverterForResourceOptions) {\n    return new TypeConverter({\n      ...opts,\n      typeDefinitionConverter: (typeDefinition, converter) => {\n        // Defensive programming: we have some current issues in the database\n        // that would lead to duplicate definitions. Short-circuit that by checking if the\n        // type already exists and return that instead.\n        const existing = new RichScope(opts.resourceClass).tryFindTypeByName(\n          structNameFromTypeDefinition(typeDefinition),\n        );\n        if (existing) {\n          return {\n            structType: existing as StructType,\n            build: () => {},\n          };\n        }\n\n        const structType = new TypeDefinitionStruct({\n          resource: opts.resource,\n          resourceClass: opts.resourceClass,\n          converter,\n          typeDefinition,\n          relationshipDecider: opts.relationshipDecider,\n        });\n\n        return {\n          structType: structType,\n          build: () => structType.build(),\n        };\n      },\n    });\n  }\n\n  /**\n   * Make a type converter for a resource that uses a default TypeDefinition builder for this resource scope\n   */\n  public static forMixin(opts: TypeConverterForResourceOptions) {\n    return new TypeConverter({\n      ...opts,\n      typeDefinitionConverter: (typeDefinition, converter) => {\n        // Defensive programming: we have some current issues in the database\n        // that would lead to duplicate definitions. Short-circuit that by checking if the\n        // type already exists and return that instead.\n        const existing = new RichScope(opts.resourceClass).tryFindTypeByName(\n          structNameFromTypeDefinition(typeDefinition),\n        );\n        if (existing) {\n          return {\n            structType: existing as StructType,\n            build: () => {},\n          };\n        }\n\n        const structType = new PartialTypeDefinitionStruct({\n          resource: opts.resource,\n          resourceClass: opts.resourceClass,\n          converter,\n          typeDefinition,\n          relationshipDecider: opts.relationshipDecider,\n          cfnProducer: false,\n          cfnParser: false,\n        });\n\n        return {\n          structType: structType,\n          build: () => structType.build(),\n        };\n      },\n    });\n  }\n\n  public readonly db: SpecDatabase;\n  public readonly module: Module;\n  private readonly typeDefinitionConverter: TypeDefinitionConverter;\n  private readonly typeDefCache = new Map<TypeDefinition, StructType>();\n  private readonly isEventBridgeType;\n\n  /** Reverse mapping so we can find the original type back for every generated Type */\n  private readonly originalTypes = new WeakMap<Type, PropertyType>();\n\n  constructor(options: TypeConverterOptions) {\n    this.db = options.db;\n    this.typeDefinitionConverter = options.typeDefinitionConverter;\n    this.module = Module.of(options.resourceClass);\n    this.isEventBridgeType = options.isEventBridgeType;\n  }\n\n  /**\n   * Return the appropriate typewriter type for a servicespec type\n   */\n  public typeFromProperty(property: Property): Type {\n    // For backwards compatibility reasons we always have to use the original type\n    return this.typeFromSpecType(this.typeHistoryFromProperty(property)[0]);\n  }\n\n  /**\n   * Return the appropriate typewriter type for a servicespec type for modern tags\n   * Unlike typeFromProperty, we want to default to use the newest type instead.\n   */\n  public typeFromPropertyForModernTags(property: Property): Type {\n    // For backwards compatibility reasons we always have to use the original type\n    const types = this.typeHistoryFromProperty(property);\n    return this.typeFromSpecType(types[types.length - 1]);\n  }\n\n  /**\n   * Return the full type history for a servicespec property\n   */\n  public typeHistoryFromProperty(property: Property): PropertyType[] {\n    // For backwards compatibility reasons we always have to use the original type\n    return new RichProperty(property).types();\n  }\n\n  /**\n   * Convert a spec Type to a typewriter Type\n   */\n  public typeFromSpecType(type: PropertyType): Type {\n    const converted = ((): Type => {\n      switch (type?.type) {\n        case 'string':\n          return Type.STRING;\n        case 'number':\n        case 'integer':\n          return Type.NUMBER;\n        case 'boolean':\n          return Type.BOOLEAN;\n        case 'date-time':\n          return Type.DATE_TIME;\n        case 'array':\n          return Type.arrayOf(this.typeFromSpecType(type.element));\n        case 'map':\n          return Type.mapOf(this.typeFromSpecType(type.element));\n        case 'ref':\n          const ref = !this.isEventBridgeType ?\n            this.db.get('typeDefinition', type.reference.$ref)\n            : this.db.get('eventTypeDefinition', type.reference.$ref);\n          return this.convertTypeDefinitionType(ref).type;\n        case 'tag':\n          return CDK_CORE.CfnTag;\n        case 'union':\n          return Type.unionOf(...type.types.map((t) => this.typeFromSpecType(t)));\n        case 'null':\n          return Type.UNDEFINED;\n        case 'tag':\n          return CDK_CORE.CfnTag;\n        case 'json':\n          return Type.ANY;\n      }\n    })();\n    this.originalTypes.set(converted, type);\n    return converted;\n  }\n\n  public originalType(type: Type): PropertyType {\n    const ret = this.originalTypes.get(type);\n    if (!ret) {\n      throw new Error(`Don't know original type for ${type}`);\n    }\n    return ret;\n  }\n\n  public convertTypeDefinitionType(ref: TypeDefinition): TypeDeclaration {\n    const existing = this.typeDefCache.get(ref);\n    if (existing) {\n      return existing;\n    }\n\n    const ret = this.typeDefinitionConverter(ref, this);\n    // First stage: hold on to this type so we can resolve recursive references eagerly\n    this.typeDefCache.set(ref, ret.structType);\n    // Finish building it\n    ret.build();\n    return ret.structType;\n  }\n\n  /**\n   * For a given type, returned a resolvable version of the type\n   *\n   * We do this by checking if the type can be represented directly by a Token (e.g. `Token.asList(value))`).\n   * If not we recursively apply a type union with `cdk.IResolvable` to the type.\n   */\n  public makeTypeResolvable(type: Type): Type {\n    if (isTokenizableType(type)) {\n      return type;\n    }\n\n    if (type.primitive) {\n      return Type.unionOf(type, CDK_CORE.IResolvable);\n    }\n\n    if (type.arrayOfType) {\n      return Type.unionOf(Type.arrayOf(this.makeTypeResolvable(type.arrayOfType)), CDK_CORE.IResolvable);\n    }\n\n    if (type.mapOfType) {\n      return Type.unionOf(Type.mapOf(this.makeTypeResolvable(type.mapOfType)), CDK_CORE.IResolvable);\n    }\n\n    if (type.unionOfTypes) {\n      return Type.distinctUnionOf(...type.unionOfTypes.map((t) => this.makeTypeResolvable(t)), CDK_CORE.IResolvable);\n    }\n\n    return Type.unionOf(type, CDK_CORE.IResolvable);\n  }\n}", "language": "typescript"}
{"input": "Defines how the model should choose which tool to use.", "output": "export class ToolChoice {\n  /**\n   * The model must request at least one tool (no text is generated).\n   */\n  public static readonly ANY = new ToolChoice({}, undefined, undefined);\n\n  /**\n   * (Default). The Model automatically decides if a tool should be called or whether to generate text instead.\n   */\n  public static readonly AUTO = new ToolChoice(undefined, {}, undefined);\n\n  /**\n   * The Model must request the specified tool. Only supported by some models like Anthropic Claude 3 models.\n   *\n   * @param toolName - The name of the specific tool to use\n   * @returns A ToolChoice instance configured for the specific tool\n   */\n  public static specificTool(toolName: string): ToolChoice {\n    return new ToolChoice(undefined, undefined, toolName);\n  }\n\n  /**\n   * Configuration for ANY tool choice.\n   */\n  public readonly any?: any;\n\n  /**\n   * Configuration for AUTO tool choice.\n   */\n  public readonly auto?: any;\n\n  /**\n   * The specific tool name if using specific tool choice.\n   */\n  public readonly tool?: string;\n\n  constructor(any: any, auto: any, tool?: string) {\n    this.any = any;\n    this.auto = auto;\n    this.tool = tool;\n  }\n\n  /**\n   * Renders the tool choice as a CloudFormation property.\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): CfnPrompt.ToolChoiceProperty {\n    return {\n      any: this.any,\n      auto: this.auto,\n      tool: this.tool !== undefined ? { name: this.tool } : undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class Script for AWS resource management", "output": "export class Script extends ScriptBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-gamelift-alpha.Script';\n\n  /**\n   * Create a new realtime server script from s3 content\n   */\n  static fromBucket(scope: Construct, id: string, bucket: s3.IBucket, key: string, objectVersion?: string) {\n    return new Script(scope, id, {\n      content: Content.fromBucket(bucket, key, objectVersion),\n    });\n  }\n\n  /**\n   * Create a new realtime server script from asset content\n   */\n  static fromAsset(scope: Construct, id: string, path: string, options?: s3_assets.AssetOptions) {\n    return new Script(scope, id, {\n      content: Content.fromAsset(path, options),\n    });\n  }\n\n  /**\n   * Import a script into CDK using its ARN\n   */\n  static fromScriptArn(scope: Construct, id: string, scriptArn: string): IScript {\n    return this.fromScriptAttributes(scope, id, { scriptArn });\n  }\n\n  /**\n   * Import an existing realtime server script from its attributes.\n   */\n  static fromScriptAttributes(scope: Construct, id: string, attrs: ScriptAttributes): IScript {\n    const scriptArn = attrs.scriptArn;\n    const scriptId = extractIdFromArn(attrs.scriptArn);\n    const role = attrs.role;\n\n    class Import extends ScriptBase {\n      public readonly scriptArn = scriptArn;\n      public readonly scriptId = scriptId;\n      public readonly grantPrincipal:iam.IPrincipal;\n      public readonly role = role;\n\n      constructor(s: Construct, i: string) {\n        super(s, i, {\n          environmentFromArn: scriptArn,\n        });\n\n        this.grantPrincipal = this.role || new iam.UnknownPrincipal({ resource: this });\n      }\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The Identifier of the realtime server script.\n   */\n  public readonly scriptId: string;\n\n  /**\n   * The ARN of the realtime server script.\n   */\n  public readonly scriptArn: string;\n\n  /**\n   * The IAM role GameLift assumes to acccess server script content.\n   */\n  public readonly role: iam.IRole;\n\n  /**\n   * The principal this GameLift script is using.\n   */\n  public readonly grantPrincipal: iam.IPrincipal;\n\n  constructor(scope: Construct, id: string, props: ScriptProps) {\n    super(scope, id, {\n      physicalName: props.scriptName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.scriptName && !cdk.Token.isUnresolved(props.scriptName)) {\n      if (props.scriptName.length > 1024) {\n        throw new Error(`Script name can not be longer than 1024 characters but has ${props.scriptName.length} characters.`);\n      }\n    }\n    this.role = props.role ?? new iam.Role(this, 'ServiceRole', {\n      assumedBy: new iam.ServicePrincipal('gamelift.amazonaws.com'),\n    });\n    this.grantPrincipal = this.role;\n    const content = props.content.bind(this, this.role);\n\n    const resource = new CfnScript(this, 'Resource', {\n      name: props.scriptName,\n      version: props.scriptVersion,\n      storageLocation: {\n        bucket: content.s3Location && content.s3Location.bucketName,\n        key: content.s3Location && content.s3Location.objectKey,\n        objectVersion: content.s3Location && content.s3Location.objectVersion,\n        roleArn: this.role.roleArn,\n      },\n    });\n\n    this.scriptId = this.getResourceNameAttribute(resource.ref);\n    this.scriptArn = this.getResourceArnAttribute(resource.attrArn, {\n      service: 'gamelift',\n      resource: `script/${this.physicalName}`,\n      arnFormat: cdk.ArnFormat.COLON_RESOURCE_NAME,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class DashboardWithGraphWidgetWithStatisticIntegrationTest for AWS resource management", "output": "class DashboardWithGraphWidgetWithStatisticIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const dashboard = new Dashboard(this, 'Dash');\n\n    const widget = new GraphWidget({\n      title: 'My fancy graph',\n      left: [\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 1 - p99',\n          statistic: Stats.p(99),\n        }),\n\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 2 - TC_10P_90P',\n          statistic: Stats.tc(10, 90),\n        }),\n\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 3 - TS(5%:95%)',\n          statistic: 'TS(5%:95%)',\n        }),\n      ],\n      right: [\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric right 1 - p90.1234',\n          statistic: 'p90.1234',\n        }),\n      ],\n    });\n\n    dashboard.addWidgets(widget);\n  }\n}", "language": "typescript"}
{"input": "CDK class Image for AWS resource management", "output": "export class Image extends ImageBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.Image';\n\n  /**\n   * Import an existing image given its ARN\n   */\n  public static fromImageArn(scope: Construct, id: string, imageArn: string): IImage {\n    return this.fromImageAttributes(scope, id, { imageArn });\n  }\n\n  /**\n   * Import an existing image given its name. The provided name must be normalized by converting all alphabetical\n   * characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromImageName(scope: Construct, id: string, imageName: string): IImage {\n    return this.fromImageAttributes(scope, id, { imageName });\n  }\n\n  /**\n   * Import an existing image by providing its attributes. If the image name is provided as an attribute, it must be\n   * normalized by converting all alphabetical characters to lowercase, and replacing all spaces and underscores with\n   * hyphens.\n   */\n  public static fromImageAttributes(scope: Construct, id: string, attrs: ImageAttributes): IImage {\n    if (!attrs.imageArn && !attrs.imageName) {\n      throw new cdk.ValidationError('either imageArn or imageName is required', scope);\n    }\n\n    const imageArn =\n      attrs.imageArn ??\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'image',\n        resourceName: `${attrs.imageName}/${attrs.imageVersion ?? LATEST_VERSION}`,\n      });\n\n    const [imageName, imageVersion] = (() => {\n      if (attrs.imageName) {\n        return [attrs.imageName, attrs.imageVersion ?? LATEST_VERSION];\n      }\n\n      const imageNameVersion = cdk.Stack.of(scope).splitArn(imageArn, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName!;\n\n      const imageNameVersionSplit = cdk.Fn.split('/', imageNameVersion);\n      return [cdk.Fn.select(0, imageNameVersionSplit), cdk.Fn.select(1, imageNameVersionSplit)];\n    })();\n\n    class Import extends ImageBase {\n      public readonly imageArn = imageArn;\n      public readonly imageName = imageName;\n      public readonly imageVersion = imageVersion;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Return whether the given object is an Image.\n   */\n  public static isImage(x: any): x is Image {\n    return x !== null && typeof x === 'object' && IMAGE_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the image\n   */\n  public readonly imageArn: string;\n\n  /**\n   * The name of the image\n   */\n  public readonly imageName: string;\n\n  /**\n   * The version of the image\n   */\n  public readonly imageVersion: string;\n\n  /**\n   * The AMI ID of the EC2 AMI, or URI for the container\n   *\n   * @attribute\n   */\n  public readonly imageId: string;\n\n  /**\n   * The infrastructure configuration used for the image build\n   */\n  public readonly infrastructureConfiguration: IInfrastructureConfiguration;\n\n  /**\n   * The execution role used for the image build\n   */\n  public readonly executionRole?: iam.IRole;\n\n  private readonly props: ImageProps;\n\n  public constructor(scope: Construct, id: string, props: ImageProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, IMAGE_SYMBOL, { value: true });\n\n    this.props = props;\n\n    this.infrastructureConfiguration =\n      props.infrastructureConfiguration ?? new InfrastructureConfiguration(this, 'InfrastructureConfiguration');\n\n    this.executionRole = getExecutionRole(\n      this,\n      (grantee: iam.IGrantable) => this.grantDefaultExecutionRolePermissions(grantee),\n      {\n        ...props,\n        imageLogGroup: props.logGroup,\n      },\n    );\n\n    const [image, recipe] = this.createImageFromRecipe(props);\n\n    this.imageName = this.getResourceNameAttribute(image.attrName);\n    this.imageArn = image.attrArn;\n\n    if (recipe._isImageRecipe()) {\n      this.imageId = image.attrImageId;\n      this.imageVersion = recipe.imageRecipeVersion;\n    } else if (recipe._isContainerRecipe()) {\n      this.imageId = image.attrImageUri;\n      this.imageVersion = recipe.containerRecipeVersion;\n    } else {\n      throw new cdk.ValidationError('recipe must either be an image recipe or container recipe', this);\n    }\n  }\n\n  /**\n   * Grants the default permissions for building an image to the provided execution role.\n   *\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The execution role used for the image build.\n   */\n  @MethodMetadata()\n  public grantDefaultExecutionRolePermissions(grantee: iam.IGrantable): iam.Grant[] {\n    const policies = defaultExecutionRolePolicy(this, this.props);\n    return policies.map((policy) =>\n      iam.Grant.addToPrincipal({\n        grantee: grantee,\n        resourceArns: policy.resources,\n        actions: policy.actions,\n        conditions: policy.conditions,\n        scope: this,\n      }),\n    );\n  }\n\n  /**\n   * Creates a CfnImage resource from the recipe and props provided.\n   *\n   * @param props Props input for the construct\n   * @private\n   */\n  private createImageFromRecipe(props: ImageProps): [CfnImage, IRecipeBase] {\n    const recipe = props.recipe;\n    if (InfrastructureConfiguration.isInfrastructureConfiguration(this.infrastructureConfiguration)) {\n      this.infrastructureConfiguration._bind({ isContainerBuild: recipe._isContainerRecipe() });\n    }\n\n    if (recipe._isImageRecipe() && recipe._isContainerRecipe()) {\n      throw new cdk.ValidationError('the recipe cannot be both an IImageRecipe and an IContainerRecipe', this);\n    }\n\n    if (!recipe._isImageRecipe() && !recipe._isContainerRecipe()) {\n      throw new cdk.ValidationError('the recipe must either be an IImageRecipe or IContainerRecipe', this);\n    }\n\n    const image = new CfnImage(this, 'Resource', {\n      ...(recipe._isImageRecipe() && { imageRecipeArn: recipe.imageRecipeArn }),\n      ...(recipe._isContainerRecipe() && { containerRecipeArn: recipe.containerRecipeArn }),\n      infrastructureConfigurationArn: this.infrastructureConfiguration.infrastructureConfigurationArn,\n      distributionConfigurationArn: props.distributionConfiguration?.distributionConfigurationArn,\n      executionRole: this.executionRole?.roleArn,\n      enhancedImageMetadataEnabled: props.enhancedImageMetadataEnabled,\n      loggingConfiguration: this.buildLoggingConfiguration(props),\n      imageTestsConfiguration: buildImageTestsConfiguration<ImageProps, CfnImage.ImageTestsConfigurationProperty>(\n        props,\n      ),\n      imageScanningConfiguration: buildImageScanningConfiguration<\n        ImageProps,\n        CfnImage.ImageScanningConfigurationProperty\n      >(this, props),\n      workflows: buildWorkflows<ImageProps, CfnImage.WorkflowConfigurationProperty[]>(props),\n      deletionSettings: this.buildDeletionSettings(props),\n      tags: props.tags,\n    });\n\n    return [image, recipe];\n  }\n\n  /**\n   * Generates the loggingConfiguration property into the `LoggingConfiguration` type in the CloudFormation L1\n   * definition.\n   *\n   * @param props Props input for the construct\n   */\n  private buildLoggingConfiguration(props: ImageProps): CfnImage.ImageLoggingConfigurationProperty | undefined {\n    if (!props.logGroup) {\n      return undefined;\n    }\n\n    return { logGroupName: props.logGroup.logGroupName };\n  }\n\n  /**\n   * Generates the deletionSettings property into the `DeletionSettings` type in the CloudFormation L1 definition.\n   *\n   * @param props Props input for the construct\n   */\n  private buildDeletionSettings(props: ImageProps): CfnImage.DeletionSettingsProperty | undefined {\n    if (props.deletionExecutionRole === undefined) {\n      return undefined;\n    }\n\n    return { executionRole: props.deletionExecutionRole.roleArn };\n  }\n}", "language": "typescript"}
{"input": "CDK class Pipe for AWS resource management", "output": "export class Pipe extends PipeBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-pipes-alpha.Pipe';\n\n  /**\n   * Creates a pipe from the name of a pipe.\n   */\n  static fromPipeName(scope: Construct, id: string, pipeName: string): IPipe {\n    return new ImportedPipe(scope, id, pipeName);\n  }\n\n  public readonly pipeName: string;\n  public readonly pipeArn: string;\n  public readonly pipeRole: IRole;\n\n  constructor(scope: Construct, id: string, props: PipeProps) {\n    super(scope, id, { physicalName: props.pipeName });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    /**\n     * Role setup\n     */\n    this.pipeRole =\n      props.role ||\n      new Role(this, 'Role', {\n        assumedBy: new ServicePrincipal('pipes.amazonaws.com'),\n      });\n\n    /**\n     * Source / Filter setup\n     */\n    const source = props.source.bind(this);\n    props.source.grantRead(this.pipeRole);\n\n    /**\n     * An optional dead-letter queue stores any events that are not successfully delivered to\n     * a target after all retry attempts are exhausted. The IAM role needs permission to write\n     * events to the dead-letter queue, either an SQS queue or SNS topic.\n     */\n    if (SourceWithDeadLetterTarget.isSourceWithDeadLetterTarget(props.source)) {\n      props.source.grantPush(this.pipeRole, props.source.deadLetterTarget);\n    }\n\n    // Add the filter criteria to the source parameters\n    const sourceParameters : CfnPipe.PipeSourceParametersProperty= {\n      ...source.sourceParameters,\n      filterCriteria: props.filter,\n    };\n\n    /**\n     * Enrichment setup\n     */\n    const enrichment = props.enrichment?.bind(this);\n    props.enrichment?.grantInvoke(this.pipeRole);\n\n    /**\n     * Target setup\n     */\n    const target = props.target.bind(this);\n    props.target.grantPush(this.pipeRole);\n\n    /**\n     * Logs setup\n     */\n    const initialLogConfiguration: CfnPipe.PipeLogConfigurationProperty = {\n      level: props.logLevel || LogLevel.ERROR,\n      includeExecutionData: props.logIncludeExecutionData || undefined,\n    };\n\n    // Iterate over all the log destinations and add them to the log configuration\n    const logConfiguration = props.logDestinations?.reduce((currentLogConfiguration, destination) => {\n      const logDestinationConfig = destination.bind(this);\n      destination.grantPush(this.pipeRole);\n      const additionalLogConfiguration = logDestinationConfig.parameters;\n      return { ...currentLogConfiguration, ...additionalLogConfiguration };\n    }, initialLogConfiguration);\n\n    if (props.kmsKey) {\n      if (!props.pipeName) {\n        throw new ValidationError('`pipeName` is required when specifying a `kmsKey` prop.', this);\n      }\n      // Add permissions to the KMS key\n      // see https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-encryption-pipes-cmkey.html#eb-encryption-key-policy-pipe\n      props.kmsKey.addToResourcePolicy(\n        new PolicyStatement({\n          actions: ['kms:Decrypt', 'kms:DescribeKey', 'kms:GenerateDataKey'],\n          resources: ['*'],\n          principals: [new ArnPrincipal(this.pipeRole.roleArn)],\n          conditions: {\n            'ArnLike': {\n              'kms:EncryptionContext:aws:pipe:arn': Stack.of(this).formatArn({\n                service: 'pipes',\n                resource: 'pipe',\n                resourceName: props.pipeName,\n              }),\n            },\n            'ForAnyValue:StringEquals': {\n              'kms:EncryptionContextKeys': [\n                'aws:pipe:arn',\n              ],\n            },\n          },\n        }),\n      );\n    }\n\n    /**\n     * Pipe resource\n     */\n    const resource = new CfnPipe(this, 'Resource', {\n      name: props.pipeName,\n      description: props.description,\n      roleArn: this.pipeRole.roleArn,\n      source: props.source.sourceArn,\n      sourceParameters: sourceParameters,\n      enrichment: props.enrichment?.enrichmentArn,\n      enrichmentParameters: enrichment?.enrichmentParameters,\n      target: props.target.targetArn,\n      targetParameters: target.targetParameters,\n      desiredState: props.desiredState,\n      logConfiguration: logConfiguration,\n      kmsKeyIdentifier: props.kmsKey?.keyArn,\n      tags: props.tags,\n    });\n\n    this.pipeName = resource.ref;\n    this.pipeArn = resource.attrArn;\n  }\n}", "language": "typescript"}
{"input": "CDK class NoSynthResource for AWS resource management", "output": "class NoSynthResource extends core.CfnResource {\n        protected shouldSynthesize(): boolean {\n          return false;\n        }\n      }", "language": "typescript"}
{"input": "CDK helper function for CloudWatch Logs operations", "output": "def __init__(self, scope: Construct, id: str, bucket_name):\n        super().__init__(scope, id)\n\n        res = AwsCustomResource(\n            scope=self,\n            id='AWSCustomResource',\n            policy=AwsCustomResourcePolicy.from_sdk_calls(resources=[f'arn:aws:s3:::{bucket_name}/*']),\n            log_retention=logs.RetentionDays.INFINITE,\n            on_create=self.create(bucket_name),\n            on_delete=self.delete(bucket_name),\n            resource_type='Custom::MyCustomResource'\n        )", "language": "python"}
{"input": "CloudFormation intrinsic functions. http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference.html", "output": "export class Fn {\n  /**\n   * The ``Ref`` intrinsic function returns the value of the specified parameter or resource.\n   * Note that it doesn't validate the logicalName, it mainly serves parameter/resource reference defined in a ``CfnInclude`` template.\n   * @param logicalName The logical name of a parameter/resource for which you want to retrieve its value.\n   */\n  public static ref(logicalName: string): string {\n    return new FnRef(logicalName).toString();\n  }\n\n  /**\n   * The ``Fn::GetAtt`` intrinsic function returns the value of an attribute\n   * from a resource in the template.\n   * @param logicalNameOfResource The logical name (also called logical ID) of\n   * the resource that contains the attribute that you want.\n   * @param attributeName The name of the resource-specific attribute whose\n   * value you want. See the resource's reference page for details about the\n   * attributes available for that resource type.\n   * @returns an IResolvable object\n   */\n  public static getAtt(logicalNameOfResource: string, attributeName: string): IResolvable {\n    return new FnGetAtt(logicalNameOfResource, attributeName);\n  }\n\n  /**\n   * The intrinsic function ``Fn::Join`` appends a set of values into a single\n   * value, separated by the specified delimiter. If a delimiter is the empty\n   * string, the set of values are concatenated with no delimiter.\n   * @param delimiter The value you want to occur between fragments. The\n   * delimiter will occur between fragments only. It will not terminate the\n   * final value.\n   * @param listOfValues The list of values you want combined.\n   * @returns a token represented as a string\n   */\n  public static join(delimiter: string, listOfValues: string[]): string {\n    if (listOfValues.length === 0) {\n      throw new UnscopedValidationError('FnJoin requires at least one value to be provided');\n    }\n\n    return new FnJoin(delimiter, listOfValues).toString();\n  }\n\n  /**\n   * Split a string token into a token list of string values.\n   *\n   * Specify the location of splits with a delimiter such as ',' (a comma).\n   * Renders to the `Fn::Split` intrinsic function.\n   *\n   * Lists with unknown lengths (default)\n   * -------------------------------------\n   *\n   * Since this function is used to work with deploy-time values, if `assumedLength`\n   * is not given the CDK cannot know the length of the resulting list at synthesis time.\n   * This brings the following restrictions:\n   *\n   * - You must use `Fn.select(i, list)` to pick elements out of the list (you must not use\n   *   `list[i]`).\n   * - You cannot add elements to the list, remove elements from the list,\n   *   combine two such lists together, or take a slice of the list.\n   * - You cannot pass the list to constructs that do any of the above.\n   *\n   * The only valid operation with such a tokenized list is to pass it unmodified to a\n   * CloudFormation Resource construct.\n   *\n   * Lists with assumed lengths\n   * --------------------------\n   *\n   * Pass `assumedLength` if you know the length of the list that will be\n   * produced by splitting. The actual list length at deploy time may be\n   * *longer* than the number you pass, but not *shorter*.\n   *\n   * The returned list will look like:\n   *\n   * ```\n   * [Fn.select(0, split), Fn.select(1, split), Fn.select(2, split), ...]\n   * ```\n   *\n   * The restrictions from the section \"Lists with unknown lengths\" will now be lifted,\n   * at the expense of having to know and fix the length of the list.\n   *\n   * @param delimiter A string value that determines where the source string is divided.\n   * @param source The string value that you want to split.\n   * @param assumedLength The length of the list that will be produced by splitting\n   * @returns a token represented as a string array\n   */\n  public static split(delimiter: string, source: string, assumedLength?: number): string[] {\n    // short-circuit if source is not a token\n    if (!Token.isUnresolved(source)) {\n      return source.split(delimiter);\n    }\n\n    if (Token.isUnresolved(delimiter)) {\n      // Limitation of CloudFormation\n      throw new UnscopedValidationError('Fn.split: \\'delimiter\\' may not be a token value');\n    }\n\n    const split = Token.asList(new FnSplit(delimiter, source));\n    if (assumedLength === undefined) {\n      return split;\n    }\n\n    if (Token.isUnresolved(assumedLength)) {\n      throw new UnscopedValidationError('Fn.split: \\'assumedLength\\' may not be a token value');\n    }\n\n    return range(assumedLength).map(i => Fn.select(i, split));\n  }\n\n  /**\n   * The intrinsic function ``Fn::Select`` returns a single object from a list of objects by index.\n   * @param index The index of the object to retrieve. This must be a value from zero to N-1, where N represents the number of elements in the array.\n   * @param array The list of objects to select from. This list must not be null, nor can it have null entries.\n   * @returns a token represented as a string\n   */\n  public static select(index: number, array: string[]): string {\n    if (!Token.isUnresolved(index) && !Token.isUnresolved(array) && !array.some(Token.isUnresolved)) {\n      return array[index];\n    }\n\n    return new FnSelect(index, array).toString();\n  }\n\n  /**\n   * The intrinsic function ``Fn::Sub`` substitutes variables in an input string\n   * with values that you specify. In your templates, you can use this function\n   * to construct commands or outputs that include values that aren't available\n   * until you create or update a stack.\n   * @param body A string with variables that AWS CloudFormation substitutes\n   * with their associated values at runtime. Write variables as ${MyVarName}.\n   * Variables can be template parameter names, resource logical IDs, resource\n   * attributes, or a variable in a key-value map. If you specify only template\n   * parameter names, resource logical IDs, and resource attributes, don't\n   * specify a key-value map.\n   * @param variables The name of a variable that you included in the String\n   * parameter. The value that AWS CloudFormation substitutes for the associated\n   * variable name at runtime.\n   * @returns a token represented as a string\n   */\n  public static sub(body: string, variables?: { [key: string]: string }): string {\n    return new FnSub(body, variables).toString();\n  }\n\n  /**\n   * The intrinsic function ``Fn::Base64`` returns the Base64 representation of\n   * the input string. This function is typically used to pass encoded data to\n   * Amazon EC2 instances by way of the UserData property.\n   * @param data The string value you want to convert to Base64.\n   * @returns a token represented as a string\n   */\n  public static base64(data: string): string {\n    return new FnBase64(data).toString();\n  }\n\n  /**\n   * The intrinsic function ``Fn::Cidr`` returns the specified Cidr address block.\n   * @param ipBlock  The user-specified default Cidr address block.\n   * @param count  The number of subnets' Cidr block wanted. Count can be 1 to 256.\n   * @param sizeMask The digit covered in the subnet.\n   * @returns a token represented as a string\n   */\n  public static cidr(ipBlock: string, count: number, sizeMask?: string): string[] {\n    return Token.asList(new FnCidr(ipBlock, count, sizeMask));\n  }\n\n  /**\n   * Given an url, parse the domain name\n   * @param url the url to parse\n   */\n  public static parseDomainName(url: string): string {\n    const noHttps = Fn.select(1, Fn.split('//', url));\n    return Fn.select(0, Fn.split('/', noHttps));\n  }\n\n  /**\n   * The intrinsic function ``Fn::GetAZs`` returns an array that lists\n   * Availability Zones for a specified region. Because customers have access to\n   * different Availability Zones, the intrinsic function ``Fn::GetAZs`` enables\n   * template authors to write templates that adapt to the calling user's\n   * access. That way you don't have to hard-code a full list of Availability\n   * Zones for a specified region.\n   * @param region The name of the region for which you want to get the\n   * Availability Zones. You can use the AWS::Region pseudo parameter to specify\n   * the region in which the stack is created. Specifying an empty string is\n   * equivalent to specifying AWS::Region.\n   * @returns a token represented as a string array\n   */\n  public static getAzs(region?: string): string[] {\n    return Token.asList(new FnGetAZs(region));\n  }\n\n  /**\n   * The intrinsic function ``Fn::ImportValue`` returns the value of an output\n   * exported by another stack. You typically use this function to create\n   * cross-stack references. In the following example template snippets, Stack A\n   * exports VPC security group values and Stack B imports them.\n   * @param sharedValueToImport The stack output value that you want to import.\n   * @returns a token represented as a string\n   */\n  public static importValue(sharedValueToImport: string): string {\n    return new FnImportValue(sharedValueToImport).toString();\n  }\n\n  /**\n   * Like `Fn.importValue`, but import a list with a known length\n   *\n   * If you explicitly want a list with an unknown length, call `Fn.split(',',\n   * Fn.importValue(exportName))`. See the documentation of `Fn.split` to read\n   * more about the limitations of using lists of unknown length.\n   *\n   * `Fn.importListValue(exportName, assumedLength)` is the same as\n   * `Fn.split(',', Fn.importValue(exportName), assumedLength)`,\n   * but easier to read and impossible to forget to pass `assumedLength`.\n   */\n  public static importListValue(sharedValueToImport: string, assumedLength: number, delimiter = ','): string[] {\n    return Fn.split(delimiter, Fn.importValue(sharedValueToImport), assumedLength);\n  }\n\n  /**\n   * The intrinsic function ``Fn::FindInMap`` returns the value corresponding to\n   * keys in a two-level map that is declared in the Mappings section.\n   * Warning: do not use with lazy mappings as this function will not guarentee a lazy mapping to render in the template.\n   * Prefer to use `CfnMapping.findInMap` in general.\n   * @returns a token represented as a string\n   */\n  public static findInMap(mapName: string, topLevelKey: string, secondLevelKey: string, defaultValue?: string): string {\n    return Fn._findInMap(mapName, topLevelKey, secondLevelKey, defaultValue).toString();\n  }\n\n  /**\n   * An additional function used in CfnParser,\n   * as Fn::FindInMap does not always return a string.\n   *\n   * @internal\n   */\n  public static _findInMap(mapName: string, topLevelKey: string, secondLevelKey: string, defaultValue?: string): IResolvable {\n    return new FnFindInMap(mapName, topLevelKey, secondLevelKey, defaultValue);\n  }\n\n  /**\n   * Creates a token representing the ``Fn::Transform`` expression\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-transform.html\n   * @param macroName The name of the macro to perform the processing\n   * @param parameters The parameters to be passed to the macro\n   * @returns a token representing the transform expression\n   */\n  public static transform(macroName: string, parameters: { [name: string]: any }): IResolvable {\n    return new FnTransform(macroName, parameters);\n  }\n\n  /**\n   * Returns true if all the specified conditions evaluate to true, or returns\n   * false if any one of the conditions evaluates to false. ``Fn::And`` acts as\n   * an AND operator. The minimum number of conditions that you can include is\n   * 1.\n   * @param conditions conditions to AND\n   * @returns an FnCondition token\n   */\n  public static conditionAnd(...conditions: ICfnConditionExpression[]): ICfnRuleConditionExpression {\n    if (conditions.length === 0) {\n      throw new UnscopedValidationError('Fn.conditionAnd() needs at least one argument');\n    }\n    if (conditions.length === 1) {\n      return conditions[0] as ICfnRuleConditionExpression;\n    }\n    if (conditions.length <= 10) {\n      return new FnAnd(...conditions);\n    }\n    return Fn.conditionAnd(..._inGroupsOf(conditions, 10).map(group => Fn.conditionAnd(...group)));\n  }\n\n  /**\n   * Compares if two values are equal. Returns true if the two values are equal\n   * or false if they aren't.\n   * @param lhs A value of any type that you want to compare.\n   * @param rhs A value of any type that you want to compare.\n   * @returns an FnCondition token\n   */\n  public static conditionEquals(lhs: any, rhs: any): ICfnRuleConditionExpression {\n    return new FnEquals(lhs, rhs);\n  }\n\n  /**\n   * Returns one value if the specified condition evaluates to true and another\n   * value if the specified condition evaluates to false. Currently, AWS\n   * CloudFormation supports the ``Fn::If`` intrinsic function in the metadata\n   * attribute, update policy attribute, and property values in the Resources\n   * section and Outputs sections of a template. You can use the AWS::NoValue\n   * pseudo parameter as a return value to remove the corresponding property.\n   * @param conditionId A reference to a condition in the Conditions section. Use\n   * the condition's name to reference it.\n   * @param valueIfTrue A value to be returned if the specified condition\n   * evaluates to true.\n   * @param valueIfFalse A value to be returned if the specified condition\n   * evaluates to false.\n   * @returns an FnCondition token\n   */\n  public static conditionIf(conditionId: string, valueIfTrue: any, valueIfFalse: any): ICfnRuleConditionExpression {\n    return new FnIf(conditionId, valueIfTrue, valueIfFalse);\n  }\n\n  /**\n   * Returns true for a condition that evaluates to false or returns false for a\n   * condition that evaluates to true. ``Fn::Not`` acts as a NOT operator.\n   * @param condition A condition such as ``Fn::Equals`` that evaluates to true\n   * or false.\n   * @returns an FnCondition token\n   */\n  public static conditionNot(condition: ICfnConditionExpression): ICfnRuleConditionExpression {\n    return new FnNot(condition);\n  }\n\n  /**\n   * Returns true if any one of the specified conditions evaluate to true, or\n   * returns false if all of the conditions evaluates to false. ``Fn::Or`` acts\n   * as an OR operator. The minimum number of conditions that you can include is\n   * 1.\n   * @param conditions conditions that evaluates to true or false.\n   * @returns an FnCondition token\n   */\n  public static conditionOr(...conditions: ICfnConditionExpression[]): ICfnRuleConditionExpression {\n    if (conditions.length === 0) {\n      throw new UnscopedValidationError('Fn.conditionOr() needs at least one argument');\n    }\n    if (conditions.length === 1) {\n      return conditions[0] as ICfnRuleConditionExpression;\n    }\n    if (conditions.length <= 10) {\n      return new FnOr(...conditions);\n    }\n    return Fn.conditionOr(..._inGroupsOf(conditions, 10).map(group => Fn.conditionOr(...group)));\n  }\n\n  /**\n   * Returns true if a specified string matches at least one value in a list of\n   * strings.\n   * @param listOfStrings A list of strings, such as \"A\", \"B\", \"C\".\n   * @param value A string, such as \"A\", that you want to compare against a list of strings.\n   * @returns an FnCondition token\n   */\n  public static conditionContains(listOfStrings: string[], value: string): ICfnRuleConditionExpression {\n    return new FnContains(listOfStrings, value);\n  }\n\n  /**\n   * Returns true if a specified string matches all values in a list.\n   * @param listOfStrings A list of strings, such as \"A\", \"B\", \"C\".\n   * @param value A string, such as \"A\", that you want to compare against a list\n   * of strings.\n   * @returns an FnCondition token\n   */\n  public static conditionEachMemberEquals(listOfStrings: string[], value: string): ICfnRuleConditionExpression {\n    return new FnEachMemberEquals(listOfStrings, value);\n  }\n\n  /**\n   * Returns true if each member in a list of strings matches at least one value\n   * in a second list of strings.\n   * @param stringsToCheck A list of strings, such as \"A\", \"B\", \"C\". AWS\n   * CloudFormation checks whether each member in the strings_to_check parameter\n   * is in the strings_to_match parameter.\n   * @param stringsToMatch A list of strings, such as \"A\", \"B\", \"C\". Each member\n   * in the strings_to_match parameter is compared against the members of the\n   * strings_to_check parameter.\n   * @returns an FnCondition token\n   */\n  public static conditionEachMemberIn(stringsToCheck: string[], stringsToMatch: string[]): ICfnRuleConditionExpression {\n    return new FnEachMemberIn(stringsToCheck, stringsToMatch);\n  }\n\n  /**\n   * Returns all values for a specified parameter type.\n   * @param parameterType An AWS-specific parameter type, such as\n   * AWS::EC2::SecurityGroup::Id or AWS::EC2::VPC::Id. For more information, see\n   * Parameters in the AWS CloudFormation User Guide.\n   * @returns a token represented as a string array\n   */\n  public static refAll(parameterType: string): string[] {\n    return Token.asList(new FnRefAll(parameterType));\n  }\n\n  /**\n   * Returns an attribute value or list of values for a specific parameter and\n   * attribute.\n   * @param parameterOrLogicalId The name of a parameter for which you want to\n   * retrieve attribute values. The parameter must be declared in the Parameters\n   * section of the template.\n   * @param attribute The name of an attribute from which you want to retrieve a\n   * value.\n   * @returns a token represented as a string\n   */\n  public static valueOf(parameterOrLogicalId: string, attribute: string): string {\n    return new FnValueOf(parameterOrLogicalId, attribute).toString();\n  }\n\n  /**\n   * Returns a list of all attribute values for a given parameter type and\n   * attribute.\n   * @param parameterType An AWS-specific parameter type, such as\n   * AWS::EC2::SecurityGroup::Id or AWS::EC2::VPC::Id. For more information, see\n   * Parameters in the AWS CloudFormation User Guide.\n   * @param attribute The name of an attribute from which you want to retrieve a\n   * value. For more information about attributes, see Supported Attributes.\n   * @returns a token represented as a string array\n   */\n  public static valueOfAll(parameterType: string, attribute: string): string[] {\n    return Token.asList(new FnValueOfAll(parameterType, attribute));\n  }\n\n  /**\n   * The `Fn::ToJsonString` intrinsic function converts an object or array to its\n   * corresponding JSON string.\n   *\n   * @param object The object or array to stringify\n   */\n  public static toJsonString(object: any): string {\n    // short-circuit if object is not a token\n    if (!Token.isUnresolved(object)) {\n      return JSON.stringify(object);\n    }\n    return new FnToJsonString(object).toString();\n  }\n\n  /**\n   * The intrinsic function `Fn::Length` returns the number of elements within an array\n   * or an intrinsic function that returns an array.\n   *\n   * @param array The array you want to return the number of elements from\n   */\n  public static len(array: any): number {\n    // short-circuit if array is not a token\n    if (!Token.isUnresolved(array)) {\n      if (!Array.isArray(array)) {\n        throw new UnscopedValidationError('Fn.length() needs an array');\n      }\n      return array.length;\n    }\n    return Token.asNumber(new FnLength(array));\n  }\n\n  /**\n   * Test whether the given object extends FnBase class.\n   *\n   * @internal\n   */\n  public static _isFnBase(x: any): x is FnBase {\n    return x !== null && typeof(x) === 'object' && FN_BASE_SYMBOL in x;\n  }\n\n  private constructor() { }\n}\n\nconst FN_BASE_SYMBOL = Symbol.for('@aws-cdk/core.CfnFnBase');\n\n/**\n * Base class for tokens that represent CloudFormation intrinsic functions.\n */\nclass FnBase extends Intrinsic {\n  constructor(name: string, value: any) {\n    super({ [name]: value });\n\n    Object.defineProperty(this, FN_BASE_SYMBOL, { value: true });\n  }\n}\n\n/**\n * The intrinsic function ``Ref`` returns the value of the specified parameter or resource.\n * When you specify a parameter's logical name, it returns the value of the parameter.\n * When you specify a resource's logical name, it returns a value that you can typically use to refer to that resource, such as a physical ID.\n */\nclass FnRef extends FnBase {\n  /**\n   * Creates an ``Ref`` function.\n   * @param logicalName The logical name of a parameter/resource for which you want to retrieve its value.\n   */\n  constructor(logicalName: string) {\n    super('Ref', logicalName);\n  }\n}\n\n/**\n * The intrinsic function ``Fn::FindInMap`` returns the value corresponding to keys in a two-level\n * map that is declared in the Mappings section.\n */\nclass FnFindInMap extends FnBase {\n  /**\n   * Creates an ``Fn::FindInMap`` function.\n   * @param mapName The logical name of a mapping declared in the Mappings section that contains the keys and values.\n   * @param topLevelKey The top-level key name. Its value is a list of key-value pairs.\n   * @param secondLevelKey The second-level key name, which is set to one of the keys from the list assigned to TopLevelKey.\n   * @param defaultValue The value of the default value returned if either the key is not found in the map\n   */\n\n  private readonly mapName: string;\n  private readonly topLevelKey: string;\n  private readonly secondLevelKey: string;\n  private readonly defaultValue?: string;\n\n  constructor(mapName: string, topLevelKey: any, secondLevelKey: any, defaultValue?: string) {\n    super('Fn::FindInMap', [mapName, topLevelKey, secondLevelKey, defaultValue !== undefined ? { DefaultValue: defaultValue } : undefined]);\n    this.mapName = mapName;\n    this.topLevelKey = topLevelKey;\n    this.secondLevelKey = secondLevelKey;\n    this.defaultValue = defaultValue;\n  }\n\n  public resolve(context: IResolveContext): any {\n    if (this.defaultValue !== undefined) {\n      Stack.of(context.scope).addTransform('AWS::LanguageExtensions');\n    }\n    return { 'Fn::FindInMap': [this.mapName, this.topLevelKey, this.secondLevelKey, this.defaultValue !== undefined ? { DefaultValue: this.defaultValue } : undefined] };\n  }\n}\n\n/**\n * The intrinsic function ``Fn::Transform`` specifies a macro to perform custom processing on part of a stack template.\n */\nclass FnTransform extends FnBase {\n  /**\n   * creates an ``Fn::Transform`` function.\n   * @param macroName The name of the macro to be invoked\n   * @param parameters the parameters to pass to it\n   */\n  constructor(macroName: string, parameters: { [name: string]: any }) {\n    super('Fn::Transform', { Name: macroName, Parameters: parameters });\n  }\n}\n\n/**\n * The ``Fn::GetAtt`` intrinsic function returns the value of an attribute from a resource in the template.\n */\nclass FnGetAtt extends FnBase {\n  /**\n   * Creates a ``Fn::GetAtt`` function.\n   * @param logicalNameOfResource The logical name (also called logical ID) of the resource that contains the attribute that you want.\n   * @param attributeName The name of the resource-specific attribute whose value you want. See the resource's reference page for details about the attributes available for that resource type.\n   */\n  constructor(logicalNameOfResource: string, attributeName: string) {\n    super('Fn::GetAtt', [logicalNameOfResource, attributeName]);\n  }\n}", "language": "typescript"}
{"input": "CDK class Ipam for AWS resource management", "output": "export class Ipam extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.Ipam';\n  /**\n   * Provides access to default public IPAM scope through add pool method.\n   * Usage: To add an Ipam Pool to a default public scope\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-ipamscope.html\n   */\n  public readonly publicScope: IIpamScopeBase;\n\n  /**\n   * Provides access to default private IPAM scope through add pool method.\n   * Usage: To add an Ipam Pool to a default private scope\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-ipamscope.html\n   * */\n  public readonly privateScope: IIpamScopeBase;\n\n  // Resource IPAM\n  private readonly _ipam: CfnIPAM;\n  /**\n   * Access to Ipam resource id that can be used later to add a custom private scope to this IPAM\n   * @attribute IpamId\n   */\n  public readonly ipamId: string;\n\n  /**\n   * List of operating regions for IPAM\n   */\n  public readonly operatingRegions: string[];\n\n  /**\n   * List of scopes created under this IPAM\n   */\n  public readonly scopes: IIpamScopeBase[] = [];\n\n  /**\n   * IPAM name to be used for tagging\n   * @default - no tag specified\n   * @attribute IpamName\n   */\n  public readonly ipamName?: string;\n\n  constructor(scope: Construct, id: string, props?: IpamProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    if (props?.ipamName) {\n      Tags.of(this).add(NAME_TAG, props.ipamName);\n    }\n    if (props?.operatingRegions && (props.operatingRegions.length === 0)) {\n      throw new Error('Please provide at least one operating region');\n    }\n\n    this.operatingRegions = props?.operatingRegions ?? [Stack.of(this).region];\n    this.ipamName = props?.ipamName;\n\n    this._ipam = new CfnIPAM(this, 'Ipam', {\n      operatingRegions: this.operatingRegions ? this.operatingRegions.map(region => ({ regionName: region })) : [],\n    });\n    this.node.defaultChild = this._ipam;\n\n    this.ipamId = this._ipam.attrIpamId;\n    this.publicScope = new IpamScopeBase(this, 'DefaultPublicScope', {\n      ipamOperatingRegions: this.operatingRegions,\n      ipamId: this._ipam.attrIpamId,\n      ipamScopeId: this._ipam.attrPublicDefaultScopeId,\n    });\n    this.privateScope = new IpamScopeBase(this, 'DefaultPrivateScope', {\n      ipamOperatingRegions: this.operatingRegions,\n      ipamId: this._ipam.attrIpamId,\n      ipamScopeId: this._ipam.attrPrivateDefaultScopeId,\n    });\n\n    this.scopes.push(this.publicScope, this.privateScope);\n  }\n\n  /**\n   * Function to add custom scope to an existing IPAM\n   * Custom scopes can only be private\n   */\n  @MethodMetadata()\n  public addScope(scope: Construct, id: string, options: IpamScopeOptions): IIpamScopeBase {\n    const ipamScope = new IpamScope(scope, id, {\n      ...options,\n      ipamId: this.ipamId,\n      ipamOperatingRegions: this.operatingRegions,\n    });\n    this.scopes.push(ipamScope);\n    return ipamScope;\n  }\n}", "language": "typescript"}
{"input": "CDK class EasyDkim for AWS resource management", "output": "class EasyDkim extends DkimIdentity {\n  constructor(private readonly signingKeyLength?: EasyDkimSigningKeyLength) {\n    super();\n  }\n\n  public bind(emailIdentity: EmailIdentity, hostedZone?: route53.IPublicHostedZone): DkimIdentityConfig | undefined {\n    if (hostedZone) {\n      // Use CfnRecordSet instead of CnameRecord to avoid current bad handling of\n      // tokens in route53.determineFullyQualifiedDomainName() at https://github.com/aws/aws-cdk/blob/main/packages/aws-cdk-lib/aws-route53/lib/util.ts\n      new route53.CfnRecordSet(emailIdentity, 'DkimDnsToken1', {\n        hostedZoneId: hostedZone.hostedZoneId,\n        name: Lazy.string({ produce: () => emailIdentity.dkimDnsTokenName1 }),\n        type: 'CNAME',\n        resourceRecords: [Lazy.string({ produce: () => emailIdentity.dkimDnsTokenValue1 })],\n        ttl: '1800',\n      });\n\n      new route53.CfnRecordSet(emailIdentity, 'DkimDnsToken2', {\n        hostedZoneId: hostedZone.hostedZoneId,\n        name: Lazy.string({ produce: () => emailIdentity.dkimDnsTokenName2 }),\n        type: 'CNAME',\n        resourceRecords: [Lazy.string({ produce: () => emailIdentity.dkimDnsTokenValue2 })],\n        ttl: '1800',\n      });\n\n      new route53.CfnRecordSet(emailIdentity, 'DkimDnsToken3', {\n        hostedZoneId: hostedZone.hostedZoneId,\n        name: Lazy.string({ produce: () => emailIdentity.dkimDnsTokenName3 }),\n        type: 'CNAME',\n        resourceRecords: [Lazy.string({ produce: () => emailIdentity.dkimDnsTokenValue3 })],\n        ttl: '1800',\n      });\n    }\n\n    return this.signingKeyLength\n      ? { nextSigningKeyLength: this.signingKeyLength }\n      : undefined;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, VPC, CloudFormation resources", "output": "class EC2DualStack extends cdk.Stack {\n  public readonly instancePublicIp: string;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Ip6VpcDualStack', {\n      ipProtocol: ec2.IpProtocol.DUAL_STACK,\n      subnetConfiguration: [\n        {\n          name: 'Public',\n          subnetType: ec2.SubnetType.PUBLIC,\n          mapPublicIpOnLaunch: true,\n        },\n        {\n          name: 'Private',\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n        },\n      ],\n      flowLogs: {\n        cloudwatchLogs: {\n          destination: ec2.FlowLogDestination.toCloudWatchLogs(),\n        },\n      },\n    });\n\n    const instance = new ec2.Instance(this, 'MyInstance', {\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.T2, ec2.InstanceSize.MICRO),\n      machineImage: ec2.MachineImage.latestAmazonLinux2(),\n      vpc: vpc,\n      vpcSubnets: { subnetType: ec2.SubnetType.PUBLIC },\n      allowAllIpv6Outbound: true,\n      init: ec2.CloudFormationInit.fromConfigSets({\n        configSets: {\n          default: ['default'],\n        },\n        configs: {\n          default: new ec2.InitConfig([\n            ec2.InitFile.fromAsset('/app/webserver.zip', path.join(__dirname, 'integ.vpc-dual-stack-ec2.assets')),\n            ec2.InitCommand.shellCommand('unzip webserver.zip', { cwd: '/app' }),\n            ec2.InitService.systemdConfigFile('webserver', {\n              command: '/usr/bin/python3 web-server.py',\n              cwd: '/app',\n            }),\n            ec2.InitService.enable('webserver', {\n              serviceManager: ec2.ServiceManager.SYSTEMD,\n            }),\n          ]),\n        },\n      }),\n    });\n\n    this.instancePublicIp = instance.instancePublicIp;\n\n    instance.connections.allowFromAnyIpv4(ec2.Port.tcp(22), 'Allow SSH access');\n    instance.connections.allowFromAnyIpv4(ec2.Port.tcp(8000), 'HTTP traffic');\n    instance.connections.allowFromAnyIpv4(ec2.Port.icmpPing());\n    instance.connections.allowFrom(ec2.Peer.anyIpv6(), ec2.Port.allIcmpV6(), 'allow ICMP6');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates SNS, CloudWatch, CloudFormation resources", "output": "class HealthcheckAlarmStack(Stack):\n  def __init__(self, scope: Construct, construct_id: str, zone: route53.HostedZone, primaryLoadBalancer: elbv2.ILoadBalancerV2, secondaryLoadBalancer: elbv2.ILoadBalancerV2, email: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # primary record\n        primaryHealthCheck = route53.CfnHealthCheck(self, \"DNSPrimaryHealthCheck\", health_check_config=route53.CfnHealthCheck.HealthCheckConfigProperty(\n            fully_qualified_domain_name=primaryLoadBalancer.load_balancer_dns_name,\n            type=\"HTTP\",\n            port=80\n        ))\n        primary = route53.ARecord(self, \"PrimaryRecordSet\",\n            zone = zone,\n            record_name=\"failover\",\n            target = route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(primaryLoadBalancer)),\n        )\n        primaryRecordSet = primary.node.default_child\n        primaryRecordSet.failover = \"PRIMARY\"\n        primaryRecordSet.health_check_id = primaryHealthCheck.attr_health_check_id\n        primaryRecordSet.set_identifier = \"Primary\"\n\n        # secondary record\n        secondaryHealthCheck = route53.CfnHealthCheck(self, \"DNSSecondaryHealthCheck\", health_check_config=route53.CfnHealthCheck.HealthCheckConfigProperty(\n            fully_qualified_domain_name=secondaryLoadBalancer.load_balancer_dns_name,\n            type=\"HTTP\",\n            port=80,\n        ))\n        secondary = route53.ARecord(self, \"SecondaryRecordSet\",\n            zone = zone,\n            record_name=\"failover\",\n            target= route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(secondaryLoadBalancer)),\n        )\n        secondaryRecordSet = secondary.node.default_child\n        secondaryRecordSet.failover = \"SECONDARY\"\n        secondaryRecordSet.health_check_id = secondaryHealthCheck.attr_health_check_id\n        secondaryRecordSet.set_identifier = \"Secondary\"\n\n        # cloudwatch metric & alarm to SNS\n        snsTopic = sns.Topic(self, \"AlarmNotificationTopic\")\n        snsTopic.add_subscription(\n            EmailSubscription(email_address=email)\n        )\n\n        healthCheckMetric = cloudwatch.Metric(\n            metric_name=\"HealthCheckStatus\",\n            namespace=\"AWS/Route53\",\n            statistic=\"Minimum\",\n            period=Duration.minutes(1),\n            region=\"us-east-1\",\n            dimensions_map={\n                \"HealthCheckId\": primaryHealthCheck.attr_health_check_id\n            }\n        )\n        healthCheckAlarm = healthCheckMetric.create_alarm(self, 'HealthCheckFailureAlarm', \n            evaluation_periods=1,\n            threshold=1,\n            comparison_operator=cloudwatch.ComparisonOperator.LESS_THAN_THRESHOLD\n        )\n\n        healthCheckAlarm.add_alarm_action(SnsAction(snsTopic))", "language": "python"}
{"input": "CDK class GrantWriteTest for AWS resource management", "output": "class GrantWriteTest extends GrantTestBase {\n  actions = perms.TABLE_WRITE_ACCESS;\n  getTableName() {\n    return 'grant_write_table';\n  }\n  grantAccess() {\n    this.table.grantWrite(new iam.ServicePrincipal(PRINCIPAL));\n  }\n}", "language": "typescript"}
{"input": "The HTTP methods that the Behavior will accept requests on.", "output": "export class AllowedMethods {\n  /** HEAD and GET */\n  public static readonly ALLOW_GET_HEAD = new AllowedMethods(['GET', 'HEAD']);\n  /** HEAD, GET, and OPTIONS */\n  public static readonly ALLOW_GET_HEAD_OPTIONS = new AllowedMethods(['GET', 'HEAD', 'OPTIONS']);\n  /** All supported HTTP methods */\n  public static readonly ALLOW_ALL = new AllowedMethods(['GET', 'HEAD', 'OPTIONS', 'PUT', 'PATCH', 'POST', 'DELETE']);\n\n  /** HTTP methods supported */\n  public readonly methods: string[];\n\n  private constructor(methods: string[]) { this.methods = methods; }\n}", "language": "typescript"}
{"input": "Lambda code from a local directory.", "output": "export class AssetCode extends Code {\n  public readonly isInline = false;\n  private asset?: s3_assets.Asset;\n\n  /**\n   * @param path The path to the asset file or directory.\n   */\n  constructor(public readonly path: string, private readonly options: s3_assets.AssetOptions = { }) {\n    super();\n  }\n\n  public bind(scope: Construct): CodeConfig {\n    // If the same AssetCode is used multiple times, retain only the first instantiation.\n    if (!this.asset) {\n      this.asset = new s3_assets.Asset(scope, 'Code', {\n        path: this.path,\n        deployTime: true,\n        ...this.options,\n      });\n    } else if (cdk.Stack.of(this.asset) !== cdk.Stack.of(scope)) {\n      throw new ValidationError(`Asset is already associated with another stack '${cdk.Stack.of(this.asset).stackName}'. ` +\n        'Create a new Code instance for every stack.', scope);\n    }\n\n    if (!this.asset.isZipArchive) {\n      throw new ValidationError(`Asset must be a .zip file or a directory (${this.path})`, scope);\n    }\n\n    return {\n      s3Location: {\n        bucketName: this.asset.s3BucketName,\n        objectKey: this.asset.s3ObjectKey,\n      },\n      sourceKMSKeyArn: this.options.sourceKMSKey?.keyRef.keyArn,\n    };\n  }\n\n  public bindToResource(resource: cdk.CfnResource, options: ResourceBindOptions = { }) {\n    if (!this.asset) {\n      throw new ValidationError('bindToResource() must be called after bind()', resource);\n    }\n\n    const resourceProperty = options.resourceProperty || 'Code';\n\n    // https://github.com/aws/aws-cdk/issues/1432\n    this.asset.addResourceMetadata(resource, resourceProperty);\n  }\n}", "language": "typescript"}
{"input": "CDK class AWSCustomResourceDynamoDb for AWS resource management", "output": "export class AWSCustomResourceDynamoDb extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const myTable = new dynamodb.Table(this, 'myTable', {\n      partitionKey: {\n        name: 'id',\n        type: dynamodb.AttributeType.STRING,\n      },\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    new cr.AwsCustomResource(this, 'myCR', {\n      memorySize: 1024,\n      policy: cr.AwsCustomResourcePolicy.fromSdkCalls({\n        resources: cr.AwsCustomResourcePolicy.ANY_RESOURCE,\n      }),\n      installLatestAwsSdk: true,\n      onCreate: {\n        service: 'DynamoDB',\n        action: 'PutItem',\n        parameters: {\n          Item: {\n            id: { S: 'test-value' },\n          },\n          TableName: myTable.tableName,\n        },\n        physicalResourceId: cr.PhysicalResourceId.of('myCRphysicalResourceID'),\n      },\n      onUpdate: {\n        service: 'DynamoDB',\n        action: 'PutItem',\n        parameters: {\n          service: 'DynamoDB',\n          action: 'PutItem',\n          parameters: {\n            Item: {\n              id: { S: 'test-value' },\n            },\n            TableName: myTable.tableName,\n          },\n          physicalResourceId: cr.PhysicalResourceId.of('myCRphysicalResourceID'),\n        },\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, CDK Pipelines, CodePipeline resources", "output": "export class pipelineStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: pipelineProps) {\n    super(scope, id, props);\n    \n    const pipeline = new CodePipeline(this, 'pipeline', {\n      selfMutation:     true,\n      crossAccountKeys: true,\n      reuseCrossRegionSupportStacks: true,\n      synth: new ShellStep('Synth', {\n        input: CodePipelineSource.connection(`${props.githubOrg}/${props.githubRepo}`, `${props.githubBranch}`,{\n          // You need to replace the below code connection arn:\n          connectionArn: `arn:aws:codestar-connections:${props.pipelineRegion}:${props.pipelineAccountId}:connection/0ce75950-a29b-4ee4-a9d3-b0bad3b2c0a6`\n        }),\n        commands: [\n          'npm ci',\n          'npm run build',\n          'npx cdk synth'\n        ]\n      }),\n      synthCodeBuildDefaults: {\n        rolePolicy: [\n          new PolicyStatement({\n            resources: [ '*' ],\n            actions: [ 'ec2:DescribeAvailabilityZones' ],\n          }),\n      ]}\n    });\n\n    const devStage = pipeline.addStage(new pipelineAppStage(this, `${props.devEnv}`, {\n      env: { account: `${props.pipelineAccountId}`, region: `${props.pipelineRegion}`}\n    }));\n    devStage.addPost(new ManualApprovalStep('approval'));\n\n    // add waves:\n    const devWave = pipeline.addWave(`${props.devEnv}Wave`);\n\n    devWave.addStage(new pipelineAppStage(this, `${props.devEnv}-${props.primaryRegion}`, {\n      env: { account: `${props.devAccountId}`, region: `${props.primaryRegion}`}\n    }));\n\n    devWave.addStage(new pipelineAppStage(this, `${props.devEnv}-${props.secondaryRegion}`, {\n      env: { account: `${props.devAccountId}`, region: `${props.secondaryRegion}`}\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation, ECS resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 2, natGateways: 1, restrictDefaultSecurityGroup: false });\n\n    const task = new ecs.FargateTaskDefinition(this, 'Task', { cpu: 256, memoryLimitMiB: 512 });\n    task.addContainer('nginx', {\n      image: ecs.ContainerImage.fromRegistry('public.ecr.aws/nginx/nginx:latest'),\n      portMappings: [{ containerPort: 80 }],\n    });\n    const svc = new patterns.ApplicationLoadBalancedFargateService(this, 'Service', {\n      vpc,\n      taskDefinition: task,\n      publicLoadBalancer: false,\n    });\n\n    const nlb = new elbv2.NetworkLoadBalancer(this, 'Nlb', {\n      vpc,\n      crossZoneEnabled: true,\n      internetFacing: true,\n    });\n    const listener = nlb.addListener('listener', {\n      port: 80,\n    });\n\n    const target = listener.addTargets('Targets', {\n      targets: [new targets.AlbTarget(svc.loadBalancer, 80)],\n      port: 80,\n      healthCheck: {\n        protocol: elbv2.Protocol.HTTP,\n      },\n    });\n    target.node.addDependency(svc.listener);\n\n    new CfnOutput(this, 'NlbEndpoint', { value: `http://${nlb.loadBalancerDnsName}` });\n  }\n}", "language": "typescript"}
{"input": "Returns true for a condition that evaluates to false or returns false for a condition that evaluates to true. ``Fn::Not`` acts as a NOT operator.", "output": "class FnNot extends FnConditionBase {\n  /**\n   * Creates an ``Fn::Not`` condition function.\n   * @param condition A condition such as ``Fn::Equals`` that evaluates to true or false.\n   */\n  constructor(condition: ICfnConditionExpression) {\n    super('Fn::Not', [condition]);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, KMS, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const key = new kms.Key(this, 'Key');\n\n    const domainProps: es.DomainProps = {\n      removalPolicy: RemovalPolicy.DESTROY,\n      version: es.ElasticsearchVersion.V7_1,\n      ebs: {\n        volumeSize: 10,\n        volumeType: EbsDeviceVolumeType.GENERAL_PURPOSE_SSD,\n      },\n      logging: {\n        slowSearchLogEnabled: true,\n        appLogEnabled: true,\n      },\n      nodeToNodeEncryption: true,\n      encryptionAtRest: {\n        enabled: true,\n        kmsKey: key,\n      },\n      // test the access policies custom resource works\n      accessPolicies: [\n        new iam.PolicyStatement({\n          effect: iam.Effect.ALLOW,\n          actions: ['es:ESHttp*'],\n          principals: [new iam.AccountRootPrincipal()],\n          resources: ['*'],\n        }),\n      ],\n    };\n\n    new es.Domain(this, 'Domain', domainProps);\n  }\n}", "language": "typescript"}
{"input": "The ALPN protocol identifier.", "output": "export class Alpn {\n  /** HTTP/1.1 */\n  public static readonly HTTP1_1 = Alpn.of('http1.1');\n  /** HTTP2 */\n  public static readonly H2 = Alpn.of('h2');\n  /** HTTP3 (QUIC) */\n  public static readonly H3 = Alpn.of('h3');\n\n  /**\n   * A custom ALPN protocol identifier.\n   * @param protocol The ALPN protocol identifier.\n   */\n  public static of(protocol: string): Alpn {\n    return new Alpn(protocol);\n  }\n\n  /**\n   * @param protocol The ALPN protocol identifier.\n   */\n  private constructor(public readonly protocol: string) {}\n}", "language": "typescript"}
{"input": "Need to Change different app", "output": "class FargateAppStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create VPC and Fargate Cluster\n        # NOTE: Limit AZs to avoid reaching resource quotas\n        vpc = ec2.Vpc(\n            self, \"MyVpc\",\n            max_azs=2\n        )\n\n        cluster = ecs.Cluster(\n            self, 'Ec2Cluster',\n            vpc=vpc\n        )\n\n        self.fargate_service = ecs_patterns.NetworkLoadBalancedFargateService(\n            self, \"FargateService\",\n            cluster=cluster,\n            task_image_options=ecs_patterns.NetworkLoadBalancedTaskImageOptions(\n                image=ecs.ContainerImage.from_registry(\"amazon/amazon-ecs-sample\")\n            )\n        )\n\n        self.fargate_service.service.connections.security_groups[0].add_ingress_rule(\n            peer = ec2.Peer.ipv4(vpc.vpc_cidr_block),\n            connection = ec2.Port.tcp(80),\n            description=\"Allow http inbound from VPC\"\n        )\n\n        CfnOutput(\n            self, \"LoadBalancerDNS\",\n            value=self.fargate_service.load_balancer.load_balancer_dns_name\n        )", "language": "python"}
{"input": "CDK class AmplifyAssetDeploymentProvider for AWS resource management", "output": "class AmplifyAssetDeploymentProvider extends NestedStack {\n  /**\n   * Returns the singleton provider.\n   */\n  public static getOrCreate(scope: Construct) {\n    const providerId =\n      'com.amazonaws.cdk.custom-resources.amplify-asset-deployment-provider';\n    const stack = Stack.of(scope);\n    const group =\n      (stack.node.tryFindChild(providerId) as AmplifyAssetDeploymentProvider) ?? new AmplifyAssetDeploymentProvider(stack, providerId);\n    return group.provider.serviceToken;\n  }\n\n  private readonly provider: Provider;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const onEvent = new AssetDeploymentOnEventFunction(this, 'amplify-asset-deployment-on-event');\n    onEvent.addToRolePolicy(new iam.PolicyStatement({\n      resources: ['*'],\n      actions: [\n        's3:GetObject',\n        's3:GetSignedUrl',\n        'amplify:ListJobs',\n        'amplify:StartDeployment',\n      ],\n    }));\n\n    const isComplete = new AssetDeploymentIsCompleteFunction(this, 'amplify-asset-deployment-is-complete');\n    isComplete.addToRolePolicy(new iam.PolicyStatement({\n      resources: ['*'],\n      actions: ['amplify:GetJob*'],\n    }));\n\n    this.provider = new Provider(\n      this,\n      'amplify-asset-deployment-handler-provider',\n      {\n        onEventHandler: onEvent,\n        isCompleteHandler: isComplete,\n        totalTimeout: Duration.minutes(5),\n      },\n    );\n  }\n}", "language": "typescript"}
{"input": "Manages AWS-vended Custom Resources This feature is currently experimental.", "output": "export class CustomResourceConfig {\n  /**\n   * Returns the CustomResourceConfig for this scope.\n   */\n  public static of(scope: IConstruct): CustomResourceConfig {\n    return new CustomResourceConfig(scope);\n  }\n\n  private constructor(private readonly scope: IConstruct) { }\n\n  /**\n   * Set the log retention of AWS-vended custom resource lambdas.\n   *\n   * This feature is currently experimental.\n   */\n  public addLogRetentionLifetime(retention: logs.RetentionDays) {\n    Aspects.of(this.scope).add(new CustomResourceLogRetention(retention), {\n      priority: mutatingAspectPrio32333(this.scope),\n    });\n  }\n\n  /**\n   * Set the removal policy of AWS-vended custom resource logGroup.\n   *\n   * This feature is currently experimental.\n   */\n  public addRemovalPolicy(removalPolicy: RemovalPolicy) {\n    Aspects.of(this.scope).add(new CustomResourceRemovalPolicy(removalPolicy), {\n      priority: mutatingAspectPrio32333(this.scope),\n    });\n  }\n\n  /**\n   * Set the runtime version on AWS-vended custom resources lambdas.\n   *\n   * This feature is currently experimental.\n   */\n  public addLambdaRuntime(lambdaRuntime: lambda.Runtime) {\n    Aspects.of(this.scope).add(new CustomResourceLambdaRuntime(lambdaRuntime), {\n      priority: mutatingAspectPrio32333(this.scope),\n    });\n  }\n}", "language": "typescript"}
{"input": "Author must be AWS (as an Organization)", "output": "export class AuthorAWS extends ValidationRule {\n  public readonly name = 'package-info/author';\n\n  public validate(pkg: PackageJson): void {\n    expectJSON(this.name, pkg, 'author.name', 'Amazon Web Services');\n    expectJSON(this.name, pkg, 'author.url', 'https://aws.amazon.com');\n    expectJSON(this.name, pkg, 'author.organization', true);\n  }\n}", "language": "typescript"}
{"input": "A single Application Load Balancer's listener as the target for load balancing.", "output": "export class AlbListenerTarget extends AlbArnTarget {\n  /**\n   * Create a new ALB target.\n   * The associated target group will automatically have a dependency added\n   * against the ALB's listener.\n   *\n   * @param albListener The application load balancer listener to target.\n   */\n  constructor(private albListener: elbv2.ApplicationListener) {\n    super(albListener.loadBalancer.loadBalancerArn, albListener.port);\n  }\n\n  private attach(targetGroup: aws_elasticloadbalancingv2.ITargetGroupRef): elbv2.LoadBalancerTargetProps {\n    targetGroup.node.addDependency(this.albListener);\n    return super._attach(targetGroup);\n  }\n\n  /**\n   * Register this ALB target with a load balancer.\n   *\n   * Don't call this, it is called automatically when you add the target to a\n   * load balancer.\n   *\n   * This adds dependency on albListener because creation of ALB listener and NLB can vary during runtime.\n   * More Details on - https://github.com/aws/aws-cdk/issues/17208\n   */\n  public attachToNetworkTargetGroup(targetGroup: elbv2.INetworkTargetGroup): elbv2.LoadBalancerTargetProps {\n    return this.attach(targetGroup);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, CloudWatch Logs, CloudFormation resources", "output": "class LogGroupIntegStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    var audit = new LogGroup(this, 'LogGroupLambdaAudit', {});\n\n    var bucket = new Bucket(this, 'audit-bucket-id');\n\n    const dataProtectionPolicy = new DataProtectionPolicy({\n      name: 'policy-name',\n      description: 'policy description',\n      identifiers: [DataIdentifier.DRIVERSLICENSE_US, new DataIdentifier('EmailAddress'), new CustomDataIdentifier('EmployeeId', 'EmployeeId-\\\\d{9}')],\n      logGroupAuditDestination: audit,\n      s3BucketAuditDestination: bucket,\n    });\n\n    const fieldIndexPolicy = new FieldIndexPolicy({\n      fields: ['Operation', 'RequestId'],\n    });\n\n    new LogGroup(this, 'LogGroupLambda', {\n      dataProtectionPolicy: dataProtectionPolicy,\n      fieldIndexPolicies: [fieldIndexPolicy],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for EKS operations", "output": "const addManagedAddon = (id: string, addonName: string) => {\n      new eks.CfnAddon(this, id, {\n        addonName,\n        clusterName: eksCluster.clusterName,\n      });\n    }", "language": "typescript"}
{"input": "The type of Aurora Cluster Instance. Can be either serverless v2 or provisioned", "output": "export class ClusterInstanceType {\n  /**\n   * Aurora Serverless V2 instance type\n   * @see https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless-v2.html\n   */\n  public static serverlessV2(): ClusterInstanceType {\n    return new ClusterInstanceType('db.serverless', InstanceType.SERVERLESS_V2);\n  }\n\n  /**\n   * Aurora Provisioned instance type\n   */\n  public static provisioned(instanceType?: ec2.InstanceType): ClusterInstanceType {\n    return new ClusterInstanceType(\n      (instanceType ?? ec2.InstanceType.of(ec2.InstanceClass.T3, ec2.InstanceSize.MEDIUM)).toString(),\n      InstanceType.PROVISIONED,\n    );\n  }\n\n  constructor(\n    private readonly instanceType: string,\n    public readonly type: InstanceType,\n  ) { }\n\n  /**\n   * String representation of the instance type that can be used in the CloudFormation resource\n   */\n  public toString(): string {\n    return this.instanceType;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, Route 53 resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const hostedZone = new route53.PublicHostedZone(this, 'HostedZone', {\n      zoneName: 'cdk.dev',\n    });\n\n    const healthCheck = new route53.HealthCheck(this, 'HealthCheck', {\n      type: route53.HealthCheckType.HTTP,\n      fqdn: 'example.com',\n      port: 80,\n      resourcePath: '/health',\n      failureThreshold: 3,\n      requestInterval: Duration.seconds(30),\n    });\n\n    // Primary failover record with health check\n    new route53.ARecord(this, 'ARecordFailoverPrimary', {\n      zone: hostedZone,\n      recordName: 'failover',\n      target: route53.RecordTarget.fromIpAddresses('1.2.3.4'),\n      failover: route53.Failover.PRIMARY,\n      healthCheck,\n      setIdentifier: 'failover-primary',\n      ttl: Duration.seconds(60),\n    });\n\n    // Secondary failover record\n    new route53.ARecord(this, 'ARecordFailoverSecondary', {\n      zone: hostedZone,\n      recordName: 'failover',\n      target: route53.RecordTarget.fromIpAddresses('5.6.7.8'),\n      failover: route53.Failover.SECONDARY,\n      setIdentifier: 'failover-secondary',\n      ttl: Duration.seconds(60),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class AnomalyDetectionAlarm for AWS resource management", "output": "export class AnomalyDetectionAlarm extends Alarm {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cloudwatch.AnomalyDetectionAlarm';\n\n  constructor(scope: Construct, id: string, props: AnomalyDetectionAlarmProps) {\n    super(scope, id, {\n      ...props,\n      comparisonOperator: props.comparisonOperator ?? ComparisonOperator.LESS_THAN_LOWER_OR_GREATER_THAN_UPPER_THRESHOLD,\n      metric: Metric.anomalyDetectionFor({\n        ...props,\n        period: metricPeriod(props.metric), // AnomalyDetectionAlarmProps.period is deprecated - the guidance recommends encoding the period in the metric itself.\n      }),\n      threshold: Alarm.ANOMALY_DETECTION_NO_THRESHOLD,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.comparisonOperator && !isAnomalyDetectionOperator(props.comparisonOperator)) {\n      throw new ValidationError(`Must use one of the anomaly detection operators, got ${props.comparisonOperator}`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Access control implementation using a raw access string.", "output": "class AccessControlString extends AccessControl {\n  /**\n   * The access string that defines user's permissions.\n   */\n  public readonly accessString: string;\n\n  constructor(accessString: string) {\n    super();\n    this.accessString = accessString;\n  }\n}\n\n/**\n * Properties for defining an ElastiCache base user.\n */\nexport interface UserBaseProps {\n  /**\n   * The engine type for the user.\n   * Enum options: UserEngine.VALKEY, UserEngine.REDIS.\n   *\n   * @default - UserEngine.REDIS for NoPasswordUser, UserEngine.VALKEY for all other user types.\n   */\n  readonly engine?: UserEngine;\n  /**\n   * The ID of the user.\n   */\n  readonly userId: string;\n  /**\n   * Access control configuration for the user.\n   */\n  readonly accessControl: AccessControl;\n}\n\n/**\n * Represents an ElastiCache base user.\n */\nexport interface IUser extends IResource {\n  /**\n   * The user's ID.\n   *\n   * @attribute\n   */\n  readonly userId: string;\n  /**\n   * The engine for the user.\n   */\n  readonly engine?: UserEngine;\n  /**\n   * The user's name.\n   *\n   * @attribute\n   */\n  readonly userName?: string;\n  /**\n   * The user's ARN.\n   *\n   * @attribute\n   */\n  readonly userArn: string;\n}", "language": "typescript"}
{"input": "CDK Stack that creates VPC, SSM Parameter Store, CloudFormation resources", "output": "class ProducerStack extends Stack {\n  public stringListGetAtt: string[];\n  public stringListRef: CfnParameter;\n  public manualExport: string[];\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    const vpc = new Vpc(this, 'vpc');\n    this.stringListGetAtt = new InterfaceVpcEndpoint(this, 'endpoint', {\n      vpc,\n      service: InterfaceVpcEndpointAwsService.SECRETS_MANAGER,\n    }).vpcEndpointDnsEntries;\n\n    this.stringListRef = new CfnParameter(this, 'stringListParam', {\n      default: 'BLAT,BLAH',\n      type: 'List<String>',\n    });\n\n    this.manualExport = this.exportStringListValue(['string1', 'string2'], {\n      name: 'ManualExport',\n    });\n  }\n}", "language": "typescript"}
{"input": "Must declare minimum node version", "output": "export class MustHaveNodeEnginesDeclaration extends ValidationRule {\n  public readonly name = 'package-info/engines';\n\n  public validate(pkg: PackageJson): void {\n    if (cdkMajorVersion() === 2) {\n      expectJSON(this.name, pkg, 'engines.node', '>= 18.0.0');\n    } else {\n      expectJSON(this.name, pkg, 'engines.node', '>= 10.13.0 <13 || >=13.7.0');\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, SQS, CloudFormation resources", "output": "class EventSourceStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const rule = new events.Rule(this, 'Rule', {\n      schedule: events.Schedule.expression('rate(1 minute)'),\n    });\n\n    const queue = new sqs.Queue(this, 'Queue');\n\n    rule.addTarget(new targets.EventBus(\n      events.EventBus.fromEventBusArn(\n        this,\n        'External',\n        `arn:aws:events:${this.region}:999999999999:event-bus/test-bus`,\n      ),\n      {\n        deadLetterQueue: queue,\n      },\n    ));\n  }\n}", "language": "typescript"}
{"input": "CDK class OnlyEncryptionKeyTest for AWS resource management", "output": "class OnlyEncryptionKeyTest extends EncryptionTestBase {\n  public readonly tableBucket: s3tables.TableBucket;\n  public readonly key: kms.IKey;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n    this.key = new kms.Key(this, 'Key', {});\n    this.tableBucket = new s3tables.TableBucket(this, id, {\n      tableBucketName: 'integ-tb-key-only',\n      encryptionKey: this.key,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n\n  public validateAssertions(integ: IntegTest) {\n    const encryptionConfig = integ.assertions.awsApiCall('@aws-sdk/client-s3tables', 'GetTableBucketEncryptionCommand', {\n      tableBucketARN: this.tableBucket.tableBucketArn,\n    });\n\n    encryptionConfig.expect(ExpectedResult.objectLike({\n      encryptionConfiguration: {\n        sseAlgorithm: 'aws:kms',\n        kmsKeyArn: this.key.keyArn,\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "Abstract base class for runtime authorizer configurations. Provides static factory methods to create different authentication types.", "output": "class RuntimeAuthorizerConfiguration {\n  /**\n   * Use IAM authentication (default).\n   * Requires AWS credentials to sign requests using SigV4.\n   *\n   * @returns RuntimeAuthorizerConfiguration for IAM authentication\n   */\n  public static usingIAM(): RuntimeAuthorizerConfiguration {\n    return new IamAuthorizerConfiguration();\n  }\n\n  /**\n   * Use custom JWT authentication.\n   * Validates JWT tokens against the specified OIDC provider.\n   *\n   * @param discoveryUrl The OIDC discovery URL (must end with /.well-known/openid-configuration)\n   * @param allowedClients Optional array of allowed client IDs\n   * @param allowedAudience Optional array of allowed audiences\n   * @returns RuntimeAuthorizerConfiguration for JWT authentication\n   */\n  public static usingJWT(\n    discoveryUrl: string,\n    allowedClients?: string[],\n    allowedAudience?: string[],\n  ): RuntimeAuthorizerConfiguration {\n    if (!Token.isUnresolved(discoveryUrl) && !discoveryUrl.endsWith('/.well-known/openid-configuration')) {\n      throw new ValidationError('JWT discovery URL must end with /.well-known/openid-configuration');\n    }\n    return new JwtAuthorizerConfiguration(discoveryUrl, allowedClients, allowedAudience);\n  }\n\n  /**\n   * Use AWS Cognito User Pool authentication.\n   * Validates Cognito-issued JWT tokens.\n   *\n   * @param userPool The Cognito User Pool\n   * @param userPoolClients The Cognito User Pool App Clients\n   * @param allowedAudience Optional array of allowed audiences\n   * @returns RuntimeAuthorizerConfiguration for Cognito authentication\n   */\n  public static usingCognito(\n    userPool: IUserPool,\n    userPoolClients: IUserPoolClient[],\n    allowedAudience?: string[],\n  ): RuntimeAuthorizerConfiguration {\n    return new CognitoAuthorizerConfiguration(userPool, userPoolClients, allowedAudience);\n  }\n\n  /**\n   * Use OAuth 2.0 authentication.\n   * Supports various OAuth providers.\n   *\n   * @param discoveryUrl The OIDC discovery URL (must end with /.well-known/openid-configuration)\n   * @param clientId OAuth client ID\n   * @param allowedAudience Optional array of allowed audiences\n   * @returns RuntimeAuthorizerConfiguration for OAuth authentication\n   */\n  public static usingOAuth(\n    discoveryUrl: string,\n    clientId: string,\n    allowedAudience?: string[],\n  ): RuntimeAuthorizerConfiguration {\n    if (!Token.isUnresolved(discoveryUrl) && !discoveryUrl.endsWith('/.well-known/openid-configuration')) {\n      throw new ValidationError('OAuth discovery URL must end with /.well-known/openid-configuration');\n    }\n    return new OAuthAuthorizerConfiguration(discoveryUrl, clientId, allowedAudience);\n  }\n\n  /**\n   * Render the authorizer configuration for CloudFormation\n   * @internal\n   */\n  public abstract _render(): CfnRuntime.AuthorizerConfigurationProperty | undefined;\n}", "language": "typescript"}
{"input": "CDK class DistributionConfiguration for AWS resource management", "output": "export class DistributionConfiguration extends DistributionConfigurationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.DistributionConfiguration';\n\n  /**\n   * Import an existing distribution configuration given its ARN.\n   */\n  public static fromDistributionConfigurationArn(\n    scope: Construct,\n    id: string,\n    distributionConfigurationArn: string,\n  ): IDistributionConfiguration {\n    const distributionConfigurationName = cdk.Stack.of(scope).splitArn(\n      distributionConfigurationArn,\n      cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    ).resourceName!;\n\n    class Import extends DistributionConfigurationBase {\n      public readonly distributionConfigurationArn = distributionConfigurationArn;\n      public readonly distributionConfigurationName = distributionConfigurationName;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing distribution configuration given its name. The provided name must be normalized by converting\n   * all alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromDistributionConfigurationName(\n    scope: Construct,\n    id: string,\n    distributionConfigurationName: string,\n  ): IDistributionConfiguration {\n    return this.fromDistributionConfigurationArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'distribution-configuration',\n        resourceName: distributionConfigurationName,\n      }),\n    );\n  }\n\n  /**\n   * Return whether the given object is a DistributionConfiguration.\n   */\n  public static isDistributionConfiguration(x: any): x is DistributionConfiguration {\n    return x !== null && typeof x === 'object' && DISTRIBUTION_CONFIGURATION_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the distribution configuration\n   */\n  public readonly distributionConfigurationArn: string;\n\n  /**\n   * The name of the distribution configuration\n   */\n  public readonly distributionConfigurationName: string;\n\n  private readonly amiDistributionsByRegion: { [region: string]: AmiDistribution } = {};\n  private readonly containerDistributionsByRegion: {\n    [region: string]: ContainerDistribution;\n  } = {};\n\n  public constructor(scope: Construct, id: string, props: DistributionConfigurationProps = {}) {\n    super(scope, id, {\n      physicalName:\n        props.distributionConfigurationName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, DISTRIBUTION_CONFIGURATION_SYMBOL, { value: true });\n\n    this.validateDistributionConfigurationName();\n\n    this.addAmiDistributions(...(props.amiDistributions ?? []));\n    this.addContainerDistributions(...(props.containerDistributions ?? []));\n\n    const distributionConfiguration = new CfnDistributionConfiguration(this, 'Resource', {\n      name: this.physicalName,\n      description: props.description,\n      distributions: cdk.Lazy.any({ produce: () => this.renderDistributions() }),\n      tags: props.tags,\n    });\n\n    this.distributionConfigurationName = this.getResourceNameAttribute(distributionConfiguration.attrName);\n    this.distributionConfigurationArn = this.getResourceArnAttribute(distributionConfiguration.attrArn, {\n      service: 'imagebuilder',\n      resource: 'distribution-configuration',\n      resourceName: this.physicalName,\n    });\n  }\n\n  /**\n   * Adds AMI distribution settings to the distribution configuration\n   *\n   * @param amiDistributions The list of AMI distribution settings to apply\n   */\n  @MethodMetadata()\n  public addAmiDistributions(...amiDistributions: AmiDistribution[]): void {\n    amiDistributions.forEach((amiDistribution) => {\n      const region = amiDistribution.region ?? cdk.Stack.of(this).region;\n      if (this.amiDistributionsByRegion[region]) {\n        throw new cdk.ValidationError(\n          `duplicate AMI distribution found for region \"${region}\"; only one AMI distribution per region is allowed`,\n          this,\n        );\n      }\n\n      this.amiDistributionsByRegion[region] = amiDistribution;\n    });\n  }\n\n  /**\n   * Adds container distribution settings to the distribution configuration\n   *\n   * @param containerDistributions The list of container distribution settings to apply\n   */\n  @MethodMetadata()\n  public addContainerDistributions(...containerDistributions: ContainerDistribution[]): void {\n    containerDistributions.forEach((containerDistribution) => {\n      const region = containerDistribution.region ?? cdk.Stack.of(this).region;\n      if (this.containerDistributionsByRegion[region]) {\n        throw new cdk.ValidationError(\n          `duplicate Container distribution found for region \"${region}\"; only one Container distribution per region is allowed`,\n          this,\n        );\n      }\n\n      this.containerDistributionsByRegion[region] = containerDistribution;\n    });\n  }\n\n  private validateDistributionConfigurationName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError('The distributionConfigurationName cannot be longer than 128 characters', this);\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError('The distributionConfigurationName cannot contain spaces', this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError('The distributionConfigurationName cannot contain underscores', this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError('The distributionConfigurationName must be lowercase', this);\n    }\n  }\n\n  /**\n   * Renders the AMI and container distributions provided as input to the construct, into the `Distribution[]` structure\n   * that CfnDistributionConfiguration expects to receive. Distributions provided to CfnDistributionConfiguration must\n   * map to a unique region per entry in the list - this render function also handles combining AMI and container\n   * distributions in the same region into a single entry.\n   *\n   * This is rendered at synthesis time, as users can add additional AMI and container distributions with\n   * `addAmiDistributions` and `addContainerDistributions`, after the construct has been instantiated.\n   *\n   * @private\n   */\n  private renderDistributions(): CfnDistributionConfiguration.DistributionProperty[] {\n    if (\n      !Object.keys(this.amiDistributionsByRegion).length &&\n      !Object.keys(this.containerDistributionsByRegion).length\n    ) {\n      throw new cdk.ValidationError('You must specify at least one AMI or container distribution', this);\n    }\n\n    const distributionByRegion: { [region: string]: CfnDistributionConfiguration.DistributionProperty } = {};\n\n    for (const [region, distribution] of Object.entries(this.amiDistributionsByRegion)) {\n      distributionByRegion[region] = {\n        region,\n        amiDistributionConfiguration: this.buildAmiDistribution(distribution),\n        fastLaunchConfigurations: this.buildFastLaunchConfigurations(distribution),\n        launchTemplateConfigurations: this.buildLaunchTemplateConfigurations(distribution),\n        ssmParameterConfigurations: this.buildSsmParameterConfigurations(distribution),\n        licenseConfigurationArns: this.buildLicenseConfigurationArns(distribution),\n      };\n    }\n\n    for (const [region, containerDistribution] of Object.entries(this.containerDistributionsByRegion)) {\n      distributionByRegion[region] = {\n        ...(distributionByRegion[region] ?? {}),\n        region,\n        containerDistributionConfiguration: this.buildContainerDistribution(containerDistribution),\n      };\n    }\n\n    const distributions = Object.values(distributionByRegion);\n\n    distributions.forEach((distribution) => {\n      const { region: _, ...distributionWithoutRegion } = distribution;\n      if (!Object.entries(distributionWithoutRegion).some(([__, value]) => value !== undefined)) {\n        throw new cdk.ValidationError(\n          `at least one distribution property must be set for region \"${distribution.region}\"`,\n          this,\n        );\n      }\n    });\n\n    return distributions;\n  }\n\n  private buildAmiDistribution(amiDistribution: AmiDistribution): object | undefined {\n    const launchPermissions = this.buildAmiLaunchPermissions(amiDistribution);\n    const amiDistributionConfiguration = {\n      ...(Object.keys(amiDistribution.amiTags ?? {}).length && { AmiTags: amiDistribution.amiTags }),\n      ...(amiDistribution.amiDescription !== undefined && { Description: amiDistribution.amiDescription }),\n      ...(amiDistribution.amiKmsKey !== undefined && { KmsKeyId: amiDistribution.amiKmsKey.keyArn }),\n      ...(launchPermissions && { LaunchPermissionConfiguration: launchPermissions }),\n      ...(amiDistribution.amiName !== undefined && { Name: amiDistribution.amiName }),\n      ...(amiDistribution.amiTargetAccountIds !== undefined && {\n        TargetAccountIds: amiDistribution.amiTargetAccountIds,\n      }),\n    };\n\n    return Object.keys(amiDistributionConfiguration).length ? amiDistributionConfiguration : undefined;\n  }\n\n  private buildContainerDistribution(containerDistribution: ContainerDistribution): object | undefined {\n    return {\n      ContainerTags: containerDistribution.containerTags,\n      Description: containerDistribution.containerDescription,\n      TargetRepository: {\n        RepositoryName: containerDistribution.containerRepository.repositoryName,\n        Service: containerDistribution.containerRepository.service,\n      },\n    };\n  }\n\n  private buildAmiLaunchPermissions(amiDistribution: AmiDistribution): object | undefined {\n    if (amiDistribution.amiLaunchPermission?.isPublicUserGroup) {\n      cdk.Annotations.of(this).addWarning(\n        'AMI is configured for public access, making it available to any AWS account globally. ' +\n          'Ensure no sensitive data, credentials, or proprietary configurations are included. ' +\n          \"Review your organization's security policies before deploying public AMIs.\",\n      );\n    }\n\n    const launchPermissions = {\n      ...(amiDistribution.amiLaunchPermission?.organizationalUnitArns !== undefined && {\n        OrganizationalUnitArns: amiDistribution.amiLaunchPermission?.organizationalUnitArns,\n      }),\n      ...(amiDistribution.amiLaunchPermission?.organizationArns !== undefined && {\n        OrganizationArns: amiDistribution.amiLaunchPermission?.organizationArns,\n      }),\n      ...(amiDistribution.amiLaunchPermission?.isPublicUserGroup && {\n        UserGroups: ['all'],\n      }),\n      ...(amiDistribution.amiLaunchPermission?.accountIds !== undefined && {\n        UserIds: amiDistribution.amiLaunchPermission?.accountIds,\n      }),\n    };\n\n    return Object.keys(launchPermissions).length ? launchPermissions : undefined;\n  }\n\n  private buildFastLaunchConfigurations(\n    amiDistribution: AmiDistribution,\n  ): CfnDistributionConfiguration.FastLaunchConfigurationProperty[] | undefined {\n    const fastLaunchConfigurations = amiDistribution.fastLaunchConfigurations?.map(\n      (fastLaunchConfiguration): CfnDistributionConfiguration.FastLaunchConfigurationProperty => {\n        if (\n          fastLaunchConfiguration.maxParallelLaunches !== undefined &&\n          !cdk.Token.isUnresolved(fastLaunchConfiguration.maxParallelLaunches) &&\n          fastLaunchConfiguration.maxParallelLaunches < MIN_PARALLEL_LAUNCHES\n        ) {\n          throw new cdk.ValidationError(\n            `you must specify a maximum parallel launch count of at least ${MIN_PARALLEL_LAUNCHES}`,\n            this,\n          );\n        }\n\n        const launchTemplate = fastLaunchConfiguration.launchTemplate;\n        const useFastLaunchLaunchTemplateId = launchTemplate?.launchTemplateId !== undefined;\n        const fastLaunchLaunchTemplate: CfnDistributionConfiguration.FastLaunchLaunchTemplateSpecificationProperty = {\n          ...(useFastLaunchLaunchTemplateId && {\n            launchTemplateId: launchTemplate?.launchTemplateId,\n          }),\n          ...(!useFastLaunchLaunchTemplateId && {\n            launchTemplateName: launchTemplate?.launchTemplateName,\n          }),\n          ...(launchTemplate?.versionNumber !== undefined && {\n            launchTemplateVersion: launchTemplate?.versionNumber,\n          }),\n        };\n\n        return {\n          enabled: fastLaunchConfiguration.enabled,\n          maxParallelLaunches: fastLaunchConfiguration.maxParallelLaunches,\n          ...(Object.keys(fastLaunchLaunchTemplate).length && { launchTemplate: fastLaunchLaunchTemplate }),\n          ...(fastLaunchConfiguration.targetSnapshotCount !== undefined && {\n            snapshotConfiguration: { targetResourceCount: fastLaunchConfiguration.targetSnapshotCount },\n          }),\n        };\n      },\n    );\n\n    return fastLaunchConfigurations?.length ? fastLaunchConfigurations : undefined;\n  }\n\n  private buildLaunchTemplateConfigurations(\n    amiDistribution: AmiDistribution,\n  ): CfnDistributionConfiguration.LaunchTemplateConfigurationProperty[] | undefined {\n    const launchTemplateConfigurations = amiDistribution.launchTemplates?.map(\n      (launchTemplateConfiguration): CfnDistributionConfiguration.LaunchTemplateConfigurationProperty => {\n        if (!launchTemplateConfiguration.launchTemplate.launchTemplateId) {\n          throw new cdk.ValidationError(\n            'You must reference launch templates by ID in launch template configurations',\n            this,\n          );\n        }\n\n        return {\n          accountId: launchTemplateConfiguration.accountId,\n          launchTemplateId: launchTemplateConfiguration.launchTemplate.launchTemplateId,\n          setDefaultVersion: launchTemplateConfiguration.setDefaultVersion,\n        };\n      },\n    );\n\n    return launchTemplateConfigurations?.length ? launchTemplateConfigurations : undefined;\n  }\n\n  private buildLicenseConfigurationArns(amiDistribution: AmiDistribution): string[] | undefined {\n    return amiDistribution.licenseConfigurationArns?.length ? amiDistribution.licenseConfigurationArns : undefined;\n  }\n\n  private buildSsmParameterConfigurations(\n    amiDistribution: AmiDistribution,\n  ): CfnDistributionConfiguration.SsmParameterConfigurationProperty[] | undefined {\n    const ssmParameterConfigurations = amiDistribution.ssmParameters?.map(\n      (ssmParameterConfiguration): CfnDistributionConfiguration.SsmParameterConfigurationProperty => ({\n        amiAccountId: ssmParameterConfiguration.amiAccount,\n        dataType: ssmParameterConfiguration.dataType,\n        parameterName: ssmParameterConfiguration.parameter.parameterName,\n      }),\n    );\n\n    return ssmParameterConfigurations?.length ? ssmParameterConfigurations : undefined;\n  }\n}", "language": "typescript"}
{"input": "CDK class UntrustedCodeBoundaryPolicy for AWS resource management", "output": "export class UntrustedCodeBoundaryPolicy extends iam.ManagedPolicy {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codebuild.UntrustedCodeBoundaryPolicy';\n\n  constructor(scope: Construct, id: string, props: UntrustedCodeBoundaryPolicyProps = {}) {\n    super(scope, id, {\n      managedPolicyName: props.managedPolicyName,\n      description: 'Permissions Boundary Policy for CodeBuild Projects running untrusted code',\n      statements: [\n        new iam.PolicyStatement({\n          actions: [\n            // For logging\n            'logs:CreateLogGroup',\n            'logs:CreateLogStream',\n            'logs:PutLogEvents',\n\n            // For test reports\n            'codebuild:CreateReportGroup',\n            'codebuild:CreateReport',\n            'codebuild:UpdateReport',\n            'codebuild:BatchPutTestCases',\n            'codebuild:BatchPutCodeCoverages',\n\n            // For batch builds\n            'codebuild:StartBuild',\n            'codebuild:StopBuild',\n            'codebuild:RetryBuild',\n\n            // For pulling ECR images\n            'ecr:GetDownloadUrlForLayer',\n            'ecr:BatchGetImage',\n            'ecr:BatchCheckLayerAvailability',\n\n            // For running in a VPC\n            'ec2:CreateNetworkInterfacePermission',\n            'ec2:CreateNetworkInterface',\n            'ec2:DescribeNetworkInterfaces',\n            'ec2:DeleteNetworkInterface',\n            'ec2:DescribeSubnets',\n            'ec2:DescribeSecurityGroups',\n            'ec2:DescribeDhcpOptions',\n            'ec2:DescribeVpcs',\n\n            // NOTABLY MISSING:\n            // - Reading secrets\n            // - Reading parameterstore\n          ],\n          resources: ['*'],\n        }),\n        ...props.additionalStatements ?? [],\n      ],\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, API Gateway operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        base_lambda = _lambda.Function(self, 'ApiCorsLambda',\n                                       handler='lambda-handler.handler',\n                                       runtime=_lambda.Runtime.PYTHON_3_7,\n                                       code=_lambda.Code.from_asset('lambda'))\n\n        base_api = _apigw.RestApi(self, 'ApiGatewayWithCors',\n                                  rest_api_name='ApiGatewayWithCors')\n\n        example_entity = base_api.root.add_resource(\n            'example',\n            default_cors_preflight_options=_apigw.CorsOptions(\n                allow_methods=['GET', 'OPTIONS'],\n                allow_origins=_apigw.Cors.ALL_ORIGINS)\n        )\n        example_entity_lambda_integration = _apigw.LambdaIntegration(\n            base_lambda,\n            proxy=False,\n            integration_responses=[\n                _apigw.IntegrationResponse(\n                    status_code=\"200\",\n                    response_parameters={\n                        'method.response.header.Access-Control-Allow-Origin': \"'*'\"\n                    }\n                )\n            ]\n        )\n        example_entity.add_method(\n            'GET', example_entity_lambda_integration,\n            method_responses=[\n                _apigw.MethodResponse(\n                    status_code=\"200\",\n                    response_parameters={\n                        'method.response.header.Access-Control-Allow-Origin': True\n                    }\n                )\n            ]\n        )", "language": "python"}
{"input": "An event destination", "output": "class EventDestination {\n  /**\n   * Use a SNS topic as event destination\n   */\n  public static snsTopic(topic: sns.ITopic): EventDestination {\n    return { topic };\n  }\n\n  /**\n   * Use CloudWatch dimensions as event destination\n   */\n  public static cloudWatchDimensions(dimensions: CloudWatchDimension[]): EventDestination {\n    return { dimensions };\n  }\n\n  /**\n   * Use Event Bus as event destination\n   */\n  public static eventBus(eventBus: events.IEventBusRef): EventDestination {\n    return { bus: eventBus };\n  }\n\n  /**\n   * Use Firehose Delivery Stream as event destination\n   */\n  public static firehoseDeliveryStream(stream: FirehoseDeliveryStreamDestination): EventDestination {\n    return { stream };\n  }\n\n  /**\n   * A SNS topic to use as event destination\n   *\n   * @default - do not send events to a SNS topic\n   */\n  public abstract readonly topic?: sns.ITopic;\n\n  /**\n   * A list of CloudWatch dimensions upon which to categorize your emails\n   *\n   * @default - do not send events to CloudWatch\n   */\n  public abstract readonly dimensions?: CloudWatchDimension[];\n\n  /**\n   * Use Event Bus as event destination\n   *\n   * @default - do not send events to Event bus\n   */\n  public abstract readonly bus?: events.IEventBusRef;\n\n  /**\n   * Use Firehose Delivery Stream\n   *\n   * @default - do not send events to Firehose Delivery Stream\n   */\n  public abstract readonly stream?: FirehoseDeliveryStreamDestination;\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudWatch Logs, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props: TestStackProps) {\n    super(scope, id, props);\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n\n    const serverCertificate = new acm.Certificate(this, 'Certificate', {\n      domainName: `server.${props.hostedZoneName}`,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n    const clientCertificate = new acm.Certificate(this, 'ClientCertificate', {\n      domainName: `client.${props.hostedZoneName}`,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 2, natGateways: 0 });\n\n    const logGroup = new logs.LogGroup(this, 'LogGroup', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    vpc.addClientVpnEndpoint('Endpoint', {\n      cidr: '10.100.0.0/16',\n      serverCertificateArn: serverCertificate.certificateArn,\n      clientCertificateArn: clientCertificate.certificateArn,\n      logGroup,\n      clientRouteEnforcementOptions: {\n        enforced: true,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Lambda code from an S3 archive. With option to set KMSKey for encryption.", "output": "export class S3CodeV2 extends Code {\n  public readonly isInline = false;\n  private bucketName: string;\n\n  constructor(bucket: s3.IBucket, private key: string, private options?: BucketOptions) {\n    super();\n    if (!bucket.bucketName) {\n      throw new ValidationError('bucketName is undefined for the provided bucket', bucket);\n    }\n\n    this.bucketName = bucket.bucketName;\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      s3Location: {\n        bucketName: this.bucketName,\n        objectKey: this.key,\n        objectVersion: this.options?.objectVersion,\n      },\n      sourceKMSKeyArn: this.options?.sourceKMSKey?.keyRef.keyArn,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ELB / ALB / NLB resources", "output": "export class SplitAtListener_LoadBalancerStack extends Stack {\n  public readonly loadBalancer: elbv2.ApplicationLoadBalancer;\n\n  constructor(scope: Construct, id: string, props: SplitAtListener_LoadBalancerStackProps) {\n    super(scope, id, props);\n\n    this.loadBalancer = new elbv2.ApplicationLoadBalancer(this, 'LoadBalancer', {\n      vpc: props.vpc,\n      internetFacing: true\n    });\n\n    new CfnOutput(this, 'LoadBalancerDNS', { value: this.loadBalancer.loadBalancerDnsName, });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function __init__", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)", "language": "python"}
{"input": "Integration test for bucket deployment with basic VPC configuration: - Lambda function runs in VPC with isolated subnets - Uses S3 Gateway endpoint to access S3 without NAT Gateway", "output": "class TestBucketDeploymentVpcBasic extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Basic VPC with isolated subnets - no NAT Gateway or Elastic IP needed\n    // Add S3 VPC Gateway endpoint for Lambda to access S3 without internet\n    const vpc = new ec2.Vpc(this, 'BasicVpc', {\n      restrictDefaultSecurityGroup: false,\n      natGateways: 0,\n      subnetConfiguration: [\n        {\n          cidrMask: 24,\n          name: 'Isolated',\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n        },\n      ],\n    });\n\n    // Add S3 Gateway endpoint so Lambda can access S3 without NAT Gateway\n    vpc.addGatewayEndpoint('S3Endpoint', {\n      service: ec2.GatewayVpcEndpointAwsService.S3,\n    });\n\n    const bucket = new s3.Bucket(this, 'Destination', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    new s3deploy.BucketDeployment(this, 'DeployWithBasicVpc', {\n      sources: [s3deploy.Source.asset(path.join(__dirname, 'my-website'))],\n      destinationBucket: bucket,\n      destinationKeyPrefix: 'basic-vpc/',\n      vpc: vpc,\n      retainOnDelete: false,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, SSM Parameter Store, SNS resources", "output": "class AwsCdkSdkJsStack extends cdk.Stack {\n  public readonly topicArn: string;\n\n  constructor(scope: Construct, id: string, props?: AwsCdkSdkJsStackProps) {\n    super(scope, id);\n    const topic = new sns.Topic(this, 'Topic');\n    this.topicArn = topic.topicArn;\n\n    const snsPublish = new AwsCustomResource(this, 'Publish', {\n      resourceType: 'Custom::SNSPublisher',\n      onUpdate: {\n        service: 'SNS',\n        action: 'publish',\n        parameters: {\n          Message: 'hello',\n          TopicArn: this.topicArn,\n        },\n        physicalResourceId: PhysicalResourceId.of(topic.topicArn),\n      },\n      policy: AwsCustomResourcePolicy.fromSdkCalls({ resources: AwsCustomResourcePolicy.ANY_RESOURCE }),\n    });\n\n    const listTopics = new AwsCustomResource(this, 'ListTopics', {\n      onUpdate: {\n        service: 'SNS',\n        action: 'listTopics',\n        physicalResourceId: PhysicalResourceId.fromResponse('Topics.0.TopicArn'),\n      },\n      policy: AwsCustomResourcePolicy.fromSdkCalls({ resources: AwsCustomResourcePolicy.ANY_RESOURCE }),\n    });\n    listTopics.node.addDependency(topic);\n\n    const ssmParameter = new ssm.StringParameter(this, 'Utf8Parameter', {\n      stringValue: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ\u00c5\u00c4\u00d6!\"#\u00a4%&/()=?`\u00b4^*+~_-.,:;<>|',\n    });\n    const getParameter = new AwsCustomResource(this, 'GetParameter', {\n      resourceType: 'Custom::SSMParameter',\n      onUpdate: {\n        service: 'SSM',\n        action: 'getParameter',\n        parameters: {\n          Name: ssmParameter.parameterName,\n          WithDecryption: true,\n        },\n        physicalResourceId: PhysicalResourceId.fromResponse('Parameter.ARN'),\n      },\n      policy: AwsCustomResourcePolicy.fromSdkCalls({ resources: AwsCustomResourcePolicy.ANY_RESOURCE }),\n    });\n\n    const customRole = new iam.Role(this, 'CustomRole', {\n      assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n    });\n    customRole.addToPolicy(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        resources: ['*'],\n        actions: [\n          'ssm:*',\n        ],\n      }),\n    );\n    const getParameterNoPolicy = new AwsCustomResource(this, 'GetParameterNoPolicy', {\n      resourceType: 'Custom::SSMParameter',\n      onUpdate: {\n        service: 'SSM',\n        action: 'getParameter',\n        parameters: {\n          Name: ssmParameter.parameterName,\n          WithDecryption: true,\n        },\n        physicalResourceId: PhysicalResourceId.fromResponse('Parameter.ARN'),\n      },\n      role: customRole,\n    });\n\n    new AwsCustomResource(this, 'DescribeCluster', {\n      resourceType: 'Custom::EKSClusterDescription',\n      onUpdate: {\n        service: 'EKS',\n        action: 'describeCluster',\n        parameters: {\n          name: 'fake-cluster',\n        },\n        physicalResourceId: PhysicalResourceId.of('fake-cluster'),\n        ignoreErrorCodesMatching: 'ResourceNotFoundException',\n      },\n      policy: AwsCustomResourcePolicy.fromSdkCalls({ resources: AwsCustomResourcePolicy.ANY_RESOURCE }),\n    });\n\n    new cdk.CfnOutput(this, 'MessageId', { value: snsPublish.getResponseField('MessageId') });\n    new cdk.CfnOutput(this, 'TopicArn', { value: listTopics.getResponseField('Topics.0.TopicArn') });\n    new cdk.CfnOutput(this, 'ParameterValue', { value: getParameter.getResponseField('Parameter.Value') });\n    new cdk.CfnOutput(this, 'ParameterValueNoPolicy', { value: getParameterNoPolicy.getResponseField('Parameter.Value') });\n\n    if (props?.runtime) {\n      const awsCustomResourceProviderId ='AWS679f53fac002430cb0da5b7982bd2287';\n      const provider = this.node.findChild(awsCustomResourceProviderId).node.defaultChild as lambda.CfnFunction;\n      provider.runtime = props.runtime.name;\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, CloudFormation, Lake Formation resources", "output": "class TestNestedStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    const stack1 = new NestedStack(this, 'Stack1');\n    const stack2 = new NestedStack(this, 'Stack2');\n    const resource1 = new lambda.Function(stack1, 'Lambda1', {\n      code: new lambda.InlineCode('foo'),\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n    }).node.defaultChild! as CfnResource;\n    const resource2 = new lambda.Function(stack2, 'Lambda2', {\n      code: new lambda.InlineCode('foo'),\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n    }).node.defaultChild! as CfnResource;\n\n    // The following two statements should cancel each other out\n    resource1.addDependency(resource2);\n    resource1.removeDependency(resource2);\n\n    resource2.addDependency(resource1);\n  }\n}", "language": "typescript"}
{"input": "CDK class Mesh for AWS resource management", "output": "export class Mesh extends MeshBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appmesh.Mesh';\n\n  /**\n   * Import an existing mesh by arn\n   */\n  public static fromMeshArn(scope: Construct, id: string, meshArn: string): IMesh {\n    const parts = cdk.Stack.of(scope).splitArn(meshArn, cdk.ArnFormat.SLASH_RESOURCE_NAME);\n\n    class Import extends MeshBase {\n      public meshName = parts.resourceName || '';\n      public meshArn = meshArn;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: meshArn,\n    });\n  }\n\n  /**\n   * Import an existing mesh by name\n   */\n  public static fromMeshName(scope: Construct, id: string, meshName: string): IMesh {\n    const arn = cdk.Stack.of(scope).formatArn({\n      service: 'appmesh',\n      resource: 'mesh',\n      resourceName: meshName,\n    });\n\n    class Import extends MeshBase {\n      public meshName = meshName;\n      public meshArn = arn;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The name of the AppMesh mesh\n   */\n  public readonly meshName: string;\n\n  /**\n   * The Amazon Resource Name (ARN) of the AppMesh mesh\n   */\n  public readonly meshArn: string;\n\n  constructor(scope: Construct, id: string, props: MeshProps = {}) {\n    super(scope, id, {\n      physicalName: props.meshName || cdk.Lazy.string({ produce: () => cdk.Names.uniqueId(this) }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const mesh = new CfnMesh(this, 'Resource', {\n      meshName: this.physicalName,\n      spec: {\n        egressFilter: props.egressFilter ? {\n          type: props.egressFilter,\n        } : undefined,\n        serviceDiscovery: props.serviceDiscovery,\n      },\n    });\n\n    this.meshName = this.getResourceNameAttribute(mesh.attrMeshName);\n    this.meshArn = this.getResourceArnAttribute(mesh.ref, {\n      service: 'appmesh',\n      resource: 'mesh',\n      resourceName: this.physicalName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, CodeBuild resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    /// !show\n    new codebuild.Project(this, 'MyProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: [\n              'echo \"Hello, CodeBuild!\"',\n            ],\n          },\n        },\n      }),\n    });\n    /// !hide\n  }\n}", "language": "typescript"}
{"input": "`DeployTimeSubstitutedFile` is an extension of `BucketDeployment` that allows users to upload individual files and specify to make substitutions in the file.", "output": "export class DeployTimeSubstitutedFile extends BucketDeployment {\n  public readonly objectKey: string;\n\n  constructor(scope: Construct, id: string, props: DeployTimeSubstitutedFileProps) {\n    if (!fs.existsSync(props.source)) {\n      throw new ValidationError(`No file found at 'source' path ${props.source}`, scope);\n    }\n    // Makes substitutions on the file\n    let fileData = fs.readFileSync(props.source, 'utf-8');\n    fileData = fileData.replace(/{{\\s*(\\w+)\\s*}}/g, function (match, expr) {\n      return props.substitutions[expr] ?? match;\n    });\n\n    const objectKey = props.destinationKey ?? cdk.FileSystem.fingerprint(props.source);\n    const fileSource = Source.data(objectKey, fileData);\n    const fullBucketDeploymentProps: BucketDeploymentProps = {\n      prune: false,\n      extract: true,\n      ...props,\n      sources: [fileSource],\n      role: props.role,\n    };\n    super(scope, id, fullBucketDeploymentProps);\n    // sets the object key\n    this.objectKey = objectKey;\n  }\n\n  public get bucket(): s3.IBucket {\n    return this.deployedBucket;\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomPythonInjector for AWS resource management", "output": "class CustomPythonInjector extends appsignals.PythonInjector {\n  get containerPath(): string {\n    return '/otel-snapshot';\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    for (const env of appsignals.PythonInjector.PYTHON_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n    envsToInject[appsignals.PythonInstrumentation.PYTHONPATH] = `${this.containerPath}/auto_instrumentation:${this.containerPath}`;\n  }\n}", "language": "typescript"}
{"input": "CDK class TransitGatewayRouteTableAssociation for AWS resource management", "output": "export class TransitGatewayRouteTableAssociation extends TransitGatewayAssociationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.TransitGatewayRouteTableAssociation';\n  /**\n   * The ID of the transit gateway route table association.\n   */\n  public readonly transitGatewayAssociationId: string;\n\n  constructor(scope: Construct, id: string, props: TransitGatewayRouteTableAssociationProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnTransitGatewayRouteTableAssociation(this, id, {\n      transitGatewayAttachmentId: props.transitGatewayVpcAttachment.transitGatewayAttachmentId,\n      transitGatewayRouteTableId: props.transitGatewayRouteTable.routeTableId,\n    });\n    this.node.defaultChild = resource;\n\n    this.transitGatewayAssociationId = resource.ref;\n  }\n}", "language": "typescript"}
{"input": "CDK class InstanceConnectEndpoint for AWS resource management", "output": "export class InstanceConnectEndpoint extends Construct {\n  constructor(scope: Construct, id: string, props: InstanceConnectEndpointProps) {\n    super(scope, id);\n\n    const role = new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n    });\n\n    // required policies: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/permissions-for-ec2-instance-connect-endpoint.html\n    role.addToPolicy(new iam.PolicyStatement({\n      actions: [\n        'ec2:CreateInstanceConnectEndpoint',\n        'ec2:DeleteInstanceConnectEndpoint',\n        'ec2:CreateTags',\n        'ec2:CreateNetworkInterface',\n      ],\n      resources: [\n        Stack.of(this).formatArn({\n          resource: 'instance-connect-endpoint',\n          service: 'ec2',\n          resourceName: '*',\n        }),\n        Stack.of(this).formatArn({\n          resource: 'network-interface',\n          service: 'ec2',\n          resourceName: '*',\n        }),\n        Stack.of(this).formatArn({\n          resource: 'subnet',\n          service: 'ec2',\n          resourceName: '*',\n        }),\n        Stack.of(this).formatArn({\n          resource: 'security-group',\n          service: 'ec2',\n          resourceName: '*',\n        }),\n      ],\n    }));\n    role.addToPolicy(new iam.PolicyStatement({\n      actions: ['ec2:DescribeInstanceConnectEndpoints'],\n      resources: ['*'],\n    }));\n    role.addToPolicy(new iam.PolicyStatement({\n      actions: ['iam:CreateServiceLinkedRole'],\n      resources: ['*'],\n    }));\n\n    // Create an asset for the Lambda code\n    const lambdaAsset = new assets.Asset(this, 'LambdaAsset', {\n      path: path.join(__dirname, '../lambda.d'),\n    });\n\n    // Common properties for Lambda functions\n    const commonProps = {\n      runtime: lambda.Runtime.PYTHON_3_9,\n      memorySize: 256,\n      timeout: Duration.minutes(10),\n      role,\n      code: lambda.Code.fromBucket(lambdaAsset.bucket, lambdaAsset.s3ObjectKey),\n    };\n\n    const onEventHandler = new lambda.Function(this, 'onEventHandler', {\n      ...commonProps,\n      handler: 'index.on_event',\n    });\n\n    const isCompleteHandler = new lambda.Function(this, 'isCompleteHandler', {\n      ...commonProps,\n      handler: 'index.is_complete',\n    });\n\n    const provider = new cr.Provider(this, 'Provider', {\n      onEventHandler,\n      isCompleteHandler,\n    });\n\n    new CustomResource(this, 'EICEndpointResource', {\n      serviceToken: provider.serviceToken,\n      resourceType: 'Custom::EC2InstanceConnectEndpoint',\n      properties: {\n        SubnetId: props.subnet.subnetId,\n        PreserveClientIp: props.preserveClientIp ?? true,\n        SecurityGroup: props.securityGroup?.map(sg => sg.securityGroupId),\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "A scope for ResourceServer", "output": "export class ResourceServerScope {\n  /**\n   * The name of the scope\n   */\n  public readonly scopeName: string;\n\n  /**\n   * A description of the scope.\n   */\n  public readonly scopeDescription: string;\n\n  constructor(props: ResourceServerScopeProps) {\n    this.scopeName = props.scopeName;\n    this.scopeDescription = props.scopeDescription;\n  }\n}", "language": "typescript"}
{"input": "CDK class LogsDeliveryBuilder for AWS resource management", "output": "export class LogsDeliveryBuilder extends LibraryBuilder<LogsDeliveryBuilderServiceModule> {\n  private readonly filePattern: string;\n\n  public constructor(props: LogsDeliveryBuilderProps) {\n    super(props);\n    this.filePattern = '%moduleName%/logs-delivery-mixins.generated.ts';\n  }\n\n  protected createServiceSubmodule(service: Service, submoduleName: string): LogsDeliveryBuilderServiceModule {\n    return new LogsDeliveryBuilderServiceModule({\n      submoduleName,\n      service,\n    });\n  }\n\n  protected addResourceToSubmodule(submodule: LogsDeliveryBuilderServiceModule, resource: Resource, _props?: AddServiceProps): void {\n    const resourceReference = new ResourceReference(resource);\n    if (resource.vendedLogs && resourceReference.hasArnGetter) {\n      const service = this.db.incoming('hasResource', resource).only().entity;\n      const logsModule = this.obtainLogsDeliveryModule(submodule, service);\n\n      const vendedLogsMixin = new LogsDelivery(logsModule.module, this.db, resource, submodule.constructLibModule);\n      submodule.registerResource(`${resource.cloudFormationType}VendedLogs`, vendedLogsMixin.mixin);\n\n      vendedLogsMixin.build();\n    }\n  }\n\n  private obtainLogsDeliveryModule(submodule: LogsDeliveryBuilderServiceModule, service: Service): LocatedModule<Module> {\n    const mod = this.createLogsDeliveryModule(submodule, service);\n    if (this.modules.has(mod.filePath)) {\n      return {\n        module: this.modules.get(mod.filePath)!,\n        filePath: mod.filePath,\n      };\n    }\n\n    return this.rememberModule(mod);\n  }\n\n  private createLogsDeliveryModule(submodule: LogsDeliveryBuilderServiceModule, service: Service): LocatedModule<Module> {\n    const module = new Module(`@aws-cdk/mixins-preview/${submodule.submoduleName}/logs`);\n    const filePath = this.pathFor(this.filePattern, submodule.submoduleName, service);\n\n    submodule.registerModule({ module, filePath });\n\n    CDK_CORE.import(module, 'cdk');\n    CDK_INTERFACES.import(module, 'interfaces');\n    CONSTRUCTS.import(module, 'constructs');\n    MIXINS_CORE.import(module, 'core', { fromLocation: relativeImportPath(filePath, '../core') });\n    MIXINS_LOGS_DELIVERY.import(module, 'logsDelivery', { fromLocation: '../aws-logs/logs-delivery' });\n    submodule.constructLibModule.import(module, 'service');\n\n    return { module, filePath };\n  }\n}", "language": "typescript"}
{"input": "Text inference configuration for prompts.", "output": "class TextInferenceConfiguration extends PromptInferenceConfiguration {\n  constructor(private readonly props: PromptInferenceConfigurationProps) {\n    super();\n\n    // Validate maxTokens if provided\n    if (props.maxTokens !== undefined && props.maxTokens <= 0) {\n      throw new ValidationError('maxTokens must be a positive number');\n    }\n\n    // Validate temperature range if provided\n    if (props.temperature !== undefined && (props.temperature < 0.0 || props.temperature > 1.0)) {\n      throw new ValidationError('temperature must be between 0.0 and 1.0');\n    }\n\n    // Validate topP range if provided\n    if (props.topP !== undefined && (props.topP < 0.0 || props.topP > 1.0)) {\n      throw new ValidationError('topP must be between 0.0 and 1.0');\n    }\n  }\n\n  public _render(): bedrock.CfnPrompt.PromptInferenceConfigurationProperty {\n    return {\n      text: {\n        maxTokens: this.props.maxTokens,\n        stopSequences: this.props.stopSequences,\n        temperature: this.props.temperature,\n        topP: this.props.topP,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "A function tool that can be called by the model.", "output": "class FunctionTool extends Tool {\n  constructor(private readonly props: FunctionToolProps) {\n    super();\n  }\n\n  public _render(): CfnPrompt.ToolProperty {\n    return {\n      toolSpec: {\n        name: this.props.name,\n        description: this.props.description,\n        inputSchema: {\n          json: this.props.inputSchema,\n        },\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "A source that reads from Kinesis.", "output": "export class KinesisSource extends StreamSource {\n  private readonly stream: IStream;\n  private readonly startingPosition: KinesisStartingPosition;\n  private readonly startingPositionTimestamp?: Date;\n  private readonly deadLetterTargetArn?: string;\n\n  constructor(stream: IStream, parameters: KinesisSourceParameters) {\n    super(stream.streamArn, parameters);\n    this.stream = stream;\n    this.startingPosition = parameters.startingPosition;\n    this.startingPositionTimestamp = parameters.startingPositionTimestamp;\n    this.deadLetterTargetArn = this.getDeadLetterTargetArn(this.deadLetterTarget);\n\n    if (this.startingPositionTimestamp && this.startingPosition !== KinesisStartingPosition.AT_TIMESTAMP) {\n      throw new Error(`Timestamp only valid with StartingPosition AT_TIMESTAMP for Kinesis streams, received ${this.startingPosition}`);\n    }\n  }\n\n  bind(_pipe: IPipe): SourceConfig {\n    return {\n      sourceParameters: {\n        kinesisStreamParameters: {\n          batchSize: this.sourceParameters.batchSize,\n          deadLetterConfig: this.deadLetterTargetArn ? { arn: this.deadLetterTargetArn } : undefined,\n          maximumBatchingWindowInSeconds: this.sourceParameters.maximumBatchingWindow?.toSeconds(),\n          maximumRecordAgeInSeconds: this.sourceParameters.maximumRecordAge?.toSeconds(),\n          maximumRetryAttempts: this.sourceParameters.maximumRetryAttempts,\n          onPartialBatchItemFailure: this.sourceParameters.onPartialBatchItemFailure,\n          parallelizationFactor: this.sourceParameters.parallelizationFactor,\n          startingPosition: this.startingPosition,\n          startingPositionTimestamp: this.startingPositionTimestamp?.toISOString(),\n        },\n      },\n    };\n  }\n\n  grantRead(grantee: IRole): void {\n    this.stream.grantRead(grantee);\n  }\n}", "language": "typescript"}
{"input": "A Stack that sets up MyCustomResource and shows how to get an attribute from it.", "output": "class MyStack(Stack):\n    def __init__(self, scope: App, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create s3 bucket\n        bucket = s3.Bucket(self, \"CustomResourceTestBucket\",\n                           encryption=s3.BucketEncryption.S3_MANAGED, block_public_access=s3.BlockPublicAccess.BLOCK_ALL)\n\n        resource = MyCustomResource(\n            self, \"MyCustomResource\",\n            bucket_name=bucket.bucket_name\n        )", "language": "python"}
{"input": "CDK Stack that creates S3, Lambda, EC2, IAM resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const appName = 'MyApplication';\n\n    const s3bucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    const asset = new s3assets.Asset(this, 'Asset', {\n      path: `${__dirname}/integ.elastic-beanstalk-environment-target-assets`,\n    });\n    asset.node.addDependency(s3bucket);\n\n    const app = new elasticbeanstalk.CfnApplication(this, 'Application', {\n      applicationName: appName,\n    });\n\n    const appVersion = new elasticbeanstalk.CfnApplicationVersion(this, 'ApplicationVersion', {\n      applicationName: appName,\n      sourceBundle: {\n        s3Bucket: asset.s3BucketName,\n        s3Key: asset.s3ObjectKey,\n      },\n    });\n    appVersion.node.addDependency(app);\n    appVersion.node.addDependency(asset);\n\n    const instanceRole = new iam.Role(this, `${appName}-aws-elasticbeanstalk-ec2-role`, {\n      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n    });\n\n    const managedPolicy = iam.ManagedPolicy.fromAwsManagedPolicyName('AWSElasticBeanstalkWebTier');\n    instanceRole.addManagedPolicy(managedPolicy);\n\n    const instanceProfile = `${appName}-aws-elasticbeanstalk-ec2-instance-profile`;\n    new iam.CfnInstanceProfile(this, instanceProfile, {\n      instanceProfileName: instanceProfile,\n      roles: [instanceRole.roleName],\n    });\n\n    const optionSettingProperties: elasticbeanstalk.CfnEnvironment.OptionSettingProperty[] = [\n      {\n        namespace: 'aws:autoscaling:launchconfiguration',\n        optionName: 'IamInstanceProfile',\n        value: instanceProfile,\n      },\n      {\n        namespace: 'aws:autoscaling:asg',\n        optionName: 'MinSize',\n        value: '1',\n      },\n      {\n        namespace: 'aws:autoscaling:asg',\n        optionName: 'MaxSize',\n        value: '1',\n      },\n      {\n        namespace: 'aws:ec2:instances',\n        optionName: 'InstanceTypes',\n        value: 't3.micro',\n      },\n    ];\n\n    const eb = new elasticbeanstalk.CfnEnvironment(this, 'Environment', {\n      applicationName: appName,\n      solutionStackName: SOLUTION_STACK_NAME.NODEJS_20,\n      environmentName: 'MyEnvironment',\n      optionSettings: optionSettingProperties,\n      versionLabel: appVersion.ref,\n    });\n    eb.node.addDependency(app);\n\n    var getEnvironmentUrl = new custom.AwsCustomResource(this, 'GetEnvironmentUrl', {\n      onCreate: {\n        service: 'ElasticBeanstalk',\n        action: 'describeEnvironments',\n        parameters: {\n          EnvironmentNames: [cdk.Token.asString(eb.environmentName)],\n        },\n        physicalResourceId: custom.PhysicalResourceId.of('EnvironmentUrl'),\n        logging: custom.Logging.withDataHidden(),\n      },\n      policy: custom.AwsCustomResourcePolicy.fromSdkCalls({ resources: custom.AwsCustomResourcePolicy.ANY_RESOURCE }),\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    getEnvironmentUrl.node.addDependency(eb);\n\n    const zone = new route53.PublicHostedZone(this, 'HostedZone', {\n      zoneName: 'test.public',\n    });\n\n    const aliastWithoutHealthCheck = new route53.ARecord(this, 'Alias', {\n      zone,\n      recordName: 'without-health-check',\n      target: route53.RecordTarget.fromAlias(\n        new targets.ElasticBeanstalkEnvironmentEndpointTarget('http://placeholder.placeholder.us-east-1.elasticbeanstalk.com'),\n      ),\n    });\n    aliastWithoutHealthCheck.node.addDependency(getEnvironmentUrl);\n    (aliastWithoutHealthCheck.node.defaultChild as route53.CfnRecordSet).aliasTarget = {\n      hostedZoneId: RegionInfo.get('us-east-1').ebsEnvEndpointHostedZoneId,\n      dnsName: getEnvironmentUrl.getResponseField('Environments.0.CNAME'),\n    } as route53.CfnRecordSet.AliasTargetProperty;\n\n    const aliasWithHealthCheck = new route53.ARecord(this, 'AliasWithHealthCheck', {\n      zone,\n      recordName: 'with-health-check',\n      target: route53.RecordTarget.fromAlias(\n        new targets.ElasticBeanstalkEnvironmentEndpointTarget('http://placeholder.placeholder.us-east-1.elasticbeanstalk.com', {\n          evaluateTargetHealth: true,\n        }),\n      ),\n    });\n    aliasWithHealthCheck.node.addDependency(getEnvironmentUrl);\n    (aliasWithHealthCheck.node.defaultChild as route53.CfnRecordSet).aliasTarget = {\n      hostedZoneId: RegionInfo.get('us-east-1').ebsEnvEndpointHostedZoneId,\n      dnsName: getEnvironmentUrl.getResponseField('Environments.0.CNAME'),\n      evaluateTargetHealth: true,\n    } as route53.CfnRecordSet.AliasTargetProperty;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, WAF, SQS resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const ruleSet = new gamelift.MatchmakingRuleSet(this, 'QueuedMatchmakingConfiguration', {\n      matchmakingRuleSetName: 'my-test-ruleset',\n      content: gamelift.RuleSetContent.fromJsonFile(path.join(__dirname, 'my-ruleset', 'ruleset.json')),\n    });\n\n    const build = new gamelift.Build(this, 'Build', {\n      content: gamelift.Content.fromAsset(path.join(__dirname, 'my-game-build')),\n      operatingSystem: gamelift.OperatingSystem.AMAZON_LINUX_2,\n    });\n\n    const fleet = new gamelift.BuildFleet(this, 'BuildFleet', {\n      fleetName: 'test-fleet',\n      content: build,\n      ingressRules: [{\n        source: gamelift.Peer.anyIpv4(),\n        port: gamelift.Port.tcp(1935),\n      }],\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.C5, ec2.InstanceSize.LARGE),\n      runtimeConfiguration: {\n        gameSessionActivationTimeout: cdk.Duration.seconds(300),\n        maxConcurrentGameSessionActivations: 1,\n        serverProcesses: [{\n          launchPath: '/local/game/TestApplicationServer',\n          parameters: 'port:1935 gameSessionLengthSeconds:20',\n          concurrentExecutions: 1,\n        }],\n      },\n    });\n\n    const queue = new gamelift.GameSessionQueue(this, 'MyGameSessionQueue', {\n      gameSessionQueueName: 'test-gameSessionQueue',\n      destinations: [fleet],\n    });\n\n    const matchmakingConfiguration = new gamelift.QueuedMatchmakingConfiguration(this, 'MyQueuedMatchmakingConfiguration', {\n      matchmakingConfigurationName: 'test-config-name',\n      gameSessionQueues: [queue],\n      ruleSet: ruleSet,\n      customEventData: 'event-data',\n      gameProperties: [{\n        key: 'test-key',\n        value: 'test-value',\n      }],\n      gameSessionData: 'test-session-data',\n      manualBackfillMode: true,\n      additionalPlayerCount: 3,\n      description: 'test description',\n      requestTimeout: cdk.Duration.seconds(30),\n      requireAcceptance: true,\n      acceptanceTimeout: cdk.Duration.seconds(30),\n    });\n\n    new CfnOutput(this, 'MatchmakingConfigurationArn', { value: matchmakingConfiguration.matchmakingConfigurationArn });\n    new CfnOutput(this, 'MatchmakingConfigurationName', { value: matchmakingConfiguration.matchmakingConfigurationName });\n  }\n}", "language": "typescript"}
{"input": "CDK class Gateway for AWS resource management", "output": "export class Gateway extends GatewayBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-agentcore-alpha.Gateway';\n  /**\n   * Import an existing Gateway using its attributes\n   *\n   * @param scope The construct scope\n   * @param id The construct id\n   * @param attrs The attributes of the existing Gateway\n   * @returns An IGateway instance representing the imported gateway\n   */\n  public static fromGatewayAttributes(\n    scope: Construct,\n    id: string,\n    attrs: GatewayAttributes,\n  ): IGateway {\n    class ImportedGateway extends GatewayBase {\n      public readonly gatewayArn = attrs.gatewayArn;\n      public readonly gatewayId = attrs.gatewayId;\n      public readonly name = attrs.gatewayName;\n      public readonly description = undefined;\n      public readonly protocolConfiguration: IGatewayProtocolConfig;\n      public readonly authorizerConfiguration: IGatewayAuthorizerConfig;\n      public readonly exceptionLevel = undefined;\n      public readonly kmsKey = undefined;\n      public readonly role = attrs.role;\n      public readonly gatewayUrl = undefined;\n      public readonly status = undefined;\n      public readonly statusReason = undefined;\n      public readonly createdAt = undefined;\n      public readonly updatedAt = undefined;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n        // Create placeholder protocol and authorizer configurations\n        this.protocolConfiguration = new McpProtocolConfiguration({\n          supportedVersions: [MCPProtocolVersion.MCP_2025_03_26],\n          searchType: McpGatewaySearchType.SEMANTIC,\n          instructions: 'Imported gateway',\n        });\n        this.authorizerConfiguration = GatewayAuthorizer.usingAwsIam();\n      }\n    }\n    return new ImportedGateway(scope, id);\n  }\n\n  /**\n   * The ARN of the gateway\n   * @attribute\n   */\n  public readonly gatewayArn: string;\n\n  /**\n   * The unique identifier of the gateway\n   * @attribute\n   */\n  public readonly gatewayId: string;\n\n  /**\n   * The name of the gateway\n   */\n  public readonly name: string;\n\n  /**\n   * The description of the gateway\n   */\n  public readonly description?: string;\n\n  /**\n   * The protocol configuration for the gateway\n   */\n  public readonly protocolConfiguration: IGatewayProtocolConfig;\n\n  /**\n   * The authorizer configuration for the gateway\n   */\n  public readonly authorizerConfiguration: IGatewayAuthorizerConfig;\n\n  /**\n   * The exception level for the gateway\n   */\n  public readonly exceptionLevel?: GatewayExceptionLevel;\n\n  /**\n   * The KMS key used for encryption\n   */\n  public readonly kmsKey?: kms.IKey;\n\n  /**\n   * The IAM role for the gateway\n   */\n  public readonly role: iam.IRole;\n\n  /**\n   * The URL endpoint for the gateway\n   * @attribute\n   */\n  public readonly gatewayUrl?: string;\n\n  /**\n   * The status of the gateway\n   * @attribute\n   */\n  public readonly status?: string;\n\n  /**\n   * The status reasons for the gateway\n   * @attribute\n   */\n  public readonly statusReason?: string[];\n\n  /**\n   * Timestamp when the gateway was created\n   * @attribute\n   */\n  public readonly createdAt?: string;\n\n  /**\n   * Timestamp when the gateway was last updated\n   * @attribute\n   */\n  public readonly updatedAt?: string;\n\n  /**\n   * Tags applied to the gateway\n   */\n  public readonly tags?: { [key: string]: string };\n\n  /**\n   * The Cognito User Pool created for the gateway (if using default Cognito authorizer)\n   */\n  public userPool?: cognito.IUserPool;\n\n  /**\n   * The Cognito User Pool Client created for the gateway (if using default Cognito authorizer)\n   */\n  public userPoolClient?: cognito.IUserPoolClient;\n\n  /**\n   * The Cognito User Pool Domain created for the gateway (if using default Cognito authorizer)\n   */\n  public userPoolDomain?: cognito.IUserPoolDomain;\n\n  /**\n   * The Cognito Resource Server created for the gateway (if using default Cognito authorizer)\n   */\n  public resourceServer?: cognito.IUserPoolResourceServer;\n\n  /**\n   * The OAuth2 token endpoint URL for client credentials flow.\n   * Only available when using the default Cognito authorizer.\n   */\n  public readonly tokenEndpointUrl?: string;\n\n  /**\n   * The OAuth2 scope strings for client credentials flow.\n   * Only available when using the default Cognito authorizer.\n   */\n  public readonly oauthScopes?: string[];\n\n  constructor(scope: Construct, id: string, props: GatewayProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    // ------------------------------------------------------\n    // Assignments\n    // ------------------------------------------------------\n\n    this.name = props.gatewayName;\n    this.validateGatewayName(this.name);\n\n    this.description = props.description;\n    if (this.description) {\n      this.validateDescription(this.description);\n    }\n\n    this.kmsKey = props.kmsKey;\n    this.role = props.role ?? this.createGatewayRole();\n\n    if (this.kmsKey && this.role) {\n      this.kmsKey.grantEncryptDecrypt(this.role);\n    }\n\n    this.protocolConfiguration = props.protocolConfiguration ?? this.createDefaultMcpProtocolConfiguration();\n    if (props.authorizerConfiguration) {\n      this.authorizerConfiguration = props.authorizerConfiguration;\n    } else {\n      const defaultCognitoAuth = this.createDefaultCognitoAuthorizerConfig();\n      this.authorizerConfiguration = defaultCognitoAuth.authorizerConfig;\n      this.tokenEndpointUrl = defaultCognitoAuth.tokenEndpointUrl;\n      this.oauthScopes = defaultCognitoAuth.oauthScopes;\n    }\n    this.exceptionLevel = props.exceptionLevel;\n\n    this.tags = props.tags ?? {};\n\n    // ------------------------------------------------------\n    // L1 Instantiation\n    // ------------------------------------------------------\n    const _resource = new bedrockagentcore.CfnGateway(this, 'Resource', {\n      authorizerConfiguration: this.authorizerConfiguration._render(),\n      authorizerType: this.authorizerConfiguration.authorizerType,\n      description: this.description,\n      exceptionLevel: this.exceptionLevel,\n      kmsKeyArn: this.kmsKey?.keyArn,\n      name: this.name,\n      protocolConfiguration: this.protocolConfiguration._render(),\n      protocolType: this.protocolConfiguration.protocolType,\n      roleArn: this.role?.roleArn,\n      tags: this.tags,\n    });\n\n    this.gatewayId = _resource.attrGatewayIdentifier;\n    this.gatewayArn = _resource.attrGatewayArn;\n    this.gatewayUrl = _resource.attrGatewayUrl;\n    this.status = _resource.attrStatus;\n    this.createdAt = _resource.attrCreatedAt;\n    this.updatedAt = _resource.attrUpdatedAt;\n    this.statusReason = _resource.attrStatusReasons;\n  }\n\n  /**\n   * Add a Lambda target to this gateway\n   * This is a convenience method that creates a GatewayTarget associated with this gateway\n   *\n   * @param id The construct id for the target\n   * @param props Properties for the Lambda target\n   * @returns The created GatewayTarget\n   */\n  @MethodMetadata()\n  public addLambdaTarget(\n    id: string,\n    props: AddLambdaTargetOptions,\n  ): GatewayTarget {\n    // Lambda invoke permissions are automatically granted in LambdaTargetConfiguration.bind()\n    // Build target props, conditionally including credentials if array has items\n    const targetProps: any = {\n      gatewayTargetName: props.gatewayTargetName,\n      description: props.description,\n      gateway: this,\n      lambdaFunction: props.lambdaFunction,\n      toolSchema: props.toolSchema,\n      ...(props.credentialProviderConfigurations && props.credentialProviderConfigurations.length > 0\n        ? { credentialProviderConfigurations: props.credentialProviderConfigurations }\n        : {}),\n    };\n\n    const target = GatewayTarget.forLambda(this, id, targetProps);\n\n    return target;\n  }\n\n  /**\n   * Add an OpenAPI target to this gateway\n   * This is a convenience method that creates a GatewayTarget associated with this gateway\n   *\n   * @param id The construct id for the target\n   * @param props Properties for the OpenAPI target\n   * @returns The created GatewayTarget\n   */\n  @MethodMetadata()\n  public addOpenApiTarget(\n    id: string,\n    props: AddOpenApiTargetOptions,\n  ): GatewayTarget {\n    const target = GatewayTarget.forOpenApi(this, id, {\n      gatewayTargetName: props.gatewayTargetName,\n      description: props.description,\n      gateway: this,\n      apiSchema: props.apiSchema,\n      validateOpenApiSchema: props.validateOpenApiSchema,\n      credentialProviderConfigurations: props.credentialProviderConfigurations,\n    });\n\n    return target;\n  }\n\n  /**\n   * Add a Smithy target to this gateway\n   * This is a convenience method that creates a GatewayTarget associated with this gateway\n   *\n   * @param id The construct id for the target\n   * @param props Properties for the Smithy target\n   * @returns The created GatewayTarget\n   */\n  @MethodMetadata()\n  public addSmithyTarget(\n    id: string,\n    props: AddSmithyTargetOptions,\n  ): GatewayTarget {\n    // Build target props, conditionally including credentials if array has items\n    const targetProps: any = {\n      gatewayTargetName: props.gatewayTargetName,\n      description: props.description,\n      gateway: this,\n      smithyModel: props.smithyModel,\n      ...(props.credentialProviderConfigurations && props.credentialProviderConfigurations.length > 0\n        ? { credentialProviderConfigurations: props.credentialProviderConfigurations }\n        : {}),\n    };\n\n    const target = GatewayTarget.forSmithy(this, id, targetProps);\n\n    return target;\n  }\n\n  /**\n   * Add an MCP server target to this gateway\n   * This is a convenience method that creates a GatewayTarget associated with this gateway\n   *\n   * @param id The construct id for the target\n   * @param props Properties for the MCP server target\n   * @returns The created GatewayTarget\n   * @see https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/gateway-target-MCPservers.html\n   */\n  @MethodMetadata()\n  public addMcpServerTarget(\n    id: string,\n    props: AddMcpServerTargetOptions,\n  ): GatewayTarget {\n    // Build target props, conditionally including credentials if array has items\n    const targetProps: any = {\n      gatewayTargetName: props.gatewayTargetName,\n      description: props.description,\n      gateway: this,\n      endpoint: props.endpoint,\n      ...(props.credentialProviderConfigurations && props.credentialProviderConfigurations.length > 0\n        ? { credentialProviderConfigurations: props.credentialProviderConfigurations }\n        : {}),\n    };\n\n    const target = GatewayTarget.forMcpServer(this, id, targetProps);\n\n    return target;\n  }\n\n  /**\n   * Creates the service role for the gateway to assume\n   *\n   * The service role starts with minimal permissions. Additional permissions\n   * are added automatically when targets are configured:\n   * - KMS encryption: Automatically grants encrypt/decrypt permissions\n   *\n   * For other target types, manually grant permissions using standard CDK grant methods:\n   * @internal\n   */\n  private createGatewayRole(): iam.Role {\n    const role = new iam.Role(this, 'ServiceRole', {\n      assumedBy: new iam.ServicePrincipal('bedrock-agentcore.amazonaws.com'),\n      description: `Service role for Bedrock AgentCore Gateway ${this.name}`,\n    });\n\n    const region = Stack.of(this).region;\n    const account = Stack.of(this).account;\n    const partition = Stack.of(this).partition;\n\n    // This restricts role assumption to the specific gateway resource only in this account,\n    // preventing other accounts from assuming this role.\n    // See:https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/gateway-prerequisites-permissions.html#gateway-service-role-permissions\n    role.assumeRolePolicy?.addStatements(\n      new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        principals: [new iam.ServicePrincipal('bedrock-agentcore.amazonaws.com')],\n        actions: GATEWAY_ASSUME_ROLE,\n        conditions: {\n          StringEquals: {\n            'aws:SourceAccount': account,\n          },\n          ArnLike: {\n            'aws:SourceArn': `arn:${partition}:bedrock-agentcore:${region}:${account}:gateway/${this.name}*`,\n          },\n        },\n      }),\n    );\n\n    if (this.kmsKey) {\n      role.addToPolicy(new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        actions: GATEWAY_KMS_KEY_PERMS,\n        resources: [this.kmsKey.keyArn],\n      }));\n    }\n    return role;\n  }\n\n  /**\n   * Validates the gateway name format\n   * Pattern: ^([0-9a-zA-Z][-]?){1,100}$\n   * Max length: 48 characters\n   * @param name The gateway name to validate\n   * @throws Error if the name is invalid\n   * @internal\n   */\n  private validateGatewayName(name: string): void {\n    if (Token.isUnresolved(name)) {\n      return;\n    }\n\n    const lengthErrors = validateStringField({\n      value: name,\n      minLength: 1,\n      maxLength: 48,\n      fieldName: 'Gateway name',\n    });\n\n    if (lengthErrors.length > 0) {\n      throw new ValidationError(lengthErrors.join('\\n'));\n    }\n\n    const patternErrors = validateFieldPattern(\n      name,\n      'Gateway name',\n      /^([0-9a-zA-Z][-]?){1,100}$/,\n      'Gateway name must contain only alphanumeric characters and hyphens, with hyphens only between characters',\n    );\n\n    if (patternErrors.length > 0) {\n      throw new ValidationError(patternErrors.join('\\n'));\n    }\n  }\n\n  /**\n   * Validates the description format\n   * Max length: 200 characters\n   * @param description The description to validate\n   * @throws Error if validation fails\n   * @internal\n   */\n  private validateDescription(description: string): void {\n    if (Token.isUnresolved(description)) {\n      return;\n    }\n\n    const errors = validateStringField({\n      value: description,\n      minLength: 1,\n      maxLength: 200,\n      fieldName: 'Description',\n    });\n\n    if (errors.length > 0) {\n      throw new ValidationError(errors.join('\\n'));\n    }\n  }\n\n  /**\n   * Creates a default Cognito authorizer for the gateway\n   * Provisions a Cognito User Pool and configures M2M (machine-to-machine) JWT authentication\n   * using OAuth 2.0 client credentials grant flow\n   * @see https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/identity-idp-cognito.html\n   * @internal\n   */\n  private createDefaultCognitoAuthorizerConfig(): {\n    authorizerConfig: IGatewayAuthorizerConfig;\n    tokenEndpointUrl: string;\n    oauthScopes: string[];\n  } {\n    const userPool = new cognito.UserPool(this, 'UserPool', {\n      signInCaseSensitive: false,\n    });\n\n    const resourceServer = userPool.addResourceServer('ResourceServer', {\n      identifier: Names.uniqueResourceName(this, { maxLength: 256, separator: '-' }),\n      scopes: [\n        {\n          scopeName: 'read',\n          scopeDescription: 'Read access to gateway tools',\n        },\n        {\n          scopeName: 'write',\n          scopeDescription: 'Write access to gateway tools',\n        },\n      ],\n    });\n\n    const oauthScopes = [\n      cognito.OAuthScope.resourceServer(resourceServer, {\n        scopeName: 'read',\n        scopeDescription: 'Read access to gateway tools',\n      }),\n      cognito.OAuthScope.resourceServer(resourceServer, {\n        scopeName: 'write',\n        scopeDescription: 'Write access to gateway tools',\n      }),\n    ];\n\n    const userPoolClient = userPool.addClient('DefaultClient', {\n      generateSecret: true,\n      oAuth: {\n        flows: {\n          clientCredentials: true,\n        },\n        scopes: oauthScopes,\n      },\n    });\n\n    // Create Cognito Domain for OAuth2 token endpoint\n    // Use uniqueResourceName to generate a unique domain prefix toLowerCase() is required because the hash portion is uppercase\n    const domainPrefix = Names.uniqueResourceName(this, {\n      maxLength: 63, // Cognito domain prefix max length\n      separator: '-',\n    }).toLowerCase();\n\n    const userPoolDomain = userPool.addDomain('Domain', {\n      cognitoDomain: {\n        domainPrefix: domainPrefix,\n      },\n    });\n\n    this.userPool = userPool;\n    this.userPoolClient = userPoolClient;\n    this.userPoolDomain = userPoolDomain;\n    this.resourceServer = resourceServer;\n\n    return {\n      authorizerConfig: GatewayAuthorizer.usingCognito({\n        userPool: userPool,\n        allowedClients: [userPoolClient],\n      }),\n      tokenEndpointUrl: `https://${userPoolDomain.domainName}.auth.${Stack.of(this).region}.amazoncognito.com/oauth2/token`,\n      oauthScopes: oauthScopes.map(scope => scope.scopeName),\n    };\n  }\n\n  /**\n   * Creates a default MCP protocol configuration for the gateway\n   * Provides sensible defaults for MCP protocol settings\n   * @internal\n   */\n  private createDefaultMcpProtocolConfiguration(): IGatewayProtocolConfig {\n    return new McpProtocolConfiguration({\n      supportedVersions: [MCPProtocolVersion.MCP_2025_03_26],\n      searchType: McpGatewaySearchType.SEMANTIC,\n      instructions: 'Default gateway to connect to external MCP tools',\n    });\n  }\n}", "language": "typescript"}
{"input": "NOTICE files must contain 3rd party attributions", "output": "export class ThirdPartyAttributions extends ValidationRule {\n  public readonly name = 'license/3p-attributions';\n\n  public validate(pkg: PackageJson): void {\n    const alwaysCheck = ['aws-cdk-lib'];\n    if (pkg.json.private && !alwaysCheck.includes(pkg.json.name)) {\n      return;\n    }\n    const bundled = pkg.getAllBundledDependencies().filter(dep => !dep.startsWith('@aws-cdk'));\n    const attribution = pkg.json.pkglint?.attribution ?? [];\n    const noticePath = path.join(pkg.packageRoot, 'NOTICE');\n    const lines = fs.existsSync(noticePath)\n      ? fs.readFileSync(noticePath, { encoding: 'utf8' }).split('\\n')\n      : [];\n\n    const re = /^\\*\\* (\\S+)/;\n    const attributions = lines.filter(l => re.test(l)).map(l => l.match(re)![1]);\n\n    for (const dep of bundled) {\n      if (!attributions.includes(dep)) {\n        pkg.report({\n          message: `Missing attribution for bundled dependency '${dep}' in NOTICE file.`,\n          ruleName: this.name,\n        });\n      }\n    }\n    for (const attr of attributions) {\n      if (!bundled.includes(attr) && !attribution.includes(attr)) {\n        pkg.report({\n          message: `Unnecessary attribution found for dependency '${attr}' in NOTICE file. Attribution is determined from package.json (all \"bundledDependencies\" or the list in \"pkglint.attribution\")`,\n          ruleName: this.name,\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class DynamoDbDataSource for AWS resource management", "output": "export class DynamoDbDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.DynamoDbDataSource';\n\n  constructor(scope: Construct, id: string, props: DynamoDbDataSourceProps) {\n    super(scope, id, props, {\n      type: 'AMAZON_DYNAMODB',\n      dynamoDbConfig: {\n        tableName: props.table.tableName,\n        awsRegion: props.table.env.region,\n        useCallerCredentials: props.useCallerCredentials,\n      },\n    });\n    if (props.readOnlyAccess) {\n      props.table.grantReadData(this);\n    } else {\n      props.table.grantReadWriteData(this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Represents the App Runner connection that enables the App Runner service to connect to a source repository. It's required for GitHub code repositories.", "output": "export class GitHubConnection {\n  /**\n   * Using existing App Runner connection by specifying the connection ARN.\n   * @param arn connection ARN\n   * @returns Connection\n   */\n  public static fromConnectionArn(arn: string): GitHubConnection {\n    return new GitHubConnection(arn);\n  }\n\n  /**\n   * The ARN of the Connection for App Runner service to connect to the repository.\n   */\n  public readonly connectionArn: string;\n  constructor(arn: string) {\n    this.connectionArn = arn;\n  }\n}", "language": "typescript"}
{"input": "CDK class AccessPoint for AWS resource management", "output": "export class AccessPoint extends AccessPointBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-efs.AccessPoint';\n\n  /**\n   * Import an existing Access Point by attributes\n   */\n  public static fromAccessPointAttributes(scope: Construct, id: string, attrs: AccessPointAttributes): IAccessPoint {\n    return new ImportedAccessPoint(scope, id, attrs);\n  }\n\n  /**\n   * Import an existing Access Point by id\n   */\n  public static fromAccessPointId(scope: Construct, id: string, accessPointId: string): IAccessPoint {\n    return new ImportedAccessPoint(scope, id, {\n      accessPointId: accessPointId,\n    });\n  }\n\n  /**\n   * The ARN of the Access Point\n   * @attribute\n   */\n  public readonly accessPointArn: string;\n\n  /**\n   * The ID of the Access Point\n   * @attribute\n   */\n  public readonly accessPointId: string;\n\n  private readonly _fileSystem: IFileSystemRef;\n\n  /**\n   * The file system of the access point\n   */\n  public get fileSystem(): IFileSystem {\n    return toIFileSystem(this._fileSystem);\n  }\n\n  constructor(scope: Construct, id: string, props: AccessPointProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const clientToken = props.clientToken;\n    if ((clientToken?.length === 0 || (clientToken && clientToken.length > 64)) && !Token.isUnresolved(clientToken)) {\n      throw new ValidationError(`The length of \\'clientToken\\' must range from 1 to 64 characters, got: ${clientToken.length} characters`, this);\n    }\n\n    const resource = new CfnAccessPoint(this, 'Resource', {\n      fileSystemId: props.fileSystem.fileSystemRef.fileSystemId,\n      rootDirectory: {\n        creationInfo: props.createAcl ? {\n          ownerGid: props.createAcl.ownerGid,\n          ownerUid: props.createAcl.ownerUid,\n          permissions: props.createAcl.permissions,\n        } : undefined,\n        path: props.path,\n      },\n      posixUser: props.posixUser ? {\n        uid: props.posixUser.uid,\n        gid: props.posixUser.gid,\n        secondaryGids: props.posixUser.secondaryGids,\n      } : undefined,\n      clientToken,\n    });\n\n    Tags.of(this).add('Name', this.node.path);\n\n    this.accessPointId = resource.ref;\n    this.accessPointArn = Stack.of(scope).formatArn({\n      service: 'elasticfilesystem',\n      resource: 'access-point',\n      resourceName: this.accessPointId,\n    });\n    this._fileSystem = props.fileSystem;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, CloudFormation, ECR resources", "output": "class LambdaContainerFunctionStack(Stack):\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n\n        image_name    = \"lambdaContainerFunction\"\n\n        ##\n        ## If use_pre_existing_image is True\n        ## then use an image that already exists in ECR.\n        ## Otherwise, build a new image\n        ##\n        use_pre_existing_image = False\n\n\n\n        ##\n        ## ECR\n        ##\n        if (use_pre_existing_image):\n\n            ##\n            ## Container was build previously, or elsewhere.\n            ## Use the pre-existing container\n            ##\n            ecr_repository = aws_ecr.Repository.from_repository_attributes(self,\n                id              = \"ECR\",\n                repository_arn  ='arn:aws:ecr:{0}:{1}:repository/{2}'.format(Aws.REGION, Aws.ACCOUNT_ID, image_name),\n                repository_name = image_name\n            ) ## aws_ecr.Repository.from_repository_attributes\n\n            ##\n            ## Container Image.\n            ## Pulled from the ECR repository.\n            ##\n            # ecr_image is expecting a `Code` type, so casting `EcrImageCode` to `Code` resolves mypy error\n            ecr_image = typing.cast(\"aws_lambda.Code\", aws_lambda.EcrImageCode(\n                repository = ecr_repository\n            )) ## aws_lambda.EcrImageCode\n\n        else:\n            ##\n            ## Create new Container Image.\n            ##\n            ecr_image = aws_lambda.EcrImageCode.from_asset_image(\n                directory = os.path.join(os.getcwd(), \"lambda-image\")\n            )\n\n\n\n\n        ##\n        ## Lambda Function\n        ##\n        aws_lambda.Function(self,\n          id            = \"lambdaContainerFunction\",\n          description   = \"Sample Lambda Container Function\",\n          code          = ecr_image,\n          ##\n          ## Handler and Runtime must be *FROM_IMAGE*\n          ## when provisioning Lambda from Container.\n          ##\n          handler       = aws_lambda.Handler.FROM_IMAGE,\n          runtime       = aws_lambda.Runtime.FROM_IMAGE,\n          environment   = {\"hello\":\"world\"},\n          function_name = \"sampleContainerFunction\",\n          memory_size   = 128,\n          reserved_concurrent_executions = 10,\n          timeout       = Duration.seconds(10),\n        ) ## aws_lambda.Function", "language": "python"}
{"input": "CDK Stack that creates Lambda, DynamoDB, CloudFormation resources", "output": "class SdkV3TestStack extends Stack {\n  public lambdaFunction: IFunction;\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const table = new dynamodb.TableV2(this, 'SdkCallee', {\n      tableName: 'external-sdk-table',\n      partitionKey: { name: 'call', type: dynamodb.AttributeType.STRING },\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    // This function uses @aws-sdk/* but it will not be included\n    this.lambdaFunction = new lambda.NodejsFunction(this, 'external-sdk-v3', {\n      entry: path.join(__dirname, 'integ-handlers/dependencies-sdk-v3.ts'),\n      runtime: STANDARD_NODEJS_RUNTIME,\n      environment: {\n        TABLE_NAME: table.tableName,\n      },\n    });\n\n    // grant the lambda role read/write permissions to our table\n    table.grantReadWriteData(this.lambdaFunction);\n  }\n}", "language": "typescript"}
{"input": "CDK class FeatureStabilityRule for AWS resource management", "output": "export class FeatureStabilityRule extends ValidationRule {\n  public readonly name = 'package-info/feature-stability';\n  private readonly badges: { [key: string]: string } = {\n    'Not Implemented': 'https://img.shields.io/badge/not--implemented-black.svg?style=for-the-badge',\n    'Experimental': 'https://img.shields.io/badge/experimental-important.svg?style=for-the-badge',\n    'Developer Preview': 'https://img.shields.io/badge/developer--preview-informational.svg?style=for-the-badge',\n    'Stable': 'https://img.shields.io/badge/stable-success.svg?style=for-the-badge',\n  };\n\n  public validate(pkg: PackageJson): void {\n    if (pkg.json.private || !pkg.json.features) {\n      return;\n    }\n\n    const featuresColumnWitdh = Math.max(\n      13, // 'CFN Resources'.length\n      ...pkg.json.features.map((feat: { name: string }) => feat.name.length),\n    );\n\n    const stabilityBanner: string = [\n      '<!--BEGIN STABILITY BANNER-->',\n      '',\n      '---',\n      '',\n      `Features${' '.repeat(featuresColumnWitdh - 8)} | Stability`,\n      `--------${'-'.repeat(featuresColumnWitdh - 8)}-|-----------${'-'.repeat(Math.max(0, 100 - featuresColumnWitdh - 13))}`,\n      ...this.featureEntries(pkg, featuresColumnWitdh),\n      '',\n      ...this.bannerNotices(pkg),\n      '---',\n      '',\n      '<!--END STABILITY BANNER-->',\n      '',\n    ].join('\\n');\n\n    const readmeFile = path.join(pkg.packageRoot, 'README.md');\n    if (!fs.existsSync(readmeFile)) {\n      // Presence of the file is asserted by another rule\n      return;\n    }\n    const readmeContent = fs.readFileSync(readmeFile, { encoding: 'utf8' });\n    const stabilityRegex = toRegExp(stabilityBanner);\n    if (!stabilityRegex.test(readmeContent)) {\n      const [title, ...body] = readmeContent.replace(/<!--BEGIN STABILITY BANNER-->(?:.|\\n)+<!--END STABILITY BANNER-->\\n+/m, '').split('\\n');\n      pkg.report({\n        ruleName: this.name,\n        message: 'Stability banner does not match as expected',\n        fix: () => fs.writeFileSync(readmeFile, [title, stabilityBanner, ...body].join('\\n')),\n      });\n    }\n  }\n\n  private featureEntries(pkg: PackageJson, featuresColumnWitdh: number): string[] {\n    const entries: string[] = [];\n    if (pkg.json['cdk-build']?.cloudformation) {\n      entries.push(`CFN Resources${' '.repeat(featuresColumnWitdh - 13)} | ![Stable](${this.badges.Stable})`);\n    }\n    pkg.json.features.forEach((feature: { [key: string]: string }) => {\n      const badge = this.badges[feature.stability];\n      if (!badge) {\n        throw new Error(`Unknown stability - ${feature.stability}`);\n      }\n      entries.push(`${feature.name}${' '.repeat(featuresColumnWitdh - feature.name.length)} | ![${feature.stability}](${badge})`);\n    });\n    return entries;\n  }\n\n  private bannerNotices(pkg: PackageJson): string[] {\n    const notices: string[] = [];\n    if (pkg.json['cdk-build']?.cloudformation) {\n      notices.push(readBannerFile('features-cfn-stable.md'));\n      notices.push('');\n    }\n\n    const noticeOrder = ['Experimental', 'Developer Preview', 'Stable'];\n    const stabilities = pkg.json.features.map((f: { [k: string]: string }) => f.stability);\n    const filteredNotices = noticeOrder.filter(v => stabilities.includes(v));\n    for (const notice of filteredNotices) {\n      if (notices.length !== 0) {\n        // This delimiter helps ensure proper parsing & rendering with various parsers\n        notices.push('<!-- -->', '');\n      }\n      const lowerTrainCase = notice.toLowerCase().replace(/\\s/g, '-');\n      notices.push(readBannerFile(`features-${lowerTrainCase}.md`));\n      notices.push('');\n    }\n    return notices;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, CloudWatch, CloudFormation resources", "output": "export class LambdaCloudwatchDashboardStack extends Stack {\n  private lambdaFunction: Function\n  private dashboard: Dashboard\n\n  constructor(scope: Construct, id: string, props: LambdaCloudwatchDashboardStackProps) {\n    super(scope, id, props);\n\n    // Create Sample Lambda Function which will create metrics\n    this.lambdaFunction = new Function(this, \"SampleLambda\", {\n      handler: \"lambda-handler.handler\",\n      runtime: Runtime.PYTHON_3_7,\n      code: new AssetCode(`./lambda`),\n      memorySize: 512,\n      timeout: Duration.seconds(10)\n    })\n\n    // Create CloudWatch Dashboard\n    this.dashboard = new Dashboard(this, \"SampleLambdaDashboard\", {\n      dashboardName: props.dashboardName\n    })\n\n    // Create Title for Dashboard\n    this.dashboard.addWidgets(new TextWidget({\n      markdown: `# Dashboard: ${this.lambdaFunction.functionName}`,\n      height: 1,\n      width: 24\n    }))\n\n    // Create CloudWatch Dashboard Widgets: Errors, Invocations, Duration, Throttles\n    this.dashboard.addWidgets(new GraphWidget({\n      title: \"Invocations\",\n      left: [this.lambdaFunction.metricInvocations()],\n      width: 24\n    }))\n\n    this.dashboard.addWidgets(new GraphWidget({\n      title: \"Errors\",\n      left: [this.lambdaFunction.metricErrors()],\n      width: 24\n    }))\n\n    this.dashboard.addWidgets(new GraphWidget({\n      title: \"Duration\",\n      left: [this.lambdaFunction.metricDuration()],\n      width: 24\n    }))\n\n    this.dashboard.addWidgets(new GraphWidget({\n      title: \"Throttles\",\n      left: [this.lambdaFunction.metricThrottles()],\n      width: 24\n    }))\n\n    // Create Widget to show last 20 Log Entries\n    this.dashboard.addWidgets(new LogQueryWidget({\n      logGroupNames: [this.lambdaFunction.logGroup.logGroupName],\n      queryLines:[\n        \"fields @timestamp, @message\",\n        \"sort @timestamp desc\",\n        \"limit 20\"],\n      width: 24,\n      }))\n\n    // Generate Outputs\n    const cloudwatchDashboardURL = `https://${Aws.REGION}.console.aws.amazon.com/cloudwatch/home?region=${Aws.REGION}#dashboards:name=${props.dashboardName}`;\n    new CfnOutput(this, 'DashboardOutput', {\n      value: cloudwatchDashboardURL,\n      description: 'URL of Sample CloudWatch Dashboard',\n      exportName: 'SampleCloudWatchDashboardURL'\n    });\n    new CfnOutput(this, 'LambdaName', {\n      value: this.lambdaFunction.functionName,\n      description: 'Name of the sample Lambda Function',\n      exportName: 'LambdaName'\n    });\n  };\n}", "language": "typescript"}
{"input": "An import source from a local file.", "output": "export class AssetImportSource extends ImportSource {\n  private asset?: s3_assets.Asset;\n\n  /**\n   * @param path the path to the local file\n   * @param options the configuration for the temporarily created S3 file\n   */\n  constructor(public readonly path: string, private readonly options: s3_assets.AssetOptions = {}) {\n    super();\n  }\n\n  /**\n   * @internal\n   */\n  public _bind(scope: Construct): CfnKeyValueStore.ImportSourceProperty {\n    if (!this.asset) {\n      this.asset = new s3_assets.Asset(scope, 'ImportSource', {\n        path: this.path,\n        deployTime: true,\n        ...this.options,\n      });\n    } else if (Stack.of(this.asset) !== Stack.of(scope)) {\n      throw new ValidationError(\n        `Asset is already associated with another stack '${Stack.of(this.asset).stackName}. ` +\n          'Create a new ImportSource instance for every stack.',\n        scope,\n      );\n    }\n\n    return {\n      sourceType: 'S3',\n      sourceArn: this.asset.bucket.arnForObjects(this.asset.s3ObjectKey),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudWatch Logs, CloudFormation resources", "output": "class LogGroupIntegStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n    const logGroup = new LogGroup(this, 'LogGroup');\n    logGroup.addToResourcePolicy(new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      actions: ['logs:PutLogEvents'],\n      principals: [new iam.AnyPrincipal()],\n      resources: [logGroup.logGroupArn],\n    }));\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: * aws docdb describe-db-cluster-snapshots --db-cluster-identifier <deployed db cluster identifier>", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: constructs.Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const params = new ClusterParameterGroup(this, 'Params', {\n      family: 'docdb3.6',\n      description: 'A nice parameter group',\n      parameters: {\n        audit_logs: 'disabled',\n        tls: 'enabled',\n        ttl_monitor: 'enabled',\n      },\n    });\n\n    const kmsKey = new kms.Key(this, 'DbSecurity', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const cluster = new DatabaseCluster(this, 'Database', {\n      engineVersion: '3.6.0',\n      masterUser: {\n        username: 'docdb',\n        password: cdk.SecretValue.unsafePlainText('7959866cacc02c2d243ecfe177464fe6'),\n      },\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.R5, ec2.InstanceSize.LARGE),\n      vpcSubnets: { subnetType: ec2.SubnetType.PUBLIC },\n      vpc,\n      parameterGroup: params,\n      kmsKey,\n      removalPolicy: cdk.RemovalPolicy.SNAPSHOT,\n      enablePerformanceInsights: true,\n    });\n\n    cluster.connections.allowDefaultPortFromAnyIpv4('Open to the world');\n  }\n}", "language": "typescript"}
{"input": "Connection endpoint of a neptune cluster or instance Consists of a combination of hostname and port.", "output": "export class Endpoint {\n  /**\n   * The hostname of the endpoint\n   */\n  public readonly hostname: string;\n\n  /**\n   * The port of the endpoint\n   */\n  public readonly port: number;\n\n  /**\n   * The combination of \"HOSTNAME:PORT\" for this endpoint\n   */\n  public readonly socketAddress: string;\n\n  constructor(address: string, port: number) {\n    this.hostname = address;\n    this.port = port;\n\n    const portDesc = Token.isUnresolved(port) ? Token.asString(port) : port;\n    this.socketAddress = `${address}:${portDesc}`;\n  }\n}", "language": "typescript"}
{"input": "A set of group metrics", "output": "export class GroupMetrics {\n  /**\n   * Report all group metrics.\n   */\n  public static all(): GroupMetrics {\n    return new GroupMetrics();\n  }\n\n  /**\n   * @internal\n   */\n  public _metrics = new Set<GroupMetric>();\n\n  constructor(...metrics: GroupMetric[]) {\n    metrics?.forEach(metric => this._metrics.add(metric));\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Step Functions operations", "output": "const resolver = (props: Expression) => {\n      if (propType.arrayOfType) {\n        const mapper = this.createMapperLambda(propType.arrayOfType, expr.directCode(buildChain('item')));\n        return CDK_CORE.mapArrayInPlace.call(expr.get(props, name), mapper);\n      } else {\n        return expr.directCode(buildChain(`props.${name}`));\n      }\n    }", "language": "typescript"}
{"input": "CDK class CdkCloudWatch for AWS resource management", "output": "export class CdkCloudWatch extends ExternalModule {\n  public readonly Metric = $T(Type.fromName(this, 'Metric'));\n  public readonly MetricOptions = Type.fromName(this, 'MetricOptions');\n}", "language": "typescript"}
{"input": "CDK class ImageRecipe for AWS resource management", "output": "export class ImageRecipe extends ImageRecipeBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.ImageRecipe';\n\n  /**\n   * Import an existing image recipe given its ARN.\n   */\n  public static fromImageRecipeArn(scope: Construct, id: string, imageRecipeArn: string): IImageRecipe {\n    return this.fromImageRecipeAttributes(scope, id, { imageRecipeArn });\n  }\n\n  /**\n   * Import the latest version of an existing image recipe given its name. The provided name must be normalized by\n   * converting all alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromImageRecipeName(scope: Construct, id: string, imageRecipeName: string): IImageRecipe {\n    return this.fromImageRecipeAttributes(scope, id, { imageRecipeName });\n  }\n\n  /**\n   * Import an existing image recipe by providing its attributes. If the image recipe name is provided as an attribute,\n   * it must be normalized by converting all alphabetical characters to lowercase, and replacing all spaces and\n   * underscores with hyphens.\n   */\n  public static fromImageRecipeAttributes(scope: Construct, id: string, attrs: ImageRecipeAttributes): IImageRecipe {\n    if (!attrs.imageRecipeArn && !attrs.imageRecipeName) {\n      throw new cdk.ValidationError(\n        'either imageRecipeArn or imageRecipeName must be provided to import an image recipe',\n        scope,\n      );\n    }\n\n    const imageRecipeArn =\n      attrs.imageRecipeArn ??\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'image-recipe',\n        resourceName: `${attrs.imageRecipeName}/${attrs.imageRecipeVersion ?? LATEST_VERSION}`,\n      });\n\n    const [imageRecipeName, imageRecipeVersion] = (() => {\n      if (attrs.imageRecipeName) {\n        return [attrs.imageRecipeName, attrs.imageRecipeVersion ?? LATEST_VERSION];\n      }\n\n      const imageRecipeNameVersion = cdk.Stack.of(scope).splitArn(\n        imageRecipeArn,\n        cdk.ArnFormat.SLASH_RESOURCE_NAME,\n      ).resourceName!;\n\n      const imageRecipeNameVersionSplit = cdk.Fn.split('/', imageRecipeNameVersion);\n      return [cdk.Fn.select(0, imageRecipeNameVersionSplit), cdk.Fn.select(1, imageRecipeNameVersionSplit)];\n    })();\n\n    class Import extends ImageRecipeBase {\n      public readonly imageRecipeArn = imageRecipeArn;\n      public readonly imageRecipeName = imageRecipeName;\n      public readonly imageRecipeVersion = imageRecipeVersion;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Return whether the given object is an ImageRecipe.\n   */\n  public static isImageRecipe(x: any): x is ImageRecipe {\n    return x !== null && typeof x === 'object' && IMAGE_RECIPE_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the image recipe\n   */\n  public readonly imageRecipeArn: string;\n\n  /**\n   * The name of the image recipe\n   */\n  public readonly imageRecipeName: string;\n\n  /**\n   * The version of the image recipe\n   */\n  public readonly imageRecipeVersion: string;\n\n  private readonly blockDevices: ec2.BlockDevice[] = [];\n\n  public constructor(scope: Construct, id: string, props: ImageRecipeProps) {\n    super(scope, id, {\n      physicalName:\n        props.imageRecipeName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, IMAGE_RECIPE_SYMBOL, { value: true });\n\n    this.validateImageRecipeName();\n\n    this.addBlockDevice(...(props.blockDevices ?? []));\n\n    const components: CfnImageRecipe.ComponentConfigurationProperty[] | undefined = props.components?.map(\n      (component) => ({\n        componentArn: component.component.componentArn,\n        ...(component.parameters && {\n          parameters: Object.entries(component.parameters).map(\n            ([name, param]): CfnImageRecipe.ComponentParameterProperty => ({\n              name,\n              value: param.value,\n            }),\n          ),\n        }),\n      }),\n    );\n\n    const imageRecipeVersion = props.imageRecipeVersion ?? DEFAULT_RECIPE_VERSION;\n    const imageRecipe = new CfnImageRecipe(this, 'Resource', {\n      name: this.physicalName,\n      version: imageRecipeVersion,\n      description: props.description,\n      parentImage: props.baseImage.image,\n      blockDeviceMappings: cdk.Lazy.any({ produce: () => this.renderBlockDevices() }),\n      workingDirectory: props.workingDirectory,\n      additionalInstanceConfiguration: this.buildAdditionalInstanceConfiguration(props),\n      amiTags: props.amiTags,\n      tags: props.tags,\n      ...(components?.length && { components }),\n    });\n\n    this.imageRecipeName = this.getResourceNameAttribute(imageRecipe.attrName);\n    this.imageRecipeArn = this.getResourceArnAttribute(imageRecipe.attrArn, {\n      service: 'imagebuilder',\n      resource: 'image-recipe',\n      resourceName: `${this.physicalName}/${imageRecipeVersion}`,\n    });\n    this.imageRecipeVersion = imageRecipe.getAtt('Version').toString();\n  }\n\n  /**\n   * Adds block devices to attach to the instance used for building the image.\n   *\n   * @param blockDevices The list of block devices to attach\n   */\n  @MethodMetadata()\n  public addBlockDevice(...blockDevices: ec2.BlockDevice[]): void {\n    this.blockDevices.push(...blockDevices);\n  }\n\n  /**\n   * Renders the input block devices, into the `BlockDeviceMapping[]` structure that CfnImageRecipe expects to receive.\n   * This is rendered at synthesis time, as users can add additional block devices with `addBlockDevice`, after the\n   * construct has been instantiated.\n   *\n   * @private\n   */\n  private renderBlockDevices(): CfnImageRecipe.InstanceBlockDeviceMappingProperty[] | undefined {\n    const blockDevices = this.blockDevices.map((blockDevice): CfnImageRecipe.InstanceBlockDeviceMappingProperty => {\n      const ebsDevice = blockDevice.volume.ebsDevice;\n      const ebs: CfnImageRecipe.EbsInstanceBlockDeviceSpecificationProperty = {\n        ...(ebsDevice?.deleteOnTermination !== undefined && { deleteOnTermination: ebsDevice.deleteOnTermination }),\n        ...(ebsDevice?.encrypted !== undefined && { encrypted: ebsDevice.encrypted }),\n        ...(ebsDevice?.iops !== undefined && { iops: ebsDevice.iops }),\n        ...(ebsDevice?.kmsKey !== undefined && { kmsKeyId: ebsDevice.kmsKey.keyArn }),\n        ...(ebsDevice?.snapshotId !== undefined && { snapshotId: ebsDevice.snapshotId }),\n        ...(ebsDevice?.throughput !== undefined && { throughput: ebsDevice.throughput }),\n        ...(ebsDevice?.volumeSize !== undefined && { volumeSize: ebsDevice.volumeSize }),\n        ...(ebsDevice?.volumeType !== undefined && { volumeType: ebsDevice.volumeType }),\n      };\n\n      return {\n        deviceName: blockDevice.deviceName,\n        virtualName: blockDevice.volume.virtualName,\n        ...(blockDevice.mappingEnabled === false && { noDevice: '' }),\n        ...(Object.keys(ebs).length && { ebs }),\n      };\n    });\n\n    return blockDevices.length ? blockDevices : undefined;\n  }\n\n  /**\n   * Generates the additional instance configuration property into the `AdditionalInstanceConfiguration` type in the\n   * CloudFormation L1 definition.\n   *\n   * @param props The props passed as input to the construct\n   * @private\n   */\n  private buildAdditionalInstanceConfiguration(\n    props: ImageRecipeProps,\n  ): CfnImageRecipe.AdditionalInstanceConfigurationProperty | undefined {\n    const systemsManagerAgent: CfnImageRecipe.SystemsManagerAgentProperty = {\n      ...(props.uninstallSsmAgentAfterBuild !== undefined && {\n        uninstallAfterBuild: props.uninstallSsmAgentAfterBuild,\n      }),\n    };\n\n    const additionalInstanceConfiguration: CfnImageRecipe.AdditionalInstanceConfigurationProperty = {\n      ...(Object.keys(systemsManagerAgent).length && { systemsManagerAgent }),\n      ...(props.userDataOverride !== undefined && { userDataOverride: cdk.Fn.base64(props.userDataOverride.render()) }),\n    };\n\n    return Object.keys(additionalInstanceConfiguration).length ? additionalInstanceConfiguration : undefined;\n  }\n\n  private validateImageRecipeName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError(\n        `the imageRecipeName cannot be longer than 128 characters, got: '${this.physicalName}'`,\n        this,\n      );\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError(`the imageRecipeName cannot contain spaces, got: '${this.physicalName}'`, this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError(\n        `the imageRecipeName cannot contain underscores, got: '${this.physicalName}'`,\n        this,\n      );\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError(`the imageRecipeName must be lowercase, got: '${this.physicalName}'`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "Represents a statement in an IAM policy document.", "output": "export class PolicyStatement {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-iam.PolicyStatement';\n\n  /**\n   * Creates a new PolicyStatement based on the object provided.\n   * This will accept an object created from the `.toJSON()` call\n   * @param obj the PolicyStatement in object form.\n   */\n  public static fromJson(obj: any) {\n    const ret = new PolicyStatement({\n      sid: obj.Sid,\n      actions: ensureArrayOrUndefined(obj.Action),\n      resources: ensureArrayOrUndefined(obj.Resource),\n      conditions: obj.Condition,\n      effect: obj.Effect,\n      notActions: ensureArrayOrUndefined(obj.NotAction),\n      notResources: ensureArrayOrUndefined(obj.NotResource),\n      principals: obj.Principal ? [new JsonPrincipal(obj.Principal)] : undefined,\n      notPrincipals: obj.NotPrincipal ? [new JsonPrincipal(obj.NotPrincipal)] : undefined,\n    });\n\n    // validate that the PolicyStatement has the correct shape\n    const errors = ret.validateForAnyPolicy();\n    if (errors.length > 0) {\n      throw new UnscopedValidationError('Incorrect Policy Statement: ' + errors.join('\\n'));\n    }\n\n    return ret;\n  }\n\n  private readonly _action = new OrderedSet<string>();\n  private readonly _notAction = new OrderedSet<string>();\n  private readonly _principal: { [key: string]: any[] } = {};\n  private readonly _notPrincipal: { [key: string]: any[] } = {};\n  private readonly _resource = new OrderedSet<string>();\n  private readonly _notResource = new OrderedSet<string>();\n  private readonly _condition: { [key: string]: any } = { };\n  private _sid?: string;\n  private _effect: Effect;\n  private principalConditionsJson?: string;\n\n  // Hold on to those principals\n  private readonly _principals = new OrderedSet<IPrincipal>();\n  private readonly _notPrincipals = new OrderedSet<IPrincipal>();\n  private _frozen = false;\n\n  constructor(props: PolicyStatementProps = {}) {\n    this._sid = props.sid;\n    this._effect = props.effect || Effect.ALLOW;\n\n    this.addActions(...props.actions || []);\n    this.addNotActions(...props.notActions || []);\n    this.addPrincipals(...props.principals || []);\n    this.addNotPrincipals(...props.notPrincipals || []);\n    this.addResources(...props.resources || []);\n    this.addNotResources(...props.notResources || []);\n    if (props.conditions !== undefined) {\n      this.addConditions(props.conditions);\n    }\n  }\n\n  /**\n   * Statement ID for this statement\n   */\n  public get sid(): string | undefined {\n    return this._sid;\n  }\n\n  /**\n   * Set Statement ID for this statement\n   */\n  public set sid(sid: string | undefined) {\n    this.assertNotFrozen('sid');\n    this._sid = sid;\n  }\n\n  /**\n   * Whether to allow or deny the actions in this statement\n   */\n  public get effect(): Effect {\n    return this._effect;\n  }\n\n  /**\n   * Set effect for this statement\n   */\n  public set effect(effect: Effect) {\n    this.assertNotFrozen('effect');\n    this._effect = effect;\n  }\n\n  //\n  // Actions\n  //\n\n  /**\n   * Specify allowed actions into the \"Action\" section of the policy statement.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_action.html\n   *\n   * @param actions actions that will be allowed.\n   */\n  public addActions(...actions: string[]) {\n    this.assertNotFrozen('addActions');\n    if (actions.length > 0 && this._notAction.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'Actions\\' to policy statement if \\'NotActions\\' have been added');\n    }\n    this.validatePolicyActions(actions);\n    this._action.push(...actions);\n  }\n\n  /**\n   * Explicitly allow all actions except the specified list of actions into the \"NotAction\" section\n   * of the policy document.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_notaction.html\n   *\n   * @param notActions actions that will be denied. All other actions will be permitted.\n   */\n  public addNotActions(...notActions: string[]) {\n    this.assertNotFrozen('addNotActions');\n    if (notActions.length > 0 && this._action.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'NotActions\\' to policy statement if \\'Actions\\' have been added');\n    }\n    this.validatePolicyActions(notActions);\n    this._notAction.push(...notActions);\n  }\n\n  //\n  // Principal\n  //\n\n  /**\n   * Indicates if this permission has a \"Principal\" section.\n   */\n  public get hasPrincipal() {\n    return this._principals.length + this._notPrincipals.length > 0;\n  }\n\n  /**\n   * Adds principals to the \"Principal\" section of a policy statement.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_principal.html\n   *\n   * @param principals IAM principals that will be added\n   */\n  public addPrincipals(...principals: IPrincipal[]) {\n    this.assertNotFrozen('addPrincipals');\n    if (principals.length > 0 && this._notPrincipals.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'Principals\\' to policy statement if \\'NotPrincipals\\' have been added');\n    }\n    for (const principal of principals) {\n      this.validatePolicyPrincipal(principal);\n    }\n\n    const added = this._principals.push(...principals);\n    for (const principal of added) {\n      const fragment = principal.policyFragment;\n      mergePrincipal(this._principal, fragment.principalJson);\n      this.addPrincipalConditions(fragment.conditions);\n    }\n  }\n\n  /**\n   * Specify principals that is not allowed or denied access to the \"NotPrincipal\" section of\n   * a policy statement.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_notprincipal.html\n   *\n   * @param notPrincipals IAM principals that will be denied access\n   */\n  public addNotPrincipals(...notPrincipals: IPrincipal[]) {\n    this.assertNotFrozen('addNotPrincipals');\n    if (notPrincipals.length > 0 && this._principals.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'NotPrincipals\\' to policy statement if \\'Principals\\' have been added');\n    }\n    for (const notPrincipal of notPrincipals) {\n      this.validatePolicyPrincipal(notPrincipal);\n    }\n\n    const added = this._notPrincipals.push(...notPrincipals);\n    for (const notPrincipal of added) {\n      const fragment = notPrincipal.policyFragment;\n      mergePrincipal(this._notPrincipal, fragment.principalJson);\n      this.addPrincipalConditions(fragment.conditions);\n    }\n  }\n\n  private validatePolicyActions(actions: string[]) {\n    // In case of an unresolved list of actions return early\n    if (cdk.Token.isUnresolved(actions)) return;\n    for (const action of actions || []) {\n      if (!cdk.Token.isUnresolved(action) && !/^(\\*|[a-zA-Z0-9-]+:[a-zA-Z0-9*]+)$/.test(action)) {\n        throw new UnscopedValidationError(`Action '${action}' is invalid. An action string consists of a service namespace, a colon, and the name of an action. Action names can include wildcards.`);\n      }\n    }\n  }\n\n  private validatePolicyPrincipal(principal: IPrincipal) {\n    if (principal instanceof Group) {\n      throw new UnscopedValidationError('Cannot use an IAM Group as the \\'Principal\\' or \\'NotPrincipal\\' in an IAM Policy');\n    }\n  }\n\n  /**\n   * Specify AWS account ID as the principal entity to the \"Principal\" section of a policy statement.\n   */\n  public addAwsAccountPrincipal(accountId: string) {\n    this.addPrincipals(new AccountPrincipal(accountId));\n  }\n\n  /**\n   * Specify a principal using the ARN  identifier of the principal.\n   * You cannot specify IAM groups and instance profiles as principals.\n   *\n   * @param arn ARN identifier of AWS account, IAM user, or IAM role (i.e. arn:aws:iam::123456789012:user/user-name)\n   */\n  public addArnPrincipal(arn: string) {\n    this.addPrincipals(new ArnPrincipal(arn));\n  }\n\n  /**\n   * Adds a service principal to this policy statement.\n   *\n   * @param service the service name for which a service principal is requested (e.g: `s3.amazonaws.com`).\n   * @param opts    options for adding the service principal (such as specifying a principal in a different region)\n   */\n  public addServicePrincipal(service: string, opts?: ServicePrincipalOpts) {\n    this.addPrincipals(new ServicePrincipal(service, opts));\n  }\n\n  /**\n   * Adds a federated identity provider such as Amazon Cognito to this policy statement.\n   *\n   * @param federated federated identity provider (i.e. 'cognito-identity.amazonaws.com')\n   * @param conditions The conditions under which the policy is in effect.\n   *   See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   */\n  public addFederatedPrincipal(federated: any, conditions: Conditions) {\n    this.addPrincipals(new FederatedPrincipal(federated, conditions));\n  }\n\n  /**\n   * Adds an AWS account root user principal to this policy statement\n   */\n  public addAccountRootPrincipal() {\n    this.addPrincipals(new AccountRootPrincipal());\n  }\n\n  /**\n   * Adds a canonical user ID principal to this policy document\n   *\n   * @param canonicalUserId unique identifier assigned by AWS for every account\n   */\n  public addCanonicalUserPrincipal(canonicalUserId: string) {\n    this.addPrincipals(new CanonicalUserPrincipal(canonicalUserId));\n  }\n\n  /**\n   * Adds all identities in all accounts (\"*\") to this policy statement\n   */\n  public addAnyPrincipal() {\n    this.addPrincipals(new AnyPrincipal());\n  }\n\n  //\n  // Resources\n  //\n\n  /**\n   * Specify resources that this policy statement applies into the \"Resource\" section of\n   * this policy statement.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_resource.html\n   *\n   * @param arns Amazon Resource Names (ARNs) of the resources that this policy statement applies to\n   */\n  public addResources(...arns: string[]) {\n    this.assertNotFrozen('addResources');\n    if (arns.length > 0 && this._notResource.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'Resources\\' to policy statement if \\'NotResources\\' have been added');\n    }\n    this._resource.push(...arns);\n  }\n\n  /**\n   * Specify resources that this policy statement will not apply to in the \"NotResource\" section\n   * of this policy statement. All resources except the specified list will be matched.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_notresource.html\n   *\n   * @param arns Amazon Resource Names (ARNs) of the resources that this policy statement does not apply to\n   */\n  public addNotResources(...arns: string[]) {\n    this.assertNotFrozen('addNotResources');\n    if (arns.length > 0 && this._resource.length > 0) {\n      throw new UnscopedValidationError('Cannot add \\'NotResources\\' to policy statement if \\'Resources\\' have been added');\n    }\n    this._notResource.push(...arns);\n  }\n\n  /**\n   * Adds a ``\"*\"`` resource to this statement.\n   */\n  public addAllResources() {\n    this.addResources('*');\n  }\n\n  /**\n   * Indicates if this permission has at least one resource associated with it.\n   */\n  public get hasResource() {\n    return this._resource && this._resource.length > 0;\n  }\n\n  //\n  // Condition\n  //\n\n  /**\n   * Add a condition to the Policy\n   *\n   * If multiple calls are made to add a condition with the same operator and field, only\n   * the last one wins. For example:\n   *\n   * ```ts\n   * declare const stmt: iam.PolicyStatement;\n   *\n   * stmt.addCondition('StringEquals', { 'aws:SomeField': '1' });\n   * stmt.addCondition('StringEquals', { 'aws:SomeField': '2' });\n   * ```\n   *\n   * Will end up with the single condition `StringEquals: { 'aws:SomeField': '2' }`.\n   *\n   * If you meant to add a condition to say that the field can be *either* `1` or `2`, write\n   * this:\n   *\n   * ```ts\n   * declare const stmt: iam.PolicyStatement;\n   *\n   * stmt.addCondition('StringEquals', { 'aws:SomeField': ['1', '2'] });\n   * ```\n   */\n  public addCondition(key: string, value: Condition) {\n    this.assertNotFrozen('addCondition');\n    validateConditionObject(value);\n\n    const existingValue = this._condition[key];\n    this._condition[key] = existingValue ? { ...existingValue, ...value } : value;\n  }\n\n  /**\n   * Add multiple conditions to the Policy\n   *\n   * See the `addCondition` function for a caveat on calling this method multiple times.\n   */\n  public addConditions(conditions: Conditions) {\n    Object.keys(conditions).map(key => {\n      this.addCondition(key, conditions[key]);\n    });\n  }\n\n  /**\n   * Add a `StringEquals` condition that limits to a given account from `sts:ExternalId`.\n   *\n   * This method can only be called once: subsequent calls will overwrite earlier calls.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html\n   */\n  public addAccountCondition(accountId: string) {\n    this.addCondition('StringEquals', { 'sts:ExternalId': accountId });\n  }\n\n  /**\n   * Add an `StringEquals` condition that limits to a given account from `aws:SourceAccount`.\n   *\n   * This method can only be called once: subsequent calls will overwrite earlier calls.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourceaccount\n   */\n  public addSourceAccountCondition(accountId: string) {\n    this.addCondition('StringEquals', { 'aws:SourceAccount': accountId });\n  }\n\n  /**\n   * Add an `ArnEquals` condition that limits to a given resource arn from `aws:SourceArn`.\n   *\n   * This method can only be called once: subsequent calls will overwrite earlier calls.\n   *\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-keys.html#condition-keys-sourcearn\n   */\n  public addSourceArnCondition(arn: string) {\n    this.addCondition('ArnEquals', { 'aws:SourceArn': arn });\n  }\n\n  /**\n   * Create a new `PolicyStatement` with the same exact properties\n   * as this one, except for the overrides\n   */\n  public copy(overrides: PolicyStatementProps = {}) {\n    return new PolicyStatement({\n      sid: overrides.sid ?? this.sid,\n      effect: overrides.effect ?? this.effect,\n      actions: overrides.actions ?? this.actions,\n      notActions: overrides.notActions ?? this.notActions,\n\n      principals: overrides.principals ?? this.principals,\n      notPrincipals: overrides.notPrincipals ?? this.notPrincipals,\n\n      resources: overrides.resources ?? this.resources,\n      notResources: overrides.notResources ?? this.notResources,\n\n      conditions: overrides.conditions ?? this.conditions,\n    });\n  }\n\n  /**\n   * JSON-ify the policy statement\n   *\n   * Used when JSON.stringify() is called\n   */\n  public toStatementJson(): any {\n    return normalizeStatement({\n      Action: this._action.direct(),\n      NotAction: this._notAction.direct(),\n      Condition: this._condition,\n      Effect: this.effect,\n      Principal: this._principal,\n      NotPrincipal: this._notPrincipal,\n      Resource: this._resource.direct(),\n      NotResource: this._notResource.direct(),\n      Sid: this.sid,\n    });\n  }\n\n  /**\n   * String representation of this policy statement\n   */\n  public toString() {\n    return cdk.Token.asString(this, {\n      displayHint: 'PolicyStatement',\n    });\n  }\n\n  /**\n   * JSON-ify the statement\n   *\n   * Used when JSON.stringify() is called\n   */\n  public toJSON() {\n    return this.toStatementJson();\n  }\n\n  /**\n   * Add a principal's conditions\n   *\n   * For convenience, principals have been modeled as both a principal\n   * and a set of conditions. This makes it possible to have a single\n   * object represent e.g. an \"SNS Topic\" (SNS service principal + aws:SourcArn\n   * condition) or an Organization member (* + aws:OrgId condition).\n   *\n   * However, when using multiple principals in the same policy statement,\n   * they must all have the same conditions or the OR samentics\n   * implied by a list of principals cannot be guaranteed (user needs to\n   * add multiple statements in that case).\n   */\n  private addPrincipalConditions(conditions: Conditions) {\n    // Stringifying the conditions is an easy way to do deep equality\n    const theseConditions = JSON.stringify(conditions);\n    if (this.principalConditionsJson === undefined) {\n      // First principal, anything goes\n      this.principalConditionsJson = theseConditions;\n    } else {\n      if (this.principalConditionsJson !== theseConditions) {\n        throw new UnscopedValidationError(`All principals in a PolicyStatement must have the same Conditions (got '${this.principalConditionsJson}' and '${theseConditions}'). Use multiple statements instead.`);\n      }\n    }\n    this.addConditions(conditions);\n  }\n\n  /**\n   * Validate that the policy statement satisfies base requirements for a policy.\n   *\n   * @returns An array of validation error messages, or an empty array if the statement is valid.\n   */\n  public validateForAnyPolicy(): string[] {\n    const errors = new Array<string>();\n    if (this._action.length === 0 && this._notAction.length === 0) {\n      errors.push('A PolicyStatement must specify at least one \\'action\\' or \\'notAction\\'.');\n    }", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation, CodePipeline, CodeBuild resources", "output": "export class CIStack extends Stack {\n    constructor(scope: Construct, name: string, props: CIStackProps) {\n        super(scope, name, props)\n\n        const pipeline = new Pipeline(this, \"Pipeline\", {})\n\n        const repo = Repository.fromRepositoryName(\n            this,\n            \"WidgetsServiceRepository\",\n            props.repositoryName,\n        )\n        const sourceOutput = new Artifact(\"SourceOutput\")\n        const sourceAction = new CodeCommitSourceAction({\n            actionName: \"CodeCommit\",\n            repository: repo,\n            output: sourceOutput,\n            branch: \"main\",\n        })\n        pipeline.addStage({\n            stageName: \"Source\",\n            actions: [sourceAction],\n        })\n\n        this.createBuildStage(pipeline, sourceOutput)\n    }\n\n    private createBuildStage(pipeline: Pipeline, sourceOutput: Artifact) {\n        const project = new PipelineProject(this, `BuildProject`, {\n            environment: {\n                buildImage: LinuxBuildImage.STANDARD_7_0,\n            },\n        })\n        const cdkAssumeRolePolicy = new PolicyStatement()\n        cdkAssumeRolePolicy.addActions(\"sts:AssumeRole\")\n        cdkAssumeRolePolicy.addResources(\n            this.formatArn({\n                service: \"iam\",\n                resource: \"role\",\n                region: \"\",\n                resourceName: \"cdk-*\",\n            }),\n        )\n        const cdkDeployPolicy = new PolicyStatement()\n        cdkDeployPolicy.addActions(\n            \"cloudformation:GetTemplate\",\n            \"cloudformation:CreateChangeSet\",\n            \"cloudformation:DescribeChangeSet\",\n            \"cloudformation:ExecuteChangeSet\",\n            \"cloudformation:DescribeStackEvents\",\n            \"cloudformation:DeleteChangeSet\",\n            \"cloudformation:DescribeStacks\",\n            \"s3:*Object\",\n            \"s3:ListBucket\",\n            \"s3:getBucketLocation\",\n            \"lambda:UpdateFunctionCode\",\n            \"lambda:GetFunction\",\n            \"lambda:CreateFunction\",\n            \"lambda:DeleteFunction\",\n            \"lambda:GetFunctionConfiguration\",\n            \"lambda:AddPermission\",\n            \"lambda:RemovePermission\",\n            \"ssm:GetParameter\",\n        )\n        cdkDeployPolicy.addResources(\n            this.formatArn({\n                service: \"cloudformation\",\n                resource: \"stack\",\n                resourceName: \"CDKToolkit/*\",\n            }),\n            this.formatArn({\n                service: \"cloudformation\",\n                resource: \"stack\",\n                resourceName: `${lambdaApiStackName}/*`,\n            }),\n            this.formatArn({\n                service: \"lambda\",\n                resource: \"function\",\n                arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n                resourceName: lambdaFunctionName,\n            }),\n            this.formatArn({\n                service: \"ssm\",\n                resource: \"parameter\",\n                resourceName: \"cdk-bootstrap/*\",\n            }),\n            \"arn:aws:s3:::cdktoolkit-stagingbucket-*\",\n        )\n        const editOrCreateLambdaDependencies = new PolicyStatement()\n        editOrCreateLambdaDependencies.addActions(\n            \"iam:GetRole\",\n            \"iam:PassRole\",\n            \"iam:CreateRole\",\n            \"iam:AttachRolePolicy\",\n            \"iam:PutRolePolicy\",\n            \"apigateway:GET\",\n            \"apigateway:DELETE\",\n            \"apigateway:PUT\",\n            \"apigateway:POST\",\n            \"apigateway:PATCH\",\n            \"s3:CreateBucket\",\n            \"s3:PutBucketTagging\",\n        )\n        editOrCreateLambdaDependencies.addResources(\"*\")\n        project.addToRolePolicy(cdkDeployPolicy)\n        project.addToRolePolicy(editOrCreateLambdaDependencies)\n        project.addToRolePolicy(cdkAssumeRolePolicy)\n\n        const buildOutput = new Artifact(`BuildOutput`)\n        const buildAction = new CodeBuildAction({\n            actionName: `Build`,\n            project,\n            input: sourceOutput,\n            outputs: [buildOutput],\n        })\n\n        pipeline.addStage({\n            stageName: \"build\",\n            actions: [buildAction],\n        })\n\n        return buildOutput\n    }\n}", "language": "typescript"}
{"input": "CDK class AppStage for AWS resource management", "output": "class AppStage extends Stage {\n  public readonly output: CfnOutput;\n\n  constructor(scope: Construct, id: string, props?: StageProps) {\n    super(scope, id, props);\n\n    const stack = new Stack(this, 'Stack');\n    this.output = new CfnOutput(stack, 'OutputVariable', { value: 'Hello' });\n  }\n}", "language": "typescript"}
{"input": "Passing L1 & L2 key to L2 Events.Rule with cloudtrail pattern", "output": "class L1L2KeyWithL2Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l1Key = new CfnKey(this, 'KeyL1', {});\n    const l1KeyWithEvent = KeyEvents.fromKey(l1Key);\n\n    const l2Key = new Key(this, 'KeyL2', {});\n    const l2KeyWithEvent = KeyEvents.fromKey(l2Key);\n\n    const fn = new Function(this, 'MyFuncA', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n\n    const rule = new Rule(this, 'L2RuleForL1', {\n      targets: [new LambdaFunction(fn)],\n    });\n\n    rule.addEventPattern(l1KeyWithEvent.awsAPICallViaCloudTrailPattern({}));\n    rule.addEventPattern(l2KeyWithEvent.awsAPICallViaCloudTrailPattern({ eventName: ['RotateKeyOnDemand'] }));\n  }\n}", "language": "typescript"}
{"input": "CDK helper function validator", "output": "const validator = (value: string) => {\n        const errors: string[] = [];\n        if (value !== 'valid') {\n          errors.push('Value must be \"valid\"');\n        }\n        return errors;\n      }", "language": "typescript"}
{"input": "CDK Stack that creates S3, AppSync, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class OpensSearch23Stack extends cdk.Stack {\n  constructor(scope: Construct) {\n    super(scope, 'appsync-opensearch');\n\n    const user = new User(this, 'User');\n\n    const domain = new opensearch.Domain(this, 'Domain', {\n      version: opensearch.EngineVersion.OPENSEARCH_2_3,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      fineGrainedAccessControl: {\n        masterUserArn: user.userArn,\n      },\n      encryptionAtRest: {\n        enabled: true,\n      },\n      nodeToNodeEncryption: true,\n      enforceHttps: true,\n      capacity: {\n        multiAzWithStandbyEnabled: false,\n      },\n    });\n\n    const api = new appsync.GraphqlApi(this, 'api', {\n      name: 'api',\n      schema: appsync.SchemaFile.fromAsset(path.join(__dirname, 'appsync.test.graphql')),\n    });\n\n    const ds = api.addOpenSearchDataSource('ds', domain);\n\n    ds.createResolver('QueryGetTests', {\n      typeName: 'Query',\n      fieldName: 'getTests',\n      requestMappingTemplate: appsync.MappingTemplate.fromString(JSON.stringify({\n        version: '2017-02-28',\n        operation: 'GET',\n        path: '/id/post/_search',\n        params: {\n          headers: {},\n          queryString: {},\n          body: {\n            from: 0,\n            size: 50,\n          },\n        },\n      })),\n      responseMappingTemplate: appsync.MappingTemplate.fromString(JSON.stringify({\n        version: '2017-02-28',\n        operation: 'GET',\n        path: '/id/post/_search',\n        params: {\n          headers: {},\n          queryString: {},\n          body: {\n            from: 0,\n            size: 50,\n            query: {\n              term: {\n                author: '$util.toJson($context.arguments.author)',\n              },\n            },\n          },\n        },\n      })),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Dashboard for AWS resource management", "output": "export class Dashboard extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cloudwatch.Dashboard';\n  /**\n   * The name of this dashboard\n   *\n   * @attribute\n   */\n  public readonly dashboardName: string;\n\n  /**\n   * ARN of this dashboard\n   *\n   * @attribute\n   */\n  public readonly dashboardArn: string;\n\n  private readonly rows: IWidget[] = [];\n\n  private readonly variables: IVariable[] = [];\n\n  constructor(scope: Construct, id: string, props: DashboardProps = {}) {\n    super(scope, id, {\n      physicalName: props.dashboardName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    {\n      const { dashboardName } = props;\n      if (dashboardName && !Token.isUnresolved(dashboardName) && !dashboardName.match(/^[\\w-]+$/)) {\n        throw new ValidationError([\n          `The value ${dashboardName} for field dashboardName contains invalid characters.`,\n          'It can only contain alphanumerics, dash (-) and underscore (_).',\n        ].join(' '), this);\n      }\n    }\n\n    if (props.start !== undefined && props.defaultInterval !== undefined) {\n      throw new ValidationError('both properties defaultInterval and start cannot be set at once', this);\n    }\n\n    if (props.end !== undefined && props.start === undefined) {\n      throw new ValidationError('If you specify a value for end, you must also specify a value for start.', this);\n    }\n\n    const dashboard = new CfnDashboard(this, 'Resource', {\n      dashboardName: this.physicalName,\n      dashboardBody: Lazy.string({\n        produce: () => {\n          const column = new Column(...this.rows);\n          column.position(0, 0);\n          return Stack.of(this).toJsonString({\n            start: props.defaultInterval !== undefined ? `-${props.defaultInterval?.toIsoString()}` : props.start,\n            end: props.defaultInterval !== undefined ? undefined : props.end,\n            periodOverride: props.periodOverride,\n            widgets: column.toJson(),\n            variables: this.variables.length > 0 ? this.variables.map(variable => variable.toJson()) : undefined,\n          });\n        },\n      }),\n    });\n\n    this.dashboardName = this.getResourceNameAttribute(dashboard.ref);\n\n    (props.widgets || []).forEach(row => {\n      this.addWidgets(...row);\n    });\n\n    (props.variables || []).forEach(variable => this.addVariable(variable));\n\n    this.dashboardArn = Stack.of(this).formatArn({\n      service: 'cloudwatch',\n      resource: 'dashboard',\n      region: '',\n      resourceName: this.physicalName,\n    });\n  }\n\n  /**\n   * Add a widget to the dashboard.\n   *\n   * Widgets given in multiple calls to add() will be laid out stacked on\n   * top of each other.\n   *\n   * Multiple widgets added in the same call to add() will be laid out next\n   * to each other.\n   */\n  @MethodMetadata()\n  public addWidgets(...widgets: IWidget[]) {\n    if (widgets.length === 0) {\n      return;\n    }\n\n    const warnings = allWidgetsDeep(widgets).reduce((prev, curr) => {\n      return {\n        ...prev,\n        ...curr.warningsV2,\n      };\n    }, {} as { [id: string]: string });\n    for (const [id, message] of Object.entries(warnings ?? {})) {\n      Annotations.of(this).addWarningV2(id, message);\n    }\n\n    const w = widgets.length > 1 ? new Row(...widgets) : widgets[0];\n    this.rows.push(w);\n  }\n\n  /**\n   * Add a variable to the dashboard.\n   *\n   * @see https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_dashboard_variables.html\n   */\n  @MethodMetadata()\n  public addVariable(variable: IVariable) {\n    this.variables.push(variable);\n  }\n}", "language": "typescript"}
{"input": "Determines whether any URL query strings in viewer requests (and if so, which query strings) are included in requests that CloudFront sends to the origin.", "output": "export class OriginRequestQueryStringBehavior {\n  /**\n   * Query strings in viewer requests are not included in requests that CloudFront sends to the origin.\n   * Any query strings that are listed in a CachePolicy are still included in origin requests.\n   */\n  public static none() { return new OriginRequestQueryStringBehavior('none'); }\n\n  /** All query strings in viewer requests are included in requests that CloudFront sends to the origin. */\n  public static all() { return new OriginRequestQueryStringBehavior('all'); }\n\n  /** Only the provided `queryStrings` are included in requests that CloudFront sends to the origin. */\n  public static allowList(...queryStrings: string[]) {\n    if (queryStrings.length === 0) {\n      throw new UnscopedValidationError('At least one query string to allow must be provided');\n    }\n    return new OriginRequestQueryStringBehavior('whitelist', queryStrings);\n  }\n\n  /** All query strings except the provided `queryStrings` are included in requests that CloudFront sends to the origin. */\n  public static denyList(...queryStrings: string[]) {\n    if (queryStrings.length === 0) {\n      throw new UnscopedValidationError('At least one query string to deny must be provided');\n    }\n    return new OriginRequestQueryStringBehavior('allExcept', queryStrings);\n  }\n\n  /** The behavior of query strings -- allow all, none, or only an allow list. */\n  public readonly behavior: string;\n  /** The query strings to allow, if the behavior is an allow list. */\n  public readonly queryStrings?: string[];\n\n  private constructor(behavior: string, queryStrings?: string[]) {\n    this.behavior = behavior;\n    this.queryStrings = queryStrings;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, Secrets Manager, SSM Parameter Store resources", "output": "class StackUnderTest extends Stack {\n  constructor(scope: Construct, id: string, props: StackUnderTestProps) {\n    super(scope, id, props);\n\n    const parameter = new StringParameter(this, 'Parameter', {\n      parameterName: `email_url_${id}`,\n      stringValue: 'api.example.com',\n    });\n    const secret = new Secret(this, 'MySecret');\n\n    const paramsAndSecrets = ParamsAndSecretsLayerVersion.fromVersion(ParamsAndSecretsVersions.V1_0_103, {\n      cacheSize: 100,\n      cacheEnabled: true,\n      httpPort: 8080,\n      logLevel: ParamsAndSecretsLogLevel.DEBUG,\n      maxConnections: 5,\n      secretsManagerTtl: cdk.Duration.seconds(100),\n      parameterStoreTtl: cdk.Duration.seconds(100),\n    });\n\n    const lambdaFunction = new Function(this, 'MyFunc', {\n      runtime: Runtime.NODEJS_20_X,\n      handler: 'index.handler',\n      code: Code.fromAsset(path.join(__dirname, 'params-and-secrets-handler')),\n      architecture: props.architecture,\n      paramsAndSecrets,\n    });\n\n    secret.grantRead(lambdaFunction);\n    parameter.grantRead(lambdaFunction);\n  }\n}", "language": "typescript"}
{"input": "Class to parse and update the metadata of enum-like classes. These are classes which are similar to enums, but map to classes rather than primitive types.", "output": "export class MissingEnumsUpdater {\n    \n  private CUSTOM_PARAM_MAPPINGS: { [cdkModule: string]: {[cdkEnumLike: string]: any}} = {\n    \"module\": {\n      \"EnumLike\": (param1: string) => {\n        return `${param1}, ${param1.toUpperCase()}`\n      }\n    }\n  }\n\n  protected project: Project;\n\n  constructor(dir: string) {\n    const projectDir = path.resolve(__dirname, dir);\n\n    // Initialize a ts-morph Project\n    this.project = new Project({\n      tsConfigFilePath: path.resolve(__dirname, \"../tsconfig.json\"),\n      manipulationSettings: {\n        quoteKind: QuoteKind.Single,\n        indentationText: IndentationText.TwoSpaces\n      },\n    });\n    this.project.addSourceFilesAtPaths(this.readTypescriptFiles(projectDir));\n\n    console.log(\"Transformation complete.\");\n  }\n\n  /**\n   * Recursively collect all .ts files from a given directory.\n   */\n  private readTypescriptFiles(dir: string, filesList: string[] = []) {\n    const files = fs.readdirSync(dir);\n\n    files.forEach((file) => {\n      const filePath = path.join(dir, file);\n      if (fs.statSync(filePath).isDirectory()) {\n        // Check if this directory is in the list of directories to skip\n        if (!DIRECTORIES_TO_SKIP.includes(file)) {\n          this.readTypescriptFiles(filePath, filesList);\n        }\n      } else if (\n        filePath.endsWith(\".ts\") &&\n        !filePath.endsWith(\".generated.ts\") &&\n        !filePath.endsWith(\".d.ts\") &&\n        !file.includes(\"test\")\n      ) {\n        filesList.push(filePath);\n      }\n    });\n\n    return filesList;\n  }\n\n  /**\n   * Identifies missing enum values by comparing CDK enums with AWS SDK enums based on a static mapping.\n   */\n  private async findMissingValues(\n    staticMapping: StaticMapping,\n    cdkEnums: CdkEnums,\n    sdkEnums: SdkEnums,\n    exclusions: Record<string, any>\n  ): Promise<MissingValues> {\n    const missingValues: MissingValues = {};\n  \n    for (const [module, enums] of Object.entries(staticMapping)) {\n      for (const [enumName, mapping] of Object.entries(enums)) {\n        const cdkValues = cdkEnums[module][enumName].values;\n        const sdkValues = sdkEnums[mapping.sdk_service][mapping.sdk_enum_name];\n\n        let exclusion = new Set();\n        if (exclusions[module] && exclusions[module][enumName]) {\n          const exclusionDict = exclusions[module][enumName];\n          if (!exclusionDict[\"values\"]) {\n            continue;\n          }\n          exclusion = normalizeEnumValues(exclusionDict[\"values\"]);\n        }\n        \n        // Get normalized sets of values\n        const normalizedCdkValues = normalizeEnumValues(cdkValues);\n        const normalizedSdkValues = normalizeEnumValues(sdkValues);\n        \n        // Find missing values using normalized comparison\n        const missingNormalized = [...normalizedSdkValues].filter(sdkValue => \n          !normalizedCdkValues.has(sdkValue) && !exclusion.has(sdkValue)\n        );\n        \n        if (missingNormalized.length > 0) {\n          if (!missingValues[module]) {\n            missingValues[module] = {};\n          }\n  \n          // Get original SDK values that correspond to missing normalized values\n          const missingOriginal = sdkValues.filter(value => \n            missingNormalized.includes(normalizeValue(value))\n          );\n  \n          missingValues[module][enumName] = {\n            cdk_path: cdkEnums[module][enumName].path,\n            missing_values: missingOriginal\n          };\n        }\n      }\n    }\n  \n    const totalEnumsWithMissing = Object.keys(missingValues).reduce((sum, module) => \n      sum + Object.keys(missingValues[module]).length, 0);\n    \n    const totalMissingValues = Object.keys(missingValues).reduce((sum, module) => \n      sum + Object.keys(missingValues[module]).reduce((moduleSum, enumName) => \n        moduleSum + missingValues[module][enumName].missing_values.length, 0), 0);\n  \n    console.log(`Enums with missing values: ${totalEnumsWithMissing}`);\n    console.log(`Total missing values found: ${totalMissingValues}`);\n  \n    return missingValues;\n  }\n  \n  /**\n   * Saves missing enum values to a temporary JSON file.\n   */\n  private async saveMissingValues(\n    staticMapping: StaticMapping,\n    cdkEnums: CdkEnums,\n    sdkEnums: SdkEnums,\n    exclusions: Record<string, any>\n  ): Promise<string> {\n    try {\n      const missingValues = await this.findMissingValues(staticMapping, cdkEnums, sdkEnums, exclusions);\n      \n      const tmpFile = tmp.fileSync({ postfix: '.json' });\n      fs.writeFileSync(tmpFile.name, JSON.stringify(missingValues, null, 2));\n  \n      return tmpFile.name;\n    } catch (error) {\n      console.error('Error saving missing values:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Analyzes missing enum values between CDK and SDK by loading mappings and processing them.\n   */\n  private async analyzeMissingEnumValues(): Promise<string> {\n    try {\n      const staticMapping: StaticMapping = JSON.parse(fs.readFileSync(STATIC_MAPPING, 'utf8'));\n      const cdkEnums: CdkEnums = JSON.parse(fs.readFileSync(CDK_ENUMS, 'utf8'));\n      const sdkEnums: SdkEnums = JSON.parse(fs.readFileSync(SDK_ENUMS, 'utf8'));\n      const exclusions: Record<string, any> = JSON.parse(fs.readFileSync(EXCLUDE_ENUMS, 'utf8'));\n  \n      const missingValuesPath = await this.saveMissingValues(staticMapping, cdkEnums, sdkEnums, exclusions);\n      \n      const totalMappings = Object.values(staticMapping)\n        .reduce((sum, moduleEnums) => sum + Object.keys(moduleEnums).length, 0);\n      \n      console.log(\"\\nAnalysis Statistics:\");\n      console.log(`Total mappings analyzed: ${totalMappings}`);\n      console.log(\"Missing values analysis completed.\");\n\n      return missingValuesPath;\n    } catch (error) {\n      console.error('Error analyzing missing enum values:', error);\n      throw error;\n    }\n  }\n  \n  \n  /**\n   * Retrieve the generated list of enum-like classes and the missing values,\n   * and update the source files with any missing values.\n   */\n  public updateEnumValues(missingValuesPath: string): void {\n    // Get list of enum-likes and missing enum-likes\n    const parsedEnums = this.getParsedEnumValues();\n    const missingEnums = this.getMissingEnumValues(missingValuesPath);\n\n    // Update the parsed_cdk_enums.json file\n    Object.keys(missingEnums).forEach((cdkModule) => {\n      Object.keys(missingEnums[cdkModule]).forEach((enumKey) => {\n        if (parsedEnums[cdkModule]?.[enumKey]) {\n          this.updateEnum(enumKey, missingEnums[cdkModule][enumKey])\n        }\n      });\n    });\n  }\n  \n  /**\n   * Retrieve the parsed enum values from the generated list\n   * @returns A dictionary containing the parsed_cdk_enums.json file with only regular enums\n   */\n  private getParsedEnumValues(): any {\n    // Get file contents\n    const fileContent = fs.readFileSync(CDK_ENUMS, 'utf8');\n    var jsonData = JSON.parse(fileContent);\n\n    // Remove anything that is enum-like\n    Object.keys(jsonData).forEach((cdkModule) => {\n      Object.keys(jsonData[cdkModule]).forEach((enumKey) => {\n        if (jsonData[cdkModule][enumKey].enumLike) {\n          delete jsonData[cdkModule][enumKey];\n        }\n      });\n    });\n\n    // Clean up empty modules\n    Object.keys(jsonData).forEach((cdkModule) => {\n      if (Object.keys(jsonData[cdkModule]).length === 0) {\n        delete jsonData[cdkModule];\n      }\n    });\n\n    return jsonData;\n  }\n    \n  /**\n   * Retrieve the list of missing values for regular enum values\n   * @returns A dictionary containing the missing-values.json file with only regular enums with missing values\n   */\n  private getMissingEnumValues(missingValuesPath: string): any {\n    // Get file contents\n    const fileContent = fs.readFileSync(missingValuesPath, 'utf8');\n    var jsonData = JSON.parse(fileContent);\n\n    const parsedEnums = this.getParsedEnumValues();\n\n    // Remove anything that isn't in the parsed enum-likes (regular enums)\n    Object.keys(jsonData).forEach((cdkModule) => {\n      Object.keys(jsonData[cdkModule]).forEach((enumKey) => {\n        if (!parsedEnums[cdkModule]?.[enumKey]) {\n          delete jsonData[cdkModule][enumKey];\n        }\n      });\n    });\n\n    // Clean up empty modules\n    Object.keys(jsonData).forEach((cdkModule) => {\n      if (Object.keys(jsonData[cdkModule]).length === 0) {\n        delete jsonData[cdkModule];\n      }\n    });\n\n    return jsonData\n  }\n\n  /**\n   * Update a single enum value\n   * @param enumName The enum name\n   * @param missingValue The dictionary from the `missing-values.json` file\n   * containing the cdk_path and missing_values for the enum\n   */\n  private updateEnum(enumName: string, missingValue: any): void {\n    // Get the right source file to modify\n    let sourceFile = this.project.getSourceFile(path.resolve(__dirname, '../../../..', this.removeAwsCdkPrefix(missingValue['cdk_path'])));\n    if (!sourceFile) {\n      throw new Error(`Source file not found: ${missingValue['cdk_path']}`);\n    }\n\n    // Get the class declaration\n    const enumDeclaration = sourceFile.getEnum(enumName)\n    if (!enumDeclaration) {\n      throw new Error(`Enum declaration not found: ${enumName}`);\n    }\n    \n    const newEnumValues = missingValue['missing_values'];\n\n    // First get the full text\n    let enumText = enumDeclaration.getFullText();\n\n    // If the text starts with empty lines before the docstring (which starts with /**),\n    // remove only those empty lines\n    if (enumText.startsWith('\\n') && enumText.includes('/**')) {\n      const docstringStart = enumText.indexOf('/**');\n      const leadingText = enumText.substring(0, docstringStart);\n      const restOfText = enumText.substring(docstringStart);\n      enumText = leadingText.replace(/^\\n+/, '') + restOfText;\n    }\n    \n    // Get just the enum body (everything between the curly braces)\n    const enumBodyStart = enumText.indexOf('{') + 1;\n    const enumBodyEnd = enumText.lastIndexOf('}');\n    const enumBody = enumText.substring(enumBodyStart, enumBodyEnd);\n\n    // Check for double line breaks only in the enum body\n    const hasDoubleLineBreaks = enumBody.includes('\\n\\n');\n\n    // Find the position to insert new members (just before the closing brace)\n    const insertPosition = enumText.lastIndexOf('}');\n\n    // Prepare the text to insert - only add initial newline if enum uses double line breaks\n    let textToInsert = hasDoubleLineBreaks ? '\\n' : '';\n\n    newEnumValues.forEach((enumVal: string, index: number) => {\n      // Make sure enumValue is a string\n      const enumValue = enumVal.toString();\n      const enumConstantName = enumValue.toUpperCase().replace(/[^A-Z0-9]+/g, '_').replace(/_+$/, '');\n      \n      textToInsert += `  /**\\n   * PLACEHOLDER_COMMENT_TO_BE_FILLED_OUT\\n   */\\n`;\n      textToInsert += `  ${enumConstantName} = '${enumValue}'`;\n      \n      // Add a comma and appropriate newlines after each member\n      textToInsert += ',';\n      \n      // Add newlines after each member except the last one\n      if (index < newEnumValues.length - 1) {\n          textToInsert += hasDoubleLineBreaks ? '\\n\\n' : '\\n';\n      }\n    });\n\n    // Add final newline before the closing brace\n    textToInsert += '\\n';\n\n    // Insert the new text\n    enumText = enumText.slice(0, insertPosition) + textToInsert + enumText.slice(insertPosition);\n\n    // Set the full text of the enum\n    enumDeclaration.replaceWithText(enumText);\n\n    // Write the updated file back to disk\n    sourceFile.saveSync();\n  }\n  \n  /**\n   * Retrieve the generated list of enum-like classes and the missing values,\n   * and update the source files with any missing values.\n   */\n  public updateEnumLikeValues(missingValuesPath: string): void {\n    // Get list of enum-likes and missing enum-likes\n    const parsedEnumLikes = this.getParsedEnumLikeValues();\n    const missingEnumLikes = this.getMissingEnumLikeValues(missingValuesPath);\n\n    // Update the parsed_cdk_enums.json file\n    Object.keys(missingEnumLikes).forEach((cdkModule) => {\n      Object.keys(missingEnumLikes[cdkModule]).forEach((enumKey) => {\n        if (parsedEnumLikes[cdkModule]?.[enumKey]) {\n          this.updateEnumLike(cdkModule, enumKey, missingEnumLikes[cdkModule][enumKey])\n        }\n      });\n    });\n  }\n\n  /**\n   * Retrieve the parsed enum-like values from the generated list\n   * @returns A dictionary containing the parsed_cdk_enums.json file with only enum-likes\n   */\n  private getParsedEnumLikeValues(): any {\n    // Get file contents\n    const fileContent = fs.readFileSync(CDK_ENUMS, 'utf8');\n    var jsonData = JSON.parse(fileContent);\n\n    // Remove anything that isn't enum-like\n    Object.keys(jsonData).forEach((cdkModule) => {\n      Object.keys(jsonData[cdkModule]).forEach((enumKey) => {\n        if (!jsonData[cdkModule][enumKey].enumLike) {\n          delete jsonData[cdkModule][enumKey];\n        }\n      });\n    });\n\n    // Clean up empty modules\n    Object.keys(jsonData).forEach((cdkModule) => {\n      if (Object.keys(jsonData[cdkModule]).length === 0) {\n        delete jsonData[cdkModule];\n      }\n    });\n\n    return jsonData;\n  }", "language": "typescript"}
{"input": "CDK class ResourcePolicy for AWS resource management", "output": "export class ResourcePolicy extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-kinesis.ResourcePolicy';\n  /**\n   * The IAM policy document for this policy.\n   */\n  public readonly document = new PolicyDocument();\n\n  constructor(scope: Construct, id: string, props: ResourcePolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.stream && props.streamConsumer) {\n      throw new ValidationError('Only one of stream or streamConsumer can be set', this);\n    }\n    if (props.stream === undefined && props.streamConsumer === undefined) {\n      throw new ValidationError('One of stream or streamConsumer must be set', this);\n    }\n\n    this.document = props.policyDocument ?? this.document;\n\n    if (props.stream) {\n      this.createResourcePolicy(props.stream.streamArn);\n    } else if (props.streamConsumer) {\n      this.createResourcePolicy(props.streamConsumer.streamConsumerArn);\n    }\n  }\n\n  private createResourcePolicy(resourceArn: string): CfnResourcePolicy {\n    return new CfnResourcePolicy(this, 'Resource', {\n      resourcePolicy: this.document,\n      resourceArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "Schedule for scheduled event rules Note that rates cannot be defined in fractions of minutes. @see https://docs.aws.amazon.com/eventbridge/latest/userguide/scheduled-events.html", "output": "class Schedule {\n  /**\n   * Construct a schedule from a literal schedule expression\n   *\n   * @param expression The expression to use. Must be in a format that EventBridge will recognize\n   */\n  public static expression(expression: string): Schedule {\n    return new LiteralSchedule(expression);\n  }\n\n  /**\n   * Construct a schedule from an interval and a time unit\n   *\n   * Rates may be defined with any unit of time, but when converted into minutes, the duration must be a positive whole number of minutes.\n   */\n  public static rate(duration: Duration): Schedule {\n    if (duration.isUnresolved()) {\n      const validDurationUnit = ['minute', 'minutes', 'hour', 'hours', 'day', 'days'];\n      if (validDurationUnit.indexOf(duration.unitLabel()) === -1) {\n        throw new UnscopedValidationError(\"Allowed units for scheduling are: 'minute', 'minutes', 'hour', 'hours', 'day', 'days'\");\n      }\n      return new LiteralSchedule(`rate(${duration.formatTokenToNumber()})`);\n    }\n    if (duration.toMinutes() === 0) {\n      throw new UnscopedValidationError('Duration cannot be 0');\n    }\n\n    let rate = maybeRate(duration.toDays({ integral: false }), 'day');\n    if (rate === undefined) { rate = maybeRate(duration.toHours({ integral: false }), 'hour'); }\n    if (rate === undefined) { rate = makeRate(duration.toMinutes({ integral: true }), 'minute'); }\n    return new LiteralSchedule(rate);\n  }\n\n  /**\n   * Create a schedule from a set of cron fields\n   */\n  public static cron(options: CronOptions): Schedule {\n    if (options.weekDay !== undefined && options.day !== undefined) {\n      throw new UnscopedValidationError('Cannot supply both \\'day\\' and \\'weekDay\\', use at most one');\n    }\n\n    const minute = fallback(options.minute, '*');\n    const hour = fallback(options.hour, '*');\n    const month = fallback(options.month, '*');\n    const year = fallback(options.year, '*');\n\n    // Weekday defaults to '?' if not supplied. If it is supplied, day must become '?'\n    const day = fallback(options.day, options.weekDay !== undefined ? '?' : '*');\n    const weekDay = fallback(options.weekDay, '?');\n\n    return new class extends Schedule {\n      public readonly expressionString: string = `cron(${minute} ${hour} ${day} ${month} ${weekDay} ${year})`;\n      public _bind(scope: Construct) {\n        if (!options.minute) {\n          Annotations.of(scope).addWarningV2('@aws-cdk/aws-events:scheduleWillRunEveryMinute', 'cron: If you don\\'t pass \\'minute\\', by default the event runs every minute. Pass \\'minute: \\'*\\'\\' if that\\'s what you intend, or \\'minute: 0\\' to run once per hour instead.');\n        }\n        return new LiteralSchedule(this.expressionString);\n      }\n    };\n  }\n\n  /**\n   * Retrieve the expression for this schedule\n   */\n  public abstract readonly expressionString: string;\n\n  protected constructor() {}\n\n  /**\n   *\n   * @internal\n   */\n  public abstract _bind(scope: Construct): void;\n}", "language": "typescript"}
{"input": "CDK class Channel for AWS resource management", "output": "export class Channel extends ChannelBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ivs-alpha.Channel';\n\n  /**\n   * Import an existing channel\n   */\n  public static fromChannelArn(scope: Construct, id: string, channelArn: string): IChannel {\n    // This will throw an error if the arn cannot be parsed\n    let arnComponents = core.Arn.split(channelArn, core.ArnFormat.SLASH_RESOURCE_NAME);\n\n    if (!core.Token.isUnresolved(arnComponents.service) && arnComponents.service !== 'ivs') {\n      throw new Error(`Invalid service, expected 'ivs', got '${arnComponents.service}'`);\n    }\n\n    if (!core.Token.isUnresolved(arnComponents.resource) && arnComponents.resource !== 'channel') {\n      throw new Error(`Invalid resource, expected 'channel', got '${arnComponents.resource}'`);\n    }\n\n    class Import extends ChannelBase {\n      public readonly channelArn = channelArn;\n    }\n\n    return new Import(scope, id);\n  }\n\n  public readonly channelArn: string;\n\n  /**\n   * Channel ingest endpoint, part of the definition of an ingest server, used when you set up streaming software.\n   * For example: a1b2c3d4e5f6.global-contribute.live-video.net\n   * @attribute\n   */\n  public readonly channelIngestEndpoint: string;\n\n  /**\n   * Channel playback URL. For example:\n   * https://a1b2c3d4e5f6.us-west-2.playback.live-video.net/api/video/v1/us-west-2.123456789012.channel.abcdEFGH.m3u8\n   * @attribute\n   */\n  public readonly channelPlaybackUrl: string;\n\n  constructor(scope: Construct, id: string, props: ChannelProps = {}) {\n    super(scope, id, {\n      physicalName: props.channelName ?? Lazy.string({\n        produce: () => Names.uniqueResourceName(this, { maxLength: 128, allowedSpecialCharacters: '-_' }),\n      }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (this.physicalName && !core.Token.isUnresolved(this.physicalName) && !/^[a-zA-Z0-9-_]*$/.test(this.physicalName)) {\n      throw new Error(`channelName must contain only numbers, letters, hyphens and underscores, got: '${this.physicalName}'`);\n    }\n\n    let preset;\n\n    if (props.type && [ChannelType.STANDARD, ChannelType.BASIC].includes(props.type) && props.preset) {\n      preset = '';\n    } else {\n      preset = props.preset;\n    }\n\n    if (props.multitrackInputConfiguration !== undefined) {\n      if (props.type !== undefined && props.type !== ChannelType.STANDARD) {\n        throw new Error(`\\`multitrackInputConfiguration\\` is only supported for \\`ChannelType.STANDARD\\`, got: ${props.type}.`);\n      }\n\n      if (props.containerFormat !== undefined && props.containerFormat !== ContainerFormat.FRAGMENTED_MP4) {\n        throw new Error(`\\`containerFormat\\` must be set to \\`ContainerFormat.FRAGMENTED_MP4\\` when \\`multitrackInputConfiguration\\` is specified, got: ${props.containerFormat}.`);\n      }\n    }\n\n    const resource = new CfnChannel(this, 'Resource', {\n      authorized: props.authorized,\n      insecureIngest: props.insecureIngest,\n      latencyMode: props.latencyMode,\n      name: this.physicalName,\n      type: props.type,\n      preset,\n      recordingConfigurationArn: props.recordingConfiguration?.recordingConfigurationArn,\n      containerFormat: props.containerFormat ??\n        (props.multitrackInputConfiguration ? ContainerFormat.FRAGMENTED_MP4 : undefined),\n      multitrackInputConfiguration: props.multitrackInputConfiguration ?\n        {\n          enabled: true,\n          maximumResolution: props.multitrackInputConfiguration.maximumResolution,\n          policy: props.multitrackInputConfiguration.policy,\n        }\n        : undefined,\n    });\n\n    this.channelArn = resource.attrArn;\n    this.channelIngestEndpoint = resource.attrIngestEndpoint;\n    this.channelPlaybackUrl = resource.attrPlaybackUrl;\n  }\n}", "language": "typescript"}
{"input": "Compares if two values are equal. Returns true if the two values are equal or false if they aren't.", "output": "class FnEquals extends FnConditionBase {\n  /**\n   * Creates an ``Fn::Equals`` condition function.\n   * @param lhs A value of any type that you want to compare.\n   * @param rhs A value of any type that you want to compare.\n   */\n  constructor(lhs: any, rhs: any) {\n    super('Fn::Equals', [lhs, rhs]);\n  }\n}", "language": "typescript"}
{"input": "A target tracking scaling policy that automatically adjusts the capacity provider's compute resources to maintain a specified target value by tracking the required CloudWatch metric.", "output": "export class TargetTrackingScalingPolicy {\n  /**\n   * Creates a target tracking scaling policy for CPU utilization.\n   *\n   * @param targetCpuUtilization The target value for CPU utilization. The capacity provider will scale resources to maintain this target value.\n   */\n  public static cpuUtilization(targetCpuUtilization: number): TargetTrackingScalingPolicy {\n    return new TargetTrackingScalingPolicy('LambdaCapacityProviderAverageCPUUtilization', targetCpuUtilization);\n  }\n\n  /**\n   * The predefined metric type for this scaling policy.\n   */\n  readonly predefinedMetricType: string;\n\n  /**\n   * The target value for the specified metric as a percentage. The capacity provider will scale resources to maintain this target value.\n   */\n  readonly targetValue: number;\n\n  /**\n   * Creates a new TargetTrackingScalingPolicy.\n   *\n   * @param metricType The predefined metric type\n   * @param value The target value for the metric\n   */\n  private constructor(\n    public readonly metricType: string,\n    public readonly value: number) {\n    this.predefinedMetricType = metricType;\n    this.targetValue = value;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, WAF resources", "output": "class CdkIotThingStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n        \n        \n        # Environment variables\n        account=Aws.ACCOUNT_ID\n        region=Aws.REGION\n        iot_thing_name=\"CdkThing001\"\n\n        # Create an IoT Thing\n        cfn_thing=iot.CfnThing(self, \"MyCdkThing\",\n            thing_name=iot_thing_name\n        )\n        \n        # Lambda role for creating certs and keys\n        lambda_role = iam.Role(self, f\"{iot_thing_name}LambdaRole\", \n            assumed_by=iam.ServicePrincipal(\"lambda.amazonaws.com\")\n        )\n    \n        lambda_role.add_to_policy(\n            iam.PolicyStatement(\n                actions=[\"secretsmanager:CreateSecret\",\"secretsmanager:DeleteSecret\"],\n                resources=[\"arn:aws:secretsmanager:*:*:secret:*\"]\n            )\n        )\n        \n        lambda_role.add_to_policy(\n            iam.PolicyStatement(\n                actions=[\"iot:CreateKeysAndCertificate\", \"iot:UpdateCertificate\"],\n                resources=[\"*\"]\n            )\n        )\n        \n        \n        # Custom Lambda to create IoT certificate and storing in secrets manager\n        cert_lambda = _lambda.Function(\n            self,\"CertHandler\",\n            function_name=\"CertHandlerFunction\",\n            runtime=_lambda.Runtime.PYTHON_3_11,\n            code=_lambda.Code.from_asset(\"lambda\"),\n            handler=\"cert_handler.lambda_handler\",\n            role=lambda_role,\n            log_retention=logs.RetentionDays.ONE_DAY,\n            timeout=Duration.seconds(60)\n        )\n\n        provider = CustomResourceProvider.Provider(\n            self,'IoTCertProvider',\n            on_event_handler= cert_lambda\n        )\n        \n        certificate = CustomResource(\n            self, \"IoTCertCustomResource\",\n            service_token=provider.service_token\n        )        \n        \n        # Create a policy of the certificate\n        cfn_policy = iot.CfnPolicy(self, \"CfnPolicy\",\n            policy_document={\n                \"Version\":\"2012-10-17\",\n                \"Statement\":[\n                    {\n                        \"Effect\":\"Allow\",\n                        \"Action\":[\n                            \"iot:Connect\"\n                        ],\n                        \"Resource\":[\n                            f\"arn:aws:iot:\"+region+\":\"+account+\":client/\"+iot_thing_name\n                            ]\n                    },\n                    {\n                        \"Effect\": \"Allow\",\n                        \"Action\": [\n                            \"iot:Publish\"\n                        ],\n                        \"Resource\":[f\"arn:aws:iot:\"+region+\":\"+account+\":topic/*\"]\n                    }\n                ]\n            },\n        policy_name=f\"{iot_thing_name}IoTCertPolicy\"\n        )\n        \n        # Connect the certificate and policy\n        policy_attchment = iot.CfnPolicyPrincipalAttachment(\n            self,\n            id=iot_thing_name+\"PolicyPrincipalAttachment\",\n            policy_name=iot_thing_name+\"IoTCertPolicy\",\n            principal=f\"arn:aws:iot:{region}:{account}:cert/{certificate.get_att_string('certificateId')}\"\n        )\n\n        # Connect the IoT thing and certificate\n        principal_attchmnt = iot.CfnThingPrincipalAttachment(\n            self,\n            id=iot_thing_name+\"ThingPrincipalAttachment\",\n            principal=f\"arn:aws:iot:{region}:{account}:cert/{certificate.get_att_string('certificateId')}\",\n            thing_name=iot_thing_name\n        )\n\n        \n        iam_role_name=\"CdkIoTCoreCloudWatchAccessRole\"\n       \n        # Create an IAM role for logging the IoT rule event\n        cfn_role=iam.CfnRole(self, \"CfnRole\",\n            assume_role_policy_document=iam.PolicyDocument(\n                statements=[iam.PolicyStatement(\n                    actions=[\"sts:AssumeRole\"],\n                    effect=iam.Effect.ALLOW,\n                    principals=[iam.ServicePrincipal(\"iot.amazonaws.com\")]\n                )]\n            ),\n            description=\"CDK created role for logging IoT rule event\",\n            role_name=iam_role_name,\n            policies=[iam.CfnRole.PolicyProperty(\n                policy_document=iam.PolicyDocument(\n                    statements=[iam.PolicyStatement(\n                        actions=[\"logs:CreateLogStream\",\n                                 \"logs:DescribeLogStreams\",\n                                 \"logs:PutLogEvents\"],\n                        effect=iam.Effect.ALLOW,\n                        resources=[\"*\"]\n                    )]\n                ),\n                policy_name=\"CdkIoTCoreCloudWatchAccessPolicy\"\n            )]\n        )\n        \n        \n        # Configure log group for short retention\n        logGroupName=\"CdkThing001LogGroup\"\n        cfn_log_group=logs.CfnLogGroup(self, \"CfnLogGroup\",\n            log_group_name=logGroupName,\n            retention_in_days=7\n            ##apply_removal_policy=True\n        )\n        \n        # IoT Rule with SQL. The rule action to send data to Amazon CloudWatch Logs.\n        iot_topic_rule_sql=\"SELECT color AS rgb FROM 'device/color' WHERE temperature > 50\"\n \n        iot_topic_rule=iot.CfnTopicRule(\n            self, \"CdkIoTCoreRule\",\n            topic_rule_payload=iot.CfnTopicRule.TopicRulePayloadProperty(\n                sql=iot_topic_rule_sql,\n                actions=[iot.CfnTopicRule.ActionProperty(\n                cloudwatch_logs=iot.CfnTopicRule.CloudwatchLogsActionProperty(\n                    log_group_name=logGroupName,\n                    role_arn=cfn_role.attr_arn,\n                    # the properties below are optional\n                    batch_mode=False\n                ))]\n            )\n        )", "language": "python"}
{"input": "The main pipeline stack, using a GitHub connection source.", "output": "class PipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const pipelineSource = pipelines.CodePipelineSource.connection('aws/aws-cdk', 'main', {\n      connectionArn: 'arn:aws:codeconnections:us-east-1:486673125664:connection/a3bf1dc7-eefb-4278-9f04-cc8fed8b569a',\n      codeBuildCloneOutput: true,\n    });\n\n    const pipeline = new pipelines.CodePipeline(this, 'Pipeline', {\n      pipelineName: 'pipeline-name',\n      useChangeSets: false,\n      crossAccountKeys: false,\n      synth: new pipelines.ShellStep('Synth', {\n        input: pipelineSource,\n        commands: ['npm ci && npm run build'],\n      }),\n      dockerEnabledForSynth: true,\n      codeBuildDefaults: {\n        buildEnvironment: {\n          buildImage: codebuild.LinuxBuildImage.AMAZON_LINUX_2023_5,\n          computeType: codebuild.ComputeType.SMALL,\n          dockerServer: {\n            computeType: codebuild.DockerServerComputeType.SMALL,\n          },\n        },\n        cache: codebuild.Cache.local(codebuild.LocalCacheMode.DOCKER_LAYER),\n      },\n    });\n\n    pipeline.addStage(new ProdStage(this, 'Prod'), {\n      pre: [new pipelines.ManualApprovalStep('PromoteToProd')],\n    });\n  }\n}", "language": "typescript"}
{"input": "API Schema from a local asset. The asset is uploaded to an S3 staging bucket, then moved to its final location by CloudFormation during deployment.", "output": "export class AssetApiSchema extends ApiSchema {\n  private asset?: s3_assets.Asset;\n\n  constructor(private readonly path: string, private readonly options: s3_assets.AssetOptions = {}) {\n    super();\n  }\n\n  /**\n   * Gets the file path for internal validation purposes\n   * @internal\n   */\n  public _getFilePath(): string {\n    return this.path;\n  }\n\n  /**\n   * Binds this API schema to a construct scope.\n   * This method initializes the S3 asset if it hasn't been initialized yet.\n   * Must be called before rendering the schema as CFN properties.\n   *\n   * @param scope - The construct scope to bind to\n   */\n  public bind(scope: Construct): void {\n    // If the same AssetApiSchema is used multiple times, retain only the first instantiation\n    if (!this.asset) {\n      // Note: Validation is handled at the target configuration level where we know the schema type\n      // and whether validation is enabled\n      this.asset = new s3_assets.Asset(scope, 'Schema', {\n        path: this.path,\n        ...this.options,\n      });\n      // Note: Permissions will be granted by the Gateway target construct when adding the target\n    }\n  }\n\n  /**\n   * Format as CFN properties\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): any {\n    if (!this.asset) {\n      throw new ApiSchemaError(\n        'ApiSchema must be bound to a scope before rendering. Call bind() first.',\n        'Asset not initialized',\n      );\n    }\n\n    return {\n      s3: {\n        uri: `s3://${this.asset.s3BucketName}/${this.asset.s3ObjectKey}`,\n      },\n    };\n  }\n\n  public grantPermissionsToRole(role: IRole): void {\n    if (this.asset) {\n      this.asset.grantRead(role);\n    }\n  }\n}\n\n// ------------------------------------------------------\n/**\n * Class to define an API Schema from an inline string.\n * The schema can be provided directly as a string.\n * Validation is performed at the target configuration level where the schema type is known.\n */\nexport class InlineApiSchema extends ApiSchema {\n  constructor(private readonly schema: string) {\n    super(undefined, undefined, schema);\n  }\n\n  /**\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): any {\n    return {\n      inlinePayload: this.schema,\n    };\n  }\n\n  public grantPermissionsToRole(_role: IRole): void {\n    // No-op - InlineApiSchema doesn't need permissions\n  }", "language": "typescript"}
{"input": "CDK class ImagePipeline for AWS resource management", "output": "export class ImagePipeline extends ImagePipelineBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-imagebuilder-alpha.ImagePipeline';\n\n  /**\n   * Import an existing image pipeline given its ARN.\n   */\n  public static fromImagePipelineArn(scope: Construct, id: string, imagePipelineArn: string): IImagePipeline {\n    const imagePipelineName = cdk.Stack.of(scope).splitArn(\n      imagePipelineArn,\n      cdk.ArnFormat.SLASH_RESOURCE_NAME,\n    ).resourceName!;\n\n    class Import extends ImagePipelineBase {\n      public readonly imagePipelineArn = imagePipelineArn;\n      public readonly imagePipelineName = imagePipelineName;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import an existing image pipeline given its name. The provided name must be normalized by converting all\n   * alphabetical characters to lowercase, and replacing all spaces and underscores with hyphens.\n   */\n  public static fromImagePipelineName(scope: Construct, id: string, imagePipelineName: string): IImagePipeline {\n    return this.fromImagePipelineArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'image-pipeline',\n        resourceName: imagePipelineName,\n      }),\n    );\n  }\n\n  /**\n   * Return whether the given object is an ImagePipeline.\n   */\n  public static isImagePipeline(x: any): x is ImagePipeline {\n    return x !== null && typeof x === 'object' && IMAGE_PIPELINE_SYMBOL in x;\n  }\n\n  /**\n   * The ARN of the image pipeline\n   */\n  public readonly imagePipelineArn: string;\n\n  /**\n   * The name of the image pipeline\n   */\n  public readonly imagePipelineName: string;\n\n  /**\n   * The infrastructure configuration used for the image build\n   */\n  public readonly infrastructureConfiguration: IInfrastructureConfiguration;\n\n  /**\n   * The execution role used for the image build. If there is no execution role, then the build will be executed with\n   * the AWSServiceRoleForImageBuilder service-linked role.\n   */\n  public readonly executionRole?: iam.IRole;\n\n  private readonly props: ImagePipelineProps;\n\n  public constructor(scope: Construct, id: string, props: ImagePipelineProps) {\n    super(scope, id, {\n      physicalName:\n        props.imagePipelineName ??\n        cdk.Lazy.string({\n          produce: () =>\n            cdk.Names.uniqueResourceName(this, {\n              maxLength: 128,\n              separator: '-',\n              allowedSpecialCharacters: '-',\n            }).toLowerCase(), // Enforce lowercase for the auto-generated fallback\n        }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    Object.defineProperty(this, IMAGE_PIPELINE_SYMBOL, { value: true });\n\n    this.validateImagePipelineName();\n\n    this.props = props;\n\n    this.infrastructureConfiguration =\n      props.infrastructureConfiguration ?? new InfrastructureConfiguration(this, 'InfrastructureConfiguration');\n    this.executionRole = getExecutionRole(\n      this,\n      (grantee: iam.IGrantable) => this.grantDefaultExecutionRolePermissions(grantee),\n      props,\n    );\n\n    if (InfrastructureConfiguration.isInfrastructureConfiguration(this.infrastructureConfiguration)) {\n      this.infrastructureConfiguration._bind({ isContainerBuild: props.recipe._isContainerRecipe() });\n    }\n\n    if (props.recipe._isImageRecipe() && props.recipe._isContainerRecipe()) {\n      throw new cdk.ValidationError('the recipe cannot be both an IImageRecipe and an IContainerRecipe', this);\n    }\n\n    if (!props.recipe._isImageRecipe() && !props.recipe._isContainerRecipe()) {\n      throw new cdk.ValidationError('the recipe must either be an IImageRecipe or IContainerRecipe', this);\n    }\n\n    const imagePipeline = new CfnImagePipeline(this, 'Resource', {\n      name: this.physicalName,\n      description: props.description,\n      ...(props.recipe._isImageRecipe() && { imageRecipeArn: props.recipe.imageRecipeArn }),\n      ...(props.recipe._isContainerRecipe() && { containerRecipeArn: props.recipe.containerRecipeArn }),\n      ...(props.status !== undefined && { status: props.status }),\n      infrastructureConfigurationArn: this.infrastructureConfiguration.infrastructureConfigurationArn,\n      distributionConfigurationArn: props.distributionConfiguration?.distributionConfigurationArn,\n      enhancedImageMetadataEnabled: props.enhancedImageMetadataEnabled,\n      executionRole: this.executionRole?.roleArn,\n      schedule: this.buildSchedule(props),\n      loggingConfiguration: this.buildLoggingConfiguration(props),\n      imageTestsConfiguration: buildImageTestsConfiguration<\n        ImagePipelineProps,\n        CfnImagePipeline.ImageTestsConfigurationProperty\n      >(props),\n      imageScanningConfiguration: buildImageScanningConfiguration<\n        ImagePipelineProps,\n        CfnImagePipeline.ImageScanningConfigurationProperty\n      >(this, props),\n      workflows: buildWorkflows<ImagePipelineProps, CfnImagePipeline.WorkflowConfigurationProperty[]>(props),\n      tags: props.tags,\n    });\n\n    this.imagePipelineName = this.getResourceNameAttribute(imagePipeline.attrName);\n    this.imagePipelineArn = this.getResourceArnAttribute(imagePipeline.attrArn, {\n      service: 'imagebuilder',\n      resource: 'image-pipeline',\n      resourceName: this.physicalName,\n    });\n  }\n\n  /**\n   * Grants the default permissions for building an image to the provided execution role.\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee The execution role used for the image build.\n   */\n  @MethodMetadata()\n  public grantDefaultExecutionRolePermissions(grantee: iam.IGrantable): iam.Grant[] {\n    const policies = defaultExecutionRolePolicy(this, this.props);\n    return policies.map((policy) =>\n      iam.Grant.addToPrincipal({\n        grantee: grantee,\n        resourceArns: policy.resources,\n        actions: policy.actions,\n        conditions: policy.conditions,\n        scope: this,\n      }),\n    );\n  }\n\n  private validateImagePipelineName() {\n    if (cdk.Token.isUnresolved(this.physicalName)) {\n      return; // Cannot validate unresolved tokens, given their actual value is rendered at deployment time\n    }\n\n    if (this.physicalName.length > 128) {\n      throw new cdk.ValidationError('The imagePipelineName cannot be longer than 128 characters', this);\n    }\n\n    if (this.physicalName.includes(' ')) {\n      throw new cdk.ValidationError('The imagePipelineName cannot contain spaces', this);\n    }\n\n    if (this.physicalName.includes('_')) {\n      throw new cdk.ValidationError('The imagePipelineName cannot contain underscores', this);\n    }\n\n    if (this.physicalName !== this.physicalName.toLowerCase()) {\n      throw new cdk.ValidationError('The imagePipelineName must be lowercase', this);\n    }\n  }\n\n  private buildSchedule(props: ImagePipelineProps): CfnImagePipeline.ScheduleProperty | undefined {\n    const schedule = props.schedule;\n    if (!schedule) {\n      return undefined;\n    }\n\n    if (schedule.autoDisableFailureCount !== undefined && !cdk.Token.isUnresolved(schedule.autoDisableFailureCount)) {\n      if (schedule.autoDisableFailureCount < 1 || schedule.autoDisableFailureCount > 10) {\n        throw new cdk.ValidationError('the autoDisableFailureCount must be between 1 and 10', this);\n      }\n    }\n\n    return {\n      scheduleExpression: schedule.expression.expressionString,\n      ...(schedule.autoDisableFailureCount !== undefined && {\n        autoDisablePolicy: {\n          failureCount: schedule.autoDisableFailureCount,\n        },\n      }),\n      ...(schedule.startCondition !== undefined && {\n        pipelineExecutionStartCondition: schedule.startCondition,\n      }),\n    };\n  }\n\n  /**\n   * Generates the loggingConfiguration property into the `LoggingConfiguration` type in the CloudFormation L1\n   * definition.\n   *\n   * @param props Props input for the construct\n   */\n  private buildLoggingConfiguration = (\n    props: ImagePipelineProps,\n  ): CfnImagePipeline.PipelineLoggingConfigurationProperty | undefined => {\n    const loggingConfiguration = {\n      ...(props.imageLogGroup && { imageLogGroupName: props.imageLogGroup.logGroupName }),\n      ...(props.imagePipelineLogGroup && { pipelineLogGroupName: props.imagePipelineLogGroup.logGroupName }),\n    };\n\n    return Object.keys(loggingConfiguration).length ? loggingConfiguration : undefined;\n  };\n}", "language": "typescript"}
{"input": "CDK class MixinsCommon for AWS resource management", "output": "class MixinsCommon extends ExternalModule {\n  public readonly PropertyMergeStrategy = $T(Type.fromName(this, 'PropertyMergeStrategy'));\n  public readonly CfnPropertyMixinOptions = Type.fromName(this, 'CfnPropertyMixinOptions');\n}", "language": "typescript"}
{"input": "CDK class ClusterParameterGroup for AWS resource management", "output": "export class ClusterParameterGroup extends ClusterParameterGroupBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-redshift-alpha.ClusterParameterGroup';\n\n  /**\n   * Imports a parameter group\n   */\n  public static fromClusterParameterGroupName(scope: Construct, id: string, clusterParameterGroupName: string): IClusterParameterGroup {\n    class Import extends Resource implements IClusterParameterGroup {\n      public readonly clusterParameterGroupName = clusterParameterGroupName;\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * The name of the parameter group\n   */\n  public readonly clusterParameterGroupName: string;\n\n  /**\n   * The parameters in the parameter group\n   */\n  readonly parameters: { [name: string]: string };\n\n  /**\n   * The underlying CfnClusterParameterGroup\n   */\n  private readonly resource: CfnClusterParameterGroup;\n\n  constructor(scope: Construct, id: string, props: ClusterParameterGroupProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    this.parameters = props.parameters;\n    this.resource = new CfnClusterParameterGroup(this, 'Resource', {\n      description: props.description || 'Cluster parameter group for family redshift-1.0',\n      parameterGroupFamily: 'redshift-1.0',\n      parameters: this.parseParameters(),\n    });\n\n    this.clusterParameterGroupName = this.resource.ref;\n  }\n  private parseParameters(): any {\n    return Object.entries(this.parameters).map(([name, value]) => {\n      return { parameterName: name, parameterValue: value };\n    });\n  }\n\n  /**\n   * Adds a parameter to the parameter group\n   *\n   * @param name the parameter name\n   * @param value the parameter name\n   */\n  @MethodMetadata()\n  public addParameter(name: string, value: string): void {\n    const existingValue = Object.entries(this.parameters).find(([key, _]) => key === name)?.[1];\n    if (existingValue === undefined) {\n      this.parameters[name] = value;\n      this.resource.parameters = this.parseParameters();\n    } else if (existingValue !== value) {\n      throw new ValidationError(`The parameter group already contains the parameter \"${name}\", but with a different value (Given: ${value}, Existing: ${existingValue}).`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class DashboardWithGraphWidgetWithAnnotationsIntegrationTest for AWS resource management", "output": "class DashboardWithGraphWidgetWithAnnotationsIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const dashboard = new Dashboard(this, 'Dash');\n\n    const widget = new GraphWidget({\n      title: 'My fancy graph',\n      left: [\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 1 - p99',\n          statistic: Stats.p(99),\n        }),\n\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 2 - TC_10P_90P',\n          statistic: Stats.tc(10, 90),\n        }),\n\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric left 3 - TS(5%:95%)',\n          statistic: 'TS(5%:95%)',\n        }),\n      ],\n      right: [\n        new Metric({\n          namespace: 'CDK/Test',\n          metricName: 'Metric',\n          label: 'Metric right 1 - p90.1234',\n          statistic: 'p90.1234',\n        }),\n      ],\n      leftAnnotations: [\n        {\n          value: 10,\n          label: 'Left annotation',\n          color: '#00ff00',\n          fill: Shading.ABOVE,\n          visible: true,\n        },\n      ],\n      rightAnnotations: [\n        {\n          value: 20,\n          label: 'Right annotation',\n          color: '#e30d0d',\n          fill: Shading.BELOW,\n          visible: false,\n        },\n      ],\n      verticalAnnotations: [\n        {\n          date: '2023-08-20T00:00:00.000Z',\n          label: 'Vertical annotation',\n          color: '#2556f6',\n          fill: VerticalShading.AFTER,\n          visible: true,\n        },\n      ],\n    });\n\n    dashboard.addWidgets(widget);\n  }\n}", "language": "typescript"}
{"input": "CDK class TestFunction for AWS resource management", "output": "export class TestFunction extends lambda.Function {\n  constructor(scope: constructs.Construct, id: string) {\n    super(scope, id, {\n      handler: 'index.handler',\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n      runtime: STANDARD_NODEJS_RUNTIME,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderApple for AWS resource management", "output": "export class UserPoolIdentityProviderApple extends UserPoolIdentityProviderBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderApple';\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderAppleProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const scopes = props.scopes ?? ['name'];\n\n    // Exactly one of the properties must be configured\n    if ((!props.privateKey && !props.privateKeyValue) ||\n      (props.privateKey && props.privateKeyValue)) {\n      throw new ValidationError('Exactly one of \"privateKey\" or \"privateKeyValue\" must be configured.', this);\n    }\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: 'SignInWithApple', // must be 'SignInWithApple' when the type is 'SignInWithApple'\n      providerType: 'SignInWithApple',\n      providerDetails: {\n        client_id: props.clientId,\n        team_id: props.teamId,\n        key_id: props.keyId,\n        private_key: props.privateKeyValue ? props.privateKeyValue.unsafeUnwrap() : props.privateKey,\n        authorize_scopes: scopes.join(' '),\n      },\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, CloudMap (Service Discovery) resources", "output": "export class MyWidgetServiceStack extends cdk.Stack {\n    constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n      super(scope, id, props);\n  \n      new widget_service.WidgetService(this, 'Widgets');\n    }\n  }", "language": "typescript"}
{"input": "CDK Stack that creates WAF, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const ruleSet = new gamelift.MatchmakingRuleSet(this, 'MatchmakingRuleSet', {\n      matchmakingRuleSetName: 'my-test-ruleset',\n      content: gamelift.RuleSetContent.fromJsonFile(path.join(__dirname, 'my-ruleset', 'ruleset.json')),\n    });\n\n    new CfnOutput(this, 'MatchmakingRuleSetArn', { value: ruleSet.matchmakingRuleSetArn });\n    new CfnOutput(this, 'MatchmakingRuleSetName', { value: ruleSet.matchmakingRuleSetName });\n  }\n}", "language": "typescript"}
{"input": "This stack is used to test the EKS cluster with auto mode enabled.", "output": "export class EksAutoModeBaseStack extends Stack {\n  constructor(scope: Construct, id: string, props: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { natGateways: 1 });\n    const mastersRole = new iam.Role(this, 'Role', {\n      assumedBy: new iam.AccountRootPrincipal(),\n    });\n\n    new EksMinimalCluster(this, 'hello-eks', {\n      vpc,\n      mastersRole,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF, Config operations", "output": "def make_rules(self, list_of_rules={}):\n    rules = list()\n    for r in list_of_rules:\n      rule = wafv2.CfnWebACL.RuleProperty(\n        name             = r[\"name\"],\n        priority         = r[\"priority\"],\n        override_action  = wafv2.CfnWebACL.OverrideActionProperty(none={}),\n        statement        = wafv2.CfnWebACL.StatementProperty(\n          managed_rule_group_statement = wafv2.CfnWebACL.ManagedRuleGroupStatementProperty(\n            name           = r[\"name\"],\n            vendor_name    = \"AWS\",\n            excluded_rules = []\n          ) ## managed_rule_group_statement\n        ), ## statement\n        visibility_config=wafv2.CfnWebACL.VisibilityConfigProperty(\n          cloud_watch_metrics_enabled = True,\n          metric_name                 = r[\"name\"],\n          sampled_requests_enabled    = True\n        ) ## visibility_config\n      ) ## wafv2.CfnWebACL.RuleProperty\n      rules.append(rule)\n\n    ##\n    ## Allowed country list\n    ##\n    ruleGeoMatch = wafv2.CfnWebACL.RuleProperty(\n      name     = 'GeoMatch',\n      priority =  0,\n      action   = wafv2.CfnWebACL.RuleActionProperty(\n        block={} ## To disable, change to *count*\n      ),\n      statement = wafv2.CfnWebACL.StatementProperty(\n        not_statement = wafv2.CfnWebACL.NotStatementProperty(\n          statement = wafv2.CfnWebACL.StatementProperty(\n            geo_match_statement = wafv2.CfnWebACL.GeoMatchStatementProperty(\n              ##\n              ## block connection if source not in the below country list\n              ##\n              country_codes = [\n                \"AR\", ## Argentina\n                \"BO\", ## Bolivia\n                \"BR\", ## Brazil\n                \"CL\", ## Chile\n                \"CO\", ## Colombia\n                \"EC\", ## Ecuador\n                \"FK\", ## Falkland Islands\n                \"GF\", ## French Guiana\n                \"GY\", ## Guiana\n                \"GY\", ## Guyana\n                \"PY\", ## Paraguay\n                \"PE\", ## Peru\n                \"SR\", ## Suriname\n                \"UY\", ## Uruguay\n                \"VE\", ## Venezuela\n              ] ## country_codes\n            ) ## geo_match_statement\n          ) ## statement\n        ) ## not_statement\n      ), ## statement\n      visibility_config = wafv2.CfnWebACL.VisibilityConfigProperty(\n        cloud_watch_metrics_enabled = True,\n        metric_name                 = 'GeoMatch',\n        sampled_requests_enabled    = True\n      ) ## visibility_config\n    ) ## GeoMatch\n    rules.append(ruleGeoMatch)\n\n    ##\n    ## The rate limit is the maximum number of requests from a\n    ## single IP address that are allowed in a five-minute period.\n    ## This value is continually evaluated,\n    ## and requests will be blocked once this limit is reached.\n    ## The IP address is automatically unblocked after it falls below the limit.\n    ##\n    ruleLimitRequests100 = wafv2.CfnWebACL.RuleProperty(\n          name     = 'LimitRequests100',\n          priority = 1,\n          action   = wafv2.CfnWebACL.RuleActionProperty(\n            block = {} ## To disable, change to *count*\n          ), ## action\n          statement= wafv2.CfnWebACL.StatementProperty(\n            rate_based_statement = wafv2.CfnWebACL.RateBasedStatementProperty(\n              limit              = 100,\n              aggregate_key_type = \"IP\"\n            ) ## rate_based_statement\n          ), ## statement\n          visibility_config= wafv2.CfnWebACL.VisibilityConfigProperty(\n            cloud_watch_metrics_enabled = True,\n            metric_name                 = 'LimitRequests100',\n            sampled_requests_enabled    = True\n          )\n        ) ## limit requests to 100\n    rules.append(ruleLimitRequests100);\n\n    return rules", "language": "python"}
{"input": "CDK class TagOptions for AWS resource management", "output": "export class TagOptions extends cdk.Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicecatalog.TagOptions';\n  /**\n   * List of underlying CfnTagOption resources.\n   *\n   * @internal\n   */\n  public _cfnTagOptions: CfnTagOption[];\n\n  constructor(scope: Construct, id: string, props: TagOptionsProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this._cfnTagOptions = this.createUnderlyingTagOptions(props.allowedValuesForTags);\n  }\n\n  private createUnderlyingTagOptions(allowedValuesForTags: { [tagKey: string]: string[] }): CfnTagOption[] {\n    if (Object.keys(allowedValuesForTags).length === 0) {\n      throw new ValidationError(`No tag option keys or values were provided for resource ${this.node.path}`, this);\n    }\n    var tagOptions: CfnTagOption[] = [];\n\n    for (const [tagKey, tagValues] of Object.entries(allowedValuesForTags)) {\n      InputValidator.validateLength(this.node.addr, 'TagOption key', 1, 128, tagKey);\n\n      const uniqueTagValues = new Set(tagValues);\n      if (uniqueTagValues.size === 0) {\n        throw new ValidationError(`No tag option values were provided for tag option key ${tagKey} for resource ${this.node.path}`, this);\n      }\n      uniqueTagValues.forEach((tagValue: string) => {\n        InputValidator.validateLength(this.node.addr, 'TagOption value', 1, 256, tagValue);\n        const tagOptionIdentifier = hashValues(tagKey, tagValue);\n        const tagOption = new CfnTagOption(this, tagOptionIdentifier, {\n          key: tagKey,\n          value: tagValue,\n          active: true,\n        });\n        tagOptions.push(tagOption);\n      });\n    }\n    return tagOptions;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, VPC, IAM resources", "output": "class Ec2CdkStack(Stack):\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Create a portfolio\n        portfolio = sc.Portfolio(self, \"DevToolsPortfolio\", \n            display_name=\"DevTools\",\n            provider_name=\"IT\",\n        )\n\n        # Create an EC2 product from a Product Stack\n        product = sc.CloudFormationProduct(self, \"VpcEC2SampleStack\", \n            product_name=\"Ec2CdkStack\",\n            owner=\"IT\",\n            product_versions=[\n                sc.CloudFormationProductVersion(\n                    cloud_formation_template=sc.CloudFormationTemplate.from_product_stack(Ec2Product(self, \"EC2Product\")),\n                    product_version_name=\"FromProductStack\",\n                    description=\"A VPC containing an EC2 Instance\",\n                ),\n                sc.CloudFormationProductVersion(\n                    cloud_formation_template=sc.CloudFormationTemplate.from_asset(path=\"assets/ec2_vpc.json\"),\n                    product_version_name=\"FromAsset\",\n                    description=\"A VPC containing an EC2 Instance\",\n                ),\n            ],\n        )\n\n        # Add a launch template constraint\n        portfolio.constrain_cloud_formation_parameters(product,\n            rule=sc.TemplateRule(\n                rule_name=\"EC2InstanceTypes\",\n                assertions=[sc.TemplateRuleAssertion(\n                    assert_=Fn.condition_contains([\"t4g.micro\", \"t4g.small\"], Fn.ref(\"InstanceType\")),\n                    description=\"For test environment, valid instance types are t4g.micro or t4g.small\",\n                )],\n            ),\n        )\n\n        # Associate product to the portfolio\n        portfolio.add_product(product)\n\n        # Create SNS topics to listen to product events\n        stack_events_topic = sns.Topic(self, \"StackEventsTopic\")\n        # Add launch notification constraint\n        portfolio.notify_on_stack_events(product, stack_events_topic)\n\n        # Grant access to an end user\n        dev_role = iam.Role(self, \"SCRole\", \n            assumed_by=iam.AccountRootPrincipal(),\n            role_name=\"Developer\",\n        )\n        portfolio.give_access_to_role(dev_role)\n\n        # Grant access to an IAM Group\n        test_group = iam.Group(self, \"TestGroup\", \n            group_name=\"Testers\",\n        )\n        portfolio.give_access_to_group(test_group)", "language": "python"}
{"input": "Types of PII that are general, and not domain-specific.", "output": "export class GeneralPIIType extends PIIType {\n  /**\n   * A physical address, such as \"100 Main Street, Anytown, USA\" or \"Suite #12,\n   * Building 123\". An address can include information such as the street, building,\n   * location, city, state, country, county, zip code, precinct, and neighborhood.\n   */\n  public static readonly ADDRESS = new GeneralPIIType('ADDRESS');\n  /**\n   * An individual's age, including the quantity and unit of time.\n   */\n  public static readonly AGE = new GeneralPIIType('AGE');\n  /**\n   * The number assigned to a driver's license, which is an official document\n   * permitting an individual to operate one or more motorized vehicles on a\n   * public road. A driver's license number consists of alphanumeric characters.\n   */\n  public static readonly DRIVER_ID = new GeneralPIIType('DRIVER_ID');\n  /**\n   * An email address, such as marymajor@email.com.\n   */\n  public static readonly EMAIL = new GeneralPIIType('EMAIL');\n  /**\n   * A license plate for a vehicle is issued by the state or country where the\n   * vehicle is registered. The format for passenger vehicles is typically five\n   * to eight digits, consisting of upper-case letters and numbers. The format\n   * varies depending on the location of the issuing state or country.\n   */\n  public static readonly LICENSE_PLATE = new GeneralPIIType('LICENSE_PLATE');\n  /**\n   * An individual's name. This entity type does not include titles, such as Dr.,\n   *  Mr., Mrs., or Miss.\n   */\n  public static readonly NAME = new GeneralPIIType('NAME');\n  /**\n   * An alphanumeric string that is used as a password, such as \"*very20special#pass*\".\n   */\n  public static readonly PASSWORD = new GeneralPIIType('PASSWORD');\n  /**\n   * A phone number. This entity type also includes fax and pager numbers.\n   */\n  public static readonly PHONE = new GeneralPIIType('PHONE');\n  /**\n   * A user name that identifies an account, such as a login name, screen name,\n   * nick name, or handle.\n   */\n  public static readonly USERNAME = new GeneralPIIType('USERNAME');\n  /**\n   * A Vehicle Identification Number (VIN) uniquely identifies a vehicle. VIN\n   * content and format are defined in the ISO 3779 specification. Each country\n   * has specific codes and formats for VINs.\n   */\n  public static readonly VEHICLE_IDENTIFICATION_NUMBER = new GeneralPIIType('VEHICLE_IDENTIFICATION_NUMBER');\n\n  private constructor(value: string) { super(value); }\n}", "language": "typescript"}
{"input": "An intrinsic Token that represents a reference to a construct. References are recorded.", "output": "class Reference extends Intrinsic {\n  /**\n   * Check whether this is actually a Reference\n   */\n  public static isReference(x: any): x is Reference {\n    return typeof x === 'object' && x !== null && REFERENCE_SYMBOL in x;\n  }\n\n  public readonly target: IConstruct;\n  public readonly displayName: string;\n\n  constructor(value: any, target: IConstruct, displayName?: string, typeHint?: ResolutionTypeHint) {\n    super(value, { typeHint });\n    Object.defineProperty(this, REFERENCE_SYMBOL, { value: true });\n    this.target = target;\n    this.displayName = displayName || 'Reference';\n  }\n}", "language": "typescript"}
{"input": "CDK class AaaaRecord for AWS resource management", "output": "export class AaaaRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.AaaaRecord';\n\n  constructor(scope: Construct, id: string, props: AaaaRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.AAAA,\n      target: props.target,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class Import for AWS resource management", "output": "class Import extends cdk.Resource {\n   *      public applicationInstanceRef: ApplicationInstanceReference;\n   *\n   *      public constructor(scope: constructs.Construct, id: string, arn: string) {\n   *        super(scope, id, {\n   *          \"environmentFromArn\": arn\n   *        });\n   *\n   *        const variables = new cfn_parse.TemplateString(\"arn:${Partition}:panorama:${Region}:${Account}:applicationInstance/${ApplicationInstanceId}\").parse(arn);\n   *        this.applicationInstanceRef = {\n   *          \"applicationInstanceId\": variables.ApplicationInstanceId,\n   *          \"applicationInstanceArn\": arn\n   *        };\n   *      }\n   *    }", "language": "typescript"}
{"input": "Represents an SVCB and an HTTPS record value.", "output": "class SvcbRecordValueBase {\n  protected constructor(private readonly props: SvcbRecordValueBaseProps) {}\n\n  /**\n   * Returns the string representation of SVCB and HTTPS record value.\n   */\n  public toString(): string {\n    const parts: string[] = [`${this.props.priority}`, this.props.targetName];\n    if (this.props.mandatory?.length) {\n      parts.push(`mandatory=\"${this.props.mandatory.join(',')}\"`);\n    }\n    if (this.props.alpn?.length) {\n      parts.push(`alpn=\"${this.props.alpn.map((alpn) => alpn.protocol).join(',')}\"`);\n    }\n    if (this.props.noDefaultAlpn) {\n      parts.push('no-default-alpn');\n    }\n    if (this.props.port !== undefined) {\n      parts.push(`port=${this.props.port}`);\n    }\n    if (this.props.ipv4hint?.length) {\n      parts.push(`ipv4hint=\"${this.props.ipv4hint.join(',')}\"`);\n    }\n    if (this.props.ipv6hint?.length) {\n      parts.push(`ipv6hint=\"${this.props.ipv6hint.join(',')}\"`);\n    }\n    return parts.join(' ');\n  }\n}", "language": "typescript"}
{"input": "Test service with empty placement strategies", "output": "class EcsWithEmptyStrategiesStack extends BaseEcsStack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    const { cluster, taskDefinition } = this.createBaseResources();\n\n    new ecs.Ec2Service(this, 'Service', {\n      cluster,\n      taskDefinition,\n      placementStrategies: [],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudWatch Logs, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\"SELECT topic(2) as device_id FROM 'device/+/data'\"),\n    });\n\n    const logGroup = new logs.LogGroup(this, 'MyLogGroup', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    topicRule.addAction(new actions.CloudWatchLogsAction(logGroup));\n  }\n}", "language": "typescript"}
{"input": "Code property for the DockerImageFunction construct", "output": "class DockerImageCode {\n  /**\n   * Use an existing ECR image as the Lambda code.\n   * @param repository the ECR repository that the image is in\n   * @param props properties to further configure the selected image\n   */\n  public static fromEcr(repository: ecr.IRepository, props?: EcrImageCodeProps): DockerImageCode {\n    return {\n      _bind() {\n        return new EcrImageCode(repository, props);\n      },\n    };\n  }\n\n  /**\n   * Create an ECR image from the specified asset and bind it as the Lambda code.\n   * @param directory the directory from which the asset must be created\n   * @param props properties to further configure the selected image\n   */\n  public static fromImageAsset(directory: string, props: AssetImageCodeProps = {}): DockerImageCode {\n    return {\n      _bind(architecture?: Architecture) {\n        return new AssetImageCode(directory, {\n          // determine the platform from `architecture`.\n          ...architecture?.dockerPlatform ? { platform: Platform.custom(architecture.dockerPlatform) } : {},\n          ...props,\n        });\n      },\n    };\n  }\n\n  /**\n   * Produce a `Code` instance from this `DockerImageCode`.\n   * @internal\n   */\n  public abstract _bind(architecture?: Architecture): Code;\n}", "language": "typescript"}
{"input": "Types of PII in the domain of Finance.", "output": "export class FinancePIIType extends PIIType {\n  /**\n   * A three-digit card verification code (CVV) that is present on VISA, MasterCard,\n   * and Discover credit and debit cards. For American Express credit or debit cards,\n   * the CVV is a four-digit numeric code.\n   */\n  public static readonly CREDIT_DEBIT_CARD_CVV = new FinancePIIType('CREDIT_DEBIT_CARD_CVV');\n  /**\n   * The expiration date for a credit or debit card. This number is usually four digits\n   * long and is often formatted as month/year or MM/YY. Guardrails recognizes expiration\n   * dates such as 01/21, 01/2021, and Jan 2021.\n   */\n  public static readonly CREDIT_DEBIT_CARD_EXPIRY = new FinancePIIType('CREDIT_DEBIT_CARD_EXPIRY');\n  /**\n   * The number for a credit or debit card. These numbers can vary from 13 to 16 digits\n   * in length.\n   */\n  public static readonly CREDIT_DEBIT_CARD_NUMBER = new FinancePIIType('CREDIT_DEBIT_CARD_NUMBER');\n  /**\n   * A four-digit personal identification number (PIN) with which you can access your\n   * bank account.\n   */\n  public static readonly PIN = new FinancePIIType('PIN');\n  /**\n   * A SWIFT code is a standard format of Bank Identifier Code (BIC) used to specify a\n   * particular bank or branch. Banks use these codes for money transfers such as\n   * international wire transfers. SWIFT codes consist of eight or 11 characters.\n   */\n  public static readonly SWIFT_CODE = new FinancePIIType('SWIFT_CODE');\n  /**\n   * An International Bank Account Number (IBAN). It has specific formats in each country.\n   */\n  public static readonly INTERNATIONAL_BANK_ACCOUNT_NUMBER = new FinancePIIType('INTERNATIONAL_BANK_ACCOUNT_NUMBER');\n\n  private constructor(value: string) { super(value); }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, CloudFormation resources", "output": "export class DynamoDBStack extends NestedStack {\n  constructor(scope: Construct, id: string, props: Props) {\n    super(scope, id, props);\n \n    new dynamodb.CfnGlobalTable(this, 'global-table', {\n      tableName: props.tableName,\n      billingMode: 'PAY_PER_REQUEST',\n      attributeDefinitions: [{\n        attributeName: 'id',\n        attributeType: 'S',\n      }],\n      keySchema: [{\n        attributeName: 'id',\n        keyType: 'HASH',\n      }],\n      replicas: props.tableReplicaRegions.map((replicaConfig: ReplicaConfig) => (\n        {\n          region: replicaConfig.region,\n          sseSpecification: {\n            kmsMasterKeyId: Fn.importValue(replicaConfig.keyExportName).toString(),\n          },\n        }\n      )),\n      sseSpecification: {\n        sseEnabled: true,\n        sseType: 'KMS',\n      },\n      streamSpecification: {\n        streamViewType: 'KEYS_ONLY',\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class LookedUpApplicationListener for AWS resource management", "output": "class LookedUpApplicationListener extends ExternalApplicationListener {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-elasticloadbalancingv2.LookedUpApplicationListener';\n  public readonly isApplicationListener = true;\n  public readonly listenerArn: string;\n  public readonly connections: ec2.Connections;\n\n  constructor(scope: Construct, id: string, props: cxapi.LoadBalancerListenerContextResponse) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.listenerArn = props.listenerArn;\n    this.connections = new ec2.Connections({\n      defaultPort: ec2.Port.tcp(props.listenerPort),\n    });\n\n    for (const securityGroupId of props.securityGroupIds) {\n      const securityGroup = ec2.SecurityGroup.fromLookupById(this, `SecurityGroup-${securityGroupId}`, securityGroupId);\n      this.connections.addSecurityGroup(securityGroup);\n    }\n  }\n}", "language": "typescript"}
{"input": "This stack is used to test the EKS cluster with auto mode enabled with empty node pools.", "output": "export class EksAutoModeNodePoolsStack extends Stack {\n  constructor(scope: Construct, id: string, props: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { natGateways: 1 });\n    const mastersRole = new iam.Role(this, 'Role', {\n      assumedBy: new iam.AccountRootPrincipal(),\n    });\n\n    new EksMinimalCluster(this, 'hello-eks', {\n      vpc,\n      mastersRole,\n      compute: {\n        nodePools: [],\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // deploy the latest opensearch domain with minimal configuration\n    // required for gp3 volumes\n    const domainProps: opensearch.DomainProps = {\n      removalPolicy: RemovalPolicy.DESTROY,\n      version: opensearch.EngineVersion.OPENSEARCH_2_5,\n      ebs: {\n        volumeSize: 30,\n        volumeType: EbsDeviceVolumeType.GP3,\n        throughput: 125,\n        iops: 3000,\n      },\n      zoneAwareness: {\n        enabled: true,\n        availabilityZoneCount: 3,\n      },\n      vpcSubnets: [\n        { subnetType: SubnetType.PRIVATE_WITH_EGRESS },\n      ],\n      capacity: {\n        dataNodeInstanceType: 'm7g.medium.search',\n        dataNodes: 3,\n        // Add dedicated master node - required for multi-AZ with standby\n        // m7g.large.search has 8GB RAM (minimum for 30 nodes/15K shards)\n        masterNodeInstanceType: 'm7g.large.search',\n        masterNodes: 3,\n      },\n    };\n\n    new opensearch.Domain(this, 'Domain', domainProps);\n  }\n}", "language": "typescript"}
{"input": "integ-tests can only depend on '@aws-cdk/core' so this construct creates a lambda function provider using only CfnResource", "output": "class LambdaFunctionProvider extends Construct {\n  /**\n   * The ARN of the lambda function which can be used\n   * as a serviceToken to a CustomResource\n   */\n  public readonly serviceToken: string;\n\n  /**\n   * A Reference to the provider lambda exeuction role ARN\n   */\n  public readonly roleArn: Reference;\n\n  private readonly policies: any[] = [];\n\n  constructor(scope: Construct, id: string, props?: LambdaFunctionProviderProps) {\n    super(scope, id);\n\n    const staging = new AssetStaging(this, 'Staging', {\n      sourcePath: path.join(__dirname, 'lambda-handler.bundle'),\n    });\n\n    const stack = Stack.of(this);\n    const asset = stack.synthesizer.addFileAsset({\n      fileName: staging.relativeStagedPath(stack),\n      sourceHash: staging.assetHash,\n      packaging: FileAssetPackaging.ZIP_DIRECTORY,\n    });\n\n    const role = new CfnResource(this, 'Role', {\n      type: 'AWS::IAM::Role',\n      properties: {\n        AssumeRolePolicyDocument: {\n          Version: '2012-10-17',\n          Statement: [{ Action: 'sts:AssumeRole', Effect: 'Allow', Principal: { Service: 'lambda.amazonaws.com' } }],\n        },\n        ManagedPolicyArns: [\n          { 'Fn::Sub': 'arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole' },\n        ],\n        Policies: Lazy.any({\n          produce: () => {\n            const policies = this.policies.length > 0 ? [\n              {\n                PolicyName: 'Inline',\n                PolicyDocument: {\n                  Version: '2012-10-17',\n                  Statement: this.policies,\n                },\n              },\n            ] : undefined;\n            return policies;\n          },\n        }),\n      },\n    });\n\n    const functionProperties: any = {\n      Runtime: determineLatestNodeRuntimeName(this),\n      Code: {\n        S3Bucket: asset.bucketName,\n        S3Key: asset.objectKey,\n      },\n      Timeout: Duration.minutes(2).toSeconds(),\n      Handler: props?.handler ?? 'index.handler',\n      Role: role.getAtt('Arn'),\n    };\n\n    if (props?.logRetention) {\n      const logGroup = new CfnResource(this, 'LogGroup', {\n        type: 'AWS::Logs::LogGroup',\n        properties: {\n          LogGroupName: `/aws/lambda/${id}`,\n          RetentionInDays: props.logRetention,\n        },\n      });\n\n      functionProperties.LoggingConfig = {\n        LogGroup: logGroup.ref,\n      };\n    }\n\n    const handler = new CfnResource(this, 'Handler', {\n      type: 'AWS::Lambda::Function',\n      properties: functionProperties,\n    });\n\n    this.serviceToken = Token.asString(handler.getAtt('Arn'));\n    this.roleArn = role.getAtt('Arn');\n  }\n\n  public addPolicies(policies: any[]): void {\n    this.policies.push(...policies);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF, EventBridge operations", "output": "def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc_id,\n                role_arn,\n                subnet_ids,\n                bootstrap_brokers_sasl_scram,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Iot destination \n        destination = IotProducerDestination(self, \"IotProducerTopicDestination\", \n            role_arn=role_arn,\n            vpc_id=vpc_id,\n            subnet_ids=subnet_ids\n        )\n        \n        # Create Iot Messaging Rule for MSK Cluster using the destination ARN\n        rule = iot.CfnTopicRule(self, \"TopicRule\",\n            topic_rule_payload=iot.CfnTopicRule.TopicRulePayloadProperty(\n                actions=[iot.CfnTopicRule.ActionProperty(\n                    kafka=iot.CfnTopicRule.KafkaActionProperty(\n                        destination_arn=destination.arn,\n                        topic=constants[\"MSK_TOPIC\"],\n                        client_properties= {\n                            'bootstrap.servers': bootstrap_brokers_sasl_scram,\n                            'sasl.mechanism': 'SCRAM-SHA-512',\n                            'security.protocol': 'SASL_SSL',\n                            'sasl.scram.username': \"${get_secret('AmazonMSK_iotCluster_demo', 'SecretString', 'username', '\" + role_arn + \"')}\",\n                            'sasl.scram.password': \"${get_secret('AmazonMSK_iotCluster_demo', 'SecretString', 'password', '\" + role_arn + \"')}\"\n                        }\n                    )\n                )],\n                sql='SELECT * FROM \"' + constants[\"IOT_TOPIC\"] + '\"'\n            )\n        )", "language": "python"}
{"input": "CDK class BucketDeployment for AWS resource management", "output": "export class BucketDeployment extends Construct {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-s3-deployment.BucketDeployment';\n\n  private readonly cr: cdk.CustomResource;\n  private _deployedBucket?: s3.IBucket;\n  private requestDestinationArn: boolean = false;\n  private readonly destinationBucket: s3.IBucket;\n  private readonly sources: SourceConfig[];\n\n  /**\n   * Execution role of the Lambda function behind the custom CloudFormation resource of type `Custom::CDKBucketDeployment`.\n   */\n  public readonly handlerRole: iam.IRole;\n\n  constructor(scope: Construct, id: string, props: BucketDeploymentProps) {\n    super(scope, id);\n\n    if (props.distributionPaths) {\n      if (!props.distribution) {\n        throw new ValidationError('Distribution must be specified if distribution paths are specified', this);\n      }\n      if (!cdk.Token.isUnresolved(props.distributionPaths)) {\n        if (!props.distributionPaths.every(distributionPath => cdk.Token.isUnresolved(distributionPath) || distributionPath.startsWith('/'))) {\n          throw new ValidationError('Distribution paths must start with \"/\"', this);\n        }\n      }\n    }\n\n    if (props.useEfs && !props.vpc) {\n      throw new ValidationError('Vpc must be specified if useEfs is set', this);\n    }\n\n    this.destinationBucket = props.destinationBucket;\n\n    const accessPointPath = '/lambda';\n    let accessPoint;\n    if (props.useEfs && props.vpc) {\n      const accessMode = '0777';\n      const fileSystem = this.getOrCreateEfsFileSystem(scope, {\n        vpc: props.vpc,\n        removalPolicy: cdk.RemovalPolicy.DESTROY,\n      });\n      accessPoint = fileSystem.addAccessPoint('AccessPoint', {\n        path: accessPointPath,\n        createAcl: {\n          ownerUid: '1001',\n          ownerGid: '1001',\n          permissions: accessMode,\n        },\n        posixUser: {\n          uid: '1001',\n          gid: '1001',\n        },\n      });\n      accessPoint.node.addDependency(fileSystem.mountTargetsAvailable);\n    }\n\n    // Making VPC dependent on BucketDeployment so that CFN stack deletion is smooth.\n    // Refer comments on https://github.com/aws/aws-cdk/pull/15220 for more details.\n    if (props.vpc) {\n      this.node.addDependency(props.vpc);\n    }\n\n    const mountPath = `/mnt${accessPointPath}`;\n    const handler = new BucketDeploymentSingletonFunction(this, 'CustomResourceHandler', {\n      uuid: this.renderSingletonUuid(props.memoryLimit, props.ephemeralStorageSize, props.vpc, props.securityGroups),\n      layers: [new AwsCliLayer(this, 'AwsCliLayer')],\n      environment: {\n        ...props.useEfs ? { MOUNT_PATH: mountPath } : undefined,\n        // Override the built-in CA bundle from the AWS CLI with the Lambda-curated one\n        // This is necessary to make the CLI work in ADC regions.\n        AWS_CA_BUNDLE: '/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem',\n      },\n      lambdaPurpose: 'Custom::CDKBucketDeployment',\n      timeout: cdk.Duration.minutes(15),\n      role: props.role,\n      memorySize: props.memoryLimit,\n      ephemeralStorageSize: props.ephemeralStorageSize,\n      vpc: props.vpc,\n      vpcSubnets: props.vpcSubnets,\n      securityGroups: props.securityGroups && props.securityGroups.length > 0 ? props.securityGroups : undefined,\n      filesystem: accessPoint ? lambda.FileSystem.fromEfsAccessPoint(\n        accessPoint,\n        mountPath,\n      ) : undefined,\n      // props.logRetention is deprecated, make sure we only set it if it is actually provided\n      // otherwise jsii will print warnings even for users that don't use this directly\n      ...(props.logRetention ? { logRetention: props.logRetention } : {}),\n      logGroup: props.logGroup,\n    });\n\n    const handlerRole = handler.role;\n    if (!handlerRole) { throw new ValidationError('lambda.SingletonFunction should have created a Role', this); }\n    this.handlerRole = handlerRole;\n\n    this.sources = props.sources.map((source: ISource) => source.bind(this, { handlerRole: this.handlerRole }));\n\n    this.destinationBucket.grantReadWrite(handler);\n    if (props.accessControl) {\n      this.destinationBucket.grantPutAcl(handler);\n    }\n    if (props.distribution) {\n      handler.addToRolePolicy(new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        actions: ['cloudfront:GetInvalidation', 'cloudfront:CreateInvalidation'],\n        resources: ['*'],\n      }));\n    }\n\n    // Markers are not replaced if zip sources are not extracted, so throw an error\n    // if extraction is not wanted and sources have markers.\n    const _this = this;\n    this.node.addValidation({\n      validate(): string[] {\n        if (_this.sources.some(source => source.markers) && props.extract == false) {\n          return ['Some sources are incompatible with extract=false; sources with deploy-time values (such as \\'snsTopic.topicArn\\') must be extracted.'];\n        }\n        return [];\n      },\n    }", "language": "typescript"}
{"input": "Determines whether any cookies in viewer requests (and if so, which cookies) are included in requests that CloudFront sends to the origin.", "output": "export class OriginRequestCookieBehavior {\n  /**\n   * Cookies in viewer requests are not included in requests that CloudFront sends to the origin.\n   * Any cookies that are listed in a CachePolicy are still included in origin requests.\n   */\n  public static none() { return new OriginRequestCookieBehavior('none'); }\n\n  /** All cookies in viewer requests are included in requests that CloudFront sends to the origin. */\n  public static all() { return new OriginRequestCookieBehavior('all'); }\n\n  /** All cookies except the provided `cookies` are included in requests that CloudFront sends to the origin. */\n  public static denyList(...cookies: string[]) {\n    if (cookies.length === 0) {\n      throw new UnscopedValidationError('At least one cookie to deny must be provided');\n    }\n    return new OriginRequestCookieBehavior('allExcept', cookies);\n  }\n\n  /** Only the provided `cookies` are included in requests that CloudFront sends to the origin. */\n  public static allowList(...cookies: string[]) {\n    if (cookies.length === 0) {\n      throw new UnscopedValidationError('At least one cookie to allow must be provided');\n    }\n    return new OriginRequestCookieBehavior('whitelist', cookies);\n  }\n\n  /** The behavior of cookies: allow all, none or an allow list. */\n  public readonly behavior: string;\n  /** The cookies to allow, if the behavior is an allow list. */\n  public readonly cookies?: string[];\n\n  private constructor(behavior: string, cookies?: string[]) {\n    this.behavior = behavior;\n    this.cookies = cookies;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Step Functions, CloudFormation, CloudMap (Service Discovery) resources", "output": "class TestStack extends cdk.Stack {\n  public readonly stateMachine: sfn.StateMachine;\n  constructor(scope: cdk.App, id: string, props: cdk.StackProps = {}) {\n    super(scope, id, props);\n\n    const sendSuccess = new tasks.CallAwsService(this, 'SendSuccess', {\n      service: 'sfn',\n      action: 'sendTaskSuccess',\n      parameters: {\n        TaskToken: sfn.JsonPath.stringAt('$.taskToken'),\n        Output: '{}',\n      },\n      iamResources: ['*'],\n    });\n    const acceptorStateMachine = new sfn.StateMachine(this, 'AcceptorStateMachine', {\n      definitionBody: sfn.DefinitionBody.fromChainable(sendSuccess),\n    });\n\n    const targetRegion = cdk.Stack.of(this).region;\n\n    const startExecution = new tasks.CallAwsServiceCrossRegion(this, 'StartExecution', {\n      service: 'sfn',\n      action: 'startExecution',\n      parameters: {\n        'stateMachineArn': acceptorStateMachine.stateMachineArn,\n        'input.$': 'States.Format(\\'\\\\{\"taskToken\": \"{}\"\\\\}\\', $$.Task.Token)',\n      },\n      iamResources: [acceptorStateMachine.stateMachineArn],\n      region: targetRegion,\n      resultPath: sfn.JsonPath.DISCARD,\n      integrationPattern: sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN,\n    });\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definitionBody: sfn.DefinitionBody.fromChainable(startExecution),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function doAddMethod", "output": "const doAddMethod = () => {\n      const method = this.addMethod({\n        name: `arnFor${this.resource.name}`,\n        static: true,\n        visibility: MemberVisibility.Public,\n        returnType: Type.STRING,\n      });\n\n      method.addParameter({\n        name: 'resource',\n        type: this.ref.interfaceType,\n      });\n\n      return method;\n    }", "language": "typescript"}
{"input": "Test for SNS Topic and Subscription: S3 Upload Event Notification", "output": "def test_sns_topic_created(template):\n    \"\"\"\n      Test for SNS Topic and Subscription: S3 Upload Event Notification\n      \"\"\"\n\n    template.resource_count_is(\"AWS::SNS::Subscription\", 1)\n    template.resource_count_is(\"AWS::SNS::Topic\", 1)\n    template.resource_count_is(\"AWS::SNS::TopicPolicy\", 1)", "language": "python"}
{"input": "CDK class LambdaDataSource for AWS resource management", "output": "export class LambdaDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.LambdaDataSource';\n\n  constructor(scope: Construct, id: string, props: LambdaDataSourceProps) {\n    super(scope, id, props, {\n      type: 'AWS_LAMBDA',\n      lambdaConfig: {\n        lambdaFunctionArn: props.lambdaFunction.functionArn,\n      },\n    });\n    props.lambdaFunction.grantInvoke(this);\n  }\n}", "language": "typescript"}
{"input": "CDK class InlineDockerfileData for AWS resource management", "output": "class InlineDockerfileData extends DockerfileData {\n  protected readonly data: string;\n\n  public constructor(data: string) {\n    super();\n\n    this.data = data;\n  }\n\n  /**\n   * The rendered Dockerfile text, for use in CloudFormation\n   */\n  public render(): DockerfileTemplateConfig {\n    return { dockerfileTemplateData: this.data };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, IAM, CloudFormation, CodePipeline resources", "output": "export class ImagebuilderStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create ImageBuilder component that will handle installing git in the base container image\n    const gitComponenet = new imagebuilder.CfnComponent(this, \"GitComponenet\", {\n      // Prefix component name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"Git\",\n      platform: \"Linux\",\n      version: \"1.0.0\",\n      data: fs.readFileSync(\n          path.resolve('bin/imagebuilder-components/git.yaml'),\n          'utf8'\n        )\n    });\n\n    // Create ImageBuilder component that will handle installing NodeJS in the base container image\n    const nodejsComponenet = new imagebuilder.CfnComponent(this, \"NodejsComponenet\", {\n      // Prefix component name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"Nodejs\",\n      platform: \"Linux\",\n      version: \"1.0.0\",\n      data: fs.readFileSync(\n          path.resolve('bin/imagebuilder-components/node.yaml'),\n          'utf8'\n        )\n    });\n\n    // Create ImageBuilder component that will handle installing Docker in the base container image\n    const dockerComponenet = new imagebuilder.CfnComponent(this, \"DockerComponenet\", {\n      // Prefix component name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"Docker\",\n      platform: \"Linux\",\n      version: \"1.0.2\",\n      data: fs.readFileSync(\n          path.resolve('bin/imagebuilder-components/docker.yaml'),\n          'utf8'\n        )\n    });\n\n    // Create the Amazon Elastic Container Registry repository that will host the resulting image(s)\n    const ecrRepoForImageBuilderCodeCatalyst = new ecr.Repository(this, \"EcrRepoForImageBuilderCodeCatalyst\")\n\n    // Create an ImageBuilder recipe that contains the 3 components\n    const AmazonLinux2023wGitNodeRecipe = new imagebuilder.CfnContainerRecipe(this, \"AmazonLinux2023withGitAndNodeRecipe\", {\n      components: [\n        {\n          componentArn : gitComponenet.attrArn,\n        },\n        {\n          componentArn : nodejsComponenet.attrArn,\n        },\n        {\n          componentArn : dockerComponenet.attrArn,\n        }\n      ],\n      containerType: \"DOCKER\",\n      dockerfileTemplateData: \"FROM {{{ imagebuilder:parentImage }}}\\n{{{ imagebuilder:environments }}}\\n{{{ imagebuilder:components }}}\\n\",\n      // Prefix recipe name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"AmazonLinux2023WithGit\",\n      // Use amazon linux 2023 base image with the latest version tag indicated by /x.x.x\n      parentImage: `arn:aws:imagebuilder:${this.region}:aws:image/amazon-linux-2023-x86-latest/x.x.x`,\n      // Specify the destination repository as the one created above\n      targetRepository: {\n        repositoryName: ecrRepoForImageBuilderCodeCatalyst.repositoryName,\n        service : \"ECR\"\n      },\n      version: \"2.1.2\"\n    })\n\n    // Create an IAM role for ImageBuilder EC2 build instances, that has the needed AWS Managed policies\n    const iamRoleForImageBuilder = new iam.Role(this, 'EC2InstanceProfileForImageBuilder', {\n      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n      managedPolicies: [\n        {\n          managedPolicyArn: \"arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore\"\n        },\n        {\n          managedPolicyArn: \"arn:aws:iam::aws:policy/EC2InstanceProfileForImageBuilder\"\n        },\n        {\n          managedPolicyArn: \"arn:aws:iam::aws:policy/EC2InstanceProfileForImageBuilderECRContainerBuilds\"\n        }\n      ]\n    })\n    // Suppress cdk_nag warning on use of managed policies\n    NagSuppressions.addResourceSuppressions(iamRoleForImageBuilder, [\n      { id: 'AwsSolutions-IAM4', reason: 'Managed policies for ImageBuilder are used as the provide a comprehensive set of permissions to allow ImageBuilder to function in this sample' },\n    ]);\n\n    // Create an EC2 instance profile that uses the IAM role created above\n    const instanceProfileForImageBuilder = new iam.InstanceProfile(this, \"InstanceProfileForImageBuilder\", {\n      role: iamRoleForImageBuilder\n    });\n\n    // Create build infrastructure configuration that uses the instance profile\n    const infraConfig = new imagebuilder.CfnInfrastructureConfiguration(this, \"ImageBuilderInfraConfig\", {\n      // Prefix recipe name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"infra\",\n      instanceProfileName: instanceProfileForImageBuilder.instanceProfileName,\n    });\n\n    // Create a distribution config to specify where the resulting image(s) should be stored\n    const distConfig = new imagebuilder.CfnDistributionConfiguration(this, \"ImageBuilderDistConfig\", {\n      // Prefix recipe name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"dist\",\n      distributions: [\n        {\n          // Set the target region to the same region where the current stack is deployed\n          region: this.region!,\n          containerDistributionConfiguration: {\n            \"TargetRepository\" : {\n              // Set the repository to the one created above\n              \"RepositoryName\" : ecrRepoForImageBuilderCodeCatalyst.repositoryName,\n              \"Service\" : \"ECR\"\n            }\n          }\n        }\n      ]\n    });\n\n    // Create the ImageBuilder pipeline using the infrastructure, distribution, and container recipe above\n    const imageBuilderPipeline = new imagebuilder.CfnImagePipeline(this, \"AmazonLinux2023WithGitPipeline\", {\n      // Prefix recipe name with stack name for inter-environment uniqueness\n      name: this.stackName + '-' + \"AmazonLinux23WithGitPipeline\",\n      infrastructureConfigurationArn: infraConfig.attrArn,\n      distributionConfigurationArn: distConfig.attrArn,\n      containerRecipeArn: AmazonLinux2023wGitNodeRecipe.attrArn,\n      status: \"ENABLED\",\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudWatch, CloudFormation resources", "output": "export class CodewhispererDashboardStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Set up a CloudWatch dashboard that shows CodeWhisperer accept rate metrics\n    const acceptDashboard = new Dashboard(this, \"cw-dashboard\", {\n        dashboardName: \"CodeWhisperer-AcceptRates\"\n    });\n\n    // Replicate all widgets for these languages\n    const languages = [\"Python\", \"Java\", \"JavaScript\", \"TypeScript\"];\n\n    function createInvocationMetric(\n        language: string, completionType: string, accept: boolean) {\n\n        return new Metric({\n            metricName: \"InvocationCount\", \n            namespace: \"AWS/CodeWhisperer\", \n            dimensionsMap: {\n                \"SuggestionState\": accept ? \"ACCEPT\" : \"REJECT\", \n                \"CompletionType\": completionType, \n                \"ProgrammingLanguage\": language.toLowerCase() \n            },\n            statistic: \"Sum\", \n            label: completionType + \" Accept\", \n            period: Duration.seconds(300)\n        });\n    }\n\n    for (const language of languages) {\n\n        // Create a metric for block accept\n        const m1 = createInvocationMetric(language, \"BLOCK\", true)\n\n        // Create a metric for block reject\n        const m2 = createInvocationMetric(language, \"BLOCK\", false)\n\n        // Create a metric for line accept\n        const m3 = createInvocationMetric(language, \"LINE\", true)\n\n        // Create a metric for line reject\n        const m4 = createInvocationMetric(language, \"LINE\", false)\n\n        // Create an expression for accept rate \n        const blockRate = new MathExpression({\n            label: \"Block Accept Rate\", \n            expression: \"100*m1/(m1+m2)\",\n            usingMetrics: {\n                \"m1\": m1, \n                \"m2\": m2\n            }\n        });\n\n        const lineRate = new MathExpression({\n            label: \"Line Accept Rate\", \n            expression: \"100*m3/(m3+m4)\",\n            usingMetrics: {\n                \"m3\": m3, \n                \"m4\": m4\n            }\n        });\n\n        // Create a widget to display block accepts and rejects\n        const w1 = new GraphWidget({\n            width: 6, \n            title: language + \" Block Accept/Reject\", \n            left: [ m1, m2 ]\n        });\n\n        // Create a widget to display block accept rate\n        const w2 = new GraphWidget({\n            width: 6, \n            title: language + \" Block Accept Rate\", \n            left: [ blockRate ]\n        });\n\n        // Create a widget to display line accepts and rejects\n        const w3 = new GraphWidget({\n            width: 6, \n            title: language + \" Line Accept/Reject\", \n            left: [ m3, m4 ]\n        });\n\n        // Create a widget to display line accept rate\n        const w4 = new GraphWidget({\n            width: 6, \n            title: language + \" Line Accept Rate\", \n            left: [ lineRate ]\n        });\n\n        acceptDashboard.addWidgets(w1, w2, w3, w4);\n    }\n\n    // Set up a CloudWatch dashboard that shows CodeWhisperer character counts\n    const charDashboard = new Dashboard(this, \"cw-dashboard-char\", {\n        dashboardName: \"CodeWhisperer-WrittenBy\"\n    });\n\n    function createCharMetric(language: string, total: boolean) {\n        return new Metric({\n            metricName: total ? \"TotalCharacterCount\" : \"CodeWhispererCharacterCount\", \n            namespace: \"AWS/CodeWhisperer\", \n            dimensionsMap: {\n                \"ProgrammingLanguage\": language.toLowerCase() \n            },\n            statistic: \"Sum\", \n            label: total ? \"Total\" : \"CodeWhisperer\", \n            period: Duration.seconds(300)\n        });\n    }\n\n    for (const language of languages) {\n\n        // Written by CW\n        const m1 = createCharMetric(language, false);\n\n        // Total\n        const m2 = createCharMetric(language, true);\n\n        // Create an expression for percentage of code written by Cw \n        const pct = new MathExpression({\n            label: \"Pct written by CodeWhisperer\", \n            expression: \"100*m1/m2\",\n            usingMetrics: {\n                \"m1\": m1, \n                \"m2\": m2\n            }\n        });\n\n        const w1 = new GraphWidget({\n            width: 6, \n            title: language + \" Characters Written\", \n            left: [ m1, m2 ]\n        });\n\n        const w2 = new GraphWidget({\n            width: 6, \n            title: language + \" Pct by CW\", \n            left: [ pct ]\n        });\n\n        charDashboard.addWidgets(w1, w2);\n\n    }\n\n  }\n}", "language": "typescript"}
{"input": "@see https://docs.aws.amazon.com/athena/latest/ug/data-types.html", "output": "export class Schema {\n  public static readonly BOOLEAN: Type = {\n    isPrimitive: true,\n    inputString: 'boolean',\n  };\n\n  public static readonly BINARY: Type = {\n    isPrimitive: true,\n    inputString: 'binary',\n  };\n\n  /**\n   * A 64-bit signed INTEGER in two\u2019s complement format, with a minimum value of -2^63 and a maximum value of 2^63-1.\n   */\n  public static readonly BIG_INT: Type = {\n    isPrimitive: true,\n    inputString: 'bigint',\n  };\n\n  public static readonly DOUBLE: Type = {\n    isPrimitive: true,\n    inputString: 'double',\n  };\n\n  public static readonly FLOAT: Type = {\n    isPrimitive: true,\n    inputString: 'float',\n  };\n\n  /**\n   * A 32-bit signed INTEGER in two\u2019s complement format, with a minimum value of -2^31 and a maximum value of 2^31-1.\n   */\n  public static readonly INTEGER: Type = {\n    isPrimitive: true,\n    inputString: 'int',\n  };\n\n  /**\n   * A 16-bit signed INTEGER in two\u2019s complement format, with a minimum value of -2^15 and a maximum value of 2^15-1.\n   */\n  public static readonly SMALL_INT: Type = {\n    isPrimitive: true,\n    inputString: 'smallint',\n  };\n\n  /**\n   * A 8-bit signed INTEGER in two\u2019s complement format, with a minimum value of -2^7 and a maximum value of 2^7-1\n   */\n  public static readonly TINY_INT: Type = {\n    isPrimitive: true,\n    inputString: 'tinyint',\n  };\n\n  /**\n   * Date type.\n   */\n  public static readonly DATE: Type = {\n    isPrimitive: true,\n    inputString: 'date',\n  };\n\n  /**\n   * Timestamp type (date and time).\n   */\n  public static readonly TIMESTAMP: Type = {\n    isPrimitive: true,\n    inputString: 'timestamp',\n  };\n\n  /**\n   * Arbitrary-length string type.\n   */\n  public static readonly STRING: Type = {\n    isPrimitive: true,\n    inputString: 'string',\n  };\n\n  /**\n   * Creates a decimal type.\n   *\n   * TODO: Bounds\n   *\n   * @param precision the total number of digits\n   * @param scale the number of digits in fractional part, the default is 0\n   */\n  public static decimal(precision: number, scale?: number): Type {\n    return {\n      isPrimitive: true,\n      inputString: scale !== undefined ? `decimal(${precision},${scale})` : `decimal(${precision})`,\n    };\n  }\n\n  /**\n   * Fixed length character data, with a specified length between 1 and 255.\n   *\n   * @param length length between 1 and 255\n   */\n  public static char(length: number): Type {\n    if (length <= 0 || length > 255) {\n      throw new UnscopedValidationError(`char length must be (inclusively) between 1 and 255, but was ${length}`);\n    }\n    if (length % 1 !== 0) {\n      throw new UnscopedValidationError(`char length must be a positive integer, was ${length}`);\n    }\n    return {\n      isPrimitive: true,\n      inputString: `char(${length})`,\n    };\n  }\n\n  /**\n   * Variable length character data, with a specified length between 1 and 65535.\n   *\n   * @param length length between 1 and 65535.\n   */\n  public static varchar(length: number): Type {\n    if (length <= 0 || length > 65535) {\n      throw new UnscopedValidationError(`varchar length must be (inclusively) between 1 and 65535, but was ${length}`);\n    }\n    if (length % 1 !== 0) {\n      throw new UnscopedValidationError(`varchar length must be a positive integer, was ${length}`);\n    }\n    return {\n      isPrimitive: true,\n      inputString: `varchar(${length})`,\n    };\n  }\n\n  /**\n   * Creates an array of some other type.\n   *\n   * @param itemType type contained by the array.\n   */\n  public static array(itemType: Type): Type {\n    return {\n      isPrimitive: false,\n      inputString: `array<${itemType.inputString}>`,\n    };\n  }\n\n  /**\n   * Creates a map of some primitive key type to some value type.\n   *\n   * @param keyType type of key, must be a primitive.\n   * @param valueType type fo the value indexed by the key.\n   */\n  public static map(keyType: Type, valueType: Type): Type {\n    if (!keyType.isPrimitive) {\n      throw new UnscopedValidationError(`the key type of a 'map' must be a primitive, but was ${keyType.inputString}`);\n    }\n    return {\n      isPrimitive: false,\n      inputString: `map<${keyType.inputString},${valueType.inputString}>`,\n    };\n  }\n\n  /**\n   * Creates a nested structure containing individually named and typed columns.\n   *\n   * @param columns the columns of the structure.\n   */\n  public static struct(columns: Column[]): Type {\n    return {\n      isPrimitive: false,\n      inputString: `struct<${columns.map(column => {\n        if (column.comment === undefined) {\n          return `${column.name}:${column.type.inputString}`;\n        } else {\n          return `${column.name}:${column.type.inputString} COMMENT '${column.comment}'`;\n        }\n      }).join(',')}>`,\n    };\n  }\n}", "language": "typescript"}
{"input": "Returns all values for a specified parameter type.", "output": "class FnRefAll extends FnBase {\n  /**\n   * Creates an ``Fn::RefAll`` function.\n   * @param parameterType An AWS-specific parameter type, such as AWS::EC2::SecurityGroup::Id or\n   *            AWS::EC2::VPC::Id. For more information, see Parameters in the AWS\n   *            CloudFormation User Guide.\n   */\n  constructor(parameterType: string) {\n    super('Fn::RefAll', parameterType);\n  }\n}", "language": "typescript"}
{"input": "CDK Construct for Lambda infrastructure components", "output": "export class SampleLambdaConstruct extends Construct {\n    constructor(scope: Construct, id: string){\n        super(scope, id);\n\n        const lambdaProps: lambda.FunctionProps = {\n            handler: 'index.handler',\n            code: lambda.Code.fromInline('export function handler(event, context){}'),\n            runtime: lambda.Runtime.NODEJS_18_X,\n        }\n\n        new lambda.Function(this, 'StandardFunction', lambdaProps);\n\n        new lambda.Function(this, 'FunctionWithReservedCEs', {\n            ...lambdaProps,\n            //Our aspect should not update this value, based on the logic in our \"visit\" method\n            reservedConcurrentExecutions: 10,\n        });\n    }\n}", "language": "typescript"}
{"input": "Deployment environment for an AWS Service Catalog product stack. Interoperates with the StackSynthesizer of the parent stack.", "output": "export class ProductStackSynthesizer extends cdk.StackSynthesizer {\n  private readonly parentStack: cdk.Stack;\n  private readonly assetBucket?: IBucket;\n  private readonly serverSideEncryption? : ServerSideEncryption;\n  private readonly serverSideEncryptionAwsKmsKeyId? : string;\n  private readonly memoryLimit?: number;\n  private parentAssetBucket?: IBucket;\n\n  constructor(props: ProductStackSynthesizerProps) {\n    super();\n    this.parentStack = props.parentStack;\n    this.assetBucket = props.assetBucket;\n    this.serverSideEncryption = props.serverSideEncryption;\n    this.serverSideEncryptionAwsKmsKeyId = props.serverSideEncryptionAwsKmsKeyId;\n    this.memoryLimit = props.memoryLimit;\n\n    if (this.assetBucket && !cdk.Resource.isOwnedResource(this.assetBucket)) {\n      cdk.Annotations.of(this.parentStack).addWarningV2('@aws-cdk/aws-servicecatalog:assetsManuallyAddBucketPermissions', '[WARNING] Bucket Policy Permissions cannot be added to' +\n        ' referenced Bucket. Please make sure your bucket has the correct permissions');\n    }\n  }\n\n  public addFileAsset(asset: cdk.FileAssetSource): cdk.FileAssetLocation {\n    if (!this.assetBucket) {\n      throw new UnscopedValidationError('An Asset Bucket must be provided to use Assets');\n    }\n\n    // This assumes all assets added to the parent stack's synthesizer go into the same bucket.\n    const location = this.parentStack.synthesizer.addFileAsset(asset);\n    if (!this.parentAssetBucket) {\n      this.parentAssetBucket = Bucket.fromBucketName(this.boundStack, 'ParentAssetBucket', location.bucketName);\n    }\n    const objectKey = location.objectKey;\n    const source = Source.bucket(this.parentAssetBucket, location.objectKey);\n\n    if (this.serverSideEncryption === ServerSideEncryption.AWS_KMS && !this.serverSideEncryptionAwsKmsKeyId) {\n      throw new UnscopedValidationError('A KMS Key must be provided to use SSE_KMS');\n    }\n    if (this.serverSideEncryption !== ServerSideEncryption.AWS_KMS && this.serverSideEncryptionAwsKmsKeyId) {\n      throw new UnscopedValidationError('A SSE_KMS encryption must be enabled if you provide KMS Key');\n    }\n\n    // Multiple Products deploying into the same bucket will use the same 'BucketDeployment' construct.\n    const deploymentScope = this.assetBucket;\n    const deploymentCid = 'ProductAssetsDeployment';\n    const bucketDeployment = deploymentScope.node.tryFindChild(deploymentCid) as BucketDeployment | undefined\n      ?? new BucketDeployment(deploymentScope, deploymentCid, {\n        sources: [source],\n        destinationBucket: this.assetBucket,\n        extract: false,\n        prune: false,\n        retainOnDelete: true,\n        serverSideEncryption: this.serverSideEncryption,\n        serverSideEncryptionAwsKmsKeyId: this.serverSideEncryptionAwsKmsKeyId,\n        memoryLimit: this.memoryLimit,\n        outputObjectKeys: false,\n      });\n    bucketDeployment.addSource(source);\n\n    const bucketName = this.physicalNameOfBucket(this.assetBucket);\n    if (!asset.fileName) {\n      throw new UnscopedValidationError('Asset file name is undefined');\n    }\n    const s3ObjectUrl = `s3://${bucketName}/${objectKey}`;\n    const httpUrl = `https://s3.${bucketName}/${objectKey}`;\n\n    return { bucketName, objectKey, httpUrl, s3ObjectUrl, s3Url: httpUrl };\n  }\n\n  private physicalNameOfBucket(bucket: IBucket) {\n    let resolvedName;\n    if (cdk.Resource.isOwnedResource(bucket)) {\n      resolvedName = cdk.Stack.of(bucket).resolve((bucket.node.defaultChild as CfnBucket).bucketName);\n    } else {\n      resolvedName = bucket.bucketName;\n    }\n    if (resolvedName === undefined) {\n      throw new UnscopedValidationError('A bucketName must be provided to use Assets');\n    }\n    return resolvedName;\n  }\n\n  public addDockerImageAsset(_asset: cdk.DockerImageAssetSource): cdk.DockerImageAssetLocation {\n    throw new UnscopedValidationError('Service Catalog Product Stacks cannot use Assets');\n  }\n\n  public synthesize(session: cdk.ISynthesisSession): void {\n    // Synthesize the template, but don't emit as a cloud assembly artifact.\n    // It will be registered as an S3 asset of its parent instead.\n    this.synthesizeTemplate(session);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, IAM, KMS resources", "output": "class AppSyncCdkStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        table_name = 'items'\n\n        items_graphql_api = CfnGraphQLApi(\n            self, 'ItemsApi',\n            name='items-api',\n            authentication_type='API_KEY'\n        )\n\n        CfnApiKey(\n            self, 'ItemsApiKey',\n            api_id=items_graphql_api.attr_api_id\n        )\n\n        api_schema = CfnGraphQLSchema(\n            self, 'ItemsSchema',\n            api_id=items_graphql_api.attr_api_id,\n            definition=f\"\"\"\\\n                type {table_name} {{\n                    {table_name}Id: ID!\n                    name: String\n                }}\n                type Paginated{table_name} {{\n                    items: [{table_name}!]!\n                    nextToken: String\n                }}\n                type Query {{\n                    all(limit: Int, nextToken: String): Paginated{table_name}!\n                    getOne({table_name}Id: ID!): {table_name}\n                }}\n                type Mutation {{\n                    save(name: String!): {table_name}\n                    delete({table_name}Id: ID!): {table_name}\n                }}\n                type Schema {{\n                    query: Query\n                    mutation: Mutation\n                }}\"\"\"\n        )\n\n        items_table = Table(\n            self, 'ItemsTable',\n            table_name=table_name,\n            partition_key=Attribute(\n                name=f'{table_name}Id',\n                type=AttributeType.STRING\n            ),\n            billing_mode=BillingMode.PAY_PER_REQUEST,\n            stream=StreamViewType.NEW_IMAGE,\n\n            # The default removal policy is RETAIN, which means that cdk\n            # destroy will not attempt to delete the new table, and it will\n            # remain in your account until manually deleted. By setting the\n            # policy to DESTROY, cdk destroy will delete the table (even if it\n            # has data in it)\n            removal_policy=RemovalPolicy.DESTROY  # NOT recommended for production code\n        )\n\n        items_table_role = Role(\n            self, 'ItemsDynamoDBRole',\n            assumed_by=ServicePrincipal('appsync.amazonaws.com')\n        )\n\n        items_table_role.add_managed_policy(\n            ManagedPolicy.from_aws_managed_policy_name(\n                'AmazonDynamoDBFullAccess'\n            )\n        )\n\n        data_source = CfnDataSource(\n            self, 'ItemsDataSource',\n            api_id=items_graphql_api.attr_api_id,\n            name='ItemsDynamoDataSource',\n            type='AMAZON_DYNAMODB',\n            dynamo_db_config=CfnDataSource.DynamoDBConfigProperty(\n                table_name=items_table.table_name,\n                aws_region=self.region\n            ),\n            service_role_arn=items_table_role.role_arn\n        )\n\n        get_one_resolver = CfnResolver(\n            self, 'GetOneQueryResolver',\n            api_id=items_graphql_api.attr_api_id,\n            type_name='Query',\n            field_name='getOne',\n            data_source_name=data_source.name,\n            request_mapping_template=f\"\"\"\\\n            {{\n                \"version\": \"2017-02-28\",\n                \"operation\": \"GetItem\",\n                \"key\": {{\n                \"{table_name}Id\": $util.dynamodb.toDynamoDBJson($ctx.args.{table_name}Id)\n                }}\n            }}\"\"\",\n            response_mapping_template=\"$util.toJson($ctx.result)\"\n        )\n\n        get_one_resolver.add_dependency(api_schema)\n        get_one_resolver.add_dependency(data_source)\n\n        get_all_resolver = CfnResolver(\n            self, 'GetAllQueryResolver',\n            api_id=items_graphql_api.attr_api_id,\n            type_name='Query',\n            field_name='all',\n            data_source_name=data_source.name,\n            request_mapping_template=f\"\"\"\\\n            {{\n                \"version\": \"2017-02-28\",\n                \"operation\": \"Scan\",\n                \"limit\": $util.defaultIfNull($ctx.args.limit, 20),\n                \"nextToken\": $util.toJson($util.defaultIfNullOrEmpty($ctx.args.nextToken, null))\n            }}\"\"\",\n            response_mapping_template=\"$util.toJson($ctx.result)\"\n        )\n\n        get_all_resolver.add_dependency(api_schema)\n        get_all_resolver.add_dependency(data_source)\n\n        save_resolver = CfnResolver(\n            self, 'SaveMutationResolver',\n            api_id=items_graphql_api.attr_api_id,\n            type_name='Mutation',\n            field_name='save',\n            data_source_name=data_source.name,\n            request_mapping_template=f\"\"\"\\\n            {{\n                \"version\": \"2017-02-28\",\n                \"operation\": \"PutItem\",\n                \"key\": {{\n                    \"{table_name}Id\": {{ \"S\": \"$util.autoId()\" }}\n                }},\n                \"attributeValues\": {{\n                    \"name\": $util.dynamodb.toDynamoDBJson($ctx.args.name)\n                }}\n            }}\"\"\",\n            response_mapping_template=\"$util.toJson($ctx.result)\"\n        )\n\n        save_resolver.add_dependency(api_schema)\n        save_resolver.add_dependency(data_source)\n\n        delete_resolver = CfnResolver(\n            self, 'DeleteMutationResolver',\n            api_id=items_graphql_api.attr_api_id,\n            type_name='Mutation',\n            field_name='delete',\n            data_source_name=data_source.name,\n            request_mapping_template=f\"\"\"\\\n            {{\n                \"version\": \"2017-02-28\",\n                \"operation\": \"DeleteItem\",\n                \"key\": {{\n                \"{table_name}Id\": $util.dynamodb.toDynamoDBJson($ctx.args.{table_name}Id)\n                }}\n            }}\"\"\",\n            response_mapping_template=\"$util.toJson($ctx.result)\"\n        )\n\n        delete_resolver.add_dependency(api_schema)\n        delete_resolver.add_dependency(data_source)", "language": "python"}
{"input": "CDK Stack that creates CloudFormation, OpenSearch (Elasticsearch) resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new es.Domain(this, 'Domain', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      version: es.ElasticsearchVersion.V7_1,\n      useUnsignedBasicAuth: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "Determines whether any URL query strings in viewer requests are included in the cache key and automatically included in requests that CloudFront sends to the origin.", "output": "export class CacheQueryStringBehavior {\n  /**\n   * Query strings in viewer requests are not included in the cache key and\n   * are not automatically included in requests that CloudFront sends to the origin.\n   */\n  public static none() { return new CacheQueryStringBehavior('none'); }\n\n  /**\n   * All query strings in viewer requests are included in the cache key and are automatically included in requests that CloudFront sends to the origin.\n   */\n  public static all() { return new CacheQueryStringBehavior('all'); }\n\n  /**\n   * Only the provided `queryStrings` are included in the cache key and automatically included in requests that CloudFront sends to the origin.\n   */\n  public static allowList(...queryStrings: string[]) {\n    if (queryStrings.length === 0) {\n      throw new UnscopedValidationError('At least one query string to allow must be provided');\n    }\n    return new CacheQueryStringBehavior('whitelist', queryStrings);\n  }\n\n  /**\n   * All query strings except the provided `queryStrings` are included in the cache key and\n   * automatically included in requests that CloudFront sends to the origin.\n   */\n  public static denyList(...queryStrings: string[]) {\n    if (queryStrings.length === 0) {\n      throw new UnscopedValidationError('At least one query string to deny must be provided');\n    }\n    return new CacheQueryStringBehavior('allExcept', queryStrings);\n  }\n\n  /** The behavior of query strings -- allow all, none, only an allow list, or a deny list. */\n  public readonly behavior: string;\n  /** The query strings to allow or deny, if the behavior is an allow or deny list. */\n  public readonly queryStrings?: string[];\n\n  private constructor(behavior: string, queryStrings?: string[]) {\n    this.behavior = behavior;\n    this.queryStrings = queryStrings;\n  }\n}", "language": "typescript"}
{"input": "CDK class TreeCloudArtifact for AWS resource management", "output": "export class TreeCloudArtifact extends CloudArtifact {\n  /**\n   * Checks if `art` is an instance of this class.\n   *\n   * Use this method instead of `instanceof` to properly detect `TreeCloudArtifact`\n   * instances, even when the construct library is symlinked.\n   *\n   * Explanation: in JavaScript, multiple copies of the `cx-api` library on\n   * disk are seen as independent, completely different libraries. As a\n   * consequence, the class `TreeCloudArtifact` in each copy of the `cx-api` library\n   * is seen as a different class, and an instance of one class will not test as\n   * `instanceof` the other class. `npm install` will not create installations\n   * like this, but users may manually symlink construct libraries together or\n   * use a monorepo tool: in those cases, multiple copies of the `cx-api`\n   * library can be accidentally installed, and `instanceof` will behave\n   * unpredictably. It is safest to avoid using `instanceof`, and using\n   * this type-testing method instead.\n   */\n  public static isTreeCloudArtifact(art: any): art is TreeCloudArtifact {\n    return art && typeof art === 'object' && TREE_CLOUD_ARTIFACT_SYM in art;\n  }\n\n  public readonly file: string;\n\n  constructor(assembly: CloudAssembly, name: string, artifact: cxschema.ArtifactManifest) {\n    super(assembly, name, artifact);\n\n    const properties = (this.manifest.properties || {}) as cxschema.TreeArtifactProperties;\n    if (!properties.file) {\n      throw new CloudAssemblyError('Invalid TreeCloudArtifact. Missing \"file\" property');\n    }\n    this.file = properties.file;\n  }\n}", "language": "typescript"}
{"input": "CDK class CodePipelinePropsCheckTest for AWS resource management", "output": "class CodePipelinePropsCheckTest extends cdk.Stack {\n  cProps: CodePipelineStackProps;\n  public constructor(scope: Construct, id: string, props: CodePipelineStackProps) {\n    super(scope, id, props);\n    this.cProps = props;\n  }\n  public create() {\n    if (this.cProps.pipelineName !== undefined) {\n      new cdkp.CodePipeline(this, 'CodePipeline1', {\n        pipelineName: this.cProps.pipelineName,\n        codePipeline: new Pipeline(this, 'Pipeline1'),\n        synth: new cdkp.ShellStep('Synth', { commands: ['ls'] }),\n      }).buildPipeline();\n    }\n    if (this.cProps.crossAccountKeys !== undefined) {\n      new cdkp.CodePipeline(this, 'CodePipeline2', {\n        crossAccountKeys: this.cProps.crossAccountKeys,\n        codePipeline: new Pipeline(this, 'Pipeline2'),\n        synth: new cdkp.ShellStep('Synth', { commands: ['ls'] }),\n      }).buildPipeline();\n    }\n    if (this.cProps.enableKeyRotation !== undefined) {\n      new cdkp.CodePipeline(this, 'CodePipeline3', {\n        enableKeyRotation: this.cProps.enableKeyRotation,\n        codePipeline: new Pipeline(this, 'Pipeline3'),\n        synth: new cdkp.ShellStep('Synth', { commands: ['ls'] }),\n      }).buildPipeline();\n    }\n    if (this.cProps.reuseCrossRegionSupportStacks !== undefined) {\n      new cdkp.CodePipeline(this, 'CodePipeline4', {\n        reuseCrossRegionSupportStacks: this.cProps.reuseCrossRegionSupportStacks,\n        codePipeline: new Pipeline(this, 'Pipeline4'),\n        synth: new cdkp.ShellStep('Synth', { commands: ['ls'] }),\n      }).buildPipeline();\n    }\n    if (this.cProps.role !== undefined) {\n      new cdkp.CodePipeline(this, 'CodePipeline5', {\n        role: this.cProps.role,\n        codePipeline: new Pipeline(this, 'Pipeline5'),\n        synth: new cdkp.ShellStep('Synth', { commands: ['ls'] }),\n      }).buildPipeline();\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class S3EventSourceTest for AWS resource management", "output": "class S3EventSourceTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const fn = new TestFunction(this, 'F');\n    const bucket = new s3.Bucket(this, 'B', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    fn.addEventSource(new S3EventSource(bucket, {\n      events: [s3.EventType.OBJECT_CREATED],\n      filters: [{ prefix: 'subdir/' }],\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class NoTsConfig for AWS resource management", "output": "export class NoTsConfig extends ValidationRule {\n  public readonly name = 'npmignore/tsconfig';\n\n  public validate(pkg: PackageJson): void {\n    // skip private packages\n    if (pkg.json.private) { return; }\n\n    fileShouldContain(this.name, pkg, '.npmignore', 'tsconfig.json');\n  }\n}", "language": "typescript"}
{"input": "CDK helper function create", "output": "def create(self, bucket_name):\n\n        create_params = {\n            \"Body\": \"Hello world\",\n            \"Bucket\": bucket_name,\n            \"Key\": \"helloWorld.txt\"\n        }\n\n        return AwsSdkCall(\n            action='putObject',\n            service='S3',\n            parameters=create_params,\n            physical_resource_id=PhysicalResourceId.of('myAutomationExecution')\n        )", "language": "python"}
{"input": "The RemoveTag Aspect will handle removing tags from this node and children", "output": "export class RemoveTag extends TagBase {\n  private readonly defaultPriority = 200;\n\n  constructor(key: string, props: TagProps = {}) {\n    super(key, props);\n  }\n\n  protected applyTag(resource: ITaggable): void {\n    this.applyManager(resource.tags);\n  }\n\n  protected applyTagV2(resource: ITaggableV2): void {\n    this.applyManager(resource.cdkTagManager);\n  }\n\n  private applyManager(mgr: TagManager) {\n    if (mgr.applyTagAspectHere(this.props.includeResourceTypes, this.props.excludeResourceTypes)) {\n      mgr.removeTag(this.key, this.props.priority ?? this.defaultPriority);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class Step1SourceAccount for AWS resource management", "output": "export class Step1SourceAccount extends Stack {\n  public replicationRole: Role;\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const crossAccountReplicationRole = new Role(\n      this,\n      \"s3-cross-account-replication-role\",\n      {\n        assumedBy: new ServicePrincipal(\"s3.amazonaws.com\"),\n        roleName: Config.replicationRoleName,\n        description: \"Role used to replicate across accounts for S3 buckets\",\n        path: \"/\",\n      }\n    );\n\n    const crossAccountReplicationRolePolicy = new PolicyDocument({\n      statements: [\n        new PolicyStatement({\n          effect: Effect.ALLOW,\n          actions: [\n            \"s3:ListBucket\",\n            \"s3:GetReplicationConfiguration\",\n            \"s3:GetObjectVersionForReplication\",\n            \"s3:GetObjectVersionAcl\",\n            \"s3:GetObjectVersionTagging\",\n            \"s3:GetObjectRetention\",\n            \"s3:GetObjectLegalHold\",\n          ],\n          resources: [\n            `arn:aws:s3:::${Config.sourceBucketName}`,\n            `arn:aws:s3:::${Config.sourceBucketName}/*`,\n            `arn:aws:s3:::${Config.destinationBucketName}`,\n            `arn:aws:s3:::${Config.destinationBucketName}/*`,\n          ],\n        }),\n        new PolicyStatement({\n          effect: Effect.ALLOW,\n          actions: [\n            \"s3:ReplicateObject\",\n            \"s3:ReplicateDelete\",\n            \"s3:ReplicateTags\",\n            \"s3:ObjectOwnerOverrideToBucketOwner\",\n          ],\n          resources: [\n            `arn:aws:s3:::${Config.sourceBucketName}/*`,\n            `arn:aws:s3:::${Config.destinationBucketName}/*`,\n          ],\n        }),\n        new PolicyStatement({\n          sid: \"AllowPermissionsToDoEncryption\",\n          effect: Effect.ALLOW,\n          actions: [\"kms:Encrypt\"],\n          resources: [\n            `arn:aws:kms:${Config.destinationRegion}:${Config.destinationAccountId}:key/*`,\n          ],\n        }),\n        new PolicyStatement({\n          sid: \"AllowPermissionsToDoDecryption\",\n          effect: Effect.ALLOW,\n          actions: [\"kms:Decrypt\"],\n          resources: [\n            `arn:aws:kms:${Config.sourceRegion}:${Config.sourceAccountId}:key/*`,\n          ],\n        }),\n      ],\n    });\n    crossAccountReplicationRole.attachInlinePolicy(\n      new Policy(this, Config.replicationRolePolicyName, {\n        policyName: Config.replicationRolePolicyName,\n        document: crossAccountReplicationRolePolicy,\n      })\n    );\n\n    this.replicationRole = crossAccountReplicationRole;\n    new CfnOutput(this, \"crossAccountReplicationRoleArn\", {\n      value: crossAccountReplicationRole.roleArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class NetworkAclEntry for AWS resource management", "output": "export class NetworkAclEntry extends NetworkAclEntryBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.NetworkAclEntry';\n\n  public readonly networkAcl: INetworkAcl;\n  public readonly networkAclEntryRef: NetworkAclEntryReference;\n\n  constructor(scope: Construct, id: string, props: NetworkAclEntryProps) {\n    super(scope, id, {\n      physicalName: props.networkAclEntryName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.networkAcl = props.networkAcl;\n\n    const resource = new CfnNetworkAclEntry(this, 'Resource', {\n      networkAclId: this.networkAcl.networkAclRef.networkAclId,\n      ruleNumber: props.ruleNumber,\n      ruleAction: props.ruleAction ?? Action.ALLOW,\n      egress: props.direction !== undefined ? props.direction === TrafficDirection.EGRESS : undefined,\n      ...props.traffic.toTrafficConfig(),\n      ...props.cidr.toCidrConfig(),\n    });\n    this.networkAclEntryRef = resource.networkAclEntryRef;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, MSK (Kafka), CloudFormation, ECS resources", "output": "class ClusterStack extends cdk.Stack {\n      public eksCluster: eks.Cluster;\n\n      constructor(scope: Construct, id: string, props: { sg: ec2.ISecurityGroup; vpc: ec2.IVpc }) {\n        super(scope, id);\n        this.eksCluster = new eks.Cluster(this, 'Cluster', {\n          version: CLUSTER_VERSION,\n          prune: false,\n          securityGroup: props.sg,\n          vpc: props.vpc,\n          kubectlLayer: new KubectlV31Layer(this, 'KubectlLayer'),\n        });\n      }\n    }", "language": "typescript"}
{"input": "Passing L1 Bucket to L1 Events.Rule with cloudtrail pattern", "output": "class L1BucketWithL1Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l1Bucket = new s3.CfnBucket(this, 'bucket');\n    const l1BucketWithEvent = BucketEvents.fromBucket(l1Bucket);\n\n    const trail = new Trail(this, 'Trail', {});\n    trail.addS3EventSelector([{ bucket: l1Bucket }], { readWriteType: ReadWriteType.ALL });\n\n    const fn1 = new Function(this, 'MyFuncB', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n    const rule1 = new CfnRule(this, 'RuleL1BucketL1', {\n      state: 'ENABLED',\n      eventPattern: l1BucketWithEvent.awsAPICallViaCloudTrailPattern(),\n      targets: [{ arn: fn1.functionArn, id: 'L1' }],\n    });\n    fn1.addPermission('L1', {\n      sourceArn: rule1.attrArn,\n      action: 'lambda:InvokeFunction',\n      principal: new ServicePrincipal('events.amazonaws.com'),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class CallApiGatewayRestApiEndpoint for AWS resource management", "output": "export class CallApiGatewayRestApiEndpoint extends CallApiGatewayEndpointBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-stepfunctions-tasks.CallApiGatewayRestApiEndpoint';\n\n  /**\n   * Call REST API endpoint as a Task  using JSONPath\n   *\n   * Be aware that the header values must be arrays. When passing the Task Token\n   * in the headers field `WAIT_FOR_TASK_TOKEN` integration, use\n   * `JsonPath.array()` to wrap the token in an array:\n   *\n   * ```ts\n   * import * as apigateway from 'aws-cdk-lib/aws-apigateway';\n   * declare const api: apigateway.RestApi;\n   *\n   * tasks.CallApiGatewayRestApiEndpoint.jsonPath(this, 'Endpoint', {\n   *   api,\n   *   stageName: 'Stage',\n   *   method: tasks.HttpMethod.PUT,\n   *   integrationPattern: sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN,\n   *   headers: sfn.TaskInput.fromObject({\n   *     TaskToken: sfn.JsonPath.array(sfn.JsonPath.taskToken),\n   *   }),\n   * });\n   * ```\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-api-gateway.html\n   */\n  public static jsonPath(scope: Construct, id: string, props: CallApiGatewayRestApiEndpointJsonPathProps) {\n    return new CallApiGatewayRestApiEndpoint(scope, id, props);\n  }\n  /**\n   * Call REST API endpoint as a Task using JSONata\n   *\n   * Be aware that the header values must be arrays. When passing the Task Token\n   * in the headers field `WAIT_FOR_TASK_TOKEN` integration, use\n   * `JsonPath.array()` to wrap the token in an array:\n   *\n   * ```ts\n   * import * as apigateway from 'aws-cdk-lib/aws-apigateway';\n   * declare const api: apigateway.RestApi;\n   *\n   * tasks.CallApiGatewayRestApiEndpoint.jsonata(this, 'Endpoint', {\n   *   api,\n   *   stageName: 'Stage',\n   *   method: tasks.HttpMethod.PUT,\n   *   integrationPattern: sfn.IntegrationPattern.WAIT_FOR_TASK_TOKEN,\n   *   headers: sfn.TaskInput.fromObject({\n   *     TaskToken: '{% States.Array($states.context.taskToken) %}',\n   *   }),\n   * });\n   * ```\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-api-gateway.html\n   */\n  public static jsonata(scope: Construct, id: string, props: CallApiGatewayRestApiEndpointJsonataProps) {\n    return new CallApiGatewayRestApiEndpoint(scope, id, {\n      ...props,\n      queryLanguage: sfn.QueryLanguage.JSONATA,\n    });\n  }\n  protected readonly taskMetrics?: sfn.TaskMetricsConfig | undefined;\n  protected readonly taskPolicies?: iam.PolicyStatement[] | undefined;\n\n  protected readonly apiEndpoint: string;\n  protected readonly arnForExecuteApi: string;\n  protected readonly stageName?: string;\n\n  constructor(scope: Construct, id: string, private readonly props: CallApiGatewayRestApiEndpointProps) {\n    super(scope, id, props);\n\n    this.apiEndpoint = this.getApiEndpoint(props.region);\n    this.arnForExecuteApi = props.api.arnForExecuteApi(props.method, props.apiPath, props.stageName);\n    this.stageName = props.stageName;\n\n    this.taskPolicies = this.createPolicyStatements();\n  }\n\n  private getApiEndpoint(region?: string): string {\n    const apiStack = cdk.Stack.of(this.props.api);\n    return `${this.props.api.restApiId}.execute-api.${region ?? apiStack.region}.${apiStack.urlSuffix}`;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, WAF, SQS resources", "output": "export class AStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: AStackProps) {\n    super(scope, id, props);\n\n    const queue = new sqs.Queue(this, 'SampleQueue');\n    queue.grant(new iam.ServicePrincipal('s3.amazonaws.com', {\n      conditions: {\n        ArnLike: {\n          'aws:SourceArn': cdk.Arn.format({\n            service: 's3',\n            region: '',\n            account: '',\n            resource: props.bucketName\n          }, this)\n        }\n      }\n    }), 'sqs:SendMessage', 'sqs:GetQueueAttributes', 'sqs:GetQueueUrl');\n\n    const lambdaArn = cdk.Arn.format({\n      service: 'lambda',\n      resource: 'S3EventNotificationsManager'\n    }, this);\n    new cdk.CustomResource(this, 'SampleBucketNotification', {\n      serviceToken: lambdaArn,\n      properties: {\n        BucketName: props.bucketName,\n        NotificationConfiguration: {\n          QueueConfigurations: [\n            {\n              Id: 'SampleQueueNotification',\n              Events: ['s3:ObjectCreated:*'],\n              Filter: {\n                Key: {\n                  FilterRules: [\n                    {\n                      Name: 'prefix',\n                      Value: 'CategoryA/'\n                    }\n                  ]\n                }\n              },\n              QueueArn: queue.queueArn\n            }\n          ]\n        }\n      }\n    });\n  }\n}", "language": "typescript"}
{"input": "Default Priority values for Aspects.", "output": "export class AspectPriority {\n  /**\n   * Suggested priority for Aspects that mutate the construct tree.\n   */\n  static readonly MUTATING: number = 200;\n\n  /**\n   * Suggested priority for Aspects that only read the construct tree.\n   */\n  static readonly READONLY: number = 1000;\n\n  /**\n   * Default priority for Aspects that are applied without a priority.\n   */\n  static readonly DEFAULT: number = 500;\n}", "language": "typescript"}
{"input": "Kubernetes cluster version @see https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar", "output": "export class KubernetesVersion {\n  /**\n   * Kubernetes version 1.14\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_14 = KubernetesVersion.of('1.14');\n\n  /**\n   * Kubernetes version 1.15\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_15 = KubernetesVersion.of('1.15');\n\n  /**\n   * Kubernetes version 1.16\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_16 = KubernetesVersion.of('1.16');\n\n  /**\n   * Kubernetes version 1.17\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_17 = KubernetesVersion.of('1.17');\n\n  /**\n   * Kubernetes version 1.18\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_18 = KubernetesVersion.of('1.18');\n\n  /**\n   * Kubernetes version 1.19\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_19 = KubernetesVersion.of('1.19');\n\n  /**\n   * Kubernetes version 1.20\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_20 = KubernetesVersion.of('1.20');\n\n  /**\n   * Kubernetes version 1.21\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_21 = KubernetesVersion.of('1.21');\n\n  /**\n   * Kubernetes version 1.22\n   * @deprecated Use newer version of EKS\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV22Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v22`.\n   * @deprecated Use newer version of EKS\n   */\n  public static readonly V1_22 = KubernetesVersion.of('1.22');\n\n  /**\n   * Kubernetes version 1.23\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV23Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v23`.\n   */\n  public static readonly V1_23 = KubernetesVersion.of('1.23');\n\n  /**\n   * Kubernetes version 1.24\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV24Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v24`.\n   */\n  public static readonly V1_24 = KubernetesVersion.of('1.24');\n\n  /**\n   * Kubernetes version 1.25\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV25Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v25`.\n   */\n  public static readonly V1_25 = KubernetesVersion.of('1.25');\n\n  /**\n   * Kubernetes version 1.26\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV26Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v26`.\n   */\n  public static readonly V1_26 = KubernetesVersion.of('1.26');\n\n  /**\n   * Kubernetes version 1.27\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV27Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v27`.\n   */\n  public static readonly V1_27 = KubernetesVersion.of('1.27');\n\n  /**\n   * Kubernetes version 1.28\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV28Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v28`.\n   */\n  public static readonly V1_28 = KubernetesVersion.of('1.28');\n\n  /**\n   * Kubernetes version 1.29\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV29Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v29`.\n   */\n  public static readonly V1_29 = KubernetesVersion.of('1.29');\n\n  /**\n   * Kubernetes version 1.30\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV30Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v30`.\n   */\n  public static readonly V1_30 = KubernetesVersion.of('1.30');\n\n  /**\n   * Kubernetes version 1.31\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV31Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v31`.\n   */\n  public static readonly V1_31 = KubernetesVersion.of('1.31');\n\n  /**\n   * Kubernetes version 1.32\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV32Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v32`.\n   */\n  public static readonly V1_32 = KubernetesVersion.of('1.32');\n\n  /**\n   * Kubernetes version 1.33\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV33Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v33`.\n   */\n  public static readonly V1_33 = KubernetesVersion.of('1.33');\n\n  /**\n   * Kubernetes version 1.34\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV34Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v34`.\n   */\n  public static readonly V1_34 = KubernetesVersion.of('1.34');\n\n  /**\n   * Custom cluster version\n   * @param version custom version number\n   */\n  public static of(version: string) { return new KubernetesVersion(version); }\n  /**\n   *\n   * @param version cluster version number\n   */\n  private constructor(public readonly version: string) { }\n}", "language": "typescript"}
{"input": "Filter implementation of FilterOrPolicy", "output": "export class Filter extends FilterOrPolicy {\n  /**\n   * Type used in DFS buildFilterPolicyWithMessageBody to determine json value type\n   */\n  public readonly type = FilterOrPolicyType.FILTER;\n  /**\n   * Policy constructor\n   * @param filterDoc filter argument to construct\n   */\n  public constructor(public readonly filterDoc: SubscriptionFilter) {\n    super();\n  }\n}", "language": "typescript"}
{"input": "Construct that creates a CustomResource to assert that two values are equal", "output": "export class EqualsAssertion extends Construct {\n  /**\n   * The result of the assertion\n   */\n  public readonly result: string;\n\n  constructor(scope: Construct, id: string, props: EqualsAssertionProps) {\n    super(scope, id);\n\n    const assertionProvider = new AssertionsProvider(this, 'AssertionProvider');\n    const properties: AssertionRequest = {\n      actual: props.actual.result,\n      expected: props.expected.result,\n      failDeployment: props.failDeployment,\n    };\n    const resource = new CustomResource(this, 'Default', {\n      serviceToken: assertionProvider.serviceToken,\n      properties: {\n        ...properties,\n        salt: Date.now().toString(), // always update,\n      },\n      resourceType: ASSERT_RESOURCE_TYPE,\n    });\n    this.result = resource.getAttString('data');\n\n    new CfnOutput(this, 'AssertionResults', {\n      value: this.result,\n    }).overrideLogicalId(`AssertionResults${id}${md5hash({ actual: props.actual.result, expected: props.expected.result })}`);\n  }\n}", "language": "typescript"}
{"input": "CDK class CoreTypes for AWS resource management", "output": "export class CoreTypes {\n  /**\n   * @returns true if assembly has the Core module\n   */\n  public static hasCoreModule(assembly: reflect.Assembly) {\n    return (!assembly.system.assemblies.find(a => a.name === CORE_MODULE));\n  }\n\n  /**\n   * @returns true if `classType` represents an L1 Cfn Resource\n   */\n  public static isCfnResource(c: reflect.ClassType) {\n    if (!c.system.includesAssembly(CORE_MODULE)) {\n      return false;\n    }\n\n    // skip CfnResource itself\n    if (c.fqn === CoreTypesFqn.CfnResource) {\n      return false;\n    }\n\n    if (!this.isConstructClass(c)) {\n      return false;\n    }\n\n    const cfnResourceClass = c.system.findFqn(CoreTypesFqn.CfnResource);\n    if (!c.extends(cfnResourceClass)) {\n      return false;\n    }\n\n    return c.name.startsWith('Cfn');\n  }\n\n  /**\n   * @returns true if `classType` represents a Construct\n   */\n  public static isConstructClass(c: reflect.ClassType) {\n    if (!c.system.includesAssembly(CORE_MODULE)) {\n      return false;\n    }\n\n    if (!c.isClassType()) {\n      return false;\n    }\n\n    if (c.abstract) {\n      return false;\n    }\n\n    return c.extends(c.system.findFqn(CoreTypesFqn.Construct));\n  }\n\n  /**\n   * @returns true if `classType` represents an AWS resource (i.e. extends `cdk.Resource`).\n   */\n  public static isResourceClass(classType: reflect.ClassType) {\n    const baseResource = classType.system.findClass(CoreTypesFqn.Resource);\n    return classType.extends(baseResource) || getDocTag(classType, 'resource');\n  }\n\n  /**\n   * @returns true if `interfaceType` looks like an L2 interface (`IBucket`)\n   */\n  public static isL2Interface(interfaceType: reflect.InterfaceType) {\n    // We determine this by it being a behavioral interface, and it inheriting from `IResource`.\n    const baseInterface = interfaceType.system.findInterface(CoreTypesFqn.ResourceInterface);\n    return !interfaceType.datatype && interfaceExtends(interfaceType, baseInterface);\n  }\n\n  /**\n   * @returns true if `interfaceType` looks like an L1 Ref interface (`IBucketRef)`\n   */\n  public static isL1RefInterface(interfaceType: reflect.InterfaceType) {\n    // We determine this by it being a behavioral interface, and it living inside the `aws-cdk-lib.interfaces` namespace\n    // with a name ending in `Ref`.\n    return !interfaceType.datatype && interfaceType.fqn.startsWith('aws-cdk-lib.interfaces.') && interfaceType.name.endsWith('Ref');\n  }\n\n  /**\n   * Return true if the nesting parent of the given interface is a CFN class\n   */\n  public static isCfnNestedType(interfaceType: reflect.Type) {\n    return interfaceType.nestingParent && CoreTypes.isCfnType(interfaceType.nestingParent);\n  }\n\n  /**\n   * Return true if the given interface type is a CFN class, prop type or interface\n   */\n  public static isCfnType(interfaceType: reflect.Type): boolean {\n    // aws_service.CfnTheResource\n    if (interfaceType.name.startsWith('Cfn')) {\n      return true;\n    }\n\n    // aws_service.ITheResourceRf\n    if (/^I\\w+Ref/.test(interfaceType.name)) {\n      return true;\n    }\n\n    if (interfaceType.namespace) {\n      if (interfaceType.namespace.startsWith('Cfn')) {\n        return true;\n      }\n\n      const namespaceParts = interfaceType.namespace.split('.');\n\n      // aws_service.CfnTheResource.SubType\n      if (namespaceParts.at(1)?.startsWith('Cfn')) {\n        return true;\n      }\n\n      // aws_service.mixins.CfnTheResource.SubType\n      if (namespaceParts.at(1) === 'mixins' && namespaceParts.at(2)?.startsWith('Cfn')) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  /**\n   * @returns `classType` for the core type Construct\n   * @deprecated - use `baseConstructClass()`\n   */\n  public get constructClass() {\n    return this.baseConstructClass;\n  }\n\n  /**\n   * @returns `classType` for the core type Construct\n   */\n  public get baseConstructClass() {\n    return this.sys.findClass(this.baseConstructClassFqn);\n  }\n\n  /**\n   * @returns `classType` for the core type Construct\n   */\n  public get baseConstructClassFqn() {\n    return CoreTypesFqn.Construct;\n  }\n\n  /**\n   * @returns `interfacetype` for the core type Construct\n   * @deprecated - use `baseConstructInterface()`\n   */\n  public get constructInterface() {\n    return this.baseConstructInterface;\n  }\n\n  /**\n   * @returns `interfacetype` for the core type Construct\n   */\n  public get baseConstructInterface() {\n    return this.sys.findInterface(this.baseConstructInterfaceFqn);\n  }\n\n  /**\n   * @returns fqn for for the core Construct interface\n   */\n  public get baseConstructInterfaceFqn() {\n    return CoreTypesFqn.ConstructInterface;\n  }\n\n  /**\n   * @returns `classType` for the core type Resource\n   */\n  public get resourceClass() {\n    return this.sys.findClass(this.resourceClassFqn);\n  }\n\n  /**\n   * @returns fqn for the core type Resource\n   */\n  public get resourceClassFqn() {\n    return CoreTypesFqn.Resource;\n  }\n\n  /**\n   * @returns fqn for the core Resource interface\n   */\n  public get resourceInterface() {\n    return this.sys.findInterface(this.resourceInterfaceFqn);\n  }\n\n  /**\n   * @returns `interfaceType` for the core type Resource\n   */\n  public get resourceInterfaceFqn() {\n    return CoreTypesFqn.ResourceInterface;\n  }\n\n  /**\n   * @returns `classType` for the core type Token\n   */\n  public get tokenInterface() {\n    return this.sys.findInterface(this.tokenInterfaceFqn);\n  }\n\n  /**\n   * @returns fqn for the core type Token\n   */\n  public get tokenInterfaceFqn() {\n    return CoreTypesFqn.ResolvableInterface;\n  }\n\n  public get physicalNameClass() {\n    return this.sys.findClass(CoreTypesFqn.PhysicalName);\n  }\n\n  private readonly sys: reflect.TypeSystem;\n\n  constructor(sys: reflect.TypeSystem) {\n    this.sys = sys;\n    if (!sys.includesAssembly(CORE_MODULE)) {\n      // disable-all-checks\n      return;\n    }\n  }\n}", "language": "typescript"}
{"input": "Some construct code made an assumption somewhere that doesn't hold true This error always indicates a bug in the construct. @internal", "output": "export class AssumptionError extends ConstructError {\n  public get type(): 'assumption' {\n    return 'assumption';\n  }\n\n  constructor(msg: string) {\n    super(msg, undefined, AssumptionError.name);\n    Object.setPrototypeOf(this, AssumptionError.prototype);\n    Object.defineProperty(this, ASSUMPTION_ERROR_SYMBOL, { value: true });\n  }\n}", "language": "typescript"}
{"input": "CDK class DatabaseClusterFromSnapshot for AWS resource management", "output": "export class DatabaseClusterFromSnapshot extends DatabaseClusterNew {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.DatabaseClusterFromSnapshot';\n\n  public readonly clusterIdentifier: string;\n  public readonly clusterResourceIdentifier: string;\n  public readonly clusterEndpoint: Endpoint;\n  public readonly clusterReadEndpoint: Endpoint;\n  public readonly connections: ec2.Connections;\n  public readonly instanceIdentifiers: string[];\n  public readonly instanceEndpoints: Endpoint[];\n\n  /**\n   * The secret attached to this cluster\n   */\n  public readonly secret?: secretsmanager.ISecret;\n\n  constructor(scope: Construct, id: string, props: DatabaseClusterFromSnapshotProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.credentials && !props.credentials.password && !props.credentials.secret) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-rds:useSnapshotCredentials', 'Use `snapshotCredentials` to modify password of a cluster created from a snapshot.');\n    }\n    if (!props.credentials && !props.snapshotCredentials) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-rds:generatedCredsNotApplied', 'Generated credentials will not be applied to cluster. Use `snapshotCredentials` instead. `addRotationSingleUser()` and `addRotationMultiUser()` cannot be used on this cluster.');\n    }\n\n    const deprecatedCredentials = !FeatureFlags.of(this).isEnabled(cxapi.RDS_PREVENT_RENDERING_DEPRECATED_CREDENTIALS)\n      ? renderCredentials(this, props.engine, props.credentials)\n      : undefined;\n\n    const credentials = renderSnapshotCredentials(this, props.snapshotCredentials);\n\n    const cluster = new CfnDBCluster(this, 'Resource', {\n      ...this.newCfnProps,\n      snapshotIdentifier: props.snapshotIdentifier,\n      masterUserPassword: credentials?.secret?.secretValueFromJson('password')?.unsafeUnwrap() ?? credentials?.password?.unsafeUnwrap(), // Safe usage\n    });\n\n    this.clusterIdentifier = cluster.ref;\n    this.clusterResourceIdentifier = cluster.attrDbClusterResourceId;\n\n    if (credentials?.secret) {\n      this.secret = credentials.secret.attach(this);\n    }\n\n    if (deprecatedCredentials?.secret) {\n      const deprecatedSecret = deprecatedCredentials.secret.attach(this);\n      if (!this.secret) {\n        this.secret = deprecatedSecret;\n      }\n    }\n\n    // create a number token that represents the port of the cluster\n    const portAttribute = Token.asNumber(cluster.attrEndpointPort);\n    this.clusterEndpoint = new Endpoint(cluster.attrEndpointAddress, portAttribute);\n    this.clusterReadEndpoint = new Endpoint(cluster.attrReadEndpointAddress, portAttribute);\n    this.connections = new ec2.Connections({\n      securityGroups: this.securityGroups,\n      defaultPort: ec2.Port.tcp(this.clusterEndpoint.port),\n    });\n\n    cluster.applyRemovalPolicy(props.removalPolicy ?? RemovalPolicy.SNAPSHOT);\n\n    setLogRetention(this, props);\n    if ((props.writer || props.readers) && (props.instances || props.instanceProps)) {\n      throw new ValidationError('Cannot provide clusterInstances if instances or instanceProps are provided', this);\n    }\n    const createdInstances = props.writer ? this._createInstances(props) : legacyCreateInstances(this, props, this.subnetGroupRef);\n    this.instanceIdentifiers = createdInstances.instanceIdentifiers;\n    this.instanceEndpoints = createdInstances.instanceEndpoints;\n  }\n}", "language": "typescript"}
{"input": "CDK class FakeTask for AWS resource management", "output": "class FakeTask extends stepfunctions.TaskStateBase {\n  protected readonly taskMetrics?: stepfunctions.TaskMetricsConfig;\n  protected readonly taskPolicies?: iam.PolicyStatement[];\n\n  constructor(scope: Construct, id: string, props: FakeTaskProps = {}) {\n    super(scope, id, props);\n    this.taskPolicies = props.policies;\n  }\n\n  protected _renderTask(): any {\n    return {\n      Resource: 'my-resource',\n      Parameters: stepfunctions.FieldUtils.renderObject({\n        MyParameter: 'myParameter',\n      }),\n    };\n  }\n}", "language": "typescript"}
{"input": "Principal entity that represents a SAML federated identity provider", "output": "export class SamlPrincipal extends FederatedPrincipal {\n  constructor(samlProvider: ISAMLProviderRef, conditions: Conditions) {\n    super(samlProvider.samlProviderRef.samlProviderArn, conditions, 'sts:AssumeRoleWithSAML');\n  }\n\n  public toString() {\n    return `SamlPrincipal(${this.federated})`;\n  }\n}", "language": "typescript"}
{"input": "CDK class ARecord for AWS resource management", "output": "export class ARecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.ARecord';\n\n  /**\n   * Creates new A record of type alias with target set to an existing A Record DNS.\n   * Use when the target A record is created outside of CDK\n   * For records created as part of CDK use @aws-cdk-lib/aws-route53-targets/route53-record.ts\n   * @param scope the parent Construct for this Construct\n   * @param id Logical Id of the resource\n   * @param attrs the ARecordAttributes (Target Arecord DNS name and HostedZone)\n   * @returns AWS::Route53::RecordSet of type A with target alias set to existing A record\n   */\n  public static fromARecordAttributes(scope: Construct, id: string, attrs: ARecordAttrs): ARecord {\n    const aliasTarget = RecordTarget.fromAlias(new ARecordAsAliasTarget(attrs));\n    return new ARecord(scope, id, {\n      ...attrs,\n      target: aliasTarget,\n    });\n  }\n\n  constructor(scope: Construct, id: string, props: ARecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.A,\n      target: props.target,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "Determines which resources trigger an evaluation of an AWS Config rule.", "output": "export class RuleScope {\n  /** restricts scope of changes to a specific resource type or resource identifier */\n  public static fromResource(resourceType: ResourceType, resourceId?: string) {\n    return new RuleScope(resourceId, [resourceType]);\n  }\n  /** restricts scope of changes to specific resource types */\n  public static fromResources(resourceTypes: ResourceType[]) {\n    return new RuleScope(undefined, resourceTypes);\n  }\n  /** restricts scope of changes to a specific tag */\n  public static fromTag(key: string, value?: string) {\n    return new RuleScope(undefined, undefined, key, value);\n  }\n\n  /** Resource types that will trigger evaluation of a rule */\n  public readonly resourceTypes?: ResourceType[];\n\n  /** ID of the only AWS resource that will trigger evaluation of a rule */\n  public readonly resourceId?: string;\n\n  /** tag key applied to resources that will trigger evaluation of a rule  */\n  public readonly key?: string;\n\n  /** tag value applied to resources that will trigger evaluation of a rule */\n  public readonly value?: string;\n\n  private constructor(resourceId?: string, resourceTypes?: ResourceType[], tagKey?: string, tagValue?: string) {\n    this.resourceTypes = resourceTypes;\n    this.resourceId = resourceId;\n    this.key = tagKey;\n    this.value = tagValue;\n  }\n}", "language": "typescript"}
{"input": "JSII .NET namespace is required and must look sane", "output": "export class JSIIDotNetNamespaceIsRequired extends ValidationRule {\n  public readonly name = 'jsii/dotnet';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return; }\n\n    const dotnet = deepGet(pkg.json, ['jsii', 'targets', 'dotnet', 'namespace']) as string | undefined;\n    const moduleName = cdkModuleName(pkg.json.name);\n    expectJSON(this.name, pkg, 'jsii.targets.dotnet.namespace', moduleName.dotnetNamespace, /\\./g, /* case insensitive*/ true);\n\n    if (dotnet) {\n      const actualPrefix = dotnet.split('.').slice(0, 2).join('.');\n      const expectedPrefix = moduleName.dotnetNamespace.split('.').slice(0, 2).join('.');\n      if (actualPrefix !== expectedPrefix) {\n        pkg.report({\n          ruleName: this.name,\n          message: `.NET namespace must share the first two segments of the default namespace, '${expectedPrefix}' vs '${actualPrefix}'`,\n          fix: () => deepSet(pkg.json, ['jsii', 'targets', 'dotnet', 'namespace'], moduleName.dotnetNamespace),\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "All consumed versions of dependencies must be the same NOTE: this rule will only be useful when validating multiple package.jsons at the same time", "output": "export class AllVersionsTheSame extends ValidationRule {\n  public readonly name = 'dependencies/versions-consistent';\n\n  private readonly ourPackages: {[pkg: string]: string} = {};\n  private readonly usedDeps: {[pkg: string]: VersionCount[]} = {};\n\n  public prepare(pkg: PackageJson): void {\n    this.ourPackages[pkg.json.name] = pkg.json.version;\n    this.recordDeps(pkg.json.dependencies);\n    this.recordDeps(pkg.json.devDependencies);\n  }\n\n  public validate(pkg: PackageJson): void {\n    this.validateDeps(pkg, 'dependencies');\n    this.validateDeps(pkg, 'devDependencies');\n  }\n\n  private recordDeps(deps: {[pkg: string]: string} | undefined) {\n    if (!deps) { return; }\n\n    Object.keys(deps).forEach(dep => {\n      this.recordDep(dep, deps[dep]);\n    });\n  }\n\n  private validateDeps(pkg: PackageJson, section: string) {\n    if (!pkg.json[section]) { return; }\n\n    Object.keys(pkg.json[section]).forEach(dep => {\n      this.validateDep(pkg, section, dep);\n    });\n  }\n\n  private recordDep(dep: string, version: string) {\n    if (version === '*') {\n      // '*' does not give us info, so skip\n      return;\n    }\n\n    if (!(dep in this.usedDeps)) {\n      this.usedDeps[dep] = [];\n    }\n\n    const i = this.usedDeps[dep].findIndex(vc => vc.version === version);\n    if (i === -1) {\n      this.usedDeps[dep].push({ version, count: 1 });\n    } else {\n      this.usedDeps[dep][i].count += 1;\n    }\n  }\n\n  private validateDep(pkg: PackageJson, depField: string, dep: string) {\n    if (dep in this.ourPackages) {\n      expectJSON(this.name, pkg, [depField, dep], this.ourPackages[dep]);\n      return;\n    }\n\n    // Otherwise, must match the majority version declaration. Might be empty if we only\n    // have '*', in which case that's fine.\n    if (!(dep in this.usedDeps)) { return; }\n\n    const versions = this.usedDeps[dep];\n    versions.sort((a, b) => b.count - a.count);\n    expectJSON(this.name, pkg, [depField, dep], versions[0].version);\n  }\n}\n\nexport class AwsLint extends ValidationRule {\n  public readonly name = 'awslint';\n\n  public validate(pkg: PackageJson) {\n    if (!isJSII(pkg)) {\n      return;\n    }\n\n    if (!isAWS(pkg)) {\n      return;\n    }\n\n    expectJSON(this.name, pkg, 'scripts.awslint', 'cdk-awslint');\n  }\n}\n\n/**\n * Packages inside JSII packages (typically used for embedding Lambda handles)\n * must only have dev dependencies and their node_modules must not be published.\n *\n * We might loosen this at some point but we'll have to bundle all runtime dependencies\n * and we don't have good transitive license checks.\n */\nexport class PackageInJsiiPackageNoRuntimeDeps extends ValidationRule {\n  public readonly name = 'lambda-packages-no-runtime-deps';\n\n  public validate(pkg: PackageJson) {\n    if (!isJSII(pkg) || pkg.packageName === '@aws-cdk/cli-lib-alpha') { return; }\n\n    for (const inner of findInnerPackages(pkg.packageRoot)) {\n      const innerPkg = PackageJson.fromDirectory(inner);\n\n      if (Object.keys(innerPkg.dependencies).length > 0) {\n        pkg.report({\n          ruleName: `${this.name}:1`,\n          message: `NPM Package '${innerPkg.packageName}' inside jsii package '${pkg.packageName}', can only have devDependencies`,\n        });\n      }\n\n      const nodeModulesRelPath = path.relative(pkg.packageRoot, innerPkg.packageRoot) + '/node_modules';\n      fileShouldContain(`${this.name}:2`, pkg, '.npmignore', nodeModulesRelPath);\n    }\n  }\n}\n\n/**\n * Requires packages to have fast-fail build scripts, allowing to combine build, test and package/extract in a single command.\n * This involves multiple targets: `build+test`, `build+extract`, `build+test+extract`, and `build+test+package`\n */\nexport class FastFailingBuildScripts extends ValidationRule {\n  public readonly name = 'fast-failing-build-scripts';\n\n  public validate(pkg: PackageJson) {\n    const scripts = pkg.json.scripts || {};\n\n    const hasTest = 'test' in scripts;\n    const hasPack = 'package' in scripts;\n    const hasExtract = 'rosetta:extract' in scripts;\n\n    const cmdBuild = 'yarn build';\n    expectJSON(this.name, pkg, 'scripts.build+test', hasTest ? [cmdBuild, 'yarn test'].join(' && ') : cmdBuild);\n    expectJSON(this.name, pkg, 'scripts.build+extract', hasExtract ? [cmdBuild, 'yarn rosetta:extract'].join(' && ') : cmdBuild);\n\n    const cmdBuildTest = 'yarn build+test';\n    expectJSON(this.name, pkg, 'scripts.build+test+package', hasPack ? [cmdBuildTest, 'yarn package'].join(' && ') : cmdBuildTest);\n    expectJSON(this.name, pkg, 'scripts.build+test+extract', hasExtract ? [cmdBuildTest, 'yarn rosetta:extract'].join(' && ') : cmdBuildTest);\n  }\n}\n\nexport class YarnNohoistBundledDependencies extends ValidationRule {\n  public readonly name = 'yarn/nohoist-bundled-dependencies';\n\n  public validate(pkg: PackageJson) {\n    const bundled: string[] = pkg.json.bundleDependencies || pkg.json.bundledDependencies || [];\n    if (bundled.length === 0) { return; }\n\n    const repoPackageJson = path.resolve(monoRepoRoot(), 'package.json');\n\n    const nohoist: string[] = require(repoPackageJson).workspaces.nohoist; // eslint-disable-line @typescript-eslint/no-require-imports\n\n    const missing = new Array<string>();\n    for (const dep of bundled) {\n      for (const entry of [`${pkg.packageName}/${dep}`, `${pkg.packageName}/${dep}/**`]) {\n        if (nohoist.indexOf(entry) >= 0) { continue; }\n        missing.push(entry);\n      }\n    }\n\n    if (missing.length > 0) {\n      pkg.report({\n        ruleName: this.name,\n        message: `Repository-level 'workspaces.nohoist' directive is missing: ${missing.join(', ')}`,\n        fix: () => {\n          const packageJson = require(repoPackageJson); // eslint-disable-line @typescript-eslint/no-require-imports\n          packageJson.workspaces.nohoist = [...packageJson.workspaces.nohoist, ...missing].sort();\n          fs.writeFileSync(repoPackageJson, `${JSON.stringify(packageJson, null, 2)}\\n`, { encoding: 'utf8' });\n        },\n      });\n    }\n  }\n}\n\nexport class ConstructsDependency extends ValidationRule {\n  public readonly name = 'constructs/dependency';\n\n  public validate(pkg: PackageJson) {\n    const REQUIRED_VERSION = ConstructsVersion.VERSION;\n\n    // require a \"constructs\" dependency if there's a @aws-cdk/core dependency\n    const requiredDev = pkg.getDevDependency('@aws-cdk/core') && !pkg.getDevDependency('constructs');\n    if (requiredDev || (pkg.devDependencies?.constructs && pkg.devDependencies?.constructs !== REQUIRED_VERSION)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION}`,\n        fix: () => {\n          pkg.addDevDependency('constructs', REQUIRED_VERSION);\n        },\n      });\n    }\n\n    const requiredDep = pkg.dependencies?.['@aws-cdk/core'] && !pkg.dependencies?.constructs;\n    if (requiredDep || (pkg.dependencies.constructs && pkg.dependencies.constructs !== REQUIRED_VERSION)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION}`,\n        fix: () => {\n          pkg.addDependency('constructs', REQUIRED_VERSION);\n        },\n      });\n\n      if (!pkg.peerDependencies.constructs || pkg.peerDependencies.constructs !== REQUIRED_VERSION) {\n        pkg.report({\n          ruleName: this.name,\n          message: `\"constructs\" must have a version requirement ${REQUIRED_VERSION} in peerDependencies`,\n          fix: () => {\n            pkg.addPeerDependency('constructs', REQUIRED_VERSION);\n          },\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class Pipeline for AWS resource management", "output": "class Pipeline(Stack):\n    def __init__(self, app: App, id: str, props, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n        # define the s3 artifact\n        source_output = aws_codepipeline.Artifact(artifact_name='source')\n        # define the pipeline\n        pipeline = aws_codepipeline.Pipeline(\n            self, \"Pipeline\",\n            pipeline_name=f\"{props['namespace']}\",\n            artifact_bucket=props['bucket'],\n            stages=[\n                aws_codepipeline.StageProps(\n                    stage_name='Source',\n                    actions=[\n                        aws_codepipeline_actions.S3SourceAction(\n                            bucket=props['bucket'],\n                            bucket_key='source.zip',\n                            action_name='S3Source',\n                            run_order=1,\n                            output=source_output,\n                            trigger=aws_codepipeline_actions.S3Trigger.POLL\n                        ),\n                    ]\n                ),\n                aws_codepipeline.StageProps(\n                    stage_name='Build',\n                    actions=[\n                        aws_codepipeline_actions.CodeBuildAction(\n                            action_name='DockerBuildImages',\n                            input=source_output,\n                            project=props['cb_docker_build'],\n                            run_order=1,\n                        )\n                    ]\n                )\n            ]\n\n        )\n        # give pipelinerole read write to the bucket\n        props['bucket'].grant_read_write(pipeline.role)\n\n        #pipeline param to get the\n        pipeline_param = aws_ssm.StringParameter(\n            self, \"PipelineParam\",\n            parameter_name=f\"{props['namespace']}-pipeline\",\n            string_value=pipeline.pipeline_name,\n            description='cdk pipeline bucket'\n        )\n        # cfn output\n        CfnOutput(\n            self, \"PipelineOut\",\n            description=\"Pipeline\",\n            value=pipeline.pipeline_name\n        )", "language": "python"}
{"input": "CDK Stack that creates SSM Parameter Store, CloudFormation, Route 53 resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const hostedZone = new route53.PublicHostedZone(this, 'HostedZone', {\n      zoneName: 'cdk.dev',\n    });\n\n    const weightParameterProps = {\n      type: 'Number',\n      default: 0,\n      minValue: 0,\n      maxValue: 255,\n    };\n\n    [\n      { target: '1.2.3.4', weight: new CfnParameter(this, 'RecordWeight0', weightParameterProps) },\n      { target: '2.3.4.5', weight: new CfnParameter(this, 'RecordWeight1', weightParameterProps) },\n      { target: '3.4.5.6', weight: new CfnParameter(this, 'RecordWeight2', weightParameterProps) },\n      { target: '4.5.6.7', weight: new CfnParameter(this, 'RecordWeight3', weightParameterProps) },\n    ].forEach((data, index) => {\n      new route53.ARecord(this, `RecordWithParamWeight${index}`, {\n        zone: hostedZone,\n        recordName: 'www',\n        weight: data.weight.valueAsNumber,\n        ttl: Duration.seconds(10),\n        target: route53.RecordTarget.fromIpAddresses(data.target),\n      });\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, EC2, VPC, CloudFormation resources", "output": "class TestStack extends Stack {\n  public readonly lb: elbv2.IApplicationLoadBalancer;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const vpc = new ec2.Vpc(this, 'Stack', { maxAzs: 2, natGateways: 1, restrictDefaultSecurityGroup: false });\n\n    this.lb = new elbv2.ApplicationLoadBalancer(this, 'LB', { vpc, internetFacing: true });\n    const listener = this.lb.addListener('Listener', { port: 80 });\n\n    const fn = new lambda.Function(this, 'Fun', {\n      code: lambda.Code.fromInline(`\nimport json\ndef handler(event, context):\n  return {\n    \"isBase64Encoded\": False,\n    \"statusCode\": 200,\n    \"statusDescription\": \"200 OK\",\n    \"headers\": {\n        \"Set-cookie\": \"cookies\",\n        \"Content-Type\": \"application/json\"\n    },\n    \"body\": json.dumps({ \"message\": \"Hello from Lambda\" })\n  }\n      `),\n      runtime: lambda.Runtime.PYTHON_3_9,\n      handler: 'index.handler',\n    });\n\n    listener.addTargets('Targets', {\n      targets: [new targets.LambdaTarget(fn)],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class PkgLintAsScript for AWS resource management", "output": "export class PkgLintAsScript extends ValidationRule {\n  public readonly name = 'package-info/scripts/pkglint';\n\n  public validate(pkg: PackageJson): void {\n    const script = 'pkglint -f';\n\n    expectDevDependency(this.name, pkg, '@aws-cdk/pkglint', `${PKGLINT_VERSION}`);\n\n    if (!pkg.npmScript('pkglint')) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'a script called \"pkglint\" must be included to allow fixing package linting issues',\n        fix: () => pkg.changeNpmScript('pkglint', () => script),\n      });\n    }\n\n    if (pkg.npmScript('pkglint') !== script) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'the pkglint script should be: ' + script,\n        fix: () => pkg.changeNpmScript('pkglint', () => script),\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class EventBus for AWS resource management", "output": "export class EventBus extends EventBusBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-events.EventBus';\n\n  /**\n   * Import an existing event bus resource\n   * @param scope Parent construct\n   * @param id Construct ID\n   * @param eventBusArn ARN of imported event bus\n   */\n  public static fromEventBusArn(scope: Construct, id: string, eventBusArn: string): IEventBus {\n    const parts = Stack.of(scope).splitArn(eventBusArn, ArnFormat.SLASH_RESOURCE_NAME);\n\n    return new ImportedEventBus(scope, id, {\n      eventBusArn: eventBusArn,\n      eventBusName: parts.resourceName || '',\n      eventBusPolicy: '',\n    });\n  }\n\n  /**\n   * Import an existing event bus resource\n   * @param scope Parent construct\n   * @param id Construct ID\n   * @param eventBusName Name of imported event bus\n   */\n  public static fromEventBusName(scope: Construct, id: string, eventBusName: string): IEventBus {\n    const eventBusArn = Stack.of(scope).formatArn({\n      resource: 'event-bus',\n      service: 'events',\n      resourceName: eventBusName,\n    });\n\n    return EventBus.fromEventBusAttributes(scope, id, {\n      eventBusName: eventBusName,\n      eventBusArn: eventBusArn,\n      eventBusPolicy: '',\n    });\n  }\n\n  /**\n   * Import an existing event bus resource\n   * @param scope Parent construct\n   * @param id Construct ID\n   * @param attrs Imported event bus properties\n   */\n  public static fromEventBusAttributes(scope: Construct, id: string, attrs: EventBusAttributes): IEventBus {\n    return new ImportedEventBus(scope, id, attrs);\n  }\n\n  /**\n   * Permits an IAM Principal to send custom events to EventBridge\n   * so that they can be matched to rules.\n   *\n   * @param grantee The principal (no-op if undefined)\n   * @deprecated use grantAllPutEvents instead\n   */\n  public static grantPutEvents(grantee: iam.IGrantable): iam.Grant {\n    // It's currently not possible to restrict PutEvents to specific resources.\n    // See https://docs.aws.amazon.com/eventbridge/latest/userguide/permissions-reference-eventbridge.html\n    return iam.Grant.addToPrincipal({\n      grantee,\n      actions: ['events:PutEvents'],\n      resourceArns: ['*'],\n    });\n  }\n\n  /**\n   * Permits an IAM Principal to send custom events to EventBridge\n   * so that they can be matched to rules.\n   *\n   * @param grantee The principal (no-op if undefined)\n   */\n  public static grantAllPutEvents(grantee: iam.IGrantable): iam.Grant {\n    // FIXME Doing this hack because this method is static, and we don't have an actual instance of\n    //  IEventBusRef to use here for the grants.\n    const eventBus = EventBus.fromEventBusName(new Stack(), 'dummy', 'dummy');\n    return EventBusGrants.fromEventBus(eventBus).allPutEvents(grantee);\n  }\n\n  private static eventBusProps(defaultEventBusName: string, props: EventBusProps = {}) {\n    const { eventBusName, eventSourceName } = props;\n    const eventBusNameRegex = /^[\\/\\.\\-_A-Za-z0-9]{1,256}$/;\n\n    if (eventBusName !== undefined && eventSourceName !== undefined) {\n      throw new UnscopedValidationError(\n        '\\'eventBusName\\' and \\'eventSourceName\\' cannot both be provided',\n      );\n    }\n\n    if (eventBusName !== undefined) {\n      if (!Token.isUnresolved(eventBusName)) {\n        if (eventBusName === 'default') {\n          throw new UnscopedValidationError(\n            '\\'eventBusName\\' must not be \\'default\\'',\n          );\n        } else if (eventBusName.indexOf('/') > -1) {\n          throw new UnscopedValidationError(\n            '\\'eventBusName\\' must not contain \\'/\\'',\n          );\n        } else if (!eventBusNameRegex.test(eventBusName)) {\n          throw new UnscopedValidationError(\n            `'eventBusName' must satisfy: ${eventBusNameRegex}`,\n          );\n        }\n      }\n      return { eventBusName };\n    }\n\n    if (eventSourceName !== undefined) {\n      if (!Token.isUnresolved(eventSourceName)) {\n        // Ex: aws.partner/PartnerName/acct1/repo1\n        const eventSourceNameRegex = /^aws\\.partner(\\/[\\.\\-_A-Za-z0-9]+){2,}$/;\n        if (!eventSourceNameRegex.test(eventSourceName)) {\n          throw new UnscopedValidationError(\n            `'eventSourceName' must satisfy: ${eventSourceNameRegex}`,\n          );\n        } else if (!eventBusNameRegex.test(eventSourceName)) {\n          throw new UnscopedValidationError(\n            `'eventSourceName' must satisfy: ${eventBusNameRegex}`,\n          );\n        }\n      }\n      return { eventBusName: eventSourceName, eventSourceName };\n    }\n\n    return { eventBusName: defaultEventBusName };\n  }\n\n  /**\n   * The physical ID of this event bus resource\n   */\n  public readonly eventBusName: string;\n\n  /**\n   * The ARN of the event bus, such as:\n   * arn:aws:events:us-east-2:123456789012:event-bus/aws.partner/PartnerName/acct1/repo1.\n   */\n  public readonly eventBusArn: string;\n\n  /**\n   * The policy for the event bus in JSON form.\n   */\n  public readonly eventBusPolicy: string;\n\n  /**\n   * The name of the partner event source\n   */\n  public readonly eventSourceName?: string;\n\n  constructor(scope: Construct, id: string, props?: EventBusProps) {\n    const { eventBusName, eventSourceName } = EventBus.eventBusProps(\n      Lazy.string({ produce: () => Names.uniqueId(this) }),\n      props,\n    );\n\n    super(scope, id, { physicalName: eventBusName });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props?.description && !Token.isUnresolved(props.description) && props.description.length > 512) {\n      throw new ValidationError(`description must be less than or equal to 512 characters, got ${props.description.length}`, this);\n    }\n\n    const eventBus = new CfnEventBus(this, 'Resource', {\n      name: this.physicalName,\n      eventSourceName,\n      deadLetterConfig: props?.deadLetterQueue ? {\n        arn: props.deadLetterQueue.queueArn,\n      } : undefined,\n      description: props?.description,\n      kmsKeyIdentifier: props?.kmsKey?.keyArn,\n      logConfig: props?.logConfig,\n    });\n\n    this.eventBusArn = this.getResourceArnAttribute(eventBus.attrArn, {\n      service: 'events',\n      resource: 'event-bus',\n      resourceName: eventBus.name,\n    });\n\n    /**\n     * Allow EventBridge to use customer managed key\n     *\n     * @see https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-encryption-key-policy.html#eb-encryption-key-policy-bus\n     */\n    if (props?.kmsKey) {\n      props?.kmsKey.addToResourcePolicy(new iam.PolicyStatement({\n        resources: ['*'],\n        actions: ['kms:Decrypt', 'kms:GenerateDataKey', 'kms:DescribeKey'],\n        principals: [new iam.ServicePrincipal('events.amazonaws.com')],\n        conditions: {\n          StringEquals: {\n            'aws:SourceAccount': this.stack.account,\n            'aws:SourceArn': Stack.of(this).formatArn({\n              service: 'events',\n              resource: 'event-bus',\n              resourceName: eventBusName,\n            }),\n            'kms:EncryptionContext:aws:events:event-bus:arn': Stack.of(this).formatArn({\n              service: 'events',\n              resource: 'event-bus',\n              resourceName: eventBusName,\n            }),\n          },\n        },\n      }));\n    }\n\n    this.eventBusName = this.getResourceNameAttribute(eventBus.ref);\n    this.eventBusPolicy = eventBus.attrPolicy;\n    this.eventSourceName = eventBus.eventSourceName;\n  }\n\n  /**\n   * Adds a statement to the IAM resource policy associated with this event bus.\n   */\n  @MethodMetadata()\n  public addToResourcePolicy(statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n    // If no sid is provided, generate one based on the event bus id\n    if (statement.sid == null) {\n      throw new ValidationError('Event Bus policy statements must have a sid', this);\n    }\n\n    // In order to generate new statementIDs for the change in https://github.com/aws/aws-cdk/pull/27340\n    const statementId = `cdk-${statement.sid}`.slice(0, 64);\n    statement.sid = statementId;\n    const policy = new EventBusPolicy(this, statementId, {\n      eventBus: this,\n      statement: statement.toJSON(),\n      statementId,\n    });\n\n    return { statementAdded: true, policyDependable: policy };\n  }\n}", "language": "typescript"}
{"input": "Represents the function's source code loaded from an external file", "output": "class FileCode extends FunctionCode {\n  constructor(private options: FileCodeOptions) {\n    super();\n  }\n\n  public render(): string {\n    return fs.readFileSync(this.options.filePath, { encoding: 'utf-8' });\n  }\n}", "language": "typescript"}
{"input": "The duration of the timer.", "output": "class TimerDuration {\n  /**\n   * Create a timer-duration from Duration.\n   *\n   * The range of the duration is 60-31622400 seconds.\n   * The evaluated result of the duration expression is rounded down to the nearest whole number.\n   * For example, if you set the timer to 60.99 seconds, the evaluated result of the duration expression is 60 seconds.\n   */\n  public static fromDuration(duration: Duration): TimerDuration {\n    const seconds = duration.toSeconds();\n    if (seconds < 60) {\n      throw new Error(`duration cannot be less than 60 seconds, got: ${duration.toString()}`);\n    }\n    if (seconds > 31622400) {\n      throw new Error(`duration cannot be greater than 31622400 seconds, got: ${duration.toString()}`);\n    }\n    return new TimerDurationImpl(seconds.toString());\n  }\n\n  /**\n   * Create a timer-duration from Expression.\n   *\n   * You can use a string expression that includes numbers, variables ($variable.<variable-name>),\n   * and input values ($input.<input-name>.<path-to-datum>) as the duration.\n   *\n   * The range of the duration is 60-31622400 seconds.\n   * The evaluated result of the duration expression is rounded down to the nearest whole number.\n   * For example, if you set the timer to 60.99 seconds, the evaluated result of the duration expression is 60 seconds.\n   */\n  public static fromExpression(expression: iotevents.Expression): TimerDuration {\n    return new TimerDurationImpl(expression.evaluate());\n  }\n\n  /**\n   * @internal\n   */\n  public abstract _bind(): string;\n}", "language": "typescript"}
{"input": "CDK class ProductWithAnAsset for AWS resource management", "output": "class ProductWithAnAsset extends servicecatalog.ProductStack {\n  constructor(scope: Construct, id: string, props: servicecatalog.ProductStackProps & { description?: string }) {\n    super(scope, id, props);\n\n    new lambda.Function(this, 'HelloHandler', {\n      runtime: lambda.Runtime.PYTHON_3_9,\n      description: props.description,\n      code: lambda.Code.fromAsset(path.join(__dirname, 'assets')),\n      handler: 'index.handler',\n    });\n  }\n}", "language": "typescript"}
{"input": "Object respresenting an Aspect application. Stores the Aspect, the pointer to the construct it was applied to, and the priority value of that Aspect.", "output": "export class AspectApplication {\n  /**\n   * The construct that the Aspect was applied to.\n   */\n  public readonly construct: IConstruct;\n\n  /**\n   * The Aspect that was applied.\n   */\n  public readonly aspect: IAspect;\n\n  /**\n   * The priority value of this Aspect. Must be non-negative integer.\n   */\n  private _priority: number;\n\n  /**\n   * Initializes AspectApplication object\n   */\n  public constructor(construct: IConstruct, aspect: IAspect, priority: number) {\n    this.construct = construct;\n    this.aspect = aspect;\n    this._priority = priority;\n  }\n\n  /**\n   * Gets the priority value.\n   */\n  public get priority(): number {\n    return this._priority;\n  }\n\n  /**\n   * Sets the priority value.\n   */\n  public set priority(priority: number) {\n    if (priority < 0) {\n      throw new ValidationError('Priority must be a non-negative number', this.construct);\n    }\n    this._priority = priority;\n\n    // This invalidates any cached ordering.\n    bumpAspectTreeRevision(this.construct);\n  }\n}", "language": "typescript"}
{"input": "Factory class for creating Gateway Authorizers", "output": "class GatewayAuthorizer {\n  /**\n   * AWS IAM authorizer instance\n   */\n  public static usingAwsIam(): IGatewayAuthorizerConfig {\n    return new IamAuthorizer();\n  }\n\n  /**\n   * Create a custom JWT authorizer\n   * @param configuration - The JWT configuration\n   * @returns IGatewayAuthorizerConfig configured for custom JWT\n   */\n  public static usingCustomJwt(configuration: CustomJwtConfiguration): IGatewayAuthorizerConfig {\n    // At least one of allowedAudience or allowedClients must be defined for CUSTOM_JWT authorizer\n    if (!configuration.allowedAudience && !configuration.allowedClients) {\n      throw new ValidationError('At least one of allowedAudience or allowedClients must be defined for CUSTOM_JWT authorizer');\n    }\n    return new CustomJwtAuthorizer(configuration);\n  }\n\n  /**\n   * Create a JWT authorizer from Cognito User Pool\n   * @param props - The Cognito configuration\n   * @returns CustomJwtAuthorizer configured for Cognito\n   */\n  public static usingCognito(props: CognitoAuthorizerProps): IGatewayAuthorizerConfig {\n    const discoveryUrl = `https://cognito-idp.${props.userPool.env.region}.amazonaws.com/${props.userPool.userPoolId}/.well-known/openid-configuration`;\n\n    return new CustomJwtAuthorizer({\n      discoveryUrl: discoveryUrl,\n      allowedClients: props.allowedClients?.flatMap((client) => client.userPoolClientId),\n      allowedAudience: props.allowedAudiences,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class VirtualNode for AWS resource management", "output": "export class VirtualNode extends VirtualNodeBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appmesh.VirtualNode';\n\n  /**\n   * Import an existing VirtualNode given an ARN\n   */\n  public static fromVirtualNodeArn(scope: Construct, id: string, virtualNodeArn: string): IVirtualNode {\n    return new class extends VirtualNodeBase {\n      readonly virtualNodeArn = virtualNodeArn;\n      private readonly parsedArn = cdk.Fn.split('/', cdk.Stack.of(scope).splitArn(virtualNodeArn, cdk.ArnFormat.SLASH_RESOURCE_NAME).resourceName!);\n      readonly mesh = Mesh.fromMeshName(this, 'Mesh', cdk.Fn.select(0, this.parsedArn));\n      readonly virtualNodeName = cdk.Fn.select(2, this.parsedArn);\n    }(scope, id);\n  }\n\n  /**\n   * Import an existing VirtualNode given its name\n   */\n  public static fromVirtualNodeAttributes(scope: Construct, id: string, attrs: VirtualNodeAttributes): IVirtualNode {\n    return new class extends VirtualNodeBase {\n      readonly mesh = attrs.mesh;\n      readonly virtualNodeName = attrs.virtualNodeName;\n      readonly virtualNodeArn = cdk.Stack.of(this).formatArn({\n        service: 'appmesh',\n        resource: `mesh/${attrs.mesh.meshName}/virtualNode`,\n        resourceName: this.virtualNodeName,\n      });\n    }(scope, id);\n  }\n\n  /**\n   * The name of the VirtualNode\n   */\n  public readonly virtualNodeName: string;\n\n  /**\n   * The Amazon Resource Name belonging to the VirtualNode\n   */\n  public readonly virtualNodeArn: string;\n\n  /**\n   * The Mesh which the VirtualNode belongs to\n   */\n  public readonly mesh: IMesh;\n\n  private readonly serviceDiscoveryConfig?: ServiceDiscoveryConfig;\n\n  private readonly backends = new Array<CfnVirtualNode.BackendProperty>();\n  private readonly listeners = new Array<VirtualNodeListenerConfig>();\n\n  constructor(scope: Construct, id: string, props: VirtualNodeProps) {\n    super(scope, id, {\n      physicalName: props.virtualNodeName || cdk.Lazy.string({ produce: () => cdk.Names.uniqueId(this) }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.mesh = props.mesh;\n    this.serviceDiscoveryConfig = props.serviceDiscovery?.bind(this);\n\n    props.backends?.forEach(backend => this.addBackend(backend));\n    props.listeners?.forEach(listener => this.addListener(listener));\n    const accessLogging = props.accessLog?.bind(this);\n\n    const node = new CfnVirtualNode(this, 'Resource', {\n      virtualNodeName: this.physicalName,\n      meshName: this.mesh.meshName,\n      meshOwner: renderMeshOwner(this.env.account, this.mesh.env.account),\n      spec: {\n        backends: cdk.Lazy.any({ produce: () => this.backends }, { omitEmptyArray: true }),\n        listeners: cdk.Lazy.any({ produce: () => this.listeners.map(listener => listener.listener) }, { omitEmptyArray: true }),\n        backendDefaults: props.backendDefaults !== undefined\n          ? {\n            clientPolicy: {\n              tls: renderTlsClientPolicy(this, props.backendDefaults?.tlsClientPolicy),\n            },\n          }\n          : undefined,\n        serviceDiscovery: renderServiceDiscovery(this.serviceDiscoveryConfig),\n        logging: accessLogging !== undefined ? {\n          accessLog: accessLogging.virtualNodeAccessLog,\n        } : undefined,\n      },\n    });\n\n    this.virtualNodeName = this.getResourceNameAttribute(node.attrVirtualNodeName);\n    this.virtualNodeArn = this.getResourceArnAttribute(node.ref, {\n      service: 'appmesh',\n      resource: `mesh/${props.mesh.meshName}/virtualNode`,\n      resourceName: this.physicalName,\n    });\n  }\n\n  /**\n   * Utility method to add an inbound listener for this VirtualNode\n   *\n   * Note: At this time, Virtual Nodes support at most one listener. Adding\n   * more than one will result in a failure to deploy the CloudFormation stack.\n   * However, the App Mesh team has plans to add support for multiple listeners\n   * on Virtual Nodes and Virtual Routers.\n   *\n   * @see https://github.com/aws/aws-app-mesh-roadmap/issues/120\n   */\n  @MethodMetadata()\n  public addListener(listener: VirtualNodeListener) {\n    if (!this.serviceDiscoveryConfig) {\n      throw new cdk.ValidationError('Service discovery information is required for a VirtualNode with a listener.', this);\n    }\n    this.listeners.push(listener.bind(this));\n  }\n\n  /**\n   * Add a Virtual Services that this node is expected to send outbound traffic to\n   */\n  @MethodMetadata()\n  public addBackend(backend: Backend) {\n    this.backends.push(backend.bind(this).virtualServiceBackend);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, IAM, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    new iam.Role(this, 'RoleWithCompositePrincipal', {\n      assumedBy: new iam.CompositePrincipal(\n        new iam.ServicePrincipal('ec2.amazonaws.com'),\n        new iam.AnyPrincipal(),\n      ),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, KMS, CloudFormation resources", "output": "export class LambdaPCScalingScheduleStack extends Stack {\n  private lambdaFunction: Function\n  private lambdaFunctionName: string\n\n  constructor(scope: Construct, id: string, props: LambdaPCScalingScheduleStackProps) {\n    super(scope, id, props);\n    this.lambdaFunctionName = props.functionName\n\n    // Create Sample Lambda Function which will create metrics\n    this.lambdaFunction = new NodejsFunction(this, 'LambdaFunction', {\n      functionName: this.lambdaFunctionName,\n      entry: `./lambda/lambda-handler.ts`,\n      runtime: Runtime.NODEJS_18_X,\n      memorySize: 512,\n      timeout: Duration.seconds(6),\n    });\n    // Enable Provisioned Concurrency\n    new Alias(this, `LambdaFunctionAlias`, {\n      aliasName: 'provisioned',\n      version: this.lambdaFunction.currentVersion,\n      provisionedConcurrentExecutions: 1,\n    });\n    // Enable AutoScaling Scalable Schedule\n    const asg = new ScalableTarget(this, `${this.lambdaFunctionName}ScalableSchedule`, {\n      serviceNamespace: ServiceNamespace.LAMBDA,\n      maxCapacity: 1,\n      minCapacity: 0,\n      resourceId: `function:${this.lambdaFunctionName}:provisioned`,\n      scalableDimension: 'lambda:function:ProvisionedConcurrency',\n    })\n    // Scaling out every weekday (Monday through Friday) at 11:00 AM(UTC+0),\n    asg.scaleOnSchedule(`${this.lambdaFunctionName}ScheduleScaleOut`, {\n      schedule: Schedule.expression('cron(0 11 ? * MON-FRI *))'), \n      minCapacity: 1,\n      maxCapacity: 1\n    })\n    // Scaling in every weekday (Monday through Friday) at 12:00 AM(UTC+0),\n    asg.scaleOnSchedule(`${this.lambdaFunctionName}ScheduleScaleIn`, {\n      schedule: Schedule.expression('cron(0 12 ? * MON-FRI *))'),  \n      minCapacity: 0,\n      maxCapacity: 0\n    })\n  };\n}", "language": "typescript"}
{"input": "Type union for a record that accepts multiple types of target.", "output": "export class RecordTarget {\n  /**\n   * Use string values as target.\n   */\n  public static fromValues(...values: string[]) {\n    return new RecordTarget(values);\n  }\n\n  /**\n   * Use an alias as target.\n   */\n  public static fromAlias(aliasTarget: IAliasRecordTarget) {\n    return new RecordTarget(undefined, aliasTarget);\n  }\n\n  /**\n   * Use ip addresses as target.\n   */\n  public static fromIpAddresses(...ipAddresses: string[]) {\n    return RecordTarget.fromValues(...ipAddresses);\n  }\n\n  /**\n   *\n   * @param values correspond with the chosen record type (e.g. for 'A' Type, specify one or more IP addresses)\n   * @param aliasTarget alias for targets such as CloudFront distribution to route traffic to\n   */\n  protected constructor(public readonly values?: string[], public readonly aliasTarget?: IAliasRecordTarget) {\n  }\n}", "language": "typescript"}
{"input": "The format of the source data.", "output": "class InputFormat {\n  /**\n   * DynamoDB JSON format.\n   */\n  public static dynamoDBJson(): InputFormat {\n    return new class extends InputFormat {\n      public _render(): Pick<CfnTable.ImportSourceSpecificationProperty, 'inputFormat' | 'inputFormatOptions'> {\n        return {\n          inputFormat: 'DYNAMODB_JSON',\n        };\n      }\n    }();\n  }\n\n  /**\n   * Amazon Ion format.\n   */\n  public static ion(): InputFormat {\n    return new class extends InputFormat {\n      public _render(): Pick<CfnTable.ImportSourceSpecificationProperty, 'inputFormat' | 'inputFormatOptions'> {\n        return {\n          inputFormat: 'ION',\n        };\n      }\n    }();\n  }\n\n  /**\n   * CSV format.\n   */\n  public static csv(options?: CsvOptions): InputFormat {\n    // We are using the .length property to check the length of the delimiter.\n    // Note that .length may not return the expected result for multi-codepoint characters like full-width characters or emojis,\n    // but such characters are not expected to be used as delimiters in this context.\n    if (options?.delimiter && (!this.validCsvDelimiters.includes(options.delimiter) || options.delimiter.length !== 1)) {\n      throw new UnscopedValidationError([\n        'Delimiter must be a single character and one of the following:',\n        `${this.readableValidCsvDelimiters.join(', ')},`,\n        `got '${options.delimiter}'`,\n      ].join(' '));\n    }\n\n    return new class extends InputFormat {\n      public _render(): Pick<CfnTable.ImportSourceSpecificationProperty, 'inputFormat' | 'inputFormatOptions'> {\n        return {\n          inputFormat: 'CSV',\n          inputFormatOptions: {\n            csv: {\n              delimiter: options?.delimiter,\n              headerList: options?.headerList,\n            },\n          },\n        };\n      }\n    }();\n  }\n\n  /**\n   * Valid CSV delimiters.\n   *\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-dynamodb-table-csv.html#cfn-dynamodb-table-csv-delimiter\n   */\n  private static validCsvDelimiters = [',', '\\t', ':', ';', '|', ' '];\n\n  private static readableValidCsvDelimiters = ['comma (,)', 'tab (\\\\t)', 'colon (:)', 'semicolon (;)', 'pipe (|)', 'space ( )'];\n\n  /**\n   * Render the input format and options.\n   *\n   * @internal\n   */\n  public abstract _render(): Pick<CfnTable.ImportSourceSpecificationProperty, 'inputFormat' | 'inputFormatOptions'>;\n}", "language": "typescript"}
{"input": "Must use 'cdk-watch' command", "output": "export class MustUseCDKWatch extends ValidationRule {\n  public readonly name = 'package-info/scripts/watch';\n\n  public validate(pkg: PackageJson): void {\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n\n    expectJSON(this.name, pkg, 'scripts.watch', 'cdk-watch');\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderFacebook for AWS resource management", "output": "export class UserPoolIdentityProviderFacebook extends UserPoolIdentityProviderBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderFacebook';\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderFacebookProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const scopes = props.scopes ?? ['public_profile'];\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: 'Facebook', // must be 'Facebook' when the type is 'Facebook'\n      providerType: 'Facebook',\n      providerDetails: {\n        client_id: props.clientId,\n        client_secret: props.clientSecret,\n        authorize_scopes: scopes.join(','),\n        api_version: props.apiVersion,\n      },\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n}", "language": "typescript"}
{"input": "See integ.product.ts for instructions on how to test successful deployments by hand", "output": "class PortfolioStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const portfolio = new servicecatalog.Portfolio(this, 'TestPortfolio', {\n      displayName: 'TestPortfolio',\n      providerName: 'TestProvider',\n      description: 'This is our Service Catalog Portfolio',\n      messageLanguage: servicecatalog.MessageLanguage.EN,\n    });\n\n    const testAssetBucket = new s3.Bucket(this, 'TestAssetBucket', {\n      bucketName: `product-stack-asset-bucket-${this.account}-${this.region}`,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    portfolio.addProduct(new servicecatalog.CloudFormationProduct(this, 'Product1', {\n      productName: 'Prod 1',\n      owner: 'Owner 1',\n      productVersions: [{\n        productVersionName: 'v1',\n        cloudFormationTemplate: servicecatalog.CloudFormationTemplate.fromProductStack(\n          new TestAssetProductStack1(this, 'MyProductStack1', {\n            assetBucket: testAssetBucket,\n            memoryLimit: 256,\n          }),\n        ),\n      }],\n    }));\n\n    portfolio.addProduct(new servicecatalog.CloudFormationProduct(this, 'Product2', {\n      productName: 'Prod 2',\n      owner: 'Owner 2',\n      productVersions: [{\n        productVersionName: 'v1',\n        cloudFormationTemplate: servicecatalog.CloudFormationTemplate.fromProductStack(\n          new TestAssetProductStack2(this, 'MyProductStack2', {\n            assetBucket: testAssetBucket,\n          }),\n        ),\n      }],\n    }));\n\n    new cdk.CfnOutput(this, 'PortfolioId', { value: portfolio.portfolioId });\n  }\n}", "language": "typescript"}
{"input": "Linux-specific implementation of the .NET SDK injector. Handles CoreCLR profiler setup and paths for Linux environments.", "output": "export class DotNetLinuxInjector extends DotNetInjector {\n  protected static readonly DOTNET_LINUX_ENVS: EnvironmentExtension[] = [\n    {\n      name: constants.DotnetInstrumentation.CORECLR_ENABLE_PROFILING,\n      value: constants.DotnetInstrumentation.CORECLR_ENABLE_PROFILING_ENABLED,\n    },\n    {\n      name: constants.DotnetInstrumentation.CORECLR_PROFILER,\n      value: constants.DotnetInstrumentation.CORECLR_PROFILER_OTEL,\n    },\n  ];\n\n  private cpuArch: ecs.CpuArchitecture;\n\n  constructor(\n    sharedVolumeName: string,\n    instrumentationVersion: inst.InstrumentationVersion,\n    cpuArch: ecs.CpuArchitecture,\n    overrideEnvironments?: EnvironmentExtension[]) {\n    super(sharedVolumeName, instrumentationVersion, overrideEnvironments);\n    this.cpuArch = cpuArch;\n  }\n\n  get command(): string[] {\n    return ['cp', '-a', '/autoinstrumentation/.', this.containerPath];\n  }\n\n  protected injectAdditionalEnvironments(envsToInject: { [key: string]: string }, envsFromTaskDef: { [key: string]: string }): void {\n    if (envsFromTaskDef[constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_HOME]) {\n      // If OTEL_DOTNET_AUTO_HOME env var is already set, we will assume that .NET Auto-instrumentation is already configured.\n      return;\n    }\n\n    for (const env of DotNetInjector.DOTNET_COMMON_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n    for (const env of DotNetLinuxInjector.DOTNET_LINUX_ENVS) {\n      envsToInject[env.name] = env.value;\n    }\n\n    envsToInject[constants.DotnetInstrumentation.CORECLR_PROFILER_PATH] = this.getCoreCLRProfilerPath();\n    envsToInject[constants.DotnetInstrumentation.DOTNET_STARTUP_HOOKS] = `${this.containerPath}/net/OpenTelemetry.AutoInstrumentation.StartupHook.dll`;\n    envsToInject[constants.DotnetInstrumentation.DOTNET_ADDITIONAL_DEPS] = `${this.containerPath}/AdditionalDeps`;\n    envsToInject[constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_HOME] = `${this.containerPath}`;\n    envsToInject[constants.DotnetInstrumentation.DOTNET_SHARED_STORE] = `${this.containerPath}/store`;\n  }\n\n  get containerPath(): string {\n    return '/otel-auto-instrumentation-dotnet';\n  }\n\n  protected overrideAdditionalEnvironments(_envsToOverride: { [key: string]: string }, _envsFromTaskDef: { [key: string]: string }): void {\n    // No additional overrides needed for .NET on Linux\n  }\n\n  private getCoreCLRProfilerPath() {\n    const subPath = this.cpuArch == ecs.CpuArchitecture.ARM64 ? 'linux-arm64': 'linux-x64';\n    return `${this.containerPath}/${subPath}/OpenTelemetry.AutoInstrumentation.Native.so`;\n  }\n}", "language": "typescript"}
{"input": "JWT authorizer configuration", "output": "class JwtAuthorizerConfiguration extends RuntimeAuthorizerConfiguration {\n  constructor(\n    private readonly discoveryUrl: string,\n    private readonly allowedClients?: string[],\n    private readonly allowedAudience?: string[],\n  ) {\n    super();\n  }\n\n  public _render(): CfnRuntime.AuthorizerConfigurationProperty {\n    return {\n      customJwtAuthorizer: {\n        discoveryUrl: this.discoveryUrl,\n        allowedClients: this.allowedClients,\n        allowedAudience: this.allowedAudience,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class ProfilingGroup for AWS resource management", "output": "export class ProfilingGroup extends ProfilingGroupBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-codeguruprofiler.ProfilingGroup';\n\n  /**\n   * Import an existing Profiling Group provided a Profiling Group Name.\n   *\n   * @param scope The parent creating construct\n   * @param id The construct's name\n   * @param profilingGroupName Profiling Group Name\n   */\n  public static fromProfilingGroupName(scope: Construct, id: string, profilingGroupName: string): IProfilingGroup {\n    const stack = Stack.of(scope);\n\n    return this.fromProfilingGroupArn(scope, id, stack.formatArn({\n      service: 'codeguru-profiler',\n      resource: 'profilingGroup',\n      resourceName: profilingGroupName,\n    }));\n  }\n\n  /**\n   * Import an existing Profiling Group provided an ARN.\n   *\n   * @param scope The parent creating construct\n   * @param id The construct's name\n   * @param profilingGroupArn Profiling Group ARN\n   */\n  public static fromProfilingGroupArn(scope: Construct, id: string, profilingGroupArn: string): IProfilingGroup {\n    class Import extends ProfilingGroupBase {\n      public readonly profilingGroupName = Stack.of(scope).splitArn(profilingGroupArn, ArnFormat.SLASH_RESOURCE_NAME).resourceName!;\n      public readonly profilingGroupArn = profilingGroupArn;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: profilingGroupArn,\n    });\n  }\n\n  /**\n   * The name of the Profiling Group.\n   *\n   * @attribute\n   */\n  public readonly profilingGroupName: string;\n\n  /**\n   * The ARN of the Profiling Group.\n   *\n   * @attribute\n   */\n  public readonly profilingGroupArn: string;\n\n  constructor(scope: Construct, id: string, props: ProfilingGroupProps = {}) {\n    super(scope, id, {\n      physicalName: props.profilingGroupName ?? Lazy.string({ produce: () => this.generateUniqueId() }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const profilingGroup = new CfnProfilingGroup(this, 'ProfilingGroup', {\n      profilingGroupName: this.physicalName,\n      computePlatform: props.computePlatform,\n    });\n\n    this.profilingGroupName = this.getResourceNameAttribute(profilingGroup.ref);\n\n    this.profilingGroupArn = this.getResourceArnAttribute(profilingGroup.attrArn, {\n      service: 'codeguru-profiler',\n      resource: 'profilingGroup',\n      resourceName: this.physicalName,\n    });\n  }\n\n  private generateUniqueId(): string {\n    const name = Names.uniqueId(this);\n    if (name.length > 240) {\n      return name.substring(0, 120) + name.substring(name.length - 120);\n    }\n    return name;\n  }\n}", "language": "typescript"}
{"input": "CDK class EslintSetup for AWS resource management", "output": "export class EslintSetup extends ValidationRule {\n  public readonly name = 'package-info/eslint';\n\n  public validate(pkg: PackageJson) {\n    const eslintrcFilename = 'eslint.config.mjs';\n    if (!fs.existsSync(eslintrcFilename)) {\n      pkg.report({\n        ruleName: this.name,\n        message: `There must be a ${eslintrcFilename} file at the root of the package`,\n        fix: () => {\n          fs.writeFileSync(\n            eslintrcFilename,\n            [\n              'import { makeConfig } from \\'@aws-cdk/eslint-config\\';',\n              'export default makeConfig(\\'tsconfig.json\\');',\n            ].join('\\n') + '\\n',\n          );\n        },\n      });\n    }\n    fileShouldContain(this.name, pkg, '.gitignore', `!${eslintrcFilename}`);\n    fileShouldContain(this.name, pkg, '.npmignore', eslintrcFilename);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function requestPayload", "output": "const requestPayload = (field: string, { withArgs = false, withSource = false }) => {\n  const _field = `\"field\": \"${field}\"`;\n  const _args = '\"arguments\": $utils.toJson($context.arguments)';\n  const _source = '\"source\": $utils.toJson($context.source)';\n\n  const _payload = [_field];\n  if (withArgs) _payload.push(_args);\n  if (withSource) _payload.push(_source);\n\n  return _payload.reduce((acc, v) => `${acc} ${v},`, '{').slice(0, -1) + '}';\n}", "language": "typescript"}
{"input": "Checks API backwards compatibility against the latest released version.", "output": "export class CompatScript extends ValidationRule {\n  public readonly name = 'package-info/scripts/compat';\n\n  public validate(pkg: PackageJson): void {\n    if (!isJSII(pkg)) { return ; }\n\n    expectJSON(this.name, pkg, 'scripts.compat', 'cdk-compat');\n  }\n}", "language": "typescript"}
{"input": "User-based authentication for a client VPN endpoint", "output": "class ClientVpnUserBasedAuthentication {\n  /**\n   * Active Directory authentication\n   */\n  public static activeDirectory(directoryId: string): ClientVpnUserBasedAuthentication {\n    return new ActiveDirectoryAuthentication(directoryId);\n  }\n\n  /** Federated authentication */\n  public static federated(samlProvider: ISAMLProviderRef, selfServiceSamlProvider?: ISAMLProviderRef): ClientVpnUserBasedAuthentication {\n    return new FederatedAuthentication(samlProvider, selfServiceSamlProvider);\n  }\n\n  /** Renders the user based authentication */\n  public abstract render(): any;\n}", "language": "typescript"}
{"input": "example tests. To run these tests, uncomment this file along with the example resource in ec2_alarms_to_opsitem/ec2_alarms_to_opsitem_stack.py", "output": "def test_sqs_queue_created():\n    app = core.App()\n    stack = Ec2AlarmsToOpsitemStack(app, \"ec2-alarms-to-opsitem\")\n    template = assertions.Template.from_stack(stack)", "language": "python"}
{"input": "The intrinsic function ``Fn::FindInMap`` returns the value corresponding to keys in a two-level map that is declared in the Mappings section.", "output": "class FnFindInMap extends FnBase {\n  /**\n   * Creates an ``Fn::FindInMap`` function.\n   * @param mapName The logical name of a mapping declared in the Mappings section that contains the keys and values.\n   * @param topLevelKey The top-level key name. Its value is a list of key-value pairs.\n   * @param secondLevelKey The second-level key name, which is set to one of the keys from the list assigned to TopLevelKey.\n   * @param defaultValue The value of the default value returned if either the key is not found in the map\n   */\n\n  private readonly mapName: string;\n  private readonly topLevelKey: string;\n  private readonly secondLevelKey: string;\n  private readonly defaultValue?: string;\n\n  constructor(mapName: string, topLevelKey: any, secondLevelKey: any, defaultValue?: string) {\n    super('Fn::FindInMap', [mapName, topLevelKey, secondLevelKey, defaultValue !== undefined ? { DefaultValue: defaultValue } : undefined]);\n    this.mapName = mapName;\n    this.topLevelKey = topLevelKey;\n    this.secondLevelKey = secondLevelKey;\n    this.defaultValue = defaultValue;\n  }\n\n  public resolve(context: IResolveContext): any {\n    if (this.defaultValue !== undefined) {\n      Stack.of(context.scope).addTransform('AWS::LanguageExtensions');\n    }\n    return { 'Fn::FindInMap': [this.mapName, this.topLevelKey, this.secondLevelKey, this.defaultValue !== undefined ? { DefaultValue: this.defaultValue } : undefined] };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, API Gateway, CloudFormation operations", "output": "const createApiTemplate = (lambdaFunctionName: string) => {\n      const stack = new Stack();\n      stack.node.setContext('@aws-cdk/aws-apigateway:authorizerChangeDeploymentLogicalId', true);\n\n      const func = new lambda.Function(stack, 'myfunction', {\n        handler: 'handler',\n        functionName: lambdaFunctionName,\n        code: lambda.Code.fromInline('foo'),\n        runtime: lambda.Runtime.NODEJS_20_X,\n      });\n\n      const auth = new RequestAuthorizer(stack, 'myauthorizer', {\n        handler: func,\n        resultsCacheTtl: Duration.seconds(0),\n        identitySources: [],\n      });\n\n      const restApi = new RestApi(stack, 'myrestapi');\n      restApi.root.addMethod('ANY', undefined, {\n        authorizer: auth,\n        authorizationType: AuthorizationType.CUSTOM,\n      });\n\n      return Template.fromStack(stack);\n    }", "language": "typescript"}
{"input": "The parameter value for a workflow parameter", "output": "export class WorkflowParameterValue {\n  /**\n   * The value of the parameter as a boolean\n   *\n   * @param value The boolean value of the parameter\n   */\n  public static fromBoolean(value: boolean): WorkflowParameterValue {\n    return new WorkflowParameterValue([value.toString()]);\n  }\n\n  /**\n   * The value of the parameter as an integer\n   *\n   * @param value The integer value of the parameter\n   */\n  public static fromInteger(value: number): WorkflowParameterValue {\n    return new WorkflowParameterValue([value.toString()]);\n  }\n\n  /**\n   * The value of the parameter as a string\n   * @param value The string value of the parameter\n   */\n  public static fromString(value: string): WorkflowParameterValue {\n    return new WorkflowParameterValue([value]);\n  }\n\n  /**\n   * The value of the parameter as a string list\n   *\n   * @param values The string list value of the parameter\n   */\n  public static fromStringList(values: string[]): WorkflowParameterValue {\n    return new WorkflowParameterValue(values);\n  }\n\n  /**\n   * The rendered parameter value\n   */\n  public readonly value: string[];\n\n  protected constructor(value: string[]) {\n    this.value = value;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudWatch, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const metric = new cloudwatch.Metric({\n      namespace: 'MyNamespace',\n      metricName: 'MyMetric',\n      dimensionsMap: { MyDimension: 'MyDimensionValue' },\n    });\n    const alarm = new cloudwatch.Alarm(this, 'MyAlarm', {\n      metric: metric,\n      threshold: 100,\n      evaluationPeriods: 3,\n      datapointsToAlarm: 2,\n    });\n    const topicRule = new iot.TopicRule(this, 'TopicRule', {\n      sql: iot.IotSql.fromStringAsVer20160323(\"SELECT topic(2) as device_id FROM 'device/+/data'\"),\n    });\n\n    topicRule.addAction(new actions.CloudWatchSetAlarmStateAction(alarm, {\n      alarmStateToSet: cloudwatch.AlarmState.ALARM,\n    }));\n  }\n}", "language": "typescript"}
{"input": "The intrinsic function ``Fn::Transform`` specifies a macro to perform custom processing on part of a stack template.", "output": "class FnTransform extends FnBase {\n  /**\n   * creates an ``Fn::Transform`` function.\n   * @param macroName The name of the macro to be invoked\n   * @param parameters the parameters to pass to it\n   */\n  constructor(macroName: string, parameters: { [name: string]: any }) {\n    super('Fn::Transform', { Name: macroName, Parameters: parameters });\n  }\n}", "language": "typescript"}
{"input": "CDK class QueryDefinition for AWS resource management", "output": "export class QueryDefinition extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-logs.QueryDefinition';\n  /**\n   * The ID of the query definition.\n   *\n   * @attribute\n   */\n  public readonly queryDefinitionId: string;\n\n  constructor(scope: Construct, id: string, props: QueryDefinitionProps) {\n    super(scope, id, {\n      physicalName: props.queryDefinitionName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.queryString.statsStatementsLength && props.queryString.statsStatementsLength > 2) {\n      throw new ValidationError(`CloudWatch Logs Insights only supports up to two stats commands in a single query, received ${props.queryString.statsStatementsLength}.`, this);\n    }\n\n    if (props.queryString.hasStatsAndStatsStatements) {\n      Annotations.of(this).addWarningV2('QueryDefinitionStatsWarning',\n        'Both stats and statsStatements properties are provided. The stats property is deprecated and will be ignored in favor of statsStatements.');\n    }\n\n    const queryDefinition = new CfnQueryDefinition(this, 'Resource', {\n      name: props.queryDefinitionName,\n      queryString: props.queryString.toString(),\n      logGroupNames: typeof props.logGroups === 'undefined' ? [] : props.logGroups.flatMap(logGroup => logGroup.logGroupRef.logGroupName),\n    });\n\n    this.queryDefinitionId = queryDefinition.attrQueryDefinitionId;\n  }\n}", "language": "typescript"}
{"input": "This is the Stack containing the CodePipeline definition that deploys an ECS Service.", "output": "export class PipelineStack extends cdk.Stack {\n  public readonly tagParameterContainerImage: ecs.TagParameterContainerImage;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    /* ********** ECS part **************** */\n\n    // this is the ECR repository where the built Docker image will be pushed\n    const appEcrRepo = new ecr.Repository(this, 'EcsDeployRepository');\n    // the build that creates the Docker image, and pushes it to the ECR repo\n    const appCodeDockerBuild = new codebuild.PipelineProject(this, 'AppCodeDockerImageBuildAndPushProject', {\n      environment: {\n        // we need to run Docker\n        privileged: true,\n      },\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: [\n              // login to ECR first\n              '$(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email)',\n              // if your application needs any build steps, they would be invoked here\n\n              // build the image, and tag it with the commit hash\n              // (CODEBUILD_RESOLVED_SOURCE_VERSION is a special environment variable available in CodeBuild)\n              'docker build -t $REPOSITORY_URI:$CODEBUILD_RESOLVED_SOURCE_VERSION .',\n            ],\n          },\n          post_build: {\n            commands: [\n              // push the built image into the ECR repository\n              'docker push $REPOSITORY_URI:$CODEBUILD_RESOLVED_SOURCE_VERSION',\n              // save the declared tag as an environment variable,\n              // that is then exported below in the 'exported-variables' section as a CodePipeline Variable\n              'export imageTag=$CODEBUILD_RESOLVED_SOURCE_VERSION',\n            ],\n          },\n        },\n        env: {\n          // save the imageTag environment variable as a CodePipeline Variable\n          'exported-variables': [\n            'imageTag',\n          ],\n        },\n      }),\n      environmentVariables: {\n        REPOSITORY_URI: {\n          value: appEcrRepo.repositoryUri,\n        },\n      },\n    });\n    // needed for `docker push`\n    appEcrRepo.grantPullPush(appCodeDockerBuild);\n    // create the ContainerImage used for the ECS application Stack\n    this.tagParameterContainerImage = new ecs.TagParameterContainerImage(appEcrRepo);\n\n    const cdkCodeBuild = new codebuild.PipelineProject(this, 'CdkCodeBuildProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          install: {\n            commands: [\n              'npm install',\n            ],\n          },\n          build: {\n            commands: [\n              // synthesize the CDK code for the ECS application Stack\n              'npx cdk synth --verbose',\n            ],\n          },\n        },\n        artifacts: {\n          // store the entire Cloud Assembly as the output artifact\n          'base-directory': 'cdk.out',\n          'files': '**/*',\n        },\n      }),\n    });\n\n    /* ********** Pipeline part **************** */\n\n    const appCodeSourceOutput = new codepipeline.Artifact();\n    const cdkCodeSourceOutput = new codepipeline.Artifact();\n    const cdkCodeBuildOutput = new codepipeline.Artifact();\n    const appCodeBuildAction = new codepipeline_actions.CodeBuildAction({\n      actionName: 'AppCodeDockerImageBuildAndPush',\n      project: appCodeDockerBuild,\n      input: appCodeSourceOutput,\n    });\n    new codepipeline.Pipeline(this, 'CodePipelineDeployingEcsApplication', {\n      artifactBucket: new s3.Bucket(this, 'ArtifactBucket', {\n        removalPolicy: cdk.RemovalPolicy.DESTROY,\n      }),\n      stages: [\n        {\n          stageName: 'Source',\n          actions: [\n            // this is the Action that takes the source of your application code\n            new codepipeline_actions.CodeCommitSourceAction({\n              actionName: 'AppCodeSource',\n              repository: new codecommit.Repository(this, 'AppCodeSourceRepository', { repositoryName: 'AppCodeSourceRepository' }),\n              output: appCodeSourceOutput,\n            }),\n            // this is the Action that takes the source of your CDK code\n            // (which would probably include this Pipeline code as well)\n            new codepipeline_actions.CodeCommitSourceAction({\n              actionName: 'CdkCodeSource',\n              repository: new codecommit.Repository(this, 'CdkCodeSourceRepository', { repositoryName: 'CdkCodeSourceRepository' }),\n              output: cdkCodeSourceOutput,\n            }),\n          ],\n        },\n        {\n          stageName: 'Build',\n          actions: [\n            appCodeBuildAction,\n            new codepipeline_actions.CodeBuildAction({\n              actionName: 'CdkCodeBuildAndSynth',\n              project: cdkCodeBuild,\n              input: cdkCodeSourceOutput,\n              outputs: [cdkCodeBuildOutput],\n            }),\n          ],\n        },\n        {\n          stageName: 'Deploy',\n          actions: [\n            new codepipeline_actions.CloudFormationCreateUpdateStackAction({\n              actionName: 'CFN_Deploy',\n              stackName: 'SampleEcsStackDeployedFromCodePipeline',\n              // this name has to be the same name as used below in the CDK code for the application Stack\n              templatePath: cdkCodeBuildOutput.atPath('EcsStackDeployedInPipeline.template.json'),\n              adminPermissions: true,\n              parameterOverrides: {\n                // read the tag pushed to the ECR repository from the CodePipeline Variable saved by the application build step,\n                // and pass it as the CloudFormation Parameter for the tag\n                [this.tagParameterContainerImage.tagParameterName]: appCodeBuildAction.variable('imageTag'),\n              },\n            }),\n          ],\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, CloudFormation, CloudFront resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const bucket = new s3.Bucket(this, 'Bucket', {\n      publicReadAccess: true,\n      blockPublicAccess: {\n        blockPublicPolicy: false,\n        blockPublicAcls: false,\n        ignorePublicAcls: false,\n        restrictPublicBuckets: false,\n      },\n      websiteIndexDocument: 'index.html',\n      websiteErrorDocument: '404.html',\n    });\n\n    new cloudfront.CloudFrontWebDistribution(this, 'Distribution', {\n      viewerProtocolPolicy: cloudfront.ViewerProtocolPolicy.REDIRECT_TO_HTTPS,\n      priceClass: cloudfront.PriceClass.PRICE_CLASS_200,\n      originConfigs: [\n        {\n          behaviors: [{ isDefaultBehavior: true }],\n          customOriginSource: {\n            originProtocolPolicy: cloudfront.OriginProtocolPolicy.HTTP_ONLY,\n            domainName: bucket.bucketWebsiteDomainName,\n          },\n        },\n      ],\n    },\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lake Formation operations", "output": "const visit = (node: IConstruct) => {\n      if (CfnResource.isCfnResource(node) && this.types.includes(node.cfnResourceType)) {\n        result.push(node);\n      }\n      for (const child of node.node.children) {\n        visit(child);\n      }\n    }", "language": "typescript"}
{"input": "Returns true if a specified string matches all values in a list.", "output": "class FnEachMemberEquals extends FnConditionBase {\n  /**\n   * Creates an ``Fn::EachMemberEquals`` function.\n   * @param listOfStrings A list of strings, such as \"A\", \"B\", \"C\".\n   * @param value A string, such as \"A\", that you want to compare against a list of strings.\n   */\n  constructor(listOfStrings: any, value: string) {\n    super('Fn::EachMemberEquals', [listOfStrings, value]);\n  }\n}", "language": "typescript"}
{"input": "CDK class HttpDataSource for AWS resource management", "output": "export class HttpDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.HttpDataSource';\n\n  constructor(scope: Construct, id: string, props: HttpDataSourceProps) {\n    const authorizationConfig = props.authorizationConfig ? {\n      authorizationType: 'AWS_IAM',\n      awsIamConfig: props.authorizationConfig,\n    } : undefined;\n    super(scope, id, props, {\n      type: 'HTTP',\n      httpConfig: {\n        endpoint: props.endpoint,\n        authorizationConfig,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Policy Implementation of FilterOrPolicy", "output": "export class Policy extends FilterOrPolicy {\n  /**\n   * Type used in DFS buildFilterPolicyWithMessageBody to determine json value type\n   */\n  public readonly type = FilterOrPolicyType.POLICY;\n  /**\n   * Policy constructor\n   * @param policyDoc policy argument to construct\n   */\n  public constructor(public readonly policyDoc: { [attribute: string]: FilterOrPolicy }) {\n    super();\n  }\n}", "language": "typescript"}
{"input": "Hosted rotation type", "output": "export class HostedRotationType {\n  /** MySQL Single User */\n  public static readonly MYSQL_SINGLE_USER = new HostedRotationType('MySQLSingleUser');\n\n  /** MySQL Multi User */\n  public static readonly MYSQL_MULTI_USER = new HostedRotationType('MySQLMultiUser', true);\n\n  /** PostgreSQL Single User */\n  public static readonly POSTGRESQL_SINGLE_USER = new HostedRotationType('PostgreSQLSingleUser');\n\n  /** PostgreSQL Multi User */\n  public static readonly POSTGRESQL_MULTI_USER = new HostedRotationType('PostgreSQLMultiUser', true);\n\n  /** Oracle Single User */\n  public static readonly ORACLE_SINGLE_USER = new HostedRotationType('OracleSingleUser');\n\n  /** Oracle Multi User */\n  public static readonly ORACLE_MULTI_USER = new HostedRotationType('OracleMultiUser', true);\n\n  /** MariaDB Single User */\n  public static readonly MARIADB_SINGLE_USER = new HostedRotationType('MariaDBSingleUser');\n\n  /** MariaDB Multi User */\n  public static readonly MARIADB_MULTI_USER = new HostedRotationType('MariaDBMultiUser', true);\n\n  /** SQL Server Single User */\n  public static readonly SQLSERVER_SINGLE_USER = new HostedRotationType('SQLServerSingleUser');\n\n  /** SQL Server Multi User */\n  public static readonly SQLSERVER_MULTI_USER = new HostedRotationType('SQLServerMultiUser', true);\n\n  /** Redshift Single User */\n  public static readonly REDSHIFT_SINGLE_USER = new HostedRotationType('RedshiftSingleUser');\n\n  /** Redshift Multi User */\n  public static readonly REDSHIFT_MULTI_USER = new HostedRotationType('RedshiftMultiUser', true);\n\n  /** MongoDB Single User */\n  public static readonly MONGODB_SINGLE_USER = new HostedRotationType('MongoDBSingleUser');\n\n  /** MongoDB Multi User */\n  public static readonly MONGODB_MULTI_USER = new HostedRotationType('MongoDBMultiUser', true);\n\n  /**\n   * @param name The type of rotation\n   * @param isMultiUser Whether the rotation uses the mutli user scheme\n   */\n  private constructor(public readonly name: string, public readonly isMultiUser?: boolean) {}\n}", "language": "typescript"}
{"input": "networking mode on build time supported by docker", "output": "export class NetworkMode {\n  /**\n   * The default networking mode if omitted, create a network stack on the default Docker bridge\n   */\n  public static readonly DEFAULT = new NetworkMode('default');\n\n  /**\n   * Use the Docker host network stack\n   */\n  public static readonly HOST = new NetworkMode('host');\n\n  /**\n   * Disable the network stack, only the loopback device will be created\n   */\n  public static readonly NONE = new NetworkMode('none');\n\n  /**\n   * Reuse another container's network stack\n   *\n   * @param containerId The target container's id or name\n   */\n  public static fromContainer(containerId: string) {\n    return new NetworkMode(`container:${containerId}`);\n  }\n\n  /**\n   * Used to specify a custom networking mode\n   * Use this if the networking mode name is not yet supported by the CDK.\n   *\n   * @param mode The networking mode to use for docker build\n   */\n  public static custom(mode: string) {\n    return new NetworkMode(mode);\n  }\n\n  /**\n   * @param mode The networking mode to use for docker build\n   */\n  private constructor(public readonly mode: string) { }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, KMS, AppSync, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props: TestStackProps) {\n    super(scope, id);\n\n    const { domainName, certificateArn, hostedZoneId } = props;\n\n    const certificate = acm.Certificate.fromCertificateArn(this, 'cert', certificateArn);\n\n    const api = new appsync.GraphqlApi(this, 'api', {\n      definition: appsync.Definition.fromFile(join(__dirname, '..', '..', 'aws-appsync', 'test', 'appsync.test.graphql')),\n      domainName: {\n        certificate,\n        domainName,\n      },\n      name: 'api',\n    });\n\n    const zone = route53.HostedZone.fromHostedZoneAttributes(this, 'hosted-zone', {\n      zoneName: domainName,\n      hostedZoneId,\n    });\n\n    new route53.ARecord(this, 'Alias', {\n      zone,\n      target: route53.RecordTarget.fromAlias(new targets.AppSyncTarget(api)),\n    });\n  }\n}", "language": "typescript"}
{"input": "Controller version. Corresponds to the image tag of 'amazon/aws-load-balancer-controller' image.", "output": "export class AlbControllerVersion {\n  /**\n   * v2.0.0\n   */\n  public static readonly V2_0_0 = new AlbControllerVersion('v2.0.0', '1.4.1', false);\n\n  /**\n   * v2.0.1\n   */\n  public static readonly V2_0_1 = new AlbControllerVersion('v2.0.1', '1.4.1', false);\n\n  /**\n   * v2.1.0\n   */\n  public static readonly V2_1_0 = new AlbControllerVersion('v2.1.0', '1.4.1', false);\n\n  /**\n   * v2.1.1\n   */\n  public static readonly V2_1_1 = new AlbControllerVersion('v2.1.1', '1.4.1', false);\n\n  /**\n   * v2.1.2\n   */\n  public static readonly V2_1_2 = new AlbControllerVersion('v2.1.2', '1.4.1', false);\n\n  /**\n   * v2.1.3\n   */\n  public static readonly V2_1_3 = new AlbControllerVersion('v2.1.3', '1.4.1', false);\n\n  /**\n   * v2.0.0\n   */\n  public static readonly V2_2_0 = new AlbControllerVersion('v2.2.0', '1.4.1', false);\n\n  /**\n   * v2.2.1\n   */\n  public static readonly V2_2_1 = new AlbControllerVersion('v2.2.1', '1.4.1', false);\n\n  /**\n   * v2.2.2\n   */\n  public static readonly V2_2_2 = new AlbControllerVersion('v2.2.2', '1.4.1', false);\n\n  /**\n   * v2.2.3\n   */\n  public static readonly V2_2_3 = new AlbControllerVersion('v2.2.3', '1.4.1', false);\n\n  /**\n   * v2.2.4\n   */\n  public static readonly V2_2_4 = new AlbControllerVersion('v2.2.4', '1.4.1', false);\n\n  /**\n   * v2.3.0\n   */\n  public static readonly V2_3_0 = new AlbControllerVersion('v2.3.0', '1.4.1', false);\n\n  /**\n   * v2.3.1\n   */\n  public static readonly V2_3_1 = new AlbControllerVersion('v2.3.1', '1.4.1', false);\n\n  /**\n   * v2.4.1\n   */\n  public static readonly V2_4_1 = new AlbControllerVersion('v2.4.1', '1.4.1', false);\n\n  /**\n   * v2.4.2\n   */\n  public static readonly V2_4_2 = new AlbControllerVersion('v2.4.2', '1.4.3', false);\n\n  /**\n   * v2.4.3\n   */\n  public static readonly V2_4_3 = new AlbControllerVersion('v2.4.3', '1.4.4', false);\n\n  /**\n   * v2.4.4\n   */\n  public static readonly V2_4_4 = new AlbControllerVersion('v2.4.4', '1.4.5', false);\n\n  /**\n   * v2.4.5\n   */\n  public static readonly V2_4_5 = new AlbControllerVersion('v2.4.5', '1.4.6', false);\n\n  /**\n   * v2.4.6\n   */\n  public static readonly V2_4_6 = new AlbControllerVersion('v2.4.6', '1.4.7', false);\n\n  /**\n   * v2.4.7\n   */\n  public static readonly V2_4_7 = new AlbControllerVersion('v2.4.7', '1.4.8', false);\n\n  /**\n   * v2.5.0\n   */\n  public static readonly V2_5_0 = new AlbControllerVersion('v2.5.0', '1.5.0', false);\n\n  /**\n   * v2.5.1\n   */\n  public static readonly V2_5_1 = new AlbControllerVersion('v2.5.1', '1.5.2', false);\n\n  /**\n   * v2.5.2\n   */\n  public static readonly V2_5_2 = new AlbControllerVersion('v2.5.2', '1.5.3', false);\n\n  /**\n   * v2.5.3\n   */\n  public static readonly V2_5_3 = new AlbControllerVersion('v2.5.3', '1.5.4', false);\n\n  /**\n   * v2.5.4\n   */\n  public static readonly V2_5_4 = new AlbControllerVersion('v2.5.4', '1.5.5', false);\n\n  /**\n   * v2.6.0\n   */\n  public static readonly V2_6_0 = new AlbControllerVersion('v2.6.0', '1.6.0', false);\n\n  /**\n   * v2.6.1\n   */\n  public static readonly V2_6_1 = new AlbControllerVersion('v2.6.1', '1.6.1', false);\n\n  /**\n   * v2.6.2\n   */\n  public static readonly V2_6_2 = new AlbControllerVersion('v2.6.2', '1.6.2', false);\n\n  /**\n   * v2.7.0\n   */\n  public static readonly V2_7_0 = new AlbControllerVersion('v2.7.0', '1.7.0', false);\n\n  /**\n   * v2.7.1\n   */\n  public static readonly V2_7_1 = new AlbControllerVersion('v2.7.1', '1.7.1', false);\n\n  /**\n   * v2.7.2\n   */\n  public static readonly V2_7_2 = new AlbControllerVersion('v2.7.2', '1.7.2', false);\n\n  /**\n   * v2.8.0\n   */\n  public static readonly V2_8_0 = new AlbControllerVersion('v2.8.0', '1.8.0', false);\n\n  /**\n   * v2.8.1\n   */\n  public static readonly V2_8_1 = new AlbControllerVersion('v2.8.1', '1.8.1', false);\n\n  /**\n   * v2.8.2\n   */\n  public static readonly V2_8_2 = new AlbControllerVersion('v2.8.2', '1.8.2', false);\n\n  /**\n   * Specify a custom version and an associated helm chart version.\n   * Use this if the version you need is not available in one of the predefined versions.\n   * Note that in this case, you will also need to provide an IAM policy in the controller options.\n   *\n   * ALB controller version and helm chart version compatibility information can be found\n   * here: https://github.com/aws/eks-charts/blob/v0.0.133/stable/aws-load-balancer-controller/Chart.yaml\n   *\n   * @param version The version number.\n   * @param helmChartVersion The version of the helm chart. Version 1.4.1 is the default version to support legacy\n   * users.\n   */\n  public static of(version: string, helmChartVersion: string = '1.4.1') {\n    return new AlbControllerVersion(version, helmChartVersion, true);\n  }\n\n  private constructor(\n    /**\n     * The version string.\n     */\n    public readonly version: string,\n    /**\n     * The version of the helm chart to use.\n     */\n    public readonly helmChartVersion: string,\n    /**\n     * Whether or not its a custom version.\n     */\n    public readonly custom: boolean) { }\n}", "language": "typescript"}
{"input": "CDK class DynamoEventSourceTest for AWS resource management", "output": "class DynamoEventSourceTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const fn = new TestFunction(this, 'F');\n    const queue = new dynamodb.Table(this, 'T', {\n      partitionKey: {\n        name: 'id',\n        type: dynamodb.AttributeType.STRING,\n      },\n      stream: dynamodb.StreamViewType.NEW_IMAGE,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    const eventSource = new DynamoEventSource(queue, {\n      batchSize: 5,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      tumblingWindow: cdk.Duration.seconds(60),\n    });\n\n    fn.addEventSource(eventSource);\n\n    new cdk.CfnOutput(this, 'OutputEventSourceMappingArn', { value: eventSource.eventSourceMappingArn });\n  }\n}", "language": "typescript"}
{"input": "Defines a state of a detector.", "output": "export class State {\n  /**\n   * The name of the state.\n   */\n  public readonly stateName: string;\n\n  private readonly transitionEvents: TransitionEvent[] = [];\n\n  constructor(private readonly props: StateProps) {\n    this.stateName = props.stateName;\n  }\n\n  /**\n   * Add a transition event to the state.\n   * The transition event will be triggered if condition is evaluated to `true`.\n   *\n   * @param targetState the state that will be transit to when the event triggered\n   * @param options transition options including the condition that causes the state transition\n   */\n  public transitionTo(targetState: State, options: TransitionOptions) {\n    const alreadyAdded = this.transitionEvents.some(transitionEvent => transitionEvent.nextState === targetState);\n    if (alreadyAdded) {\n      throw new Error(`State '${this.stateName}' already has a transition defined to '${targetState.stateName}'`);\n    }\n\n    this.transitionEvents.push({\n      eventName: options.eventName ?? `${this.stateName}_to_${targetState.stateName}`,\n      nextState: targetState,\n      condition: options.when,\n      actions: options.executing,\n    });\n  }\n\n  /**\n   * Collect states in dependency graph that constructed by state transitions,\n   * and return the JSONs of the states.\n   * This function is called recursively and collect the states.\n   *\n   * @internal\n   */\n  public _collectStateJsons(scope: Construct, actionBindOptions: ActionBindOptions, collectedStates: Set<State>): CfnDetectorModel.StateProperty[] {\n    if (collectedStates.has(this)) {\n      return [];\n    }\n    collectedStates.add(this);\n\n    return [\n      this.toStateJson(scope, actionBindOptions),\n      ...this.transitionEvents.flatMap(transitionEvent => {\n        return transitionEvent.nextState._collectStateJsons(scope, actionBindOptions, collectedStates);\n      }),\n    ];\n  }\n\n  /**\n   * Returns true if this state has at least one condition via events.\n   *\n   * @internal\n   */\n  public _onEnterEventsHaveAtLeastOneCondition(): boolean {\n    return this.props.onEnter?.some(event => event.condition) ?? false;\n  }\n\n  private toStateJson(scope: Construct, actionBindOptions: ActionBindOptions): CfnDetectorModel.StateProperty {\n    const { onEnter, onInput, onExit } = this.props;\n    return {\n      stateName: this.stateName,\n      onEnter: onEnter && {\n        events: toEventsJson(scope, actionBindOptions, onEnter),\n      },\n      onInput: (onInput || this.transitionEvents.length !== 0) ? {\n        events: toEventsJson(scope, actionBindOptions, onInput),\n        transitionEvents: toTransitionEventsJson(scope, actionBindOptions, this.transitionEvents),\n      } : undefined,\n      onExit: onExit && {\n        events: toEventsJson(scope, actionBindOptions, onExit),\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "A Volume that can be mounted to a container supported by EKS", "output": "class EksVolume {\n  /**\n   * Creates a Kubernetes EmptyDir volume\n   *\n   * @see https://kubernetes.io/docs/concepts/storage/volumes/#emptydir\n   */\n  static emptyDir(options: EmptyDirVolumeOptions) {\n    return new EmptyDirVolume(options);\n  }\n  /**\n   * Creates a Kubernetes HostPath volume\n   *\n   * @see https://kubernetes.io/docs/concepts/storage/volumes/#hostpath\n   */\n  static hostPath(options: HostPathVolumeOptions) {\n    return new HostPathVolume(options);\n  }\n  /**\n   * Creates a Kubernetes Secret volume\n   *\n   * @see https://kubernetes.io/docs/concepts/storage/volumes/#secret\n   */\n  static secret(options: SecretPathVolumeOptions) {\n    return new SecretPathVolume(options);\n  }\n\n  /**\n   * The name of this volume.\n   * The name must be a valid DNS subdomain name.\n   *\n   * @see https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names\n   */\n  readonly name: string;\n\n  /**\n   * The path on the container where the container is mounted.\n   *\n   * @default - the container is not mounted\n   */\n  readonly containerPath?: string;\n\n  /**\n   * If specified, the container has readonly access to the volume.\n   * Otherwise, the container has read/write access.\n   *\n   * @default false\n   */\n  readonly readonly?: boolean;\n\n  constructor(options: EksVolumeOptions) {\n    this.name = options.name;\n    this.containerPath = options.mountPath;\n    this.readonly = options.readonly;\n  }\n}", "language": "typescript"}
{"input": "Search all descendants depth-first", "output": "const searchChildren = (parent: IConstruct, distance: number) => {\n    // Stop searching if we're already farther than the closest match\n    if (distance >= closestDistance) {\n      return;\n    }\n\n    // Check each child and recursively search its descendants\n    for (const child of parent.node.children) {\n      // Skip if already visited\n      if (visited.has(child)) {\n        continue;\n      }\n      visited.add(child);\n\n      checkCandidate(child, distance);\n      searchChildren(child, distance + 1);\n    }\n  };\n\n  searchChildren(primary, 1);\n\n  // Search ancestors and their descendants breadth-first\n  let ancestor = primary.node.scope;\n  let ancestorDistance = 1;\n\n  // Walk up the tree while we have ancestors and haven't exceeded closest distance\n  while (ancestor && ancestorDistance < closestDistance) {\n    // Check all siblings and their descendants at this ancestor level\n    for (const sibling of ancestor.node.children) {\n      searchChildren(sibling, ancestorDistance);\n    }\n    ancestor = ancestor.node.scope;\n    ancestorDistance++;\n  }\n\n  return closestMatch;\n}", "language": "typescript"}
{"input": "Neptune log types that can be exported to CloudWatch logs @see https://docs.aws.amazon.com/neptune/latest/userguide/cloudwatch-logs.html", "output": "export class LogType {\n  /**\n   * Audit logs\n   *\n   * @see https://docs.aws.amazon.com/neptune/latest/userguide/auditing.html\n   */\n  public static readonly AUDIT = new LogType('audit');\n\n  /**\n   * Constructor for specifying a custom log type\n   * @param value the log type\n   */\n  public constructor(public readonly value: string) { }\n}", "language": "typescript"}
{"input": "CDK class CdkCore for AWS resource management", "output": "export class CdkCore extends ExternalModule {\n  public readonly helpers = new CdkInternalHelpers(this);\n  public readonly errors = new CdkErrors(this);\n\n  public readonly CfnResource = Type.fromName(this, 'CfnResource');\n  public readonly Resource = $T(Type.fromName(this, 'Resource'));\n  public readonly IInspectable = Type.fromName(this, 'IInspectable');\n  public readonly TreeInspector = Type.fromName(this, 'TreeInspector');\n  public readonly Token = $T(Type.fromName(this, 'Token'));\n  public readonly ResolutionTypeHint = Type.fromName(this, 'ResolutionTypeHint');\n  public readonly CfnTag = Type.fromName(this, 'CfnTag');\n  public readonly TagManager = $T(Type.fromName(this, 'TagManager'));\n  public readonly TagType = $T(Type.fromName(this, 'TagType'));\n  public readonly Fn = $T(Type.fromName(this, 'Fn'));\n  public readonly Aws = $T(Type.fromName(this, 'Aws'));\n  public readonly ITaggable = Type.fromName(this, 'ITaggable');\n  public readonly ITaggableV2 = Type.fromName(this, 'ITaggableV2');\n  public readonly IResolvable = Type.fromName(this, 'IResolvable');\n  public readonly Stack = Type.fromName(this, 'Stack');\n  public readonly Names = $T(Type.fromName(this, 'Names'));\n  public readonly Arn = $T(Type.fromName(this, 'Arn'));\n\n  public readonly objectToCloudFormation = makeCallableExpr(this, 'objectToCloudFormation');\n  public readonly eventPatternToCloudFormation = makeCallableExpr(this, 'eventPatternToCloudFormation');\n  public readonly stringToCloudFormation = makeCallableExpr(this, 'stringToCloudFormation');\n  public readonly dateToCloudFormation = makeCallableExpr(this, 'dateToCloudFormation');\n  public readonly booleanToCloudFormation = makeCallableExpr(this, 'booleanToCloudFormation');\n  public readonly numberToCloudFormation = makeCallableExpr(this, 'numberToCloudFormation');\n  public readonly cfnTagToCloudFormation = makeCallableExpr(this, 'cfnTagToCloudFormation');\n  public readonly canInspect = makeCallableExpr(this, 'canInspect');\n  public readonly listMapper = makeCallableExpr(this, 'listMapper');\n  public readonly hashMapper = makeCallableExpr(this, 'hashMapper');\n  public readonly unionMapper = makeCallableExpr(this, 'unionMapper');\n  public readonly requireProperty = makeCallableExpr(this, 'requireProperty');\n  public readonly isResolvableObject = makeCallableExpr(this, 'isResolvableObject');\n  public readonly mapArrayInPlace = makeCallableExpr(this, 'mapArrayInPlace');\n\n  public readonly ValidationResult = $T(Type.fromName(this, 'ValidationResult'));\n  public readonly VALIDATION_SUCCESS = makeCallableExpr(this, 'VALIDATION_SUCCESS');\n  public readonly ValidationResults = $T(Type.fromName(this, 'ValidationResults'));\n\n  public readonly propertyValidator = makeCallableExpr(this, 'propertyValidator');\n  public readonly requiredValidator = makeCallableExpr(this, 'requiredValidator');\n  public readonly listValidator = makeCallableExpr(this, 'listValidator');\n  public readonly hashValidator = makeCallableExpr(this, 'hashValidator');\n  public readonly unionValidator = makeCallableExpr(this, 'unionValidator');\n  public readonly validateCfnTag = makeCallableExpr(this, 'validateCfnTag');\n  public readonly validateObject = makeCallableExpr(this, 'validateObject');\n  public readonly validateDate = makeCallableExpr(this, 'validateDate');\n  public readonly validateBoolean = makeCallableExpr(this, 'validateBoolean');\n  public readonly validateNumber = makeCallableExpr(this, 'validateNumber');\n  public readonly validateString = makeCallableExpr(this, 'validateString');\n\n  public readonly AWSEventMetadata = Type.fromName(this, 'AWSEventMetadata');\n  public readonly AWSEventMetadataProps = Type.fromName(this, 'AWSEventMetadataProps');\n\n  constructor(fqn: string) {\n    super(fqn);\n  }\n\n  public tokenAsString(arg: Expression) {\n    return this.Token.asString(arg);\n  }\n\n  public tokenAsNumber(arg: Expression) {\n    return this.Token.asNumber(arg);\n  }\n\n  public tokenAsList(arg: Expression) {\n    return this.Token.asList(arg);\n  }\n\n  public uniqueId(arg: Expression) {\n    return this.Names.uniqueId(arg);\n  }\n\n  public uniqueResourceName(...args: Expression[]) {\n    return this.Names.uniqueResourceName(...args);\n  }\n\n  public arnFormat(...args: Expression[]) {\n    return this.Arn.format(...args);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, IAM, KMS resources", "output": "export class CWLogsSubscriptionStack extends Stack {\n    \n    private readonly STACK_NAMING_PREFIX: string = 'cwlogs-subscription';\n    \n    constructor(scope: Construct, id: string, props: CWLogsSubscriptionStackProps) {\n      super(scope, id, props);\n  \n        /////////////////////////////////////////////////////////////////////////////////\n        //\n        // Create the Log Emitter Lambda resources\n        // \n        /////////////////////////////////////////////////////////////////////////////////\n        const logGroup = new LogGroup(this, `EventBridgeTriggeredLambdaLogGroup`, {\n          retention: RetentionDays.ONE_WEEK,\n        });\n    \n        // Lambda Function to publish message\n        const lambdaFn = new Function(this, 'EventBridgeTriggeredLambdaFunction', {\n          code: Code.fromAsset(path.join(__dirname, '../resources/lambda/log_emitter')),\n          handler: 'handler.log_emitter',\n          timeout: Duration.seconds(300),\n          runtime: Runtime.PYTHON_3_12,\n          logGroup: logGroup\n        });\n    \n        // Run the eventbridge every 5 minute interval to generate logs\n        const rule = new Rule(this, 'Rule', {\n          schedule: Schedule.rate(Duration.minutes(5))\n        });\n    \n        // Add the lambda function as a target to the eventbridge\n        rule.addTarget(new LambdaFunction(lambdaFn));\n  \n  \n        /////////////////////////////////////////////////////////////////////////////////\n        //\n        // Create the CloudWatch Log group subscription filter resources\n        // \n        /////////////////////////////////////////////////////////////////////////////////\n  \n        const lambdaLayer = new PythonLayerVersion(this, `${this.STACK_NAMING_PREFIX}LambdaLayer`, {\n          entry: path.join(__dirname, \"../resources/lambda/cw_subscription_filter/layers\"),\n          compatibleRuntimes: [\n            Runtime.PYTHON_3_12,\n            Runtime.PYTHON_3_11,\n          ],\n          description: \"A layer that contains the required modules\",\n          license: \"MIT License\",\n        });\n    \n        const lambdaFunction = new Function(this, `${this.STACK_NAMING_PREFIX}LambdaFunction`, {\n            runtime: Runtime.PYTHON_3_12,\n            code: Code.fromAsset(path.join(__dirname, '../resources/lambda/cw_subscription_filter')),\n            handler: 'handler.cw_subscription_handler',\n            layers: [lambdaLayer],\n            environment: {\n              OSI_INGESTION_ENDPOINT: props.ingestionEndpointURL,\n            },\n          }\n        );\n   \n        new Alias(this, `${this.STACK_NAMING_PREFIX}LambdaFunctionAlias`, {\n          aliasName: 'live',\n          version: lambdaFunction.currentVersion,\n        });\n    \n        lambdaFunction.addToRolePolicy(\n          new PolicyStatement({\n            effect: Effect.ALLOW,\n            resources: ['*'],\n            actions: ['osis:ingest'],\n          }),\n        );\n  \n        // Create a Lambda Subscription Filter on the specific log group created above\n        const subscriptionFilter = new SubscriptionFilter(this, `${this.STACK_NAMING_PREFIX}LogSubscription`, {\n          logGroup: logGroup,\n          destination: new LambdaDestination(lambdaFunction),\n          filterPattern: FilterPattern.allEvents(),\n        });\n        subscriptionFilter.node.addDependency(lambdaFunction);\n      }\n  \n}", "language": "typescript"}
{"input": "CDK class TrustStoreRevocation for AWS resource management", "output": "export class TrustStoreRevocation extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-elasticloadbalancingv2.TrustStoreRevocation';\n\n  constructor(scope: Construct, id: string, props: TrustStoreRevocationProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnTrustStoreRevocation(this, 'Resource', {\n      trustStoreArn: props.trustStore.trustStoreRef.trustStoreArn,\n      revocationContents: props.revocationContents?.map(content => ({\n        revocationType: content.revocationType,\n        s3Bucket: content.bucket.bucketRef.bucketName,\n        s3Key: content.key,\n        s3ObjectVersion: content.version,\n      })),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for EC2 operations", "output": "const createInstance = (id: string, initCommands: string[]) => {\n  const instance = new ec2.Instance(stack, id, {\n    vpc,\n    instanceType: ec2.InstanceType.of(ec2.InstanceClass.T4G, ec2.InstanceSize.NANO),\n    machineImage: ec2.MachineImage.latestAmazonLinux2023({\n      cpuType: ec2.AmazonLinuxCpuType.ARM_64,\n    }),\n    ssmSessionPermissions: true,\n    init: ec2.CloudFormationInit.fromConfig(\n      new ec2.InitConfig(initCommands.map((command) => ec2.InitCommand.shellCommand(command))),\n    ),\n    initOptions: {\n      timeout: cdk.Duration.minutes(10),\n    },\n  });\n  fileSystem.connections.allowDefaultPortFrom(instance);\n  return instance;\n}", "language": "typescript"}
{"input": "CDK class Deployment for AWS resource management", "output": "export class Deployment extends Resource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.Deployment';\n\n  /** @attribute */\n  public readonly deploymentId: string;\n  public readonly api: IRestApi;\n  /**\n   * The stage of the API gateway deployment.\n   */\n  public readonly stageName?: string;\n\n  private readonly resource: LatestDeploymentResource;\n\n  constructor(scope: Construct, id: string, props: DeploymentProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.resource = new LatestDeploymentResource(this, 'Resource', {\n      description: props.description,\n      restApi: props.api,\n      stageName: props.stageName,\n    });\n    this.resource.addMetadata(ArtifactMetadataEntryType.DO_NOT_REFACTOR, true);\n\n    if (props.retainDeployments) {\n      this.resource.applyRemovalPolicy(RemovalPolicy.RETAIN);\n    }\n\n    this.api = props.api;\n    this.deploymentId = Lazy.string({ produce: () => this.resource.ref });\n\n    if (props.api instanceof RestApiBase) {\n      props.api._attachDeployment(this);\n    }\n  }\n\n  /**\n   * Adds a component to the hash that determines this Deployment resource's\n   * logical ID.\n   *\n   * This should be called by constructs of the API Gateway model that want to\n   * invalidate the deployment when their settings change. The component will\n   * be resolved during synthesis so tokens are welcome.\n   */\n  @MethodMetadata()\n  public addToLogicalId(data: any) {\n    this.resource.addToLogicalId(data);\n  }\n\n  /**\n   * Quoting from CloudFormation's docs:\n   *\n   *   If you create an AWS::ApiGateway::RestApi resource and its methods (using\n   *   AWS::ApiGateway::Method) in the same template as your deployment, the\n   *   deployment must depend on the RestApi's methods. To create a dependency,\n   *   add a DependsOn attribute to the deployment. If you don't, AWS\n   *   CloudFormation creates the deployment right after it creates the RestApi\n   *   resource that doesn't contain any methods, and AWS CloudFormation\n   *   encounters the following error: The REST API doesn't contain any methods.\n   *\n   * @param method The method to add as a dependency of the deployment\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-apigateway-deployment.html\n   * @see https://github.com/aws/aws-cdk/pull/6165\n   * @internal\n   */\n  public _addMethodDependency(method: Method) {\n    // adding a dependency between the constructs using `node.addDependency()`\n    // will create additional dependencies between `AWS::ApiGateway::Deployment`\n    // and the `AWS::Lambda::Permission` resources (children under Method),\n    // causing cyclic dependency errors. Hence, falling back to declaring\n    // dependencies between the underlying CfnResources.\n    this.node.addDependency(method.node.defaultChild as CfnResource);\n  }\n}", "language": "typescript"}
{"input": "CDK class KafkaSelfManagedErrorHandlingTest for AWS resource management", "output": "class KafkaSelfManagedErrorHandlingTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\nMIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\ncmUuiAii9R0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\nc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n-----END CERTIFICATE-----\"\n`;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\nzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n-----END ENCRYPTED PRIVATE KEY-----`;\n\n    const rootCASecret = new secretsmanager.Secret(this, 'RootCASecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'ClientCertSecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n        privateKey: cdk.SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n\n    const bootstrapServers = [\n      'my-self-hosted-kafka-broker-1:9092',\n      'my-self-hosted-kafka-broker-2:9092',\n      'my-self-hosted-kafka-broker-3:9092',\n    ];\n\n    // Test with function response type and retry configuration\n    const fn = new TestFunction(this, 'ErrorHandlingFunction');\n    rootCASecret.grantRead(fn);\n    clientCertificatesSecret.grantRead(fn);\n\n    fn.addEventSource(new SelfManagedKafkaEventSource({\n      bootstrapServers,\n      topic: 'error-handling-topic',\n      consumerGroupId: 'errorHandlingConsumerGroup',\n      secret: clientCertificatesSecret,\n      authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n      rootCACertificate: rootCASecret,\n      startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n      retryAttempts: 3,\n      maxBatchingWindow: cdk.Duration.seconds(10),\n      batchSize: 50,\n      maxRecordAge: cdk.Duration.hours(24),\n      reportBatchItemFailures: true,\n      provisionedPollerConfig: {\n        minimumPollers: 1,\n        maximumPollers: 1,\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class DatabaseCluster for AWS resource management", "output": "export class DatabaseCluster extends DatabaseClusterNew {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-rds.DatabaseCluster';\n\n  /**\n   * Lookup an existing DatabaseCluster using clusterIdentifier.\n   */\n  public static fromLookup(scope: Construct, id: string, options: DatabaseClusterLookupOptions): IDatabaseCluster {\n    if (Token.isUnresolved(options.clusterIdentifier)) {\n      throw new UnscopedValidationError('Cannot look up a cluster with a tokenized cluster identifier.');\n    }\n    const response: {[key: string]: any}[] = ContextProvider.getValue(scope, {\n      provider: cxschema.ContextProvider.CC_API_PROVIDER,\n      props: {\n        typeName: 'AWS::RDS::DBCluster',\n        exactIdentifier: options.clusterIdentifier,\n        propertiesToReturn: [\n          'DBClusterArn',\n          'Endpoint.Address',\n          'Endpoint.Port',\n          'ReadEndpoint.Address',\n          'DBClusterResourceId',\n          'VpcSecurityGroupIds',\n          'EnableHttpEndpoint',\n        ],\n      } as cxschema.CcApiContextQuery,\n      dummyValue: [\n        {\n          'Identifier': 'TEST',\n          'DBClusterArn': 'TESTARN',\n          'Endpoint.Address': 'TESTADDRESS',\n          'Endpoint.Port': '5432',\n          'ReadEndpoint.Address': 'TESTREADERADDRESS',\n          'DBClusterResourceId': 'TESTID',\n          'VpcSecurityGroupIds': [],\n          'EnableHttpEndpoint': true,\n        },\n      ],\n    }).value;\n\n    // getValue returns a list of result objects. We are expecting 1 result or Error.\n    const cluster = response[0];\n\n    // Get ISecurityGroup from securityGroupId\n    let securityGroups: ec2.ISecurityGroup[] = [];\n    const dbsg: string[] = cluster.VpcSecurityGroupIds;\n    if (dbsg) {\n      securityGroups = dbsg.map((securityGroupId) => {\n        return ec2.SecurityGroup.fromSecurityGroupId(\n          scope,\n          `LSG-${securityGroupId}`,\n          securityGroupId,\n        );\n      });\n    }\n\n    return this.fromDatabaseClusterAttributes(scope, id, {\n      clusterIdentifier: options.clusterIdentifier,\n      clusterEndpointAddress: cluster['Endpoint.Address'],\n      readerEndpointAddress: cluster['ReadEndpoint.Address'],\n      port: Number(cluster['Endpoint.Port']),\n      clusterResourceIdentifier: cluster.DBClusterResourceId,\n      securityGroups: securityGroups,\n      dataApiEnabled: cluster.EnableHttpEndpoint,\n    });\n  }\n\n  /**\n   * Import an existing DatabaseCluster from properties\n   */\n  public static fromDatabaseClusterAttributes(scope: Construct, id: string, attrs: DatabaseClusterAttributes): IDatabaseCluster {\n    return new ImportedDatabaseCluster(scope, id, attrs);\n  }\n\n  public readonly clusterIdentifier: string;\n  public readonly clusterResourceIdentifier: string;\n  public readonly clusterEndpoint: Endpoint;\n  public readonly clusterReadEndpoint: Endpoint;\n  public readonly connections: ec2.Connections;\n  public readonly instanceIdentifiers: string[];\n  public readonly instanceEndpoints: Endpoint[];\n\n  /**\n   * The secret attached to this cluster\n   */\n  public readonly secret?: secretsmanager.ISecret;\n\n  constructor(scope: Construct, id: string, props: DatabaseClusterProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const credentials = renderCredentials(this, props.engine, props.credentials);\n    const secret = credentials.secret;\n\n    const canHaveCredentials = props.replicationSourceIdentifier == undefined;\n\n    const cluster = new CfnDBCluster(this, 'Resource', {\n      ...this.newCfnProps,\n      // Admin\n      masterUsername: canHaveCredentials ? credentials.username : undefined,\n      masterUserPassword: canHaveCredentials ? credentials.password?.unsafeUnwrap() : undefined,\n      replicationSourceIdentifier: props.replicationSourceIdentifier,\n    });\n\n    this.clusterIdentifier = cluster.ref;\n    this.clusterResourceIdentifier = cluster.attrDbClusterResourceId;\n\n    if (secret) {\n      this.secret = secret.attach(this);\n    }\n\n    // create a number token that represents the port of the cluster\n    const portAttribute = Token.asNumber(cluster.attrEndpointPort);\n    this.clusterEndpoint = new Endpoint(cluster.attrEndpointAddress, portAttribute);\n    this.clusterReadEndpoint = new Endpoint(cluster.attrReadEndpointAddress, portAttribute);\n    this.connections = new ec2.Connections({\n      securityGroups: this.securityGroups,\n      defaultPort: ec2.Port.tcp(this.clusterEndpoint.port),\n    });\n\n    cluster.applyRemovalPolicy(props.removalPolicy ?? RemovalPolicy.SNAPSHOT);\n\n    setLogRetention(this, props);\n\n    // create the instances for only standard aurora clusters\n    if (props.clusterScalabilityType !== ClusterScalabilityType.LIMITLESS && props.clusterScailabilityType !== ClusterScailabilityType.LIMITLESS) {\n      if ((props.writer || props.readers) && (props.instances || props.instanceProps)) {\n        throw new ValidationError('Cannot provide writer or readers if instances or instanceProps are provided', this);\n      }\n\n      if (!props.instanceProps && !props.writer) {\n        throw new ValidationError('writer must be provided', this);\n      }\n\n      const createdInstances = props.writer ? this._createInstances(props) : legacyCreateInstances(this, props, this.subnetGroupRef);\n      this.instanceIdentifiers = createdInstances.instanceIdentifiers;\n      this.instanceEndpoints = createdInstances.instanceEndpoints;\n    } else {\n      // Limitless database does not have instances,\n      // but an empty array will be assigned to avoid destructive changes.\n      this.instanceIdentifiers = [];\n      this.instanceEndpoints = [];\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class EksStandardAccessEntry for AWS resource management", "output": "class EksStandardAccessEntry extends Stack {\n  constructor(scope: App, id: string) {\n    super(scope, id);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', {\n      maxAzs: 2,\n      natGateways: 1,\n      restrictDefaultSecurityGroup: false,\n    });\n    const cluster = new eks.Cluster(this, 'Cluster', {\n      vpc,\n      ...getClusterVersionConfig(this, eks.KubernetesVersion.V1_30),\n      defaultCapacity: 0,\n      authenticationMode: eks.AuthenticationMode.API_AND_CONFIG_MAP,\n    });\n\n    const role = new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n    });\n\n    new eks.AccessEntry(this, 'AccessEntry', {\n      accessPolicies: [\n        eks.AccessPolicy.fromAccessPolicyName('AmazonEKSClusterAdminPolicy', {\n          accessScopeType: eks.AccessScopeType.CLUSTER,\n        }),\n      ],\n      cluster,\n      principal: role.roleArn,\n      accessEntryType: eks.AccessEntryType.STANDARD,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function assumeAtmosphereRole", "output": "export const assumeAtmosphereRole = async (roleArn: string) => {\n  const sts = new STSClient({});\n  const response = await sts.send(new AssumeRoleCommand({\n    RoleArn: roleArn,\n    RoleSessionName: 'run-tests@aws-cdk-deployment-integ',\n    DurationSeconds: 3600,\n  }));\n\n  if (response.Credentials === undefined) throw new Error('Failed to assume atmopshere role');\n\n  return response.Credentials;\n}", "language": "typescript"}
{"input": "Principal entity that represents a SAML federated identity provider for programmatic and AWS Management Console access.", "output": "export class SamlConsolePrincipal extends SamlPrincipal {\n  constructor(samlProvider: ISamlProvider, conditions: Conditions = {}) {\n    super(samlProvider, {\n      ...conditions,\n      StringEquals: {\n        'SAML:aud': RegionInfo.get(cdk.Stack.of(samlProvider).region).samlSignOnUrl ?? 'https://signin.aws.amazon.com/saml',\n      },\n    });\n  }\n\n  public toString() {\n    return `SamlConsolePrincipal(${this.federated})`;\n  }\n}", "language": "typescript"}
{"input": "Provider for NAT Gateways", "output": "export class NatGatewayProvider extends NatProvider {\n  private gateways: PrefSet<string> = new PrefSet<string>();\n\n  constructor(private readonly props: NatGatewayProps = {}) {\n    super();\n  }\n\n  public configureNat(options: ConfigureNatOptions) {\n    if (\n      this.props.eipAllocationIds != null\n      && !Token.isUnresolved(this.props.eipAllocationIds)\n      && this.props.eipAllocationIds.length < options.natSubnets.length\n    ) {\n      throw new UnscopedValidationError(`Not enough NAT gateway EIP allocation IDs (${this.props.eipAllocationIds.length} provided) for the requested subnet count (${options.natSubnets.length} needed).`);\n    }\n\n    // Create the NAT gateways\n    let i = 0;\n    for (const sub of options.natSubnets) {\n      const eipAllocationId = this.props.eipAllocationIds ? pickN(i, this.props.eipAllocationIds) : undefined;\n      const gateway = sub.addNatGateway(eipAllocationId);\n      this.gateways.add(sub.availabilityZone, gateway.ref);\n      i++;\n    }\n\n    // Add routes to them in the private subnets\n    for (const sub of options.privateSubnets) {\n      this.configureSubnet(sub);\n    }\n  }\n\n  public configureSubnet(subnet: PrivateSubnet) {\n    const az = subnet.availabilityZone;\n    const gatewayId = this.gateways.pick(az);\n    subnet.addRoute('DefaultRoute', {\n      routerType: RouterType.NAT_GATEWAY,\n      routerId: gatewayId,\n      enablesInternetConnectivity: true,\n    });\n  }\n\n  public get configuredGateways(): GatewayConfig[] {\n    return this.gateways.values().map(x => ({ az: x[0], gatewayId: x[1] }));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, Step Functions, CloudFormation resources", "output": "class DistributedMapStack extends cdk.Stack {\n  readonly stateMachine: sfn.StateMachine;\n  readonly bucket: s3.Bucket;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.bucket = new s3.Bucket(this, 'Bucket', {\n      autoDeleteObjects: true,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const distributedMap = sfn.DistributedMap.jsonata(this, 'DistributedMap', {\n      itemReader: new sfn.S3CsvItemReader({\n        bucket: this.bucket,\n        key: CSV_KEY,\n        csvHeaders: sfn.CsvHeaders.useFirstRow(),\n      }),\n      assign: {\n        uniqueId: '{% $invalidFunction() %}', // This function does not exist, triggering an error\n      },\n    }).addCatch(\n      sfn.Fail.jsonPath(this, 'failed', {\n        error: 'ErrorHappened',\n        cause: 'We got stuck',\n      }),\n      {\n        outputs: '$states.errorOutput',\n      },\n    );\n\n    distributedMap.itemProcessor(sfn.Pass.jsonata(this, 'Pass'), {\n      mode: sfn.ProcessorMode.DISTRIBUTED,\n      executionType: sfn.ProcessorType.STANDARD,\n    });\n\n    this.stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definition: distributedMap,\n      queryLanguage: sfn.QueryLanguage.JSONATA,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, MSK (Kafka), CloudFormation resources", "output": "class EksFargateClusterStack extends Stack {\n  public readonly vpc: ec2.IVpc;\n  constructor(scope: App, id: string, props?: EksFargateClusterStackProps) {\n    super(scope, id, props);\n\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n    this.vpc = props?.vpc ?? this.createDummyVpc();\n    new eks.FargateCluster(this, 'FargateCluster', {\n      ...getClusterVersionConfig(this, eks.KubernetesVersion.V1_34),\n      prune: false,\n      authenticationMode: props?.authMode,\n      vpc: this.vpc,\n    });\n  }\n  private createDummyVpc(): ec2.IVpc {\n    return new ec2.Vpc(this, 'DummyVpc', { maxAzs: 2, natGateways: 1, restrictDefaultSecurityGroup: false });\n  }\n}", "language": "typescript"}
{"input": "CDK class StreamConsumer for AWS resource management", "output": "export class StreamConsumer extends StreamConsumerBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-kinesis.StreamConsumer';\n\n  /**\n   * Imports an existing Kinesis Stream Consumer by its arn.\n   *\n   * @param scope the Construct scope.\n   * @param id the ID of the construct.\n   * @param streamConsumerArn the arn of the existing stream consumer.\n   */\n  public static fromStreamConsumerArn(scope: Construct, id: string, streamConsumerArn: string): IStreamConsumer {\n    return StreamConsumer.fromStreamConsumerAttributes(scope, id, { streamConsumerArn });\n  }\n\n  /**\n   * Imports an existing Kinesis Stream Consumer by its attributes.\n   *\n   * @param scope the Construct scope.\n   * @param id the ID of the construct.\n   * @param attrs the attributes of the existing stream consumer.\n   */\n  public static fromStreamConsumerAttributes(scope: Construct, id: string, attrs: StreamConsumerAttributes): IStreamConsumer {\n    const parsedArn = Stack.of(scope).splitArn(attrs.streamConsumerArn, ArnFormat.SLASH_RESOURCE_NAME);\n    const [streamName, _consumer, consumerNameTimestamp] = parsedArn.resourceName!.split('/');\n    const [consumerName, _creationTimestamp] = consumerNameTimestamp.split(':');\n    const streamArn = Stack.of(scope).formatArn({\n      ...parsedArn,\n      resourceName: streamName,\n    });\n\n    class Import extends StreamConsumerBase {\n      public readonly streamConsumerArn = attrs.streamConsumerArn;\n      public readonly streamConsumerName = consumerName;\n      public readonly stream = Stream.fromStreamArn(scope, `${id}ImportedStream`, streamArn);\n\n      protected readonly autoCreatePolicy = false;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The Amazon Resource Name (ARN) of the stream consumer.\n   */\n  public readonly streamConsumerArn: string;\n\n  /**\n   * The name of the stream consumer.\n   */\n  public readonly streamConsumerName: string;\n\n  /**\n   * The Kinesis data stream this consumer is associated with.\n   */\n  public readonly stream: IStream;\n\n  protected readonly autoCreatePolicy = true;\n\n  constructor(scope: Construct, id: string, props: StreamConsumerProps) {\n    super(scope, id, {\n      physicalName: props.streamConsumerName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const streamConsumer = new CfnStreamConsumer(this, 'Resource', {\n      consumerName: props.streamConsumerName,\n      streamArn: props.stream.streamArn,\n    });\n\n    this.streamConsumerArn = this.getResourceArnAttribute(streamConsumer.attrConsumerArn, {\n      service: 'kinesis',\n      resource: 'stream',\n      // use '*' in place of the consumer creation timestamp for cross environment references\n      resourceName: `${props.stream.streamName}/consumer/${this.physicalName}:*`,\n      arnFormat: ArnFormat.SLASH_RESOURCE_NAME,\n    });\n    this.streamConsumerName = this.getResourceNameAttribute(streamConsumer.attrConsumerName);\n    this.stream = props.stream;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, RDS resources", "output": "class ImageContentSearchStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        with open(\"stack/config.yml\", 'r') as stream:\n            configs = yaml.safe_load(stream)\n\n        ### S3 core\n        images_S3_bucket = _s3.Bucket(self, \"ICS_IMAGES\")\n\n        images_S3_bucket.add_cors_rule(\n            allowed_methods=[_s3.HttpMethods.POST],\n            allowed_origins=[\"*\"] # add API gateway web resource URL\n        )\n\n        ### SQS core\n        image_deadletter_queue = _sqs.Queue(self, \"ICS_IMAGES_DEADLETTER_QUEUE\")\n        image_queue = _sqs.Queue(self, \"ICS_IMAGES_QUEUE\",\n            dead_letter_queue=_sqs.DeadLetterQueue(\n                max_receive_count=configs[\"DeadLetterQueue\"][\"MaxReceiveCount\"],\n                queue=image_deadletter_queue\n            )\n        )\n\n        ### api gateway core\n        api_gateway = RestApi(self, 'ICS_API_GATEWAY', rest_api_name='ImageContentSearchApiGateway')\n        api_gateway_resource = api_gateway.root.add_resource(configs[\"ProjectName\"])\n        api_gateway_landing_page_resource = api_gateway_resource.add_resource('web')\n        api_gateway_get_signedurl_resource = api_gateway_resource.add_resource('signedUrl')\n        api_gateway_image_search_resource = api_gateway_resource.add_resource('search')\n\n        ### landing page function\n        get_landing_page_function = Function(self, \"ICS_GET_LANDING_PAGE\",\n            function_name=\"ICS_GET_LANDING_PAGE\",\n            runtime=Runtime.PYTHON_3_7,\n            handler=\"main.handler\",\n            code=Code.from_asset(\"./src/landingPage\"))\n\n        get_landing_page_integration = LambdaIntegration(\n            get_landing_page_function,\n            proxy=True,\n            integration_responses=[IntegrationResponse(\n                status_code='200',\n                response_parameters={\n                    'method.response.header.Access-Control-Allow-Origin': \"'*'\"\n                }\n            )])\n\n        api_gateway_landing_page_resource.add_method('GET', get_landing_page_integration,\n            method_responses=[MethodResponse(\n                status_code='200',\n                response_parameters={\n                    'method.response.header.Access-Control-Allow-Origin': True\n                }\n            )])\n\n        ### cognito\n        required_attribute = _cognito.StandardAttribute(required=True)\n\n        users_pool = _cognito.UserPool(self, \"ICS_USERS_POOL\",\n            auto_verify=_cognito.AutoVerifiedAttrs(email=True), #required for self sign-up\n            standard_attributes=_cognito.StandardAttributes(email=required_attribute), #required for self sign-up\n            self_sign_up_enabled=configs[\"Cognito\"][\"SelfSignUp\"])\n\n        user_pool_app_client = _cognito.CfnUserPoolClient(self, \"ICS_USERS_POOL_APP_CLIENT\",\n            supported_identity_providers=[\"COGNITO\"],\n            allowed_o_auth_flows=[\"implicit\"],\n            allowed_o_auth_scopes=configs[\"Cognito\"][\"AllowedOAuthScopes\"],\n            user_pool_id=users_pool.user_pool_id,\n            callback_ur_ls=[api_gateway.url_for_path('/web')],\n            allowed_o_auth_flows_user_pool_client=True,\n            explicit_auth_flows=[\"ALLOW_REFRESH_TOKEN_AUTH\"])\n\n        user_pool_domain = _cognito.UserPoolDomain(self, \"ICS_USERS_POOL_DOMAIN\",\n            user_pool=users_pool,\n            cognito_domain=_cognito.CognitoDomainOptions(domain_prefix=configs[\"Cognito\"][\"DomainPrefix\"]))\n\n        ### get signed URL function\n        get_signedurl_function = Function(self, \"ICS_GET_SIGNED_URL\",\n            function_name=\"ICS_GET_SIGNED_URL\",\n            environment={\n                \"ICS_IMAGES_BUCKET\": images_S3_bucket.bucket_name,\n                \"DEFAULT_SIGNEDURL_EXPIRY_SECONDS\": configs[\"Functions\"][\"DefaultSignedUrlExpirySeconds\"]\n            },\n            runtime=Runtime.PYTHON_3_7,\n            handler=\"main.handler\",\n            code=Code.from_asset(\"./src/getSignedUrl\"))\n\n        get_signedurl_integration = LambdaIntegration(\n            get_signedurl_function,\n            proxy=True,\n            integration_responses=[IntegrationResponse(\n                status_code='200',\n                response_parameters={\n                   'method.response.header.Access-Control-Allow-Origin': \"'*'\",\n                }\n            )])\n\n        api_gateway_get_signedurl_authorizer = CfnAuthorizer(self, \"ICS_API_GATEWAY_GET_SIGNED_URL_AUTHORIZER\",\n            rest_api_id=api_gateway_get_signedurl_resource.api.rest_api_id,\n            name=\"ICS_API_GATEWAY_GET_SIGNED_URL_AUTHORIZER\",\n            type=\"COGNITO_USER_POOLS\",\n            identity_source=\"method.request.header.Authorization\",\n            provider_arns=[users_pool.user_pool_arn])\n\n        get_signedurl_method = api_gateway_get_signedurl_resource.add_method('GET', get_signedurl_integration,\n            authorization_type=AuthorizationType.COGNITO,\n            method_responses=[MethodResponse(\n                status_code='200',\n                response_parameters={\n                    'method.response.header.Access-Control-Allow-Origin': True,\n                }\n            )])\n        signedurl_custom_resource = typing.cast(\"aws_cloudformation.CfnCustomResource\", get_signedurl_method.node.find_child('Resource'))\n        signedurl_custom_resource.add_property_override('AuthorizerId', api_gateway_get_signedurl_authorizer.ref)\n\n        images_S3_bucket.grant_put(get_signedurl_function, objects_key_pattern=\"new/*\")\n\n        ### image massage function\n        image_massage_function = Function(self, \"ICS_IMAGE_MASSAGE\",\n            function_name=\"ICS_IMAGE_MASSAGE\",\n            timeout=Duration.seconds(6),\n            runtime=Runtime.PYTHON_3_7,\n            environment={\"ICS_IMAGE_MASSAGE\": image_queue.queue_name},\n            handler=\"main.handler\",\n            code=Code.from_asset(\"./src/imageMassage\"))\n\n        images_S3_bucket.grant_write(image_massage_function, \"processed/*\")\n        images_S3_bucket.grant_delete(image_massage_function, \"new/*\")\n        images_S3_bucket.grant_read(image_massage_function, \"new/*\")\n\n        new_image_added_notification = _s3notification.LambdaDestination(image_massage_function)\n\n        images_S3_bucket.add_event_notification(_s3.EventType.OBJECT_CREATED,\n            new_image_added_notification,\n            _s3.NotificationKeyFilter(prefix=\"new/\")\n            )\n\n        image_queue.grant_send_messages(image_massage_function)\n\n        ### image analyzer function\n        image_analyzer_function = Function(self, \"ICS_IMAGE_ANALYSIS\",\n            function_name=\"ICS_IMAGE_ANALYSIS\",\n            runtime=Runtime.PYTHON_3_7,\n            timeout=Duration.seconds(10),\n            environment={\n                \"ICS_IMAGES_BUCKET\": images_S3_bucket.bucket_name,\n                \"DEFAULT_MAX_CALL_ATTEMPTS\": configs[\"Functions\"][\"DefaultMaxApiCallAttempts\"],\n                \"REGION\": Aws.REGION,\n                },\n            handler=\"main.handler\",\n            code=Code.from_asset(\"./src/imageAnalysis\"))\n\n        image_analyzer_function.add_event_source(_lambda_event_source.SqsEventSource(queue=image_queue, batch_size=10))\n        image_queue.grant_consume_messages(image_massage_function)\n\n        lambda_rekognition_access = _iam.PolicyStatement(\n            effect=_iam.Effect.ALLOW,\n            actions=[\"rekognition:DetectLabels\", \"rekognition:DetectModerationLabels\"],\n            resources=[\"*\"]\n        )\n\n        image_analyzer_function.add_to_role_policy(lambda_rekognition_access)\n        images_S3_bucket.grant_read(image_analyzer_function, \"processed/*\")\n\n        ### API gateway finalizing\n        self.add_cors_options(api_gateway_get_signedurl_resource)\n        self.add_cors_options(api_gateway_landing_page_resource)\n        self.add_cors_options(api_gateway_image_search_resource)\n\n        ### database\n        database_secret = _secrets_manager.Secret(self, \"ICS_DATABASE_SECRET\",\n            secret_name=\"rds-db-credentials/image-content-search-rds-secret\",\n            generate_secret_string=_secrets_manager.SecretStringGenerator(\n                generate_string_key='password',\n                secret_string_template='{\"username\": \"dba\"}',\n                exclude_punctuation=True,\n                exclude_characters='/@\\\" \\\\\\'',\n                require_each_included_type=True\n            )\n        )\n\n        database = _rds.CfnDBCluster(self, \"ICS_DATABASE\",\n            engine=_rds.DatabaseClusterEngine.aurora_mysql(version=_rds.AuroraMysqlEngineVersion.VER_5_7_12).engine_type,\n            engine_mode=\"serverless\",\n            database_name=configs[\"Database\"][\"Name\"],\n            enable_http_endpoint=True,\n            deletion_protection=configs[\"Database\"][\"DeletionProtection\"],\n            master_username=database_secret.secret_value_from_json(\"username\").to_string(),\n            master_user_password=database_secret.secret_value_from_json(\"password\").to_string(),\n            scaling_configuration=_rds.CfnDBCluster.ScalingConfigurationProperty(\n                auto_pause=configs[\"Database\"][\"Scaling\"][\"AutoPause\"],\n                min_capacity=configs[\"Database\"][\"Scaling\"][\"Min\"],\n                max_capacity=configs[\"Database\"][\"Scaling\"][\"Max\"],\n                seconds_until_auto_pause=configs[\"Database\"][\"Scaling\"][\"SecondsToAutoPause\"]\n            ),\n        )\n\n        database_cluster_arn = \"arn:aws:rds:{}:{}:cluster:{}\".format(Aws.REGION, Aws.ACCOUNT_ID, database.ref)\n\n        secret_target = _secrets_manager.CfnSecretTargetAttachment(self,\"ICS_DATABASE_SECRET_TARGET\",\n            target_type=\"AWS::RDS::DBCluster\",\n            target_id=database.ref,\n            secret_id=database_secret.secret_arn\n        )\n\n        secret_target.node.add_dependency(database)\n\n        ### database function\n        image_data_function_role = _iam.Role(self, \"ICS_IMAGE_DATA_FUNCTION_ROLE\",\n            role_name=\"ICS_IMAGE_DATA_FUNCTION_ROLE\",\n            assumed_by=_iam.ServicePrincipal(\"lambda.amazonaws.com\"),\n            managed_policies=[\n                _iam.ManagedPolicy.from_aws_managed_policy_name(\"service-role/AWSLambdaVPCAccessExecutionRole\"),\n                _iam.ManagedPolicy.from_aws_managed_policy_name(\"service-role/AWSLambdaBasicExecutionRole\"),\n                _iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonRDSDataFullAccess\")\n            ]\n        )\n\n        assert database.database_name is not None\n\n        image_data_function = Function(self, \"ICS_IMAGE_DATA\",\n            function_name=\"ICS_IMAGE_DATA\",\n            runtime=Runtime.PYTHON_3_7,\n            timeout=Duration.seconds(5),\n            role=image_data_function_role,\n            environment={\n                \"DEFAULT_MAX_CALL_ATTEMPTS\": configs[\"Functions\"][\"DefaultMaxApiCallAttempts\"],\n                \"CLUSTER_ARN\": database_cluster_arn,\n                \"CREDENTIALS_ARN\": database_secret.secret_arn,\n                \"DB_NAME\": database.database_name,\n                \"REGION\": Aws.REGION\n                },\n            handler=\"main.handler\",\n            code=Code.from_asset(\"./src/imageData\")\n        )\n\n        image_search_integration = LambdaIntegration(\n            image_data_function,\n            proxy=True,\n            integration_responses=[IntegrationResponse(\n                status_code='200',\n                response_parameters={\n                   'method.response.header.Access-Control-Allow-Origin': \"'*'\",\n                }\n            )])\n\n        api_gateway_image_search_authorizer = CfnAuthorizer(self, \"ICS_API_GATEWAY_IMAGE_SEARCH_AUTHORIZER\",\n            rest_api_id=api_gateway_image_search_resource.api.rest_api_id,\n            name=\"ICS_API_GATEWAY_IMAGE_SEARCH_AUTHORIZER\",\n            type=\"COGNITO_USER_POOLS\",\n            identity_source=\"method.request.header.Authorization\",\n            provider_arns=[users_pool.user_pool_arn])\n\n        search_integration_method = api_gateway_image_search_resource.add_method('POST', image_search_integration,\n            authorization_type=AuthorizationType.COGNITO,\n            method_responses=[MethodResponse(\n                status_code='200',\n                response_parameters={\n                    'method.response.header.Access-Control-Allow-Origin': True,\n                }\n            )])\n        search_integration_custom_resource = typing.cast(\"aws_cloudformation.CfnCustomResource\", search_integration_method.node.find_child('Resource'))\n        search_integration_custom_resource.add_property_override('AuthorizerId', api_gateway_image_search_authorizer.ref)\n\n        lambda_access_search = _iam.PolicyStatement(\n            effect=_iam.Effect.ALLOW,\n            actions=[\"translate:TranslateText\"],\n            resources=[\"*\"]\n        )\n\n        image_data_function.add_to_role_policy(lambda_access_search)\n\n        ### custom resource\n        lambda_provider = Provider(self, 'ICS_IMAGE_DATA_PROVIDER',\n            on_event_handler=image_data_function\n        )\n\n        CustomResource(self, 'ICS_IMAGE_DATA_RESOURCE',\n            service_token=lambda_provider.service_token,\n            pascal_case_properties=False,\n            resource_type=\"Custom::SchemaCreation\",\n            properties={\n                \"source\": \"Cloudformation\"\n            }\n        )\n\n        ### event bridge\n        event_bus = _events.EventBus(self, \"ICS_IMAGE_CONTENT_BUS\", event_bus_name=\"ImageContentBus\")\n\n        event_rule = _events.Rule(self, \"ICS_IMAGE_CONTENT_RULE\",\n            rule_name=\"ICS_IMAGE_CONTENT_RULE\",\n            description=\"The event from image analyzer to store the data\",\n            event_bus=event_bus,\n            event_pattern=_events.EventPattern(resources=[image_analyzer_function.function_arn]),\n        )\n\n        event_rule.add_target(_event_targets.LambdaFunction(image_data_function))\n\n        event_bus.grant_all_put_events(image_analyzer_function)\n        image_analyzer_function.add_environment(\"EVENT_BUS\", event_bus.event_bus_name)\n\n        assert user_pool_domain.domain_name is not None\n        assert user_pool_app_client.allowed_o_auth_scopes is not None\n\n        ### outputs\n        CfnOutput(self, 'CognitoHostedUILogin',\n            value='https://{domain}.auth.{region}.amazoncognito.com/login?client_id={client_id}&response_type=token&scope={scope}&redirect_uri={redirect_uri}'.format(\n                domain=user_pool_domain.domain_name,\n                region=Aws.REGION,\n                client_id=user_pool_app_client.ref,\n                scope='+'.join(user_pool_app_client.allowed_o_auth_scopes),\n                redirect_uri=api_gateway.url_for_path('/web')\n            ),\n            description='The Cognito Hosted UI Login Page'\n        )\n\n    def add_cors_options(self, apigw_resource):\n        apigw_resource.add_method('OPTIONS', MockIntegration(\n            integration_responses=[{\n                'statusCode': '200',\n                'responseParameters': {\n                    'method.response.header.Access-Control-Allow-Headers': \"'Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token'\",\n                    'method.response.header.Access-Control-Allow-Origin': \"'*'\",\n                    'method.response.header.Access-Control-Allow-Methods': \"'GET,OPTIONS'\"\n                }\n            }\n            ],\n            passthrough_behavior=PassthroughBehavior.WHEN_NO_MATCH,\n            request_templates={\"application/json\":\"{\\\"statusCode\\\":200}\"}\n        ),\n        method_responses=[{\n            'statusCode': '200',\n            'responseParameters': {\n                'method.response.header.Access-Control-Allow-Headers': True,\n                'method.response.header.Access-Control-Allow-Methods': True,\n                'method.response.header.Access-Control-Allow-Origin': True,\n                }\n            }\n        ],\n    )", "language": "python"}
{"input": "Job Code from a local file.", "output": "export class AssetCode extends Code {\n  private asset?: s3assets.Asset;\n\n  /**\n   * @param path The path to the Code file.\n   */\n  constructor(private readonly path: string, private readonly options: s3assets.AssetOptions = { }) {\n    super();\n\n    if (fs.lstatSync(this.path).isDirectory()) {\n      throw new cdk.UnscopedValidationError(`Code path ${this.path} is a directory. Only files are supported`);\n    }\n  }\n\n  public bind(scope: constructs.Construct, grantable: iam.IGrantable): CodeConfig {\n    // If the same AssetCode is used multiple times, retain only the first instantiation.\n    if (!this.asset) {\n      this.asset = new s3assets.Asset(scope, `Code${this.hashcode(this.path)}`, {\n        path: this.path,\n        ...this.options,\n      });\n    } else if (cdk.Stack.of(this.asset) !== cdk.Stack.of(scope)) {\n      throw new cdk.UnscopedValidationError(`Asset is already associated with another stack '${cdk.Stack.of(this.asset).stackName}'. ` +\n        'Create a new Code instance for every stack.');\n    }\n    this.asset.grantRead(grantable);\n    return {\n      s3Location: {\n        bucketName: this.asset.s3BucketName,\n        objectKey: this.asset.s3ObjectKey,\n      },\n    };\n  }\n\n  /**\n   * Hash a string\n   */\n  private hashcode(s: string): string {\n    return md5hash(s);\n  }\n}", "language": "typescript"}
{"input": "CDK class PlaybackKeyPair for AWS resource management", "output": "export class PlaybackKeyPair extends PlaybackKeyPairBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ivs-alpha.PlaybackKeyPair';\n  public readonly playbackKeyPairArn: string;\n\n  /**\n   * Key-pair identifier. For example: 98:0d:1a:a0:19:96:1e:ea:0a:0a:2c:9a:42:19:2b:e7\n   *\n   * @attribute\n   */\n  public readonly playbackKeyPairFingerprint: string;\n\n  constructor(scope: Construct, id: string, props: PlaybackKeyPairProps) {\n    super(scope, id, {\n      physicalName: props.playbackKeyPairName ?? Lazy.string({\n        produce: () => Names.uniqueResourceName(this, { maxLength: 128, allowedSpecialCharacters: '-_' }),\n      }),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (props.playbackKeyPairName && !core.Token.isUnresolved(props.playbackKeyPairName) && !/^[a-zA-Z0-9-_]*$/.test(props.playbackKeyPairName)) {\n      throw new Error(`playbackKeyPairName must contain only numbers, letters, hyphens and underscores, got: '${props.playbackKeyPairName}'`);\n    }\n\n    const resource = new CfnPlaybackKeyPair(this, 'Resource', {\n      publicKeyMaterial: props.publicKeyMaterial,\n      name: props.playbackKeyPairName,\n    });\n\n    this.playbackKeyPairArn = resource.attrArn;\n    this.playbackKeyPairFingerprint = resource.attrFingerprint;\n  }\n}", "language": "typescript"}
{"input": "CDK class DefinitionBody for AWS resource management", "output": "class DefinitionBody {\n  public static fromFile(path: string, options?: s3_assets.AssetOptions): DefinitionBody {\n    return new FileDefinitionBody(path, options);\n  }\n\n  public static fromString(definition: string): DefinitionBody {\n    return new StringDefinitionBody(definition);\n  }\n\n  public static fromChainable(chainable: IChainable): DefinitionBody {\n    return new ChainDefinitionBody(chainable);\n  }\n\n  public abstract bind(scope: Construct, sfnPrincipal: iam.IPrincipal, sfnProps: StateMachineProps, graph?: StateGraph): DefinitionConfig;\n}", "language": "typescript"}
{"input": "CDK class MyCustomResource for AWS resource management", "output": "export class MyCustomResource extends Construct {\n  public readonly response: string;\n\n  constructor(scope: Construct, id: string, props: MyCustomResourceProps) {\n    super(scope, id);\n\n\n    const onEvent = new lambda.SingletonFunction(this, 'Singleton', {\n      uuid: 'f7d4f730-4ee1-11e8-9c2d-fa7ae01bbebc',\n      code: new lambda.InlineCode(fs.readFileSync('custom-resource-handler.py', { encoding: 'utf-8' })),\n      handler: 'index.on_event',\n      timeout: cdk.Duration.seconds(300),\n      runtime: lambda.Runtime.PYTHON_3_6,\n    });\n\n    const myProvider = new cr.Provider(this, 'MyProvider', {\n      onEventHandler: onEvent,\n      // isCompleteHandler: isComplete,        // optional async \"waiter\" lambda, see custom-resource-handler.py\n      logRetention: logs.RetentionDays.ONE_DAY   // default is INFINITE\n    });\n\n    const resource = new cdk.CustomResource(this, 'Resource1', { serviceToken: myProvider.serviceToken, properties: props });\n\n    this.response = resource.getAtt('Response').toString();\n\n  }\n}", "language": "typescript"}
{"input": "Builds a struct type for a TypeDefinition in the database model Uses the TypeDefinitionDecider for the actual decisions, and carries those out.", "output": "export class TypeDefinitionStruct extends StructType {\n  private readonly typeDefinition: TypeDefinition;\n  private readonly converter: TypeConverter;\n  private readonly resource: Resource;\n  private readonly module: Module;\n  private readonly relationshipDecider: RelationshipDecider;\n  private readonly options: TypeDefinitionStructOptions;\n\n  constructor(options: TypeDefinitionStructOptions) {\n    super(options.resourceClass, {\n      export: true,\n      name: structNameFromTypeDefinition(options.typeDefinition),\n      docs: {\n        ...splitDocumentation(options.typeDefinition.documentation),\n        stability: Stability.External,\n        see: cloudFormationDocLink({\n          resourceType: options.resource.cloudFormationType,\n          propTypeName: options.typeDefinition.name,\n        }),\n      },\n    });\n\n    this.options = options;\n    this.typeDefinition = options.typeDefinition;\n    this.converter = options.converter;\n    this.resource = options.resource;\n    this.relationshipDecider = options.relationshipDecider;\n    this.options = options;\n\n    this.module = Module.of(this);\n  }\n\n  public build() {\n    const cfnMapping = new CloudFormationMapping(this.module, this.converter, {\n      resourceType: this.resource.cloudFormationType,\n      propTypeName: this.typeDefinition.name,\n    });\n\n    const decider = new TypeDefinitionDecider(this.resource, this.typeDefinition, this.converter, this.relationshipDecider);\n\n    for (const prop of decider.properties) {\n      this.addProperty(prop.propertySpec);\n      cfnMapping.add(prop.cfnMapping);\n    }\n\n    let needsResolverFunction = false;\n    for (const [propName, prop] of Object.entries(this.typeDefinition.properties)) {\n      needsResolverFunction = needsResolverFunction\n        ? needsResolverFunction\n        : this.relationshipDecider.needsFlatteningFunction(propName, prop);\n    }\n\n    if (needsResolverFunction) {\n      const resolverFunction = new FreeFunction(this.module, {\n        name: flattenFunctionNameFromType(this),\n        returnType: Type.unionOf(this.type, CDK_CORE.IResolvable),\n        parameters: [{ name: 'props', type: Type.unionOf(this.type, CDK_CORE.IResolvable) }],\n      });\n\n      const propsParam = resolverFunction.parameters[0];\n      resolverFunction.addBody(\n        stmt.if_(CDK_CORE.isResolvableObject(propsParam))\n          .then(stmt.ret(propsParam)),\n\n        stmt.ret(expr.object(\n          Object.fromEntries(\n            decider.properties.map(prop => [\n              prop.propertySpec.name,\n              prop.resolver(propsParam),\n            ]),\n          ),\n        )),\n      );\n    }\n\n    if (this.options.cfnProducer ?? true) {\n      cfnMapping.makeCfnProducer(this.module, this);\n    }\n    if (this.options.cfnParser ?? true) {\n      cfnMapping.makeCfnParser(this.module, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class PythonLayerVersion for AWS resource management", "output": "export class PythonLayerVersion extends lambda.LayerVersion {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-lambda-python-alpha.PythonLayerVersion';\n\n  constructor(scope: Construct, id: string, props: PythonLayerVersionProps) {\n    const compatibleRuntimes = props.compatibleRuntimes ?? [lambda.Runtime.PYTHON_3_7];\n    const compatibleArchitectures = props.compatibleArchitectures ?? [lambda.Architecture.X86_64];\n\n    // Ensure that all compatible runtimes are python\n    for (const runtime of compatibleRuntimes) {\n      if (runtime && runtime.family !== lambda.RuntimeFamily.PYTHON) {\n        throw new Error('Only `PYTHON` runtimes are supported.');\n      }\n    }\n\n    // Entry and defaults\n    const entry = path.resolve(props.entry);\n    // Pick the first compatibleRuntime and compatibleArchitectures to use for bundling\n    const runtime = compatibleRuntimes[0];\n    const architecture = compatibleArchitectures[0];\n\n    super(scope, id, {\n      ...props,\n      compatibleRuntimes,\n      code: Bundling.bundle({\n        entry,\n        runtime,\n        architecture,\n        outputPathSuffix: 'python',\n        skip: !Stack.of(scope).bundlingRequired,\n        ...props.bundling,\n      }),\n    });\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for SNS, CloudWatch operations", "output": "def __init__(self, scope: Construct, construct_id: str, zone: route53.HostedZone, primaryLoadBalancer: elbv2.ILoadBalancerV2, secondaryLoadBalancer: elbv2.ILoadBalancerV2, email: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # primary record\n        primaryHealthCheck = route53.CfnHealthCheck(self, \"DNSPrimaryHealthCheck\", health_check_config=route53.CfnHealthCheck.HealthCheckConfigProperty(\n            fully_qualified_domain_name=primaryLoadBalancer.load_balancer_dns_name,\n            type=\"HTTP\",\n            port=80\n        ))\n        primary = route53.ARecord(self, \"PrimaryRecordSet\",\n            zone = zone,\n            record_name=\"failover\",\n            target = route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(primaryLoadBalancer)),\n        )\n        primaryRecordSet = primary.node.default_child\n        primaryRecordSet.failover = \"PRIMARY\"\n        primaryRecordSet.health_check_id = primaryHealthCheck.attr_health_check_id\n        primaryRecordSet.set_identifier = \"Primary\"\n\n        # secondary record\n        secondaryHealthCheck = route53.CfnHealthCheck(self, \"DNSSecondaryHealthCheck\", health_check_config=route53.CfnHealthCheck.HealthCheckConfigProperty(\n            fully_qualified_domain_name=secondaryLoadBalancer.load_balancer_dns_name,\n            type=\"HTTP\",\n            port=80,\n        ))\n        secondary = route53.ARecord(self, \"SecondaryRecordSet\",\n            zone = zone,\n            record_name=\"failover\",\n            target= route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(secondaryLoadBalancer)),\n        )\n        secondaryRecordSet = secondary.node.default_child\n        secondaryRecordSet.failover = \"SECONDARY\"\n        secondaryRecordSet.health_check_id = secondaryHealthCheck.attr_health_check_id\n        secondaryRecordSet.set_identifier = \"Secondary\"\n\n        # cloudwatch metric & alarm to SNS\n        snsTopic = sns.Topic(self, \"AlarmNotificationTopic\")\n        snsTopic.add_subscription(\n            EmailSubscription(email_address=email)\n        )\n\n        healthCheckMetric = cloudwatch.Metric(\n            metric_name=\"HealthCheckStatus\",\n            namespace=\"AWS/Route53\",\n            statistic=\"Minimum\",\n            period=Duration.minutes(1),\n            region=\"us-east-1\",\n            dimensions_map={\n                \"HealthCheckId\": primaryHealthCheck.attr_health_check_id\n            }\n        )\n        healthCheckAlarm = healthCheckMetric.create_alarm(self, 'HealthCheckFailureAlarm', \n            evaluation_periods=1,\n            threshold=1,\n            comparison_operator=cloudwatch.ComparisonOperator.LESS_THAN_THRESHOLD\n        )\n\n        healthCheckAlarm.add_alarm_action(SnsAction(snsTopic))", "language": "python"}
{"input": "Cognito User for testing", "output": "class CognitoUser extends Construct {\n  readonly username: string;\n  readonly password: string;\n  constructor(scope: Construct, id: string, props: CognitoUserProps) {\n    super(scope, id);\n    const user = new AwsCustomResource(this, 'Resource', {\n      resourceType: 'Custom::CognitoUser',\n      onCreate: {\n        service: 'CognitoIdentityServiceProvider',\n        action: 'adminCreateUser',\n        parameters: {\n          UserPoolId: props.userPool.userPoolId,\n          Username: props.username,\n          UserAttributes: [\n            {\n              Name: 'email',\n              Value: props.username,\n            },\n            {\n              Name: 'email_verified',\n              Value: 'true',\n            },\n          ],\n          MessageAction: 'SUPPRESS',\n        },\n        physicalResourceId: PhysicalResourceId.of('User'),\n      },\n      policy: AwsCustomResourcePolicy.fromStatements([new iam.PolicyStatement({\n        actions: ['cognito-idp:AdminCreateUser'],\n        resources: [props.userPool.userPoolArn],\n      })]),\n    });\n\n    new AwsCustomResource(this, 'SetUserPassword', {\n      resourceType: 'Custom::CognitoUserPassword',\n      onCreate: {\n        service: 'CognitoIdentityServiceProvider',\n        action: 'adminSetUserPassword',\n        parameters: {\n          UserPoolId: props.userPool.userPoolId,\n          Username: user.getResponseField('User.Username'),\n          Password: props.password,\n          Permanent: true,\n        },\n        physicalResourceId: PhysicalResourceId.of('SetUserPassword'),\n      },\n      policy: AwsCustomResourcePolicy.fromStatements([new iam.PolicyStatement({\n        actions: ['cognito-idp:AdminSetUserPassword'],\n        resources: [props.userPool.userPoolArn],\n      })]),\n    }).node.addDependency(user);\n    this.password = props.password;\n    this.username = props.username;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, WAF, EventBridge, SQS resources", "output": "class LambdaStack extends Stack {\n  public readonly queue: sqs.Queue;\n\n  constructor(scope: constructs.Construct, id: string) {\n    super(scope, id);\n\n    this.queue = new sqs.Queue(this, 'Queue');\n\n    const fn = new lambda.Function(this, 'MyFunction', {\n      runtime: STANDARD_NODEJS_RUNTIME,\n      handler: 'index.handler',\n      code: lambda.Code.fromInline(`exports.handler = async (event) => {\n        return 'success';\n      };`),\n      onSuccess: new SqsDestination(this.queue),\n    });\n\n    const logGroup = new logs.LogGroup(this, 'LogGroup', { removalPolicy: RemovalPolicy.DESTROY });\n    const lambdaDestination = new LambdaDestination(fn);\n\n    new logs.SubscriptionFilter(this, 'Subscription', {\n      logGroup: logGroup,\n      destination: lambdaDestination,\n      filterPattern: logs.FilterPattern.allEvents(),\n    });\n\n    const customRule = new events.Rule(this, 'CustomRule', {\n      eventPattern: {\n        source: ['cdk-lambda-integ'],\n        detailType: ['cdk-integ-custom-rule'],\n      },\n    });\n    customRule.addTarget(new CloudWatchLogGroup(logGroup, {\n      logEvent: LogGroupTargetInput.fromObject({\n        message: 'Howdy Ho!',\n      }),\n    }));\n  }\n}", "language": "typescript"}
{"input": "Represents the properties needed to define the provider for a VirtualService", "output": "class VirtualServiceProvider {\n  /**\n   * Returns a VirtualNode based Provider for a VirtualService\n   */\n  public static virtualNode(virtualNode: IVirtualNode): VirtualServiceProvider {\n    return new VirtualServiceProviderImpl(virtualNode, undefined);\n  }\n\n  /**\n   * Returns a VirtualRouter based Provider for a VirtualService\n   */\n  public static virtualRouter(virtualRouter: IVirtualRouter): VirtualServiceProvider {\n    return new VirtualServiceProviderImpl(undefined, virtualRouter);\n  }\n\n  /**\n   * Returns an Empty Provider for a VirtualService. This provides no routing capabilities\n   * and should only be used as a placeholder\n   */\n  public static none(mesh: IMesh): VirtualServiceProvider {\n    return new VirtualServiceProviderImpl(undefined, undefined, mesh);\n  }\n\n  /**\n   * Enforces mutual exclusivity for VirtualService provider types.\n   */\n  public abstract bind(_construct: Construct): VirtualServiceProviderConfig;\n}", "language": "typescript"}
{"input": "PolicySynthesizer token resolver implementation", "output": "export class PolicySynthesizerTokenResolver extends DefaultTokenResolver {\n  constructor(concat: IFragmentConcatenator) {\n    super(concat);\n  }\n\n  /**\n   * PolicySynthesizer Token resolution\n   *\n   * Resolve the Token until the token can be resolved into\n   * \"(Path/To/SomeResource.Arn)\" format. Otherwise, recurse\n   * into whatever it returns,\n   */\n  public resolveToken(t: IResolvable, context: any, postProcessor: any) {\n    try {\n      let resolved = t.resolve(context);\n\n      // If the token value is resolvable into the format \"(Path/To/SomeResource.Arn)\", return it\n      // as this is the format expected by the Policy Synthesizer.\n      const resolvable = Tokenization.reverseString(resolved);\n      if (resolvable.length === 1 && Reference.isReference(resolvable.firstToken)) {\n        return `(${resolvable.firstToken.target.node.path}.${resolvable.firstToken.displayName})`;\n      }\n      // The token might have returned more values that need resolving, recurse\n      resolved = context.resolve(resolved);\n      resolved = postProcessor.postProcess(resolved, context);\n      return resolved;\n    } catch (e: any) {\n      let message = `Resolution error: ${e.message}.`;\n      if (t.creationStack && t.creationStack.length > 0) {\n        message += `\\nObject creation stack:\\n  at ${t.creationStack.join('\\n  at ')}`;\n      }\n\n      e.message = message;\n      throw e;\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, CloudFormation resources", "output": "class DependencyTestStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n    const vpc = new Vpc(this, 'VPC', { natGateways: 1 });\n\n    const bucket = new s3.Bucket(this, 'Bucket', {\n      autoDeleteObjects: true,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    vpc.addFlowLog('FlowLogS3', {\n      destination: FlowLogDestination.toS3(bucket, 'vpcFlowLog'),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class KafkaPollerGroupNameTest for AWS resource management", "output": "class KafkaPollerGroupNameTest extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const dummyCertString = `-----BEGIN CERTIFICATE-----\nMIIE5DCCAsygAwIBAgIRAPJdwaFaNRrytHBto0j5BA0wDQYJKoZIhvcNAQELBQAw\ncmUuaAii9R0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIFgjCCA2qgAwIBAgIQdjNZd6uFf9hbNC5RdfmHrzANBgkqhkiG9w0BAQsFADBb\nc8PH3PSoAaRwMMgOSA2ALJvbRz8mpg==\n-----END CERTIFICATE-----\"\n`;\n\n    const dummyPrivateKey = `-----BEGIN ENCRYPTED PRIVATE KEY-----\nzp2mwJn2NYB7AZ7+imp0azDZb+8YG2aUCiyqb6PnnA==\n-----END ENCRYPTED PRIVATE KEY-----`;\n\n    const fn1 = new TestFunction(this, 'SelfManagedFunction');\n    const rootCASecret = new secretsmanager.Secret(this, 'RootCASecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n      },\n    });\n    const clientCertificatesSecret = new secretsmanager.Secret(this, 'ClientCertSecret', {\n      secretObjectValue: {\n        certificate: cdk.SecretValue.unsafePlainText(dummyCertString),\n        privateKey: cdk.SecretValue.unsafePlainText(dummyPrivateKey),\n      },\n    });\n    rootCASecret.grantRead(fn1);\n    clientCertificatesSecret.grantRead(fn1);\n\n    const bootstrapServers = [\n      'my-self-hosted-kafka-broker-1:9092',\n      'my-self-hosted-kafka-broker-2:9092',\n      'my-self-hosted-kafka-broker-3:9092',\n    ];\n\n    fn1.addEventSource(\n      new SelfManagedKafkaEventSource({\n        bootstrapServers,\n        topic: 'my-test-topic-with-poller-group',\n        consumerGroupId: 'myTestConsumerGroupWithPollerGroup',\n        secret: clientCertificatesSecret,\n        authenticationMethod: AuthenticationMethod.CLIENT_CERTIFICATE_TLS_AUTH,\n        rootCACertificate: rootCASecret,\n        startingPosition: lambda.StartingPosition.TRIM_HORIZON,\n        provisionedPollerConfig: {\n          minimumPollers: 1,\n          maximumPollers: 3,\n          pollerGroupName: 'test-poller-group-self-managed',\n        },\n      }),\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK Construct MyBeautifulConstruct for reusable infrastructure components", "output": "class MyBeautifulConstruct extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n  }\n}", "language": "typescript"}
{"input": "CDK class AwsAppSyncEvent for AWS resource management", "output": "class AwsAppSyncEvent extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const api = new appsync.GraphqlApi(this, 'baseApi', {\n      name: 'aws-cdk-aws-appsync-target-integ-api',\n      definition: appsync.Definition.fromFile(path.join(__dirname, 'appsync.test.graphql')),\n      authorizationConfig: { defaultAuthorization: { authorizationType: appsync.AuthorizationType.IAM } },\n    });\n    const none = api.addNoneDataSource('none');\n    none.createResolver('publisher', {\n      typeName: 'Mutation',\n      fieldName: 'publish',\n      code: appsync.AssetCode.fromInline(`\nexport const request = (ctx) => ({payload: null})\nexport const response = (ctx) => ctx.args.message\n`.trim()),\n      runtime: appsync.FunctionRuntime.JS_1_0_0,\n    });\n\n    const graphQLOperation = 'mutation Publish($message: String!){ publish(message: $message) { message } }';\n    const queue = new sqs.Queue(this, 'Queue');\n\n    const timer = new events.Rule(this, 'Timer', {\n      schedule: events.Schedule.rate(cdk.Duration.minutes(1)),\n    });\n    timer.addTarget(new targets.AppSync(api, {\n      graphQLOperation,\n      variables: events.RuleTargetInput.fromObject({\n        message: 'hello world',\n      }),\n      deadLetterQueue: queue,\n    }));\n  }\n}", "language": "typescript"}
{"input": "A Kubernetes EmptyDir volume @see https://kubernetes.io/docs/concepts/storage/volumes/#emptydir", "output": "export class EmptyDirVolume extends EksVolume {\n  /**\n   * Returns `true` if `x` is an EmptyDirVolume, `false` otherwise\n   */\n  public static isEmptyDirVolume(x: any) : x is EmptyDirVolume {\n    return x !== null && typeof(x) === 'object' && EMPTY_DIR_VOLUME_SYMBOL in x;\n  }\n\n  /**\n   * The storage type to use for this Volume.\n   *\n   * @default `EmptyDirMediumType.DISK`\n   */\n  readonly medium?: EmptyDirMediumType;\n\n  /**\n   * The maximum size for this Volume\n   *\n   * @default - no size limit\n   */\n  readonly sizeLimit?: Size;\n\n  constructor(options: EmptyDirVolumeOptions) {\n    super(options);\n    this.medium = options.medium;\n    this.sizeLimit = options.sizeLimit;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function ensureArrayOrUndefined", "output": "const ensureArrayOrUndefined = (field: any) => {\n  if (field === undefined) {\n    return undefined;\n  }\n  if (typeof (field) !== 'string' && !Array.isArray(field)) {\n    throw new UnscopedValidationError('Fields must be either a string or an array of strings');\n  }\n  if (Array.isArray(field) && !!field.find((f: any) => typeof (f) !== 'string')) {\n    throw new UnscopedValidationError('Fields must be either a string or an array of strings');\n  }\n  return Array.isArray(field) ? field : [field];\n}", "language": "typescript"}
{"input": "Ec2 instance that creates the kafka topic and can be used to consume MSK messages", "output": "class MSKClient(NestedStack):\n    def __init__(self, \n                scope: Construct, \n                construct_id: str, \n                vpc, \n                client_subnet, \n                zookeeper,\n                **kwargs):\n        super().__init__(scope, construct_id, **kwargs)\n\n        # Amazon Linux AMI\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            edition=ec2.AmazonLinuxEdition.STANDARD,\n            virtualization=ec2.AmazonLinuxVirt.HVM,\n            storage=ec2.AmazonLinuxStorage.GENERAL_PURPOSE\n        )\n        \n        # MSK client Role\n        role = iam.Role(self, \"InstanceSSM\", assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"))\n\n        # AWS managed policy added to MSK client role\n        role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSSMManagedInstanceCore\"))\n\n        # MSK Client\n        instance = ec2.Instance(self, \"Instance\",\n            instance_type=ec2.InstanceType(constants[\"KAFKA_CLIENT_INSTANCE\"]),\n            machine_image=amzn_linux,\n            vpc = vpc,\n            vpc_subnets=client_subnet,\n            role = role,\n            \n        )\n\n        # Ec2 security group in the MSK VPC\n        client_security_group = ec2.SecurityGroup(self, 'InstanceSecurityGroup', vpc=vpc)\n        \n        # Enable connection from anywhere on port 22\n        client_security_group.add_ingress_rule(\n            ec2.Peer.ipv4('0.0.0.0/0'),\n            ec2.Port.tcp(22),\n        )\n        instance.add_security_group(client_security_group)\n\n        # Commands to install dependencies and create the kafka topic\n        instance.user_data.add_commands(\n            \"yum install java-1.8.0 -y\",\n            f'wget https://archive.apache.org/dist/kafka/{constants[\"KAFKA_VERSION\"]}/{constants[\"KAFKA_DOWNLOAD_VERSION\"]}.tgz',\n            f\"tar -xzf {constants['KAFKA_DOWNLOAD_VERSION']}.tgz\",\n            f\"./{constants['KAFKA_DOWNLOAD_VERSION']}/bin/kafka-topics.sh --create --zookeeper {zookeeper} --replication-factor 2 --partitions 1 --topic {constants['MSK_TOPIC']}\",\n        )", "language": "python"}
{"input": "Test for table with default parameters", "output": "class DefaultTableStack extends core.Stack {\n  public readonly table: s3tables.Table;\n  public readonly namespace: s3tables.Namespace;\n  public readonly tableBucket: s3tables.TableBucket;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n\n    this.tableBucket = new s3tables.TableBucket(this, 'DefaultBucket', {\n      tableBucketName: 'table-test-bucket',\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    this.namespace = new s3tables.Namespace(this, 'DefaultNamespace', {\n      namespaceName: 'table_test_namespace',\n      tableBucket: this.tableBucket,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n\n    this.table = new s3tables.Table(this, 'DefaultTable', {\n      tableName: 'default_test_table',\n      namespace: this.namespace,\n      openTableFormat: s3tables.OpenTableFormat.ICEBERG,\n      withoutMetadata: true,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n}", "language": "typescript"}
{"input": "Represents the service source from ECR Public.", "output": "export class EcrPublicSource extends Source {\n  private readonly props: EcrPublicProps;\n  constructor(props: EcrPublicProps) {\n    super();\n    this.props = props;\n  }\n  public bind(_scope: Construct): SourceConfig {\n    return {\n      imageRepository: {\n        imageConfiguration: this.props.imageConfiguration,\n        imageIdentifier: this.props.imageIdentifier,\n        imageRepositoryType: ImageRepositoryType.ECR_PUBLIC,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, IAM, CloudFormation, Backup resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    new Table(this, 'Table', {\n      partitionKey: {\n        name: 'id',\n        type: AttributeType.STRING,\n      },\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const firstVault = new backup.BackupVault(this, 'FirstVault', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      lockConfiguration: {\n        minRetention: Duration.days(5),\n      },\n    });\n\n    const secondVault = new backup.BackupVault(this, 'SecondVault', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      lockConfiguration: {\n        minRetention: Duration.days(5),\n      },\n    });\n\n    const firstPlan = backup.BackupPlan.dailyWeeklyMonthly5YearRetention(this, 'FirstPlan', firstVault);\n    const secondPlan = backup.BackupPlan.dailyWeeklyMonthly5YearRetention(this, 'SecondPlan', secondVault);\n\n    firstPlan.addSelection('SelectionWithAutoGeneratedPolicy', {\n      resources: [\n        backup.BackupResource.fromConstruct(this),\n      ],\n      allowRestores: true,\n    });\n\n    const role = new Role(this, 'BackupRole', {\n      assumedBy: new ServicePrincipal('backup.amazonaws.com'),\n    });\n    role.addManagedPolicy(ManagedPolicy.fromAwsManagedPolicyName('AWSBackupServiceRolePolicyForS3Backup'));\n    role.addManagedPolicy(ManagedPolicy.fromAwsManagedPolicyName('AWSBackupServiceRolePolicyForS3Restore'));\n    secondPlan.addSelection('SelectionWithoutAutoGeneratedPolicy', {\n      resources: [\n        backup.BackupResource.fromConstruct(this),\n      ],\n      role,\n      disableDefaultBackupPolicy: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, VPC, MSK (Kafka), CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    const vpc = new Vpc(this, 'VPC');\n\n    new FlowLog(this, 'FlowLogsCW', {\n      resourceType: FlowLogResourceType.fromVpc(vpc),\n      logFormat: [\n        LogFormat.SRC_PORT,\n      ],\n    });\n\n    new Cluster(this, 'ECSCluster', { vpc });\n\n    new FlowLog(this, 'FlowLogsAllFormatCW', {\n      resourceType: FlowLogResourceType.fromVpc(vpc),\n      logFormat: [\n        LogFormat.VERSION,\n        LogFormat.ACCOUNT_ID,\n        LogFormat.INTERFACE_ID,\n        LogFormat.SRC_ADDR,\n        LogFormat.DST_ADDR,\n        LogFormat.SRC_PORT,\n        LogFormat.DST_PORT,\n        LogFormat.PROTOCOL,\n        LogFormat.PACKETS,\n        LogFormat.BYTES,\n        LogFormat.START_TIMESTAMP,\n        LogFormat.END_TIMESTAMP,\n        LogFormat.ACTION,\n        LogFormat.LOG_STATUS,\n        LogFormat.VPC_ID,\n        LogFormat.SUBNET_ID,\n        LogFormat.INSTANCE_ID,\n        LogFormat.TCP_FLAGS,\n        LogFormat.TRAFFIC_TYPE,\n        LogFormat.PKT_SRC_ADDR,\n        LogFormat.PKT_DST_ADDR,\n        LogFormat.REGION,\n        LogFormat.AZ_ID,\n        LogFormat.SUBLOCATION_TYPE,\n        LogFormat.SUBLOCATION_ID,\n        LogFormat.PKT_SRC_AWS_SERVICE,\n        LogFormat.PKT_DST_AWS_SERVICE,\n        LogFormat.FLOW_DIRECTION,\n        LogFormat.TRAFFIC_PATH,\n        LogFormat.ECS_CLUSTER_ARN,\n        LogFormat.ECS_CLUSTER_NAME,\n        LogFormat.ECS_CONTAINER_INSTANCE_ARN,\n        LogFormat.ECS_CONTAINER_INSTANCE_ID,\n        LogFormat.ECS_CONTAINER_ID,\n        LogFormat.ECS_SECOND_CONTAINER_ID,\n        LogFormat.ECS_SERVICE_NAME,\n        LogFormat.ECS_TASK_DEFINITION_ARN,\n        LogFormat.ECS_TASK_ARN,\n        LogFormat.ECS_TASK_ID,\n      ],\n    });\n\n    const bucket = new Bucket(this, 'Bucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n    vpc.addFlowLog('FlowLogsS3', {\n      destination: FlowLogDestination.toS3(bucket, 'prefix/'),\n      logFormat: [\n        LogFormat.DST_PORT,\n        LogFormat.SRC_PORT,\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, WAF, CloudFormation resources", "output": "export class AwsBackupS3Stack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const bucket = new aws_s3.Bucket(this, \"testBucket\", {\n      blockPublicAccess: {\n        blockPublicAcls: true,\n        blockPublicPolicy: true,\n        ignorePublicAcls: true,\n        restrictPublicBuckets: true,\n      },\n      enforceSSL: true,\n      publicReadAccess: false,\n      encryption: aws_s3.BucketEncryption.S3_MANAGED,\n      versioned: true,\n    });\n    Tags.of(bucket).add(\"daily-backup\", \"true\");\n\n    const backupRole = this.createBackupRole();\n\n    // Daily 35 day retention\n    const vault = new aws_backup.BackupVault(this, \"Vault\", {});\n    const plan = aws_backup.BackupPlan.daily35DayRetention(\n      this,\n      \"demo-backup-plan\",\n      vault\n    );\n\n    plan.addSelection(\"Selection\", {\n      role: backupRole,\n      resources: [aws_backup.BackupResource.fromTag(\"daily-backup\", \"true\")],\n    });\n  }\n\n  private createBackupRole() {\n    const backupRole = new aws_iam.Role(this, \"Role\", {\n      assumedBy: new aws_iam.ServicePrincipal(\"backup.amazonaws.com\"),\n    });\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\n          \"s3:GetInventoryConfiguration\",\n          \"s3:PutInventoryConfiguration\",\n          \"s3:ListBucketVersions\",\n          \"s3:ListBucket\",\n          \"s3:GetBucketVersioning\",\n          \"s3:GetBucketNotification\",\n          \"s3:PutBucketNotification\",\n          \"s3:GetBucketLocation\",\n          \"s3:GetBucketTagging\",\n        ],\n        resources: [\"arn:aws:s3:::*\"],\n        sid: \"S3BucketBackupPermissions\",\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\n          \"s3:GetObjectAcl\",\n          \"s3:GetObject\",\n          \"s3:GetObjectVersionTagging\",\n          \"s3:GetObjectVersionAcl\",\n          \"s3:GetObjectTagging\",\n          \"s3:GetObjectVersion\",\n        ],\n        resources: [\"arn:aws:s3:::*/*\"],\n        sid: \"S3ObjectBackupPermissions\",\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\"s3:ListAllMyBuckets\"],\n        resources: [\"*\"],\n        sid: \"S3GlobalPermissions\",\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\"s3:ListAllMyBuckets\"],\n        resources: [\"*\"],\n        sid: \"S3GlobalPermissions\",\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\"kms:Decrypt\", \"kms:DescribeKey\"],\n        resources: [\"*\"],\n        sid: \"KMSBackupPermissions\",\n        conditions: {\n          StringLike: {\n            \"kms:ViaService\": \"s3.*.amazonaws.com\",\n          },\n        },\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\n          \"events:DescribeRule\",\n          \"events:EnableRule\",\n          \"events:PutRule\",\n          \"events:DeleteRule\",\n          \"events:PutTargets\",\n          \"events:RemoveTargets\",\n          \"events:ListTargetsByRule\",\n          \"events:DisableRule\",\n        ],\n        resources: [\"arn:aws:events:*:*:rule/AwsBackupManagedRule*\"],\n        sid: \"EventsPermissions\",\n      })\n    );\n    backupRole.addToPolicy(\n      new aws_iam.PolicyStatement({\n        actions: [\"cloudwatch:GetMetricData\", \"events:ListRules\"],\n        resources: [\"*\"],\n        sid: \"EventsMetricsGlobalPermissions\",\n      })\n    );\n    return backupRole;\n  }\n}", "language": "typescript"}
{"input": "A CloudFormation Hook for CodeDeploy blue-green ECS deployments. @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/blue-green.html#blue-green-template-reference", "output": "export class CfnCodeDeployBlueGreenHook extends CfnHook {\n  /**\n   * A factory method that creates a new instance of this class from an object\n   * containing the CloudFormation properties of this resource.\n   * Used in the @aws-cdk/cloudformation-include module.\n   *\n   * @internal\n   */\n  public static _fromCloudFormation(scope: Construct, id: string, hookAttributes: any,\n    options: FromCloudFormationOptions): CfnCodeDeployBlueGreenHook {\n    hookAttributes = hookAttributes || {};\n    const hookProperties = options.parser.parseValue(hookAttributes.Properties);\n    return new CfnCodeDeployBlueGreenHook(scope, id, {\n      serviceRole: hookProperties?.ServiceRole,\n      applications: hookProperties?.Applications?.map(applicationFromCloudFormation),\n      trafficRoutingConfig: {\n        type: hookProperties?.TrafficRoutingConfig?.Type,\n        timeBasedCanary: {\n          stepPercentage: hookProperties?.TrafficRoutingConfig?.TimeBasedCanary?.StepPercentage,\n          bakeTimeMins: hookProperties?.TrafficRoutingConfig?.TimeBasedCanary?.BakeTimeMins,\n        },\n        timeBasedLinear: {\n          stepPercentage: hookProperties?.TrafficRoutingConfig?.TimeBasedLinear?.StepPercentage,\n          bakeTimeMins: hookProperties?.TrafficRoutingConfig?.TimeBasedLinear?.BakeTimeMins,\n        },\n      },\n      additionalOptions: {\n        terminationWaitTimeInMinutes: hookProperties?.AdditionalOptions?.TerminationWaitTimeInMinutes,\n      },\n      lifecycleEventHooks: {\n        beforeInstall: hookProperties?.LifecycleEventHooks?.BeforeInstall,\n        afterInstall: hookProperties?.LifecycleEventHooks?.AfterInstall,\n        afterAllowTestTraffic: hookProperties?.LifecycleEventHooks?.AfterAllowTestTraffic,\n        beforeAllowTraffic: hookProperties?.LifecycleEventHooks?.BeforeAllowTraffic,\n        afterAllowTraffic: hookProperties?.LifecycleEventHooks?.AfterAllowTraffic,\n      },\n    });\n\n    function applicationFromCloudFormation(app: any) {\n      const target = findResource(app?.Target?.LogicalID);\n      const taskDefinitions: Array<CfnResource | undefined> | undefined = app?.ECSAttributes?.TaskDefinitions?.map(\n        (td: any) => findResource(td));\n      const taskSets: Array<CfnResource | undefined> | undefined = app?.ECSAttributes?.TaskSets?.map(\n        (ts: any) => findResource(ts));\n      const prodTrafficRoute = findResource(app?.ECSAttributes?.TrafficRouting?.ProdTrafficRoute?.LogicalID);\n      const testTrafficRoute = findResource(app?.ECSAttributes?.TrafficRouting?.TestTrafficRoute?.LogicalID);\n      const targetGroups: Array<CfnResource | undefined> | undefined = app?.ECSAttributes?.TrafficRouting?.TargetGroups?.map(\n        (tg: any) => findResource(tg));\n\n      return {\n        target: {\n          type: app?.Target?.Type,\n          logicalId: target?.logicalId,\n        },\n        ecsAttributes: {\n          taskDefinitions: taskDefinitions?.map(td => td?.logicalId),\n          taskSets: taskSets?.map(ts => ts?.logicalId),\n          trafficRouting: {\n            prodTrafficRoute: {\n              type: app?.ECSAttributes?.TrafficRouting?.ProdTrafficRoute?.Type,\n              logicalId: prodTrafficRoute?.logicalId,\n            },\n            testTrafficRoute: {\n              type: app?.ECSAttributes?.TrafficRouting?.TestTrafficRoute?.Type,\n              logicalId: testTrafficRoute?.logicalId,\n            },\n            targetGroups: targetGroups?.map((tg) => tg?.logicalId),\n          },\n        },\n      };\n    }\n\n    function findResource(logicalId: string | undefined): CfnResource | undefined {\n      if (logicalId == null) {\n        return undefined;\n      }\n      const ret = options.parser.finder.findResource(logicalId);\n      if (!ret) {\n        throw new UnscopedValidationError(`Hook '${id}' references resource '${logicalId}' that was not found in the template`);\n      }\n      return ret;\n    }\n  }\n\n  private _serviceRole: string;\n  private _applications: CfnCodeDeployBlueGreenApplication[];\n  private _trafficRoutingConfig?: CfnTrafficRoutingConfig;\n  private _additionalOptions?: CfnCodeDeployBlueGreenAdditionalOptions;\n  private _lifecycleEventHooks?: CfnCodeDeployBlueGreenLifecycleEventHooks;\n\n  /**\n   * Creates a new CodeDeploy blue-green ECS Hook.\n   *\n   * @param scope the scope to create the hook in (usually the containing Stack object)\n   * @param id the identifier of the construct - will be used to generate the logical ID of the Hook\n   * @param props the properties of the Hook\n   */\n  constructor(scope: Construct, id: string, props: CfnCodeDeployBlueGreenHookProps) {\n    super(scope, id, {\n      type: 'AWS::CodeDeploy::BlueGreen',\n      // we render the properties ourselves\n    });\n\n    this._serviceRole = props.serviceRole;\n    this._applications = props.applications;\n    this._trafficRoutingConfig = props.trafficRoutingConfig;\n    this._additionalOptions = props.additionalOptions;\n    this._lifecycleEventHooks = props.lifecycleEventHooks;\n  }\n\n  /**\n   * The IAM Role for CloudFormation to use to perform blue-green deployments.\n   */\n  public get serviceRole(): string {\n    return this._serviceRole;\n  }\n\n  public set serviceRole(serviceRole: string) {\n    this._serviceRole = serviceRole;\n  }\n\n  /**\n   * Properties of the Amazon ECS applications being deployed.\n   */\n  public get applications(): CfnCodeDeployBlueGreenApplication[] {\n    return this._applications;\n  }\n\n  public set applications(value: CfnCodeDeployBlueGreenApplication[]) {\n    this._applications = value;\n  }\n\n  /**\n   * Traffic routing configuration settings.\n   *\n   * @default - time-based canary traffic shifting, with a 15% step percentage and a five minute bake time\n   */\n  public get trafficRoutingConfig(): CfnTrafficRoutingConfig | undefined {\n    return this._trafficRoutingConfig;\n  }\n\n  public set trafficRoutingConfig(value: CfnTrafficRoutingConfig | undefined) {\n    this._trafficRoutingConfig = value;\n  }\n\n  /**\n   * Additional options for the blue/green deployment.\n   *\n   * @default - no additional options\n   */\n  public get additionalOptions(): CfnCodeDeployBlueGreenAdditionalOptions | undefined {\n    return this._additionalOptions;\n  }\n\n  public set additionalOptions(value: CfnCodeDeployBlueGreenAdditionalOptions | undefined) {\n    this._additionalOptions = value;\n  }\n\n  /**\n   * Use lifecycle event hooks to specify a Lambda function that CodeDeploy can call to validate a deployment.\n   * You can use the same function or a different one for deployment lifecycle events.\n   * Following completion of the validation tests,\n   * the Lambda `CfnCodeDeployBlueGreenLifecycleEventHooks.afterAllowTraffic`\n   * function calls back CodeDeploy and delivers a result of 'Succeeded' or 'Failed'.\n   *\n   * @default - no lifecycle event hooks\n   */\n  public get lifecycleEventHooks(): CfnCodeDeployBlueGreenLifecycleEventHooks | undefined {\n    return this._lifecycleEventHooks;\n  }\n\n  public set lifecycleEventHooks(value: CfnCodeDeployBlueGreenLifecycleEventHooks | undefined) {\n    this._lifecycleEventHooks = value;\n  }\n\n  protected renderProperties(_props?: { [p: string]: any }): { [p: string]: any } | undefined {\n    return {\n      ServiceRole: this.serviceRole,\n      Applications: this.applications.map((app) => ({\n        Target: {\n          Type: app.target.type,\n          LogicalID: app.target.logicalId,\n        },\n        ECSAttributes: {\n          TaskDefinitions: app.ecsAttributes.taskDefinitions,\n          TaskSets: app.ecsAttributes.taskSets,\n          TrafficRouting: {\n            ProdTrafficRoute: {\n              Type: app.ecsAttributes.trafficRouting.prodTrafficRoute.type,\n              LogicalID: app.ecsAttributes.trafficRouting.prodTrafficRoute.logicalId,\n            },\n            TestTrafficRoute: {\n              Type: app.ecsAttributes.trafficRouting.testTrafficRoute.type,\n              LogicalID: app.ecsAttributes.trafficRouting.testTrafficRoute.logicalId,\n            },\n            TargetGroups: app.ecsAttributes.trafficRouting.targetGroups,\n          },\n        },\n      })),\n      TrafficRoutingConfig: undefinedIfAllValuesAreEmpty({\n        Type: this.trafficRoutingConfig?.type,\n        TimeBasedCanary: undefinedIfAllValuesAreEmpty({\n          StepPercentage: this.trafficRoutingConfig?.timeBasedCanary?.stepPercentage,\n          BakeTimeMins: this.trafficRoutingConfig?.timeBasedCanary?.bakeTimeMins,\n        }),\n        TimeBasedLinear: undefinedIfAllValuesAreEmpty({\n          StepPercentage: this.trafficRoutingConfig?.timeBasedLinear?.stepPercentage,\n          BakeTimeMins: this.trafficRoutingConfig?.timeBasedLinear?.bakeTimeMins,\n        }),\n      }),\n      AdditionalOptions: undefinedIfAllValuesAreEmpty({\n        TerminationWaitTimeInMinutes: this.additionalOptions?.terminationWaitTimeInMinutes,\n      }),\n      LifecycleEventHooks: undefinedIfAllValuesAreEmpty({\n        BeforeInstall: this.lifecycleEventHooks?.beforeInstall,\n        AfterInstall: this.lifecycleEventHooks?.afterInstall,\n        AfterAllowTestTraffic: this.lifecycleEventHooks?.afterAllowTestTraffic,\n        BeforeAllowTraffic: this.lifecycleEventHooks?.beforeAllowTraffic,\n        AfterAllowTraffic: this.lifecycleEventHooks?.afterAllowTraffic,\n      }),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, Lambda operations", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n         # S3 bucket to store videos\n        video_bucket = s3.Bucket(\n            self,\n            \"S3Bucket\",\n            removal_policy=RemovalPolicy.DESTROY,\n        )\n\n        # SNS\n        rekognition_sns_topic = sns.Topic(\n            self,\n            \"RekognitionSnsTopic\",\n            display_name=\"Rekognition Job Completion SNS Topic\",\n        )\n\n        rekognition_role = iam.Role(\n            self,\n            \"RekognitionRole\",\n            assumed_by=iam.ServicePrincipal(\"rekognition.amazonaws.com\"),\n            managed_policies=[\n                iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSNSFullAccess\"),\n            ],\n        )\n\n        # Define IAM permissions needed\n        s3_lambda_policy = iam.PolicyStatement(\n            actions=[\"s3:GetObject\"],\n            resources=[video_bucket.bucket_arn, video_bucket.bucket_arn + \"/*\"],\n            effect=iam.Effect.ALLOW,\n        )\n        rekognition_lambda_policy = iam.PolicyStatement(\n            actions=[\"rekognition:*\"],\n            resources=[\"*\"],\n            effect=iam.Effect.ALLOW,\n        )\n        pass_role_lambda_policy =iam.PolicyStatement(\n                actions=[\"iam:PassRole\"],\n                resources=[\n                    rekognition_role.role_arn\n                ],\n            )\n\n        # Lambda which detects when a video has been uploaded to the S3 bucket and starts the video processing with Rekognition\n        start_processing_lambda_function = lambda_.Function(\n            self,\n            \"LambdaFunction\",\n            function_name=\"start-processing-rekognition-demo-lambda\",\n            runtime=lambda_.Runtime.PYTHON_3_10,\n            handler=\"index.lambda_handler\",\n            code=lambda_.Code.from_asset(\"lambdas/start_processing\"),\n            environment={\n                \"SNS_TOPIC_ARN\": rekognition_sns_topic.topic_arn,\n                \"SNS_ROLE_ARN\": rekognition_role.role_arn,\n            },\n        )\n\n        # Lambda which detects when a video has been processed by reckognition. It stracts the data of each celebrity identified\n        process_video_lambda = lambda_.Function(\n            self,\n            \"RekognitionLambda\",\n            function_name=\"process-video-rekognition-demo-lambda\",\n            runtime=lambda_.Runtime.PYTHON_3_10,\n            handler=\"index.lambda_handler\",\n            code=lambda_.Code.from_asset(\"lambdas/process_video\"),\n        )\n\n        # Grant permissions to the lambdas defined\n        start_processing_lambda_function.add_to_role_policy(s3_lambda_policy)\n        start_processing_lambda_function.add_to_role_policy(rekognition_lambda_policy)\n        start_processing_lambda_function.add_to_role_policy(pass_role_lambda_policy)\n\n        process_video_lambda.add_to_role_policy(rekognition_lambda_policy)\n\n        rekognition_sns_topic.grant_publish(process_video_lambda)\n        rekognition_sns_topic.add_subscription(sns_subs.LambdaSubscription(process_video_lambda))\n\n        # Automatically trigger lambda when new image is uploaded to S3\n        start_processing_lambda_function.add_event_source(\n            aws_lambda_event_sources.S3EventSource(\n                video_bucket, events=[s3.EventType.OBJECT_CREATED]\n            )\n        )", "language": "python"}
{"input": "CDK class TablePolicy for AWS resource management", "output": "export class TablePolicy extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-s3tables-alpha.TablePolicy';\n  /**\n   * The IAM PolicyDocument containing permissions represented by this policy.\n   */\n  public readonly document: iam.PolicyDocument;\n  /**\n   * @internal The underlying policy resource.\n   */\n  private readonly _resource: CfnTablePolicy;\n\n  constructor(scope: Construct, id: string, props: TablePolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Use default policy if not provided with props\n    this.document = props.resourcePolicy || new iam.PolicyDocument({});\n\n    this._resource = new CfnTablePolicy(this, id, {\n      tableArn: props.table.tableArn,\n      resourcePolicy: this.document,\n    });\n\n    if (props.removalPolicy) {\n      this._resource.applyRemovalPolicy(props.removalPolicy);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, KMS, WAF resources", "output": "export class AppSyncCdkStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const appSync2EventBridgeGraphQLApi = new CfnGraphQLApi(\n      this,\n      \"AppSync2EventBridgeApi\",\n      {\n        name: \"AppSync2EventBridge-API\",\n        authenticationType: \"API_KEY\"\n      }\n    );\n\n    new CfnApiKey(this, \"AppSync2EventBridgeApiKey\", {\n      apiId: appSync2EventBridgeGraphQLApi.attrApiId\n    });\n\n    const apiSchema = new CfnGraphQLSchema(this, \"ItemsSchema\", {\n      apiId: appSync2EventBridgeGraphQLApi.attrApiId,\n      definition: `type Event {\n        result: String\n      }\n\n      type Mutation {\n        putEvent(event: String!): Event\n      }\n\n      type Query {\n        getEvent: Event\n      }\n\n      schema {\n        query: Query\n        mutation: Mutation\n      }`\n    });\n\n    const appsyncEventBridgeRole = new Role(this, \"AppSyncEventBridgeRole\", {\n      assumedBy: new ServicePrincipal(\"appsync.amazonaws.com\")\n    });\n\n    appsyncEventBridgeRole.addToPolicy(\n      new PolicyStatement({\n        resources: [\"*\"],\n        actions: [\"events:Put*\"]\n      })\n    );\n\n    const dataSource = new CfnDataSource(this, \"ItemsDataSource\", {\n      apiId: appSync2EventBridgeGraphQLApi.attrApiId,\n      name: \"EventBridgeDataSource\",\n      type: \"HTTP\",\n      httpConfig: {\n        authorizationConfig: {\n          authorizationType: \"AWS_IAM\",\n          awsIamConfig: {\n            signingRegion: this.region,\n            signingServiceName: \"events\"\n          }\n        },\n        endpoint: \"https://events.\" + this.region + \".amazonaws.com/\"\n      },\n      serviceRoleArn: appsyncEventBridgeRole.roleArn\n    });\n\n    const putEventResolver = new CfnResolver(this, \"PutEventMutationResolver\", {\n      apiId: appSync2EventBridgeGraphQLApi.attrApiId,\n      typeName: \"Mutation\",\n      fieldName: \"putEvent\",\n      dataSourceName: dataSource.name,\n      requestMappingTemplate: `{\n        \"version\": \"2018-05-29\",\n        \"method\": \"POST\",\n        \"resourcePath\": \"/\",\n        \"params\": {\n          \"headers\": {\n            \"content-type\": \"application/x-amz-json-1.1\",\n            \"x-amz-target\":\"AWSEvents.PutEvents\"\n          },\n          \"body\": {\n            \"Entries\":[\n              {\n                \"Source\":\"appsync\",\n                \"EventBusName\": \"default\",\n                \"Detail\":\"{ \\\\\\\"event\\\\\\\": \\\\\\\"$ctx.arguments.event\\\\\\\"}\",\n                \"DetailType\":\"Event Bridge via GraphQL\"\n               }\n            ]\n          }\n        }\n      }`,\n      responseMappingTemplate: `## Raise a GraphQL field error in case of a datasource invocation error\n      #if($ctx.error)\n        $util.error($ctx.error.message, $ctx.error.type)\n      #end\n      ## if the response status code is not 200, then return an error. Else return the body **\n      #if($ctx.result.statusCode == 200)\n          ## If response is 200, return the body.\n          {\n            \"result\": \"$util.parseJson($ctx.result.body)\"\n          }\n      #else\n          ## If response is not 200, append the response to error block.\n          $utils.appendError($ctx.result.body, $ctx.result.statusCode)\n      #end`\n    });\n    putEventResolver.addDependency(apiSchema);\n\n    const echoLambda = new lambda.Function(this, \"echoFunction\", {\n      code: lambda.Code.fromInline(\n        \"exports.handler = (event, context) => { console.log(event); context.succeed(event); }\"\n      ),\n      handler: \"index.handler\",\n      runtime: lambda.Runtime.NODEJS_LATEST\n    });\n\n    const rule = new Rule(this, \"AppSyncEventBridgeRle\", {\n      eventPattern: {\n        source: [\"appsync\"]\n      }\n    });\n    rule.addTarget(new targets.LambdaFunction(echoLambda));\n  }\n}", "language": "typescript"}
{"input": "CDK class StepFunctionsRestApi for AWS resource management", "output": "export class StepFunctionsRestApi extends RestApi {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.StepFunctionsRestApi';\n\n  constructor(scope: Construct, id: string, props: StepFunctionsRestApiProps) {\n    if (props.defaultIntegration) {\n      throw new ValidationError('Cannot specify \"defaultIntegration\" since Step Functions integration is automatically defined', scope);\n    }\n\n    if ((props.stateMachine.node.defaultChild as sfn.CfnStateMachine).stateMachineType !== sfn.StateMachineType.EXPRESS) {\n      throw new ValidationError('State Machine must be of type \"EXPRESS\". Please use StateMachineType.EXPRESS as the stateMachineType', scope);\n    }\n\n    const stepfunctionsIntegration = StepFunctionsIntegration.startExecution(props.stateMachine, {\n      credentialsRole: props.role,\n      requestContext: props.requestContext,\n      path: props.path?? true,\n      querystring: props.querystring?? true,\n      headers: props.headers,\n      authorizer: props.authorizer,\n      useDefaultMethodResponses: props.useDefaultMethodResponses,\n    });\n\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.root.addMethod('ANY', stepfunctionsIntegration);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, EKS, Lake Formation resources", "output": "class ChartStack extends cdk.Stack {\n      constructor(scope: Construct, id: string, props: cdk.StackProps & { cluster: eks.Cluster }) {\n        super(scope, id, props);\n\n        const resource = new cdk.CfnResource(this, 'resource', { type: 'MyType' });\n        new eks.HelmChart(this, `chart-${id}`, { cluster: props.cluster, chart: resource.ref });\n      }\n    }", "language": "typescript"}
{"input": "Represents the Lambda Handler Code.", "output": "class Code {\n  /**\n   * Lambda handler code as an S3 object.\n   *\n   * Note: If `objectVersion` is not defined, the lambda will not be updated automatically if the code in the bucket is updated.\n   * This is because CDK/Cloudformation does not track changes on the source S3 Bucket. It is recommended to either use S3Code.fromAsset() instead or set objectVersion.\n   * @param bucket The S3 bucket\n   * @param key The object key\n   * @param objectVersion Optional S3 object version\n   */\n  public static fromBucket(bucket: s3.IBucket, key: string, objectVersion?: string): S3Code {\n    if (objectVersion === undefined) {\n      cdk.Annotations.of(bucket).addWarningV2(\n        '@aws-cdk/aws-lambda:codeFromBucketObjectVersionNotSpecified',\n        'objectVersion is not defined for S3Code.fromBucket(). The lambda will not be updated automatically if the code in the bucket is updated. ' +\n        'This is because CDK/Cloudformation does not track changes on the source S3 Bucket. It is recommended to either use S3Code.fromAsset() instead or set objectVersion.',\n      );\n    }\n\n    return new S3Code(bucket, key, objectVersion);\n  }\n\n  /**\n   * Lambda handler code as an S3 object.\n   *\n   * Note: If `options.objectVersion` is not defined, the lambda will not be updated automatically if the code in the bucket is updated.\n   * This is because CDK/Cloudformation does not track changes on the source S3 Bucket. It is recommended to either use S3Code.fromAsset() instead or set objectVersion.\n   * @param bucket The S3 bucket\n   * @param key The object key\n   * @param options Optional parameters for setting the code, current optional parameters to set here are\n   * 1. `objectVersion` to set S3 object version\n   * 2. `sourceKMSKey` to set KMS Key for encryption of code\n   */\n  public static fromBucketV2 (bucket: s3.IBucket, key: string, options?: BucketOptions): S3CodeV2 {\n    if (options?.objectVersion === undefined) {\n      cdk.Annotations.of(bucket).addWarningV2(\n        '@aws-cdk/aws-lambda:codeFromBucketObjectVersionNotSpecified',\n        'options.objectVersion is not defined for S3Code.fromBucketV2(). The lambda will not be updated automatically if the code in the bucket is updated. ' +\n        'This is because CDK/Cloudformation does not track changes on the source S3 Bucket. It is recommended to either use S3Code.fromAsset() instead or set options.objectVersion.',\n      );\n    }\n\n    return new S3CodeV2(bucket, key, options);\n  }\n\n  /**\n   * DEPRECATED\n   * @deprecated use `fromBucket`\n   */\n  public static bucket(bucket: s3.IBucket, key: string, objectVersion?: string): S3Code {\n    return this.fromBucket(bucket, key, objectVersion);\n  }\n\n  /**\n   * Inline code for Lambda handler\n   * @returns `LambdaInlineCode` with inline code.\n   * @param code The actual handler code (the resulting zip file cannot exceed 4MB)\n   */\n  public static fromInline(code: string): InlineCode {\n    return new InlineCode(code);\n  }\n\n  /**\n   * DEPRECATED\n   * @deprecated use `fromInline`\n   */\n  public static inline(code: string): InlineCode {\n    return this.fromInline(code);\n  }\n\n  /**\n   * Loads the function code from a local disk path.\n   *\n   * @param path Either a directory with the Lambda code bundle or a .zip file\n   */\n  public static fromAsset(path: string, options?: s3_assets.AssetOptions): AssetCode {\n    return new AssetCode(path, options);\n  }\n\n  /**\n   * Runs a command to build the code asset that will be used.\n   *\n   * @param output Where the output of the command will be directed, either a directory or a .zip file with the output Lambda code bundle\n   * * For example, if you use the command to run a build script (e.g., [ 'node', 'bundle_code.js' ]), and the build script generates a directory `/my/lambda/code`\n   * containing code that should be ran in a Lambda function, then output should be set to `/my/lambda/code`\n   * @param command The command which will be executed to generate the output, for example, [ 'node', 'bundle_code.js' ]\n   * @param options options for the custom command, and other asset options -- but bundling options are not allowed.\n   */\n  public static fromCustomCommand(\n    output: string,\n    command: string[],\n    options?: CustomCommandOptions,\n  ): AssetCode {\n    if (command.length === 0) {\n      throw new UnscopedValidationError('command must contain at least one argument. For example, [\"node\", \"buildFile.js\"].');\n    }\n\n    const cmd = command[0];\n    const commandArguments = command.splice(1);\n\n    const proc = options?.commandOptions === undefined\n      ? spawnSync(cmd, commandArguments) // use the default spawnSyncOptions\n      : spawnSync(cmd, commandArguments, options.commandOptions);\n\n    if (proc.error) {\n      throw new UnscopedValidationError(`Failed to execute custom command: ${proc.error}`);\n    }\n    if (proc.status !== 0) {\n      throw new UnscopedValidationError(`${command.join(' ')} exited with status: ${proc.status}\\n\\nstdout: ${proc.stdout?.toString().trim()}\\n\\nstderr: ${proc.stderr?.toString().trim()}`);\n    }\n\n    return new AssetCode(output, options);\n  }\n\n  /**\n   * Loads the function code from an asset created by a Docker build.\n   *\n   * By default, the asset is expected to be located at `/asset` in the\n   * image.\n   *\n   * @param path The path to the directory containing the Docker file\n   * @param options Docker build options\n   */\n  public static fromDockerBuild(path: string, options: DockerBuildAssetOptions = {}): AssetCode {\n    let imagePath = options.imagePath ?? '/asset/.';\n\n    // ensure imagePath ends with /. to copy the **content** at this path\n    if (imagePath.endsWith('/')) {\n      imagePath = `${imagePath}.`;\n    } else if (!imagePath.endsWith('/.')) {\n      imagePath = `${imagePath}/.`;\n    }\n\n    const assetPath = cdk.DockerImage\n      .fromBuild(path, options)\n      .cp(imagePath, options.outputPath);\n\n    return new AssetCode(assetPath);\n  }\n\n  /**\n   * DEPRECATED\n   * @deprecated use `fromAsset`\n   */\n  public static asset(path: string): AssetCode {\n    return this.fromAsset(path);\n  }\n\n  /**\n   * Creates a new Lambda source defined using CloudFormation parameters.\n   *\n   * @returns a new instance of `CfnParametersCode`\n   * @param props optional construction properties of `CfnParametersCode`\n   */\n  public static fromCfnParameters(props?: CfnParametersCodeProps): CfnParametersCode {\n    return new CfnParametersCode(props);\n  }\n\n  /**\n   * DEPRECATED\n   * @deprecated use `fromCfnParameters`\n   */\n  public static cfnParameters(props?: CfnParametersCodeProps): CfnParametersCode {\n    return this.fromCfnParameters(props);\n  }\n\n  /**\n   * Use an existing ECR image as the Lambda code.\n   * @param repository the ECR repository that the image is in\n   * @param props properties to further configure the selected image\n   */\n  public static fromEcrImage(repository: ecr.IRepository, props?: EcrImageCodeProps) {\n    return new EcrImageCode(repository, props);\n  }\n\n  /**\n   * Create an ECR image from the specified asset and bind it as the Lambda code.\n   * @param directory the directory from which the asset must be created\n   * @param props properties to further configure the selected image\n   */\n  public static fromAssetImage(directory: string, props: AssetImageCodeProps = {}) {\n    return new AssetImageCode(directory, props);\n  }\n\n  /**\n   * Determines whether this Code is inline code or not.\n   *\n   * @deprecated this value is ignored since inline is now determined based on the\n   * the `inlineCode` field of `CodeConfig` returned from `bind()`.\n   */\n  public abstract readonly isInline: boolean;\n\n  /**\n   * Called when the lambda or layer is initialized to allow this object to bind\n   * to the stack, add resources and have fun.\n   *\n   * @param scope The binding scope. Don't be smart about trying to down-cast or\n   * assume it's initialized. You may just use it as a construct scope.\n   */\n  public abstract bind(scope: Construct): CodeConfig;\n\n  /**\n   * Called after the CFN function resource has been created to allow the code\n   * class to bind to it. Specifically it's required to allow assets to add\n   * metadata for tooling like SAM CLI to be able to find their origins.\n   */\n  public bindToResource(_resource: cdk.CfnResource, _options?: ResourceBindOptions) {\n    return;\n  }\n}\n\n/**\n * Result of binding `Code` into a `Function`.\n */\nexport interface CodeConfig {\n  /**\n   * The location of the code in S3 (mutually exclusive with `inlineCode` and `image`).\n   * @default - code is not an s3 location\n   */\n  readonly s3Location?: s3.Location;\n\n  /**\n   * Inline code (mutually exclusive with `s3Location` and `image`).\n   * @default - code is not inline code\n   */\n  readonly inlineCode?: string;\n\n  /**\n   * Docker image configuration (mutually exclusive with `s3Location` and `inlineCode`).\n   * @default - code is not an ECR container image\n   */\n  readonly image?: CodeImageConfig;\n\n  /**\n   * The ARN of the KMS key used to encrypt the handler code.\n   * @default - the default server-side encryption with Amazon S3 managed keys(SSE-S3) key will be used.\n   */\n  readonly sourceKMSKeyArn?: string;\n}\n\n/**\n * Result of the bind when an ECR image is used.\n */\nexport interface CodeImageConfig {\n  /**\n   * URI to the Docker image.\n   */\n  readonly imageUri: string;\n\n  /**\n   * Specify or override the CMD on the specified Docker image or Dockerfile.\n   * This needs to be in the 'exec form', viz., `[ 'executable', 'param1', 'param2' ]`.\n   * @see https://docs.docker.com/engine/reference/builder/#cmd\n   * @default - use the CMD specified in the docker image or Dockerfile.\n   */\n  readonly cmd?: string[];\n\n  /**\n   * Specify or override the ENTRYPOINT on the specified Docker image or Dockerfile.\n   * An ENTRYPOINT allows you to configure a container that will run as an executable.\n   * This needs to be in the 'exec form', viz., `[ 'executable', 'param1', 'param2' ]`.\n   * @see https://docs.docker.com/engine/reference/builder/#entrypoint\n   * @default - use the ENTRYPOINT in the docker image or Dockerfile.\n   */\n  readonly entrypoint?: string[];\n\n  /**\n   * Specify or override the WORKDIR on the specified Docker image or Dockerfile.\n   * A WORKDIR allows you to configure the working directory the container will use.\n   * @see https://docs.docker.com/engine/reference/builder/#workdir\n   * @default - use the WORKDIR in the docker image or Dockerfile.\n   */\n  readonly workingDirectory?: string;\n}\n\n/**\n * Lambda code from an S3 archive.\n */\nexport class S3Code extends Code {\n  public readonly isInline = false;\n  private bucketName: string;\n\n  constructor(bucket: s3.IBucket, private key: string, private objectVersion?: string) {\n    super();\n\n    if (!bucket.bucketName) {\n      throw new ValidationError('bucketName is undefined for the provided bucket', bucket);\n    }\n\n    this.bucketName = bucket.bucketName;\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      s3Location: {\n        bucketName: this.bucketName,\n        objectKey: this.key,\n        objectVersion: this.objectVersion,\n      },\n    };\n  }\n}\n\n/**\n * Lambda code from an S3 archive. With option to set KMSKey for encryption.\n */\nexport class S3CodeV2 extends Code {\n  public readonly isInline = false;\n  private bucketName: string;\n\n  constructor(bucket: s3.IBucket, private key: string, private options?: BucketOptions) {\n    super();\n    if (!bucket.bucketName) {\n      throw new ValidationError('bucketName is undefined for the provided bucket', bucket);\n    }\n\n    this.bucketName = bucket.bucketName;\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      s3Location: {\n        bucketName: this.bucketName,\n        objectKey: this.key,\n        objectVersion: this.options?.objectVersion,\n      },\n      sourceKMSKeyArn: this.options?.sourceKMSKey?.keyRef.keyArn,\n    };\n  }\n}\n\n/**\n * Lambda code from an inline string.\n */\nexport class InlineCode extends Code {\n  public readonly isInline = true;\n\n  constructor(private code: string) {\n    super();\n\n    if (code.length === 0) {\n      throw new UnscopedValidationError('Lambda inline code cannot be empty');\n    }\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      inlineCode: this.code,\n    };\n  }\n}\n\n/**\n * Lambda code from a local directory.\n */\nexport class AssetCode extends Code {\n  public readonly isInline = false;\n  private asset?: s3_assets.Asset;\n\n  /**\n   * @param path The path to the asset file or directory.\n   */\n  constructor(public readonly path: string, private readonly options: s3_assets.AssetOptions = { }) {\n    super();\n  }\n\n  public bind(scope: Construct): CodeConfig {\n    // If the same AssetCode is used multiple times, retain only the first instantiation.\n    if (!this.asset) {\n      this.asset = new s3_assets.Asset(scope, 'Code', {\n        path: this.path,\n        deployTime: true,\n        ...this.options,\n      });\n    } else if (cdk.Stack.of(this.asset) !== cdk.Stack.of(scope)) {\n      throw new ValidationError(`Asset is already associated with another stack '${cdk.Stack.of(this.asset).stackName}'. ` +\n        'Create a new Code instance for every stack.', scope);\n    }\n\n    if (!this.asset.isZipArchive) {\n      throw new ValidationError(`Asset must be a .zip file or a directory (${this.path})`, scope);\n    }\n\n    return {\n      s3Location: {\n        bucketName: this.asset.s3BucketName,\n        objectKey: this.asset.s3ObjectKey,\n      },\n      sourceKMSKeyArn: this.options.sourceKMSKey?.keyRef.keyArn,\n    };\n  }\n\n  public bindToResource(resource: cdk.CfnResource, options: ResourceBindOptions = { }) {\n    if (!this.asset) {\n      throw new ValidationError('bindToResource() must be called after bind()', resource);\n    }\n\n    const resourceProperty = options.resourceProperty || 'Code';\n\n    // https://github.com/aws/aws-cdk/issues/1432\n    this.asset.addResourceMetadata(resource, resourceProperty);\n  }\n}\n\nexport interface ResourceBindOptions {\n  /**\n   * The name of the CloudFormation property to annotate with asset metadata.\n   * @see https://github.com/aws/aws-cdk/issues/1432\n   * @default Code\n   */\n  readonly resourceProperty?: string;\n}\n\n/**\n * Construction properties for `CfnParametersCode`.\n */\nexport interface CfnParametersCodeProps {\n  /**\n   * The CloudFormation parameter that represents the name of the S3 Bucket\n   * where the Lambda code will be located in.\n   * Must be of type 'String'.\n   *\n   * @default a new parameter will be created\n   */\n  readonly bucketNameParam?: cdk.CfnParameter;\n\n  /**\n   * The CloudFormation parameter that represents the path inside the S3 Bucket\n   * where the Lambda code will be located at.\n   * Must be of type 'String'.\n   *\n   * @default a new parameter will be created\n   */\n  readonly objectKeyParam?: cdk.CfnParameter;\n  /**\n   * The ARN of the KMS key used to encrypt the handler code.\n   * @default - the default server-side encryption with Amazon S3 managed keys(SSE-S3) key will be used.\n   */\n  readonly sourceKMSKey?: IKeyRef;\n}\n\n/**\n * Lambda code defined using 2 CloudFormation parameters.\n * Useful when you don't have access to the code of your Lambda from your CDK code, so you can't use Assets,\n * and you want to deploy the Lambda in a CodePipeline, using CloudFormation Actions -\n * you can fill the parameters using the `#assign` method.\n */\nexport class CfnParametersCode extends Code {\n  public readonly isInline = false;\n  private _bucketNameParam?: cdk.CfnParameter;\n  private _objectKeyParam?: cdk.CfnParameter;\n  private _sourceKMSKey?: IKeyRef;\n\n  constructor(props: CfnParametersCodeProps = {}) {\n    super();\n\n    this._bucketNameParam = props.bucketNameParam;\n    this._objectKeyParam = props.objectKeyParam;\n    this._sourceKMSKey = props.sourceKMSKey;\n  }\n\n  public bind(scope: Construct): CodeConfig {\n    if (!this._bucketNameParam) {\n      this._bucketNameParam = new cdk.CfnParameter(scope, 'LambdaSourceBucketNameParameter', {\n        type: 'String',\n      });\n    }\n\n    if (!this._objectKeyParam) {\n      this._objectKeyParam = new cdk.CfnParameter(scope, 'LambdaSourceObjectKeyParameter', {\n        type: 'String',\n      });\n    }\n\n    return {\n      s3Location: {\n        bucketName: this._bucketNameParam.valueAsString,\n        objectKey: this._objectKeyParam.valueAsString,\n      },\n      sourceKMSKeyArn: this._sourceKMSKey?.keyRef.keyArn,\n    };\n  }\n\n  /**\n   * Create a parameters map from this instance's CloudFormation parameters.\n   *\n   * It returns a map with 2 keys that correspond to the names of the parameters defined in this Lambda code,\n   * and as values it contains the appropriate expressions pointing at the provided S3 location\n   * (most likely, obtained from a CodePipeline Artifact by calling the `artifact.s3Location` method).\n   * The result should be provided to the CloudFormation Action\n   * that is deploying the Stack that the Lambda with this code is part of,\n   * in the `parameterOverrides` property.\n   *\n   * @param location the location of the object in S3 that represents the Lambda code\n   */\n  public assign(location: s3.Location): { [name: string]: any } {\n    const ret: { [name: string]: any } = {};\n    ret[this.bucketNameParam] = location.bucketName;\n    ret[this.objectKeyParam] = location.objectKey;\n    return ret;\n  }\n\n  public get bucketNameParam(): string {\n    if (this._bucketNameParam) {\n      return this._bucketNameParam.logicalId;\n    } else {\n      throw new UnscopedValidationError('Pass CfnParametersCode to a Lambda Function before accessing the bucketNameParam property');\n    }\n  }\n\n  public get objectKeyParam(): string {\n    if (this._objectKeyParam) {\n      return this._objectKeyParam.logicalId;\n    } else {\n      throw new UnscopedValidationError('Pass CfnParametersCode to a Lambda Function before accessing the objectKeyParam property');\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class AwsLint for AWS resource management", "output": "export class AwsLint extends ValidationRule {\n  public readonly name = 'awslint';\n\n  public validate(pkg: PackageJson) {\n    if (!isJSII(pkg)) {\n      return;\n    }\n\n    if (!isAWS(pkg)) {\n      return;\n    }\n\n    expectJSON(this.name, pkg, 'scripts.awslint', 'cdk-awslint');\n  }\n}", "language": "typescript"}
{"input": "CDK class AwsApi for AWS resource management", "output": "class AwsApi extends cdk.Stack {\n  public parameterUnderTest: StringParameter;\n  public encryptionKey: Key;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Force new deployment of 'cool-service' and stop 'dev-instance' at midnight everyday\n    const scheduleRule = new events.Rule(this, 'ScheduleRule', {\n      schedule: events.Schedule.cron({\n        hour: '0',\n        minute: '0',\n      }),\n    });\n\n    scheduleRule.addTarget(new targets.AwsApi({\n      service: 'ECS',\n      action: 'updateService',\n      parameters: {\n        service: 'cool-service',\n        forceNewDeployment: true,\n      },\n    }));\n\n    scheduleRule.addTarget(new targets.AwsApi({\n      service: 'RDS',\n      action: 'stopDBInstance',\n      parameters: {\n        DBInstanceIdentifier: 'dev-instance',\n      },\n    }));\n\n    // A custom rule & target to update a SSM Parameter\n    // In assertions a custom event will be fired to update the parameter value and the new value will be asserted on\n    this.parameterUnderTest = new StringParameter(this, 'TestParameter', {\n      parameterName: '/cdk-integ/aws-event-targets/aws-api-target/default-param',\n      stringValue: 'default-value',\n    });\n\n    const updateSsmRule = new events.Rule(this, 'UpdateSSMRule', {\n      eventPattern: {\n        source: ['cdk.integ'],\n        detailType: ['SSMUpdateParameter'],\n        detail: {\n          Name: [this.parameterUnderTest.parameterName],\n        },\n      },\n    });\n    updateSsmRule.node.addDependency(this.parameterUnderTest);\n\n    updateSsmRule.addTarget(new targets.AwsApi({\n      service: 'SSM',\n      action: 'putParameter',\n      parameters: {\n        Name: events.EventField.fromPath('$.detail.Name'),\n        Value: events.EventField.fromPath('$.detail.Value'),\n        Overwrite: true,\n      },\n    }));\n\n    // A custom rule & target to encrypt data with a KMS key\n    // This operation has no effect on state, so cannot be asserted.\n    this.encryptionKey = new Key(this, 'EncryptionKey');\n\n    const encryptData = new events.Rule(this, 'EncryptDataRule', {\n      eventPattern: {\n        source: ['cdk.integ'],\n        detailType: ['EncryptData'],\n        detail: {\n          KeyId: [this.encryptionKey.keyId],\n        },\n      },\n    });\n    this.encryptionKey.node.addDependency(this.encryptionKey);\n\n    encryptData.addTarget(new targets.AwsApi({\n      service: 'KMS',\n      action: 'encrypt',\n      parameters: {\n        KeyId: events.EventField.fromPath('$.detail.KeyId'),\n        Plaintext: events.EventField.fromPath('$.detail.Plaintext'),\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class InlineComponentData for AWS resource management", "output": "class InlineComponentData extends ComponentData {\n  protected readonly data: string;\n\n  public constructor(data: string) {\n    super();\n\n    this.data = data;\n  }\n\n  /**\n   * The rendered component data text, for use in CloudFormation\n   */\n  public render(): ComponentDataConfig {\n    return { data: this.data };\n  }\n}", "language": "typescript"}
{"input": "Configuration for filtering instance types that a capacity provider can use. Instances types can either be allowed or excluded, not both.", "output": "export class InstanceTypeFilter {\n  /**\n   * Creates an instance type filter that allows only the specified instance types.\n   *\n   * @param instanceTypes A list of instance types that the capacity provider is allowed to use.\n   */\n  public static allow(instanceTypes: ec2.InstanceType[]) {\n    return new InstanceTypeFilter({ instanceTypes, isAllow: true });\n  }\n\n  /**\n   * Creates an instance type filter that excludes the specified instance types.\n   *\n   * @param instanceTypes A list of instance types that the capacity provider should not use.\n   */\n  public static exclude(instanceTypes: ec2.InstanceType[]) {\n    return new InstanceTypeFilter({ instanceTypes, isAllow: false });\n  }\n\n  /**\n   * A list of instance types that the capacity provider is allowed to use.\n   */\n  public readonly allowedInstanceTypes?: ec2.InstanceType[];\n\n  /**\n   * A list of instance types that the capacity provider should not use.\n   */\n  public readonly excludedInstanceTypes?: ec2.InstanceType[];\n\n  /**\n   * Creates a new InstanceTypeFilter.\n   *\n   * @param instanceTypes The instance type configuration\n   */\n  private constructor(options: { instanceTypes: ec2.InstanceType[]; isAllow: boolean }) {\n    if (options.isAllow) {\n      this.allowedInstanceTypes = options.instanceTypes;\n    } else {\n      this.excludedInstanceTypes = options.instanceTypes;\n    }\n  }\n}", "language": "typescript"}
{"input": "Pre stack for imported resources", "output": "class PreStack extends cdk.Stack {\n  public readonly role: iam.Role;\n  public readonly asset: DockerImageAsset;\n\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    this.role = new iam.Role(this, 'ExecutionRole', {\n      assumedBy: new iam.ServicePrincipal('bedrock-agentcore.amazonaws.com'),\n    });\n    this.asset = new DockerImageAsset(this, 'TestAsset', {\n      directory: path.join(__dirname, 'testArtifact'),\n    });\n    this.asset.repository.grantPull(this.role);\n  }\n}", "language": "typescript"}
{"input": "CDK class R53ResolverVPC for AWS resource management", "output": "export class R53ResolverVPC extends Construct {\n  public vpc: ec2.Vpc;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    // @see https://docs.aws.amazon.com/cdk/api/v2/docs/aws-cdk-lib.aws_ec2.Vpc.html\n    this.vpc = new ec2.Vpc(this, \"R53ResolverTestVPC\", {\n      ipAddresses: ec2.IpAddresses.cidr(\"10.24.34.0/23\"),\n      subnetConfiguration: [\n        {\n          cidrMask: 24,\n          name: \"Private\",\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n        },\n      ],\n      maxAzs: 2,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedGateway for AWS resource management", "output": "class ImportedGateway extends GatewayBase {\n      public readonly gatewayArn = attrs.gatewayArn;\n      public readonly gatewayId = attrs.gatewayId;\n      public readonly name = attrs.gatewayName;\n      public readonly description = undefined;\n      public readonly protocolConfiguration: IGatewayProtocolConfig;\n      public readonly authorizerConfiguration: IGatewayAuthorizerConfig;\n      public readonly exceptionLevel = undefined;\n      public readonly kmsKey = undefined;\n      public readonly role = attrs.role;\n      public readonly gatewayUrl = undefined;\n      public readonly status = undefined;\n      public readonly statusReason = undefined;\n      public readonly createdAt = undefined;\n      public readonly updatedAt = undefined;\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n        // Create placeholder protocol and authorizer configurations\n        this.protocolConfiguration = new McpProtocolConfiguration({\n          supportedVersions: [MCPProtocolVersion.MCP_2025_03_26],\n          searchType: McpGatewaySearchType.SEMANTIC,\n          instructions: 'Imported gateway',\n        });\n        this.authorizerConfiguration = GatewayAuthorizer.usingAwsIam();\n      }\n    }", "language": "typescript"}
{"input": "CDK class AwsCliLayer for AWS resource management", "output": "export class AwsCliLayer extends lambda.LayerVersion {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.lambda-layer-awscli.AwsCliLayer';\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id, {\n      code: lambda.Code.fromAsset(ASSET_FILE, {\n        // we hash the layer directory (it contains the tools versions and Dockerfile) because hashing the zip is non-deterministic\n        assetHash: FileSystem.fingerprint(LAYER_SOURCE_DIR),\n      }),\n      description: '/opt/awscli/aws',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Cloud9Env for AWS resource management", "output": "class Cloud9Env extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', {\n      restrictDefaultSecurityGroup: false,\n      maxAzs: 2,\n      natGateways: 1,\n    });\n\n    const role = new Role(this, 'Cloud9OwnerRole', {\n      roleName: 'Cloud9OwnerRole',\n      description: 'Created as part of the integration tests for the Cloud9 CDK construct',\n      assumedBy: new AnyPrincipal(),\n    });\n\n    const accountId = Stack.of(this).account;\n    const roleSessionName = 'a-test-session';\n    const assumedRoleString = `${role.roleName}/${roleSessionName}`;\n\n    // create a cloud9 ec2 environment in a new VPC\n    const c9env = new cloud9.Ec2Environment(this, 'C9Env', {\n      vpc,\n      imageId: cloud9.ImageId.AMAZON_LINUX_2,\n      owner: cloud9.Owner.assumedRole(accountId, assumedRoleString),\n    });\n    new CfnOutput(this, 'URL', { value: c9env.ideUrl });\n    new CfnOutput(this, 'ARN', { value: c9env.ec2EnvironmentArn });\n  }\n}", "language": "typescript"}
{"input": "CDK class SpecRestApi for AWS resource management", "output": "export class SpecRestApi extends RestApiBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.SpecRestApi';\n\n  /**\n   * The ID of this API Gateway RestApi.\n   */\n  public readonly restApiId: string;\n\n  /**\n   * The resource ID of the root resource.\n   *\n   * @attribute\n   */\n  public readonly restApiRootResourceId: string;\n\n  public readonly root: IResource;\n\n  constructor(scope: Construct, id: string, props: SpecRestApiProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    const apiDefConfig = props.apiDefinition.bind(this);\n    this.resourcePolicy = props.policy;\n    const resource = new CfnRestApi(this, 'Resource', {\n      name: this.restApiName,\n      policy: Lazy.any({ produce: () => this.resourcePolicy }),\n      failOnWarnings: props.failOnWarnings,\n      minimumCompressionSize: props.minCompressionSize?.toBytes(),\n      binaryMediaTypes: props.binaryMediaTypes,\n      body: apiDefConfig.inlineDefinition ?? undefined,\n      bodyS3Location: apiDefConfig.inlineDefinition ? undefined : apiDefConfig.s3Location,\n      endpointConfiguration: this._configureEndpoints(props),\n      parameters: props.parameters,\n      disableExecuteApiEndpoint: props.disableExecuteApiEndpoint,\n      mode: props.mode,\n    });\n\n    props.apiDefinition.bindAfterCreate(this, this);\n\n    this.node.defaultChild = resource;\n    this.restApiId = resource.ref;\n    this.restApiRootResourceId = resource.attrRootResourceId;\n    this.root = new RootResource(this, {}, this.restApiRootResourceId);\n\n    this._configureCloudWatchRole(resource, props.cloudWatchRole, props.cloudWatchRoleRemovalPolicy);\n\n    this._configureDeployment(props);\n    if (props.domainName) {\n      this.addDomainName('CustomDomain', props.domainName);\n    }\n  }\n\n  /**\n   * Adds a statement to the resource policy associated with this rest api.\n   * A resource policy will be automatically created upon the first call to `addToResourcePolicy`.\n   *\n   * Note that this does not work with imported rest api.\n   *\n   * @param statement The policy statement to add\n   */\n  @MethodMetadata()\n  public addToResourcePolicy(statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n    this.resourcePolicy = this.resourcePolicy ?? new iam.PolicyDocument();\n    this.resourcePolicy.addStatements(statement);\n\n    return { statementAdded: true, policyDependable: this };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, KMS, WAF, CloudFormation resources", "output": "class TestStack extends Stack {\n  public readonly sourceBucket: s3.Bucket;\n  public readonly destinationBucket1: s3.Bucket;\n  public readonly destinationBucket2: s3.Bucket;\n\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.destinationBucket1 = new s3.Bucket(this, 'DestinationBucket1', {\n      versioned: true,\n      autoDeleteObjects: true,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    this.destinationBucket2 = new s3.Bucket(this, 'DestinationBucket2', {\n      versioned: true,\n      autoDeleteObjects: true,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const destinationKmsKey = new kms.Key(this, 'DestinationKmsKey', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    const sourceKmsKey = new kms.Key(this, 'SourceKmsKey', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    this.sourceBucket = new s3.Bucket(this, 'SourceBucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n      versioned: true,\n      encryptionKey: sourceKmsKey,\n      replicationRules: [\n        {\n          destination: this.destinationBucket1,\n          priority: 2,\n          sseKmsEncryptedObjects: true,\n          kmsKey: destinationKmsKey,\n          replicationTimeControl: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          metrics: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n        },\n        {\n          destination: this.destinationBucket2,\n          replicationTimeControl: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          metrics: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          kmsKey: destinationKmsKey,\n          storageClass: s3.StorageClass.INFREQUENT_ACCESS,\n          sseKmsEncryptedObjects: true,\n          replicaModifications: true,\n          priority: 1,\n          deleteMarkerReplication: true,\n          id: 'full-settings-rule',\n          filter: {\n            prefix: 'prefix',\n          },\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class GrantReadAllTablesTest for AWS resource management", "output": "class GrantReadAllTablesTest extends GrantTestBase {\n  tableBucketName = 'grant-read-bucket-all-tables';\n  type = TestType.ALL_TABLES;\n  actions = perms.TABLE_BUCKET_READ_ACCESS;\n  grantAccess() {\n    this.tableBucket.grantRead(new iam.ServicePrincipal(PRINCIPAL), WILDCARD);\n  }\n}", "language": "typescript"}
{"input": "CDK class BlockPublicAccess for AWS resource management", "output": "export class BlockPublicAccess {\n  /**\n   * Use this option if you want to ensure every public access method is blocked.\n   * However keep in mind that this is the default state of an S3 bucket, and leaving blockPublicAccess undefined would also work.\n   */\n  public static readonly BLOCK_ALL = new BlockPublicAccess({\n    blockPublicAcls: true,\n    blockPublicPolicy: true,\n    ignorePublicAcls: true,\n    restrictPublicBuckets: true,\n  });\n\n  /**\n   *\n   * @deprecated Use `BLOCK_ACLS_ONLY` instead.\n   */\n  public static readonly BLOCK_ACLS = new BlockPublicAccess({\n    blockPublicAcls: true,\n    ignorePublicAcls: true,\n  });\n\n  /**\n   * Use this option if you want to only block the ACLs, using this will set blockPublicPolicy and restrictPublicBuckets to false.\n   */\n  public static readonly BLOCK_ACLS_ONLY = new BlockPublicAccess({\n    blockPublicAcls: true,\n    blockPublicPolicy: false,\n    ignorePublicAcls: true,\n    restrictPublicBuckets: false,\n  });\n\n  public blockPublicAcls: boolean | undefined;\n  public blockPublicPolicy: boolean | undefined;\n  public ignorePublicAcls: boolean | undefined;\n  public restrictPublicBuckets: boolean | undefined;\n\n  constructor(options: BlockPublicAccessOptions) {\n    this.blockPublicAcls = options.blockPublicAcls;\n    this.blockPublicPolicy = options.blockPublicPolicy;\n    this.ignorePublicAcls = options.ignorePublicAcls;\n    this.restrictPublicBuckets = options.restrictPublicBuckets;\n  }\n}", "language": "typescript"}
{"input": "Use the AWS account into which a stack is deployed as the principal entity in a policy", "output": "export class AccountRootPrincipal extends AccountPrincipal {\n  constructor() {\n    super(new StackDependentToken(stack => stack.account).toString());\n  }\n\n  public toString() {\n    return 'AccountRootPrincipal()';\n  }\n}", "language": "typescript"}
{"input": "CDK class WaiterStateMachine for AWS resource management", "output": "export class WaiterStateMachine extends Construct {\n  /**\n   * The ARN of the statemachine\n   */\n  public readonly stateMachineArn: string;\n\n  /**\n   * The IAM Role ARN of the role used by the state machine\n   */\n  public readonly roleArn: string;\n\n  /**\n   * The AssertionsProvide that handles async requests\n   */\n  public readonly isCompleteProvider: AssertionsProvider;\n\n  constructor(scope: Construct, id: string, props: WaiterStateMachineProps = {}) {\n    super(scope, id);\n    const interval = props.interval || Duration.seconds(5);\n    const totalTimeout = props.totalTimeout || Duration.minutes(30);\n    const maxAttempts = calculateMaxRetries(totalTimeout.toSeconds(), interval.toSeconds(), props.backoffRate ?? 1);\n\n    if (Math.round(maxAttempts) !== maxAttempts) {\n      throw new Error(`Cannot determine retry count since totalTimeout=${totalTimeout.toSeconds()}s is not integrally dividable by queryInterval=${interval.toSeconds()}s`);\n    }\n\n    this.isCompleteProvider = new AssertionsProvider(this, 'IsCompleteProvider', {\n      handler: 'index.isComplete',\n      uuid: '76b3e830-a873-425f-8453-eddd85c86925',\n    });\n\n    const timeoutProvider = new AssertionsProvider(this, 'TimeoutProvider', {\n      handler: 'index.onTimeout',\n      uuid: '5c1898e0-96fb-4e3e-95d5-f6c67f3ce41a',\n    });\n\n    const role = new CfnResource(this, 'Role', {\n      type: 'AWS::IAM::Role',\n      properties: {\n        AssumeRolePolicyDocument: {\n          Version: '2012-10-17',\n          Statement: [{ Action: 'sts:AssumeRole', Effect: 'Allow', Principal: { Service: 'states.amazonaws.com' } }],\n        },\n        Policies: [\n          {\n            PolicyName: 'InlineInvokeFunctions',\n            PolicyDocument: {\n              Version: '2012-10-17',\n              Statement: [{\n                Action: 'lambda:InvokeFunction',\n                Effect: 'Allow',\n                Resource: [\n                  this.isCompleteProvider.serviceToken,\n                  timeoutProvider.serviceToken,\n                ],\n              }],\n            },\n          },\n        ],\n      },\n    });\n\n    const definition = Stack.of(this).toJsonString({\n      StartAt: 'framework-isComplete-task',\n      States: {\n        'framework-isComplete-task': {\n          End: true,\n          Retry: [{\n            ErrorEquals: ['States.ALL'],\n            IntervalSeconds: interval.toSeconds(),\n            MaxAttempts: maxAttempts,\n            BackoffRate: props.backoffRate ?? 1,\n          }],\n          Catch: [{\n            ErrorEquals: ['States.ALL'],\n            Next: 'framework-onTimeout-task',\n          }],\n          Type: 'Task',\n          Resource: this.isCompleteProvider.serviceToken,\n        },\n        'framework-onTimeout-task': {\n          End: true,\n          Type: 'Task',\n          Resource: timeoutProvider.serviceToken,\n        },\n      },\n    });\n\n    const resource = new CfnResource(this, 'Resource', {\n      type: 'AWS::StepFunctions::StateMachine',\n      properties: {\n        DefinitionString: definition,\n        RoleArn: role.getAtt('Arn'),\n      },\n    });\n    resource.node.addDependency(role);\n\n    this.stateMachineArn = resource.ref;\n    this.roleArn = role.getAtt('Arn').toString();\n    this.isCompleteProvider.grantInvoke(this.roleArn);\n    timeoutProvider.grantInvoke(this.roleArn);\n  }\n}", "language": "typescript"}
{"input": "Repository must be our GitHub repo", "output": "export class RepositoryCorrect extends ValidationRule {\n  public readonly name = 'package-info/repository';\n\n  public validate(pkg: PackageJson): void {\n    expectJSON(this.name, pkg, 'repository.type', 'git');\n    expectJSON(this.name, pkg, 'repository.url', 'https://github.com/aws/aws-cdk.git');\n    const pkgDir = path.relative(monoRepoRoot(), pkg.packageRoot);\n    // Enforcing '/' separator for builds to work in Windows.\n    const osPkgDir = pkgDir.split(path.sep).join('/');\n    expectJSON(this.name, pkg, 'repository.directory', osPkgDir);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function resolver", "output": "const resolver = (props: Expression) => {\n      const propValue = expr.get(props, name);\n      // Prop can be of type IResolvable | Array<IResolvable | CfnProperty>\n      const arrayType = resolvableType.unionOfTypes?.find(t => t.arrayOfType)?.arrayOfType;\n\n      let flattenCall;\n      if (arrayType) {\n        const mapper = this.createMapperLambda(arrayType, expr.ident(functionName).call(expr.ident('item')));\n        flattenCall = CDK_CORE.mapArrayInPlace.call(propValue, mapper);\n      } else {\n        flattenCall = expr.ident(functionName).call(propValue);\n      }\n\n      const condition = optional\n        ? expr.cond(expr.not(propValue)).then(expr.UNDEFINED).else(flattenCall)\n        : flattenCall;\n\n      return arrayType\n        ? expr.cond(CDK_CORE.isResolvableObject(propValue)).then(propValue).else(condition)\n        : condition;\n    }", "language": "typescript"}
{"input": "CDK class AccessKeysRotated for AWS resource management", "output": "export class AccessKeysRotated extends ManagedRule {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.AccessKeysRotated';\n\n  constructor(scope: Construct, id: string, props: AccessKeysRotatedProps = {}) {\n    super(scope, id, {\n      ...props,\n      identifier: ManagedRuleIdentifiers.ACCESS_KEYS_ROTATED,\n      inputParameters: {\n        ...props.maxAge\n          ? {\n            maxAccessKeyAge: props.maxAge.toDays(),\n          }\n          : {},\n      },\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class NetworkAcl for AWS resource management", "output": "export class NetworkAcl extends NetworkAclBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.NetworkAcl';\n\n  /**\n   * Import an existing NetworkAcl into this app.\n   */\n  public static fromNetworkAclId(scope: Construct, id: string, networkAclId: string): INetworkAcl {\n    class Import extends NetworkAclBase {\n      public readonly networkAclId = networkAclId;\n    }\n\n    return new Import(scope, id);\n  }\n\n  /**\n   * The ID of the NetworkACL\n   *\n   * @attribute\n   */\n  public readonly networkAclId: string;\n\n  /**\n   * The VPC ID for this NetworkACL\n   *\n   * @attribute\n   */\n  public readonly networkAclVpcId: string;\n\n  private readonly networkAcl: CfnNetworkAcl;\n  private readonly vpc: IVpc;\n\n  constructor(scope: Construct, id: string, props: NetworkAclProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.vpc = props.vpc;\n\n    Tags.of(this).add(NAME_TAG, props.networkAclName || this.node.path);\n\n    this.networkAcl = new CfnNetworkAcl(this, 'Resource', {\n      vpcId: props.vpc.vpcId,\n    });\n\n    this.networkAclId = this.networkAcl.ref;\n    this.networkAclVpcId = this.networkAcl.vpcId;\n\n    if (props.subnetSelection !== undefined) {\n      this.associateWithSubnet('DefaultAssociation', props.subnetSelection);\n    }\n  }\n\n  /**\n   * Associate the ACL with a given set of subnets\n   */\n  @MethodMetadata()\n  public associateWithSubnet(id: string, selection: SubnetSelection) {\n    const subnets = this.vpc.selectSubnets(selection);\n    for (const subnet of subnets.subnets) {\n      subnet.associateNetworkAcl(id, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class CallApiGatewayHttpApiEndpoint for AWS resource management", "output": "export class CallApiGatewayHttpApiEndpoint extends CallApiGatewayEndpointBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-stepfunctions-tasks.CallApiGatewayHttpApiEndpoint';\n\n  /**\n   * Call HTTP API endpoint as a Task using JSONPath\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-api-gateway.html\n   */\n  public static jsonPath(scope: Construct, id: string, props: CallApiGatewayHttpApiEndpointJsonPathProps) {\n    return new CallApiGatewayHttpApiEndpoint(scope, id, props);\n  }\n  /**\n   * Call HTTP API endpoint as a Task using JSONata\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-api-gateway.html\n   */\n  public static jsonata(scope: Construct, id: string, props: CallApiGatewayHttpApiEndpointJsonataProps) {\n    return new CallApiGatewayHttpApiEndpoint(scope, id, {\n      ...props,\n      queryLanguage: sfn.QueryLanguage.JSONATA,\n    });\n  }\n  protected readonly taskMetrics?: sfn.TaskMetricsConfig | undefined;\n  protected readonly taskPolicies?: iam.PolicyStatement[] | undefined;\n\n  protected readonly apiEndpoint: string;\n  protected readonly arnForExecuteApi: string;\n  protected readonly stageName?: string;\n\n  constructor(scope: Construct, id: string, private readonly props: CallApiGatewayHttpApiEndpointProps) {\n    super(scope, id, props);\n\n    this.apiEndpoint = this.getApiEndpoint();\n    this.arnForExecuteApi = this.getArnForExecuteApi();\n    this.stageName = props.stageName;\n\n    this.taskPolicies = this.createPolicyStatements();\n  }\n\n  private getApiEndpoint(): string {\n    const apiStack = this.props.apiStack;\n    return `${this.props.apiId}.execute-api.${apiStack.region}.${apiStack.urlSuffix}`;\n  }\n\n  private getArnForExecuteApi(): string {\n    const { apiId, stageName, method, apiPath } = this.props;\n\n    return this.props.apiStack.formatArn({\n      service: 'execute-api',\n      resource: apiId,\n      arnFormat: cdk.ArnFormat.SLASH_RESOURCE_NAME,\n      resourceName: `${stageName}/${method}${apiPath}`,\n    });\n  }\n}", "language": "typescript"}
{"input": "Returns true if a specified string matches at least one value in a list of strings.", "output": "class FnContains extends FnConditionBase {\n  /**\n   * Creates an ``Fn::Contains`` function.\n   * @param listOfStrings A list of strings, such as \"A\", \"B\", \"C\".\n   * @param value A string, such as \"A\", that you want to compare against a list of strings.\n   */\n  constructor(listOfStrings: any, value: string) {\n    super('Fn::Contains', [listOfStrings, value]);\n  }\n}", "language": "typescript"}
{"input": "Represents the App Runner service source.", "output": "class Source {\n  /**\n   * Source from the GitHub repository.\n   */\n  public static fromGitHub(props: GithubRepositoryProps): GithubSource {\n    return new GithubSource(props);\n  }\n\n  /**\n   * Source from the ECR repository.\n   */\n  public static fromEcr(props: EcrProps): EcrSource {\n    return new EcrSource(props);\n  }\n\n  /**\n   * Source from the ECR Public repository.\n   */\n  public static fromEcrPublic(props: EcrPublicProps): EcrPublicSource {\n    return new EcrPublicSource(props);\n  }\n\n  /**\n   * Source from local assets.\n   */\n  public static fromAsset(props: AssetProps): AssetSource {\n    return new AssetSource(props);\n  }\n\n  /**\n   * Called when the Job is initialized to allow this object to bind.\n   */\n  public abstract bind(scope: Construct): SourceConfig;\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, CodeBuild, ECR resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const ecrRepository = new ecr.Repository(this, 'MyRepo');\n\n    new codebuild.Project(this, 'MyProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: ['ls'],\n          },\n        },\n      }),\n      grantReportGroupPermissions: false,\n      /// !show\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.fromEcrRepository(ecrRepository, 'v1.0'),\n      },\n      /// !hide\n    });\n  }\n}", "language": "typescript"}
{"input": "A principal that represents an AWS Organization", "output": "export class OrganizationPrincipal extends PrincipalBase {\n  /**\n   *\n   * @param organizationId The unique identifier (ID) of an organization (i.e. o-12345abcde)\n   * It must match regex pattern ^o-[a-z0-9]{10,32}$\n   * @see https://docs.aws.amazon.com/organizations/latest/APIReference/API_Organization.html\n   */\n  constructor(public readonly organizationId: string) {\n    super();\n\n    // We can only validate if it's a literal string (not a token)\n    if (!cdk.Token.isUnresolved(organizationId)) {\n      if (!organizationId.match(/^o-[a-z0-9]{10,32}$/)) {\n        throw new UnscopedValidationError(`Expected Organization ID must match regex pattern ^o-[a-z0-9]{10,32}$, received ${organizationId}`);\n      }\n    }\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment(\n      { AWS: ['*'] },\n      { StringEquals: { 'aws:PrincipalOrgID': this.organizationId } },\n    );\n  }\n\n  public toString() {\n    return `OrganizationPrincipal(${this.organizationId})`;\n  }\n\n  public dedupeString(): string | undefined {\n    return `OrganizationPrincipal:${this.organizationId}`;\n  }\n}\n\n/**\n * A policy principal for canonicalUserIds - useful for S3 bucket policies that use\n * Origin Access identities.\n *\n * See https://docs.aws.amazon.com/general/latest/gr/acct-identifiers.html\n *\n * and\n *\n * https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html\n *\n * for more details.\n *\n */\nexport class CanonicalUserPrincipal extends PrincipalBase {\n  /**\n   *\n   * @param canonicalUserId unique identifier assigned by AWS for every account.\n   *   root user and IAM users for an account all see the same ID.\n   *   (i.e. 79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be)\n   */\n  constructor(public readonly canonicalUserId: string) {\n    super();\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ CanonicalUser: [this.canonicalUserId] });\n  }\n\n  public toString() {\n    return `CanonicalUserPrincipal(${this.canonicalUserId})`;\n  }\n\n  public dedupeString(): string | undefined {\n    return `CanonicalUserPrincipal:${this.canonicalUserId}`;\n  }\n}\n\n/**\n * Principal entity that represents a federated identity provider such as Amazon Cognito,\n * that can be used to provide temporary security credentials to users who have been authenticated.\n * Additional condition keys are available when the temporary security credentials are used to make a request.\n * You can use these keys to write policies that limit the access of federated users.\n *\n * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_iam-condition-keys.html#condition-keys-wif\n */\nexport class FederatedPrincipal extends PrincipalBase {\n  public readonly assumeRoleAction: string;\n\n  /**\n   * The conditions under which the policy is in effect.\n   * @see https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html\n   */\n  public readonly conditions: Conditions;\n\n  /**\n   *\n   * @param federated federated identity provider (i.e. 'cognito-identity.amazonaws.com' for users authenticated through Cognito)\n   * @param sessionTags Whether to enable session tagging (see https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html)\n   */\n  constructor(\n    public readonly federated: string,\n    conditions: Conditions = {},\n    assumeRoleAction: string = 'sts:AssumeRole') {\n    super();\n\n    this.conditions = conditions;\n    this.assumeRoleAction = assumeRoleAction;\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ Federated: [this.federated] }, this.conditions);\n  }\n\n  public toString() {\n    return `FederatedPrincipal(${this.federated})`;\n  }\n\n  public dedupeString(): string | undefined {\n    return `FederatedPrincipal:${this.federated}:${this.assumeRoleAction}:${JSON.stringify(this.conditions)}`;\n  }\n}\n\n/**\n * A principal that represents a federated identity provider as Web Identity such as Cognito, Amazon,\n * Facebook, Google, etc.\n */\nexport class WebIdentityPrincipal extends FederatedPrincipal {\n  /**\n   *\n   * @param identityProvider identity provider (i.e. 'cognito-identity.amazonaws.com' for users authenticated through Cognito)\n   * @param conditions The conditions under which the policy is in effect.\n   *   See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   * @param sessionTags Whether to enable session tagging (see https://docs.aws.amazon.com/IAM/latest/UserGuide/id_session-tags.html)\n   */\n  constructor(identityProvider: string, conditions: Conditions = {}) {\n    super(identityProvider, conditions ?? {}, 'sts:AssumeRoleWithWebIdentity');\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ Federated: [this.federated] }, this.conditions);\n  }\n\n  public toString() {\n    return `WebIdentityPrincipal(${this.federated})`;\n  }\n}\n\n/**\n * A principal that represents a federated identity provider as from a OpenID Connect provider.\n */\nexport class OpenIdConnectPrincipal extends WebIdentityPrincipal {\n  /**\n   *\n   * @param openIdConnectProvider OpenID Connect provider\n   * @param conditions The conditions under which the policy is in effect.\n   *   See [the IAM documentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).\n   */\n  constructor(openIdConnectProvider: IOIDCProviderRef, conditions: Conditions = {}) {\n    super(openIdConnectProvider.oidcProviderRef.oidcProviderArn, conditions ?? {});\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({ Federated: [this.federated] }, this.conditions);\n  }\n\n  public toString() {\n    return `OpenIdConnectPrincipal(${this.federated})`;\n  }\n}\n\n/**\n * Principal entity that represents a SAML federated identity provider\n */\nexport class SamlPrincipal extends FederatedPrincipal {\n  constructor(samlProvider: ISAMLProviderRef, conditions: Conditions) {\n    super(samlProvider.samlProviderRef.samlProviderArn, conditions, 'sts:AssumeRoleWithSAML');\n  }\n\n  public toString() {\n    return `SamlPrincipal(${this.federated})`;\n  }\n}\n\n/**\n * Principal entity that represents a SAML federated identity provider for\n * programmatic and AWS Management Console access.\n */\nexport class SamlConsolePrincipal extends SamlPrincipal {\n  constructor(samlProvider: ISamlProvider, conditions: Conditions = {}) {\n    super(samlProvider, {\n      ...conditions,\n      StringEquals: {\n        'SAML:aud': RegionInfo.get(cdk.Stack.of(samlProvider).region).samlSignOnUrl ?? 'https://signin.aws.amazon.com/saml',\n      },\n    });\n  }\n\n  public toString() {\n    return `SamlConsolePrincipal(${this.federated})`;\n  }\n}\n\n/**\n * Use the AWS account into which a stack is deployed as the principal entity in a policy\n */\nexport class AccountRootPrincipal extends AccountPrincipal {\n  constructor() {\n    super(new StackDependentToken(stack => stack.account).toString());\n  }\n\n  public toString() {\n    return 'AccountRootPrincipal()';\n  }\n}\n\n/**\n * A principal representing all AWS identities in all accounts\n *\n * Some services behave differently when you specify `Principal: '*'`\n * or `Principal: { AWS: \"*\" }` in their resource policy.\n *\n * `AnyPrincipal` renders to `Principal: { AWS: \"*\" }`. This is correct\n * most of the time, but in cases where you need the other principal,\n * use `StarPrincipal` instead.\n */\nexport class AnyPrincipal extends ArnPrincipal {\n  constructor() {\n    super('*');\n  }\n\n  public toString() {\n    return 'AnyPrincipal()';\n  }\n}\n\n/**\n * A principal representing all identities in all accounts\n * @deprecated use `AnyPrincipal`\n */\nexport class Anyone extends AnyPrincipal { }\n\n/**\n * A principal that uses a literal '*' in the IAM JSON language\n *\n * Some services behave differently when you specify `Principal: \"*\"`\n * or `Principal: { AWS: \"*\" }` in their resource policy.\n *\n * `StarPrincipal` renders to `Principal: *`. Most of the time, you\n * should use `AnyPrincipal` instead.\n */\nexport class StarPrincipal extends PrincipalBase {\n  public readonly policyFragment: PrincipalPolicyFragment = {\n    principalJson: { [LITERAL_STRING_KEY]: ['*'] },\n    conditions: {},\n  };\n\n  public toString() {\n    return 'StarPrincipal()';\n  }\n\n  public dedupeString(): string | undefined {\n    return 'StarPrincipal';\n  }\n}\n\n/**\n * Represents a principal that has multiple types of principals. A composite principal cannot\n * have conditions. i.e. multiple ServicePrincipals that form a composite principal\n */\nexport class CompositePrincipal extends PrincipalBase {\n  public readonly assumeRoleAction: string;\n  private readonly _principals = new Array<IPrincipal>();\n\n  constructor(...principals: IPrincipal[]) {\n    super();\n    if (principals.length === 0) {\n      throw new UnscopedValidationError('CompositePrincipals must be constructed with at least 1 Principal but none were passed.');\n    }\n    this.assumeRoleAction = principals[0].assumeRoleAction;\n    this.addPrincipals(...principals);\n  }\n\n  /**\n   * Adds IAM principals to the composite principal. Composite principals cannot have\n   * conditions.\n   *\n   * @param principals IAM principals that will be added to the composite principal\n   */\n  public addPrincipals(...principals: IPrincipal[]): this {\n    this._principals.push(...principals);\n    return this;\n  }\n\n  public addToAssumeRolePolicy(doc: PolicyDocument) {\n    for (const p of this._principals) {\n      defaultAddPrincipalToAssumeRole(p, doc);\n    }\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    // We only have a problem with conditions if we are trying to render composite\n    // principals into a single statement (which is when `policyFragment` would get called)\n    for (const p of this._principals) {\n      const fragment = p.policyFragment;\n      if (fragment.conditions && Object.keys(fragment.conditions).length > 0) {\n        throw new UnscopedValidationError(\n          'Components of a CompositePrincipal must not have conditions. ' +\n          `Tried to add the following fragment: ${JSON.stringify(fragment)}`);\n      }\n    }\n\n    const principalJson: { [key: string]: string[] } = {};\n\n    for (const p of this._principals) {\n      mergePrincipal(principalJson, p.policyFragment.principalJson);\n    }\n\n    return new PrincipalPolicyFragment(principalJson);\n  }\n\n  public toString() {\n    return `CompositePrincipal(${this._principals})`;\n  }\n\n  public dedupeString(): string | undefined {\n    const inner = this._principals.map(ComparablePrincipal.dedupeStringFor);\n    if (inner.some(x => x === undefined)) { return undefined; }\n    return `CompositePrincipal[${inner.join(',')}]`;\n  }\n\n  /**\n   * Returns the principals that make up the CompositePrincipal\n   */\n  public get principals(): IPrincipal[] {\n    return this._principals;\n  }\n}\n\n/**\n * A lazy token that requires an instance of Stack to evaluate\n */\nclass StackDependentToken implements cdk.IResolvable {\n  public readonly creationStack: string[];\n  constructor(private readonly fn: (stack: cdk.Stack) => any) {\n    this.creationStack = cdk.captureStackTrace();\n  }\n\n  public resolve(context: cdk.IResolveContext) {\n    return this.fn(cdk.Stack.of(context.scope));\n  }\n\n  public toString() {\n    return cdk.Token.asString(this);\n  }\n\n  /**\n   * JSON-ify the token\n   *\n   * Used when JSON.stringify() is called\n   */\n  public toJSON() {\n    return '<unresolved-token>';\n  }\n}\n\nclass ServicePrincipalToken implements cdk.IResolvable {\n  public readonly creationStack: string[];\n  constructor(\n    private readonly service: string,\n    private readonly opts: ServicePrincipalOpts) {\n    this.creationStack = cdk.captureStackTrace();\n  }\n\n  public resolve(ctx: cdk.IResolveContext) {\n    return this.newStandardizedBehavior(ctx);\n  }\n\n  /**\n   * Return the global (original) service principal, and a second one if region is given and points to an opt-in region\n   */\n  private newStandardizedBehavior(ctx: cdk.IResolveContext) {\n    const stack = cdk.Stack.of(ctx.scope);\n\n    // If the user had previously set the feature flag to `false` we would allow them to provide only the service name instead of the\n    // entire service principal. We can't break them so now everyone gets to do it!\n    const match = this.service.match(/^([^.]+)(?:(?:\\.amazonaws\\.com(?:\\.cn)?)|(?:\\.c2s\\.ic\\.gov)|(?:\\.sc2s\\.sgov\\.gov))?$/);\n    const service = match ? `${match[1]}.amazonaws.com` : this.service;\n    if (\n      this.opts.region &&\n      !cdk.Token.isUnresolved(this.opts.region) &&\n      stack.region !== this.opts.region &&\n      RegionInfo.get(this.opts.region).isOptInRegion\n    ) {\n      return service.replace(/\\.amazonaws\\.com$/, `.${this.opts.region}.amazonaws.com`);\n    }\n    return service;\n  }\n\n  public toString() {\n    return cdk.Token.asString(this, {\n      displayHint: this.service,\n    });\n  }\n\n  /**\n   * JSON-ify the token\n   *\n   * Used when JSON.stringify() is called\n   */\n  public toJSON() {\n    return `<${this.service}>`;\n  }\n}", "language": "typescript"}
{"input": "Passing L1 & L2 Bucket to L2 Events.Rule with cloudtrail pattern", "output": "class L1L2BucketWithL2Rule extends cdk.Stack {\n  public constructor(scope: Construct, id: string, props: cdk.StackProps) {\n    super(scope, id, props);\n\n    const l1Bucket = new s3.CfnBucket(this, 'bucket');\n    const l1BucketWithEvent = BucketEvents.fromBucket(l1Bucket);\n\n    const l2Bucket = new s3.Bucket(this, 'bucketL2');\n    const l2BucketWithEvent = BucketEvents.fromBucket(l2Bucket);\n\n    const fn = new Function(this, 'MyFuncA', {\n      runtime: Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: Code.fromInline(`\nexports.handler = async (event) => {\n  console.log(\"New Project event:\", JSON.stringify(event, null, 2));\n  return {};\n};\n`),\n    });\n\n    const trail = new Trail(this, 'Trail', {});\n    trail.addS3EventSelector([{ bucket: l1Bucket }], { readWriteType: ReadWriteType.ALL });\n    trail.addS3EventSelector([{ bucket: l2Bucket }], { readWriteType: ReadWriteType.ALL });\n    const l2Rule = new Rule(this, 'L2RuleForL1', {\n      targets: [new LambdaFunction(fn)],\n    });\n\n    l2Rule.addEventPattern(l1BucketWithEvent.awsAPICallViaCloudTrailPattern({ tlsDetails: { tlsVersion: ['TLSv1.3'] }, eventMetadata: { region: ['us-east-1'] } }));\n    l2Rule.addEventPattern(l2BucketWithEvent.awsAPICallViaCloudTrailPattern());\n  }\n}", "language": "typescript"}
{"input": "Base class for .NET SDK injectors. Contains common .NET configuration settings used by both Windows and Linux implementations.", "output": "class DotNetInjector extends Injector {\n  protected static readonly DOTNET_COMMON_ENVS: EnvironmentExtension[] = [\n    {\n      name: constants.DotnetInstrumentation.OTEL_DOTNET_DISTRO,\n      value: constants.DotnetInstrumentation.OTEL_DOTNET_DISTRO_AWS_DISTRO,\n    },\n    {\n      name: constants.DotnetInstrumentation.OTEL_DOTNET_CONFIGURATOR,\n      value: constants.DotnetInstrumentation.OTEL_DOTNET_CONFIGURATOR_AWS_CONFIGURATOR,\n    },\n    {\n      name: constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_PLUGINS,\n      value: constants.DotnetInstrumentation.OTEL_DOTNET_AUTO_PLUGINS_ADOT,\n    },\n  ];\n}", "language": "typescript"}
{"input": "CDK class SubnetNetworkAclAssociation for AWS resource management", "output": "export class SubnetNetworkAclAssociation extends SubnetNetworkAclAssociationBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.SubnetNetworkAclAssociation';\n\n  public static fromSubnetNetworkAclAssociationAssociationId(\n    scope: Construct, id: string,\n    subnetNetworkAclAssociationAssociationId: string): ISubnetNetworkAclAssociation {\n    class Import extends SubnetNetworkAclAssociationBase {\n      public readonly subnetNetworkAclAssociationAssociationId = subnetNetworkAclAssociationAssociationId;\n    }\n\n    return new Import(scope, id);\n  }\n  /**\n   * ID for the current SubnetNetworkAclAssociation\n   * @attribute\n   */\n  public readonly subnetNetworkAclAssociationAssociationId: string;\n\n  private readonly _subnet: ISubnet;\n\n  private association: CfnSubnetNetworkAclAssociation;\n  private readonly _networkAcl: INetworkAclRef;\n\n  constructor(scope: Construct, id: string, props: SubnetNetworkAclAssociationProps) {\n    super(scope, id, {\n      physicalName: props.subnetNetworkAclAssociationName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.association = new CfnSubnetNetworkAclAssociation(this, 'Resource', {\n      networkAclId: props.networkAcl.networkAclRef.networkAclId,\n      subnetId: props.subnet.subnetRef.subnetId,\n    });\n\n    this._networkAcl = props.networkAcl;\n    this._subnet = props.subnet;\n    this.subnetNetworkAclAssociationAssociationId = this.association.attrAssociationId;\n  }\n\n  /**\n   * ID of the Subnet\n   */\n  public get subnet(): ISubnet {\n    return asSubnet(this._subnet, this);\n  }\n\n  /**\n   * ID for the current Network ACL\n   */\n  public get networkAcl(): INetworkAcl {\n    return asNetworkAcl(this._networkAcl, this);\n  }\n}", "language": "typescript"}
{"input": "A stack that sets up MyCustomResource and shows how to get an attribute from it", "output": "class MyStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const resource = new MyCustomResource(this, 'DemoResource', {\n      Message: 'CustomResource says hello',\n    });\n\n    // Publish the custom resource output\n    new cdk.CfnOutput(this, 'ResponseMessage', {\n      description: 'The message that came back from the Custom Resource',\n      value: resource.response\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, Route 53 resources", "output": "class AliasHealthcheckRecordStack(Stack):\n  def __init__(self, scope: Construct, construct_id: str, zone: route53.HostedZone, primaryLoadBalancer: elbv2.ILoadBalancerV2, secondaryLoadBalancer: elbv2.ILoadBalancerV2, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # primary record\n        primary = route53.ARecord(self, \"PrimaryRecordSet\",\n            zone = zone,\n            record_name=\"alias\",\n            target = route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(primaryLoadBalancer)),\n        )\n        primaryRecordSet = primary.node.default_child\n        primaryRecordSet.failover = \"PRIMARY\"\n        primaryRecordSet.add_property_override('AliasTarget.EvaluateTargetHealth', True)\n        primaryRecordSet.set_identifier = \"Primary\"\n\n        # secondary record\n        secondary = route53.ARecord(self, \"SecondaryRecordSet\",\n            zone = zone,\n            record_name=\"alias\",\n            target= route53.RecordTarget.from_alias(route53_targets.LoadBalancerTarget(secondaryLoadBalancer)),\n        )\n        secondaryRecordSet = secondary.node.default_child\n        secondaryRecordSet.failover = \"SECONDARY\"\n        secondaryRecordSet.add_property_override('AliasTarget.EvaluateTargetHealth', True)\n        secondaryRecordSet.set_identifier = \"Secondary\"", "language": "python"}
{"input": "Assume that the CloudWatch Logs resource policy is created by another stack", "output": "class LogsResourcePolicy extends Stack {\n  public readonly logGroup: logs.LogGroup;\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.logGroup = new logs.LogGroup(this, 'AppLogsGroup', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const resourcePolicy = new logs.ResourcePolicy(this, 'ResourcePolicy');\n    resourcePolicy.document.addStatements(new iam.PolicyStatement({\n      actions: ['logs:CreateLogStream', 'logs:PutLogEvents'],\n      principals: [new iam.ServicePrincipal('es.amazonaws.com')],\n      resources: [this.logGroup.logGroupArn],\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class TokenAuthorizer for AWS resource management", "output": "export class TokenAuthorizer extends LambdaAuthorizer {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.TokenAuthorizer';\n  public readonly authorizerId: string;\n\n  public readonly authorizerArn: string;\n\n  protected readonly authorizerProps: CfnAuthorizerProps;\n\n  constructor(scope: Construct, id: string, props: TokenAuthorizerProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const restApiId = this.lazyRestApiId();\n\n    const authorizerProps: CfnAuthorizerProps = {\n      name: props.authorizerName ?? Names.uniqueId(this),\n      restApiId,\n      type: 'TOKEN',\n      authorizerUri: lambdaAuthorizerArn(props.handler),\n      authorizerCredentials: props.assumeRole?.roleArn,\n      authorizerResultTtlInSeconds: props.resultsCacheTtl?.toSeconds() ?? Duration.minutes(5).toSeconds(),\n      identitySource: props.identitySource || IdentitySource.header('Authorization'),\n      identityValidationExpression: props.validationRegex,\n    };\n\n    this.authorizerProps = authorizerProps;\n\n    const resource = new CfnAuthorizer(this, 'Resource', authorizerProps);\n\n    this.authorizerId = resource.ref;\n    this.authorizerArn = Stack.of(this).formatArn({\n      service: 'execute-api',\n      resource: restApiId,\n      resourceName: `authorizers/${this.authorizerId}`,\n    });\n\n    this.setupPermissions();\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, RDS, EC2 resources", "output": "export class PostgresLambdaStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create a VPC for our application\n    const vpc = new ec2.Vpc(this, 'PostgresLambdaVpc', {\n      maxAzs: 2,\n      natGateways: 1,\n    });\n\n    // Create a PostgreSQL Aurora Serverless v2 cluster\n    const dbCluster = new rds.DatabaseCluster(this, 'PostgresCluster', {\n      engine: rds.DatabaseClusterEngine.auroraPostgres({\n        version: rds.AuroraPostgresEngineVersion.VER_17_4,\n      }),\n      vpc: vpc,\n      writer: rds.ClusterInstance.serverlessV2('writer'),\n      serverlessV2MinCapacity: 0.5,\n      serverlessV2MaxCapacity: 1,\n      defaultDatabaseName: 'demodb',\n      credentials: rds.Credentials.fromGeneratedSecret('postgres'),\n    });\n\n\n\n    const bundleCommand = [\n      'bash', '-c', [\n        'cp -r . /asset-output/',\n      ].join(' && ')\n    ]\n\n    // Create a Lambda function that calls PostgreSQL with Docker bundling\n    const lambdaToPostgres = new lambda.Function(this, 'LambdaToPostgres', {\n      runtime: lambda.Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: lambda.Code.fromAsset(path.join(__dirname, '../lambda/lambda-to-postgres'), {\n        bundling: {\n          image: lambda.Runtime.NODEJS_LATEST.bundlingImage,\n          command: bundleCommand,\n        },\n      }),\n      vpc,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,\n      },\n      environment: {\n        DB_SECRET_ARN: dbCluster.secret?.secretArn || '',\n        DB_NAME: 'demodb',\n      },\n      timeout: cdk.Duration.seconds(30),\n    });\n\n    // Grant Lambda access to the DB\n    dbCluster.connections.allowDefaultPortFrom(lambdaToPostgres);\n\n    // Grant the Lambda function permission to read the database secret\n    dbCluster.secret?.grantRead(lambdaToPostgres);\n\n    // Create a Lambda function that is called by PostgreSQL\n    const postgresFunction = new lambda.Function(this, 'PostgresFunction', {\n      runtime: lambda.Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: lambda.Code.fromAsset(path.join(__dirname, '../lambda/postgres-to-lambda'), {\n        bundling: {\n          image: lambda.Runtime.NODEJS_LATEST.bundlingImage,\n          command: bundleCommand,\n        },\n      }),\n      environment: {\n        FUNCTION_NAME: 'PostgresFunction',\n      },\n      timeout: cdk.Duration.seconds(30),\n    });\n\n\n    // Create a role for PostgreSQL to assume to invoke Lambda\n    const postgresLambdaRole = new iam.Role(this, 'PostgresLambdaRole', {\n      assumedBy: new iam.ServicePrincipal('rds.amazonaws.com'),\n    });\n\n    postgresFunction.grantInvoke(postgresLambdaRole);\n\n\n    const l1DbCluster = dbCluster.node.defaultChild as rds.CfnDBCluster\n    const exisitingProperty = (l1DbCluster.associatedRoles as []) || [];\n    console.log(exisitingProperty);\n\n    const newRole: { FeatureName: string, RoleArn: string } = {\n      FeatureName: \"Lambda\",  // Changed to PascalCase\n      RoleArn: postgresLambdaRole.roleArn  // Changed to PascalCase\n    };\n\n    const updatedRoles: { [key in 'featureName' | 'FeatureName' | 'roleArn' | 'RoleArn']?: string; }[] = [...exisitingProperty, newRole];\n\n    l1DbCluster.addPropertyOverride('AssociatedRoles', updatedRoles);\n\n    // Create Lambda function for PostgreSQL setup with Docker bundling\n    const setupFunction = new lambda.Function(this, 'PostgresSetupFunction', {\n      runtime: lambda.Runtime.NODEJS_LATEST,\n      handler: 'index.handler',\n      code: lambda.Code.fromAsset(path.join(__dirname, '../lambda/postgres-setup'), {\n        bundling: {\n          image: lambda.Runtime.NODEJS_LATEST.bundlingImage,\n          command: bundleCommand,\n        },\n      }),\n      vpc,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,\n      },\n      environment: {\n        DB_SECRET_ARN: dbCluster.secret?.secretArn || '',\n        DB_NAME: 'demodb',\n        POSTGRES_FUNCTION_NAME: postgresFunction.functionName,\n      },\n      timeout: cdk.Duration.minutes(5),\n    });\n\n    // Grant setup function access to the DB and secrets\n    dbCluster.connections.allowDefaultPortFrom(setupFunction);\n    dbCluster.secret?.grantRead(setupFunction);\n\n    // Create custom resource to trigger setup\n    const setupProvider = new cr.Provider(this, 'PostgresSetupProvider', {\n      onEventHandler: setupFunction,\n    });\n\n    new cdk.CustomResource(this, 'PostgresSetupResource', {\n      serviceToken: setupProvider.serviceToken,\n    });\n\n    // Output the database endpoint and secret ARN\n    new cdk.CfnOutput(this, 'DBClusterEndpoint', {\n      value: dbCluster.clusterEndpoint.hostname,\n      description: 'The endpoint of the database cluster',\n    });\n\n    new cdk.CfnOutput(this, 'DBSecretArn', {\n      value: dbCluster.secret?.secretArn || 'No secret created',\n      description: 'The ARN of the database credentials secret',\n    });\n\n    new cdk.CfnOutput(this, 'LambdaToPostgresFunctionName', {\n      value: lambdaToPostgres.functionName,\n      description: 'The name of the Lambda function that calls PostgreSQL',\n    });\n\n    new cdk.CfnOutput(this, 'PostgresFunctionName', {\n      value: postgresFunction.functionName,\n      description: 'The name of the Lambda function that is called by PostgreSQL',\n    });\n\n    new cdk.CfnOutput(this, 'PostgresLambdaRoleArn', {\n      value: postgresLambdaRole.roleArn,\n      description: 'The ARN of the role that PostgreSQL can assume to invoke Lambda',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class IpInstance for AWS resource management", "output": "export class IpInstance extends InstanceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicediscovery.IpInstance';\n  /**\n   * The Id of the instance\n   */\n  public readonly instanceId: string;\n\n  /**\n   * The Cloudmap service to which the instance is registered.\n   */\n  public readonly service: IService;\n\n  /**\n   * The Ipv4 address of the instance, or blank string if none available\n   */\n  public readonly ipv4: string;\n\n  /**\n   * The Ipv6 address of the instance, or blank string if none available\n   */\n  public readonly ipv6: string;\n\n  /**\n   * The exposed port of the instance\n   */\n  public readonly port: number;\n\n  constructor(scope: Construct, id: string, props: IpInstanceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    const dnsRecordType = props.service.dnsRecordType;\n\n    if (dnsRecordType === DnsRecordType.CNAME) {\n      throw new ValidationError('Service must support `A`, `AAAA` or `SRV` records to register this instance type.', this);\n    }\n    if (dnsRecordType === DnsRecordType.SRV) {\n      if (!props.port) {\n        throw new ValidationError('A `port` must be specified for a service using a `SRV` record.', this);\n      }\n\n      if (!props.ipv4 && !props.ipv6) {\n        throw new ValidationError('At least `ipv4` or `ipv6` must be specified for a service using a `SRV` record.', this);\n      }\n    }\n\n    if (!props.ipv4 && (dnsRecordType === DnsRecordType.A || dnsRecordType === DnsRecordType.A_AAAA)) {\n      throw new ValidationError('An `ipv4` must be specified for a service using a `A` record.', this);\n    }\n\n    if (!props.ipv6 &&\n      (dnsRecordType === DnsRecordType.AAAA || dnsRecordType === DnsRecordType.A_AAAA)) {\n      throw new ValidationError('An `ipv6` must be specified for a service using a `AAAA` record.', this);\n    }\n\n    const port = props.port || 80;\n\n    const resource = new CfnInstance(this, 'Resource', {\n      instanceAttributes: {\n        AWS_INSTANCE_IPV4: props.ipv4,\n        AWS_INSTANCE_IPV6: props.ipv6,\n        AWS_INSTANCE_PORT: port.toString(),\n        ...props.customAttributes,\n      },\n      instanceId: props.instanceId || this.uniqueInstanceId(),\n      serviceId: props.service.serviceId,\n    });\n\n    this.service = props.service;\n    this.instanceId = resource.ref;\n    this.ipv4 = props.ipv4 || '';\n    this.ipv6 = props.ipv6 || '';\n    this.port = port;\n  }\n}", "language": "typescript"}
{"input": "CDK class FargateCluster for AWS resource management", "output": "export class FargateCluster extends Cluster {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-eks.FargateCluster';\n\n  /**\n   * Fargate Profile that was created with the cluster.\n   */\n  public readonly defaultProfile: FargateProfile;\n\n  constructor(scope: Construct, id: string, props: FargateClusterProps) {\n    super(scope, id, {\n      ...props,\n      defaultCapacity: 0,\n      coreDnsComputeType: props.coreDnsComputeType ?? CoreDnsComputeType.FARGATE,\n      version: props.version,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.defaultProfile = this.addFargateProfile(\n      props.defaultProfile?.fargateProfileName ?? (props.defaultProfile ? 'custom' : 'default'),\n      props.defaultProfile ?? {\n        selectors: [\n          { namespace: 'default' },\n          { namespace: 'kube-system' },\n        ],\n      },\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, MSK (Kafka), CloudFormation resources", "output": "export class ecsFargateStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props: vpcStackProps) {\n        super(scope, id, props);\n\n    const cluster = new Cluster(this, 'ecsCluster', {\n        vpc: props.vpc,\n        containerInsights: true,\n    });\n    const asset = new DockerImageAsset(this, 'AppImage', {\n        directory: path.join(__dirname, '..', 'src')\n      });\n    \n    // \ud83d\udc47 create a new ecs pattern with an alb \ud83d\udc47\n    const loadBalancedFargateService = new ApplicationLoadBalancedFargateService (this, 'ecsPattern', {\n        cluster,\n        cpu: 256,\n        memoryLimitMiB: 512,\n        desiredCount: 1,\n        publicLoadBalancer: true,\n        taskSubnets: { subnetType: SubnetType.PRIVATE_WITH_EGRESS },\n        taskImageOptions: {\n            image: EcrImage.fromDockerImageAsset(asset),\n        },\n        enableExecuteCommand: true,\n        });\n\n    // \ud83d\udc47 auto scale task count \ud83d\udc47\n    const scalableTarget = loadBalancedFargateService.service.autoScaleTaskCount({\n        minCapacity: 1,\n        maxCapacity: 6,\n        });\n        // \ud83d\udc47 auto scale cpu trigger \ud83d\udc47\n        scalableTarget.scaleOnCpuUtilization('CpuScaling', {\n            targetUtilizationPercent: 50,\n        });\n        // \ud83d\udc47 auto scale memory trigger \ud83d\udc47\n        scalableTarget.scaleOnMemoryUtilization('MemoryScaling', {\n            targetUtilizationPercent: 50,\n        });\n        // \ud83d\udc47 load balancer health check \ud83d\udc47\n        loadBalancedFargateService.targetGroup.configureHealthCheck({\n            path: \"/\",\n        });\n    }\n}", "language": "typescript"}
{"input": "CDK class SageMakerCreateEndpointConfig for AWS resource management", "output": "export class SageMakerCreateEndpointConfig extends sfn.TaskStateBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-stepfunctions-tasks.SageMakerCreateEndpointConfig';\n\n  /**\n   * A Step Functions Task using JSONPath to create a SageMaker endpoint configuration\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-sagemaker.html\n   */\n  public static jsonPath(scope: Construct, id: string, props: SageMakerCreateEndpointConfigJsonPathProps) {\n    return new SageMakerCreateEndpointConfig(scope, id, props);\n  }\n\n  /**\n   * A Step Functions Task using JSONata to create a SageMaker endpoint configuration\n   *\n   * @see https://docs.aws.amazon.com/step-functions/latest/dg/connect-sagemaker.html\n   */\n  public static jsonata(scope: Construct, id: string, props: SageMakerCreateEndpointConfigJsonataProps) {\n    return new SageMakerCreateEndpointConfig(scope, id, {\n      ...props,\n      queryLanguage: sfn.QueryLanguage.JSONATA,\n    });\n  }\n\n  private static readonly SUPPORTED_INTEGRATION_PATTERNS: sfn.IntegrationPattern[] = [\n    sfn.IntegrationPattern.REQUEST_RESPONSE,\n  ];\n  protected readonly taskMetrics?: sfn.TaskMetricsConfig;\n  protected readonly taskPolicies?: iam.PolicyStatement[];\n  private readonly integrationPattern: sfn.IntegrationPattern;\n\n  constructor(scope: Construct, id: string, private readonly props: SageMakerCreateEndpointConfigProps) {\n    super(scope, id, props);\n    this.integrationPattern = props.integrationPattern || sfn.IntegrationPattern.REQUEST_RESPONSE;\n    validatePatternSupported(this.integrationPattern, SageMakerCreateEndpointConfig.SUPPORTED_INTEGRATION_PATTERNS);\n\n    this.validateProductionVariants();\n    this.taskPolicies = this.makePolicyStatements();\n  }\n\n  /**\n   * @internal\n   */\n  protected _renderTask(topLevelQueryLanguage?: sfn.QueryLanguage): any {\n    const queryLanguage = sfn._getActualQueryLanguage(topLevelQueryLanguage, this.props.queryLanguage);\n    return {\n      Resource: integrationResourceArn('sagemaker', 'createEndpointConfig', this.integrationPattern),\n      ...this._renderParametersOrArguments(this.renderParameters(), queryLanguage),\n    };\n  }\n\n  private renderParameters(): { [key: string]: any } {\n    return {\n      EndpointConfigName: this.props.endpointConfigName,\n      Tags: this.props.tags?.value,\n      KmsKeyId: this.props.kmsKey?.keyRef.keyId,\n      ProductionVariants: this.props.productionVariants.map((variant) => ({\n        InitialInstanceCount: variant.initialInstanceCount ? variant.initialInstanceCount : 1,\n        InstanceType: isJsonPathOrJsonataExpression(variant.instanceType.toString())\n          ? variant.instanceType.toString() : `ml.${variant.instanceType}`,\n        ModelName: variant.modelName,\n        VariantName: variant.variantName,\n        AcceleratorType: variant.acceleratorType,\n        InitialVariantWeight: variant.initialVariantWeight,\n      }),\n      ),\n    };\n  }\n\n  private makePolicyStatements(): iam.PolicyStatement[] {\n    const stack = cdk.Stack.of(this);\n    // https://docs.aws.amazon.com/sagemaker/latest/dg/api-permissions-reference.html\n    return [\n      new iam.PolicyStatement({\n        actions: ['sagemaker:CreateEndpointConfig'],\n        resources: [\n          stack.formatArn({\n            service: 'sagemaker',\n            resource: 'endpoint-config',\n            // If the endpoint configuration name comes from input, we cannot target the policy to a particular ARN prefix reliably.\n            // SageMaker uses lowercase for resource name in the arn\n            resourceName: isJsonPathOrJsonataExpression(this.props.endpointConfigName) ? '*' : `${this.props.endpointConfigName.toLowerCase()}`,\n          }),\n        ],\n      }),\n      new iam.PolicyStatement({\n        actions: ['sagemaker:ListTags'],\n        // https://docs.aws.amazon.com/step-functions/latest/dg/sagemaker-iam.html\n        resources: ['*'],\n      }),\n    ];\n  }\n\n  private validateProductionVariants() {\n    if (this.props.productionVariants.length < 1 || this.props.productionVariants.length > 10) {\n      throw new ValidationError('Must specify from 1 to 10 production variants per endpoint configuration', this);\n    }\n    this.props.productionVariants.forEach((variant) => {\n      if (variant.initialInstanceCount && variant.initialInstanceCount < 1) throw new ValidationError('Must define at least one instance', this);\n      if ( variant.initialVariantWeight && variant.initialVariantWeight <= 0) {\n        throw new ValidationError('InitialVariantWeight has minimum value of 0', this);\n      }\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class Mysql for AWS resource management", "output": "export class Mysql extends Stack {\n  constructor(scope: Construct, id: string, props: MysqlProps) {\n    super(scope, id);\n\n    // default database username\n    let mysqlUsername = \"dbadmin\";\n    if (typeof props.mysqlUsername !== 'undefined') {\n      mysqlUsername = props.mysqlUsername;\n    }\n    let ingressSources = [];\n    if (typeof props.ingressSources !== 'undefined') {\n      ingressSources = props.ingressSources;\n    }\n    let engineVersion = rds.MysqlEngineVersion.VER_8_0_28;\n    if (typeof props.engineVersion !== 'undefined') {\n      engineVersion = props.engineVersion;\n    }\n\n\n\n    const azs = Fn.getAzs();\n\n    // vpc\n    const vpc = ec2.Vpc.fromVpcAttributes(this, 'ExistingVPC', {\n      vpcId: props.vpcId!,\n      availabilityZones: azs,\n    });\n\n    // Subnets\n    const subnets: any[] = [];\n\n    for (let subnetId of props.subnetIds!) {\n      const subid = subnetId\n        .replace('_', '')\n        .replace(' ', '');\n      subnets.push(\n        ec2.Subnet.fromSubnetAttributes(this, subid, {\n          subnetId: subid,\n        }),\n      );\n    }\n\n    const vpcSubnets: ec2.SubnetSelection = {\n      subnets: subnets,\n    };\n\n    const allAll = ec2.Port.allTraffic();\n    const tcp3306 = ec2.Port.tcpRange(3306, 3306);\n\n    const dbsg = new ec2.SecurityGroup(this, 'DatabaseSecurityGroup', {\n      vpc: vpc,\n      allowAllOutbound: true,\n      description: id + 'Database',\n      securityGroupName: id + 'Database',\n    });\n\n    dbsg.addIngressRule(dbsg, allAll, 'all from self');\n    dbsg.addEgressRule(ec2.Peer.ipv4('0.0.0.0/0'), allAll, 'all out');\n\n    const mysqlConnectionPorts = [\n      { port: tcp3306, description: 'tcp3306 Mysql' },\n    ];\n\n    for (let ingressSource of ingressSources!) {\n      for (let c of mysqlConnectionPorts) {\n        dbsg.addIngressRule(ingressSource, c.port, c.description);\n      }\n    }\n\n    const dbSubnetGroup = new rds.SubnetGroup(this, 'DatabaseSubnetGroup', {\n      vpc: vpc,\n      description: id + 'subnet group',\n      vpcSubnets: vpcSubnets,\n      subnetGroupName: id + 'subnet group',\n    });\n\n    const mysqlSecret = new secretsmanager.Secret(this, 'MysqlCredentials', {\n      secretName: props.dbName + 'MysqlCredentials',\n      description: props.dbName + 'Mysql Database Crendetials',\n      generateSecretString: {\n        excludeCharacters: \"\\\"@/\\\\ '\",\n        generateStringKey: 'password',\n        passwordLength: 30,\n        secretStringTemplate: JSON.stringify({username: mysqlUsername}),\n      },\n    });\n\n    const mysqlCredentials = rds.Credentials.fromSecret(\n      mysqlSecret,\n      mysqlUsername,\n    );\n\n    const dbParameterGroup = new rds.ParameterGroup(this, 'ParameterGroup', {\n      engine: rds.DatabaseInstanceEngine.mysql({\n        version: engineVersion,\n      }),\n    });\n\n\n\n    const mysqlInstance = new rds.DatabaseInstance(this, 'MysqlDatabase', {\n      databaseName: props.dbName,\n      instanceIdentifier: props.dbName,\n      credentials: mysqlCredentials,\n      engine: rds.DatabaseInstanceEngine.mysql({\n        version: engineVersion,\n      }),\n      backupRetention: Duration.days(7),\n      allocatedStorage: 20,\n      securityGroups: [dbsg],\n      allowMajorVersionUpgrade: true,\n      autoMinorVersionUpgrade: true,\n      instanceType: props.instanceType,\n      vpcSubnets: vpcSubnets,\n      vpc: vpc,\n      removalPolicy: RemovalPolicy.DESTROY,\n      storageEncrypted: true,\n      monitoringInterval: Duration.seconds(60),\n      enablePerformanceInsights: true,\n      parameterGroup: dbParameterGroup,\n      subnetGroup: dbSubnetGroup,\n      preferredBackupWindow: props.backupWindow,\n      preferredMaintenanceWindow: props.preferredMaintenanceWindow,\n      publiclyAccessible: false,\n    });\n\n    mysqlInstance.addRotationSingleUser();\n\n    // Tags\n    Tags.of(mysqlInstance).add('Name', 'MysqlDatabase', {\n      priority: 300,\n    });\n\n\n    new CfnOutput(this, 'MysqlEndpoint', {\n      exportName: 'MysqlEndPoint',\n      value: mysqlInstance.dbInstanceEndpointAddress,\n    });\n\n    new CfnOutput(this, 'MysqlUserName', {\n      exportName: 'MysqlUserName',\n      value: mysqlUsername,\n    });\n\n    new CfnOutput(this, 'MysqlDbName', {\n      exportName: 'MysqlDbName',\n      value: props.dbName!,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class RdsDataSource for AWS resource management", "output": "export class RdsDataSource extends BackedDataSource {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.RdsDataSource';\n\n  constructor(scope: Construct, id: string, props: RdsDataSourceProps);\n  constructor(scope: Construct, id: string, props: RdsDataSourcePropsV2) {\n    super(scope, id, props, {\n      type: 'RELATIONAL_DATABASE',\n      relationalDatabaseConfig: {\n        rdsHttpEndpointConfig: {\n          awsRegion: props.serverlessCluster.env.region,\n          dbClusterIdentifier: Lazy.string({\n            produce: () => {\n              return Stack.of(this).formatArn({\n                service: 'rds',\n                resource: `cluster:${props.serverlessCluster.clusterIdentifier}`,\n              });\n            },\n          }),\n          awsSecretStoreArn: props.secretStore.secretArn,\n          databaseName: props.databaseName,\n        },\n        relationalDatabaseSourceType: 'RDS_HTTP_ENDPOINT',\n      },\n    });\n\n    const clusterArn = Stack.of(this).formatArn({\n      service: 'rds',\n      resource: `cluster:${props.serverlessCluster.clusterIdentifier}`,\n    });\n    props.secretStore.grantRead(this);\n\n    // Change to grant with RDS grant becomes implemented\n    props.serverlessCluster.grantDataApiAccess(this);\n\n    Grant.addToPrincipal({\n      grantee: this,\n      actions: [\n        'rds-data:DeleteItems',\n        'rds-data:ExecuteSql',\n        'rds-data:GetItems',\n        'rds-data:InsertItems',\n        'rds-data:UpdateItems',\n      ],\n      resourceArns: [clusterArn, `${clusterArn}:*`],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class MixinsCore for AWS resource management", "output": "class MixinsCore extends ExternalModule {\n  public readonly IMixin = Type.fromName(this, 'IMixin');\n  public readonly Mixin = Type.fromName(this, 'Mixin');\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, IAM, SSM Parameter Store resources", "output": "class Ec2CdkProductStack extends sc.ProductStack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const vpc = new ec2.Vpc(this, 'VPC', {\n      natGateways: 0,\n      subnetConfiguration: [{\n        cidrMask: 24,\n        name: 'public',\n        subnetType: ec2.SubnetType.PUBLIC,\n      }]\n    });\n\n    const role = new iam.Role(this, 'ec2Role', {\n      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n    });\n\n    role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonSSMManagedInstanceCore'))\n\n    // Use Latest Amazon Linux Image - CPU Type ARM64\n    const ami = new ec2.AmazonLinuxImage({\n      generation: ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n      cpuType: ec2.AmazonLinuxCpuType.ARM_64,\n    });\n\n    // EC2 Instance Type parameter\n    const ec2InstanceType = new CfnParameter(this, 'InstanceType', {\n      type: 'String',\n      description: 'The instance type of an EC2 instance.',\n    });\n\n    // Create the instance using the Security Group, AMI, and KeyPair defined in the VPC created\n    const ec2Instance = new ec2.Instance(this, 'Instance', {\n      vpc,\n      instanceType: new ec2.InstanceType(ec2InstanceType.valueAsString),\n      machineImage: ami,\n      allowAllOutbound: true,\n      role: role,\n    });\n    ec2Instance.connections.allowFromAnyIpv4(ec2.Port.tcp(22), 'Allow SSH (TCP port 22) in');\n\n    new CfnOutput(this, 'IP Address', { value: ec2Instance.instancePublicIp });\n    new CfnOutput(this, 'Download Key Command', { value: 'aws secretsmanager get-secret-value --secret-id ec2-ssh-key/cdk-keypair/private --query SecretString --output text > cdk-key.pem && chmod 400 cdk-key.pem' });\n    new CfnOutput(this, 'ssh command', { value: 'ssh -i cdk-key.pem -o IdentitiesOnly=yes ec2-user@' + ec2Instance.instancePublicIp });\n  }\n}", "language": "typescript"}
{"input": "CDK class CloudFormationProduct for AWS resource management", "output": "export class CloudFormationProduct extends Product {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicecatalog.CloudFormationProduct';\n  public readonly productArn: string;\n  public readonly productId: string;\n  /**\n   * The asset bucket of a product created via product stack.\n   * @default - Empty - no assets are used in this product\n   */\n  public readonly assetBuckets = new Array<IBucket>();\n\n  constructor(scope: Construct, id: string, props: CloudFormationProductProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.validateProductProps(props);\n\n    const product = new CfnCloudFormationProduct(this, 'Resource', {\n      acceptLanguage: props.messageLanguage,\n      description: props.description,\n      distributor: props.distributor,\n      name: props.productName,\n      owner: props.owner,\n      provisioningArtifactParameters: this.renderProvisioningArtifacts(props),\n      replaceProvisioningArtifacts: props.replaceProductVersionIds,\n      supportDescription: props.supportDescription,\n      supportEmail: props.supportEmail,\n      supportUrl: props.supportUrl,\n    });\n\n    this.productId = product.ref;\n    this.productArn = Stack.of(this).formatArn({\n      service: 'catalog',\n      resource: 'product',\n      resourceName: product.ref,\n    });\n\n    if (props.tagOptions !== undefined) {\n      this.associateTagOptions(props.tagOptions);\n    }\n  }\n\n  private renderProvisioningArtifacts(\n    props: CloudFormationProductProps): CfnCloudFormationProduct.ProvisioningArtifactPropertiesProperty[] {\n    return props.productVersions.map(productVersion => {\n      const template = productVersion.cloudFormationTemplate.bind(this);\n      if (template.assetBucket) {\n        this.assetBuckets.push(template.assetBucket);\n      }\n      InputValidator.validateUrl(this.node.path, 'provisioning template url', template.httpUrl);\n      return {\n        name: productVersion.productVersionName,\n        description: productVersion.description,\n        disableTemplateValidation: productVersion.validateTemplate === false ? true : false,\n        info: {\n          LoadTemplateFromURL: template.httpUrl,\n        },\n      };\n    });\n  }\n\n  private validateProductProps(props: CloudFormationProductProps) {\n    InputValidator.validateLength(this.node.path, 'product product name', 1, 100, props.productName);\n    InputValidator.validateLength(this.node.path, 'product owner', 1, 8191, props.owner);\n    InputValidator.validateLength(this.node.path, 'product description', 0, 8191, props.description);\n    InputValidator.validateLength(this.node.path, 'product distributor', 0, 8191, props.distributor);\n    InputValidator.validateEmail(this.node.path, 'support email', props.supportEmail);\n    InputValidator.validateUrl(this.node.path, 'support url', props.supportUrl);\n    InputValidator.validateLength(this.node.path, 'support description', 0, 8191, props.supportDescription);\n    if (props.productVersions.length == 0) {\n      throw new ValidationError(`Invalid product versions for resource ${this.node.path}, must contain at least 1 product version`, this);\n    }\n    props.productVersions.forEach(productVersion => {\n      InputValidator.validateLength(this.node.path, 'provisioning artifact name', 0, 100, productVersion.productVersionName);\n      InputValidator.validateLength(this.node.path, 'provisioning artifact description', 0, 8191, productVersion.description);\n    });\n  }\n}", "language": "typescript"}
{"input": "Represents the VPC origin endpoint.", "output": "class VpcOriginEndpoint {\n  /**\n   * A VPC origin endpoint from an EC2 instance.\n   */\n  public static ec2Instance(instance: IInstance): VpcOriginEndpoint {\n    const endpointArn = Stack.of(instance).formatArn({\n      service: 'ec2',\n      resource: 'instance',\n      resourceName: instance.instanceId,\n    });\n    return { endpointArn, domainName: instance.instancePrivateDnsName };\n  }\n\n  /**\n   * A VPC origin endpoint from an Application Load Balancer.\n   */\n  public static applicationLoadBalancer(alb: IApplicationLoadBalancer): VpcOriginEndpoint {\n    return { endpointArn: alb.loadBalancerArn, domainName: alb.loadBalancerDnsName };\n  }\n\n  /**\n   * A VPC origin endpoint from an Network Load Balancer.\n   */\n  public static networkLoadBalancer(nlb: INetworkLoadBalancer): VpcOriginEndpoint {\n    return { endpointArn: nlb.loadBalancerArn, domainName: nlb.loadBalancerDnsName };\n  }\n\n  /**\n   * The ARN of the CloudFront VPC origin endpoint configuration.\n   */\n  abstract readonly endpointArn: string;\n  /**\n   * The domain name of the CloudFront VPC origin endpoint configuration.\n   * @default - No domain name configured\n   */\n  abstract readonly domainName?: string;\n}", "language": "typescript"}
{"input": "CDK class TransitGatewayRoute for AWS resource management", "output": "export class TransitGatewayRoute extends TransitGatewayRouteBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.TransitGatewayRoute';\n  public readonly routeTable: ITransitGatewayRouteTable;\n  public readonly destinationCidrBlock: string;\n\n  /**\n   * The AWS CloudFormation resource representing the Transit Gateway Route.\n   */\n  public readonly resource: CfnTransitGatewayRoute;\n\n  constructor(scope: Construct, id: string, props: TransitGatewayRouteProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.resource = new CfnTransitGatewayRoute(this, 'TransitGatewayRoute', {\n      blackhole: false,\n      destinationCidrBlock: props.destinationCidrBlock,\n      transitGatewayRouteTableId: props.transitGatewayRouteTable.routeTableId,\n      transitGatewayAttachmentId: props.transitGatewayAttachment?.transitGatewayAttachmentId,\n    });\n\n    this.node.defaultChild = this.resource;\n    this.destinationCidrBlock = this.resource.destinationCidrBlock;\n    this.routeTable = props.transitGatewayRouteTable;\n  }\n}", "language": "typescript"}
{"input": "CDK class RootResource for AWS resource management", "output": "class RootResource extends ResourceBase {\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.RootResource';\n  public readonly parentResource?: IResource;\n  public readonly api: RestApiBase;\n  public readonly resourceId: string;\n  public readonly path: string;\n  public readonly defaultIntegration?: Integration | undefined;\n  public readonly defaultMethodOptions?: MethodOptions | undefined;\n  public readonly defaultCorsPreflightOptions?: CorsOptions | undefined;\n\n  private readonly _restApi?: RestApi;\n\n  constructor(api: RestApiBase, props: ResourceOptions, resourceId: string) {\n    super(api, 'Default');\n    props = applyInjectors(RootResource.PROPERTY_INJECTION_ID, props, {\n      scope: api,\n      id: resourceId,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, resourceId);\n\n    this.parentResource = undefined;\n    this.defaultIntegration = props.defaultIntegration;\n    this.defaultMethodOptions = props.defaultMethodOptions;\n    this.defaultCorsPreflightOptions = props.defaultCorsPreflightOptions;\n    this.api = api;\n    this.resourceId = resourceId;\n    this.path = '/';\n\n    if (api instanceof RestApi) {\n      this._restApi = api;\n    }\n\n    if (this.defaultCorsPreflightOptions) {\n      this.addCorsPreflight(this.defaultCorsPreflightOptions);\n    }\n  }\n\n  /**\n   * Get the RestApi associated with this Resource.\n   * @deprecated - Throws an error if this Resource is not associated with an instance of `RestApi`. Use `api` instead.\n   */\n  public get restApi(): RestApi {\n    if (!this._restApi) {\n      throw new ValidationError('RestApi is not available on Resource not connected to an instance of RestApi. Use `api` instead', this);\n    }\n    return this._restApi;\n  }\n}", "language": "typescript"}
{"input": "CDK class MetricFilter for AWS resource management", "output": "export class MetricFilter extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-logs.MetricFilter';\n  private readonly metricName: string;\n  private readonly metricNamespace: string;\n\n  constructor(scope: Construct, id: string, props: MetricFilterProps) {\n    super(scope, id, {\n      physicalName: props.filterName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.metricName = props.metricName;\n    this.metricNamespace = props.metricNamespace;\n\n    const numberOfDimensions = Object.keys(props.dimensions ?? {}).length;\n    if (numberOfDimensions > 3) {\n      throw new ValidationError(`MetricFilter only supports a maximum of 3 dimensions but received ${numberOfDimensions}.`, this);\n    }\n\n    // It looks odd to map this object to a singleton list, but that's how\n    // we're supposed to do it according to the docs.\n    //\n    // > Currently, you can specify only one metric transformation for\n    // > each metric filter. If you want to specify multiple metric\n    // > transformations, you must specify multiple metric filters.\n    //\n    // https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-metricfilter.html\n    new CfnMetricFilter(this, 'Resource', {\n      logGroupName: props.logGroup.logGroupRef.logGroupName,\n      filterName: this.physicalName,\n      filterPattern: props.filterPattern.logPatternString,\n      metricTransformations: [{\n        metricNamespace: props.metricNamespace,\n        metricName: props.metricName,\n        metricValue: props.metricValue ?? '1',\n        defaultValue: props.defaultValue,\n        dimensions: props.dimensions ? Object.entries(props.dimensions).map(([key, value]) => ({ key, value })) : undefined,\n        unit: props.unit,\n      }],\n      applyOnTransformedLogs: props.applyOnTransformedLogs,\n    });\n  }\n\n  /**\n   * Return the given named metric for this Metric Filter\n   *\n   * @default avg over 5 minutes\n   */\n  @MethodMetadata()\n  public metric(props?: MetricOptions): Metric {\n    return new Metric({\n      metricName: this.metricName,\n      namespace: this.metricNamespace,\n      statistic: 'avg',\n      ...props,\n    }).attachTo(this);\n  }\n}", "language": "typescript"}
{"input": "CDK class LiteralSchedule for AWS resource management", "output": "class LiteralSchedule extends Schedule {\n  constructor(public readonly expressionString: string) {\n    super();\n  }\n\n  public _bind() {}\n}", "language": "typescript"}
{"input": "Specify AWS account ID as the principal entity in a policy to delegate authority to the account.", "output": "export class AccountPrincipal extends ArnPrincipal {\n  public readonly principalAccount: string | undefined;\n\n  /**\n   *\n   * @param accountId AWS account ID (i.e. '123456789012')\n   */\n  constructor(public readonly accountId: any) {\n    super(new StackDependentToken(stack => `arn:${stack.partition}:iam::${accountId}:root`).toString());\n    if (!cdk.Token.isUnresolved(accountId) && typeof accountId !== 'string') {\n      throw new UnscopedValidationError('accountId should be of type string');\n    }\n    this.principalAccount = accountId;\n  }\n\n  public toString() {\n    return `AccountPrincipal(${this.accountId})`;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, VPC, MSK (Kafka), CloudFormation resources", "output": "export class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n    const vpc = new Vpc(this, 'Integ-VPC');\n    new rds.DatabaseCluster(this, 'Integ-Cluster', {\n      engine: rds.DatabaseClusterEngine.auroraMysql({ version: rds.AuroraMysqlEngineVersion.VER_3_08_0 }),\n      serverlessV2MaxCapacity: 1,\n      serverlessV2MinCapacity: 0,\n      serverlessV2AutoPauseDuration: Duration.hours(1),\n      writer: ClusterInstance.serverlessV2('writer'),\n      removalPolicy: RemovalPolicy.DESTROY,\n      vpc: vpc,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, WAF operations", "output": "def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        with open(\"lambda-handler.py\", encoding=\"utf8\") as fp:\n            handler_code = fp.read()\n\n        lambdaFn = lambda_.Function(\n            self, \"Singleton\",\n            code=lambda_.InlineCode(handler_code),\n            handler=\"index.main\",\n            timeout=Duration.seconds(300),\n            runtime=lambda_.Runtime.PYTHON_3_12,\n        )\n\n        # Run every day at 6PM UTC\n        # See https://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html\n        rule = events.Rule(\n            self, \"Rule\",\n            schedule=events.Schedule.cron(\n                minute='0',\n                hour='18',\n                month='*',\n                week_day='MON-FRI',\n                year='*'),\n        )\n        rule.add_target(targets.LambdaFunction(lambdaFn))", "language": "python"}
{"input": "The intrinsic function ``Fn::Select`` returns a single object from a list of objects by index.", "output": "class FnSelect extends FnBase {\n  /**\n   * Creates an ``Fn::Select`` function.\n   * @param index The index of the object to retrieve. This must be a value from zero to N-1, where N represents the number of elements in the array.\n   * @param array The list of objects to select from. This list must not be null, nor can it have null entries.\n   */\n  constructor(index: number, array: any) {\n    super('Fn::Select', [index, array]);\n  }\n}", "language": "typescript"}
{"input": "The day of the month on which the scheduled audit takes place.", "output": "export class DayOfMonth {\n  /**\n   * The last day of the month\n   */\n  public static readonly LAST_DAY = new DayOfMonth('LAST');\n\n  /**\n   * Custom day of the month\n   * @param day the day of the month\n   */\n  public static of(day: number): DayOfMonth {\n    if (day < 1 || day > 31) {\n      throw new Error(`Day of month must be between 1 and 31, got: ${day}`);\n    }\n    if (!Number.isInteger(day)) {\n      throw new Error(`Day of month must be an integer, got: ${day}`);\n    }\n    return new DayOfMonth(String(day));\n  }\n\n  /**\n   *\n   * @param day The day of the month\n   */\n  private constructor(public readonly day: string) {}\n}", "language": "typescript"}
{"input": "CDK class SuffixNamePart for AWS resource management", "output": "class SuffixNamePart extends NamePart {\n  constructor(str: string, private readonly suffixLength: number) {\n    super(str);\n  }\n\n  public generate(): string {\n    const strLen = this.bareStr.length;\n    const startIndex = Math.max(strLen - this.suffixLength, 0);\n    return this.bareStr.slice(startIndex, strLen);\n  }\n}", "language": "typescript"}
{"input": "CDK class BonjourFargate for AWS resource management", "output": "class BonjourFargate extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create VPC and Fargate Cluster\n    // NOTE: Limit AZs to avoid reaching resource quotas\n    const vpc = new ec2.Vpc(this, 'MyVpc', { maxAzs: 2 });\n    const cluster = new ecs.Cluster(this, 'Cluster', { vpc });\n\n    // Instantiate Fargate Service with just cluster and image\n    new ecs_patterns.ApplicationLoadBalancedFargateService(this, \"FargateService\", {\n      cluster,\n      taskImageOptions: {\n        image: ecs.ContainerImage.fromRegistry(\"amazon/amazon-ecs-sample\"),\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, RDS, EC2, VPC resources", "output": "class PostgresS3TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const instanceProps = {\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.MEDIUM),\n      isFromLegacyInstanceProps: true,\n    };\n\n    const importExportBucket = new s3.Bucket(this, 'ImportExportBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    new rds.DatabaseCluster(this, 'PostgresDatabase', {\n      engine: rds.DatabaseClusterEngine.auroraPostgres({\n        version: rds.AuroraPostgresEngineVersion.VER_15_3,\n      }),\n      readers: [rds.ClusterInstance.provisioned('ReaderInstance', instanceProps)],\n      writer: rds.ClusterInstance.provisioned('WriterInstance', instanceProps),\n      vpc,\n      s3ImportBuckets: [importExportBucket],\n      s3ExportBuckets: [importExportBucket],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, WAF, CloudFormation, Config resources", "output": "export class CloudFormationStackDriftDetectionCheck extends ManagedRule {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.CloudFormationStackDriftDetectionCheck';\n  private readonly role: iam.IRoleRef;\n\n  constructor(scope: Construct, id: string, props: CloudFormationStackDriftDetectionCheckProps = {}) {\n    super(scope, id, {\n      ...props,\n      identifier: ManagedRuleIdentifiers.CLOUDFORMATION_STACK_DRIFT_DETECTION_CHECK,\n      inputParameters: {\n        cloudformationRoleArn: Lazy.string({ produce: () => this.role.roleRef.roleArn }),\n      },\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.ruleScope = RuleScope.fromResource( ResourceType.CLOUDFORMATION_STACK, props.ownStackOnly ? Stack.of(this).stackId : undefined );\n\n    this.role = props.role || new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('config.amazonaws.com'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('ReadOnlyAccess'),\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, DynamoDB operations", "output": "def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n    super().__init__(scope, construct_id, **kwargs)\n\n    global network_security_policy, encryption_security_policy, data_access_policy\n    global COLLECTION_NAME, PIPELINE_NAME, DYNAMO_TABLE_NAME, S3_EXPORT_BUCKET_FOR_DDB, NETWORK_POLICY_NAME\n\n    random_id = random.randint(0, 100)\n    STACK_NAMING_PREFIX = f'ddb-to-aoss-{random_id}'\n\n    STACK_RESOURCE_NAMING_PREFIX = 'DdbAossZetl'\n\n    COLLECTION_NAME = f'{STACK_NAMING_PREFIX}-col'\n    PIPELINE_NAME = f'{STACK_NAMING_PREFIX}-pipe'\n    DYNAMO_TABLE_NAME = f'{STACK_NAMING_PREFIX}-table'\n    S3_EXPORT_BUCKET_FOR_DDB = f'{STACK_NAMING_PREFIX}-buck'\n    NETWORK_POLICY_NAME = f'{COLLECTION_NAME}-net-pol'\n    ENCRYPTION_POLICY_NAME = f'{COLLECTION_NAME}-encr-pol'\n    DATA_ACCESS_POLICY_NAME = f\"{COLLECTION_NAME}-data-pol\"\n\n    USER_ARN = self.node.try_get_context('iam_user_arn')\n    if not USER_ARN:\n      print(\n        'Specify the IAM role or user that will be used to access OpenSearch Dashboards by adding '\n        '\"-c iam_user_arn=\\'<my-iam-arn>\\'\" to your cdk commands')\n\n    ################################################################################\n    # Create OpenSearch Serverless network access policy\n\n    network_security_policy = json.dumps([{\n      \"Rules\": [\n        {\n          \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n          \"ResourceType\": \"dashboard\"\n        }\n      ],\n      \"AllowFromPublic\": True\n    }], indent=2)\n\n    cfn_network_security_policy = opss.CfnSecurityPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}NetPolicy',\n                                                         policy=network_security_policy,\n                                                         name=NETWORK_POLICY_NAME,\n                                                         type=\"network\"\n                                                         )\n\n    ################################################################################\n    # Create OpenSearch Serverless encryption policy\n\n    encryption_security_policy = json.dumps({\n      \"Rules\": [{\n        \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n        \"ResourceType\": \"collection\"\n      }],\n      \"AWSOwnedKey\": True\n    }, indent=2)\n\n    cfn_encryption_security_policy = opss.CfnSecurityPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}EncPolicy',\n                                                            policy=encryption_security_policy,\n                                                            name=ENCRYPTION_POLICY_NAME,\n                                                            type=\"encryption\"\n                                                            )\n\n    ################################################################################\n    # Create OpenSearch Serverless collection\n\n    cfn_collection = opss.CfnCollection(self, f'{STACK_RESOURCE_NAMING_PREFIX}Collection',\n                                        name=COLLECTION_NAME,\n                                        description=\"Collection to be used for search from CDK\",\n                                        type=\"SEARCH\"\n                                        )\n    cfn_collection.add_dependency(cfn_network_security_policy)\n    cfn_collection.add_dependency(cfn_encryption_security_policy)\n\n    ################################################################################\n    # Create IAM role for OpenSearch Ingestion pipeline\n\n    pipeline_role = iam.Role(self, f'{STACK_RESOURCE_NAMING_PREFIX}PipelineRole',\n                             role_name=f'{STACK_RESOURCE_NAMING_PREFIX}PipelineRole',\n                             assumed_by=iam.ServicePrincipal('osis-pipelines.amazonaws.com'),\n                             inline_policies={\n                               'collection-pipeline-policy': self.collection_pipeline_policy_doc(\n                                 cfn_collection.attr_arn)\n                             }\n                             )\n\n    ################################################################################\n    # Create S3 Bucket for export\n\n    s3_bucket = s3.Bucket(self, f'{STACK_RESOURCE_NAMING_PREFIX}Bucket',\n                          block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n                          bucket_name=S3_EXPORT_BUCKET_FOR_DDB,\n                          encryption=s3.BucketEncryption.S3_MANAGED,\n                          enforce_ssl=True,\n                          versioned=True,\n                          removal_policy=cdk.RemovalPolicy.DESTROY\n                          )\n\n    s3_bucket_policy_statement = iam.PolicyStatement(\n      effect=iam.Effect.ALLOW,\n      resources=[f'arn:aws:s3:::{S3_EXPORT_BUCKET_FOR_DDB}/*'],\n      actions=[\n        \"s3:GetObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ],\n      principals=[iam.ArnPrincipal(pipeline_role.role_arn)]\n    )\n\n    # Add the policy to the bucket\n    s3_bucket.add_to_resource_policy(s3_bucket_policy_statement)\n\n    ################################################################################\n    # Create DynamoDB Table\n\n    dynamo_db_table = ddb.TableV2(self, f'{STACK_RESOURCE_NAMING_PREFIX}Table',\n                                  partition_key=ddb.Attribute(name=\"id\", type=ddb.AttributeType.STRING),\n                                  sort_key=ddb.Attribute(name=\"timestamp\", type=ddb.AttributeType.NUMBER),\n                                  table_name=DYNAMO_TABLE_NAME,\n                                  billing=ddb.Billing.on_demand(),\n                                  point_in_time_recovery=True,\n                                  dynamo_stream=ddb.StreamViewType.NEW_IMAGE,\n                                  removal_policy=cdk.RemovalPolicy.DESTROY\n                                  )\n\n    ################################################################################\n    # Create OpenSearch Ingestion pipeline\n\n    log_group_name = f\"/aws/vendedlogs/OpenSearchIngestion/{PIPELINE_NAME}/audit-logs\"\n    osis_pipeline_log_group = aws_logs.LogGroup(self, f'{STACK_RESOURCE_NAMING_PREFIX}LogGroup',\n                                                log_group_name=log_group_name,\n                                                retention=aws_logs.RetentionDays.THREE_DAYS,\n                                                removal_policy=cdk.RemovalPolicy.DESTROY\n                                                )\n\n    pipeline_configuration_body = self.get_pipeline_configuration(table_arn=dynamo_db_table.table_arn,\n                                                             role_arn=pipeline_role.role_arn,\n                                                             collection_endpoint=cfn_collection.attr_collection_endpoint)\n\n    cfn_pipeline = osi.CfnPipeline(self, f'{STACK_RESOURCE_NAMING_PREFIX}Pipeline',\n                                   max_units=4,\n                                   min_units=1,\n                                   pipeline_configuration_body=pipeline_configuration_body,\n                                   pipeline_name=PIPELINE_NAME,\n                                   log_publishing_options=osi.CfnPipeline.LogPublishingOptionsProperty(\n                                     cloud_watch_log_destination=osi.CfnPipeline.CloudWatchLogDestinationProperty(\n                                       log_group=log_group_name,\n                                     ),\n                                     is_logging_enabled=True\n                                   )\n                                   )\n    cfn_pipeline.add_dependency(cfn_collection)\n\n    ################################################################################\n    # Create OpenSearch Serverless data access policy\n\n    data_access_policy_principals = [pipeline_role.role_arn]\n    if USER_ARN:\n      data_access_policy_principals.append(USER_ARN)\n\n    data_access_policy = json.dumps([{\n      \"Rules\": [\n        {\n          \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n          \"Permission\": [\n            \"aoss:CreateCollectionItems\",\n            \"aoss:DeleteCollectionItems\",\n            \"aoss:UpdateCollectionItems\",\n            \"aoss:DescribeCollectionItems\"\n          ],\n          \"ResourceType\": \"collection\"\n        },\n        {\n          \"Resource\": [f\"index/{COLLECTION_NAME}/*\"],\n          \"Permission\": [\n            \"aoss:CreateIndex\",\n            \"aoss:DeleteIndex\",\n            \"aoss:UpdateIndex\",\n            \"aoss:DescribeIndex\",\n            \"aoss:ReadDocument\",\n            \"aoss:WriteDocument\"\n          ],\n          \"ResourceType\": \"index\"\n        }\n      ],\n      \"Principal\": data_access_policy_principals,\n      \"Description\": \"data-access-rule\"\n    }], indent=2)\n\n    cfn_access_policy = opss.CfnAccessPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}DataPolicy',\n                                             name=DATA_ACCESS_POLICY_NAME,\n                                             description=\"Policy for data access\",\n                                             policy=data_access_policy,\n                                             type=\"data\"\n                                             )\n    cfn_access_policy.add_dependency(cfn_collection)\n    cfn_access_policy.add_dependency(cfn_pipeline)", "language": "python"}
{"input": "Capacity provider options", "output": "export class CapacityProviderOptions {\n  /**\n   * Use a custom capacity provider strategy.\n   *\n   * You can specify between 1 and 20 capacity providers.\n   *\n   * @param capacityProviderStrategy The capacity provider strategy to use for the task.\n   */\n  public static custom(capacityProviderStrategy: ecs.CapacityProviderStrategy[]): CapacityProviderOptions {\n    if (capacityProviderStrategy.length < 1 || capacityProviderStrategy.length > 20) {\n      throw new cdk.UnscopedValidationError(\n        `Capacity provider strategy must contain between 1 and 20 capacity providers, got ${capacityProviderStrategy.length}`,\n      );\n    }\n    return new CapacityProviderOptions(capacityProviderStrategy);\n  }\n\n  /**\n   * Use the cluster's default capacity provider strategy.\n   */\n  public static default(): CapacityProviderOptions {\n    return new CapacityProviderOptions();\n  }\n\n  private constructor(private readonly capacityProviderStrategy: ecs.CapacityProviderStrategy[] = []) {}\n\n  /**\n   * @internal\n   */\n  _bind(): ecs.CapacityProviderStrategy[] {\n    return this.capacityProviderStrategy;\n  }\n}\n\n/**\n * Configuration for running an ECS task on Fargate\n *\n * @see https://docs.aws.amazon.com/AmazonECS/latest/userguide/launch_types.html#launch-type-fargate\n */\nexport class EcsFargateLaunchTarget implements IEcsLaunchTarget {\n  constructor(private readonly options?: EcsFargateLaunchTargetOptions) {}\n\n  /**\n   * Called when the Fargate launch type configured on RunTask\n   */\n  public bind(task: EcsRunTask, launchTargetOptions: LaunchTargetBindOptions): EcsLaunchTargetConfig {\n    if (!launchTargetOptions.taskDefinition.isFargateCompatible) {\n      throw new ValidationError('Supplied TaskDefinition is not compatible with Fargate', task);\n    }\n\n    // If neither `launchType` nor `capacityProviderStrategy` is specified,\n    // the cluster's `defaultCapacityProviderStrategy` is used.\n    const launchType = this.options?.capacityProviderOptions ? undefined : ecs.LaunchType.FARGATE;\n    const capacityProviderStrategyList = this.options?.capacityProviderOptions?._bind();\n    const capacityProviderStrategy = capacityProviderStrategyList?.length ? capacityProviderStrategyList.map((s) => ({\n      CapacityProvider: s.capacityProvider,\n      Weight: s.weight,\n      Base: s.base,\n    })) : undefined;\n\n    return {\n      parameters: {\n        LaunchType: launchType,\n        CapacityProviderStrategy: capacityProviderStrategy,\n        PlatformVersion: this.options?.platformVersion,\n      },\n    };\n  }", "language": "typescript"}
{"input": "CDK Stack that creates EC2, CloudFormation, EKS resources", "output": "class CapacityStack extends cdk.Stack {\n      public group: asg.AutoScalingGroup;\n\n      constructor(scope: Construct, id: string, props: cdk.StackProps & { cluster: eks.Cluster }) {\n        super(scope, id, props);\n\n        // the role is create in this stack implicitly by the ASG\n        this.group = new asg.AutoScalingGroup(this, 'autoScaling', {\n          instanceType: new ec2.InstanceType('t3.medium'),\n          vpc: props.cluster.vpc,\n          machineImage: new eks.EksOptimizedImage({\n            kubernetesVersion: CLUSTER_VERSION.version,\n            nodeType: eks.NodeType.STANDARD,\n          }),\n        });\n      }\n    }", "language": "typescript"}
{"input": "AppSync definition. Specify how you want to define your AppSync API.", "output": "class Definition {\n  /**\n   * Schema from schema object.\n   * @param schema SchemaFile.fromAsset(filePath: string) allows schema definition through schema.graphql file\n   * @returns Definition with schema from file\n   */\n  public static fromSchema(schema: ISchema): Definition {\n    return {\n      schema,\n    };\n  }\n\n  /**\n   * Schema from file, allows schema definition through schema.graphql file\n   * @param filePath the file path of the schema file\n   * @returns Definition with schema from file\n   */\n  public static fromFile(filePath: string): Definition {\n    return this.fromSchema(SchemaFile.fromAsset(filePath));\n  }\n\n  /**\n   * Schema from existing AppSync APIs - used for creating a AppSync Merged API\n   * @param sourceApiOptions Configuration for AppSync Merged API\n   * @returns Definition with for AppSync Merged API\n   */\n  public static fromSourceApis(sourceApiOptions: SourceApiOptions): Definition {\n    return {\n      sourceApiOptions,\n    };\n  }\n\n  /**\n   * Schema, when AppSync API is created from schema file\n   */\n  readonly schema?: ISchema;\n\n  /**\n   * Source APIs for Merged API\n   */\n  readonly sourceApiOptions?: SourceApiOptions;\n}", "language": "typescript"}
{"input": "CDK class ApplicationMultipleTargetGroupsFargateService for AWS resource management", "output": "export class ApplicationMultipleTargetGroupsFargateService extends ApplicationMultipleTargetGroupsServiceBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs-patterns.ApplicationMultipleTargetGroupsFargateService';\n\n  /**\n   * Determines whether the service will be assigned a public IP address.\n   */\n  public readonly assignPublicIp: boolean;\n\n  /**\n   * The Fargate service in this construct.\n   */\n  public readonly service: FargateService;\n\n  /**\n   * The Fargate task definition in this construct.\n   */\n  public readonly taskDefinition: FargateTaskDefinition;\n\n  /**\n   * The default target group for the service.\n   * @deprecated - Use `targetGroups` instead.\n   */\n  public readonly targetGroup: ApplicationTargetGroup;\n\n  /**\n   * Constructs a new instance of the ApplicationMultipleTargetGroupsFargateService class.\n   */\n  constructor(scope: Construct, id: string, props: ApplicationMultipleTargetGroupsFargateServiceProps = {}) {\n    super(scope, id, props);\n\n    this.assignPublicIp = props.assignPublicIp ?? false;\n\n    if (props.taskDefinition && props.taskImageOptions) {\n      throw new ValidationError('You must specify only one of TaskDefinition or TaskImageOptions.', this);\n    } else if (props.taskDefinition) {\n      this.taskDefinition = props.taskDefinition;\n    } else if (props.taskImageOptions) {\n      const taskImageOptions = props.taskImageOptions;\n      this.taskDefinition = new FargateTaskDefinition(this, 'TaskDef', {\n        memoryLimitMiB: props.memoryLimitMiB,\n        cpu: props.cpu,\n        ephemeralStorageGiB: props.ephemeralStorageGiB,\n        executionRole: taskImageOptions.executionRole,\n        taskRole: taskImageOptions.taskRole,\n        family: taskImageOptions.family,\n        runtimePlatform: props.runtimePlatform,\n      });\n\n      const containerName = taskImageOptions.containerName ?? 'web';\n      const container = this.taskDefinition.addContainer(containerName, {\n        image: taskImageOptions.image,\n        logging: this.logDriver,\n        environment: taskImageOptions.environment,\n        secrets: taskImageOptions.secrets,\n        dockerLabels: taskImageOptions.dockerLabels,\n      });\n      if (taskImageOptions.containerPorts) {\n        for (const containerPort of taskImageOptions.containerPorts) {\n          container.addPortMappings({\n            containerPort,\n          });\n        }\n      }\n    } else {\n      throw new ValidationError('You must specify one of: taskDefinition or image', this);\n    }\n    if (!this.taskDefinition.defaultContainer) {\n      throw new ValidationError('At least one essential container must be specified', this);\n    }\n    if (this.taskDefinition.defaultContainer.portMappings.length === 0) {\n      this.taskDefinition.defaultContainer.addPortMappings({\n        containerPort: 80,\n      });\n    }\n\n    this.service = this.createFargateService(props);\n    if (props.targetGroups) {\n      this.addPortMappingForTargets(this.taskDefinition.defaultContainer, props.targetGroups);\n      this.targetGroup = this.registerECSTargets(this.service, this.taskDefinition.defaultContainer, props.targetGroups);\n    } else {\n      this.targetGroup = this.listener.addTargets('ECS', {\n        targets: [this.service],\n        port: this.taskDefinition.defaultContainer.portMappings[0].containerPort,\n      });\n    }\n  }\n\n  private createFargateService(props: ApplicationMultipleTargetGroupsFargateServiceProps): FargateService {\n    const desiredCount = FeatureFlags.of(this).isEnabled(cxapi.ECS_REMOVE_DEFAULT_DESIRED_COUNT) ? this.internalDesiredCount : this.desiredCount;\n\n    return new FargateService(this, 'Service', {\n      cluster: this.cluster,\n      desiredCount: desiredCount,\n      taskDefinition: this.taskDefinition,\n      assignPublicIp: this.assignPublicIp,\n      serviceName: props.serviceName,\n      healthCheckGracePeriod: props.healthCheckGracePeriod,\n      propagateTags: props.propagateTags,\n      enableECSManagedTags: props.enableECSManagedTags,\n      cloudMapOptions: props.cloudMapOptions,\n      platformVersion: props.platformVersion,\n      enableExecuteCommand: props.enableExecuteCommand,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudWatch, CloudFormation, CloudFront resources", "output": "class DistributionMetricsTestStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // CloudFront distribution setup\n    const distribution = new cloudfront.Distribution(this, 'Dist', {\n      defaultBehavior: { origin: new TestOrigin('www.example.com') },\n    });\n\n    // Utility function to create alarms\n    const createAlarm = (alarmName: string, metric: cloudwatch.Metric) => {\n      return new cloudwatch.Alarm(this, alarmName, {\n        evaluationPeriods: 1,\n        threshold: 1,\n        comparisonOperator: cloudwatch.ComparisonOperator.GREATER_THAN_THRESHOLD,\n        metric: metric,\n      });\n    };\n\n    createAlarm('Alarm1', distribution.metricRequests());\n    createAlarm('Alarm2', distribution.metricBytesUploaded());\n    createAlarm('Alarm3', distribution.metricBytesDownloaded());\n    createAlarm('Alarm4', distribution.metric4xxErrorRate());\n    createAlarm('Alarm5', distribution.metric5xxErrorRate());\n    createAlarm('Alarm6', distribution.metricTotalErrorRate());\n  }\n}", "language": "typescript"}
{"input": "Peer dependencies should be a range, not a point version, to maximize compatibility", "output": "export class PeerDependencyRange extends ValidationRule {\n  public readonly name = 'peerdependency/range';\n\n  public validate(pkg: PackageJson) {\n    const packages = ['aws-cdk-lib'];\n    for (const [name, version] of Object.entries(pkg.peerDependencies)) {\n      if (packages.includes(name) && version.match(/^[0-9]/)) {\n        pkg.report({\n          ruleName: this.name,\n          message: `peerDependency on\" ${name}\" should be a range, not a point version: \"${version}\"`,\n          fix: () => {\n            pkg.addPeerDependency(name, '^' + version);\n          },\n        });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function get_pipeline_configuration", "output": "def get_pipeline_configuration(self, table_arn, role_arn, collection_endpoint):\n\n    replacements = [\n      lambda x: x.replace(\"%%%DYNAMODB_TABLE_ARN%%%\", table_arn),\n      lambda x: x.replace(\"%%%S3_BUCKET_NAME%%%\", S3_EXPORT_BUCKET_FOR_DDB),\n      lambda x: x.replace(\"%%%REGION%%%\", cdk.Aws.REGION),\n      lambda x: x.replace(\"%%%DYNAMODB_TABLE_NAME%%%\", table_arn),\n      lambda x: x.replace(\"%%%ROLE_ARN%%%\", role_arn),\n      lambda x: x.replace(\"%%%COLLECTION_ENDPOINT%%%\", collection_endpoint),\n      lambda x: x.replace(\"%%%NETWORK_POLICY_NAME%%%\", NETWORK_POLICY_NAME)\n    ]\n\n    with open(\"resources/pipeline_configuration.yaml\", 'r') as pipeline_configuration_file:\n      pipeline_configuration_format = pipeline_configuration_file.read()\n      formatted_pipeline_configuration = pipeline_configuration_format\n\n      for replace in replacements:\n        formatted_pipeline_configuration = replace(formatted_pipeline_configuration)\n\n      return formatted_pipeline_configuration", "language": "python"}
{"input": "CDK class TableBucket for AWS resource management", "output": "export class TableBucket extends TableBucketBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-s3tables-alpha.TableBucket';\n\n  /**\n   * Defines a TableBucket construct from an external table bucket ARN.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param tableBucketArn Amazon Resource Name (arn) of the table bucket\n   */\n  public static fromTableBucketArn(scope: Construct, id: string, tableBucketArn: string): ITableBucket {\n    return TableBucket.fromTableBucketAttributes(scope, id, { tableBucketArn });\n  }\n\n  /**\n   * Defines a TableBucket construct that represents an external table bucket.\n   *\n   * @param scope The parent creating construct (usually `this`).\n   * @param id The construct's name.\n   * @param attrs A `TableBucketAttributes` object. Can be manually created.\n   */\n  public static fromTableBucketAttributes(\n    scope: Construct,\n    id: string,\n    attrs: TableBucketAttributes,\n  ): ITableBucket {\n    const { tableBucketName, region, account, tableBucketArn } = validateTableBucketAttributes(scope, attrs);\n    TableBucket.validateTableBucketName(tableBucketName);\n    class Import extends TableBucketBase {\n      public readonly tableBucketName = tableBucketName!;\n      public readonly tableBucketArn = tableBucketArn;\n      public readonly tableBucketPolicy?: TableBucketPolicy;\n      public readonly region = region;\n      public readonly account = account;\n      public readonly encryptionKey?: kms.IKey = attrs.encryptionKey;\n      protected autoCreatePolicy: boolean = false;\n\n      /**\n       * Exports this bucket from the stack.\n       */\n      public export() {\n        return attrs;\n      }\n    }\n\n    return new Import(scope, id, {\n      account,\n      region,\n      physicalName: tableBucketName,\n    });\n  }\n\n  /**\n   * Throws an exception if the given table bucket name is not valid.\n   *\n   * @param bucketName name of the bucket.\n   */\n  public static validateTableBucketName(\n    bucketName: string | undefined,\n  ) {\n    if (bucketName == undefined || Token.isUnresolved(bucketName)) {\n      // the name is a late-bound value, not a defined string, so skip validation\n      return;\n    }\n\n    const errors: string[] = [];\n\n    // Length validation\n    if (bucketName.length < 3 || bucketName.length > 63) {\n      errors.push(\n        'Bucket name must be at least 3 and no more than 63 characters',\n      );\n    }\n\n    // Character set validation\n    const illegalCharsetRegEx = /[^a-z0-9-]/;\n    const allowedEdgeCharsetRegEx = /[a-z0-9]/;\n\n    const illegalCharMatch = bucketName.match(illegalCharsetRegEx);\n    if (illegalCharMatch) {\n      errors.push(\n        'Bucket name must only contain lowercase characters, numbers, and hyphens (-)' +\n          ` (offset: ${illegalCharMatch.index})`,\n      );\n    }\n\n    // Edge character validation\n    if (!allowedEdgeCharsetRegEx.test(bucketName.charAt(0))) {\n      errors.push(\n        'Bucket name must start with a lowercase letter or number (offset: 0)',\n      );\n    }\n    if (\n      !allowedEdgeCharsetRegEx.test(bucketName.charAt(bucketName.length - 1))\n    ) {\n      errors.push(\n        `Bucket name must end with a lowercase letter or number (offset: ${\n          bucketName.length - 1\n        })`,\n      );\n    }\n\n    if (errors.length > 0) {\n      throw new UnscopedValidationError(\n        `Invalid S3 table bucket name (value: ${bucketName})${EOL}${errors.join(EOL)}`,\n      );\n    }\n  }\n\n  /**\n   * Throws an exception if the given unreferencedFileRemovalProperty is not valid.\n   * @param unreferencedFileRemoval configuration for the table bucket\n   */\n  public static validateUnreferencedFileRemoval(\n    unreferencedFileRemoval?: UnreferencedFileRemoval,\n  ): void {\n    // Skip validation if property is not defined\n    if (!unreferencedFileRemoval) {\n      return;\n    }\n\n    const { noncurrentDays, status, unreferencedDays } = unreferencedFileRemoval;\n\n    const errors: string[] = [];\n\n    if (noncurrentDays != undefined) {\n      if (noncurrentDays < 1) {\n        errors.push('noncurrentDays must be at least 1 day');\n      }\n      if (!Number.isInteger(noncurrentDays)) {\n        errors.push('noncurrentDays must be a whole number');\n      }\n    }\n\n    if (unreferencedDays != undefined) {\n      if (unreferencedDays < 1) {\n        errors.push('unreferencedDays must be at least 1 day');\n      }\n      if (!Number.isInteger(noncurrentDays)) {\n        errors.push('unreferencedDays must be a whole number');\n      }\n    }\n\n    const allowedStatus = ['Enabled', 'Disabled'];\n    if (status != undefined && !allowedStatus.includes(status)) {\n      errors.push('status must be one of \\'Enabled\\' or \\'Disabled\\'');\n    }\n\n    if (errors.length > 0) {\n      throw new UnscopedValidationError(\n        `Invalid UnreferencedFileRemovalProperty})${EOL}${errors.join(EOL)}`,\n      );\n    }\n  }\n\n  /**\n   * The underlying CfnTableBucket L1 resource\n   * @internal\n   */\n  private readonly _resource: s3tables.CfnTableBucket;\n\n  /**\n   * The resource policy for this tableBucket.\n   */\n  public readonly tableBucketPolicy?: TableBucketPolicy;\n\n  /**\n   * The unique Amazon Resource Name (arn) of this table bucket\n   */\n  public readonly tableBucketArn: string;\n\n  /**\n   * The name of this table bucket\n   */\n  public readonly tableBucketName: string;\n\n  public readonly encryptionKey?: kms.IKey | undefined;\n\n  protected autoCreatePolicy: boolean = true;\n\n  constructor(scope: Construct, id: string, props: TableBucketProps) {\n    super(scope, id, {\n      physicalName: props.tableBucketName,\n    });\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    TableBucket.validateTableBucketName(props.tableBucketName);\n    TableBucket.validateUnreferencedFileRemoval(props.unreferencedFileRemoval);\n    const { bucketEncryption, encryptionKey } = this.parseEncryption(props);\n    this.encryptionKey = encryptionKey;\n\n    this._resource = new s3tables.CfnTableBucket(this, id, {\n      tableBucketName: props.tableBucketName,\n      unreferencedFileRemoval: {\n        ...props.unreferencedFileRemoval,\n        noncurrentDays: props.unreferencedFileRemoval?.noncurrentDays,\n        unreferencedDays: props.unreferencedFileRemoval?.unreferencedDays,\n      },\n      encryptionConfiguration: bucketEncryption,\n    });\n\n    this.tableBucketName = this.getResourceNameAttribute(this._resource.ref);\n    this.tableBucketArn = this._resource.attrTableBucketArn;\n    this._resource.applyRemovalPolicy(props.removalPolicy);\n  }\n\n  /**\n   * Set up key properties and return the Bucket encryption property from the\n   * user's configuration, according to the following table:\n   *\n   * | props.encryption | props.encryptionKey | bucketEncryption (return value) | encryptionKey (return value)  |\n   * |------------------|---------------------|---------------------------------|-------------------------------|\n   * | undefined        | undefined           | undefined                       | undefined                     |\n   * | undefined        | k                   | aws:kms                         | k                             |\n   * | KMS              | undefined           | aws:kms                         | new key (allow maintenance SP)|\n   * | KMS              | k                   | aws:kms                         | k                             |\n   * | S3_MANAGED       | undefined           | AES256                          | undefined                     |\n   * | S3_MANAGED       | k                   | ERROR!                          | ERROR!                        |\n   */\n  private parseEncryption(props: TableBucketProps): {\n    bucketEncryption?: s3tables.CfnTableBucket.EncryptionConfigurationProperty;\n    encryptionKey?: kms.IKey;\n  } {\n    const encryptionType = props.encryption;\n    let key = props.encryptionKey;\n\n    if (encryptionType === undefined) {\n      if ( key === undefined ) {\n        return { bucketEncryption: undefined, encryptionKey: undefined };\n      } else {\n        return {\n          bucketEncryption: {\n            kmsKeyArn: key.keyArn,\n            sseAlgorithm: TableBucketEncryption.KMS,\n          },\n          encryptionKey: key,\n        };\n      }\n    }\n\n    if (encryptionType === TableBucketEncryption.KMS) {\n      if ( key === undefined ) {\n        key = new kms.Key(this, 'Key', {\n          description: `Created by ${this.node.path}`,\n          enableKeyRotation: true,\n        });\n        this.allowTablesMaintenanceAccessToKey(key, props.tableBucketName);\n      }\n      return {\n        bucketEncryption: {\n          kmsKeyArn: key.keyArn,\n          sseAlgorithm: TableBucketEncryption.KMS,\n        },\n        encryptionKey: key,\n      };\n    }\n\n    if (encryptionType === TableBucketEncryption.S3_MANAGED) {\n      if ( key === undefined ) {\n        return {\n          bucketEncryption: {\n            sseAlgorithm: TableBucketEncryption.S3_MANAGED,\n          },\n        };\n      } else {\n        throw new UnscopedValidationError('Expected encryption = `KMS` with user provided encryption key');\n      }\n    }\n    throw new UnscopedValidationError(`Unknown encryption configuration detected: ${props.encryption} with key ${props.encryptionKey}`);\n  }\n\n  /**\n   * Allowlist S3 Tables Maintenance to access this table bucket's encryption key\n   *\n   * @see https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-kms-permissions.html\n   * @param encryptionKey The key to provide access to\n   */\n  private allowTablesMaintenanceAccessToKey(encryptionKey: kms.IKey, tableBucketName: string) {\n    const region = this.stack.region;\n    const account = this.stack.account;\n    const partition = this.stack.partition;\n\n    encryptionKey.addToResourcePolicy(new iam.PolicyStatement({\n      sid: 'AllowS3TablesMaintenanceAccess',\n      effect: iam.Effect.ALLOW,\n      principals: [\n        new iam.ServicePrincipal('maintenance.s3tables.amazonaws.com'),\n      ],\n      actions: [\n        'kms:GenerateDataKey',\n        'kms:Decrypt',\n      ],\n      resources: ['*'],\n      conditions: {\n        StringLike: {\n          'kms:EncryptionContext:aws:s3:arn': `arn:${partition}:s3tables:${region}:${account}:bucket/${tableBucketName}/*`,\n        },\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class GuardrailVersion for AWS resource management", "output": "export class GuardrailVersion extends GuardrailVersionBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-alpha.GuardrailVersion';\n\n  /**\n   * Import a Guardrail Version from its attributes.\n   */\n  public static fromGuardrailVersionAttributes(\n    scope: Construct,\n    id: string,\n    attrs: GuardrailVersionAttributes,\n  ): IGuardrailVersion {\n    class Import extends GuardrailVersionBase {\n      public readonly guardrail = Guardrail.fromGuardrailAttributes(scope, `Guardrail-${id}`, {\n        guardrailArn: attrs.guardrailArn,\n        guardrailVersion: attrs.guardrailVersion,\n      });\n      public readonly guardrailVersion = attrs.guardrailVersion;\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly guardrail: IGuardrail;\n  public readonly guardrailVersion: string;\n  /**\n   * The underlying CfnGuardrailVersion resource.\n   */\n  private readonly _resource: CfnGuardrailVersion;\n\n  /**\n   *\n   */\n  constructor(scope: Construct, id: string, props: GuardrailVersionProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    this.guardrail = props.guardrail;\n\n    // Compute hash from guardrail, to recreate the resource when guardrail has changed\n    const hash = md5hash(props.guardrail.lastUpdated ?? 'Default');\n\n    this._resource = new CfnGuardrailVersion(this, `GuardrailVersion-${hash.slice(0, 16)}`, {\n      guardrailIdentifier: this.guardrail.guardrailId,\n      description: props.description,\n    });\n\n    this.guardrailVersion = this._resource.attrVersion;\n  }\n}", "language": "typescript"}
{"input": "Function to create IAM Role for Datasync", "output": "def create_datasync_roles(self, bucket_configs):\n        # Create a list of bucket paths ending in /* for IAM policy\n        suffix = \"/*\"\n        i=0\n        datasync_s3_roles = []\n\n        for bc in bucket_configs:\n            # Create an IAM Role for DataSync to read and write to S3 bucket\n            # Create an IAM role\n            \n            role_name=\"CDKDataSyncS3Access-\" + bc[\"bucketName\"]\n            s3_role = iam.Role(\n                self, \"CDKDataSyncS3AccessRole\"+str(i),\n                assumed_by=iam.ServicePrincipal(\"datasync.amazonaws.com\"),\n                description=\"CDK Datasync role for S3\",\n                role_name=role_name\n            )\n            \n            stmt1 = iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        actions=[\"s3:GetBucketLocation\", \"s3:ListBucket\",\"s3:ListBucketMultipartUploads\"],\n                        resources=[bc[\"arn\"]]\n                        )\n            \n            stmt2 = iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        actions=[\"s3:AbortMultipartUpload\", \"s3:DeleteObject\",\"s3:GetObject\",\"s3:ListMultipartUploadParts\",\"s3:PutObjectTagging\",\"s3:GetObjectTagging\",\"s3:PutObject\"],\n                        resources=[bc[\"arn\"]+suffix]\n                    )\n            \n            s3_policy = iam.ManagedPolicy(self,\"CDKDataSyncS3Policy\"+str(i), statements = [stmt1, stmt2], roles = [s3_role])\n\n            datasync_s3_roles.append(s3_role)\n            \n            # Export the name using the same format as the Role name\n            # This will be important by downstream Stack\n            CfnOutput(self, role_name, value=s3_role.role_arn, export_name=role_name)\n            \n            i = i+1\n        \n        return datasync_s3_roles", "language": "python"}
{"input": "CDK class FakeTableL2 for AWS resource management", "output": "class FakeTableL2 extends Resource {\n    constructor(scope: Construct, id: string) {\n      super(scope, id);\n\n      new CfnTable(this, 'Resource', {\n        keySchema: [{ attributeName: 'hash', keyType: 'S' }],\n      });\n    }\n  }", "language": "typescript"}
{"input": "CDK class StringDefinitionBody for AWS resource management", "output": "export class StringDefinitionBody extends DefinitionBody {\n  constructor(public readonly body: string) {\n    super();\n  }\n\n  public bind(_scope: Construct, _sfnPrincipal: iam.IPrincipal, _sfnProps: StateMachineProps, _graph?: StateGraph): DefinitionConfig {\n    return {\n      definitionString: this.body,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class MyFirstResource for AWS resource management", "output": "class MyFirstResource extends AbstractCfnResource {\n      public readonly lazykey: string;\n\n      constructor(scope: Construct, id: string) {\n        super(scope, id);\n        this.lazykey = Lazy.string({ produce: () => 'LazyResolved!' });\n      }\n\n      protected get cfnProperties(): { [key: string]: any } {\n        return {\n          lazykey: this.lazykey,\n        };\n      }\n    }", "language": "typescript"}
{"input": "CDK class DockerAssetApp for AWS resource management", "output": "export class DockerAssetApp extends Stage {\n  constructor(scope: Construct, id: string, props?: StageProps) {\n    super(scope, id, props);\n    const stack = new Stack(this, 'Stack');\n    new ecr_assets.DockerImageAsset(stack, 'Asset', {\n      directory: path.join(__dirname, 'assets', 'test-docker-asset'),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function test_athena_queries_created", "output": "def test_athena_queries_created(template):\n    template.resource_count_is(type=\"AWS::Athena::NamedQuery\", count=3)\n\n    template.has_resource_properties(type=\"AWS::Athena::NamedQuery\",\n                                     props={\n                                         \"Database\": \"log-database\",\n                                         \"Name\": \"product-events-by-date\",\n                                         \"QueryString\": \"SELECT * FROM \\\"log-database\\\".\\\"products\\\" WHERE \\\"date\\\" = '2024-01-19'\",\n                                         \"WorkGroup\": \"log-auditing\"\n                                     })\n\n    template.has_resource_properties(type=\"AWS::Athena::NamedQuery\",\n                                     props={\n                                         \"Database\": \"log-database\",\n                                         \"Name\": \"user-events-by-date\",\n                                         \"QueryString\": \"SELECT * FROM \\\"log-database\\\".\\\"users\\\" WHERE \\\"date\\\" = '2024-01-22'\",\n                                         \"WorkGroup\": \"log-auditing\"\n                                     })\n\n    template.has_resource_properties(type=\"AWS::Athena::NamedQuery\",\n                                     props={\n                                         \"Database\": \"log-database\",\n                                         \"Name\": \"all-events-by-userId\",\n                                         \"QueryString\": \"SELECT * FROM (\\n\"\n                                                        \"    SELECT transactionid, userid, username, domain, datetime, action FROM \\\"log-database\\\".\\\"products\\\" \\n\"\n                                                        \"UNION \\n\"\n                                                        \"    SELECT transactionid, userid, username, domain, datetime, action FROM \\\"log-database\\\".\\\"users\\\" \\n\"\n                                                        \") WHERE \\\"userid\\\" = '123'\",\n                                         \"WorkGroup\": \"log-auditing\"\n                                     })", "language": "python"}
{"input": "references between siblings", "output": "class ProducerNestedStack extends NestedStack {\n  public readonly topic: sns.Topic;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    this.topic = new sns.Topic(this, 'MyTopic');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, EC2, API Gateway resources", "output": "export class ApiGatewayParallelStepFunctionsStack extends cdk.Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const { vpc: vpcLambda } = new VpcNestedStack(this, 'nested-stack-lambda');\n\n    const lambdaFunction1 = new lambda.Function(this, 'lambda-function-1', {\n      runtime: lambda.Runtime.NODEJS_18_X,\n      vpc: vpcLambda,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n      },\n      memorySize: 128,\n      timeout: cdk.Duration.seconds(5),\n      handler: 'index.main',\n      code: lambda.Code.fromAsset(path.join(__dirname, '/my-lambda-1')),\n      environment: {\n        VPC_CIDR: vpcLambda.vpcCidrBlock,\n        VPC_ID: vpcLambda.vpcId,\n      },\n      logRetention: logs.RetentionDays.ONE_DAY,\n    })\n\n    const lambdaFunction2 = new lambda.Function(this, 'lambda-function-2', {\n      runtime: lambda.Runtime.NODEJS_18_X,\n      vpc: vpcLambda,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n      },\n      memorySize: 128,\n      timeout: cdk.Duration.seconds(10),\n      handler: 'index.main',\n      code: lambda.Code.fromAsset(path.join(__dirname, '/my-lambda-2')),\n      environment: {\n        VPC_CIDR: vpcLambda.vpcCidrBlock,\n        VPC_ID: vpcLambda.vpcId,\n      },\n      logRetention: logs.RetentionDays.ONE_DAY,\n    })\n\n    // Do 2 different jobs in parallel\n    const parallel = new stepFunctions.Parallel(this, 'two-jobs', {\n      resultPath: '$.CombinedOutput'\n    })\n      .branch(\n        new MyJob(this, 'quick-job', {\n          lambdaFunction: lambdaFunction1,\n        }).prefixStates()\n      )\n      .branch(\n        new MyJob(this, 'slow-job', {\n          lambdaFunction: lambdaFunction2,\n        }).prefixStates()\n      );\n\n    const merge = new stepFunctions.Pass(this, 'merge-outcomes', {\n      parameters: {\n        'normal.$': '$.CombinedOutput[0].Payload.body',\n        'fast.$': '$.CombinedOutput[1].Payload.body',\n      },\n    });\n\n    parallel.next(merge);\n\n    const stfLogGroup = new logs.LogGroup(this, 'stepfunctions-loggroup');\n    const stateMachine = new stepFunctions.StateMachine(\n      this,\n      'my-state-machine',\n      {\n        definitionBody: stepFunctions.DefinitionBody.fromChainable(parallel),\n        stateMachineType: stepFunctions.StateMachineType.EXPRESS,\n        logs: {\n          destination: stfLogGroup,\n          level: stepFunctions.LogLevel.ALL,\n        },\n      }\n    )\n\n    const api = new apigateway.StepFunctionsRestApi(this, 'my-api', {\n      stateMachine,\n      description: 'example api gateway',\n      deployOptions: {\n        stageName: 'dev',\n      }\n    });\n\n    const items = api.root.addResource('messages');\n    items.addMethod('GET');\n  }\n}", "language": "typescript"}
{"input": "ServiceConnect ValueObjectClass having by ContainerDefinition", "output": "export class ServiceConnect {\n  /**\n   * Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n   */\n  readonly portmapping: PortMapping;\n\n  /**\n   * The networking mode to use for the containers in the task.\n   */\n  readonly networkmode: NetworkMode;\n\n  constructor(networkmode: NetworkMode, pm: PortMapping) {\n    this.portmapping = pm;\n    this.networkmode = networkmode;\n  }\n\n  /**\n   * Judge parameters can be serviceconnect logick.\n   * If parameters can be serviceConnect return true.\n   */\n  public isServiceConnect() :boolean {\n    const hasPortname = this.portmapping.name;\n    const hasAppProtcol = this.portmapping.appProtocol;\n    if (hasPortname || hasAppProtcol) return true;\n    return false;\n  }\n\n  /**\n   * Judge serviceconnect parametes are valid.\n   * If invalid, throw Error.\n   */\n  public validate() :void {\n    if (!this.isValidNetworkmode()) {\n      throw new UnscopedValidationError(`Service connect related port mapping fields 'name' and 'appProtocol' are not supported for network mode ${this.networkmode}`);\n    }\n    if (!this.isValidPortName()) {\n      throw new UnscopedValidationError('Service connect-related port mapping field \\'appProtocol\\' cannot be set without \\'name\\'');\n    }\n  }\n\n  private isValidNetworkmode() :boolean {\n    const isAwsVpcMode = this.networkmode == NetworkMode.AWS_VPC;\n    const isBridgeMode = this.networkmode == NetworkMode.BRIDGE;\n    if (isAwsVpcMode || isBridgeMode) return true;\n    return false;\n  }\n\n  private isValidPortName() :boolean {\n    if (!this.portmapping.name) return false;\n    return true;\n  }\n}", "language": "typescript"}
{"input": "User pool operations to which lambda triggers can be attached.", "output": "export class UserPoolOperation {\n  /**\n   * Creates a challenge in a custom auth flow\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-create-auth-challenge.html\n   */\n  public static readonly CREATE_AUTH_CHALLENGE = new UserPoolOperation('createAuthChallenge');\n\n  /**\n   * Advanced customization and localization of messages\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-custom-message.html\n   */\n  public static readonly CUSTOM_MESSAGE = new UserPoolOperation('customMessage');\n\n  /**\n   * Determines the next challenge in a custom auth flow\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-define-auth-challenge.html\n   */\n  public static readonly DEFINE_AUTH_CHALLENGE = new UserPoolOperation('defineAuthChallenge');\n\n  /**\n   * Event logging for custom analytics\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-post-authentication.html\n   */\n  public static readonly POST_AUTHENTICATION = new UserPoolOperation('postAuthentication');\n\n  /**\n   * Custom welcome messages or event logging for custom analytics\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-post-confirmation.html\n   */\n  public static readonly POST_CONFIRMATION = new UserPoolOperation('postConfirmation');\n\n  /**\n   * Custom validation to accept or deny the sign-in request\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-authentication.html\n   */\n  public static readonly PRE_AUTHENTICATION = new UserPoolOperation('preAuthentication');\n\n  /**\n   * Custom validation to accept or deny the sign-up request\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-sign-up.html\n   */\n  public static readonly PRE_SIGN_UP = new UserPoolOperation('preSignUp');\n\n  /**\n   * Add or remove attributes in Id tokens\n   *\n   * Set this parameter for legacy purposes.\n   * If you also set an ARN in PreTokenGenerationConfig, its value must be identical to PreTokenGeneration.\n   * For new instances of pre token generation triggers, set the LambdaArn of PreTokenGenerationConfig.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-token-generation.html\n   */\n  public static readonly PRE_TOKEN_GENERATION = new UserPoolOperation('preTokenGeneration');\n\n  /**\n   * Add or remove attributes in Id tokens and Access tokens\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-pre-token-generation.html\n   */\n  public static readonly PRE_TOKEN_GENERATION_CONFIG = new UserPoolOperation('preTokenGenerationConfig');\n\n  /**\n   * Migrate a user from an existing user directory to user pools\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-migrate-user.html\n   */\n  public static readonly USER_MIGRATION = new UserPoolOperation('userMigration');\n\n  /**\n   * Determines if a response is correct in a custom auth flow\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-verify-auth-challenge-response.html\n   */\n  public static readonly VERIFY_AUTH_CHALLENGE_RESPONSE = new UserPoolOperation('verifyAuthChallengeResponse');\n\n  /**\n   * Amazon Cognito invokes this trigger to send email notifications to users.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-custom-email-sender.html\n   */\n  public static readonly CUSTOM_EMAIL_SENDER = new UserPoolOperation('customEmailSender');\n\n  /**\n   * Amazon Cognito invokes this trigger to send email notifications to users.\n   * @see https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-custom-sms-sender.html\n   */\n  public static readonly CUSTOM_SMS_SENDER = new UserPoolOperation('customSmsSender');\n\n  /** A custom user pool operation */\n  public static of(name: string): UserPoolOperation {\n    const lowerCamelCase = name.charAt(0).toLowerCase() + name.slice(1);\n    return new UserPoolOperation(lowerCamelCase);\n  }\n\n  /** The key to use in `CfnUserPool.LambdaConfigProperty` */\n  public readonly operationName: string;\n\n  private constructor(operationName: string) {\n    this.operationName = operationName;\n  }\n}", "language": "typescript"}
{"input": "Represents an image tag mutability exclusion filter for ECR repository", "output": "export class ImageTagMutabilityExclusionFilter {\n  /**\n   * Creates a wildcard filter for image tag mutability exclusion\n   * @param pattern The wildcard pattern to match image tags (e.g., 'dev-*', 'release-v*')\n   */\n  public static wildcard(pattern: string): ImageTagMutabilityExclusionFilter {\n    return new ImageTagMutabilityExclusionFilter('WILDCARD', pattern);\n  }\n\n  private constructor(\n    private readonly filterType: string,\n    private readonly filterValue: string,\n  ) {\n    if (!filterValue) {\n      throw new UnscopedValidationError('Pattern cannot be empty');\n    }\n    if (filterValue.length > 128) {\n      throw new UnscopedValidationError(`Pattern cannot exceed 128 characters, got: ${filterValue.length} characters.`);\n    }\n    if (!/^[0-9a-zA-Z._*-]+$/.test(filterValue)) {\n      throw new UnscopedValidationError(`Pattern '${filterValue}' contains invalid characters. Only alphanumeric characters, dots, underscores, asterisks, and hyphens are allowed.`);\n    }\n  }\n\n  /**\n   * Renders the filter to CloudFormation properties\n   * @internal\n   */\n  public _render(): CfnRepository.ImageTagMutabilityExclusionFilterProperty {\n    return {\n      imageTagMutabilityExclusionFilterType: this.filterType,\n      imageTagMutabilityExclusionFilterValue: this.filterValue,\n    };\n  }\n}", "language": "typescript"}
{"input": "An error thrown when a region fact operation fails.", "output": "class RegionFactError extends Error {\n  constructor(msg: string) {\n    super(msg);\n    Object.setPrototypeOf(this, RegionFactError.prototype);\n    Object.defineProperty(this, CONSTRUCT_ERROR_SYMBOL, { value: true });\n    this.name = 'RegionFactError';\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, IAM, CloudFormation resources", "output": "class LambdaNagExampleStack(Stack):\n    def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        # Building Role\n        lambda_func_role = iam.Role(self, \"lambda-nag-func-role-example\",\n            assumed_by=iam.ServicePrincipal(\"lambda.amazonaws.com\"),\n            description=\"A simple role detached from self CDK built role\"\n        )\n        lambda_func_role_policy = iam.Policy(\n            self, \"lambda-nag-func-role-policy-example\",\n            statements=[\n                iam.PolicyStatement(\n                    actions=[\n                            \"logs:CreateLogStream\",\n                            \"logs:PutLogEvents\",\n                            \"logs:CreateLogGroup\"\n                    ],\n                    resources=[\n                        \"*\"\n                    ]\n                )\n            ],\n            roles=[lambda_func_role]\n        )\n\n        # In case of wildcard policy usage you must add a suppression in order to give a reason for that.\n        nag.NagSuppressions.add_resource_suppressions(\n            lambda_func_role_policy,\n            [{\n                \"id\": \"AwsSolutions-IAM5\",\n                \"reason\": \"A wildcard is necessary over this policy because <put your reason here>...\"\n            }]\n        )\n\n        with open(\"lambda-func/lambda-handler.py\", encoding=\"utf8\") as fcn_file:\n            handler_code = fcn_file.read()\n\n        # A non-container Lambda function is not configured to use the latest runtime version can raise a new error\n        lambda_func = lambda_.Function(\n            self, \"lambda-nag-func-example\",\n            code=lambda_.InlineCode(handler_code),\n            handler=\"index.handler\",\n            timeout=Duration.seconds(30),\n            role=lambda_func_role,\n            runtime=lambda_.Runtime.PYTHON_3_12,\n        )", "language": "python"}
{"input": "CDK class CustomNodeInjector for AWS resource management", "output": "class CustomNodeInjector extends appsignals.NodeInjector {\n  get containerPath(): string {\n    return '/otel-snapshot';\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for RDS, EC2 operations", "output": "def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Creates a security group for AWS RDS\n        sg_rds = ec2.SecurityGroup(\n                self,\n                id=\"sg_rds\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_rds\"\n        )\n\n        # Adds an ingress rule which allows resources in the VPC's CIDR\n        # to access the database.\n        sg_rds.add_ingress_rule(\n            peer=ec2.Peer.ipv4(\"10.0.0.0/16\"),\n            connection=ec2.Port.tcp(3306)\n        )\n\n        # Master username is 'admin' and database password is automatically\n        # generated and stored in AWS Secrets Manager\n        my_sql = rds.DatabaseInstance(\n                self, \"RDS\",\n                engine=rds.DatabaseInstanceEngine.mysql(\n                    version=rds.MysqlEngineVersion.VER_8_0_16\n                ),\n                vpc=props['vpc'],\n                port=3306,\n                instance_type=ec2.InstanceType.of(\n                    ec2.InstanceClass.MEMORY4,\n                    ec2.InstanceSize.LARGE,\n                    ),\n                removal_policy=RemovalPolicy.DESTROY,\n                security_groups=[sg_rds]\n                )", "language": "python"}
{"input": "CDK class Archive for AWS resource management", "output": "export class Archive extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-events.Archive';\n  /**\n   * The archive name.\n   * @attribute\n   */\n  public readonly archiveName: string;\n\n  /**\n   * The ARN of the archive created.\n   * @attribute\n   */\n  public readonly archiveArn: string;\n\n  constructor(scope: Construct, id: string, props: ArchiveProps) {\n    super(scope, id, { physicalName: props.archiveName });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Add the EventBridge in all stages policy statement if a customer key is supplied\n    if (props?.kmsKey) {\n      props?.kmsKey.addToResourcePolicy(new iam.PolicyStatement({\n        resources: ['*'],\n        actions: ['kms:Decrypt', 'kms:GenerateDataKey', 'kms:ReEncrypt*'],\n        principals: [\n          new iam.ServicePrincipal('events.amazonaws.com'),\n        ],\n        sid: 'Allow EventBridge to use kms operations',\n        effect: iam.Effect.ALLOW,\n        conditions: {\n          StringEquals: {\n            'kms:EncryptionContext:aws:events:event-bus:arn': props.sourceEventBus.eventBusRef.eventBusArn,\n          },\n        },\n      }));\n\n      props?.kmsKey.addToResourcePolicy(new iam.PolicyStatement({\n        resources: ['*'],\n        actions: ['kms:DescribeKey'],\n        principals: [\n          new iam.ServicePrincipal('events.amazonaws.com'),\n        ],\n        sid: 'Allow EventBridge to call kms:DescribeKey',\n        effect: iam.Effect.ALLOW,\n      }));\n    }\n\n    // When an empty string is supplied to the L1 template, it means to use an AWS managed key\n    // This empty string is necessary as the definitions in the L1 requires an empty string to enforce an update that removes any previously used CMK\n    let archive = new CfnArchive(this, 'Archive', {\n      sourceArn: props.sourceEventBus.eventBusRef.eventBusArn,\n      description: props.description,\n      eventPattern: renderEventPattern(props.eventPattern),\n      retentionDays: props.retention?.toDays({ integral: true }) || 0,\n      archiveName: this.physicalName,\n      kmsKeyIdentifier: props?.kmsKey?.keyArn || '',\n    });\n\n    this.archiveArn = archive.attrArn;\n    this.archiveName = archive.ref;\n    this.node.defaultChild = archive;\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedPipe for AWS resource management", "output": "class ImportedPipe extends PipeBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-pipes-alpha.ImportedPipe';\n  public readonly pipeName: string ;\n  public readonly pipeArn: string;\n  public readonly pipeRole: IRole;\n\n  constructor(scope: Construct, id: string, pipeName: string) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, { pipeName: pipeName });\n    this.pipeName = pipeName;\n    this.pipeArn = Stack.of(this).formatArn({\n      service: 'pipes',\n      partition: 'aws',\n      resource: 'pipe',\n      resourceName: this.pipeName,\n    });\n    this.pipeRole = Role.fromRoleName(this, 'Role', this.pipeName );\n  }\n}", "language": "typescript"}
{"input": "CDK class ReplaceKey for AWS resource management", "output": "export class ReplaceKey {\n  /**\n   * The specific object key to use in the redirect request\n   */\n  public static with(keyReplacement: string) {\n    return new this(keyReplacement);\n  }\n\n  /**\n   * The object key prefix to use in the redirect request\n   */\n  public static prefixWith(keyReplacement: string) {\n    return new this(undefined, keyReplacement);\n  }\n\n  private constructor(public readonly withKey?: string, public readonly prefixWithKey?: string) {\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, IAM, SNS resources", "output": "export class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    let vpc = new ec2.Vpc(this, 'myVpcAuto', { restrictDefaultSecurityGroup: false });\n    const myrole = new iam.Role(this, 'MyRole', {\n      assumedBy: new iam.ServicePrincipal('autoscaling.amazonaws.com'),\n    });\n    const topic = new sns.Topic(this, 'topic', {});\n    const topic2 = new sns.Topic(this, 'topic2', {});\n\n    const asg = new autoscaling.AutoScalingGroup(this, 'ASG', {\n      vpc,\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE2, ec2.InstanceSize.MICRO),\n      machineImage: new ec2.AmazonLinuxImage(), // get the latest Amazon Linux image\n      healthCheck: autoscaling.HealthCheck.ec2(),\n    });\n\n    // no role or notificationTarget\n    new autoscaling.LifecycleHook(this, 'LCHookNoRoleNoTarget', {\n      autoScalingGroup: asg,\n      lifecycleTransition: autoscaling.LifecycleTransition.INSTANCE_TERMINATING,\n    });\n\n    // no role with notificationTarget\n    new autoscaling.LifecycleHook(this, 'LCHookNoRoleTarget', {\n      notificationTarget: new FakeNotificationTarget(topic),\n      autoScalingGroup: asg,\n      lifecycleTransition: autoscaling.LifecycleTransition.INSTANCE_TERMINATING,\n    });\n\n    // role with target\n    new autoscaling.LifecycleHook(this, 'LCHookRoleTarget', {\n      notificationTarget: new FakeNotificationTarget(topic2),\n      role: myrole,\n      autoScalingGroup: asg,\n      lifecycleTransition: autoscaling.LifecycleTransition.INSTANCE_TERMINATING,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class SnsToLambda for AWS resource management", "output": "class SnsToLambda extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const topic = new sns.Topic(this, 'MyTopic');\n\n    const func = new lambda.Function(this, 'Echo', {\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n    });\n\n    topic.addSubscription(new subs.LambdaSubscription(func, {\n      deadLetterQueue: new sqs.Queue(this, 'DeadLetterQueue'),\n    }));\n\n    const funcFiltered = new lambda.Function(this, 'Filtered', {\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n    });\n\n    topic.addSubscription(new subs.LambdaSubscription(funcFiltered, {\n      filterPolicy: {\n        color: sns.SubscriptionFilter.stringFilter({\n          allowlist: ['red'],\n          matchPrefixes: ['bl', 'ye'],\n          matchSuffixes: ['ue', 'ow'],\n        }),\n        size: sns.SubscriptionFilter.stringFilter({\n          denylist: ['small', 'medium'],\n        }),\n        price: sns.SubscriptionFilter.numericFilter({\n          between: { start: 100, stop: 200 },\n        }),\n      },\n    }));\n\n    const funcFilteredWithMessageBody = new lambda.Function(this, 'FilteredMessageBody', {\n      handler: 'index.handler',\n      runtime: STANDARD_NODEJS_RUNTIME,\n      code: lambda.Code.fromInline(`exports.handler = ${handler.toString()}`),\n    });\n\n    topic.addSubscription(new subs.LambdaSubscription(funcFilteredWithMessageBody, {\n      filterPolicyWithMessageBody: {\n        background: sns.FilterOrPolicy.policy({\n          color: sns.FilterOrPolicy.filter(sns.SubscriptionFilter.stringFilter({\n            allowlist: ['red'],\n            matchPrefixes: ['bl', 'ye'],\n            matchSuffixes: ['ue', 'ow'],\n          })),\n        }),\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class KinesisDataFirehoseDestination for AWS resource management", "output": "class KinesisDataFirehoseDestination extends FlowLogDestination {\n  constructor(private readonly props: FlowLogDestinationConfig) {\n    super();\n  }\n\n  public bind(scope: Construct, _flowLog: FlowLog): FlowLogDestinationConfig {\n    if (this.props.deliveryStreamArn === undefined) {\n      throw new ValidationError('deliveryStreamArn is required', scope);\n    }\n    const deliveryStreamArn = this.props.deliveryStreamArn;\n\n    return {\n      logDestinationType: FlowLogDestinationType.KINESIS_DATA_FIREHOSE,\n      deliveryStreamArn,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, KMS, MSK (Kafka), CloudFormation resources", "output": "export class rdsAuroraStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props: vpcStackProps) {\n        super(scope, id, props);\n\n        const kmskey = new Key(this, 'MyKey', {\n            enableKeyRotation: true,\n            rotationPeriod: cdk.Duration.days(180), // Default is 365 days\n          });  \n\n        const cluster = new DatabaseCluster(this, 'Database', {\n            engine: DatabaseClusterEngine.auroraMysql({ version: AuroraMysqlEngineVersion.VER_3_03_0 }),\n            writer: ClusterInstance.provisioned('writer', {\n              instanceType: InstanceType.of(InstanceClass.R6G, InstanceSize.XLARGE4),\n            }),\n            serverlessV2MinCapacity: 6.5,\n            serverlessV2MaxCapacity: 64,\n            readers: [\n              // will be put in promotion tier 1 and will scale with the writer\n              ClusterInstance.serverlessV2('reader1', { scaleWithWriter: true }),\n              // will be put in promotion tier 2 and will not scale with the writer\n              ClusterInstance.serverlessV2('reader2'),\n            ],\n            credentials: { username: 'clusteradmin' },\n            cloudwatchLogsExports: [\"error\"],\n            vpc: props.vpc,\n            storageEncrypted: true,\n            storageEncryptionKey: kmskey\n          });\n}\n}", "language": "typescript"}
{"input": "Network configuration for the Runtime.", "output": "export class RuntimeNetworkConfiguration extends NetworkConfiguration {\n  /**\n   * Creates a public network configuration. PUBLIC is the default network mode.\n   * @returns A RuntimeNetworkConfiguration.\n   * Run the runtime in a public environment with internet access, suitable for less sensitive or open-use scenarios.\n   */\n  public static usingPublicNetwork(): RuntimeNetworkConfiguration {\n    return new RuntimeNetworkConfiguration('PUBLIC');\n  }\n\n  /**\n   * Creates a network configuration from a VPC configuration.\n   * @param scope - The construct scope for creating resources.\n   * @param vpcConfig - The VPC configuration.\n   * @returns A RuntimeNetworkConfiguration.\n   */\n  public static usingVpc(scope: Construct, vpcConfig: VpcConfigProps): RuntimeNetworkConfiguration {\n    return new RuntimeNetworkConfiguration('VPC', scope, vpcConfig);\n  }\n\n  /**\n   * Renders the network configuration as a CloudFormation property.\n   * @param runtimeConnections - The connections object to the runtime.\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(_runtimeConnections?: ec2.Connections): CfnRuntime.NetworkConfigurationProperty {\n    return {\n      networkMode: this.networkMode,\n      networkModeConfig: (this.networkMode == 'VPC' && _runtimeConnections) ? {\n        subnets: this.vpcSubnets?.subnets?.map(subnet => subnet.subnetId) ?? [],\n        securityGroups: _runtimeConnections?.securityGroups?.map(s=> s.securityGroupId) ?? [],\n      }: undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class Topic for AWS resource management", "output": "export class Topic extends TopicBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-sns.Topic';\n\n  /**\n   * Import an existing SNS topic provided an ARN\n   *\n   * @param scope The parent creating construct\n   * @param id The construct's name\n   * @param topicArn topic ARN (i.e. arn:aws:sns:us-east-2:444455556666:MyTopic)\n   */\n  public static fromTopicArn(scope: Construct, id: string, topicArn: string): ITopic {\n    return Topic.fromTopicAttributes(scope, id, { topicArn });\n  }\n\n  /**\n   * Import an existing SNS topic provided a topic attributes\n   *\n   * @param scope The parent creating construct\n   * @param id The construct's name\n   * @param attrs the attributes of the topic to import\n   */\n  public static fromTopicAttributes(scope: Construct, id: string, attrs: TopicAttributes): ITopic {\n    const topicName = Stack.of(scope).splitArn(attrs.topicArn, ArnFormat.NO_RESOURCE_NAME).resource;\n    const fifo = topicName.endsWith('.fifo');\n\n    if (attrs.contentBasedDeduplication && !fifo) {\n      throw new ValidationError('Cannot import topic; contentBasedDeduplication is only available for FIFO SNS topics.', scope);\n    }\n\n    class Import extends TopicBase {\n      public readonly topicArn = attrs.topicArn;\n      public readonly topicName = topicName;\n      public readonly masterKey = attrs.keyArn\n        ? Key.fromKeyArn(this, 'Key', attrs.keyArn)\n        : undefined;\n      public readonly fifo = fifo;\n      public readonly contentBasedDeduplication = attrs.contentBasedDeduplication || false;\n      protected autoCreatePolicy: boolean = false;\n    }\n\n    return new Import(scope, id, {\n      environmentFromArn: attrs.topicArn,\n    });\n  }\n\n  public readonly topicArn: string;\n  public readonly topicName: string;\n  public readonly masterKey?: IKey;\n  public readonly contentBasedDeduplication: boolean;\n  public readonly fifo: boolean;\n\n  protected readonly autoCreatePolicy: boolean = true;\n\n  private readonly loggingConfigs: LoggingConfig[] = [];\n\n  constructor(scope: Construct, id: string, props: TopicProps = {}) {\n    super(scope, id, {\n      physicalName: props.topicName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.enforceSSL = props.enforceSSL;\n\n    if (props.contentBasedDeduplication && !props.fifo) {\n      throw new ValidationError('Content based deduplication can only be enabled for FIFO SNS topics.', this);\n    }\n    if (props.messageRetentionPeriodInDays && !props.fifo) {\n      throw new ValidationError('`messageRetentionPeriodInDays` is only valid for FIFO SNS topics.', this);\n    }\n    if (props.fifoThroughputScope && !props.fifo) {\n      throw new ValidationError('`fifoThroughputScope` can only be set for FIFO SNS topics.', this);\n    }\n    if (\n      props.messageRetentionPeriodInDays !== undefined\n      && !Token.isUnresolved(props.messageRetentionPeriodInDays)\n      && (!Number.isInteger(props.messageRetentionPeriodInDays) || props.messageRetentionPeriodInDays > 365 || props.messageRetentionPeriodInDays < 1)\n    ) {\n      throw new ValidationError('`messageRetentionPeriodInDays` must be an integer between 1 and 365', this);\n    }\n\n    if (props.loggingConfigs) {\n      props.loggingConfigs.forEach(c => this.addLoggingConfig(c));\n    }\n\n    let cfnTopicName: string;\n    if (props.fifo && props.topicName && !props.topicName.endsWith('.fifo')) {\n      cfnTopicName = this.physicalName + '.fifo';\n    } else if (props.fifo && !props.topicName) {\n      // Max length allowed by CloudFormation is 256, we subtract 5 to allow for \".fifo\" suffix\n      const prefixName = Names.uniqueResourceName(this, {\n        maxLength: 256 - 5,\n        separator: '-',\n      });\n      cfnTopicName = `${prefixName}.fifo`;\n    } else {\n      cfnTopicName = this.physicalName;\n    }\n\n    if (\n      props.signatureVersion &&\n      !Token.isUnresolved(props.signatureVersion) &&\n      props.signatureVersion !== '1' &&\n      props.signatureVersion !== '2'\n    ) {\n      throw new ValidationError(`signatureVersion must be \"1\" or \"2\", received: \"${props.signatureVersion}\"`, this);\n    }\n\n    if (props.displayName && !Token.isUnresolved(props.displayName) && props.displayName.length > 100) {\n      throw new ValidationError(`displayName must be less than or equal to 100 characters, got ${props.displayName.length}`, this);\n    }\n\n    const resource = new CfnTopic(this, 'Resource', {\n      archivePolicy: props.messageRetentionPeriodInDays ? {\n        MessageRetentionPeriod: props.messageRetentionPeriodInDays,\n      } : undefined,\n      displayName: props.displayName,\n      topicName: cfnTopicName,\n      kmsMasterKeyId: props.masterKey && props.masterKey.keyArn,\n      contentBasedDeduplication: props.contentBasedDeduplication,\n      fifoTopic: props.fifo,\n      signatureVersion: props.signatureVersion,\n      deliveryStatusLogging: Lazy.any({ produce: () => this.renderLoggingConfigs() }, { omitEmptyArray: true }),\n      tracingConfig: props.tracingConfig,\n      fifoThroughputScope: props.fifoThroughputScope,\n    });\n\n    this.topicArn = this.getResourceArnAttribute(resource.ref, {\n      service: 'sns',\n      resource: this.physicalName,\n    });\n    this.topicName = this.getResourceNameAttribute(resource.attrTopicName);\n    this.masterKey = props.masterKey;\n    this.fifo = props.fifo || false;\n    this.contentBasedDeduplication = props.contentBasedDeduplication || false;\n\n    if (this.enforceSSL) {\n      this.addSSLPolicy();\n    }\n  }\n\n  private renderLoggingConfigs(): CfnTopic.LoggingConfigProperty[] {\n    const renderLoggingConfig = (spec: LoggingConfig): CfnTopic.LoggingConfigProperty => {\n      if (spec.successFeedbackSampleRate !== undefined) {\n        const rate = spec.successFeedbackSampleRate;\n        if (!Number.isInteger(rate) || rate < 0 || rate > 100) {\n          throw new ValidationError('Success feedback sample rate must be an integer between 0 and 100', this);\n        }\n      }\n      return {\n        protocol: spec.protocol,\n        failureFeedbackRoleArn: spec.failureFeedbackRole?.roleRef.roleArn,\n        successFeedbackRoleArn: spec.successFeedbackRole?.roleRef.roleArn,\n        successFeedbackSampleRate: spec.successFeedbackSampleRate?.toString(),\n      };\n    };\n\n    return this.loggingConfigs.map(renderLoggingConfig);\n  }\n\n  /**\n   * Adds a delivery status logging configuration to the topic.\n   */\n  @MethodMetadata()\n  public addLoggingConfig(config: LoggingConfig) {\n    this.loggingConfigs.push(config);\n  }\n}", "language": "typescript"}
{"input": "CDK Construct MyConstruct for reusable infrastructure components", "output": "class MyConstruct extends Construct {\n  public static IsMyConstruct(x: any): x is MyConstruct {\n    return x.visitCounter !== undefined;\n  }\n  public visitCounter: number = 0;\n}", "language": "typescript"}
{"input": "CDK class Aurora for AWS resource management", "output": "class Aurora(Stack):\n\n  def __init__(self, scope:Construct, id:str,\n                vpc_id:str,                 ## vpc id\n                subnet_ids:list,            ## list of subnet ids\n                db_name:str,                ## database name\n                instance_type = None,       ## ec2.InstanceType\n                replica_instances:int = 2,  ## At least 1. Default 2\n                aurora_cluster_username:str=\"clusteradmin\",\n                backup_retention_days:int=14,\n                backup_window:str=\"00:15-01:15\",\n                preferred_maintenance_window:str=\"Sun:23:45-Mon:00:15\",\n                engine:str=\"postgresql\",    ## Aurora Database Engine: postgresql or mysql\n                enable_babelfish:bool=True, ## Support for MSSQL. (no extra cost)\n                ingress_sources:list=[],    ## A security group object or a network subnet\n                                            ##   ec2.Peer.ipv4(\"0.0.0.0/0\")\n                                            ##   ec2.SecurityGroup\n                **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n\n    if engine not in [\"postgresql\", \"mysql\"]:\n      print(\"Unknown Engine\")\n      exit(1)\n\n    ##\n    ## Enforce a minimum backup retention period\n    ##\n    if backup_retention_days < 14:\n      backup_retention_days = 14\n\n    ##\n    ## Enforce a minimum number of read replicas\n    ##\n    if replica_instances < 1:\n      replica_instances = 1\n\n    ############################################\n    ##\n    ## CDK Nag - https://pypi.org/project/cdk-nag/\n    ##           https://github.com/cdklabs/cdk-nag\n    ##\n    ## CDK Nag Checks for AWS Engagement Solutions Secuirty Rules:\n    ##   https://github.com/cdklabs/cdk-nag/blob/main/RULES.md#awssolutions\n    ## Also checks for:\n    ##   HIPAA Security\n    ##   NIST 800-53 rev 4\n    ##   NIST 800-53 rev 5\n    ##\n    ############################################\n    Aspects.of(self).add(AwsSolutionsChecks())\n    ##\n    ## Supressed Errors\n    ##\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-IAM4\", \"reason\":\"TODO: Stop using AWS managed policies.\"}])\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-IAM5\", \"reason\":\"TODO: Remove Wildcards in IAM roles.\"}])\n    ##\n    ## Supressed Warnings\n    ##\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-RDS16\", \"reason\":\"parameter referencing an intrinsic function\"}])\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-SMG4\", \"reason\":\"Don't auto rotate secret. Remove for Prod\"}])\n\n\n    azs = Fn.get_azs()\n\n    vpc = ec2.Vpc.from_vpc_attributes(self, 'ExistingVPC', availability_zones=azs, vpc_id=vpc_id)\n    subnets = list()\n    for subnet_id in subnet_ids:\n      subnets.append(ec2.Subnet.from_subnet_attributes(self, subnet_id.replace(\"-\", \"\").replace(\"_\", \"\").replace(\" \", \"\"), subnet_id=subnet_id))\n\n    vpc_subnets = ec2.SubnetSelection(subnets=subnets)\n\n\n\n\n\n    allAll = ec2.Port(protocol=ec2.Protocol(\"ALL\"), string_representation=\"ALL\")\n    tcp3306 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=3306, to_port=3306, string_representation=\"tcp3306 MySQL\")\n    tcp5432 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=5432, to_port=5432, string_representation=\"tcp5432 PostgreSQL\")\n    tcp1433 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=1433, to_port=1433, string_representation=\"tcp1433 MSSQL\")\n\n\n\n    ##\n    ## Database Security Group\n    ##\n    dbsg = ec2.SecurityGroup(self, \"DatabaseSecurityGroup\",\n             vpc = vpc,\n             allow_all_outbound = True,\n             description = id + \" Database\",\n             security_group_name = id + \" Database\",\n           )\n    dbsg.add_ingress_rule(\n      peer =dbsg,\n      connection =allAll,\n      description=\"all from self\"\n    )\n    dbsg.add_egress_rule(\n      peer =ec2.Peer.ipv4(\"0.0.0.0/0\"),\n      connection =allAll,\n      description=\"all out\"\n    )\n\n    if engine == \"mysql\":\n      connection_port = tcp3306\n      connection_name = \"tcp3306 MySQL\"\n    else:\n      connection_port = tcp5432\n      connection_name = \"tcp5432 PostgreSQL\"\n\n    for ingress_source in ingress_sources:\n      dbsg.add_ingress_rule(\n        peer =ingress_source,\n        connection =connection_port,\n        description=connection_name\n      )\n      if engine == \"postgresql\":\n        dbsg.add_ingress_rule(\n          peer =ingress_source,\n          connection =tcp1433,\n          description=\"tcp1433 MSSQL\"\n        )\n\n    db_subnet_group = rds.SubnetGroup(self,\n                       id = \"DatabaseSubnetGroup\",\n                       vpc = vpc,\n                       description = id + \" subnet group\",\n                       vpc_subnets = vpc_subnets,\n                       subnet_group_name=id + \"subnet group\"\n    )\n\n\n    ##\n    ## use PostgreSQL by default\n    ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/AuroraPostgresEngineVersion.html#aws_cdk.aws_rds.AuroraPostgresEngineVersion\n    ##\n    aurora_engine = rds.DatabaseClusterEngine.aurora_postgres(version=rds.AuroraPostgresEngineVersion.VER_13_4)\n\n    ##\n    ## include support for MySQL\n    ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/AuroraMysqlEngineVersion.html#aws_cdk.aws_rds.AuroraMysqlEngineVersion\n    ##\n    if engine == \"mysql\":\n      aurora_engine = rds.DatabaseClusterEngine.aurora_mysql(version=rds.AuroraMysqlEngineVersion.VER_2_10_1)\n\n    aurora_parameters = {}\n    ## If PostgreSQL, and enable_babelfish is True, turn on Babelfish support.\n    if enable_babelfish and engine==\"postgresql\":\n      aurora_parameters[\"rds.babelfish_status\"] = \"on\"\n\n    aurora_parameter_group = rds.ParameterGroup(self, id=\"AuroraParameterGroup\",\n      engine =aurora_engine,\n      description=id + \" Parameter Group\",\n      parameters =aurora_parameters)\n\n\n\n    ##\n    ## Secret username/password for the cluster.\n    ##\n    aurora_cluster_secret = secretsmanager.Secret(self, \"AuroraClusterCredentials\",\n      secret_name =db_name + \"AuroraClusterCredentials\",\n      description =db_name + \"Aurora Cluster Credentials\",\n      generate_secret_string=secretsmanager.SecretStringGenerator(\n        exclude_characters =\"\\\"@/\\\\ '\",\n        generate_string_key =\"password\",\n        password_length =30,\n        secret_string_template='{\"username\":\"'+aurora_cluster_username+'\"}'),\n    )\n\n    aurora_cluster_credentials = rds.Credentials.from_secret(aurora_cluster_secret, aurora_cluster_username)\n\n    ##\n    ## Default Instance Type\n    ##\n    if not instance_type:\n      instance_type = ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE4_GRAVITON, ec2.InstanceSize.MEDIUM)\n\n    kms_key = kms.Key(self, \"AuroraDatabaseKey\",\n      enable_key_rotation=True,\n      alias=db_name\n    )\n\n\n    ##\n    ## https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/AuroraPostgreSQL.CloudWatch.html\n    ##\n    ## If PostgreSQL, export the postgresql log.\n    cloudwatch_logs_exports=[\"postgresql\"]\n    ## If MySQL, export the slowquery log.\n    if engine == \"mysql\":\n      cloudwatch_logs_exports=[\"slowquery\"]\n\n\n    aurora_cluster = rds.DatabaseCluster(self, \"AuroraDatabase\",\n        engine = aurora_engine,\n        credentials = aurora_cluster_credentials, # Optional - will default to 'admin' username and generated password\n        backup = rds.BackupProps(\n          retention =Duration.days(backup_retention_days),\n          preferred_window =backup_window\n        ),\n        parameter_group = aurora_parameter_group,\n        instances = replica_instances,\n        iam_authentication = True,\n        storage_encrypted = True,\n        storage_encryption_key = kms_key,\n        deletion_protection=True,\n        removal_policy=RemovalPolicy.SNAPSHOT,\n        copy_tags_to_snapshot=True,\n        cloudwatch_logs_exports=cloudwatch_logs_exports,\n        cloudwatch_logs_retention=logs.RetentionDays.ONE_MONTH,\n        preferred_maintenance_window=preferred_maintenance_window, # Should be specified as a range ddd:hh24:mi-ddd:hh24:mi (24H Clock UTC).\n                                                                   # Example: Sun:23:45-Mon:00:15\n                                                                   # Default: 30-minute window selected at random from an 8-hour block of time for each AWS Region,\n                                                                   #          occurring on a random day of the week.\n        #cluster_identifier=db_name,\n        instance_identifier_base = db_name,\n        instance_props = {\n            \"instance_type\": instance_type,\n            \"vpc_subnets\": vpc_subnets,\n            \"vpc\": vpc,\n            \"security_groups\": [dbsg],\n        } ## instance_props\n    ) ## rds.DatabaseCluster\n    aurora_cluster.apply_removal_policy(RemovalPolicy.RETAIN)\n    Tags.of(aurora_cluster).add(\"Name\", db_name, priority=300)\n\n    aurora_cluster.add_rotation_single_user(\n      automatically_after=Duration.days(30),\n      exclude_characters =\"\\\"@/\\\\ '\",\n      vpc_subnets=vpc_subnets\n    )\n\n\n\n\n\n\n    ##\n    ## Cloudwatch Dashboard\n    ##\n    dashboard = cloudwatch.Dashboard(self, \"AuroraMonitoringDashboard\",\n                  dashboard_name=db_name)\n\n    db_connections = aurora_cluster.metric_database_connections()\n    cpu_utilization = aurora_cluster.metric_cpu_utilization()\n    deadlocks = aurora_cluster.metric_deadlocks()\n    free_local_storage = aurora_cluster.metric_free_local_storage()\n    freeable_memory = aurora_cluster.metric_freeable_memory()\n    network_receive_throughput = aurora_cluster.metric_network_receive_throughput()\n    network_throughput = aurora_cluster.metric_network_throughput()\n    network_transmit_throughput = aurora_cluster.metric_network_transmit_throughput()\n    snapshot_storage_used = aurora_cluster.metric_snapshot_storage_used()\n    total_backup_storage_billed = aurora_cluster.metric_total_backup_storage_billed()\n    volume_bytes_used = aurora_cluster.metric_volume_bytes_used()\n    volume_read_io_ps = aurora_cluster.metric_volume_read_io_ps()\n    volume_write_io_ps = aurora_cluster.metric_volume_write_io_ps()\n\n    # The average amount of time taken per disk I/O operation (average over 1 minute)\n    read_latency = aurora_cluster.metric(\"ReadLatency\", statistic=\"Average\", period=Duration.seconds(60))\n\n    percent90 = cloudwatch.HorizontalAnnotation(\n                  value =85,\n                  color =cloudwatch.Color.RED,\n                  fill =cloudwatch.Shading('NONE'),\n                  label =\"\ud83d\udea8 DANGER\")\n\n    percent80 = cloudwatch.HorizontalAnnotation(\n                  value =75,\n                  color =cloudwatch.Color.ORANGE,\n                  fill =cloudwatch.Shading('NONE'),\n                  label =\"\u26a0\ufe0f WARNING\")\n\n    widget_db_connections = cloudwatch.GraphWidget(\n                title=\"DB Connections\",\n                # Metrics to display on left Y axis.\n                left =[db_connections],\n                #left_annotations = [percent90, percent80],\n              ) ## GraphWidget\n\n    widget_cpu_utilization = cloudwatch.GraphWidget(\n                title=\"CPU Utilization\",\n                # Metrics to display on left Y axis.\n                left =[cpu_utilization],\n                #left_annotations = [percent90, percent80],\n              ) ## GraphWidget\n\n    widget_read_latency = cloudwatch.GraphWidget(\n                title=\"Read Latency\",\n                # Metrics to display on left Y axis.\n                left =[read_latency],\n                #left_annotations = [percent90, percent80],\n              ) ## GraphWidget\n\n\n    deadlocks = aurora_cluster.metric_deadlocks()\n    free_local_storage = aurora_cluster.metric_free_local_storage()\n    freeable_memory = aurora_cluster.metric_freeable_memory()\n    network_receive_throughput = aurora_cluster.metric_network_receive_throughput()\n    network_throughput = aurora_cluster.metric_network_throughput()\n    network_transmit_throughput = aurora_cluster.metric_network_transmit_throughput()\n\n    total_backup_storage_billed = aurora_cluster.metric_total_backup_storage_billed()\n\n    volume_bytes_used = aurora_cluster.metric_volume_bytes_used()\n    snapshot_storage_used = aurora_cluster.metric_snapshot_storage_used()\n\n    volume_read_io_ps = aurora_cluster.metric_volume_read_io_ps()\n    volume_write_io_ps = aurora_cluster.metric_volume_write_io_ps()\n\n    widget_deadlocks = cloudwatch.GraphWidget(title=\"Deadlocks\", left=[deadlocks])\n    widget_free_local_storage = cloudwatch.GraphWidget(title=\"Free Local Storage\", left=[free_local_storage])\n    widget_freeable_memory = cloudwatch.GraphWidget(title=\"Freeable Memory\", left=[freeable_memory])\n    widget_network_receive_throughput = cloudwatch.GraphWidget(title=\"Network Throughput\", left=[network_receive_throughput, network_throughput, network_transmit_throughput])\n    widget_total_backup_storage_billed = cloudwatch.GraphWidget(title=\"Backup Storage Billed\", left=[total_backup_storage_billed])\n    widget_volume_bytes = cloudwatch.GraphWidget(title=\"Storage\", left=[volume_bytes_used, snapshot_storage_used])\n    widget_volume_iops = cloudwatch.GraphWidget(title=\"Volume IOPs\", left=[volume_read_io_ps, volume_write_io_ps])\n\n\n    ##\n    ## Each dashboard.add() creates a single row in the dashboard.\n    ##\n    dashboard.add_widgets(\n      widget_db_connections,\n      widget_cpu_utilization\n    )\n    dashboard.add_widgets(\n      widget_total_backup_storage_billed,\n      widget_free_local_storage\n    )\n    dashboard.add_widgets(\n      widget_freeable_memory,\n      widget_volume_bytes,\n      widget_volume_iops,\n    )\n    dashboard.add_widgets(\n      widget_network_receive_throughput,\n      widget_read_latency,\n      widget_deadlocks,\n    )\n\n\n\n\n    CfnOutput(self, \"OutputSecretName\", export_name=aurora_cluster.stack.stack_name+\":SecretName\", value=aurora_cluster.secret.secret_name) # isecret\n    CfnOutput(self, \"OutputSecretArn\", export_name=aurora_cluster.stack.stack_name+\":SecretArn\", value=aurora_cluster.secret.secret_arn) # isecret\n    CfnOutput(self, \"OutputGetSecretValue\", export_name=aurora_cluster.stack.stack_name+\":GetSecretValue\", value=\"aws secretsmanager get-secret-value --secret-id \"+aurora_cluster.secret.secret_arn)\n\n    CfnOutput(self, \"OutputIntanceIdentifiers\", export_name=aurora_cluster.stack.stack_name+\":IntanceIdentifiers\", value=str(aurora_cluster.instance_identifiers)) # list\n    instance_endpoints = []\n    for ie in aurora_cluster.instance_endpoints:\n      instance_endpoints.append(ie.hostname)\n    CfnOutput(self, \"OutputEndpoints\", export_name=aurora_cluster.stack.stack_name+\":Endpoints\", value=str(instance_endpoints)) # list\n    CfnOutput(self, \"OutputClusterEndpoint\", export_name=aurora_cluster.stack.stack_name+\":Endpoint\", value=aurora_cluster.cluster_endpoint.socket_address) # list\n\n    CfnOutput(self, \"OutputEngineFamily\", export_name=aurora_cluster.stack.stack_name+\":EngineFamily\", value=aurora_cluster.engine.engine_family) # iclusterengine\n    CfnOutput(self, \"OutputEngineType\", export_name=aurora_cluster.stack.stack_name+\":EngineType\", value=aurora_cluster.engine.engine_type) # iclusterengine\n    CfnOutput(self, \"OutputEngineFullVersion\", export_name=aurora_cluster.stack.stack_name+\":EngineFullVersion\", value=aurora_cluster.engine.engine_version.full_version) # iclusterengine\n    CfnOutput(self, \"OutputEngineMajorVersion\", export_name=aurora_cluster.stack.stack_name+\":EngineMajorVersion\", value=aurora_cluster.engine.engine_version.major_version) # iclusterengine\n    CfnOutput(self, \"OutputParameterGroupFamily\", export_name=aurora_cluster.stack.stack_name+\":ParameterGroupFamily\", value=aurora_cluster.engine.parameter_group_family)", "language": "python"}
{"input": "CDK Construct for S3, KMS infrastructure components", "output": "export class CrossRegionSupportConstruct extends Construct {\n  public readonly replicationBucket: s3.IBucket;\n\n  constructor(scope: Construct, id: string, props: CrossRegionSupportConstructProps = {}) {\n    super(scope, id);\n\n    const createKmsKey = props.createKmsKey ?? true;\n\n    let encryptionAlias;\n    if (createKmsKey) {\n      const encryptionKey = new kms.Key(this, 'CrossRegionCodePipelineReplicationBucketEncryptionKey', {\n        removalPolicy: cdk.RemovalPolicy.DESTROY,\n        enableKeyRotation: props.enableKeyRotation,\n      });\n      encryptionAlias = new AliasWithShorterGeneratedName(this, 'CrossRegionCodePipelineReplicationBucketEncryptionAlias', {\n        targetKey: encryptionKey,\n        aliasName: cdk.PhysicalName.GENERATE_IF_NEEDED,\n        removalPolicy: cdk.RemovalPolicy.DESTROY,\n      });\n    }\n    this.replicationBucket = new s3.Bucket(this, 'CrossRegionCodePipelineReplicationBucket', {\n      bucketName: cdk.PhysicalName.GENERATE_IF_NEEDED,\n      encryption: encryptionAlias ? s3.BucketEncryption.KMS : s3.BucketEncryption.KMS_MANAGED,\n      encryptionKey: encryptionAlias,\n      enforceSSL: true,\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, IAM, CloudFormation resources", "output": "class VpcEndpointServiceStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { restrictDefaultSecurityGroup: false });\n    const nlbNoPrincipals = new elbv2.NetworkLoadBalancer(this, 'NLBNoPrincipals', {\n      vpc,\n    });\n\n    const service1 = new ec2.VpcEndpointService(this, 'MyVpcEndpointServiceWithNoPrincipals', {\n      vpcEndpointServiceLoadBalancers: [nlbNoPrincipals],\n      acceptanceRequired: false,\n      allowedPrincipals: [],\n    });\n\n    const nlbWithPrincipals = new elbv2.NetworkLoadBalancer(this, 'NLBWithPrincipals', {\n      vpc,\n    });\n    const principalArn = new ArnPrincipal('arn:aws:iam::123456789012:root');\n    const servicePrincipal = new ArnPrincipal('ec2.amazonaws.com');\n\n    const service2 = new ec2.VpcEndpointService(this, 'MyVpcEndpointServiceWithPrincipals', {\n      vpcEndpointServiceLoadBalancers: [nlbWithPrincipals],\n      acceptanceRequired: false,\n      allowedPrincipals: [principalArn, servicePrincipal],\n    });\n\n    new cdk.CfnOutput(this, 'MyVpcEndpointServiceWithNoPrincipalsServiceName', {\n      exportName: 'ServiceName',\n      value: service1.vpcEndpointServiceName,\n      description: 'Give this to service consumers so they can connect via VPC Endpoint',\n    });\n\n    new cdk.CfnOutput(this, 'MyVpcEndpointServiceWithPrincipalsEndpointServiceId', {\n      exportName: 'EndpointServiceId',\n      value: service2.vpcEndpointServiceId,\n      description: 'Reference this service from other stacks',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for S3, SSM Parameter Store operations", "output": "def __init__(self, app: App, id: str, props, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n\n        # pipeline requires versioned bucket\n        bucket = aws_s3.Bucket(\n            self, \"SourceBucket\",\n            bucket_name=f\"{props['namespace'].lower()}-{Aws.ACCOUNT_ID}\",\n            versioned=True,\n            removal_policy=RemovalPolicy.DESTROY)\n        # ssm parameter to get bucket name later\n        bucket_param = aws_ssm.StringParameter(\n            self, \"ParameterB\",\n            parameter_name=f\"{props['namespace']}-bucket\",\n            string_value=bucket.bucket_name,\n            description='cdk pipeline bucket'\n        )\n        # ecr repo to push docker container into\n        ecr = aws_ecr.Repository(\n            self, \"ECR\",\n            repository_name=f\"{props['namespace']}\",\n            removal_policy=RemovalPolicy.DESTROY\n        )\n        # codebuild project meant to run in pipeline\n        cb_docker_build = aws_codebuild.PipelineProject(\n            self, \"DockerBuild\",\n            project_name=f\"{props['namespace']}-Docker-Build\",\n            build_spec=aws_codebuild.BuildSpec.from_source_filename(\n                filename='pipeline_delivery/docker_build_buildspec.yml'),\n            environment=aws_codebuild.BuildEnvironment(\n                privileged=True,\n            ),\n            # pass the ecr repo uri into the codebuild project so codebuild knows where to push\n            environment_variables={\n                'ecr': aws_codebuild.BuildEnvironmentVariable(\n                    value=ecr.repository_uri),\n                'tag': aws_codebuild.BuildEnvironmentVariable(\n                    value='cdk')\n            },\n            description='Pipeline for CodeBuild',\n            timeout=Duration.minutes(60),\n        )\n        # codebuild iam permissions to read write s3\n        bucket.grant_read_write(cb_docker_build)\n\n        # codebuild permissions to interact with ecr\n        ecr.grant_pull_push(cb_docker_build)\n\n        CfnOutput(\n            self, \"ECRURI\",\n            description=\"ECR URI\",\n            value=ecr.repository_uri,\n        )\n        CfnOutput(\n            self, \"S3Bucket\",\n            description=\"S3 Bucket\",\n            value=bucket.bucket_name\n        )\n\n        self.output_props = props.copy()\n        self.output_props['bucket']= bucket\n        self.output_props['cb_docker_build'] = cb_docker_build", "language": "python"}
{"input": "CDK Stack that creates Lambda, EC2, VPC resources", "output": "class CtcwlOssStack(Stack):\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        ################################################################################\n        # VPC\n        vpc = ec2.Vpc(self, \"SvlCTCWLVpc\")\n        es_sec_grp = ec2.SecurityGroup(\n            self,\n            \"SvlCTCWLOpenSearchSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"SvlCTCWLSecGrp\",\n        )\n        es_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(80))\n        es_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(443))\n\n        endpoint = opensearchserverless.CfnVpcEndpoint(\n            self,\n            \"SvlCTCWLEndpoint\",\n            name=\"svlctcwlendpoint\",\n            vpc_id=vpc.vpc_id,\n            security_group_ids=[es_sec_grp.security_group_id],\n            subnet_ids=[s.subnet_id for s in vpc.public_subnets],\n        )\n\n        ###############################################################################\n        # Amazon OpenSearch Serverless collection\n        network_policy = NETWORKPOLICY.replace(\"VPCENDPOINTID\", endpoint.attr_id)\n        net = opensearchserverless.CfnSecurityPolicy(\n            self,\n            \"SvlCTCWLNetwork\",\n            name=\"svlctcwlnetwork\",\n            description=f\"Open access for {COLLECTION_NAME}\",\n            type=\"network\",\n            policy=network_policy,\n        )\n        print(\"Network Policy attached to OpenSearch Collection\", net.name)\n        sec = opensearchserverless.CfnSecurityPolicy(\n            self,\n            \"SvlCTCWLEncryption\",\n            name=\"svlctcwlencryption\",\n            description=f\"AWS Owned key policy for {COLLECTION_NAME}\",\n            type=\"encryption\",\n            policy=ENCRYPTIONPOLICY,\n        )\n\n        col = opensearchserverless.CfnCollection(\n            self, COLLECTION_NAME, name=COLLECTION_NAME, type=\"TIMESERIES\"\n        )\n        col.add_dependency(sec)\n\n        ###################################################################\n        # Lambda for subscription filter\n        subscription_filter_lambda = lambda_.Function(\n            self,\n            \"StreamCTCWLtoOSSLambda\",\n            function_name=\"bulk_ingest_handler\",\n            runtime=lambda_.Runtime.PYTHON_3_9,\n            handler=\"index.handler\",\n            vpc=vpc,\n            memory_size=1024,\n            timeout=Duration.minutes(5),\n            code=lambda_.Code.from_asset('lambda')\n        )\n\n        # Load Amazon OpenSearch Service Collection to env variable\n        collection_endpoint = col.attr_collection_endpoint.replace(\"https://\", \"\")\n        print(f\"\\n\\nCollection endpoint: {collection_endpoint}\\n\")\n        subscription_filter_lambda.add_environment(\n            \"COLLECTION_ENDPOINT\", collection_endpoint\n        )\n        subscription_filter_lambda.add_environment(\"REGION\", self.region)\n        subscription_filter_lambda.add_to_role_policy(\n            iam.PolicyStatement(actions=[\"aoss:*\"], resources=[\"*\"])\n        )\n        subscription_filter_lambda.add_to_role_policy(\n            iam.PolicyStatement(actions=[\"logs:*\"], resources=[\"*\"])\n        )\n        subscription_filter_lambda.add_environment(\"INDEX_NAME\", INDEX_NAME)\n        #################################################################################\n        # The data access policy needs the lambda role ARN to allow writing.\n        dap = DATAPOLICY.replace(\n            \"LAMBDAROLEARN\", subscription_filter_lambda.role.role_arn\n        )\n        dat = opensearchserverless.CfnAccessPolicy(\n            self,\n            \"SvlCTCWLData\",\n            name=\"svlctcwldata\",\n            type=\"data\",\n            description=f\"Data access for {COLLECTION_NAME}\",\n            policy=dap,\n        )\n        print(\"Data access for collection is created\", dat.name)\n        ################################################################################\n        # CWL Log Group\n        log_group = cwl.LogGroup(\n            self,\n            \"SvlCTCWLLogGroup\",\n            log_group_name=LOG_GROUP_NAME,\n            retention=CWL_RETENTION,\n            removal_policy=RemovalPolicy.DESTROY,\n        )\n\n        ################################################################################\n        # CloudTrail trail\n        trail = ct.Trail(\n            self,\n            \"SvlCTCWLTrail\",\n            send_to_cloud_watch_logs=True,\n            cloud_watch_log_group=log_group,\n        )\n        print(\"CloudTrail is created\", trail._physical_name)\n\n        ################################################################################\n        # Set up subscription filter\n        subscription_filter = cwl.SubscriptionFilter(\n            self,\n            \"SvlCTCWLSubFilter\",\n            log_group=log_group,\n            destination=cwl_destinations.LambdaDestination(subscription_filter_lambda),\n            filter_pattern=cwl.FilterPattern.all_events(),\n        )\n        print(\n            \"Subscription Filter for CloudTrail is created\",\n            subscription_filter._physical_name,\n        )", "language": "python"}
{"input": "Game content from a local directory.", "output": "export class AssetContent extends Content {\n  private asset?: s3_assets.Asset;\n\n  /**\n   * @param path The path to the asset file or directory.\n   */\n  constructor(public readonly path: string, private readonly options: s3_assets.AssetOptions = { }) {\n    super();\n  }\n\n  public bind(scope: Construct, role: iam.IRole): ContentConfig {\n    // If the same AssetContent is used multiple times, retain only the first instantiation.\n    if (!this.asset) {\n      this.asset = new s3_assets.Asset(scope, 'Content', {\n        path: this.path,\n        ...this.options,\n      });\n    } else if (cdk.Stack.of(this.asset) !== cdk.Stack.of(scope)) {\n      throw new Error(`Asset is already associated with another stack '${cdk.Stack.of(this.asset).stackName}'. ` +\n        'Create a new Content instance for every stack.');\n    }\n    const bucket = s3.Bucket.fromBucketName(scope, 'AssetBucket', this.asset.s3BucketName);\n\n    // Adding permission to access specific content\n    role.addToPrincipalPolicy(new iam.PolicyStatement({\n      effect: iam.Effect.ALLOW,\n      resources: [bucket.arnForObjects(this.asset.s3ObjectKey)],\n      actions: ['s3:GetObject', 's3:GetObjectVersion'],\n    }));\n\n    if (!this.asset.isZipArchive) {\n      throw new Error(`Asset must be a .zip file or a directory (${this.path})`);\n    }\n\n    return {\n      s3Location: {\n        bucketName: this.asset.s3BucketName,\n        objectKey: this.asset.s3ObjectKey,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class TestApp for AWS resource management", "output": "export class TestApp extends App {\n  constructor(props?: Partial<AppProps>) {\n    super({\n      context: {\n        '@aws-cdk/core:newStyleStackSynthesis': '1',\n      },\n      stackTraces: false,\n      autoSynth: false,\n      treeMetadata: false,\n      ...props,\n    });\n  }\n\n  public stackArtifact(stackName: string | Stack) {\n    if (typeof stackName !== 'string') {\n      stackName = stackName.stackName;\n    }\n\n    this.synth();\n    const supportStack = this.node.findAll().filter(Stack.isStack).find(s => s.stackName === stackName);\n    expect(supportStack).not.toBeUndefined();\n    return supportStack;\n  }\n\n  public cleanup() {\n    rimraf(assemblyBuilderOf(this).outdir);\n  }\n}", "language": "typescript"}
{"input": "Helper class for working with Amazon-managed components", "output": "class AmazonManagedComponent {\n  /**\n   * Imports the AWS CLI v2 Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component options\n   */\n  public static awsCliV2(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.AWS_CLI_V2_CONFIG);\n  }\n\n  /**\n   * Imports the hello world Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component options\n   */\n  public static helloWorld(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.HELLO_WORLD_CONFIG);\n  }\n\n  /**\n   * Imports the Python 3 Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component options\n   */\n  public static python3(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.PYTHON_3_CONFIG);\n  }\n\n  /**\n   * Imports the reboot Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component options\n   */\n  public static reboot(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.REBOOT_CONFIG);\n  }\n\n  /**\n   * Imports the STIG hardening Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component options\n   *\n   * @see https://docs.aws.amazon.com/imagebuilder/latest/userguide/ib-stig.html\n   */\n  public static stigBuild(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.STIG_BUILD_CONFIG);\n  }\n\n  /**\n   * Imports the OS update Amazon-managed component\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param opts The Amazon-managed component attributes\n   */\n  public static updateOs(scope: Construct, id: string, opts: AmazonManagedComponentOptions): IComponent {\n    return this.predefinedManagedComponent(scope, id, opts, this.UPDATE_OS_CONFIG);\n  }\n\n  /**\n   * Imports an Amazon-managed component from its attributes\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param attrs The Amazon-managed component attributes\n   */\n  public static fromAmazonManagedComponentAttributes(\n    scope: Construct,\n    id: string,\n    attrs: AmazonManagedComponentAttributes,\n  ): IComponent {\n    return Component.fromComponentArn(\n      scope,\n      id,\n      cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        account: 'aws',\n        resource: 'component',\n        resourceName: `${attrs.componentName}/${attrs.componentVersion ?? LATEST_VERSION}`,\n      }),\n    );\n  }\n  /**\n   * Imports an Amazon-managed component from its name\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param amazonManagedComponentName - The name of the Amazon-managed component\n   */\n  public static fromAmazonManagedComponentName(\n    scope: Construct,\n    id: string,\n    amazonManagedComponentName: string,\n  ): IComponent {\n    return this.fromAmazonManagedComponentAttributes(scope, id, { componentName: amazonManagedComponentName });\n  }\n\n  private static readonly AWS_CLI_V2_CONFIG: AmazonManagedComponentConfig = {\n    component: 'awsCliV2',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'aws-cli-version-2-linux',\n      [Platform.WINDOWS]: 'aws-cli-version-2-windows',\n    },\n  };\n\n  private static readonly HELLO_WORLD_CONFIG: AmazonManagedComponentConfig = {\n    component: 'helloWorld',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'hello-world-linux',\n      [Platform.WINDOWS]: 'hello-world-windows',\n    },\n  };\n\n  private static readonly PYTHON_3_CONFIG: AmazonManagedComponentConfig = {\n    component: 'python3',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'python-3-linux',\n      [Platform.WINDOWS]: 'python-3-windows',\n    },\n  };\n\n  private static readonly REBOOT_CONFIG: AmazonManagedComponentConfig = {\n    component: 'reboot',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'reboot-linux',\n      [Platform.WINDOWS]: 'reboot-windows',\n    },\n  };\n\n  private static readonly STIG_BUILD_CONFIG: AmazonManagedComponentConfig = {\n    component: 'stigBuild',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'stig-build-linux',\n      [Platform.WINDOWS]: 'stig-build-windows',\n    },\n  };\n\n  private static readonly UPDATE_OS_CONFIG: AmazonManagedComponentConfig = {\n    component: 'updateOS',\n    supportedPlatforms: {\n      [Platform.LINUX]: 'update-linux',\n      [Platform.WINDOWS]: 'update-windows',\n    },\n  };\n\n  private static validatePredefinedManagedComponentOptions(\n    scope: Construct,\n    opts: AmazonManagedComponentOptions,\n    component: string,\n  ) {\n    if (opts.platform === undefined) {\n      throw new cdk.ValidationError(`a platform is required for ${component}`, scope);\n    }\n\n    if (cdk.Token.isUnresolved(opts.platform)) {\n      throw new cdk.ValidationError(`platform cannot be a token for ${component}`, scope);\n    }\n  }\n\n  private static predefinedManagedComponent(\n    scope: Construct,\n    id: string,\n    opts: AmazonManagedComponentOptions,\n    config: AmazonManagedComponentConfig,\n  ): IComponent {\n    this.validatePredefinedManagedComponentOptions(scope, opts, config.component);\n\n    const componentName = config.supportedPlatforms[opts.platform];\n\n    if (!componentName) {\n      throw new cdk.ValidationError(`${opts.platform} is not a supported platform for ${config.component}`, scope);\n    }\n\n    return this.fromAmazonManagedComponentAttributes(scope, id, {\n      componentName,\n      componentVersion: opts.componentVersion,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EventBridge, CloudFormation resources", "output": "export class CloudFormationStackArtifact extends CloudArtifact {\n  /**\n   * Checks if `art` is an instance of this class.\n   *\n   * Use this method instead of `instanceof` to properly detect `CloudFormationStackArtifact`\n   * instances, even when the construct library is symlinked.\n   *\n   * Explanation: in JavaScript, multiple copies of the `cx-api` library on\n   * disk are seen as independent, completely different libraries. As a\n   * consequence, the class `CloudFormationStackArtifact` in each copy of the `cx-api` library\n   * is seen as a different class, and an instance of one class will not test as\n   * `instanceof` the other class. `npm install` will not create installations\n   * like this, but users may manually symlink construct libraries together or\n   * use a monorepo tool: in those cases, multiple copies of the `cx-api`\n   * library can be accidentally installed, and `instanceof` will behave\n   * unpredictably. It is safest to avoid using `instanceof`, and using\n   * this type-testing method instead.\n   */\n  public static isCloudFormationStackArtifact(art: any): art is CloudFormationStackArtifact {\n    return art && typeof art === 'object' && CLOUDFORMATION_STACK_ARTIFACT_SYM in art;\n  }\n\n  /**\n   * The file name of the template.\n   */\n  public readonly templateFile: string;\n\n  /**\n   * The original name as defined in the CDK app.\n   */\n  public readonly originalName: string;\n\n  /**\n   * Any assets associated with this stack.\n   */\n  public readonly assets: cxschema.AssetMetadataEntry[];\n\n  /**\n   * CloudFormation parameters to pass to the stack.\n   */\n  public readonly parameters: { [id: string]: string };\n\n  /**\n   * CloudFormation tags to pass to the stack.\n   */\n  public readonly tags: { [id: string]: string };\n\n  /**\n   * SNS Topics that will receive stack events.\n   */\n  public readonly notificationArns?: string[];\n\n  /**\n   * The physical name of this stack.\n   */\n  public readonly stackName: string;\n\n  /**\n   * A string that represents this stack. Should only be used in user\n   * interfaces. If the stackName has not been set explicitly, or has been set\n   * to artifactId, it will return the hierarchicalId of the stack. Otherwise,\n   * it will return something like \"<hierarchicalId> (<stackName>)\"\n   */\n  public readonly displayName: string;\n\n  /**\n   * The physical name of this stack.\n   * @deprecated renamed to `stackName`\n   */\n  public readonly name: string;\n\n  /**\n   * The environment into which to deploy this artifact.\n   */\n  public readonly environment: Environment;\n\n  /**\n   * The role that needs to be assumed to deploy the stack\n   *\n   * @default - No role is assumed (current credentials are used)\n   */\n  public readonly assumeRoleArn?: string;\n\n  /**\n   * External ID to use when assuming role for cloudformation deployments\n   *\n   * @default - No external ID\n   */\n  readonly assumeRoleExternalId?: string;\n\n  /**\n   * Additional options to pass to STS when assuming the role for cloudformation deployments.\n   *\n   * - `RoleArn` should not be used. Use the dedicated `assumeRoleArn` property instead.\n   * - `ExternalId` should not be used. Use the dedicated `assumeRoleExternalId` instead.\n   * - `TransitiveTagKeys` defaults to use all keys (if any) specified in `Tags`. E.g, all tags are transitive by default.\n   *\n   * @see https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/STS.html#assumeRole-property\n   * @default - No additional options.\n   */\n  readonly assumeRoleAdditionalOptions?: { [key: string]: any };\n\n  /**\n   * The role that is passed to CloudFormation to execute the change set\n   *\n   * @default - No role is passed (currently assumed role/credentials are used)\n   */\n  public readonly cloudFormationExecutionRoleArn?: string;\n\n  /**\n   * The role to use to look up values from the target AWS account\n   *\n   * @default - No role is assumed (current credentials are used)\n   */\n  public readonly lookupRole?: cxschema.BootstrapRole;\n\n  /**\n   * If the stack template has already been included in the asset manifest, its asset URL\n   *\n   * @default - Not uploaded yet, upload just before deploying\n   */\n  public readonly stackTemplateAssetObjectUrl?: string;\n\n  /**\n   * Version of bootstrap stack required to deploy this stack\n   *\n   * @default - No bootstrap stack required\n   */\n  public readonly requiresBootstrapStackVersion?: number;\n\n  /**\n   * Name of SSM parameter with bootstrap stack version\n   *\n   * @default - Discover SSM parameter by reading stack\n   */\n  public readonly bootstrapStackVersionSsmParameter?: string;\n\n  /**\n   * Whether termination protection is enabled for this stack.\n   */\n  public readonly terminationProtection?: boolean;\n\n  /**\n   * Whether this stack should be validated by the CLI after synthesis\n   *\n   * @default - false\n   */\n  public readonly validateOnSynth?: boolean;\n\n  private _template: any | undefined;\n\n  constructor(assembly: CloudAssembly, artifactId: string, artifact: cxschema.ArtifactManifest) {\n    super(assembly, artifactId, artifact);\n\n    const properties = (this.manifest.properties || {}) as cxschema.AwsCloudFormationStackProperties;\n    if (!properties.templateFile) {\n      throw new CloudAssemblyError('Invalid CloudFormation stack artifact. Missing \"templateFile\" property in cloud assembly manifest');\n    }\n    if (!artifact.environment) {\n      throw new CloudAssemblyError('Invalid CloudFormation stack artifact. Missing environment');\n    }\n    this.environment = EnvironmentUtils.parse(artifact.environment);\n    this.templateFile = properties.templateFile;\n    this.parameters = properties.parameters ?? {};\n\n    // We get the tags from 'properties' if available (cloud assembly format >= 6.0.0), otherwise\n    // from the stack metadata\n    this.tags = properties.tags ?? this.tagsFromMetadata();\n    this.notificationArns = properties.notificationArns;\n    this.assumeRoleArn = properties.assumeRoleArn;\n    this.assumeRoleExternalId = properties.assumeRoleExternalId;\n    this.assumeRoleAdditionalOptions = properties.assumeRoleAdditionalOptions;\n    this.cloudFormationExecutionRoleArn = properties.cloudFormationExecutionRoleArn;\n    this.stackTemplateAssetObjectUrl = properties.stackTemplateAssetObjectUrl;\n    this.requiresBootstrapStackVersion = properties.requiresBootstrapStackVersion;\n    this.bootstrapStackVersionSsmParameter = properties.bootstrapStackVersionSsmParameter;\n    this.terminationProtection = properties.terminationProtection;\n    this.validateOnSynth = properties.validateOnSynth;\n    this.lookupRole = properties.lookupRole;\n\n    this.stackName = properties.stackName || artifactId;\n    this.assets = this.findMetadataByType(cxschema.ArtifactMetadataEntryType.ASSET).map(e => e.data as cxschema.AssetMetadataEntry);\n\n    this.displayName = this.stackName === artifactId\n      ? this.hierarchicalId\n      : `${this.hierarchicalId} (${this.stackName})`;\n\n    this.name = this.stackName; // backwards compat\n    this.originalName = this.stackName;\n  }\n\n  /**\n   * Full path to the template file\n   */\n  public get templateFullPath() {\n    return path.join(this.assembly.directory, this.templateFile);\n  }\n\n  /**\n   * The CloudFormation template for this stack.\n   */\n  public get template(): any {\n    if (this._template === undefined) {\n      this._template = JSON.parse(fs.readFileSync(this.templateFullPath, 'utf-8'));\n    }\n    return this._template;\n  }\n\n  private tagsFromMetadata() {\n    const ret: Record<string, string> = {};\n    for (const metadataEntry of this.findMetadataByType(cxschema.ArtifactMetadataEntryType.STACK_TAGS)) {\n      for (const tag of (metadataEntry.data ?? []) as cxschema.StackTagsMetadataEntry) {\n        ret[tag.key] = tag.value;\n      }\n    }\n    return ret;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates WAF, EventBridge, CloudFormation resources", "output": "class ProducerStack(Stack):\n    def __init__(self, scope: Construct, id: str, *, \n                app_name: str, \n                consumer_accounts: list[str], \n                 **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create the EventBus\n        producer_event_bus = events.EventBus(\n            self, f\"{app_name}-producer-event-bus\"\n        )\n\n        # Create rules for each consumer account\n        for index, consumer_account_id in enumerate(consumer_accounts):\n            # Create rule to forward events to consumer account\n            rule = events.Rule(\n                self, \n                f\"{app_name}-forward-to-consumer-{index + 1}-rule\",\n                event_bus=producer_event_bus,\n                event_pattern=events.EventPattern(\n                    source=['com.myapp.events']\n                )\n            )\n\n            # Add target to forward to consumer account's event bus\n            consumer_bus = events.EventBus.from_event_bus_arn(\n                self,\n                f\"{app_name}-consumer-{index + 1}-event-bus\",\n                f\"arn:aws:events:{Stack.of(self).region}:{consumer_account_id}:event-bus/default\"\n            )\n            rule.add_target(targets.EventBus(consumer_bus))", "language": "python"}
{"input": "CDK Stack that creates Lambda, WAF, EventBridge resources", "output": "class LambdaCronStack(Stack):\n    def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        with open(\"lambda-handler.py\", encoding=\"utf8\") as fp:\n            handler_code = fp.read()\n\n        lambdaFn = lambda_.Function(\n            self, \"Singleton\",\n            code=lambda_.InlineCode(handler_code),\n            handler=\"index.main\",\n            timeout=Duration.seconds(300),\n            runtime=lambda_.Runtime.PYTHON_3_12,\n        )\n\n        # Run every day at 6PM UTC\n        # See https://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html\n        rule = events.Rule(\n            self, \"Rule\",\n            schedule=events.Schedule.cron(\n                minute='0',\n                hour='18',\n                month='*',\n                week_day='MON-FRI',\n                year='*'),\n        )\n        rule.add_target(targets.LambdaFunction(lambdaFn))", "language": "python"}
{"input": "CDK class GrantWriteAllTablesTest for AWS resource management", "output": "class GrantWriteAllTablesTest extends GrantTestBase {\n  tableBucketName = 'grant-write-bucket-all-tables';\n  type = TestType.ALL_TABLES;\n  actions = perms.TABLE_BUCKET_WRITE_ACCESS;\n  grantAccess() {\n    this.tableBucket.grantWrite(new iam.ServicePrincipal(PRINCIPAL), WILDCARD);\n  }\n}", "language": "typescript"}
{"input": "The class for different repository providers", "output": "export class CloneRepository {\n  /**\n   * import repository to cloud9 environment from AWS CodeCommit\n   *\n   * @param repository the codecommit repository to clone from\n   * @param path  the target path in cloud9 environment\n   */\n  public static fromCodeCommit(repository: codecommit.IRepository, path: string): CloneRepository {\n    return {\n      repositoryUrl: repository.repositoryCloneUrlHttp,\n      pathComponent: path,\n    };\n  }\n\n  private constructor(public readonly repositoryUrl: string, public readonly pathComponent: string) {}\n}", "language": "typescript"}
{"input": "Stack that defines the key", "output": "class KeyStack extends cdk.Stack {\n  public readonly key: kms.Key;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    this.key = new kms.Key(this, 'MyKey', { removalPolicy: cdk.RemovalPolicy.DESTROY });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, DynamoDB, Kinesis, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  public readonly bucket: s3.Bucket;\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.bucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    const database = new glue.CfnDatabase(this, 'Database', {\n      databaseInput: {\n        description: 'My database',\n      },\n      catalogId: this.account,\n    });\n\n    const schemaTable = this.createTableWithInlineSchema(database);\n\n    // default hive json input with default orc output\n    this.createDeliveryStreamWithDataFormatConversion('DefaultHiveJsonOrc', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.HIVE_JSON,\n      outputFormat: firehose.OutputFormat.ORC,\n    });\n\n    // default openx json input with default parquet output\n    this.createDeliveryStreamWithDataFormatConversion('DefaultOpenXJsonParquet', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: firehose.OutputFormat.PARQUET,\n    });\n\n    // custom hive json input\n    this.createDeliveryStreamWithDataFormatConversion('CustomHiveJson', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: new firehose.HiveJsonInputFormat({\n        timestampParsers: [\n          firehose.TimestampParser.EPOCH_MILLIS,\n          firehose.TimestampParser.fromFormatString('yyyy-MM-dd'),\n        ],\n      }),\n      outputFormat: firehose.OutputFormat.ORC,\n    });\n\n    // custom openx json input\n    this.createDeliveryStreamWithDataFormatConversion('CustomOpenXJson', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: new firehose.OpenXJsonInputFormat({\n        lowercaseColumnNames: false,\n        columnToJsonKeyMappings: { column_yay: 'Column_A' },\n        convertDotsInJsonKeysToUnderscores: true,\n      }),\n      outputFormat: firehose.OutputFormat.PARQUET,\n    });\n\n    // custom orc output\n    this.createDeliveryStreamWithDataFormatConversion('CustomOrc', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.OrcOutputFormat({\n        blockSize: cdk.Size.mebibytes(256),\n        bloomFilterColumns: ['column_a'],\n        bloomFilterFalsePositiveProbability: 0.5,\n        compression: firehose.OrcCompression.NONE,\n        dictionaryKeyThreshold: 0.3,\n        formatVersion: firehose.OrcFormatVersion.V0_11,\n        enablePadding: true,\n        paddingTolerance: 0.4,\n        rowIndexStride: 5000,\n        stripeSize: cdk.Size.mebibytes(32),\n      }),\n    });\n\n    // ORC ZLIB compression\n    this.createDeliveryStreamWithDataFormatConversion('CustomOrcZlib', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.OrcOutputFormat({\n        compression: firehose.OrcCompression.ZLIB,\n        formatVersion: firehose.OrcFormatVersion.V0_12,\n      }),\n    });\n\n    // ORC SNAPPY compression\n    this.createDeliveryStreamWithDataFormatConversion('CustomOrcSnappy', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.OrcOutputFormat({\n        compression: firehose.OrcCompression.SNAPPY,\n      }),\n    });\n\n    // custom parquet output format\n    this.createDeliveryStreamWithDataFormatConversion('CustomParquet', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.ParquetOutputFormat({\n        blockSize: cdk.Size.mebibytes(128),\n        pageSize: cdk.Size.mebibytes(2),\n        compression: firehose.ParquetCompression.UNCOMPRESSED,\n        writerVersion: firehose.ParquetWriterVersion.V2,\n        enableDictionaryCompression: true,\n        maxPadding: cdk.Size.bytes(100),\n      }),\n    });\n\n    // Parquet GZIP compression\n    this.createDeliveryStreamWithDataFormatConversion('CustomParquetGzip', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.ParquetOutputFormat({\n        compression: firehose.ParquetCompression.GZIP,\n        writerVersion: firehose.ParquetWriterVersion.V1,\n      }),\n    });\n\n    // Parquet SNAPPY compression\n    this.createDeliveryStreamWithDataFormatConversion('CustomParquetSnappy', {\n      schemaConfiguration: firehose.SchemaConfiguration.fromCfnTable(schemaTable),\n      inputFormat: firehose.InputFormat.OPENX_JSON,\n      outputFormat: new firehose.ParquetOutputFormat({\n        compression: firehose.ParquetCompression.SNAPPY,\n      }),\n    });\n  }\n\n  private createTableWithInlineSchema(database: glue.CfnDatabase): glue.CfnTable {\n    return new glue.CfnTable(this, 'InlineSchemaTable', {\n      catalogId: database.catalogId,\n      databaseName: database.ref,\n      tableInput: {\n        storageDescriptor: {\n          columns: SCHEMA_COLUMNS,\n        },\n      },\n    });\n  }\n\n  private createDeliveryStreamWithDataFormatConversion(\n    id: string,\n    dataFormatConversion: firehose.DataFormatConversionProps,\n  ): firehose.DeliveryStream {\n    return new firehose.DeliveryStream(this, id, {\n      destination: new firehose.S3Bucket(this.bucket, {\n        dataOutputPrefix: `success/${id}/`,\n        errorOutputPrefix: `error/${id}/`,\n        bufferingInterval: cdk.Duration.seconds(0),\n        dataFormatConversion: dataFormatConversion,\n      }),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class NodeProxyAgentLayer for AWS resource management", "output": "export class NodeProxyAgentLayer extends lambda.LayerVersion {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.lambda-layer-node-proxy-agent.NodeProxyAgentLayer';\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id, {\n      code: lambda.Code.fromAsset(ASSET_FILE, {\n        // we hash the layer directory (it contains the tools versions and Dockerfile) because hashing the zip is non-deterministic\n        assetHash: FileSystem.fingerprint(LAYER_SOURCE_DIR),\n      }),\n      description: '/opt/nodejs/node_modules/proxy-agent',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, IAM, KMS, MSK (Kafka) resources", "output": "class EmrServicePrincipalTestStack extends cdk.Stack {\n  cluster: emr.CfnCluster;\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const subnetId = process.env.SUBNET_ID ?? process.env.CDK_INTEG_SUBNET_ID;\n    if (!subnetId) {\n      throw new Error('Env vars SUBNET_ID must be set');\n    }\n\n    const emrServiceRole = new iam.Role(this, 'EMRServiceRole', {\n      assumedBy: iam.ServicePrincipal.fromStaticServicePrincipleName('elasticmapreduce.amazonaws.com.cn'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/AmazonElasticMapReduceRole'),\n      ],\n    });\n\n    const emrJobFlowRole = new iam.Role(this, 'EMRJobFlowRole', {\n      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/AmazonElasticMapReduceforEC2Role'),\n      ],\n    });\n\n    const emrJobFlowProfile = new iam.CfnInstanceProfile(this, 'EMRJobFlowProfile', {\n      roles: [emrJobFlowRole.roleName],\n      instanceProfileName: 'EMRJobFlowProfile_',\n    });\n\n    const sshKey = new ec2.CfnKeyPair(this, 'SSHKey', {\n      keyName: 'TestingSSHKey',\n    });\n\n    this.cluster = new emr.CfnCluster(this, 'EMRCluster', {\n      name: 'My first cluster',\n      instances: {\n        coreInstanceGroup: {\n          instanceCount: 1,\n          instanceType: 'm5.xlarge',\n        },\n        ec2SubnetId: subnetId,\n        hadoopVersion: 'Amazon',\n        keepJobFlowAliveWhenNoSteps: false,\n        ec2KeyName: sshKey.ref,\n        terminationProtected: false,\n        masterInstanceGroup: {\n          instanceCount: 1,\n          instanceType: 'm5.xlarge',\n        },\n      },\n      jobFlowRole: emrJobFlowProfile.ref,\n      applications: [\n        { name: 'Spark' },\n      ],\n      serviceRole: emrServiceRole.roleName,\n      releaseLabel: 'emr-6.4.0',\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class FieldAwareEventInput for AWS resource management", "output": "export class FieldAwareEventInput extends RuleTargetInput {\n  constructor(private readonly input: any, private readonly inputType: InputType) {\n    super();\n  }\n\n  public bind(rule: IRuleRef): RuleTargetInputProperties {\n    let fieldCounter = 0;\n    const pathToKey = new Map<string, string>();\n    const inputPathsMap: {[key: string]: string} = {};\n\n    function keyForField(f: EventField) {\n      const existing = pathToKey.get(f.path);\n      if (existing !== undefined) { return existing; }\n\n      fieldCounter += 1;\n      const key = f.displayHint || `f${fieldCounter}`;\n      pathToKey.set(f.path, key);\n      return key;\n    }\n\n    class EventFieldReplacer extends DefaultTokenResolver {\n      constructor() {\n        super(new StringConcat());\n      }\n\n      public resolveToken(t: Token, _context: IResolveContext) {\n        if (!isEventField(t)) { return Token.asString(t); }\n\n        const key = keyForField(t);\n        if (inputPathsMap[key] && inputPathsMap[key] !== t.path) {\n          throw new UnscopedValidationError(`Single key '${key}' is used for two different JSON paths: '${t.path}' and '${inputPathsMap[key]}'`);\n        }\n        inputPathsMap[key] = t.path;\n\n        return `<${key}>`;\n      }\n    }\n\n    const stack = Stack.of(rule);\n\n    let resolved: string;\n    if (this.inputType === InputType.Multiline) {\n      // JSONify individual lines\n      resolved = Tokenization.resolve(this.input, {\n        scope: rule,\n        resolver: new EventFieldReplacer(),\n      });\n      resolved = resolved.split('\\n').map(stack.toJsonString).join('\\n');\n    } else {\n      resolved = stack.toJsonString(Tokenization.resolve(this.input, {\n        scope: rule,\n        resolver: new EventFieldReplacer(),\n      }));\n    }\n\n    const keys = Object.keys(inputPathsMap);\n\n    if (keys.length === 0) {\n      // Nothing special, just return 'input'\n      return { input: resolved };\n    }\n\n    return {\n      inputTemplate: this.unquoteKeyPlaceholders(resolved, keys),\n      inputPathsMap,\n    };\n  }\n\n  /**\n   * Removing surrounding quotes from any object placeholders\n   * when key is the lone value.\n   *\n   * Those have been put there by JSON.stringify(), but we need to\n   * remove them.\n   *\n   * Do not remove quotes when the key is part of a larger string.\n   *\n   * Valid: { \"data\": \"Some string with \\\"quotes\\\"<key>\" } // key will be string\n   * Valid: { \"data\": <key> } // Key could be number, bool, obj, or string\n   */\n  private unquoteKeyPlaceholders(sub: string, keys: string[]) {\n    if (this.inputType !== InputType.Object) { return sub; }\n\n    return Lazy.uncachedString({ produce: (ctx: IResolveContext) => Token.asString(deepUnquote(ctx.resolve(sub))) });\n\n    function deepUnquote(resolved: any): any {\n      if (Array.isArray(resolved)) {\n        return resolved.map(deepUnquote);\n      } else if (typeof(resolved) === 'object' && resolved !== null) {\n        for (const [key, value] of Object.entries(resolved)) {\n          resolved[key] = deepUnquote(value);\n        }\n        return resolved;\n      } else if (typeof(resolved) === 'string') {\n        return keys.reduce((r, key) => r.replace(new RegExp(`(?<!\\\\\\\\)\\\"\\<${key}\\>\\\"`, 'g'), `<${key}>`), resolved);\n      }\n      return resolved;\n    }\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: - Deploy with `--no-clean` - Verify that `ServiceTimeout` is set to 60 in the CloudWatch Logs for the Lambda function that creates custom resources.", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    const resourceType = 'Custom::Reflect';\n\n    const serviceToken = CustomResourceProvider.getOrCreate(this, resourceType, {\n      codeDirectory: `${__dirname}/core-custom-resource-provider-fixture`,\n      runtime: CustomResourceProviderRuntime.NODEJS_20_X,\n      description: 'veni vidi vici',\n    });\n\n    new CustomResource(this, 'MyResource', {\n      resourceType,\n      serviceToken,\n      serviceTimeout: Duration.seconds(60),\n    });\n  }\n}", "language": "typescript"}
{"input": "Agent Collaborator Class ***************************************************************************", "output": "export class AgentCollaborator {\n  /**\n   * The agent alias that this collaborator represents.\n   * This is the agent that will be called upon for collaboration.\n   */\n  public readonly agentAlias: IAgentAlias;\n\n  /**\n   * Instructions on how this agent should collaborate with the main agent.\n   */\n  public readonly collaborationInstruction: string;\n\n  /**\n   * A friendly name for the collaborator.\n   */\n  public readonly collaboratorName: string;\n\n  /**\n   * Whether to relay conversation history to this collaborator.\n   *\n   * @default - undefined (uses service default)\n   */\n  public readonly relayConversationHistory?: boolean;\n\n  public constructor(props: AgentCollaboratorProps) {\n    // Validate Props\n    this.validateProps(props);\n\n    // ------------------------------------------------------\n    // Set attributes or defaults\n    // ------------------------------------------------------\n    this.agentAlias = props.agentAlias;\n    this.collaborationInstruction = props.collaborationInstruction;\n    this.collaboratorName = props.collaboratorName;\n    this.relayConversationHistory = props.relayConversationHistory;\n  }\n\n  private validateProps(props: AgentCollaboratorProps) {\n    if (props.agentAlias.aliasId === 'TSTALIASID') {\n      throw new ValidationError('Agent cannot collaborate with TSTALIASID alias of another agent');\n    }\n  }\n\n  /**\n   * Format as CFN properties\n   *\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(): CfnAgent.AgentCollaboratorProperty {\n    return {\n      agentDescriptor: {\n        aliasArn: this.agentAlias.aliasArn,\n      },\n      collaborationInstruction: this.collaborationInstruction,\n      collaboratorName: this.collaboratorName,\n      relayConversationHistory: this.relayConversationHistory ? RelayConversationHistoryType.TO_COLLABORATOR : RelayConversationHistoryType.DISABLED,\n    };\n  }\n\n  /**\n   * Grants the given identity permissions to collaborate with the agent\n   * [disable-awslint:no-grants]\n   * @param grantee The principal to grant permissions to\n   * @returns The Grant object\n   */\n  public grant(grantee: IGrantable): Grant {\n    const grant1 = this.agentAlias.grantInvoke(grantee);\n    const combinedGrant = grant1.combine(this.agentAlias.grantGet(grantee));\n    return combinedGrant;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, WAF, SNS resources", "output": "export class BStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: BStackProps) {\n    super(scope, id, props);\n\n    const topic = new sns.Topic(this, 'SampleTopic');\n    topic.grantPublish(new iam.ServicePrincipal('s3.amazonaws.com', {\n      conditions: {\n        ArnLike: {\n          'aws:SourceArn': cdk.Arn.format({\n            service: 's3',\n            region: '',\n            account: '',\n            resource: props.bucketName\n          }, this)\n        }\n      }\n    }));\n\n    const lambdaArn = cdk.Arn.format({\n      service: 'lambda',\n      resource: 'S3EventNotificationsManager'\n    }, this);\n    new cdk.CustomResource(this, 'SampleBucketNotification', {\n      serviceToken: lambdaArn,\n      properties: {\n        BucketName: props.bucketName,\n        NotificationConfiguration: {\n          TopicConfigurations: [\n            {\n              Id: 'SampleSnsNotification',\n              Events: ['s3:ObjectCreated:*'],\n              Filter: {\n                Key: {\n                  FilterRules: [\n                    {\n                      Name: 'prefix',\n                      Value: 'CategoryB/'\n                    }\n                  ]\n                }\n              },\n              TopicArn: topic.topicArn\n            }\n          ]\n        }\n      }\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, CloudFormation, CloudFront resources", "output": "export class DemoCloudfrontFunctionsStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // create a bucket to deploy the website files\n    const bucket = new Bucket(this, 'WebsiteBucket', {\n      encryption: BucketEncryption.S3_MANAGED,\n      versioned: true,\n      enforceSSL: true,\n      blockPublicAccess: BlockPublicAccess.BLOCK_ALL,\n      removalPolicy: RemovalPolicy.DESTROY\n    });\n\n    // create a s3 bucket deployment to deploy the website directory's files to the website bucket\n    new BucketDeployment(this, 'WebsiteFiles', {\n      destinationBucket: bucket,\n      sources: [Source.asset('./website')],\n      contentType: 'text/html',\n      retainOnDelete: false,\n    });\n\n    // create an Origin Access Identity for CloudFront\n    const cloudfrontOAI = new OriginAccessIdentity(this, 'cloudfront-OAI', {\n      comment: `OAI for ${id}`\n    });\n\n    // grant read permissions on the bucket to the CloudFront's Origin Access Identity\n    bucket.grantRead(cloudfrontOAI);\n\n    // create a cloudFront function from the request-function.js file\n    const requestFunction = new Function(this, 'RequestFunction', {\n      functionName: 'RequestFunction',\n      runtime: FunctionRuntime.JS_2_0,\n      code: FunctionCode.fromFile({\n        filePath: './resources/functions/request-function.js'\n      })\n    });\n\n    // create a cloudFront function from the response-function.js file\n    const responseFunction = new Function(this, 'ResponseFunction', {\n      functionName: 'ResponseFunction',\n      runtime: FunctionRuntime.JS_2_0,\n      code: FunctionCode.fromFile({\n        filePath: './resources/functions/response-function.js'\n      })\n    });\n\n    // create a CloudFront behavior with origin of my website bucket and both request and response functions\n    const defaultBehavior: BehaviorOptions = {\n      origin: new S3Origin(bucket),\n      compress: true,\n      allowedMethods: AllowedMethods.ALLOW_ALL,\n      functionAssociations: [\n        {\n          function: requestFunction,\n          eventType: FunctionEventType.VIEWER_REQUEST,\n        },\n        {\n          function: responseFunction,\n          eventType: FunctionEventType.VIEWER_RESPONSE,\n        }\n      ]\n    };\n\n    // create a CloudFront distribution with the behavior created\n    const distribution = new Distribution(this, 'SiteDistribution', {\n      comment: 'CloudFront Functions example',\n      defaultRootObject: 'index.html',\n      defaultBehavior: defaultBehavior,\n    });\n\n    // create an output with the CloudFront distribution URL\n    new cdk.CfnOutput(this, 'DistributionDomainName', {\n      value: distribution.domainName,\n    });\n\n  }\n}", "language": "typescript"}
{"input": "Error thrown when cross-region inference profile validation fails.", "output": "class CrossRegionInferenceProfileError extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = 'CrossRegionInferenceProfileError';\n  }\n}", "language": "typescript"}
{"input": "The license must be Apache-2.0.", "output": "export class License extends ValidationRule {\n  public readonly name = 'package-info/license';\n\n  public validate(pkg: PackageJson): void {\n    expectJSON(this.name, pkg, 'license', 'Apache-2.0');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ECS, ELB / ALB / NLB, CloudMap (Service Discovery) resources", "output": "export class SplitAtListener_ServiceStack extends Stack {\n  constructor(scope: Construct, id: string, props: SplitAtListener_ServiceStackProps) {\n    super(scope, id, props);\n\n    // Standard ECS service setup\n    const taskDefinition = new ecs.FargateTaskDefinition(this, 'TaskDef');\n    const container = taskDefinition.addContainer('web', {\n      image: ecs.ContainerImage.fromRegistry(\"amazon/amazon-ecs-sample\"),\n      memoryLimitMiB: 256,\n    });\n\n    container.addPortMappings({\n      containerPort: 80,\n      protocol: ecs.Protocol.TCP\n    });\n\n    const service = new ecs.FargateService(this, \"Service\", {\n      cluster: props.cluster,\n      taskDefinition,\n    });\n\n    // Create a new listener in the current scope, add targets to it\n    const listener = new elbv2.ApplicationListener(this, 'Listener', {\n      loadBalancer: props.loadBalancer, // ! need to pass load balancer to attach to !\n      port: 80,\n    });\n\n    listener.addTargets('ECS', {\n      port: 80,\n      targets: [service],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ScheduleGroup for AWS resource management", "output": "export class ScheduleGroup extends ScheduleGroupBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-scheduler.ScheduleGroup';\n\n  /**\n   * Import an external schedule group by ARN.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param scheduleGroupArn the ARN of the schedule group to import (e.g. `arn:aws:scheduler:region:account-id:schedule-group/group-name`)\n   */\n  public static fromScheduleGroupArn(scope: Construct, id: string, scheduleGroupArn: string): IScheduleGroup {\n    const arnComponents = Stack.of(scope).splitArn(scheduleGroupArn, ArnFormat.SLASH_RESOURCE_NAME);\n    const scheduleGroupName = arnComponents.resourceName!;\n    class Import extends ScheduleGroupBase {\n      scheduleGroupName = scheduleGroupName;\n      scheduleGroupArn = scheduleGroupArn;\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * Import a default schedule group.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   */\n  public static fromDefaultScheduleGroup(scope: Construct, id: string): IScheduleGroup {\n    return ScheduleGroup.fromScheduleGroupName(scope, id, 'default');\n  }\n\n  /**\n   * Import an existing schedule group with a given name.\n   *\n   * @param scope construct scope\n   * @param id construct id\n   * @param scheduleGroupName the name of the existing schedule group to import\n   */\n  public static fromScheduleGroupName(scope: Construct, id: string, scheduleGroupName: string): IScheduleGroup {\n    const groupArn = Stack.of(scope).formatArn({\n      service: 'scheduler',\n      resource: 'schedule-group',\n      resourceName: scheduleGroupName,\n    });\n    return ScheduleGroup.fromScheduleGroupArn(scope, id, groupArn);\n  }\n\n  public readonly scheduleGroupName: string;\n  public readonly scheduleGroupArn: string;\n\n  public constructor(scope: Construct, id: string, props?: ScheduleGroupProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.scheduleGroupName = props?.scheduleGroupName ?? Names.uniqueResourceName(this, {\n      maxLength: 64,\n      separator: '-',\n    });\n\n    const resource = new CfnScheduleGroup(this, 'Resource', {\n      name: this.scheduleGroupName,\n    });\n\n    resource.applyRemovalPolicy(props?.removalPolicy);\n\n    this.scheduleGroupArn = this.getResourceArnAttribute(resource.attrArn, {\n      service: 'scheduler',\n      resource: 'schedule-group',\n      resourceName: this.scheduleGroupName,\n    });\n  }\n}", "language": "typescript"}
{"input": "Defines a CloudFormation Stack consisting of an EventBus, EventBus Policy,\nand a Lambda Function for consuming test events from the EventBus.", "output": "class ConsumerStack(Stack):\n    \"\"\"\n    Defines a CloudFormation Stack consisting of an EventBus, EventBus Policy,\n    and a Lambda Function for consuming test events from the EventBus.\n    \"\"\"\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        self.id = \"Consumer\"\n        self.event_bus_name = self.node.try_get_context(\"event_bus_name\")\n\n        self.event_bus = events.EventBus(\n            self,\n            self.id + \"EB\" + self.event_bus_name,\n            event_bus_name=self.event_bus_name,\n        )\n\n        self.event_bus_policy = events.CfnEventBusPolicy(\n            self,\n            self.id + \"EBPolicy\",\n            statement_id=\"AllowOrgToPutEvents\",\n            action=\"events:PutEvents\",\n            condition=events.CfnEventBusPolicy.ConditionProperty(\n                type=\"StringEquals\",\n                key=\"aws:PrincipalOrgID\",\n                value=self.node.try_get_context(\"organization_id\"),\n            ),\n            event_bus_name=self.event_bus.event_bus_name,\n            principal=\"*\",\n        )\n\n        self.deploy_consumer(self.event_bus)\n\n        # Adds CDK Nag check to stack resources\n        Aspects.of(self).add(AwsSolutionsChecks())\n\n    def deploy_consumer(self, event_bus: events.EventBus) -> None:\n        \"\"\"\n        Creates a Lambda function to consume test events on the provided\n        EventBus. Includes a Dead Letter Queue (DLQ) to handle up to 3\n        failed function invocations.\n\n        Args:\n            * event_bus (events.EventBus): The EventBridge bus to consume test\n                events\n\n        \"\"\"\n        lambda_function = _lambda.Function(\n            self,\n            \"ConsumerLambda\",\n            runtime=_lambda.Runtime.PYTHON_3_12,\n            handler=\"consumer.handler\",\n            timeout=Duration.seconds(30),\n            code=_lambda.Code.from_asset(\"./lambda/consumer\"),\n            environment={\n                \"LOG_LEVEL\": \"DEBUG\",\n            },\n        )\n\n        # This check ensures the usage of the role is not an optional (mypy)\n        if lambda_function.role is None:\n            raise ValueError(\"No Lambda function role was created\")\n\n        NagSuppressions.add_resource_suppressions(\n            construct=lambda_function.role,\n            suppressions=[\n                NagPackSuppression(\n                    id=\"AwsSolutions-IAM4\",\n                    reason=\"The default function role is an AWS managed role\",\n                )\n            ],\n        )\n\n        rule = events.Rule(\n            self,\n            self.id + \"ConsumerRule\",\n            event_bus=event_bus,\n            event_pattern=events.EventPattern(\n                source=[\"Producer\"],\n            ),\n        )\n\n        dlq = sqs.Queue(\n            self,\n            self.id + \"ConsumerDLQ\",\n            enforce_ssl=True\n        )\n\n        rule.add_target(\n            event_targets.LambdaFunction(\n                lambda_function, retry_attempts=3, dead_letter_queue=dlq\n            )\n        )\n\n        NagSuppressions.add_resource_suppressions(\n            construct=dlq,\n            suppressions=[\n                NagPackSuppression(\n                    id=\"AwsSolutions-SQS3\",\n                    reason=\"The rule target correctly has the DLQ configured\",\n                )\n            ],\n        )", "language": "python"}
{"input": "Abstract base for ``DatabaseCluster`` and ``DatabaseClusterFromSnapshot``", "output": "class DatabaseClusterNew extends DatabaseClusterBase {\n  /**\n   * The engine for this Cluster.\n   * Never undefined.\n   */\n  public readonly engine?: IClusterEngine;\n\n  protected readonly newCfnProps: CfnDBClusterProps;\n  protected readonly securityGroups: ec2.ISecurityGroup[];\n  protected readonly subnetGroupRef: aws_rds.IDBSubnetGroupRef;\n\n  private readonly domainId?: string;\n  private readonly domainRole?: iam.IRole;\n\n  /**\n   * Secret in SecretsManager to store the database cluster user credentials.\n   */\n  public abstract readonly secret?: secretsmanager.ISecret;\n\n  /**\n   * The VPC network to place the cluster in.\n   */\n  public readonly vpc: ec2.IVpc;\n\n  /**\n   * The cluster's subnets.\n   */\n  public readonly vpcSubnets?: ec2.SubnetSelection;\n\n  /**\n   * The log group is created when `cloudwatchLogsExports` is set.\n   *\n   * Each export value will create a separate log group.\n   */\n  public readonly cloudwatchLogGroups: {[engine: string]: logs.ILogGroup};\n\n  /**\n   * Application for single user rotation of the master password to this cluster.\n   */\n  public readonly singleUserRotationApplication: secretsmanager.SecretRotationApplication;\n\n  /**\n   * Application for multi user rotation to this cluster.\n   */\n  public readonly multiUserRotationApplication: secretsmanager.SecretRotationApplication;\n\n  /**\n   * Whether Performance Insights is enabled at cluster level.\n   */\n  public readonly performanceInsightsEnabled: boolean;\n\n  /**\n   * The amount of time, in days, to retain Performance Insights data.\n   */\n  public readonly performanceInsightRetention?: PerformanceInsightRetention;\n\n  /**\n   * The AWS KMS key for encryption of Performance Insights data.\n   */\n  public readonly performanceInsightEncryptionKey?: kms.IKey;\n\n  /**\n   * The database insights mode.\n   */\n  public readonly databaseInsightsMode?: DatabaseInsightsMode;\n\n  /**\n   * The IAM role for the enhanced monitoring.\n   */\n  public readonly monitoringRole?: iam.IRole;\n\n  protected readonly serverlessV2MinCapacity: number;\n  protected readonly serverlessV2MaxCapacity: number;\n  protected readonly serverlessV2AutoPauseDuration?: Duration;\n\n  protected hasServerlessInstance?: boolean;\n  protected enableDataApi?: boolean;\n\n  constructor(scope: Construct, id: string, props: DatabaseClusterBaseProps) {\n    super(scope, id);\n\n    if (props.clusterScalabilityType !== undefined && props.clusterScailabilityType !== undefined) {\n      throw new ValidationError('You cannot specify both clusterScalabilityType and clusterScailabilityType (deprecated). Use clusterScalabilityType.', this);\n    }\n\n    if ((props.vpc && props.instanceProps?.vpc) || (!props.vpc && !props.instanceProps?.vpc)) {\n      throw new ValidationError('Provide either vpc or instanceProps.vpc, but not both', this);\n    }\n    if ((props.vpcSubnets && props.instanceProps?.vpcSubnets)) {\n      throw new ValidationError('Provide either vpcSubnets or instanceProps.vpcSubnets, but not both', this);\n    }\n    this.vpc = props.instanceProps?.vpc ?? props.vpc!;\n    this.vpcSubnets = props.instanceProps?.vpcSubnets ?? props.vpcSubnets;\n\n    this.cloudwatchLogGroups = {};\n\n    this.singleUserRotationApplication = props.engine.singleUserRotationApplication;\n    this.multiUserRotationApplication = props.engine.multiUserRotationApplication;\n\n    this.serverlessV2MaxCapacity = props.serverlessV2MaxCapacity ?? 2;\n    this.serverlessV2MinCapacity = props.serverlessV2MinCapacity ?? 0.5;\n    this.serverlessV2AutoPauseDuration = props.serverlessV2AutoPauseDuration;\n\n    this.enableDataApi = props.enableDataApi;\n\n    const { subnetIds } = this.vpc.selectSubnets(this.vpcSubnets);\n\n    // Cannot test whether the subnets are in different AZs, but at least we can test the amount.\n    if (subnetIds.length < 2) {\n      Annotations.of(this).addError(`Cluster requires at least 2 subnets, got ${subnetIds.length}`);\n    }\n\n    this.subnetGroupRef = props.subnetGroup ?? new SubnetGroup(this, 'Subnets', {\n      description: `Subnets for ${id} database`,\n      vpc: this.vpc,\n      vpcSubnets: this.vpcSubnets,\n      removalPolicy: renderUnless(helperRemovalPolicy(props.removalPolicy), RemovalPolicy.DESTROY),\n    });\n\n    this.securityGroups = props.instanceProps?.securityGroups ?? props.securityGroups ?? [\n      new ec2.SecurityGroup(this, 'SecurityGroup', {\n        description: 'RDS security group',\n        vpc: this.vpc,\n      }),\n    ];\n\n    const combineRoles = props.engine.combineImportAndExportRoles ?? false;\n    let { s3ImportRole, s3ExportRole } = setupS3ImportExport(this, props, combineRoles);\n\n    if (props.parameterGroup && props.parameters) {\n      throw new ValidationError('You cannot specify both parameterGroup and parameters', this);\n    }\n    const parameterGroup = props.parameterGroup ?? (\n      props.parameters\n        ? new ParameterGroup(this, 'ParameterGroup', {\n          engine: props.engine,\n          parameters: props.parameters,\n        })\n        : undefined\n    );\n    // bind the engine to the Cluster\n    const clusterEngineBindConfig = props.engine.bindToCluster(this, {\n      s3ImportRole,\n      s3ExportRole,\n      parameterGroup,\n    });\n\n    const clusterAssociatedRoles: CfnDBCluster.DBClusterRoleProperty[] = [];\n    if (s3ImportRole) {\n      clusterAssociatedRoles.push({ roleArn: s3ImportRole.roleArn, featureName: clusterEngineBindConfig.features?.s3Import });\n    }\n    if (s3ExportRole &&\n        // only add the second associated Role if it's different than the first\n        // (duplicates in the associated Roles array are not allowed by the RDS service)\n        (s3ExportRole !== s3ImportRole ||\n        clusterEngineBindConfig.features?.s3Import !== clusterEngineBindConfig.features?.s3Export)) {\n      clusterAssociatedRoles.push({ roleArn: s3ExportRole.roleArn, featureName: clusterEngineBindConfig.features?.s3Export });\n    }\n\n    const clusterParameterGroup = props.parameterGroup ?? clusterEngineBindConfig.parameterGroup;\n    const clusterParameterGroupConfig = clusterParameterGroup?.bindToCluster({});\n    this.engine = props.engine;\n\n    const clusterIdentifier = FeatureFlags.of(this).isEnabled(cxapi.RDS_LOWERCASE_DB_IDENTIFIER) && !Token.isUnresolved(props.clusterIdentifier)\n      ? props.clusterIdentifier?.toLowerCase()\n      : props.clusterIdentifier;\n\n    if (props.domain) {\n      this.domainId = props.domain;\n      this.domainRole = props.domainRole ?? new iam.Role(this, 'RDSClusterDirectoryServiceRole', {\n        assumedBy: new iam.CompositePrincipal(\n          new iam.ServicePrincipal('rds.amazonaws.com'),\n          new iam.ServicePrincipal('directoryservice.rds.amazonaws.com'),\n        ),\n        managedPolicies: [\n          iam.ManagedPolicy.fromAwsManagedPolicyName('service-role/AmazonRDSDirectoryServiceAccess'),\n        ],\n      });\n    }\n\n    validateDatabaseClusterProps(this, props);\n    this.validateServerlessScalingConfig(clusterEngineBindConfig);\n\n    const enablePerformanceInsights = props.enablePerformanceInsights\n      || props.performanceInsightRetention !== undefined\n      || props.performanceInsightEncryptionKey !== undefined\n      || props.databaseInsightsMode === DatabaseInsightsMode.ADVANCED;\n    this.performanceInsightsEnabled = enablePerformanceInsights;\n    this.performanceInsightRetention = enablePerformanceInsights\n      ? (props.performanceInsightRetention || PerformanceInsightRetention.DEFAULT)\n      : undefined;\n    this.performanceInsightEncryptionKey = props.performanceInsightEncryptionKey;\n    this.databaseInsightsMode = props.databaseInsightsMode;\n\n    // configure enhanced monitoring role for the cluster or instance\n    this.monitoringRole = props.monitoringRole;\n    if (!props.monitoringRole && props.monitoringInterval && props.monitoringInterval.toSeconds()) {\n      this.monitoringRole = new Role(this, 'MonitoringRole', {\n        assumedBy: new ServicePrincipal('monitoring.rds.amazonaws.com'),\n        managedPolicies: [\n          ManagedPolicy.fromAwsManagedPolicyName('service-role/AmazonRDSEnhancedMonitoringRole'),\n        ],\n      });\n    }\n\n    if (props.enableClusterLevelEnhancedMonitoring && !props.monitoringInterval) {\n      throw new ValidationError('`monitoringInterval` must be set when `enableClusterLevelEnhancedMonitoring` is true.', this);\n    }\n    if (\n      props.monitoringInterval && !props.monitoringInterval.isUnresolved() &&\n      [0, 1, 5, 10, 15, 30, 60].indexOf(props.monitoringInterval.toSeconds()) === -1\n    ) {\n      throw new ValidationError(`'monitoringInterval' must be one of 0, 1, 5, 10, 15, 30, or 60 seconds, got: ${props.monitoringInterval.toSeconds()} seconds.`, this);\n    }\n\n    this.newCfnProps = {\n      // Basic\n      engine: props.engine.engineType,\n      engineVersion: props.engine.engineVersion?.fullVersion,\n      dbClusterIdentifier: clusterIdentifier,\n      dbSubnetGroupName: this.subnetGroupRef.dbSubnetGroupRef.dbSubnetGroupName,\n      vpcSecurityGroupIds: this.securityGroups.map(sg => sg.securityGroupId),\n      port: props.port ?? clusterEngineBindConfig.port,\n      dbClusterParameterGroupName: clusterParameterGroupConfig?.parameterGroupName,\n      associatedRoles: clusterAssociatedRoles.length > 0 ? clusterAssociatedRoles : undefined,\n      deletionProtection: defaultDeletionProtection(props.deletionProtection, props.removalPolicy),\n      enableIamDatabaseAuthentication: props.iamAuthentication,\n      enableHttpEndpoint: Lazy.any({ produce: () => this.enableDataApi }),\n      networkType: props.networkType,\n      serverlessV2ScalingConfiguration: Lazy.any({\n        produce: () => {\n          if (this.hasServerlessInstance) {\n            return {\n              minCapacity: this.serverlessV2MinCapacity,\n              maxCapacity: this.serverlessV2MaxCapacity,\n              secondsUntilAutoPause: this.serverlessV2AutoPauseDuration?.toSeconds(),\n            } satisfies CfnDBCluster.ServerlessV2ScalingConfigurationProperty;\n          }\n          return undefined;\n        },\n      }),\n      storageType: props.storageType?.toString(),\n      enableLocalWriteForwarding: props.enableLocalWriteForwarding,\n      clusterScalabilityType: props.clusterScalabilityType ?? props.clusterScailabilityType,\n      // Admin\n      backtrackWindow: props.backtrackWindow?.toSeconds(),\n      backupRetentionPeriod: props.backup?.retention?.toDays(),\n      preferredBackupWindow: props.backup?.preferredWindow,\n      preferredMaintenanceWindow: props.preferredMaintenanceWindow,\n      databaseName: props.defaultDatabaseName,\n      enableCloudwatchLogsExports: props.cloudwatchLogsExports,\n      // Encryption\n      kmsKeyId: props.storageEncryptionKey?.keyRef.keyArn,\n      storageEncrypted: props.storageEncryptionKey ? true : props.storageEncrypted,\n      // Tags\n      copyTagsToSnapshot: props.copyTagsToSnapshot ?? true,\n      domain: this.domainId,\n      domainIamRoleName: this.domainRole?.roleName,\n      performanceInsightsEnabled: this.performanceInsightsEnabled || props.enablePerformanceInsights, // fall back to undefined if not set\n      performanceInsightsKmsKeyId: this.performanceInsightEncryptionKey?.keyArn,\n      performanceInsightsRetentionPeriod: this.performanceInsightRetention,\n      databaseInsightsMode: this.databaseInsightsMode,\n      autoMinorVersionUpgrade: props.autoMinorVersionUpgrade,\n      monitoringInterval: props.enableClusterLevelEnhancedMonitoring ? props.monitoringInterval?.toSeconds() : undefined,\n      monitoringRoleArn: props.enableClusterLevelEnhancedMonitoring ? this.monitoringRole?.roleArn : undefined,\n      engineLifecycleSupport: props.engineLifecycleSupport,\n      deleteAutomatedBackups: props.deleteAutomatedBackups,\n    };\n  }", "language": "typescript"}
{"input": "CDK class InlineWorkflowData for AWS resource management", "output": "class InlineWorkflowData extends WorkflowData {\n  protected readonly data: string;\n\n  public constructor(data: string) {\n    super();\n\n    this.data = data;\n  }\n\n  /**\n   * The rendered workflow data text, for use in CloudFormation\n   */\n  public render(): WorkflowDataConfig {\n    return { data: this.data };\n  }\n}", "language": "typescript"}
{"input": "CDK class KeyWithKMSEncryptionTypeTest for AWS resource management", "output": "class KeyWithKMSEncryptionTypeTest extends core.Stack {\n  public readonly tableBucket: s3tables.TableBucket;\n  public readonly key: kms.IKey;\n\n  constructor(scope: Construct, id: string, props?: core.StackProps) {\n    super(scope, id, props);\n    this.key = new kms.Key(this, 'Key', {});\n    this.tableBucket = new s3tables.TableBucket(this, id, {\n      tableBucketName: 'integ-tb-key-with-type',\n      account: props?.env?.account,\n      region: props?.env?.region,\n      encryption: s3tables.TableBucketEncryption.KMS,\n      encryptionKey: this.key,\n      removalPolicy: core.RemovalPolicy.DESTROY,\n    });\n  }\n\n  public validateAssertions(integ: IntegTest) {\n    const encryptionConfig = integ.assertions.awsApiCall('@aws-sdk/client-s3tables', 'GetTableBucketEncryptionCommand', {\n      tableBucketARN: this.tableBucket.tableBucketArn,\n    });\n\n    encryptionConfig.expect(ExpectedResult.objectLike({\n      encryptionConfiguration: {\n        sseAlgorithm: 'aws:kms',\n        kmsKeyArn: this.key.keyArn,\n      },\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedEventBus for AWS resource management", "output": "class ImportedEventBus extends EventBusBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-events.ImportedEventBus';\n  public readonly eventBusArn: string;\n  public readonly eventBusName: string;\n  public readonly eventBusPolicy: string;\n  public readonly eventSourceName?: string;\n\n  constructor(scope: Construct, id: string, attrs: EventBusAttributes) {\n    const arnParts = Stack.of(scope).splitArn(attrs.eventBusArn, ArnFormat.SLASH_RESOURCE_NAME);\n    super(scope, id, {\n      account: arnParts.account,\n      region: arnParts.region,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, attrs);\n\n    this.eventBusArn = attrs.eventBusArn;\n    this.eventBusName = attrs.eventBusName;\n    this.eventBusPolicy = attrs.eventBusPolicy;\n    this.eventSourceName = attrs.eventSourceName;\n  }\n\n  @MethodMetadata()\n  public addToResourcePolicy(_statement: iam.PolicyStatement): iam.AddToResourcePolicyResult {\n    // Warn the user\n    Annotations.of(this).addWarningV2(\n      '@aws-cdk/aws-events:eventBusAddToResourcePolicy',\n      `Unable to add necessary permissions to imported target event bus: ${this.eventBusArn}`,\n    );\n    return { statementAdded: false };\n  }\n}", "language": "typescript"}
{"input": "The destination type for the flow log", "output": "class FlowLogDestination {\n  /**\n   * Use CloudWatch logs as the destination\n   */\n  public static toCloudWatchLogs(logGroup?: logs.ILogGroupRef, iamRole?: iam.IRole): FlowLogDestination {\n    return new CloudWatchLogsDestination({\n      logDestinationType: FlowLogDestinationType.CLOUD_WATCH_LOGS,\n      logGroup,\n      iamRole,\n    });\n  }\n\n  /**\n   * Use S3 as the destination\n   *\n   * @param bucket optional s3 bucket to publish logs to. If one is not provided\n   * a default bucket will be created\n   * @param keyPrefix optional prefix within the bucket to write logs to\n   * @param options additional s3 destination options\n   */\n  public static toS3(bucket?: s3.IBucket, keyPrefix?: string, options?: S3DestinationOptions): FlowLogDestination {\n    return new S3Destination({\n      logDestinationType: FlowLogDestinationType.S3,\n      s3Bucket: bucket,\n      keyPrefix,\n      destinationOptions: options,\n    });\n  }\n\n  /**\n   * Use Amazon Data Firehose as the destination\n   *\n   * @param deliveryStreamArn the ARN of Amazon Data Firehose delivery stream to publish logs to\n   */\n  public static toKinesisDataFirehoseDestination(deliveryStreamArn: string): FlowLogDestination {\n    return new KinesisDataFirehoseDestination({\n      logDestinationType: FlowLogDestinationType.KINESIS_DATA_FIREHOSE,\n      deliveryStreamArn,\n    });\n  }\n\n  /**\n   * Generates a flow log destination configuration\n   */\n  public abstract bind(scope: Construct, flowLog: FlowLog): FlowLogDestinationConfig;\n}", "language": "typescript"}
{"input": "CDK Stack that creates Kinesis, CloudWatch Logs, CloudFormation resources", "output": "class SubscriptionFilterDistributionIntegStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const logGroup = new LogGroup(this, 'LogGroup');\n\n    const stream = new Stream(this, 'Stream');\n\n    logGroup.addSubscriptionFilter('Subscription', {\n      destination: new KinesisDestination(stream),\n      filterPattern: FilterPattern.allTerms('ERROR', 'MainThread'),\n      filterName: 'CustomSubscriptionFilterName',\n      distribution: Distribution.RANDOM,\n    });\n  }\n}", "language": "typescript"}
{"input": "Configuration for Lambda-based MCP targets This configuration wraps a Lambda function as MCP tools, allowing the gateway to invoke the function to provide tool capabilities.", "output": "export class LambdaTargetConfiguration extends McpTargetConfiguration {\n  /**\n   * Create a Lambda target configuration\n   *\n   * @param lambdaFunction The Lambda function to invoke\n   * @param toolSchema The schema defining the tools\n   * @returns A new LambdaTargetConfiguration instance\n   */\n  public static create(\n    lambdaFunction: IFunction,\n    toolSchema: ToolSchema,\n  ): LambdaTargetConfiguration {\n    return new LambdaTargetConfiguration(lambdaFunction, toolSchema);\n  }\n\n  public readonly targetType = McpTargetType.LAMBDA;\n\n  /**\n   * The Lambda function that implements the MCP server logic\n   */\n  public readonly lambdaFunction: IFunction;\n\n  /**\n   * The tool schema that defines the available tools\n   */\n  public readonly toolSchema: ToolSchema;\n\n  constructor(lambdaFunction: IFunction, toolSchema: ToolSchema) {\n    super();\n    this.lambdaFunction = lambdaFunction;\n    this.toolSchema = toolSchema;\n  }\n\n  /**\n   * Binds this configuration to a construct scope\n   * Sets up necessary permissions for the gateway to invoke the Lambda function\n   *\n   * @param scope The construct scope\n   * @param gateway The gateway that will use this target\n   */\n  public bind(scope: Construct, gateway: IGateway): TargetConfigurationConfig {\n    // Bind the tool schema\n    this.toolSchema.bind(scope);\n    // Grant permissions to gateway role\n    this.toolSchema.grantPermissionsToRole(gateway.role);\n    this.lambdaFunction.grantInvoke(gateway.role);\n\n    return { bound: true };\n  }\n\n  /**\n   * Renders the MCP-specific configuration\n   */\n  protected renderMcpConfiguration(): any {\n    return {\n      lambda: {\n        lambdaArn: this.lambdaFunction.functionArn,\n        toolSchema: this.toolSchema._render(),\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class UserPoolIdentityProviderGoogle for AWS resource management", "output": "export class UserPoolIdentityProviderGoogle extends UserPoolIdentityProviderBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-cognito.UserPoolIdentityProviderGoogle';\n  public readonly providerName: string;\n\n  constructor(scope: Construct, id: string, props: UserPoolIdentityProviderGoogleProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const scopes = props.scopes ?? ['profile'];\n\n    // at least one of the properties must be configured\n    if ((!props.clientSecret && !props.clientSecretValue) ||\n      (props.clientSecret && props.clientSecretValue)) {\n      throw new ValidationError('Exactly one of \"clientSecret\" or \"clientSecretValue\" must be configured.', this);\n    }\n\n    const resource = new CfnUserPoolIdentityProvider(this, 'Resource', {\n      userPoolId: props.userPool.userPoolRef.userPoolId,\n      providerName: 'Google', // must be 'Google' when the type is 'Google'\n      providerType: 'Google',\n      providerDetails: {\n        client_id: props.clientId,\n        client_secret: props.clientSecretValue ? props.clientSecretValue.unsafeUnwrap() : props.clientSecret,\n        authorize_scopes: scopes.join(' '),\n      },\n      attributeMapping: super.configureAttributeMapping(),\n    });\n\n    this.providerName = super.getResourceNameAttribute(resource.ref);\n    props.userPool.registerIdentityProvider(this);\n  }\n}", "language": "typescript"}
{"input": "Verify that all packages have a publishConfig with a publish tag set.", "output": "export class PublishConfigTagIsRequired extends ValidationRule {\n  public readonly name = 'package-info/publish-config-tag';\n\n  public validate(pkg: PackageJson): void {\n    if (pkg.json.private) { return; }\n\n    const defaultPublishTag = 'latest';\n\n    if (pkg.json.publishConfig?.tag !== defaultPublishTag) {\n      pkg.report({\n        ruleName: this.name,\n        message: `publishConfig.tag must be ${defaultPublishTag}`,\n        fix: (() => {\n          const publishConfig = pkg.json.publishConfig ?? {};\n          publishConfig.tag = defaultPublishTag;\n          pkg.json.publishConfig = publishConfig;\n        }),\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class ImportedBedrockAgentRuntimeEndpoint for AWS resource management", "output": "class ImportedBedrockAgentRuntimeEndpoint extends RuntimeEndpointBase {\n      public readonly agentRuntimeEndpointArn = attrs.agentRuntimeEndpointArn;\n      public readonly endpointName = attrs.endpointName;\n      public readonly agentRuntimeArn = attrs.agentRuntimeArn;\n      public readonly description = attrs.description;\n      public readonly status = attrs.status;\n      public readonly liveVersion = attrs.liveVersion;\n      public readonly targetVersion = attrs.targetVersion;\n      public readonly createdAt = attrs.createdAt;\n      public readonly endpointId = attrs.endpointId;\n      public readonly lastUpdatedAt = attrs.lastUpdatedAt;\n    }", "language": "typescript"}
{"input": "CDK class S3ModelData for AWS resource management", "output": "class S3ModelData extends ModelData {\n  constructor(private readonly bucket: s3.IBucket, private readonly objectKey: string) {\n    super();\n  }\n\n  public bind(_scope: Construct, model: IModel): ModelDataConfig {\n    this.bucket.grantRead(model);\n\n    return {\n      uri: this.bucket.urlForObject(this.objectKey),\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class ChatbotGuardrailsInteg for AWS resource management", "output": "class ChatbotGuardrailsInteg extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const guardrailPolicy = iam.ManagedPolicy.fromAwsManagedPolicyName('CloudWatchReadOnlyAccess');\n\n    new chatbot.SlackChannelConfiguration(this, 'MySlackChannel', {\n      slackChannelConfigurationName: 'test-channel',\n      slackWorkspaceId: 'T49239U4W', // modify to your slack workspace id\n      slackChannelId: 'C0187JABUE9', // modify to your slack channel id\n      guardrailPolicies: [guardrailPolicy],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation resources", "output": "class DataSyncS3toS3StackIAM(Stack):\n    \n    # Function to create IAM Role for Datasync\n    def create_datasync_roles(self, bucket_configs):\n        # Create a list of bucket paths ending in /* for IAM policy\n        suffix = \"/*\"\n        i=0\n        datasync_s3_roles = []\n\n        for bc in bucket_configs:\n            # Create an IAM Role for DataSync to read and write to S3 bucket\n            # Create an IAM role\n            \n            role_name=\"CDKDataSyncS3Access-\" + bc[\"bucketName\"]\n            s3_role = iam.Role(\n                self, \"CDKDataSyncS3AccessRole\"+str(i),\n                assumed_by=iam.ServicePrincipal(\"datasync.amazonaws.com\"),\n                description=\"CDK Datasync role for S3\",\n                role_name=role_name\n            )\n            \n            stmt1 = iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        actions=[\"s3:GetBucketLocation\", \"s3:ListBucket\",\"s3:ListBucketMultipartUploads\"],\n                        resources=[bc[\"arn\"]]\n                        )\n            \n            stmt2 = iam.PolicyStatement(\n                        effect=iam.Effect.ALLOW,\n                        actions=[\"s3:AbortMultipartUpload\", \"s3:DeleteObject\",\"s3:GetObject\",\"s3:ListMultipartUploadParts\",\"s3:PutObjectTagging\",\"s3:GetObjectTagging\",\"s3:PutObject\"],\n                        resources=[bc[\"arn\"]+suffix]\n                    )\n            \n            s3_policy = iam.ManagedPolicy(self,\"CDKDataSyncS3Policy\"+str(i), statements = [stmt1, stmt2], roles = [s3_role])\n\n            datasync_s3_roles.append(s3_role)\n            \n            # Export the name using the same format as the Role name\n            # This will be important by downstream Stack\n            CfnOutput(self, role_name, value=s3_role.role_arn, export_name=role_name)\n            \n            i = i+1\n        \n        return datasync_s3_roles\n    \n\n    # Main function\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n        \n        # Store bucket configs in an array\n        bucket_configs = self.node.try_get_context(\"S3_datasync_locations\")\n        if bucket_configs:\n            # Add the arn to bucket_config, if it is not provided already\n            for b in bucket_configs:\n                if not \"arn\" in b:\n                    b[\"arn\"] = \"arn:aws:s3:::\" + b[\"bucketName\"]\n        \n            self.create_datasync_roles(bucket_configs)        \n        else:\n            print(\"ERROR: Please set a context variable for S3_datasync_locations\")", "language": "python"}
{"input": "CDK class Proxy for AWS resource management", "output": "export class Proxy extends Construct {\n  public readonly api: apiGateway.RestApi;\n\n  constructor(scope: Construct, id: string, props: ProxyProps) {\n    super(scope, id);\n\n    this.api = new apiGateway.RestApi(this, \"API\", {\n      restApiName: props.apiName,\n      endpointConfiguration: {\n        types: [props.endpointType]\n      },\n    });\n  }\n\n  public addProxy(id: string, baseUrl: string, method: string = \"GET\") {\n    const namespace = this.api.root.addResource(id);\n    const proxyResource = new apiGateway.ProxyResource(this, `ProxyResource${method}${id}`, {\n      parent: namespace,\n      anyMethod: false,\n    });\n\n    proxyResource.addMethod(method, new apiGateway.HttpIntegration(`${baseUrl}/{proxy}`, {\n      proxy: true,\n      httpMethod: method,\n      options: {\n        requestParameters: {\n          \"integration.request.path.proxy\": \"method.request.path.proxy\"\n        }\n      }\n    }), {\n      requestParameters: {\n        \"method.request.path.proxy\": true\n      }\n    });\n\n    new CfnOutput(this, `EndPoint${method}${id}`, { value: this.api.urlForPath(proxyResource.path) });\n  }\n}", "language": "typescript"}
{"input": "CDK class HttpApi for AWS resource management", "output": "export class HttpApi extends HttpApiBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigatewayv2.HttpApi';\n\n  /**\n   * Import an existing HTTP API into this CDK app.\n   */\n  public static fromHttpApiAttributes(scope: Construct, id: string, attrs: HttpApiAttributes): IHttpApi {\n    class Import extends HttpApiBase {\n      public readonly apiId = attrs.httpApiId;\n      public readonly httpApiId = attrs.httpApiId;\n      private readonly _apiEndpoint = attrs.apiEndpoint;\n\n      public get apiEndpoint(): string {\n        if (!this._apiEndpoint) {\n          throw new ValidationError('apiEndpoint is not configured on the imported HttpApi.', scope);\n        }\n        return this._apiEndpoint;\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * A human friendly name for this HTTP API. Note that this is different from `httpApiId`.\n   */\n  public readonly httpApiName?: string;\n  public readonly apiId: string;\n\n  /**\n   * The identifier of the HTTP API.\n   * @see https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-apigatewayv2-api.html#aws-resource-apigatewayv2-api-return-values\n   */\n  public readonly httpApiId: string;\n\n  /**\n   * Specifies whether clients can invoke this HTTP API by using the default execute-api endpoint.\n   */\n  public readonly disableExecuteApiEndpoint?: boolean;\n\n  /**\n   * The default stage of this API\n   */\n  public readonly defaultStage: IHttpStage | undefined;\n\n  /**\n   * Default Authorizer applied to all routes in the gateway.\n   */\n  public readonly defaultAuthorizer?: IHttpRouteAuthorizer;\n\n  /**\n   * Default OIDC scopes attached to all routes in the gateway, unless explicitly configured on the route.\n   * The scopes are used with a COGNITO_USER_POOLS authorizer to authorize the method invocation.\n   */\n  public readonly defaultAuthorizationScopes?: string[];\n\n  private readonly _apiEndpoint: string;\n\n  constructor(scope: Construct, id: string, props?: HttpApiProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.httpApiName = props?.apiName ?? id;\n    this.disableExecuteApiEndpoint = props?.disableExecuteApiEndpoint;\n\n    let corsConfiguration: CfnApi.CorsProperty | undefined;\n    if (props?.corsPreflight) {\n      const cors = props.corsPreflight;\n      if (cors.allowOrigins && cors.allowOrigins.includes('*') && cors.allowCredentials) {\n        throw new ValidationError(\"CORS preflight - allowCredentials is not supported when allowOrigin is '*'\", scope);\n      }\n      const {\n        allowCredentials,\n        allowHeaders,\n        allowMethods,\n        allowOrigins,\n        exposeHeaders,\n        maxAge,\n      } = props.corsPreflight;\n      corsConfiguration = {\n        allowCredentials,\n        allowHeaders,\n        allowMethods,\n        allowOrigins,\n        exposeHeaders,\n        maxAge: maxAge?.toSeconds(),\n      };\n    }\n\n    const apiProps: CfnApiProps = {\n      name: this.httpApiName,\n      protocolType: 'HTTP',\n      corsConfiguration,\n      description: props?.description,\n      disableExecuteApiEndpoint: this.disableExecuteApiEndpoint,\n      routeSelectionExpression: props?.routeSelectionExpression ? '${request.method} ${request.path}' : undefined,\n      ipAddressType: props?.ipAddressType,\n    };\n\n    const resource = new CfnApi(this, 'Resource', apiProps);\n    this.apiId = resource.ref;\n    this.httpApiId = resource.ref;\n    this._apiEndpoint = resource.attrApiEndpoint;\n    this.defaultAuthorizer = props?.defaultAuthorizer;\n    this.defaultAuthorizationScopes = props?.defaultAuthorizationScopes;\n\n    if (props?.defaultIntegration) {\n      new HttpRoute(this, 'DefaultRoute', {\n        httpApi: this,\n        routeKey: HttpRouteKey.DEFAULT,\n        integration: props.defaultIntegration,\n        authorizer: props.defaultAuthorizer,\n        authorizationScopes: props.defaultAuthorizationScopes,\n      });\n    }\n\n    if (props?.createDefaultStage === undefined || props.createDefaultStage === true) {\n      this.defaultStage = new HttpStage(this, 'DefaultStage', {\n        httpApi: this,\n        autoDeploy: true,\n        domainMapping: props?.defaultDomainMapping,\n      });\n\n      // to ensure the domain is ready before creating the default stage\n      if (props?.defaultDomainMapping) {\n        this.defaultStage.node.addDependency(props.defaultDomainMapping.domainName);\n      }\n    }\n\n    if (props?.createDefaultStage === false && props.defaultDomainMapping) {\n      throw new ValidationError('defaultDomainMapping not supported with createDefaultStage disabled', scope);\n    }\n  }\n\n  /**\n   * Get the default endpoint for this API.\n   */\n  public get apiEndpoint(): string {\n    if (this.disableExecuteApiEndpoint) {\n      throw new ValidationError('apiEndpoint is not accessible when disableExecuteApiEndpoint is set to true.', this);\n    }\n    return this._apiEndpoint;\n  }\n\n  /**\n   * Get the URL to the default stage of this API.\n   * Returns `undefined` if `createDefaultStage` is unset.\n   */\n  public get url(): string | undefined {\n    return this.defaultStage ? this.defaultStage.url : undefined;\n  }\n\n  /**\n   * Add a new stage.\n   */\n  @MethodMetadata()\n  public addStage(id: string, options: HttpStageOptions): HttpStage {\n    const stage = new HttpStage(this, id, {\n      httpApi: this,\n      ...options,\n    });\n    return stage;\n  }\n\n  /**\n   * Add multiple routes that uses the same configuration. The routes all go to the same path, but for different\n   * methods.\n   */\n  @MethodMetadata()\n  public addRoutes(options: AddRoutesOptions): HttpRoute[] {\n    const methods = options.methods ?? [HttpMethod.ANY];\n    return methods.map((method) => {\n      const authorizationScopes = options.authorizationScopes ?? this.defaultAuthorizationScopes;\n\n      return new HttpRoute(this, `${method}${options.path}`, {\n        httpApi: this,\n        routeKey: HttpRouteKey.with(options.path, method),\n        integration: options.integration,\n        authorizer: options.authorizer ?? this.defaultAuthorizer,\n        authorizationScopes,\n      });\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, API Gateway, CloudFormation resources", "output": "class ApiCorsLambdaStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        base_lambda = _lambda.Function(self, 'ApiCorsLambda',\n                                       handler='lambda-handler.handler',\n                                       runtime=_lambda.Runtime.PYTHON_3_7,\n                                       code=_lambda.Code.from_asset('lambda'))\n\n        base_api = _apigw.RestApi(self, 'ApiGatewayWithCors',\n                                  rest_api_name='ApiGatewayWithCors')\n\n        example_entity = base_api.root.add_resource(\n            'example',\n            default_cors_preflight_options=_apigw.CorsOptions(\n                allow_methods=['GET', 'OPTIONS'],\n                allow_origins=_apigw.Cors.ALL_ORIGINS)\n        )\n        example_entity_lambda_integration = _apigw.LambdaIntegration(\n            base_lambda,\n            proxy=False,\n            integration_responses=[\n                _apigw.IntegrationResponse(\n                    status_code=\"200\",\n                    response_parameters={\n                        'method.response.header.Access-Control-Allow-Origin': \"'*'\"\n                    }\n                )\n            ]\n        )\n        example_entity.add_method(\n            'GET', example_entity_lambda_integration,\n            method_responses=[\n                _apigw.MethodResponse(\n                    status_code=\"200\",\n                    response_parameters={\n                        'method.response.header.Access-Control-Allow-Origin': True\n                    }\n                )\n            ]\n        )", "language": "python"}
{"input": "Function to get bucket ARN", "output": "def get_bucket_arn(self, config):\n        bucket_name = config[\"bucketName\"]\n        bucket_arn = \"\"\n        \n        if config[\"create\"]:\n           bucket = self.create_bucket(bucket_name)\n           bucket_arn = bucket.bucket_arn\n        else:\n           bucket_arn = \"arn:aws:s3:::\" + bucket_name\n        \n        return bucket_arn", "language": "python"}
{"input": "OAuth authorizer configuration", "output": "class OAuthAuthorizerConfiguration extends RuntimeAuthorizerConfiguration {\n  constructor(\n    private readonly discoveryUrl: string,\n    private readonly clientId: string,\n    private readonly allowedAudience?: string[],\n  ) {\n    super();\n  }\n\n  public _render(): CfnRuntime.AuthorizerConfigurationProperty {\n    // OAuth is also represented as JWT in CloudFormation\n    return {\n      customJwtAuthorizer: {\n        discoveryUrl: this.discoveryUrl,\n        allowedClients: [this.clientId],\n        allowedAudience: this.allowedAudience,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "The interface that various route integration classes will inherit.", "output": "class WebSocketRouteIntegration {\n  private integration?: WebSocketIntegration;\n\n  /**\n   * Initialize an integration for a route on websocket api.\n   * @param id id of the underlying `WebSocketIntegration` construct.\n   */\n  constructor(private readonly id: string) {}\n\n  /**\n   * Internal method called when binding this integration to the route.\n   * @internal\n   */\n  public _bindToRoute(options: WebSocketRouteIntegrationBindOptions): { readonly integrationId: string } {\n    if (this.integration && this.integration.webSocketApi.node.addr !== options.route.webSocketApi.node.addr) {\n      throw new ValidationError('A single integration cannot be associated with multiple APIs.', options.scope);\n    }\n\n    if (!this.integration) {\n      const config = this.bind(options);\n\n      this.integration = new WebSocketIntegration(options.scope, this.id, {\n        webSocketApi: options.route.webSocketApi,\n        integrationType: config.type,\n        integrationUri: config.uri,\n        integrationMethod: config.method,\n        contentHandling: config.contentHandling,\n        credentialsRole: config.credentialsRole,\n        requestTemplates: config.requestTemplates,\n        requestParameters: config.requestParameters,\n        timeout: config.timeout,\n        passthroughBehavior: config.passthroughBehavior,\n        templateSelectionExpression: config.templateSelectionExpression,\n      });\n    }\n\n    return { integrationId: this.integration.integrationId };\n  }\n\n  /**\n   * Bind this integration to the route.\n   */\n  public abstract bind(options: WebSocketRouteIntegrationBindOptions): WebSocketRouteIntegrationConfig;\n}", "language": "typescript"}
{"input": "Create an Aurora Serverless v1 Cluster @resource AWS::RDS::DBCluster", "output": "class ServerlessClusterNew extends ServerlessClusterBase {\n  public readonly connections: ec2.Connections;\n  protected readonly newCfnProps: CfnDBClusterProps;\n  protected readonly securityGroups: ec2.ISecurityGroup[];\n  protected enableDataApi?: boolean;\n\n  constructor(scope: Construct, id: string, props: ServerlessClusterNewProps) {\n    super(scope, id);\n\n    if (props.vpc === undefined) {\n      if (props.vpcSubnets !== undefined) {\n        throw new ValidationError('A VPC is required to use vpcSubnets in ServerlessCluster. Please add a VPC or remove vpcSubnets', this);\n      }\n      if (props.subnetGroup !== undefined) {\n        throw new ValidationError('A VPC is required to use subnetGroup in ServerlessCluster. Please add a VPC or remove subnetGroup', this);\n      }\n      if (props.securityGroups !== undefined) {\n        throw new ValidationError('A VPC is required to use securityGroups in ServerlessCluster. Please add a VPC or remove securityGroups', this);\n      }\n    }\n\n    let subnetGroup: ISubnetGroup | aws_rds.IDBSubnetGroupRef | undefined = props.subnetGroup;\n    this.securityGroups = props.securityGroups ?? [];\n    if (props.vpc !== undefined) {\n      const { subnetIds } = props.vpc.selectSubnets(props.vpcSubnets);\n\n      // Cannot test whether the subnets are in different AZs, but at least we can test the amount.\n      if (subnetIds.length < 2) {\n        Annotations.of(this).addError(`Cluster requires at least 2 subnets, got ${subnetIds.length}`);\n      }\n\n      subnetGroup = props.subnetGroup ?? new SubnetGroup(this, 'Subnets', {\n        description: `Subnets for ${id} database`,\n        vpc: props.vpc,\n        vpcSubnets: props.vpcSubnets,\n        removalPolicy: props.removalPolicy === RemovalPolicy.RETAIN ? props.removalPolicy : undefined,\n      });\n\n      this.securityGroups = props.securityGroups ?? [\n        new ec2.SecurityGroup(this, 'SecurityGroup', {\n          description: 'RDS security group',\n          vpc: props.vpc,\n        }),\n      ];\n    }\n\n    if (props.backupRetention) {\n      const backupRetentionDays = props.backupRetention.toDays();\n      if (backupRetentionDays < 1 || backupRetentionDays > 35) {\n        throw new ValidationError(`backup retention period must be between 1 and 35 days. received: ${backupRetentionDays}`, this);\n      }\n    }\n\n    // bind the engine to the Cluster\n    const clusterEngineBindConfig = props.engine.bindToCluster(this, {\n      parameterGroup: props.parameterGroup,\n    });\n    const clusterParameterGroup = props.parameterGroup ?? clusterEngineBindConfig.parameterGroup;\n    const clusterParameterGroupConfig = clusterParameterGroup?.bindToCluster({});\n\n    const clusterIdentifier = FeatureFlags.of(this).isEnabled(cxapi.RDS_LOWERCASE_DB_IDENTIFIER)\n      ? props.clusterIdentifier?.toLowerCase()\n      : props.clusterIdentifier;\n\n    this.newCfnProps = {\n      backupRetentionPeriod: props.backupRetention?.toDays(),\n      databaseName: props.defaultDatabaseName,\n      dbClusterIdentifier: clusterIdentifier,\n      dbClusterParameterGroupName: clusterParameterGroupConfig?.parameterGroupName,\n      dbSubnetGroupName: subnetGroup?.dbSubnetGroupRef.dbSubnetGroupName,\n      deletionProtection: defaultDeletionProtection(props.deletionProtection, props.removalPolicy),\n      engine: props.engine.engineType,\n      engineVersion: props.engine.engineVersion?.fullVersion,\n      engineMode: 'serverless',\n      enableHttpEndpoint: Lazy.any({ produce: () => this.enableDataApi }),\n      scalingConfiguration: props.scaling ? this.renderScalingConfiguration(props.scaling) : undefined,\n      storageEncrypted: true,\n      vpcSecurityGroupIds: this.securityGroups.map(sg => sg.securityGroupId),\n      copyTagsToSnapshot: props.copyTagsToSnapshot ?? true,\n    };\n\n    this.connections = new ec2.Connections({\n      securityGroups: this.securityGroups,\n      defaultPort: ec2.Port.tcp(Lazy.number({ produce: () => this.clusterEndpoint.port })),\n    });\n  }\n\n  private renderScalingConfiguration(options: ServerlessScalingOptions): CfnDBCluster.ScalingConfigurationProperty {\n    const minCapacity = options.minCapacity;\n    const maxCapacity = options.maxCapacity;\n    const timeout = options.timeout?.toSeconds();\n\n    if (minCapacity && maxCapacity && minCapacity > maxCapacity) {\n      throw new ValidationError('maximum capacity must be greater than or equal to minimum capacity.', this);\n    }\n\n    const secondsToAutoPause = options.autoPause?.toSeconds();\n    if (secondsToAutoPause && (secondsToAutoPause < 300 || secondsToAutoPause > 86400)) {\n      throw new ValidationError('auto pause time must be between 5 minutes and 1 day.', this);\n    }\n\n    if (timeout && (timeout < 60 || timeout > 600)) {\n      throw new ValidationError(`timeout must be between 60 and 600 seconds, but got ${timeout} seconds.`, this);\n    }\n\n    return {\n      autoPause: (secondsToAutoPause === 0) ? false : true,\n      minCapacity: options.minCapacity,\n      maxCapacity: options.maxCapacity,\n      secondsUntilAutoPause: (secondsToAutoPause === 0) ? undefined : secondsToAutoPause,\n      secondsBeforeTimeout: timeout,\n      timeoutAction: options.timeoutAction,\n    };\n  }\n}", "language": "typescript"}
{"input": "Same as TypeDefinitionStruct, but all props are optional.", "output": "export class PartialTypeDefinitionStruct extends TypeDefinitionStruct {\n  /**\n   * Change property spec to make every prop optional.\n   */\n  public addProperty(prop: PropertySpec) {\n    return super.addProperty({\n      ...prop,\n      optional: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class GoFunction for AWS resource management", "output": "export class GoFunction extends lambda.Function {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-lambda-go-alpha.GoFunction';\n  /**\n   * The address of the Google Go proxy\n   */\n  public static readonly GOOGLE_GOPROXY = 'https://proxy.golang.org';\n\n  constructor(scope: Construct, id: string, props: GoFunctionProps) {\n    if (props.runtime && (props.runtime.family !== lambda.RuntimeFamily.GO && props.runtime.family != lambda.RuntimeFamily.OTHER)) {\n      throw new Error('Only `go` and `provided` runtimes are supported.');\n    }\n\n    const entry = path.resolve(props.entry);\n\n    // Find the project root\n    let moduleDir: string;\n    if (props.moduleDir) {\n      const parsedModuleDir = path.parse(props.moduleDir);\n      if (parsedModuleDir.base && parsedModuleDir.ext && parsedModuleDir.base === 'go.mod') {\n        if (!fs.existsSync(props.moduleDir)) {\n          throw new Error(`go.mod file at ${props.moduleDir} doesn't exist`);\n        }\n      } else if (parsedModuleDir.base && parsedModuleDir.ext && parsedModuleDir.base != 'go.mod') {\n        throw new Error('moduleDir is specifying a file that is not go.mod');\n      } else if (!fs.existsSync(path.join(props.moduleDir, 'go.mod'))) {\n        throw new Error(`go.mod file at ${props.moduleDir} doesn't exist`);\n      }\n      moduleDir = props.moduleDir;\n    } else {\n      const modFile = findUp('go.mod', entry);\n      if (!modFile) {\n        throw new Error ('Cannot find go.mod. Please specify it with `moduleDir`.');\n      }\n      moduleDir = modFile;\n    }\n\n    const runtime = props.runtime ?? lambda.Runtime.PROVIDED_AL2;\n    const architecture = props.architecture ?? lambda.Architecture.X86_64;\n\n    // Security warnings for potentially unsafe bundling options\n    if (props.bundling?.goBuildFlags?.length) {\n      cdk.Annotations.of(scope).addWarningV2(\n        '@aws-cdk/aws-lambda-go-alpha:goBuildFlagsSecurityWarning',\n        'goBuildFlags can execute arbitrary commands during bundling. Ensure all flags come from trusted sources. See: https://docs.aws.amazon.com/cdk/latest/guide/security.html',\n      );\n    }\n\n    if (props.bundling?.commandHooks?.beforeBundling || props.bundling?.commandHooks?.afterBundling) {\n      cdk.Annotations.of(scope).addWarningV2(\n        '@aws-cdk/aws-lambda-go-alpha:commandHooksSecurityWarning',\n        'commandHooks can execute arbitrary commands during bundling. Ensure all commands come from trusted sources. See: https://docs.aws.amazon.com/cdk/latest/guide/security.html',\n      );\n    }\n\n    super(scope, id, {\n      ...props,\n      runtime,\n      code: Bundling.bundle({\n        ...props.bundling ?? {},\n        entry,\n        runtime,\n        architecture,\n        moduleDir,\n      }),\n      handler: 'bootstrap', // setting name to bootstrap so that the 'provided' runtime can also be used\n    });\n\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "Represents a trigger schedule.", "output": "export class TriggerSchedule {\n  /**\n   * Creates a new TriggerSchedule instance with a cron expression.\n   *\n   * @param options The cron options for the schedule.\n   * @returns A new TriggerSchedule instance.\n   */\n  public static cron(options: events.CronOptions): TriggerSchedule {\n    return new TriggerSchedule(events.Schedule.cron(options).expressionString);\n  }\n\n  /**\n   * Creates a new TriggerSchedule instance with a custom expression.\n   *\n   * @param expression The custom expression for the schedule.\n   * @returns A new TriggerSchedule instance.\n   */\n  public static expression(expression: string): TriggerSchedule {\n    return new TriggerSchedule(expression);\n  }\n\n  /**\n   * @param expressionString The expression string for the schedule.\n   */\n  private constructor(public readonly expressionString: string) {}\n}", "language": "typescript"}
{"input": "CDK class Test for AWS resource management", "output": "class Test extends cdk.Stack {\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const testFormat = apigateway.AccessLogFormat.custom(JSON.stringify({\n      requestId: apigateway.AccessLogField.contextRequestId(),\n      sourceIp: apigateway.AccessLogField.contextIdentitySourceIp(),\n      method: apigateway.AccessLogField.contextHttpMethod(),\n      callerAccountId: apigateway.AccessLogField.contextCallerAccountId(),\n      ownerAccountId: apigateway.AccessLogField.contextOwnerAccountId(),\n      userContext: {\n        sub: apigateway.AccessLogField.contextAuthorizerClaims('sub'),\n        email: apigateway.AccessLogField.contextAuthorizerClaims('email'),\n      },\n      clientCertPem: apigateway.AccessLogField.contextIdentityClientCertPem(),\n      subjectDN: apigateway.AccessLogField.contextIdentityClientCertSubjectDN(),\n      issunerDN: apigateway.AccessLogField.contextIdentityClientCertIssunerDN(),\n      serialNumber: apigateway.AccessLogField.contextIdentityClientCertSerialNumber(),\n      validityNotBefore: apigateway.AccessLogField.contextIdentityClientCertValidityNotBefore(),\n      validityNotAfter: apigateway.AccessLogField.contextIdentityClientCertValidityNotAfter(),\n    }));\n\n    const logGroup = new logs.LogGroup(this, 'MyLogGroup');\n    const api = new apigateway.RestApi(this, 'MyApi', {\n      cloudWatchRole: true,\n      deployOptions: {\n        accessLogDestination: new apigateway.LogGroupLogDestination(logGroup),\n        accessLogFormat: testFormat,\n      },\n    });\n    api.root.addMethod('GET');\n  }\n}", "language": "typescript"}
{"input": "Viewer certificate configuration class", "output": "export class ViewerCertificate {\n  /**\n   * Generate an AWS Certificate Manager (ACM) viewer certificate configuration\n   *\n   * @param certificate AWS Certificate Manager (ACM) certificate.\n   *                    Your certificate must be located in the us-east-1 (US East (N. Virginia)) region to be accessed by CloudFront\n   * @param options certificate configuration options\n   */\n  public static fromAcmCertificate(certificate: ICertificateRef, options: ViewerCertificateOptions = {}) {\n    const {\n      sslMethod: sslSupportMethod = SSLMethod.SNI,\n      securityPolicy: minimumProtocolVersion,\n      aliases,\n    } = options;\n\n    return new ViewerCertificate({\n      acmCertificateArn: certificate.certificateRef.certificateId, sslSupportMethod, minimumProtocolVersion,\n    }, aliases);\n  }\n\n  /**\n   * Generate an IAM viewer certificate configuration\n   *\n   * @param iamCertificateId Identifier of the IAM certificate\n   * @param options certificate configuration options\n   */\n  public static fromIamCertificate(iamCertificateId: string, options: ViewerCertificateOptions = {}) {\n    const {\n      sslMethod: sslSupportMethod = SSLMethod.SNI,\n      securityPolicy: minimumProtocolVersion,\n      aliases,\n    } = options;\n\n    return new ViewerCertificate({\n      iamCertificateId, sslSupportMethod, minimumProtocolVersion,\n    }, aliases);\n  }\n\n  /**\n   * Generate a viewer certificate configuration using\n   * the CloudFront default certificate (e.g. d111111abcdef8.cloudfront.net)\n   * and a `SecurityPolicyProtocol.TLS_V1` security policy.\n   *\n   * @param aliases Alternative CNAME aliases\n   *                You also must create a CNAME record with your DNS service to route queries\n   */\n  public static fromCloudFrontDefaultCertificate(...aliases: string[]) {\n    return new ViewerCertificate({ cloudFrontDefaultCertificate: true }, aliases);\n  }\n\n  private constructor(\n    public readonly props: CfnDistribution.ViewerCertificateProperty,\n    public readonly aliases: string[] = []) { }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, CloudFormation, CodeBuild resources", "output": "class FleetStack extends cdk.Stack {\n  public readonly fleet: codebuild.Fleet;\n  public readonly project: codebuild.Project;\n\n  constructor(scope: Construct, id: string, { computeConfiguration, vpcProps, subnetSelection, securityGroupProps }: StackConfiguration) {\n    super(scope, id);\n\n    let vpc: ec2.Vpc | undefined;\n    let securityGroups: Array<ec2.SecurityGroup> | undefined;\n    if (vpcProps) {\n      vpc = new ec2.Vpc(this, 'Vpc', vpcProps);\n      const refinedVpc = vpc;\n      securityGroups = securityGroupProps?.map((props, i) =>\n        new ec2.SecurityGroup(this, `SecurityGroup${i}`, { ...props, vpc: refinedVpc }),\n      );\n    }\n\n    this.fleet = new codebuild.Fleet(this, 'MyFleet', {\n      baseCapacity: 1,\n      computeType: codebuild.FleetComputeType.ATTRIBUTE_BASED,\n      computeConfiguration,\n      environmentType: codebuild.EnvironmentType.LINUX_CONTAINER,\n      vpc,\n      securityGroups,\n      subnetSelection,\n    });\n\n    this.project = new codebuild.Project(this, 'MyProject', {\n      buildSpec: codebuild.BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: { commands: ['echo \"Nothing to do!\"'] },\n        },\n      }),\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.STANDARD_7_0,\n        fleet: this.fleet,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Stack verification steps: * aws docdb describe-db-clusters --db-cluster-identifier <deployed db cluster identifier>", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: constructs.Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'VPC', { maxAzs: 2, restrictDefaultSecurityGroup: false });\n\n    const params = new ClusterParameterGroup(this, 'Params', {\n      family: 'docdb3.6',\n      description: 'A nice parameter group',\n      parameters: {\n        audit_logs: 'disabled',\n        tls: 'enabled',\n        ttl_monitor: 'enabled',\n      },\n    });\n\n    const kmsKey = new kms.Key(this, 'DbSecurity', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const cluster = new DatabaseCluster(this, 'Database', {\n      engineVersion: '3.6.0',\n      masterUser: {\n        username: 'docdb',\n        password: cdk.SecretValue.unsafePlainText('7959866cacc02c2d243ecfe177464fe6'),\n      },\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.R5, ec2.InstanceSize.LARGE),\n      vpcSubnets: { subnetType: ec2.SubnetType.PUBLIC },\n      vpc,\n      parameterGroup: params,\n      kmsKey,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      enablePerformanceInsights: true,\n    });\n\n    cluster.connections.allowDefaultPortFromAnyIpv4('Open to the world');\n  }\n}", "language": "typescript"}
{"input": "Asset manifest is a description of a set of assets which need to be built and published", "output": "export class AssetManifestArtifact extends CloudArtifact {\n  /**\n   * Checks if `art` is an instance of this class.\n   *\n   * Use this method instead of `instanceof` to properly detect `AssetManifestArtifact`\n   * instances, even when the construct library is symlinked.\n   *\n   * Explanation: in JavaScript, multiple copies of the `cx-api` library on\n   * disk are seen as independent, completely different libraries. As a\n   * consequence, the class `AssetManifestArtifact` in each copy of the `cx-api` library\n   * is seen as a different class, and an instance of one class will not test as\n   * `instanceof` the other class. `npm install` will not create installations\n   * like this, but users may manually symlink construct libraries together or\n   * use a monorepo tool: in those cases, multiple copies of the `cx-api`\n   * library can be accidentally installed, and `instanceof` will behave\n   * unpredictably. It is safest to avoid using `instanceof`, and using\n   * this type-testing method instead.\n   */\n  public static isAssetManifestArtifact(this: void, art: any): art is AssetManifestArtifact {\n    return art && typeof art === 'object' && art[ASSET_MANIFEST_ARTIFACT_SYM];\n  }\n\n  /**\n   * The file name of the asset manifest\n   */\n  public readonly file: string;\n\n  /**\n   * Version of bootstrap stack required to deploy this stack\n   */\n  public readonly requiresBootstrapStackVersion: number | undefined;\n\n  /**\n   * Name of SSM parameter with bootstrap stack version\n   *\n   * @default - Discover SSM parameter by reading stack\n   */\n  public readonly bootstrapStackVersionSsmParameter?: string;\n\n  private _contents?: cxschema.AssetManifest;\n\n  constructor(assembly: CloudAssembly, name: string, artifact: cxschema.ArtifactManifest) {\n    super(assembly, name, artifact);\n\n    const properties = (this.manifest.properties || {}) as cxschema.AssetManifestProperties;\n    if (!properties.file) {\n      throw new CloudAssemblyError('Invalid AssetManifestArtifact. Missing \"file\" property');\n    }\n    this.file = path.resolve(this.assembly.directory, properties.file);\n    this.requiresBootstrapStackVersion = properties.requiresBootstrapStackVersion;\n    this.bootstrapStackVersionSsmParameter = properties.bootstrapStackVersionSsmParameter;\n  }\n\n  /**\n   * The Asset Manifest contents\n   */\n  public get contents(): cxschema.AssetManifest {\n    if (this._contents !== undefined) {\n      return this._contents;\n    }\n\n    const contents = this._contents = JSON.parse(fs.readFileSync(this.file, 'utf-8'));\n    return contents;\n  }\n}", "language": "typescript"}
{"input": "CDK class AssetSingletonRole for AWS resource management", "output": "export class AssetSingletonRole extends iam.Role {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.pipelines.AssetSingletonRole';\n  private _rejectDuplicates = false;\n  private _assumeRoleStatement: iam.PolicyStatement | undefined;\n\n  constructor(scope: Construct, id: string, props: iam.RoleProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Logging permissions\n    this.addToPolicy(new iam.PolicyStatement({\n      resources: [Stack.of(this).formatArn({\n        service: 'logs',\n        resource: 'log-group',\n        arnFormat: ArnFormat.COLON_RESOURCE_NAME,\n        resourceName: '/aws/codebuild/*',\n      })],\n      actions: ['logs:CreateLogGroup', 'logs:CreateLogStream', 'logs:PutLogEvents'],\n    }));\n\n    // CodeBuild report groups\n    this.addToPolicy(new iam.PolicyStatement({\n      actions: [\n        'codebuild:CreateReportGroup',\n        'codebuild:CreateReport',\n        'codebuild:UpdateReport',\n        'codebuild:BatchPutTestCases',\n        'codebuild:BatchPutCodeCoverages',\n      ],\n      resources: [Stack.of(this).formatArn({\n        service: 'codebuild',\n        resource: 'report-group',\n        resourceName: '*',\n      })],\n    }));\n\n    // CodeBuild start/stop\n    this.addToPolicy(new iam.PolicyStatement({\n      resources: ['*'],\n      actions: [\n        'codebuild:BatchGetBuilds',\n        'codebuild:StartBuild',\n        'codebuild:StopBuild',\n      ],\n    }));\n\n    this._rejectDuplicates = true;\n  }\n\n  @MethodMetadata()\n  public addToPrincipalPolicy(statement: PolicyStatement): iam.AddToPrincipalPolicyResult {\n    const json = statement.toStatementJson();\n    const acts = JSON.stringify(json.Action);\n\n    // These have already been added with wildcard resources on creation\n    const alreadyAdded = [\n      '[\"logs:CreateLogGroup\",\"logs:CreateLogStream\",\"logs:PutLogEvents\"]',\n      '[\"codebuild:CreateReportGroup\",\"codebuild:CreateReport\",\"codebuild:UpdateReport\",\"codebuild:BatchPutTestCases\",\"codebuild:BatchPutCodeCoverages\"]',\n      '[\"codebuild:BatchGetBuilds\",\"codebuild:StartBuild\",\"codebuild:StopBuild\"]',\n    ];\n\n    if (this._rejectDuplicates && alreadyAdded.includes(acts)) {\n      // Pretend we did it\n      return { statementAdded: true, policyDependable: new class implements IDependable { } };\n    }\n\n    // These are added in duplicate (specifically these come from\n    // Project#bindToCodePipeline) -- the original singleton asset role didn't\n    // have these, and they're not necessary either, so in order to not cause\n    // unnecessary diffs, recognize and drop them there as well.\n    if (acts === '[\"kms:Decrypt\",\"kms:Encrypt\",\"kms:ReEncrypt*\",\"kms:GenerateDataKey*\"]') {\n      // Pretend we did it\n      return { statementAdded: true, policyDependable: new class implements IDependable { } };\n    }\n\n    return super.addToPrincipalPolicy(statement);\n  }\n\n  /**\n   * Make sure the Role has sts:AssumeRole permissions to the given ARN\n   *\n   * Will add a new PolicyStatement to the Role if necessary, otherwise add resources to the existing\n   * PolicyStatement.\n   *\n   * Normally this would have been many `grantAssume()` calls (which would get deduplicated by the\n   * policy minimization logic), but we have to account for old pipelines that don't have policy\n   * minimization enabled.\n   */\n  @MethodMetadata()\n  public addAssumeRole(roleArn: string) {\n    if (!this._assumeRoleStatement) {\n      this._assumeRoleStatement = new iam.PolicyStatement({\n        actions: ['sts:AssumeRole'],\n      });\n\n      this.addToPrincipalPolicy(this._assumeRoleStatement);\n    }\n\n    // Chunk into multiple statements to facilitate overflowing into overflow policies.\n    // Ideally we would do one ARN per statement and have policy minimization do its job, but that would make\n    // the situation A LOT worse if minimization is not enabled (which it isn't by default). So find a middle\n    // ground in pre-minimization chunking: reduce overhead while still allowing splitting.\n    const MAX_ARNS_PER_STATEMENT = 10;\n\n    this._assumeRoleStatement.addResources(roleArn);\n    if (this._assumeRoleStatement.resources.length >= MAX_ARNS_PER_STATEMENT) {\n      // Next call to this function will create a new statement\n      this._assumeRoleStatement = undefined;\n    }\n  }", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, API Gateway, CloudFormation resources", "output": "export class lambdaApiStack extends cdk.Stack {\n    constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n        super(scope, id, props);\n\n        //  create a lambda function\n        const lambdaFunction = new Function(this, 'lambdaFunction', {\n            runtime: Runtime.NODEJS_20_X,\n            handler: 'index.handler',\n            code: new InlineCode(`exports.handler = async (event) => {\n    const response = {\n        statusCode: 200,\n        body: JSON.stringify('Hello from Lambda!'),\n    };\n    return response;\n};`)\n        });\n\n        // create an API Gateway\n        const api = new LambdaRestApi(this, 'ApiGateway', {\n            handler: lambdaFunction,\n            proxy: false,\n        });\n\n        // connect the lambda function to API Gateway\n        api.root.addMethod(\"GET\");\n\n    }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, DynamoDB resources", "output": "class ServerlessBackendStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n        bucket_name = _cfnParameter(self, \"uploadBucketName\", type=\"String\",\n                                    description=\"The name of the Amazon S3 bucket where uploaded images will be stored.\")\n        user_pool = _cognito.UserPool(self, \"UserPool\")\n        user_pool.add_client(\"app-client\", auth_flows=_cognito.AuthFlow(\n            user_password=True\n        ),\n            supported_identity_providers=[\n                _cognito.UserPoolClientIdentityProvider.COGNITO]\n        )\n        auth = _apigateway.CognitoUserPoolsAuthorizer(self, \"imagesAuthorizer\",\n                                                      cognito_user_pools=[\n                                                          user_pool]\n                                                      )\n        my_table = _dynamodb.Table(self, id='dynamoTable', table_name='formmetadata', partition_key=_dynamodb.Attribute(\n            name='userid', type=_dynamodb.AttributeType.STRING)) #change primary key here\n        my_bucket = _s3.Bucket(self, id='s3bucket',\n                               bucket_name=bucket_name.value_as_string)\n        my_lambda = _lambda.Function(self, id='lambdafunction', function_name=\"formlambda\", runtime=_lambda.Runtime.PYTHON_3_7,\n                                     handler='index.handler',\n                                     code=_lambda.Code.from_asset(\n                                         os.path.join(\"./\", \"lambda-handler\")),\n                                     environment={\n                                         'bucket': my_bucket.bucket_name,\n                                         'table': my_table.table_name\n                                     }\n                                     )\n        my_bucket.grant_read_write(my_lambda)\n        my_table.grant_read_write_data(my_lambda)\n        my_api = _apigateway.LambdaRestApi(\n            self, id='lambdaapi', rest_api_name='formapi', handler=my_lambda, proxy=True)\n        postData = my_api.root.add_resource(\"form\")\n        postData.add_method(\"POST\", authorizer=auth,\n                          authorization_type=_apigateway.AuthorizationType.COGNITO)  # POST images/files & metadata", "language": "python"}
{"input": "CDK class ServiceConnect for AWS resource management", "output": "class ServiceConnect extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n    const cluster = new ecs.Cluster(this, 'EcsCluster', {\n      defaultCloudMapNamespace: {\n        name: 'scorekeep.com',\n        useForServiceConnect: true,\n      },\n    });\n\n    const td = new ecs.FargateTaskDefinition(this, 'TaskDef', {\n      cpu: 1024,\n      memoryLimitMiB: 2048,\n    });\n\n    td.addContainer('container', {\n      containerName: 'web',\n      image: ecs.ContainerImage.fromRegistry('amazon/amazon-ecs-sample'),\n      portMappings: [\n        {\n          name: 'api',\n          containerPort: 80,\n          appProtocol: ecs.AppProtocol.http2,\n        },\n      ],\n      logging: ecs.LogDrivers.awsLogs({\n        streamPrefix: 'web',\n      }),\n    });\n\n    new ecs.FargateService(this, 'svc', {\n      taskDefinition: td,\n      cluster,\n      serviceConnectConfiguration: {\n        services: [\n          {\n            portMappingName: 'api',\n            dnsName: 'api',\n            port: 80,\n          },\n        ],\n        logDriver: ecs.LogDrivers.awsLogs({\n          streamPrefix: 'sc',\n        }),\n      },\n    });\n\n    const ns = new cloudmap.HttpNamespace(this, 'ns', {\n      name: 'whistler.com',\n    });\n\n    const svc2 = new ecs.FargateService(this, 'svc-two', {\n      taskDefinition: td,\n      cluster,\n    });\n\n    svc2.node.addDependency(ns);\n\n    svc2.enableServiceConnect({\n      services: [\n        {\n          portMappingName: 'api',\n          dnsName: 'api',\n          port: 80,\n          idleTimeout: cdk.Duration.seconds(30),\n          perRequestTimeout: cdk.Duration.seconds(30),\n        },\n      ],\n      namespace: ns.namespaceArn,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class CognitoProtectedApi for AWS resource management", "output": "export class CognitoProtectedApi extends Stack {\n  constructor(app: App, id: string) {\n    super(app, id);\n\n    // Function that returns 201 with \"Hello world!\"\n    const helloWorldFunction = new Function(this, 'helloWorldFunction', {\n      code: new AssetCode('src'),\n      handler: 'helloworld.handler',\n      runtime: Runtime.NODEJS_18_X\n    });\n\n    // Rest API backed by the helloWorldFunction\n    const helloWorldLambdaRestApi = new LambdaRestApi(this, 'helloWorldLambdaRestApi', {\n      restApiName: 'Hello World API',\n      handler: helloWorldFunction,\n      proxy: false,\n    });\n\n    // Cognito User Pool with Email Sign-in Type.\n    const userPool = new UserPool(this, 'userPool', {\n      signInAliases: {\n        email: true\n      }\n    })\n\n    // Authorizer for the Hello World API that uses the\n    // Cognito User pool to Authorize users.\n    const authorizer = new CfnAuthorizer(this, 'cfnAuth', {\n      restApiId: helloWorldLambdaRestApi.restApiId,\n      name: 'HelloWorldAPIAuthorizer',\n      type: 'COGNITO_USER_POOLS',\n      identitySource: 'method.request.header.Authorization',\n      providerArns: [userPool.userPoolArn],\n    })\n\n    // Hello Resource API for the REST API. \n    const hello = helloWorldLambdaRestApi.root.addResource('HELLO');\n\n    // GET method for the HELLO API resource. It uses Cognito for\n    // authorization and the auathorizer defined above.\n    hello.addMethod('GET', new LambdaIntegration(helloWorldFunction), {\n      authorizationType: AuthorizationType.COGNITO,\n      authorizer: {\n        authorizerId: authorizer.ref\n      }\n      \n    })\n    \n  }\n}", "language": "typescript"}
{"input": "A Node.js Lambda function bundled using esbuild", "output": "export class NodejsFunction extends lambda.Function {\n  constructor(scope: Construct, id: string, props: NodejsFunctionProps = {}) {\n    if (props.runtime && props.runtime.family !== lambda.RuntimeFamily.NODEJS) {\n      throw new ValidationError('Only `NODEJS` runtimes are supported.', scope);\n    }\n\n    const runtime = getRuntime(scope, props);\n\n    if (props.code !== undefined) {\n      if (props.handler === undefined) {\n        throw new ValidationError(\n          'Cannot determine handler when `code` property is specified. Use `handler` property to specify a handler.\\n'\n          + 'The handler should be the name of the exported function to be invoked and the file containing that function.\\n'\n          + 'For example, handler should be specified in the form `myFile.myFunction`', scope,\n        );\n      }\n\n      super(scope, id, {\n        ...props,\n        runtime,\n        code: props.code,\n        handler: props.handler,\n      });\n    } else {\n      // Entry and defaults\n      const entry = path.resolve(findEntry(scope, id, props.entry));\n      const architecture = props.architecture ?? Architecture.X86_64;\n      const depsLockFilePath = findLockFile(scope, props.depsLockFilePath);\n      const projectRoot = props.projectRoot ?? path.dirname(depsLockFilePath);\n      const handler = props.handler ?? 'handler';\n\n      super(scope, id, {\n        ...props,\n        runtime,\n        code: Bundling.bundle(scope, {\n          ...props.bundling ?? {},\n          entry,\n          runtime,\n          architecture,\n          depsLockFilePath,\n          projectRoot,\n        }),\n        handler: handler.indexOf('.') !== -1 ? `${handler}` : `index.${handler}`,\n      });\n    }\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Enable connection reuse for aws-sdk v2, do not set for sdk v3\n    if (isSdkV2Runtime(runtime)) {\n      if (props.awsSdkConnectionReuse ?? true) {\n        this.addEnvironment('AWS_NODEJS_CONNECTION_REUSE_ENABLED', '1', { removeInEdge: true });\n      }\n    } else {\n      if (props.awsSdkConnectionReuse) {\n        Annotations.of(scope).addWarningV2('aws-cdk-lib/aws-lambda-nodejs:unusedSdkEvironmentVariable', 'The AWS_NODEJS_CONNECTION_REUSE_ENABLED environment variable does not exist in SDK v3. You have explicitly set `awsSdkConnectionReuse`; please make sure this is intentional.');\n        this.addEnvironment('AWS_NODEJS_CONNECTION_REUSE_ENABLED', '1', { removeInEdge: true });\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class S3FileProvider for AWS resource management", "output": "class S3FileProvider extends Construct {\n  /**\n   * Returns the singleton provider.\n   */\n  public static getOrCreate(scope: Construct) {\n    const stack = Stack.of(scope);\n    const id = 'com.amazonaws.cdk.custom-resources.s3file-provider';\n    const x = Node.of(stack).tryFindChild(id) as S3FileProvider || new S3FileProvider(stack, id);\n    return x.provider.serviceToken;\n  }\n\n  private readonly provider: cr.Provider;\n\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    this.provider = new cr.Provider(this, 's3file-provider', {\n      onEventHandler: new lambda.Function(this, 's3file-on-event', {\n        code: lambda.Code.fromAsset(path.join(__dirname, 's3-file-handler'), { exclude: ['*.ts'] }),\n        runtime: STANDARD_NODEJS_RUNTIME,\n        handler: 'index.onEvent',\n        initialPolicy: [\n          new iam.PolicyStatement({\n            resources: ['*'],\n            actions: [\n              's3:GetObject*',\n              's3:GetBucket*',\n              's3:List*',\n              's3:DeleteObject*',\n              's3:PutObject*',\n              's3:Abort*',\n            ],\n          }),\n        ],\n      }),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, Kinesis operations", "output": "def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        with open(\"lambda-handler.py\", encoding=\"utf8\") as fp:\n            handler_code = fp.read()\n\n        # Creates reference to already existing kinesis stream\n        kinesis_stream = kinesis.Stream.from_stream_arn(\n            self, 'KinesisStream',\n            Arn.format(\n                ArnComponents(\n                    resource='stream',\n                    service='kinesis',\n                    resource_name='my-stream'\n                ),\n                self\n            )\n        )\n\n        lambdaFn = lambda_.Function(\n            self, 'Singleton',\n            handler='index.main',\n            code=lambda_.InlineCode(handler_code),\n            runtime=lambda_.Runtime.PYTHON_3_7,\n            timeout=Duration.seconds(300)\n        )\n\n        # Update Lambda Permissions To Use Stream\n        kinesis_stream.grant_read(lambdaFn)\n\n        # Create New Kinesis Event Source\n        kinesis_event_source = event_sources.KinesisEventSource(\n            stream=kinesis_stream,\n            starting_position=lambda_.StartingPosition.LATEST,\n            batch_size=1\n        )\n\n        # Attach New Event Source To Lambda\n        lambdaFn.add_event_source(kinesis_event_source)", "language": "python"}
{"input": "CDK Stack that creates Lambda, Step Functions, SFn Tasks resources", "output": "class JobPollerStack(Stack):\n    def __init__(self, app: App, id: str, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n\n        # Lambda Handlers Definitions\n\n        submit_lambda = _lambda.Function(self, 'submitLambda',\n                                         handler='lambda_function.lambda_handler',\n                                         runtime=_lambda.Runtime.PYTHON_3_9,\n                                         code=_lambda.Code.from_asset('lambdas/submit'))\n\n        status_lambda = _lambda.Function(self, 'statusLambda',\n                                         handler='lambda_function.lambda_handler',\n                                         runtime=_lambda.Runtime.PYTHON_3_9,\n                                         code=_lambda.Code.from_asset('lambdas/status'))\n\n        # Step functions Definition\n\n        submit_job = _aws_stepfunctions_tasks.LambdaInvoke(\n            self, \"Submit Job\",\n            lambda_function=submit_lambda,\n            output_path=\"$.Payload\",\n        )\n\n        wait_job = _aws_stepfunctions.Wait(\n            self, \"Wait 30 Seconds\",\n            time=_aws_stepfunctions.WaitTime.duration(\n                Duration.seconds(30))\n        )\n\n        status_job = _aws_stepfunctions_tasks.LambdaInvoke(\n            self, \"Get Status\",\n            lambda_function=status_lambda,\n            output_path=\"$.Payload\",\n        )\n\n        fail_job = _aws_stepfunctions.Fail(\n            self, \"Fail\",\n            cause='AWS Batch Job Failed',\n            error='DescribeJob returned FAILED'\n        )\n\n        succeed_job = _aws_stepfunctions.Succeed(\n            self, \"Succeeded\",\n            comment='AWS Batch Job succeeded'\n        )\n\n        # Create Chain\n\n        chain = submit_job.next(wait_job)\\\n            .next(status_job)\\\n            .next(_aws_stepfunctions.Choice(self, 'Job Complete?')\n                  .when(_aws_stepfunctions.Condition.string_equals('$.status', 'FAILED'), fail_job)\n                  .when(_aws_stepfunctions.Condition.string_equals('$.status', 'SUCCEEDED'), succeed_job)\n                  .otherwise(wait_job))\n\n        # Create state machine\n        sm = _aws_stepfunctions.StateMachine(\n            self, \"StateMachine\",\n            definition_body=_aws_stepfunctions.DefinitionBody.from_chainable(chain),\n            timeout=Duration.minutes(5),\n        )", "language": "python"}
{"input": "CDK Stack that creates Lambda, CloudFormation resources", "output": "class TestStack extends Stack {\n  public cleanupCanary: synthetics.Canary;\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.cleanupCanary = new synthetics.Canary(this, 'CleanupCanary', {\n      canaryName: 'cleanup',\n      runtime: synthetics.Runtime.SYNTHETICS_NODEJS_PUPPETEER_7_0,\n      test: synthetics.Test.custom({\n        handler: 'index.handler',\n        code: synthetics.Code.fromInline(`\n          exports.handler = async () => {\n            console.log(\\'hello world\\');\n          };`),\n      }),\n      memory: Size.mebibytes(2048),\n      timeout: Duration.minutes(4),\n      provisionedResourceCleanup: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, VPC, IAM resources", "output": "export class EvidentlyClientSideEvaluationEcsStack extends cdk.Stack {\n  constructor(app: cdk.App, id: string) {\n    super(app, id);\n\n    // Create AppConfig resources\n    const application = new appconfig.CfnApplication(this,'AppConfigApplication', {\n      name: 'MyApplication'\n    });\n\n    const environment = new appconfig.CfnEnvironment(this, 'AppConfigEnvironment', {\n      applicationId: application.ref,\n      name: 'MyEnvironment'\n    });\n\n    // Create Evidently resources\n    const project = new evidently.CfnProject(this, 'EvidentlyProject', {\n      name: 'WebPage',\n      appConfigResource: {\n        applicationId: application.ref,\n        environmentId: environment.ref\n      }\n    });\n\n    const feature = new evidently.CfnFeature(this, 'EvidentlyFeature', {\n      project: project.name,\n      name: 'SearchBar',\n      variations: [\n        {\n          booleanValue: false,\n          variationName: OLD_SEARCH_BAR\n        },\n        {\n          booleanValue: true,\n          variationName: NEW_SEARCH_BAR\n        }\n      ]\n    })\n    feature.addDependsOn(project)\n\n    const launch = new evidently.CfnLaunch(this, 'EvidentlyLaunch', {\n      project: project.name,\n      name: 'MyLaunch',\n      executionStatus: {\n        status: 'START'\n      },\n      groups: [\n        {\n          feature: feature.name,\n          variation: OLD_SEARCH_BAR,\n          groupName: OLD_SEARCH_BAR\n        },\n        {\n          feature: feature.name,\n          variation: NEW_SEARCH_BAR,\n          groupName: NEW_SEARCH_BAR\n        }\n      ],\n      scheduledSplitsConfig: [{\n        // This must be a timestamp. Choosing a start time in the past with status START will start the launch immediately:\n        // https://docs.aws.amazon.com/cloudwatchevidently/latest/APIReference/API_ScheduledSplitConfig.html#cloudwatchevidently-Type-ScheduledSplitConfig-startTime\n        startTime: '2022-01-01T00:00:00Z',\n        groupWeights: [\n          {\n            groupName: OLD_SEARCH_BAR,\n            splitWeight: 90000\n          },\n          {\n            groupName: NEW_SEARCH_BAR,\n            splitWeight: 10000\n          }\n        ]\n      }]\n    })\n    launch.addDependsOn(feature)\n\n    // Create ECS resources\n    const vpc = new ec2.Vpc(this, 'Vpc', { maxAzs: 2 });\n    const cluster = new ecs.Cluster(this, 'Cluster', { vpc });\n\n    // Instantiate Fargate Service with a cluster and a local image that gets\n    // uploaded to an S3 staging bucket prior to being uploaded to ECR.\n    // A new repository is created in ECR and the Fargate service is created\n    // with the image from ECR.\n    const service = new ecsPatterns.ApplicationLoadBalancedFargateService(this, \"FargateService\", {\n      cluster,\n      taskImageOptions: {\n        image: ecs.ContainerImage.fromAsset(path.resolve(__dirname, 'local-image')),\n        environment: {\n          DEPLOYMENT_TIME: new Date().getTime().toString(),\n        }\n      },\n    });\n\n    const configuration = `applications/${application.ref}/environments/${environment.ref}/configurations/${project.name}`\n    service.taskDefinition.addContainer('AppConfigAgent', {\n      image: ecs.ContainerImage.fromRegistry('public.ecr.aws/aws-appconfig/aws-appconfig-agent:2.x'),\n      portMappings: [{\n        containerPort: 2772\n      }],\n      environment: {\n        EVIDENTLY_CONFIGURATIONS: configuration,\n        PREFETCH_LIST: configuration\n      }\n    })\n\n    service.taskDefinition.taskRole.addToPrincipalPolicy(\n      new iam.PolicyStatement({\n        actions: ['appconfig:StartConfigurationSession', 'appconfig:GetLatestConfiguration'],\n        effect: iam.Effect.ALLOW,\n        resources: [`arn:aws:appconfig:${AWS_REGION}:${AWS_ACCOUNT}:application/${application.ref}/environment/${environment.ref}/configuration/*`]\n      })\n    )\n    service.taskDefinition.taskRole.addToPrincipalPolicy(\n      new iam.PolicyStatement({\n        actions: ['evidently:PutProjectEvents'],\n        effect: iam.Effect.ALLOW,\n        resources: [`arn:aws:evidently:${AWS_REGION}:${AWS_ACCOUNT}:project/${project.name}`]\n      })\n    )\n\n  }\n}", "language": "typescript"}
{"input": "CDK class DlcEcrImage for AWS resource management", "output": "class DlcEcrImage extends ContainerImage {\n  constructor(private readonly repositoryName: string, private readonly tag: string, private readonly accountId?: string) {\n    super();\n  }\n\n  public bind(scope: Construct, model: Model): ContainerImageConfig {\n    const accountId = this.accountId ?? Stack.of(scope).regionalFact(FactName.DLC_REPOSITORY_ACCOUNT);\n\n    const repository = ecr.Repository.fromRepositoryAttributes(scope, 'DlcRepository', {\n      repositoryName: this.repositoryName,\n      repositoryArn: ecr.Repository.arnForLocalRepository(\n        this.repositoryName,\n        scope,\n        accountId,\n      ),\n    });\n\n    repository.grantPull(model);\n\n    return { imageName: `${repository.repositoryUri}:${this.tag}` };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        my_main_func = lambda_.Function(\n            self,\n            \"myMainFunction\",\n            code=lambda_.InlineCode(\"def main(event, context)\\n  print('hello, world')\"),\n            handler='index.main',\n            runtime=lambda_.Runtime.PYTHON_3_7\n        )\n\n        # We assign the function to a local variable for the Object.\n        self._function = my_main_func", "language": "python"}
{"input": "CDK helper function bootstrap", "output": "export const bootstrap = async (env: NodeJS.ProcessEnv) => {\n  console.log('Bootstrapping AWS account.');\n  const spawnProcess = spawn('npx', ['cdk', 'bootstrap', ...['us-east-1', 'us-east-2', 'us-west-2'].map((region) => `aws://${env.AWS_ACCOUNT_ID}/${region}`)], {\n    stdio: ['ignore', 'inherit', 'inherit'],\n    env,\n  });\n\n  return new Promise<void>((resolve, reject) => spawnProcess.on('close', (code) => {\n    if (code == 0) resolve();\n    else reject(new Error(`Account bootstrap failed with exit code ${code}`));\n  }));\n}", "language": "typescript"}
{"input": "The gateway or endpoint targeted by the route.", "output": "export class RouteTargetType {\n  /**\n   * The gateway route target. This is used for targets such as\n   * egress-only internet gateway or VPC peering connection.\n   *\n   * @default - target is not set to a gateway, in this case an endpoint is needed.\n   */\n  readonly gateway?: IRouteTarget;\n\n  /**\n   * The endpoint route target. This is used for targets such as\n   * VPC endpoints.\n   *\n   * @default - target is not set to an endpoint, in this case a gateway is needed.\n   */\n  readonly endpoint?: IVpcEndpoint;\n\n  constructor(props: RouteTargetProps) {\n    this.gateway = props.gateway;\n    this.endpoint = props.endpoint;\n  }\n}", "language": "typescript"}
{"input": "CDK class ManagedRule for AWS resource management", "output": "export class ManagedRule extends RuleNew {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-config.ManagedRule';\n  /** @attribute */\n  public readonly configRuleName: string;\n\n  /** @attribute */\n  public readonly configRuleArn: string;\n\n  /** @attribute */\n  public readonly configRuleId: string;\n\n  /** @attribute */\n  public readonly configRuleComplianceType: string;\n\n  constructor(scope: Construct, id: string, props: ManagedRuleProps) {\n    super(scope, id, {\n      physicalName: props.configRuleName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.ruleScope = props.ruleScope;\n\n    const rule = new CfnConfigRule(this, 'Resource', {\n      configRuleName: this.physicalName,\n      description: props.description,\n      inputParameters: props.inputParameters,\n      maximumExecutionFrequency: props.maximumExecutionFrequency,\n      scope: Lazy.any({ produce: () => renderScope(this.ruleScope) }), // scope can use values such as stack id (see CloudFormationStackDriftDetectionCheck)\n      source: {\n        owner: 'AWS',\n        sourceIdentifier: props.identifier,\n      },\n      evaluationModes: props.evaluationModes?.modes.map((mode) => ({\n        mode,\n      })),\n    });\n\n    this.configRuleName = rule.ref;\n    this.configRuleArn = rule.attrArn;\n    this.configRuleId = rule.attrConfigRuleId;\n    this.configRuleComplianceType = rule.attrComplianceType;\n\n    this.isManaged = true;\n  }\n}", "language": "typescript"}
{"input": "Lambda function handler test_lambda_has_correct_iam_permissions", "output": "def test_lambda_has_correct_iam_permissions(self):\n    role_capture = Capture()\n    template.has_resource_properties('AWS::IAM::Role', {\n      'AssumeRolePolicyDocument': Match.object_like({\n        'Statement': [{\n          'Action': 'sts:AssumeRole',\n          'Effect': 'Allow',\n          'Principal': {\n            'Service': 'lambda.amazonaws.com'\n          },\n        }],\n      }),\n      'ManagedPolicyArns': [{\n        'Fn::Join': Match.array_with([\n          [ 'arn:', { 'Ref': 'AWS::Partition' }, role_capture ],\n        ]),\n      }],\n    })\n\n    assert 'AWSLambdaBasicExecutionRole' in role_capture.as_string()", "language": "python"}
{"input": "CDK Stack that creates API Gateway, CloudFormation resources", "output": "class ApplicationStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, referenced_function: lambda_.IFunction, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        my_api = apigw.LambdaRestApi(self, \"myRestAPI\", handler=referenced_function)", "language": "python"}
{"input": "An import source from an inline string.", "output": "export class InlineImportSource extends ImportSource {\n  private asset?: s3_assets.Asset;\n\n  /**\n   * @param data the contents of the KeyValueStore\n   */\n  constructor(public readonly data: string) {\n    super();\n  }\n\n  /**\n   * @internal\n   */\n  public _bind(scope: Construct): CfnKeyValueStore.ImportSourceProperty {\n    if (!this.asset) {\n      // CfnKeyValueStore does not support native in-line, so we need to use a\n      // temporary file to be uploaded with the S3 assets\n      const workdir = FileSystem.mkdtemp('key-value-store');\n      const outputPath = join(workdir, 'data.json');\n      fs.writeFileSync(outputPath, this.data);\n\n      this.asset = new s3_assets.Asset(scope, 'ImportSource', {\n        path: outputPath,\n        deployTime: true,\n      });\n    } else if (Stack.of(this.asset) !== Stack.of(scope)) {\n      throw new ValidationError(\n        `Asset is already associated with another stack '${Stack.of(this.asset).stackName}. ` +\n        'Create a new ImportSource instance for every stack.',\n        scope,\n      );\n    }\n\n    return {\n      sourceType: 'S3',\n      sourceArn: this.asset.bucket.arnForObjects(this.asset.s3ObjectKey),\n    };\n  }\n}", "language": "typescript"}
{"input": "Selects constructs from a construct tree based on various criteria.", "output": "export class ConstructSelector {\n  /**\n   * Selects all constructs in the tree.\n   */\n  static all(): IConstructSelector {\n    return new AllConstructsSelector();\n  }\n\n  /**\n   * Selects CfnResource constructs or the default CfnResource child.\n   */\n  static cfnResource(): IConstructSelector {\n    return new CfnResourceSelector();\n  }\n\n  /**\n   * Selects only the provided construct.\n   */\n  static onlyItself(): IConstructSelector {\n    return new OnlyItselfSelector();\n  }\n\n  /**\n   * Selects constructs of a specific type.\n   */\n  static resourcesOfType(...types: string[]): IConstructSelector {\n    return new ResourceTypeSelector(types);\n  }\n\n  /**\n   * Selects constructs whose construct IDs match a pattern.\n   * Uses glob like matching.\n   */\n  static byId(pattern: string): IConstructSelector {\n    return new IdPatternSelector(pattern, 'id');\n  }\n\n  /**\n   * Selects constructs whose construct paths match a pattern.\n   * Uses glob like matching.\n   */\n  static byPath(pattern: string): IConstructSelector {\n    return new IdPatternSelector(pattern, 'path');\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, IAM, Secrets Manager resources", "output": "class OpensearchSimpleDomainStack(cdk.Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # OpenSearch versions compatible with k-NN plugin\n        # https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html\n        # Note that current CDK version does not include OPENSEARCH_2_3, so\n        # we must use the custom version instead.\n        # https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_opensearchservice/EngineVersion.html\n        OPENSEARCH_VERSION = \"2.3\"\n\n        # Add the authorized IP addresses (using CIDR format) that should\n        # be granted access to the OpenSearch Domain.\n        # Create an environment variable before running cdk deploy. E.g.:\n        # OPENSEARCH_ALLOWED_IP='[\"33.45.123.8/32\"]'\n        allowed_ip_addresses = os.environ.get(\"OPENSEARCH_ALLOWED_IP\", \"x.x.x.x/32\")\n\n        # Creating OpenSearch access policy to restrict\n        # access to a specific list of IPs. We are allowing all\n        # types of HTTP commands.\n        opensearch_access_policy = cdk_iam.PolicyStatement(\n            effect=cdk_iam.Effect.ALLOW,\n            principals=[cdk_iam.AnyPrincipal()],\n            actions=[\"es:ESHttp*\"],\n            resources=[],\n            conditions={\n                \"IpAddress\": {\n                    \"aws:SourceIp\": allowed_ip_addresses\n                }\n            }\n        )\n\n        # Generating a secret and storing it with AWS Secrets Manager.\n        # https://aws.amazon.com/secrets-manager/\n        # To list secret using CLI and jq, run:\n        #   aws secretsmanager list-secrets | jq \".SecretList[].Name\"\n        # To retrieve a secret value using CLI and jq, run:\n        #   aws secretsmanager get-secret-value --secret-id <secret-name>\n        secret_opensearch_admin_password = cdk_sm.Secret(\n            self, \"OpenSearchDemoDomainAdminUser\")\n\n        # Capacity config documentation:\n        # https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_opensearchservice/CapacityConfig.html#aws_cdk.aws_opensearchservice.CapacityConfig\n        # Available instance types:\n        # https://docs.aws.amazon.com/opensearch-service/latest/developerguide/supported-instance-types.html\n        capacity_config = cdk_opensearch.CapacityConfig(\n            master_nodes=3,\n            master_node_instance_type=\"t3.small.search\",\n            data_nodes=3,\n            data_node_instance_type=\"t3.medium.search\"\n        )\n\n        # Available EBS options\n        # https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_opensearchservice/EbsOptions.html#aws_cdk.aws_opensearchservice.EbsOptions\n        ebs_config = EbsOptions(\n            volume_size=10,\n            volume_type=cdk_ec2.EbsDeviceVolumeType.GP3\n        )\n\n        # Enabling zone awareness to allow data replication across AZ's.\n        # https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_opensearchservice/ZoneAwarenessConfig.html#aws_cdk.aws_opensearchservice.ZoneAwarenessConfig\n        zone_awareness_config = ZoneAwarenessConfig(\n            availability_zone_count=3,\n            enabled=True\n        )\n\n        # Required when FGAC is enabled\n        encryption_config = EncryptionAtRestOptions(\n            enabled=True\n        )\n\n        # Required when FGAC is enabled\n        opensearch_admin_user = \"admin-user\"\n        advanced_security_config = AdvancedSecurityOptions(\n            master_user_name=opensearch_admin_user,\n            master_user_password=secret_opensearch_admin_password.secret_value\n        )\n\n        aos_domain = cdk_opensearch.Domain(\n            self, \"OpensearchDemoDomain\",\n            version=cdk_opensearch.EngineVersion.open_search(\n                OPENSEARCH_VERSION),\n            capacity=capacity_config,\n            ebs=ebs_config,\n            access_policies=[opensearch_access_policy],\n            enforce_https=True,             # Required when FGAC is enabled\n            node_to_node_encryption=True,   # Required when FGAC is enabled\n            encryption_at_rest=encryption_config,\n            fine_grained_access_control=advanced_security_config,\n            zone_awareness=zone_awareness_config\n        )\n\n        # Updating Opensearch Domain Access policy with its own resource ARN\n        opensearch_access_policy.add_resources(aos_domain.domain_arn + \"/*\")\n\n        cdk.CfnOutput(self,\"OpenSearchDomainEndpoint\", value=aos_domain.domain_endpoint)\n        cdk.CfnOutput(self,\"OpenSearchDashboardsURL\", value=(aos_domain.domain_endpoint + \"/_dashboards\"))\n        cdk.CfnOutput(self,\"OpenSearchPasswordSecretName\", value=secret_opensearch_admin_password.secret_name)\n        cdk.CfnOutput(self,\"OpenSearchAdminUser\", value=opensearch_admin_user)", "language": "python"}
{"input": "CDK Stack that creates EC2, VPC, IAM, MSK (Kafka) resources", "output": "class EksClusterStack extends Stack {\n  private cluster: eks.Cluster;\n  private vpc: ec2.IVpc;\n\n  constructor(scope: App, id: string) {\n    super(scope, id);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    // allow all account users to assume this role in order to admin the cluster\n    const mastersRole = new iam.Role(this, 'AdminRole', {\n      assumedBy: new iam.AccountRootPrincipal(),\n    });\n\n    // just need one nat gateway to simplify the test\n    this.vpc = new ec2.Vpc(this, 'Vpc', { natGateways: 1 });\n\n    // create the cluster with a default nodegroup capacity\n    this.cluster = new eks.Cluster(this, 'Cluster', {\n      vpc: this.vpc,\n      mastersRole,\n      defaultCapacity: 0,\n      ...getClusterVersionConfig(this),\n    });\n\n    this.cluster.addNodegroupCapacity('LinuxNodegroup', {\n      amiType: NodegroupAmiType.AL2_X86_64,\n    });\n    this.cluster.addNodegroupCapacity('WindowsNodegroup', {\n      amiType: NodegroupAmiType.WINDOWS_FULL_2022_X86_64,\n      taints: [\n        {\n          effect: TaintEffect.NO_SCHEDULE,\n          key: 'os',\n          value: 'windows',\n        },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class ByoDkim for AWS resource management", "output": "class ByoDkim extends DkimIdentity {\n  constructor(private readonly options: ByoDkimOptions) {\n    super();\n  }\n\n  public bind(emailIdentity: EmailIdentity, hostedZone?: route53.IPublicHostedZone): DkimIdentityConfig | undefined {\n    if (hostedZone && this.options.publicKey) {\n      new route53.TxtRecord(emailIdentity, 'DkimTxt', {\n        zone: hostedZone,\n        recordName: `${this.options.selector}._domainkey`,\n        values: [`p=${this.options.publicKey}`],\n      });\n    }\n\n    return {\n      domainSigningPrivateKey: this.options.privateKey.unsafeUnwrap(), // safe usage\n      domainSigningSelector: this.options.selector,\n    };\n  }\n}", "language": "typescript"}
{"input": "Stack with feature flag enabled - client secret would be logged", "output": "class TestStackSecretLogged extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    // Set the feature flag to true to allow logging client secret\n    this.node.setContext(cxapi.LOG_USER_POOL_CLIENT_SECRET_VALUE, true);\n    const userpool = new UserPool(this, 'pool', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const client = userpool.addClient('client', { generateSecret: true });\n    const secret = new secretsmanager.Secret(this, 'secret', {\n      secretStringValue: client.userPoolClientSecret,\n    });\n\n    new CfnOutput(this, 'ClientSecretName', {\n      value: secret.secretName,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class JestSetup for AWS resource management", "output": "export class JestSetup extends ValidationRule {\n  public readonly name = 'package-info/jest.config';\n\n  public validate(pkg: PackageJson): void {\n    const cdkBuild = pkg.json['cdk-build'] || {};\n\n    // check whether the package.json contains the \"jest\" key,\n    // which we no longer use\n    if (pkg.json.jest) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'Using Jest is set through a flag in the \"cdk-build\" key in package.json, the \"jest\" key is ignored',\n        fix: () => {\n          delete pkg.json.jest;\n          cdkBuild.jest = true;\n          pkg.json['cdk-build'] = cdkBuild;\n        },\n      });\n    }\n\n    // this rule should only be enforced for packages that use Jest for testing\n    if (!cdkBuild.jest) {\n      return;\n    }\n\n    const jestConfigFilename = 'jest.config.js';\n    if (!fs.existsSync(jestConfigFilename)) {\n      pkg.report({\n        ruleName: this.name,\n        message: 'There must be a jest.config.js file at the root of the package',\n        fix: () => {\n          const rootRelative = path.relative(pkg.packageRoot, repoRoot(pkg.packageRoot));\n          fs.writeFileSync(\n            jestConfigFilename,\n            [\n              `const baseConfig = require('${rootRelative}/tools/@aws-cdk/cdk-build-tools/config/jest.config');`,\n              'module.exports = baseConfig;',\n            ].join('\\n') + '\\n',\n          );\n        },\n      });\n    }\n    fileShouldContain(this.name, pkg, '.gitignore', '!jest.config.js');\n    fileShouldContain(this.name, pkg, '.npmignore', 'jest.config.js');\n\n    if (!(pkg.json.devDependencies ?? {})['@types/jest']) {\n      pkg.report({\n        ruleName: `${this.name}.types`,\n        message: 'There must be a devDependency on \\'@types/jest\\' if you use jest testing',\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK class DsRecord for AWS resource management", "output": "export class DsRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.DsRecord';\n\n  constructor(scope: Construct, id: string, props: DsRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.DS,\n      target: RecordTarget.fromValues(...props.values),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "Represents a base image that is used to start from in EC2 Image Builder image builds", "output": "export class BaseImage {\n  /**\n   * The AMI ID to use as a base image in an image recipe\n   *\n   * @param amiId The AMI ID to use as the base image\n   */\n  public static fromAmiId(amiId: string): BaseImage {\n    return new BaseImage(amiId);\n  }\n\n  /**\n   * The EC2 Image Builder image to use as a base image in an image recipe\n   *\n   * @param image The EC2 Image Builder image to use as a base image\n   */\n  public static fromImage(image: IImage): BaseImage {\n    return new BaseImage(image.imageArn);\n  }\n\n  /**\n   * The marketplace product ID for an AMI product to use as the base image in an image recipe\n   *\n   * @param productId The Marketplace AMI product ID to use as the base image\n   */\n  public static fromMarketplaceProductId(productId: string): BaseImage {\n    return new BaseImage(productId);\n  }\n\n  /**\n   * The SSM parameter to use as the base image in an image recipe\n   *\n   * @param parameter The SSM parameter to use as the base image\n   */\n  public static fromSsmParameter(parameter: ssm.IParameter): BaseImage {\n    return new BaseImage(`ssm:${parameter.parameterArn}`);\n  }\n\n  /**\n   * The parameter name for the SSM parameter to use as the base image in an image recipe\n   *\n   * @param parameterName The name of the SSM parameter to use as the base image\n   */\n  public static fromSsmParameterName(parameterName: string): BaseImage {\n    return new BaseImage(`ssm:${parameterName}`);\n  }\n\n  /**\n   * The direct string value of the base image to use in an image recipe. This can be an EC2 Image Builder image ARN,\n   * an SSM parameter, an AWS Marketplace product ID, or an AMI ID.\n   *\n   * @param baseImageString The base image as a direct string value\n   */\n  public static fromString(baseImageString: string): BaseImage {\n    return new BaseImage(baseImageString);\n  }\n\n  /**\n   * The rendered base image to use\n   **/\n  public readonly image: string;\n\n  protected constructor(image: string) {\n    this.image = image;\n  }\n}", "language": "typescript"}
{"input": "CDK class EventBusPolicy for AWS resource management", "output": "export class EventBusPolicy extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-events.EventBusPolicy';\n\n  constructor(scope: Construct, id: string, props: EventBusPolicyProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    new CfnEventBusPolicy(this, 'Resource', {\n      statementId: props.statementId!,\n      statement: props.statement,\n      eventBusName: props.eventBus.eventBusName,\n    });\n  }\n}", "language": "typescript"}
{"input": "Base class for configuring listener when registering targets.", "output": "class ListenerConfig {\n  /**\n   * Create a config for adding target group to ALB listener.\n   */\n  public static applicationListener(listener: elbv2.ApplicationListener, props?: elbv2.AddApplicationTargetsProps): ListenerConfig {\n    return new ApplicationListenerConfig(listener, props);\n  }\n\n  /**\n   * Create a config for adding target group to NLB listener.\n   */\n  public static networkListener(listener: elbv2.NetworkListener, props?: elbv2.AddNetworkTargetsProps): ListenerConfig {\n    return new NetworkListenerConfig(listener, props);\n  }\n\n  /**\n   * Create and attach a target group to listener.\n   */\n  public abstract addTargets(id: string, target: LoadBalancerTargetOptions, service: BaseService): void;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, KMS, SNS, SQS resources", "output": "class MyStack extends cdk.Stack {\n  public readonly bucket: s3.IBucket;\n  public readonly queue: sqs.IQueue;\n\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const kmsKey = new kms.Key(this, 'Key', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    const topic = new sns.Topic(this, 'Topic', {\n      masterKey: kmsKey,\n    });\n\n    this.queue = new sqs.Queue(this, 'Queue');\n    topic.addSubscription(new subscriptions.SqsSubscription(this.queue));\n\n    this.bucket = new s3.Bucket(this, 'MyBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    this.bucket.addObjectCreatedNotification(new s3n.SnsDestination(topic));\n  }\n}", "language": "typescript"}
{"input": "An IAM principal that represents an AWS service (i.e. `sqs.amazonaws.com`).", "output": "export class ServicePrincipal extends PrincipalBase {\n  /**\n   * Return the service principal name based on the region it's used in.\n   *\n   * Some service principal names used to be different for different partitions,\n   * and some were not. This method would return the appropriate region-specific\n   * service principal name, getting that information from the `region-info`\n   * module.\n   *\n   * These days all service principal names are standardized, and they are all\n   * of the form `<servicename>.amazonaws.com`.\n   *\n   * To avoid breaking changes, handling is provided for services added with the formats below,\n   * however, no additional handling will be added for new regions or partitions.\n   *   - s3\n   *   - s3.amazonaws.com\n   *   - s3.amazonaws.com.cn\n   *   - s3.c2s.ic.gov\n   *   - s3.sc2s.sgov.gov\n   *\n   * @example\n   * const principalName = iam.ServicePrincipal.servicePrincipalName('ec2.amazonaws.com');\n   */\n  public static servicePrincipalName(service: string): string {\n    return new ServicePrincipalToken(service, {}).toString();\n  }\n\n  /**\n   * Return the service principal using the service principal name as it is passed to the function without\n   * any change regardless of the region used in the stack if it is Opted in or not.\n   *\n   * @example\n   * const principalName = iam.ServicePrincipal.fromStaticServicePrincipleName('elasticmapreduce.amazonaws.com.cn');\n   */\n  public static fromStaticServicePrincipleName(servicePrincipalName: string): ServicePrincipal {\n    class StaticServicePrincipal extends ServicePrincipal {\n      constructor(public readonly service: string) {\n        super(service);\n      }\n\n      public get policyFragment(): PrincipalPolicyFragment {\n        return new PrincipalPolicyFragment({\n          Service: [this.service],\n        }, this.opts.conditions);\n      }\n    }\n    return new StaticServicePrincipal(servicePrincipalName);\n  }\n\n  /**\n   * Reference an AWS service, optionally in a given region\n   *\n   * @param service AWS service (i.e. sqs.amazonaws.com)\n   */\n  constructor(public readonly service: string, private readonly opts: ServicePrincipalOpts = {}) {\n    super();\n  }\n\n  public get policyFragment(): PrincipalPolicyFragment {\n    return new PrincipalPolicyFragment({\n      Service: [new ServicePrincipalToken(this.service, this.opts).toString()],\n    }, this.opts.conditions);\n  }\n\n  public toString() {\n    return `ServicePrincipal(${this.service})`;\n  }\n\n  public dedupeString(): string | undefined {\n    return `ServicePrincipal:${this.service}:${JSON.stringify(this.opts)}`;\n  }\n}\n\n/**\n * A principal that represents an AWS Organization\n */\nexport class OrganizationPrincipal extends PrincipalBase {\n  /**\n   *\n   * @param organizationId The unique identifier (ID) of an organization (i.e. o-12345abcde)\n   * It must match regex pattern ^o-[a-z0-9]{10,32}$\n   * @see https://docs.aws.amazon.com/organizations/latest/APIReference/API_Organization.html\n   */\n  constructor(public readonly organizationId: string) {\n    super();\n\n    // We can only validate if it's a literal string (not a token)\n    if (!cdk.Token.isUnresolved(organizationId)) {\n      if (!organizationId.match(/^o-[a-z0-9]{10,32}$/)) {\n        throw new UnscopedValidationError(`Expected Organization ID must match regex pattern ^o-[a-z0-9]{10,32}$, received ${organizationId}`);\n      }\n    }\n  }", "language": "typescript"}
{"input": "CDK class Ec2Product for AWS resource management", "output": "class Ec2Product(sc.ProductStack):\n    def __init__(self, scope: Construct, id: str):\n        super().__init__(scope, id)\n\n        # VPC\n        vpc = ec2.Vpc(self, \"VPC\",\n            nat_gateways=0,\n            subnet_configuration=[ec2.SubnetConfiguration(name=\"public\",subnet_type=ec2.SubnetType.PUBLIC,cidr_mask=24)],\n        )\n\n        # Instance Role and SSM Managed Policy\n        role = iam.Role(self, \"ec2Role\", assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"))\n\n        role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSSMManagedInstanceCore\"))\n\n        # AMI\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            cpu_type=ec2.AmazonLinuxCpuType.ARM_64,\n        )\n\n        # EC2 Instance Type parameter\n        ec2_instance_type = CfnParameter(self, \"InstanceType\",\n            type=\"String\",\n            description=\"The instance type of an EC2 instance.\",\n        )\n\n        # Instance\n        instance = ec2.Instance(self, \"Instance\",\n            instance_type=ec2.InstanceType(ec2_instance_type.value_as_string),\n            machine_image=amzn_linux,\n            allow_all_outbound=True,\n            vpc=vpc,\n            role=role,\n        )\n        instance.connections.allow_from_any_ipv4(ec2.Port.tcp(22), \"Allow SSH Access\")\n\n        # Create outputs for connecting\n        CfnOutput(self, \"IP Address\", value=instance.instance_public_ip)\n        CfnOutput(self, \"Download Key Command\", value=\"aws secretsmanager get-secret-value --secret-id ec2-ssh-key/cdk-keypair/private --query SecretString --output text > cdk-key.pem && chmod 400 cdk-key.pem\")\n        CfnOutput(self, \"ssh command\", value=\"ssh -i cdk-key.pem -o IdentitiesOnly=yes ec2-user@\" + instance.instance_public_ip)", "language": "python"}
{"input": "CodeCommit Source definition for a CodeBuild project.", "output": "class CodeCommitSource extends GitSource {\n  public readonly badgeSupported = true;\n  public readonly type = CODECOMMIT_SOURCE_TYPE;\n  private readonly repo: codecommit.IRepository;\n\n  constructor(props: CodeCommitSourceProps) {\n    super(props);\n    this.repo = props.repository;\n  }\n\n  public bind(_scope: Construct, project: IProject): SourceConfig {\n    // https://docs.aws.amazon.com/codebuild/latest/userguide/setting-up.html\n    project.addToRolePolicy(new iam.PolicyStatement({\n      actions: ['codecommit:GitPull'],\n      resources: [this.repo.repositoryArn],\n    }));\n\n    const superConfig = super.bind(_scope, project);\n    return {\n      sourceProperty: {\n        ...superConfig.sourceProperty,\n        location: this.repo.repositoryCloneUrlHttp,\n      },\n      sourceVersion: superConfig.sourceVersion,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class AddTwoTargetGroupsAtOnce for AWS resource management", "output": "class AddTwoTargetGroupsAtOnce extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    const vpc = new ec2.Vpc(this, 'Stack');\n    const lb = new elbv2.ApplicationLoadBalancer(this, 'LB', { vpc });\n    const listener = lb.addListener('Listener', { port: 80 });\n    const groupOne = new elbv2.ApplicationTargetGroup(this, 'TargetGroupOne', {\n      vpc, port: 80, targetType: elbv2.TargetType.INSTANCE,\n    });\n    const groupTwo = new elbv2.ApplicationTargetGroup(this, 'TargetGroupTwo', {\n      vpc, port: 80, targetType: elbv2.TargetType.INSTANCE,\n    });\n\n    listener.addTargetGroups('Default', {\n      targetGroups: [groupOne, groupTwo],\n    });\n  }\n}", "language": "typescript"}
{"input": "Represents the inputs for a step in the component document", "output": "export class ComponentStepInputs {\n  /**\n   * Creates the input value from an object, for the component step\n   *\n   * @param inputsObject The object containing the input values\n   */\n  public static fromObject(inputsObject: { [key: string]: any }): ComponentStepInputs {\n    return new ComponentStepInputs(inputsObject);\n  }\n\n  /**\n   * Creates the input value from a list of input objects, for the component step\n   *\n   * @param inputsObjectList The list of objects containing the input values\n   */\n  public static fromList(inputsObjectList: { [key: string]: any }[]): ComponentStepInputs {\n    return new ComponentStepInputs(inputsObjectList);\n  }\n\n  /**\n   * The rendered input value\n   */\n  public readonly inputs: any;\n\n  protected constructor(input: any) {\n    this.inputs = input;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ECS, ECR, CloudMap (Service Discovery) resources", "output": "class PythonStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: ApplicationSignalsStackProps) {\n    super(scope, id, props);\n\n    const taskDefinition = new ecs.FargateTaskDefinition(this, 'PythonTaskDefinition', {\n      taskRole: props.taskRole,\n      executionRole: props.taskExecutionRole,\n    });\n\n    taskDefinition.addContainer('app', {\n      image: ecs.ContainerImage.fromRegistry('public.ecr.aws/q0c5s6i7/demo-application:python-remote'),\n      command: [\n        'sh',\n        '-c',\n        'python3 manage.py migrate --noinput && python3 manage.py collectstatic --noinput && python3 manage.py runserver 0.0.0.0:8080 --noreload',\n      ],\n      environment: {\n        PYTHONPATH: '/django_remote_app',\n        DJANGO_SETTINGS_MODULE: 'django_remote_service.settings',\n      },\n      memoryLimitMiB: 512,\n    });\n\n    new appsignals.ApplicationSignalsIntegration(this, 'PythonECSIntegration', {\n      taskDefinition: taskDefinition,\n      instrumentation: {\n        sdkVersion: appsignals.PythonInstrumentationVersion.V0_8_0,\n      },\n      serviceName: 'python-demo',\n      overrideEnvironments: [\n        {\n          name: appsignals.CommonExporting.OTEL_AWS_APPLICATION_SIGNALS_EXPORTER_ENDPOINT,\n          value: 'http://cwagent-4316-http:4316/v1/metrics',\n        }, {\n          name: appsignals.TraceExporting.OTEL_EXPORTER_OTLP_TRACES_ENDPOINT,\n          value: 'http://cwagent-4316-http:4316/v1/traces',\n        }, {\n          name: appsignals.TraceExporting.OTEL_TRACES_SAMPLER_ARG,\n          value: 'endpoint=http://cwagent-2000-http:2000',\n        },\n      ],\n    });\n\n    new ecs.FargateService(this, 'PythonApp', {\n      cluster: props.ecsCluster,\n      taskDefinition: taskDefinition,\n      securityGroups: [props.securityGroup],\n      desiredCount: 1,\n      enableExecuteCommand: true,\n      serviceConnectConfiguration: {\n        namespace: props.dnsNamespace.namespaceArn,\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, Step Functions, CloudFormation resources", "output": "class StepFunctionStack extends Stack {\n  public readonly stateMachine: sfn.StateMachine;\n  public readonly crossAccountRole: Role;\n\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Create a simple Step Function\n    this.stateMachine = new sfn.StateMachine(this, 'CrossAccountStateMachine', {\n      definition: new sfn.Pass(this, 'PassState', {\n        result: sfn.Result.fromObject({ message: 'Hello from cross-account Step Function!' }),\n      }),\n      stateMachineName: 'CrossAccountStateMachine',\n    });\n\n    this.crossAccountRole = new Role(this, 'CrossAccountRole', {\n      roleName: PhysicalName.GENERATE_IF_NEEDED,\n      assumedBy: new AccountPrincipal(account),\n    });\n\n    this.stateMachine.grantStartExecution(this.crossAccountRole);\n  }\n}", "language": "typescript"}
{"input": "Util element for InsightSelector", "output": "export class InsightType {\n  /**\n   * The type of insights to log on a trail. (API Call Rate)\n   */\n  public static readonly API_CALL_RATE = new InsightType('ApiCallRateInsight');\n\n  /**\n   * The type of insights to log on a trail. (API Error Rate)\n   */\n  public static readonly API_ERROR_RATE = new InsightType('ApiErrorRateInsight');\n\n  protected constructor(public readonly value: string) {}\n}", "language": "typescript"}
{"input": "Represents the service source from a Github repository.", "output": "export class GithubSource extends Source {\n  private readonly props: GithubRepositoryProps;\n  constructor(props: GithubRepositoryProps) {\n    super();\n    this.props = props;\n  }\n  public bind(_scope: Construct): SourceConfig {\n    return {\n      codeRepository: {\n        codeConfiguration: {\n          configurationSource: this.props.configurationSource,\n          configurationValues: this.props.codeConfigurationValues,\n        },\n        repositoryUrl: this.props.repositoryUrl,\n        sourceCodeVersion: {\n          type: 'BRANCH',\n          value: this.props.branch ?? 'main',\n        },\n        connection: this.props.connection,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class NonIpInstance for AWS resource management", "output": "export class NonIpInstance extends InstanceBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-servicediscovery.NonIpInstance';\n  /**\n   * The Id of the instance\n   */\n  public readonly instanceId: string;\n\n  /**\n   * The Cloudmap service to which the instance is registered.\n   */\n  public readonly service: IService;\n\n  constructor(scope: Construct, id: string, props: NonIpInstanceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const discoveryType = props.service.discoveryType || defaultDiscoveryType(props.service.namespace);\n    if (discoveryType !== DiscoveryType.API) {\n      throw new ValidationError('This type of instance can only be registered for HTTP namespaces.', this);\n    }\n\n    if (props.customAttributes === undefined || Object.keys(props.customAttributes).length === 0) {\n      throw new ValidationError('You must specify at least one custom attribute for this instance type.', this);\n    }\n\n    const resource = new CfnInstance(this, 'Resource', {\n      instanceId: props.instanceId || this.uniqueInstanceId(),\n      serviceId: props.service.serviceId,\n      instanceAttributes: {\n        ...props.customAttributes,\n      },\n    });\n\n    this.service = props.service;\n    this.instanceId = resource.ref;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, EC2, VPC, KMS resources", "output": "class AlbOidcStack extends Stack {\n  public readonly userPool: cognito.UserPool;\n  constructor(scope: Construct, id: string, props: AlbOidcStackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', {\n      maxAzs: 2,\n    });\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n    const certificate = new acm.Certificate(this, 'Certificate', {\n      domainName: props.domainName,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    // Create Cognito UserPool as IdP\n    this.userPool = new cognito.UserPool(this, 'UserPool', {\n      signInAliases: {\n        email: true,\n      },\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    const userPoolDomain = this.userPool.addDomain('Domain', {\n      cognitoDomain: {\n        domainPrefix: props.hostedZoneId.toLowerCase(),\n      },\n    });\n    const userPoolClient = this.userPool.addClient('UserPoolClient', {\n      generateSecret: true,\n      oAuth: {\n        callbackUrls: [`https://${props.domainName}/oauth2/idpresponse`],\n        flows: {\n          authorizationCodeGrant: true,\n        },\n      },\n    });\n\n    const lb = new ApplicationLoadBalancer(this, 'LoadBalancer', {\n      vpc,\n      internetFacing: true,\n    });\n    const userPoolDomainName = `${userPoolDomain.domainName}.auth.${this.region}.amazoncognito.com`;\n    lb.addListener('Listener', {\n      protocol: ApplicationProtocol.HTTPS,\n      certificates: [certificate],\n      defaultAction: ListenerAction.authenticateOidc({\n        authorizationEndpoint: `https://${userPoolDomainName}/oauth2/authorize`,\n        clientId: userPoolClient.userPoolClientId,\n        clientSecret: userPoolClient.userPoolClientSecret,\n        issuer: `https://cognito-idp.${this.region}.amazonaws.com/${this.userPool.userPoolId}`,\n        tokenEndpoint: `https://${userPoolDomainName}/oauth2/token`,\n        userInfoEndpoint: `https://${userPoolDomainName}/oauth2/userInfo`,\n        next: ListenerAction.fixedResponse(200, {\n          contentType: 'text/plain',\n          messageBody: 'Authenticated',\n        }),\n      }),\n    });\n    new route53.ARecord(this, 'ARecord', {\n      target: route53.RecordTarget.fromAlias(new route53targets.LoadBalancerTarget(lb)),\n      zone: hostedZone,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Step Functions, CloudFormation, CodeBuild resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props: cdk.StackProps = {}) {\n    super(scope, id, props);\n\n    const project = new codebuild.Project(this, 'Project', {\n      projectName: 'MyTestProject',\n      environment: {\n        buildImage: codebuild.LinuxBuildImage.STANDARD_5_0,\n      },\n      timeout: cdk.Duration.hours(1),\n      buildSpec: codebuild.BuildSpec.fromObjectToYaml({\n        version: 0.2,\n        batch: {\n          'fast-fail': true,\n          'build-list': [\n            {\n              identifier: 'linux_small',\n              env: {\n                'compute-type': 'BUILD_GENERAL1_SMALL',\n                'image': 'aws/codebuild/standard:5.0',\n                'type': 'LINUX_CONTAINER',\n                'variables': {\n                  key1: 'value1',\n                },\n              },\n              buildspec: 'version: 0.2\\nphases:\\n  build:\\n    commands:\\n      - echo \"Hello, from small!\"',\n            },\n            {\n              identifier: 'linux_medium',\n              env: {\n                'compute-type': 'BUILD_GENERAL1_MEDIUM',\n                'image': 'aws/codebuild/standard:4.0',\n                'type': 'LINUX_CONTAINER',\n                'variables': {\n                  key2: 'value2',\n                },\n              },\n              buildspec: 'version: 0.2\\nphases:\\n  build:\\n    commands:\\n      - echo \"Hello, from medium!\"',\n            },\n          ],\n        },\n      }),\n    });\n    const buildconfig = project.enableBatchBuilds();\n\n    if (buildconfig == null) {\n      throw new Error('Batch builds not enabled');\n    }\n\n    const startBuildBatch1 = new tasks.CodeBuildStartBuildBatch(this, 'buildTask1', {\n      project,\n      integrationPattern: sfn.IntegrationPattern.REQUEST_RESPONSE,\n      environmentVariablesOverride: {\n        test: {\n          type: codebuild.BuildEnvironmentVariableType.PLAINTEXT,\n          value: 'testValue',\n        },\n      },\n    });\n\n    const startBuildBatch2 = new tasks.CodeBuildStartBuildBatch(this, 'buildTask2', {\n      project,\n      integrationPattern: sfn.IntegrationPattern.RUN_JOB,\n      environmentVariablesOverride: {\n        test: {\n          type: codebuild.BuildEnvironmentVariableType.PLAINTEXT,\n          value: 'testValue',\n        },\n      },\n    });\n\n    const definition = new sfn.Pass(this, 'Start', {\n      result: sfn.Result.fromObject({ bar: 'SomeValue' }),\n    }).next(startBuildBatch1).next(startBuildBatch2);\n\n    new sfn.StateMachine(this, 'StateMachine', {\n      definition,\n    });\n  }\n}", "language": "typescript"}
{"input": "Contains static factory methods with which you can build the input needed for application associator to work", "output": "class TargetApplication {\n  /**\n   * Factory method to build the input using the provided\n   * application ARN.\n   */\n  public static existingApplicationFromArn(options: ExistingTargetApplicationOptions) : TargetApplication {\n    return new ExistingTargetApplication(options);\n  }\n\n  /**\n   * Factory method to build the input using the provided\n   * application name and stack props.\n   */\n  public static createApplicationStack(options: CreateTargetApplicationOptions) : TargetApplication {\n    return new CreateTargetApplication(options);\n  }\n\n  /**\n   * Called when the ApplicationAssociator is initialized\n   */\n  public abstract bind(scope: Construct): BindTargetApplicationResult;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, CloudFormation resources", "output": "class AthenaS3GlueStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        # creating the buckets where the logs will be placed\n        logs_bucket = s3.Bucket(self, 'logs-bucket',\n                                bucket_name=f\"auditing-logs-{self.account}\",\n                                removal_policy=RemovalPolicy.DESTROY,\n                                auto_delete_objects=True\n                                )\n\n        # creating the bucket where the Athena queries output will be placed\n        query_output_bucket = s3.Bucket(self, 'query-output-bucket',\n                                        bucket_name=f\"auditing-analysis-output-{self.account}\",\n                                        removal_policy=RemovalPolicy.DESTROY,\n                                        auto_delete_objects=True\n                                        )\n\n        # uploading the log files to the bucket as examples\n        s3_deployment.BucketDeployment(self, 'sample-files',\n                                       destination_bucket=logs_bucket,\n                                       sources=[s3_deployment.Source.asset('./log-samples')],\n                                       content_type='application/json',\n                                       retain_on_delete=False\n                                       )\n\n        # creating the Glue Database to serve as our Data Catalog\n        glue_database = glue.CfnDatabase(self, 'log-database',\n                                         catalog_id=self.account,\n                                         database_input=glue.CfnDatabase.DatabaseInputProperty(\n                                             name=\"log-database\"\n                                         ))\n\n        # creating the permissions for the crawler to enrich our Data Catalog\n        glue_crawler_role = iam.Role(self, 'glue-crawler-role',\n                                     role_name='glue-crawler-role',\n                                     assumed_by=iam.ServicePrincipal(service='glue.amazonaws.com'),\n                                     managed_policies=[\n                                         # Remember to apply the Least Privilege Principle and provide only the permissions needed to the crawler\n                                         iam.ManagedPolicy.from_managed_policy_arn(self, 'AmazonS3FullAccess',\n                                                                                   'arn:aws:iam::aws:policy/AmazonS3FullAccess'),\n                                         iam.ManagedPolicy.from_managed_policy_arn(self, 'AWSGlueServiceRole',\n                                                                                   'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole')\n                                     ])\n\n        # creating the Glue Crawler that will automatically populate our Data Catalog. Don't forget to run the crawler\n        # as soon as the deployment finishes, otherwise our Data Catalog will be empty. Check out the README for more instructions\n        glue.CfnCrawler(self, 'logs-crawler',\n                        name='logs-crawler',\n                        database_name=glue_database.database_input.name,\n                        role=glue_crawler_role.role_name,\n                        targets={\n                            \"s3Targets\": [\n                                {\"path\": f's3://{logs_bucket.bucket_name}/products'},\n                                {\"path\": f's3://{logs_bucket.bucket_name}/users'}\n                            ]\n                        })\n\n        # creating the Athena Workgroup to store our queries\n        work_group = athena.CfnWorkGroup(self, 'log-auditing-work-group',\n                                         name='log-auditing',\n                                         work_group_configuration=athena.CfnWorkGroup.WorkGroupConfigurationProperty(\n                                             result_configuration=athena.CfnWorkGroup.ResultConfigurationProperty(\n                                                 output_location=f\"s3://{query_output_bucket.bucket_name}\",\n                                                 encryption_configuration=athena.CfnWorkGroup.EncryptionConfigurationProperty(\n                                                     encryption_option=\"SSE_S3\"\n                                                 ))))\n\n        # creating an example query to fetch all product events by date\n        product_events_by_date_query = athena.CfnNamedQuery(self, 'product-events-by-date-query',\n                                                            database=glue_database.database_input.name,\n                                                            work_group=work_group.name,\n                                                            name=\"product-events-by-date\",\n                                                            query_string=\"SELECT * FROM \\\"log-database\\\".\\\"products\\\" WHERE \\\"date\\\" = '2024-01-19'\")\n\n        # creating an example query to fetch all user events by date\n        user_events_by_date_query = athena.CfnNamedQuery(self, 'user-events-by-date-query',\n                                                         database=glue_database.database_input.name,\n                                                         work_group=work_group.name,\n                                                         name=\"user-events-by-date\",\n                                                         query_string=\"SELECT * FROM \\\"log-database\\\".\\\"users\\\" WHERE \\\"date\\\" = '2024-01-22'\")\n\n        # creating an example query to fetch all events by the user ID\n        all_events_by_userid_query = athena.CfnNamedQuery(self, 'all-events-by-userId-query',\n                                                          database=glue_database.database_input.name,\n                                                          work_group=work_group.name,\n                                                          name=\"all-events-by-userId\",\n                                                          query_string=\"SELECT * FROM (\\n\"\n                                                                       \"    SELECT transactionid, userid, username, domain, datetime, action FROM \\\"log-database\\\".\\\"products\\\" \\n\"\n                                                                       \"UNION \\n\"\n                                                                       \"    SELECT transactionid, userid, username, domain, datetime, action FROM \\\"log-database\\\".\\\"users\\\" \\n\"\n                                                                       \") WHERE \\\"userid\\\" = '123'\")\n\n        # adjusting the resource creation order\n        product_events_by_date_query.add_dependency(work_group)\n        user_events_by_date_query.add_dependency(work_group)\n        all_events_by_userid_query.add_dependency(work_group)", "language": "python"}
{"input": "CDK class TestMixin for AWS resource management", "output": "class TestMixin extends Mixin {\n  applyTo(construct: any): any {\n    (construct as any).mixinApplied = true;\n    return construct;\n  }\n}", "language": "typescript"}
{"input": "Lambda function handler test_lambda_not_running_in_vpc", "output": "def test_lambda_not_running_in_vpc(self):\n    template.has_resource('AWS::Lambda::Function', {\n      'Vpc': Match.absent()\n    })", "language": "python"}
{"input": "CDK Stack that creates Lambda, IAM, KMS, CloudFormation resources", "output": "export class CMKStack extends NestedStack {\n  private readonly keyArnExportPrefix: string = 'cmk-key-arn-';\n\n  constructor(scope: Construct, id: string, props: Props) {\n    super(scope, id, props);\n\n    const keyId = new kms.CfnKey(this, 'multi-region-cmk', {\n      keyPolicy: {\n        'Version': '2012-10-17',\n        'Statement': [\n          {\n            'Effect': 'Allow',\n            'Principal': {\n              'AWS': `arn:aws:iam::${this.account}:root`,\n            },\n            'Action': 'kms:*',\n            'Resource': '*',\n          },\n        ],\n      },\n      description: `CMK for ${props.tableName} in ${this.region}`,\n      enableKeyRotation: true,\n      enabled: true,\n      multiRegion: true,\n    }).attrKeyId;\n\n    new kms.CfnAlias(this, 'multi-region-cmk-alias', {\n      aliasName: props.keyAlias ?? `alias/multi-region-cmk-for-ddb-table-${props.tableName}`,\n      targetKeyId: keyId,\n    })\n\n    this.createKeyArnCFNOutput(this.region, keyId);\n    props.keyReplicaRegions.forEach((replicaRegion: string) => this.createKeyReplica(replicaRegion, keyId));\n  }\n\n  private createKeyReplica(replicaRegion: string, keyId: string) {\n    const awsSdkCall: cr.AwsSdkCall = {\n      service: 'KMS',\n      action: 'replicateKey',\n      physicalResourceId: cr.PhysicalResourceId.of(\n        'CustomResource::KeyReplicaCreation',\n      ),\n      parameters: {\n        KeyId: keyId,\n        ReplicaRegion: replicaRegion,\n      },\n    };\n\n    new cr.AwsCustomResource(this, `${replicaRegion}-custom-resource`, {\n      onCreate: awsSdkCall,\n      onUpdate: awsSdkCall,\n      policy: cr.AwsCustomResourcePolicy.fromStatements([\n        new iam.PolicyStatement({\n          effect: iam.Effect.ALLOW,\n          actions: [\n            'kms:*',\n          ],\n          resources: [\n            '*',\n          ],\n        }),\n      ]),\n    });\n\n    this.createKeyArnCFNOutput(replicaRegion, keyId);\n  }\n\n  private createKeyArnCFNOutput(keyRegion: string, keyId: string) {\n    new CfnOutput(this, `${keyRegion}-key-arn`, {\n      value: `arn:aws:kms:${keyRegion}:${this.account}:key/${keyId}`,\n      exportName: `${this.keyArnExportPrefix}${keyRegion}`,\n    });\n  }\n\n  public getKeyReplicaExportNames(region: string) {\n    return `${this.keyArnExportPrefix}${region}`;\n  }\n}", "language": "typescript"}
{"input": "CDK class SubscriptionFilter for AWS resource management", "output": "export class SubscriptionFilter extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-logs.SubscriptionFilter';\n\n  constructor(scope: Construct, id: string, props: SubscriptionFilterProps) {\n    super(scope, id, {\n      physicalName: props.filterName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    if (\n      props.distribution &&\n      !Token.isUnresolved(props.distribution) &&\n      !Token.isUnresolved(props.destination) &&\n      !(props.destination instanceof KinesisDestination)\n    ) {\n      throw new ValidationError('distribution property can only be used with KinesisDestination.', this);\n    }\n\n    const destProps = props.destination.bind(this, props.logGroup);\n\n    new CfnSubscriptionFilter(this, 'Resource', {\n      logGroupName: props.logGroup.logGroupRef.logGroupName,\n      destinationArn: destProps.arn,\n      roleArn: destProps.role?.roleArn,\n      filterPattern: props.filterPattern.logPatternString,\n      filterName: this.physicalName,\n      distribution: props.distribution,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class MyJob for AWS resource management", "output": "class MyJob extends stepFunctions.StateMachineFragment {\n  public readonly startState: stepFunctions.State;\n  public readonly endStates: stepFunctions.INextable[];\n\n  constructor(parent: Construct, id: string, props: any) {\n    super(parent, id);\n\n    this.startState = new tasks.LambdaInvoke(this, 'my-lambda-task', {\n      lambdaFunction: props.lambdaFunction\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, Cognito, AppSync resources", "output": "class OriginalStack extends Stack {\n  public readonly apiId: string;\n\n  constructor(scope: App, id: string) {\n    super(scope, id);\n\n    const userPool = new UserPool(this, 'Pool', {\n      userPoolName: 'myPool',\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const api = new GraphqlApi(this, 'Api', {\n      name: 'Integ_Test_IAM',\n      schema: SchemaFile.fromAsset(join(__dirname, 'integ.graphql-iam.graphql')),\n      authorizationConfig: {\n        defaultAuthorization: {\n          authorizationType: AuthorizationType.USER_POOL,\n          userPoolConfig: {\n            userPool,\n            defaultAction: UserPoolDefaultAction.ALLOW,\n          },\n        },\n        additionalAuthorizationModes: [\n          {\n            authorizationType: AuthorizationType.IAM,\n          },\n        ],\n      },\n    });\n\n    this.apiId = api.apiId;\n  }\n}", "language": "typescript"}
{"input": "An AppSync dummy datasource", "output": "export class NoneDataSource extends BaseDataSource {\n  constructor(scope: Construct, id: string, props: NoneDataSourceProps) {\n    super(scope, id, props, {\n      type: 'NONE',\n    });\n  }\n}", "language": "typescript"}
{"input": "Helper class for referencing and uploading dockerfile data for the container recipe", "output": "class DockerfileData {\n  /**\n   * Uploads dockerfile data from a local file to S3 to use as the dockerfile data\n   *\n   * @param scope The construct scope\n   * @param id Identifier of the construct\n   * @param path The local path to the dockerfile data file\n   * @param options S3 asset upload options\n   */\n  public static fromAsset(\n    scope: Construct,\n    id: string,\n    path: string,\n    options: s3assets.AssetOptions = {},\n  ): S3DockerfileData {\n    const asset = new s3assets.Asset(scope, id, { ...options, path });\n    return new S3DockerfileDataFromAsset(asset);\n  }\n\n  /**\n   * References dockerfile data from a pre-existing S3 object\n   *\n   * @param bucket The S3 bucket where the dockerfile data is stored\n   * @param key The S3 key of the dockerfile data file\n   */\n  public static fromS3(bucket: s3.IBucket, key: string): S3DockerfileData {\n    return new S3DockerfileDataFromBucketKey(bucket, key);\n  }\n\n  /**\n   * Uses an inline string as the dockerfile data\n   *\n   * @param data An inline string representing the dockerfile data\n   */\n  public static fromInline(data: string): DockerfileData {\n    return new InlineDockerfileData(data);\n  }\n\n  /**\n   * The rendered Dockerfile value, for use in CloudFormation.\n   * - For inline dockerfiles, dockerfileTemplateData is the Dockerfile template text\n   * - For S3-backed dockerfiles, dockerfileTemplateUri is the S3 URL\n   */\n  abstract render(): DockerfileTemplateConfig;\n}", "language": "typescript"}
{"input": "Used for testing common Origin functionality", "output": "export class TestOrigin extends OriginBase {\n  constructor(domainName: string, props: OriginProps = {}) { super(domainName, props); }\n  protected renderCustomOriginConfig(): CfnDistribution.CustomOriginConfigProperty | undefined {\n    return { originProtocolPolicy: OriginProtocolPolicy.HTTPS_ONLY };\n  }\n}", "language": "typescript"}
{"input": "Abstract base class for all PII types.", "output": "class PIIType {\n  /**\n   * The string value of the PII type.\n   */\n  public readonly value: string;\n\n  /**\n   * The string value of the PII type.\n   */\n  protected constructor(value: string) {\n    this.value = value;\n  }\n\n  /**\n   * Returns the string representation of the PII type.\n   * @returns The string value of the PII type.\n   */\n  toString(): string { return this.value; }\n}", "language": "typescript"}
{"input": "CDK class CDKPackage for AWS resource management", "output": "export class CDKPackage extends ValidationRule {\n  public readonly name = 'package-info/scripts/package';\n\n  public validate(pkg: PackageJson): void {\n    // skip private packages\n    if (pkg.json.private) { return; }\n\n    const merkleMarker = '.LAST_PACKAGE';\n\n    if (!shouldUseCDKBuildTools(pkg)) { return; }\n    expectJSON(this.name, pkg, 'scripts.package', 'cdk-package');\n\n    const outdir = 'dist';\n\n    // if this is\n    if (isJSII(pkg)) {\n      expectJSON(this.name, pkg, 'jsii.outdir', outdir);\n    }\n\n    fileShouldContain(this.name, pkg, '.npmignore', outdir);\n    fileShouldContain(this.name, pkg, '.gitignore', outdir);\n    fileShouldContain(this.name, pkg, '.npmignore', merkleMarker);\n    fileShouldContain(this.name, pkg, '.gitignore', merkleMarker);\n  }\n}", "language": "typescript"}
{"input": "A scheduled Fargate task that will be initiated off of CloudWatch Events.", "output": "export class ScheduledFargateTask extends ScheduledTaskBase {\n  /**\n   * The Fargate task definition in this construct.\n   */\n  public readonly taskDefinition: FargateTaskDefinition;\n\n  /**\n   * The ECS task in this construct.\n   */\n  public readonly task: EcsTask;\n\n  /**\n   * Constructs a new instance of the ScheduledFargateTask class.\n   */\n  constructor(scope: Construct, id: string, props: ScheduledFargateTaskProps) {\n    super(scope, id, props);\n\n    if (props.scheduledFargateTaskDefinitionOptions && props.scheduledFargateTaskImageOptions) {\n      throw new ValidationError('You must specify either a scheduledFargateTaskDefinitionOptions or scheduledFargateTaskOptions, not both.', this);\n    } else if (props.scheduledFargateTaskDefinitionOptions) {\n      this.taskDefinition = props.scheduledFargateTaskDefinitionOptions.taskDefinition;\n    } else if (props.scheduledFargateTaskImageOptions) {\n      const taskImageOptions = props.scheduledFargateTaskImageOptions;\n      const containerName = taskImageOptions.containerName ?? 'ScheduledContainer';\n      this.taskDefinition = new FargateTaskDefinition(this, 'ScheduledTaskDef', {\n        memoryLimitMiB: taskImageOptions.memoryLimitMiB || 512,\n        cpu: taskImageOptions.cpu || 256,\n        ephemeralStorageGiB: taskImageOptions.ephemeralStorageGiB,\n      });\n      this.taskDefinition.addContainer(containerName, {\n        image: taskImageOptions.image,\n        command: taskImageOptions.command,\n        environment: taskImageOptions.environment,\n        secrets: taskImageOptions.secrets,\n        logging: taskImageOptions.logDriver ?? this.createAWSLogDriver(this.node.id),\n      });\n    } else {\n      throw new ValidationError('You must specify one of: taskDefinition or image', this);\n    }\n\n    if (props.taskDefinition) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-ecs-patterns:propertyIgnored', 'Property \\'taskDefinition\\' is ignored, use \\'scheduledFargateTaskDefinitionOptions\\' or \\'scheduledFargateTaskImageOptions\\' instead.');\n    }\n    if (props.cpu) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-ecs-patterns:propertyIgnored', 'Property \\'cpu\\' is ignored, use \\'scheduledFargateTaskImageOptions.cpu\\' instead.');\n    }\n    if (props.memoryLimitMiB) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-ecs-patterns:propertyIgnored', 'Property \\'memoryLimitMiB\\' is ignored, use \\'scheduledFargateTaskImageOptions.memoryLimitMiB\\' instead.');\n    }\n    if (props.ephemeralStorageGiB) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-ecs-patterns:propertyIgnored', 'Property \\'ephemeralStorageGiB\\' is ignored, use \\'scheduledFargateTaskImageOptions.ephemeralStorageGiB\\' instead.');\n    }\n    if (props.runtimePlatform) {\n      Annotations.of(this).addWarningV2('@aws-cdk/aws-ecs-patterns:propertyIgnored', 'Property \\'runtimePlatform\\' is ignored.');\n    }\n\n    // Use the EcsTask as the target of the EventRule\n    this.task = new EcsTask( {\n      cluster: this.cluster,\n      taskDefinition: this.taskDefinition,\n      taskCount: this.desiredTaskCount,\n      subnetSelection: this.subnetSelection,\n      platformVersion: props.platformVersion,\n      securityGroups: props.securityGroups,\n      propagateTags: props.propagateTags,\n      tags: props.tags,\n    });\n\n    this.addTaskAsTarget(this.task);\n  }\n}", "language": "typescript"}
{"input": "CDK class HandlerFrameworkModule for AWS resource management", "output": "export class HandlerFrameworkModule extends Module {\n  private readonly renderer = new TypeScriptRenderer();\n  private readonly importer = new ModuleImporter();\n  private readonly _interfaces = new Map<string, InterfaceType>();\n  private _hasComponents = false;\n\n  /**\n   * Whether the module being generated will live inside of aws-cdk-lib/core.\n   */\n  public readonly isCoreInternal: boolean;\n\n  /**\n   * Whether the module being generated will be part of an alpha module.\n   */\n  public readonly isAlphaModule: boolean;\n\n  /**\n   * Whether the module contains provider framework components.\n   */\n  public get hasComponents() {\n    return this._hasComponents;\n  }\n\n  public constructor(fqn: string) {\n    super(fqn);\n    this.isCoreInternal = fqn.includes('core');\n    this.isAlphaModule = fqn.includes('alpha');\n  }\n\n  /**\n   * Build a framework component inside of this module.\n   */\n  public build(component: ComponentProps, codeDirectory: string) {\n    if (component.type === ComponentType.NO_OP) {\n      return;\n    }\n\n    this._hasComponents = true;\n\n    const handler = component.handler ?? 'index.handler';\n    const name = buildComponentName(this.fqn, component.type, handler);\n\n    const props: HandlerFrameworkClassProps = {\n      name,\n      handler,\n      codeDirectory,\n      runtime: component.runtime,\n      constructorVisibility: component.constructorVisibility,\n    };\n\n    switch (component.type) {\n      case ComponentType.FUNCTION: {\n        HandlerFrameworkClass.buildFunction(this, props);\n        break;\n      }\n      case ComponentType.SINGLETON_FUNCTION: {\n        HandlerFrameworkClass.buildSingletonFunction(this, props);\n        break;\n      }\n      case ComponentType.CUSTOM_RESOURCE_PROVIDER: {\n        HandlerFrameworkClass.buildCustomResourceProvider(this, props);\n        break;\n      }\n    }\n  }\n\n  /**\n   * Render module with components into an output file.\n   */\n  public renderTo(file: string) {\n    this.importer.importModulesInto(this);\n    fs.outputFileSync(file, this.renderer.render(this));\n  }\n\n  /**\n   * Register an external module to be imported into this module.\n   */\n  public registerImport(module: ImportableModule, options: ModuleImportOptions = {}) {\n    this.importer.registerImport(module, options);\n  }\n\n  /**\n   * Register an interface with this module.\n   */\n  public registerInterface(_interface: InterfaceType) {\n    this._interfaces.set(_interface.name, _interface);\n  }\n\n  /**\n   * Retrieve an interface that has been registered with this module.\n   */\n  public getInterface(name: string) {\n    return this._interfaces.get(name);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudFormation, ECR, Route 53, ACM resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props: TestStackProps) {\n    super(scope, id, props);\n\n    const repository = new codecommit.Repository(this, 'Repo', {\n      repositoryName: 'integ-amplify-app',\n    });\n\n    const app = new amplify.App(this, 'App', {\n      sourceCodeProvider: new amplify.CodeCommitSourceCodeProvider({ repository }),\n    });\n\n    const prodBranch = app.addBranch('main');\n    const devBranch = app.addBranch('dev');\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n\n    const customCertificate = new acm.Certificate(this, 'Certificate', {\n      domainName: `*.${props.domainName}`,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    const domain = app.addDomain(props.domainName, {\n      subDomains: [\n        {\n          branch: prodBranch,\n          prefix: 'prod',\n        },\n      ],\n      customCertificate,\n    });\n    domain.mapSubDomain(devBranch);\n  }\n}", "language": "typescript"}
{"input": "Stack that defines the bucket", "output": "class Producer extends cdk.Stack {\n  public readonly myBucket: s3.Bucket;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const bucket = new s3.Bucket(this, 'MyBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n    this.myBucket = bucket;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, AppSync, CloudFormation resources", "output": "class EventApiIamAuthStack extends cdk.Stack {\n  public readonly eventApi: appsync.EventApi;\n  public readonly lambdaTestFn: nodejs.NodejsFunction;\n\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    const iamProvider: appsync.AppSyncAuthProvider = {\n      authorizationType: appsync.AppSyncAuthorizationType.IAM,\n    };\n\n    this.eventApi = new appsync.EventApi(this, 'EventApiIamAuth', {\n      apiName: 'api-iam-auth-test',\n      authorizationConfig: {\n        authProviders: [\n          iamProvider,\n        ],\n      },\n    });\n\n    const defaultChannel = this.eventApi.addChannelNamespace('default');\n\n    const lambdaConfig: nodejs.NodejsFunctionProps = {\n      runtime: lambda.Runtime.NODEJS_22_X,\n      environment: {\n        EVENT_API_REALTIME_URL: `wss://${this.eventApi.realtimeDns}/event/realtime`,\n        EVENT_API_HTTP_URL: `https://${this.eventApi.httpDns}/event`,\n      },\n      bundling: {\n        bundleAwsSDK: true,\n      },\n      entry: path.join(__dirname, 'integ-assets/eventapi-grant-assertion/index.js'),\n      handler: 'handler',\n      timeout: cdk.Duration.seconds(15),\n    };\n\n    this.lambdaTestFn = new nodejs.NodejsFunction(this, 'IAMConfigTestFunction', lambdaConfig);\n\n    defaultChannel.grantPublishAndSubscribe(this.lambdaTestFn);\n    this.eventApi.grantConnect(this.lambdaTestFn);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates KMS, AppSync, CloudFormation resources", "output": "export class AppSyncCdkStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const postsGraphQLApi = new CfnGraphQLApi(this, \"PostsApiCdk\", {\n      name: \"posts-api-cdk\",\n      authenticationType: \"API_KEY\",\n    });\n\n    new CfnApiKey(this, \"PostsApiKey\", {\n      apiId: postsGraphQLApi.attrApiId,\n    });\n\n    const apiSchema = new CfnGraphQLSchema(this, \"PostsSchema\", {\n      apiId: postsGraphQLApi.attrApiId,\n      definition,\n    });\n\n    const dataSource = new CfnDataSource(this, \"PostsDataSource\", {\n      apiId: postsGraphQLApi.attrApiId,\n      name: \"PostsApiDataSource\",\n      type: \"HTTP\",\n      httpConfig: {\n        endpoint: \"https://jsonplaceholder.typicode.com\",\n      },\n    });\n\n    const getOneResolver = new CfnResolver(this, \"GetOneQueryResolver\", {\n      apiId: postsGraphQLApi.attrApiId,\n      typeName: \"Query\",\n      fieldName: \"getOne\",\n      dataSourceName: dataSource.name,\n      runtime: {\n        name: \"APPSYNC_JS\",\n        runtimeVersion: \"1.0.0\",\n      },\n      code: getOneCode,\n    });\n    getOneResolver.addDependency(apiSchema);\n\n    const getAllResolver = new CfnResolver(this, \"GetAllQueryResolver\", {\n      apiId: postsGraphQLApi.attrApiId,\n      typeName: \"Query\",\n      fieldName: \"all\",\n      dataSourceName: dataSource.name,\n      runtime: {\n        name: \"APPSYNC_JS\",\n        runtimeVersion: \"1.0.0\",\n      },\n      code: getAllCode,\n    });\n    getAllResolver.addDependency(apiSchema);\n\n    const saveResolver = new CfnResolver(this, \"SaveMutationResolver\", {\n      apiId: postsGraphQLApi.attrApiId,\n      typeName: \"Mutation\",\n      fieldName: \"save\",\n      dataSourceName: dataSource.name,\n      runtime: {\n        name: \"APPSYNC_JS\",\n        runtimeVersion: \"1.0.0\",\n      },\n      code: saveCode,\n    });\n    saveResolver.addDependency(apiSchema);\n\n    const deleteResolver = new CfnResolver(this, \"DeleteMutationResolver\", {\n      apiId: postsGraphQLApi.attrApiId,\n      typeName: \"Mutation\",\n      fieldName: \"delete\",\n      dataSourceName: dataSource.name,\n      runtime: {\n        name: \"APPSYNC_JS\",\n        runtimeVersion: \"1.0.0\",\n      },\n      code: deleteCode,\n    });\n    deleteResolver.addDependency(apiSchema);\n  }\n}", "language": "typescript"}
{"input": "CDK class CustomResource for AWS resource management", "output": "export class CustomResource extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.core.CustomResource';\n  private readonly resource: CfnResource;\n\n  constructor(scope: Construct, id: string, props: CustomResourceProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const type = renderResourceType(this, props.resourceType);\n    const pascalCaseProperties = props.pascalCaseProperties ?? false;\n    const properties = pascalCaseProperties ? uppercaseProperties(props.properties || {}) : (props.properties || {});\n\n    if (props.serviceTimeout !== undefined && !props.serviceTimeout.isUnresolved()) {\n      const serviceTimeoutSeconds = props.serviceTimeout.toSeconds();\n\n      if (serviceTimeoutSeconds < 1 || serviceTimeoutSeconds > 3600) {\n        throw new ValidationError(`serviceTimeout must either be between 1 and 3600 seconds, got ${serviceTimeoutSeconds}`, this);\n      }\n    }\n\n    const constructPropertiesPassed = {\n      ServiceToken: props.serviceToken,\n      ServiceTimeout: props.serviceTimeout?.toSeconds().toString(),\n    };\n\n    const hasCommonKeys = Object.keys(properties).some(key => key in constructPropertiesPassed);\n\n    if (hasCommonKeys) {\n      Annotations.of(this).addWarningV2('@aws-cdk/core:customResourcePropConflict', `The following keys will be overwritten as they exist in the 'properties' prop. Keys found: ${Object.keys(properties).filter(key => key in constructPropertiesPassed)}`);\n    }\n\n    this.resource = new CfnResource(this, 'Default', {\n      type,\n      properties: {\n        ...constructPropertiesPassed,\n        ...properties,\n      },\n    });\n\n    this.resource.applyRemovalPolicy(props.removalPolicy, {\n      default: RemovalPolicy.DESTROY,\n    });\n  }\n\n  /**\n   * The physical name of this custom resource.\n   */\n  public get ref() {\n    return this.resource.ref;\n  }\n\n  /**\n   * Returns the value of an attribute of the custom resource of an arbitrary\n   * type. Attributes are returned from the custom resource provider through the\n   * `Data` map where the key is the attribute name.\n   *\n   * @param attributeName the name of the attribute\n   * @returns a token for `Fn::GetAtt`. Use `Token.asXxx` to encode the returned `Reference` as a specific type or\n   * use the convenience `getAttString` for string attributes.\n   */\n  @MethodMetadata()\n  public getAtt(attributeName: string) {\n    return this.resource.getAtt(attributeName);\n  }\n\n  /**\n   * Returns the value of an attribute of the custom resource of type string.\n   * Attributes are returned from the custom resource provider through the\n   * `Data` map where the key is the attribute name.\n   *\n   * @param attributeName the name of the attribute\n   * @returns a token for `Fn::GetAtt` encoded as a string.\n   */\n  @MethodMetadata()\n  public getAttString(attributeName: string): string {\n    return Token.asString(this.getAtt(attributeName));\n  }\n}", "language": "typescript"}
{"input": "A custom resource provider that handles cluster operations. It serves multiple custom resources such as the cluster resource and the fargate resource. @internal", "output": "export class ClusterResourceProvider extends NestedStack {\n  public static getOrCreate(scope: Construct, props: ClusterResourceProviderProps) {\n    const stack = Stack.of(scope);\n    const uid = '@aws-cdk/aws-eks.ClusterResourceProvider';\n    return stack.node.tryFindChild(uid) as ClusterResourceProvider ?? new ClusterResourceProvider(stack, uid, props);\n  }\n\n  /**\n   * The custom resource provider to use for custom resources.\n   */\n  public readonly provider: cr.Provider;\n\n  private constructor(scope: Construct, id: string, props: ClusterResourceProviderProps) {\n    super(scope, id);\n\n    // The NPM dependency proxy-agent is required in order to support proxy routing with the AWS JS SDK.\n    const nodeProxyAgentLayer = new NodeProxyAgentLayer(this, 'NodeProxyAgentLayer');\n\n    const onEvent = new ClusterResourceOnEventFunction(this, 'OnEventHandler', {\n      description: 'onEvent handler for EKS cluster resource provider',\n      environment: {\n        AWS_STS_REGIONAL_ENDPOINTS: 'regional',\n        ...props.environment,\n      },\n      timeout: Duration.minutes(1),\n      vpc: props.subnets ? props.vpc : undefined,\n      vpcSubnets: props.subnets ? { subnets: props.subnets } : undefined,\n      securityGroups: props.securityGroup ? [props.securityGroup] : undefined,\n      // Allow user to override the layer.\n      layers: props.onEventLayer ? [props.onEventLayer] : [nodeProxyAgentLayer],\n    });\n\n    const isComplete = new ClusterResourceIsCompleteFunction(this, 'IsCompleteHandler', {\n      description: 'isComplete handler for EKS cluster resource provider',\n      environment: {\n        AWS_STS_REGIONAL_ENDPOINTS: 'regional',\n        ...props.environment,\n      },\n      timeout: Duration.minutes(1),\n      vpc: props.subnets ? props.vpc : undefined,\n      vpcSubnets: props.subnets ? { subnets: props.subnets } : undefined,\n      securityGroups: props.securityGroup ? [props.securityGroup] : undefined,\n      layers: [nodeProxyAgentLayer],\n    });\n\n    const disableLogging = props.disableLogging ?? true;\n\n    this.provider = new cr.Provider(this, 'Provider', {\n      onEventHandler: onEvent,\n      isCompleteHandler: isComplete,\n      totalTimeout: Duration.hours(1),\n      queryInterval: Duration.minutes(1),\n      vpc: props.subnets ? props.vpc : undefined,\n      vpcSubnets: props.subnets ? { subnets: props.subnets } : undefined,\n      securityGroups: props.securityGroup ? [props.securityGroup] : undefined,\n      disableWaiterStateMachineLogging: disableLogging,\n      // If logging is not disabled use default INFO level logging for provider lambdas\n      ...(disableLogging ? {} : {\n        frameworkLambdaLoggingLevel: lambda.ApplicationLogLevel.INFO,\n      }),\n    });\n  }\n\n  /**\n   * The custom resource service token for this provider.\n   */\n  public get serviceToken() { return this.provider.serviceToken; }\n}", "language": "typescript"}
{"input": "method to create a new EC2 instance with MySQL installed through User Data script see user_data/db_mysql txt file to see the User Data script", "output": "def create_db_mysql(self, vpc):\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2)\n        user_data = self.get_user_data(\"db_mysql\")\n        db = ec2.Instance(self, \"DBInLZ\",\n                 vpc=vpc,\n                 instance_type=ec2.InstanceType.of(ec2.InstanceClass.T3, ec2.InstanceSize.MEDIUM),\n                 machine_image=amzn_linux,\n                 user_data=ec2.UserData.custom(user_data),\n                 vpc_subnets=ec2.SubnetSelection(availability_zones=[LZ_NAME],subnet_type=ec2.SubnetType.PRIVATE_ISOLATED),\n                )\n        return db", "language": "python"}
{"input": "CDK Stack that creates Lambda, DynamoDB, API Gateway, CloudFormation resources", "output": "export class ApiLambdaCrudDynamoDBStack extends Stack {\n  constructor(app: App, id: string) {\n    super(app, id);\n\n    const dynamoTable = new Table(this, 'items', {\n      partitionKey: {\n        name: 'itemId',\n        type: AttributeType.STRING\n      },\n      tableName: 'items',\n\n      /**\n       *  The default removal policy is RETAIN, which means that cdk destroy will not attempt to delete\n       * the new table, and it will remain in your account until manually deleted. By setting the policy to\n       * DESTROY, cdk destroy will delete the table (even if it has data in it)\n       */\n      removalPolicy: RemovalPolicy.DESTROY, // NOT recommended for production code\n    });\n\n    const nodeJsFunctionProps: NodejsFunctionProps = {\n      bundling: {\n        externalModules: [\n          'aws-sdk', // Use the 'aws-sdk' available in the Lambda runtime\n        ],\n      },\n      depsLockFilePath: join(__dirname, 'lambdas', 'package-lock.json'),\n      environment: {\n        PRIMARY_KEY: 'itemId',\n        TABLE_NAME: dynamoTable.tableName,\n      },\n      runtime: Runtime.NODEJS_20_X,\n    }\n\n    // Create a Lambda function for each of the CRUD operations\n    const getOneLambda = new NodejsFunction(this, 'getOneItemFunction', {\n      entry: join(__dirname, 'lambdas', 'get-one.ts'),\n      ...nodeJsFunctionProps,\n    });\n    const getAllLambda = new NodejsFunction(this, 'getAllItemsFunction', {\n      entry: join(__dirname, 'lambdas', 'get-all.ts'),\n      ...nodeJsFunctionProps,\n    });\n    const createOneLambda = new NodejsFunction(this, 'createItemFunction', {\n      entry: join(__dirname, 'lambdas', 'create.ts'),\n      ...nodeJsFunctionProps,\n    });\n    const updateOneLambda = new NodejsFunction(this, 'updateItemFunction', {\n      entry: join(__dirname, 'lambdas', 'update-one.ts'),\n      ...nodeJsFunctionProps,\n    });\n    const deleteOneLambda = new NodejsFunction(this, 'deleteItemFunction', {\n      entry: join(__dirname, 'lambdas', 'delete-one.ts'),\n      ...nodeJsFunctionProps,\n    });\n\n    // Grant the Lambda function read access to the DynamoDB table\n    dynamoTable.grantReadWriteData(getAllLambda);\n    dynamoTable.grantReadWriteData(getOneLambda);\n    dynamoTable.grantReadWriteData(createOneLambda);\n    dynamoTable.grantReadWriteData(updateOneLambda);\n    dynamoTable.grantReadWriteData(deleteOneLambda);\n\n    // Integrate the Lambda functions with the API Gateway resource\n    const getAllIntegration = new LambdaIntegration(getAllLambda);\n    const createOneIntegration = new LambdaIntegration(createOneLambda);\n    const getOneIntegration = new LambdaIntegration(getOneLambda);\n    const updateOneIntegration = new LambdaIntegration(updateOneLambda);\n    const deleteOneIntegration = new LambdaIntegration(deleteOneLambda);\n\n\n    // Create an API Gateway resource for each of the CRUD operations\n    const api = new RestApi(this, 'itemsApi', {\n      restApiName: 'Items Service'\n      // In case you want to manage binary types, uncomment the following\n      // binaryMediaTypes: [\"*/*\"],\n    });\n\n    const items = api.root.addResource('items');\n    items.addMethod('GET', getAllIntegration);\n    items.addMethod('POST', createOneIntegration);\n    addCorsOptions(items);\n\n    const singleItem = items.addResource('{id}');\n    singleItem.addMethod('GET', getOneIntegration);\n    singleItem.addMethod('PATCH', updateOneIntegration);\n    singleItem.addMethod('DELETE', deleteOneIntegration);\n    addCorsOptions(singleItem);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF, CloudFormation operations", "output": "def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n    ##\n    ## List available Managed Rule Groups using AWS CLI\n    ## aws wafv2 list-available-managed-rule-groups --scope CLOUDFRONT\n    ##\n    managed_rules = [{\n      \"name\"            : \"AWSManagedRulesCommonRuleSet\",\n      \"priority\"        : 10,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesAmazonIpReputationList\",\n      \"priority\"        : 20,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesKnownBadInputsRuleSet\",\n      \"priority\"        : 30,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesSQLiRuleSet\",\n      \"priority\"        : 40,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesLinuxRuleSet\",\n      \"priority\"        : 50,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    },{\n      \"name\"            : \"AWSManagedRulesUnixRuleSet\",\n      \"priority\"        : 60,\n      \"override_action\" : \"none\",\n      \"excluded_rules\"  : [],\n    }]\n\n\n    #############################################################\n    ##\n    ## WAF - CloudFront\n    ##\n    #############################################################\n\n    wafacl = wafv2.CfnWebACL(self, id=\"WAF\",\n      default_action=wafv2.CfnWebACL.DefaultActionProperty(allow=wafv2.CfnWebACL.AllowActionProperty(), block=None),\n      ##\n      ## The scope of this Web ACL.\n      ## Valid options: CLOUDFRONT, REGIONAL.\n      ## For CLOUDFRONT, you must create your WAFv2 resources\n      ## in the US East (N. Virginia) Region, us-east-1\n      ## https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-wafv2-webacl.html#cfn-wafv2-webacl-scope\n      ##\n      scope=\"CLOUDFRONT\",\n      ##\n      ## Defines and enables Amazon CloudWatch metrics and web request sample collection.\n      ##\n      visibility_config=wafv2.CfnWebACL.VisibilityConfigProperty(\n        cloud_watch_metrics_enabled=True,\n        metric_name                =\"waf-cloudfront\",\n        sampled_requests_enabled   =True\n      ),\n      description = \"WAFv2 ACL for CloudFront\",\n      name        = \"waf-cloudfront\",\n      rules       = self.make_rules(managed_rules),\n    ) ## wafv2.CfnWebACL\n\n    Tags.of(wafacl).add(\"Name\",      \"waf-cloudfront\",     priority=300)\n    Tags.of(wafacl).add(\"Purpose\",   \"WAF for CloudFront\", priority=300)\n    Tags.of(wafacl).add(\"CreatedBy\", \"Cloudformation\",     priority=300)\n\n\n    CfnOutput(self, \"WafAclArn\", export_name=\"WafCloudFrontStack:WafAclCloudFrontArn\", value=wafacl.attr_arn)", "language": "python"}
{"input": "CDK class GraphqlApi for AWS resource management", "output": "export class GraphqlApi extends GraphqlApiBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-appsync.GraphqlApi';\n\n  /**\n   * Import a GraphQL API through this function\n   *\n   * @param scope scope\n   * @param id id\n   * @param attrs GraphQL API Attributes of an API\n   */\n  public static fromGraphqlApiAttributes(scope: Construct, id: string, attrs: GraphqlApiAttributes): IGraphqlApi {\n    const arn = attrs.graphqlApiArn ?? Stack.of(scope).formatArn({\n      service: 'appsync',\n      resource: `apis/${attrs.graphqlApiId}`,\n    });\n    class Import extends GraphqlApiBase {\n      public readonly apiId = attrs.graphqlApiId;\n      public readonly arn = arn;\n\n      // the GraphQL endpoint ARN is not required to identify an AppSync GraphQL API\n      // this value is only needed to construct event rules.\n      public readonly graphQLEndpointArn = attrs.graphQLEndpointArn ?? '';\n      public readonly visibility = attrs.visibility ?? Visibility.GLOBAL;\n      public readonly modes = attrs.modes ?? [];\n\n      constructor(s: Construct, i: string) {\n        super(s, i);\n      }\n    }\n    return new Import(scope, id);\n  }\n\n  /**\n   * an unique AWS AppSync GraphQL API identifier\n   * i.e. 'lxz775lwdrgcndgz3nurvac7oa'\n   */\n  public readonly apiId: string;\n\n  /**\n   * the ARN of the API\n   */\n  public readonly arn: string;\n\n  /**\n   * The GraphQL endpoint ARN\n   */\n  public readonly graphQLEndpointArn: string;\n\n  /**\n   * the URL of the endpoint created by AppSync\n   *\n   * @attribute GraphQlUrl\n   */\n  public readonly graphqlUrl: string;\n\n  /**\n   * the name of the API\n   */\n  public readonly name: string;\n\n  /**\n   * the visibility of the API\n   */\n  public readonly visibility: Visibility;\n\n  /**\n   * the schema attached to this api (only available for GraphQL APIs, not available for merged APIs)\n   */\n  public get schema(): ISchema {\n    if (this.definition.schema) {\n      return this.definition.schema;\n    }\n    throw new ValidationError('Schema does not exist for AppSync merged APIs.', this);\n  }\n\n  /**\n   * The Authorization Types for this GraphQL Api\n   */\n  public readonly modes: AuthorizationType[];\n\n  /**\n   * the configured API key, if present\n   *\n   * @default - no api key\n   */\n  public readonly apiKey?: string;\n\n  /**\n   * the CloudWatch Log Group for this API\n   */\n  public readonly logGroup: ILogGroup;\n\n  private definition: Definition;\n  private schemaResource?: CfnGraphQLSchema;\n  private api: CfnGraphQLApi;\n  private apiKeyResource?: CfnApiKey;\n  private domainNameResource?: CfnDomainName;\n  private mergedApiExecutionRole?: IRole;\n  private environmentVariables: { [key: string]: string } = {};\n\n  constructor(scope: Construct, id: string, props: GraphqlApiProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const defaultMode = props.authorizationConfig?.defaultAuthorization ??\n      { authorizationType: AuthorizationType.API_KEY };\n    const additionalModes = props.authorizationConfig?.additionalAuthorizationModes ?? [];\n    const modes = [defaultMode, ...additionalModes];\n\n    this.modes = modes.map((mode) => mode.authorizationType);\n\n    this.validateAuthorizationProps(modes);\n\n    if (!props.schema && !props.definition) {\n      throw new ValidationError('You must specify a GraphQL schema or source APIs in property definition.', this);\n    }\n    if ((props.schema !== undefined) === (props.definition !== undefined)) {\n      throw new ValidationError('You cannot specify both properties schema and definition.', this);\n    }\n    if (props.queryDepthLimit !== undefined && (props.queryDepthLimit < 0 || props.queryDepthLimit > 75)) {\n      throw new ValidationError('You must specify a query depth limit between 0 and 75.', this);\n    }\n    if (props.resolverCountLimit !== undefined && (props.resolverCountLimit < 0 || props.resolverCountLimit > 10000)) {\n      throw new ValidationError('You must specify a resolver count limit between 0 and 10000.', this);\n    }\n    if (!Token.isUnresolved(props.ownerContact) && props.ownerContact !== undefined && (props.ownerContact.length > 256)) {\n      throw new ValidationError('You must specify `ownerContact` as a string of 256 characters or less.', this);\n    }\n\n    this.definition = props.schema ? Definition.fromSchema(props.schema) : props.definition!;\n\n    if (this.definition.sourceApiOptions) {\n      this.setupMergedApiExecutionRole(this.definition.sourceApiOptions);\n    }\n\n    if (props.environmentVariables !== undefined) {\n      Object.entries(props.environmentVariables).forEach(([key, value]) => {\n        this.addEnvironmentVariable(key, value);\n      });\n    }\n    this.node.addValidation({ validate: () => this.validateEnvironmentVariables() });\n\n    this.visibility = props.visibility ?? Visibility.GLOBAL;\n\n    this.api = new CfnGraphQLApi(this, 'Resource', {\n      name: props.name,\n      authenticationType: defaultMode.authorizationType,\n      logConfig: this.setupLogConfig(props.logConfig),\n      openIdConnectConfig: this.setupOpenIdConnectConfig(defaultMode.openIdConnectConfig),\n      userPoolConfig: this.setupUserPoolConfig(defaultMode.userPoolConfig),\n      lambdaAuthorizerConfig: this.setupLambdaAuthorizerConfig(defaultMode.lambdaAuthorizerConfig),\n      additionalAuthenticationProviders: this.setupAdditionalAuthorizationModes(additionalModes),\n      xrayEnabled: props.xrayEnabled,\n      visibility: props.visibility,\n      mergedApiExecutionRoleArn: this.mergedApiExecutionRole?.roleArn,\n      apiType: this.definition.sourceApiOptions ? 'MERGED' : undefined,\n      introspectionConfig: props.introspectionConfig,\n      queryDepthLimit: props.queryDepthLimit,\n      resolverCountLimit: props.resolverCountLimit,\n      environmentVariables: Lazy.any({ produce: () => this.renderEnvironmentVariables() }),\n      ownerContact: props.ownerContact,\n    });\n\n    this.apiId = this.api.attrApiId;\n    this.arn = this.api.attrArn;\n    this.graphqlUrl = this.api.attrGraphQlUrl;\n    this.name = this.api.name;\n    this.graphQLEndpointArn = this.api.attrGraphQlEndpointArn;\n\n    if (this.definition.schema) {\n      this.schemaResource = new CfnGraphQLSchema(this, 'Schema', this.definition.schema.bind(this));\n    } else {\n      this.setupSourceApiAssociations();\n    }\n\n    if (props.domainName) {\n      this.domainNameResource = new CfnDomainName(this, 'DomainName', {\n        domainName: props.domainName.domainName,\n        certificateArn: props.domainName.certificate.certificateRef.certificateId,\n        description: `domain for ${this.name} at ${this.graphqlUrl}`,\n      });\n      const domainNameAssociation = new CfnDomainNameApiAssociation(this, 'DomainAssociation', {\n        domainName: props.domainName.domainName,\n        apiId: this.apiId,\n      });\n\n      domainNameAssociation.addDependency(this.domainNameResource);\n    }\n\n    if (modes.some((mode) => mode.authorizationType === AuthorizationType.API_KEY)) {\n      const config = modes.find((mode: AuthorizationMode) => {\n        return mode.authorizationType === AuthorizationType.API_KEY && mode.apiKeyConfig;\n      })?.apiKeyConfig;\n      this.apiKeyResource = this.createAPIKey(config);\n      if (this.schemaResource) {\n        this.apiKeyResource.addDependency(this.schemaResource);\n      }\n      this.apiKey = this.apiKeyResource.attrApiKey;\n    }\n\n    if (modes.some((mode) => mode.authorizationType === AuthorizationType.LAMBDA)) {\n      const config = modes.find((mode: AuthorizationMode) => {\n        return mode.authorizationType === AuthorizationType.LAMBDA && mode.lambdaAuthorizerConfig;\n      })?.lambdaAuthorizerConfig;\n\n      if (FeatureFlags.of(this).isEnabled(cxapi.APPSYNC_GRAPHQLAPI_SCOPE_LAMBDA_FUNCTION_PERMISSION)) {\n        config?.handler.addPermission(`${id}-appsync`, {\n          principal: new ServicePrincipal('appsync.amazonaws.com'),\n          action: 'lambda:InvokeFunction',\n          sourceArn: this.arn,\n        });\n      } else {\n        config?.handler.addPermission(`${id}-appsync`, {\n          principal: new ServicePrincipal('appsync.amazonaws.com'),\n          action: 'lambda:InvokeFunction',\n        });\n      }\n    }\n\n    const logGroupName = `/aws/appsync/apis/${this.apiId}`;\n\n    if (props.logConfig) {\n      const logRetention = new LogRetention(this, 'LogRetention', {\n        logGroupName: logGroupName,\n        retention: props.logConfig?.retention ?? RetentionDays.INFINITE,\n      });\n      this.logGroup = LogGroup.fromLogGroupArn(this, 'LogGroup', logRetention.logGroupArn);\n    } else {\n      this.logGroup = LogGroup.fromLogGroupName(this, 'LogGroup', logGroupName);\n    }\n  }\n\n  private setupSourceApiAssociations() {\n    this.definition.sourceApiOptions?.sourceApis.forEach(sourceApiConfig => {\n      const mergeType = sourceApiConfig.mergeType ?? MergeType.AUTO_MERGE;\n      let sourceApiIdentifier = sourceApiConfig.sourceApi.apiId;\n      let mergedApiIdentifier = this.apiId;\n\n      // This is protected by a feature flag because if there is an existing source api association that used the api id,\n      // updating it to use ARN as identifier leads to a resource replacement. ARN is recommended going forward because it allows support\n      // for both same account and cross account use cases.\n      if (FeatureFlags.of(this).isEnabled(cxapi.APPSYNC_ENABLE_USE_ARN_IDENTIFIER_SOURCE_API_ASSOCIATION)) {\n        sourceApiIdentifier = sourceApiConfig.sourceApi.arn;\n        mergedApiIdentifier = this.arn;\n      }\n\n      const association = new CfnSourceApiAssociation(this, `${sourceApiConfig.sourceApi.node.id}Association`, {\n        sourceApiIdentifier: sourceApiIdentifier,\n        mergedApiIdentifier: mergedApiIdentifier,\n        sourceApiAssociationConfig: {\n          mergeType: mergeType,\n        },\n        description: sourceApiConfig.description,\n      });\n\n      // Add dependency because the schema must be created first to create the source api association.\n      sourceApiConfig.sourceApi.addSchemaDependency(association);\n\n      // Add permissions to merged api execution role\n      const executionRole = this.mergedApiExecutionRole as IRole;\n      addSourceGraphQLPermission(association, executionRole);\n\n      if (mergeType === MergeType.AUTO_MERGE) {\n        addSourceApiAutoMergePermission(association, executionRole);\n      }\n    });\n  }\n\n  private setupMergedApiExecutionRole(sourceApiOptions: SourceApiOptions) {\n    if (sourceApiOptions.mergedApiExecutionRole) {\n      this.mergedApiExecutionRole = sourceApiOptions.mergedApiExecutionRole;\n    } else {\n      this.mergedApiExecutionRole = new Role(this, 'MergedApiExecutionRole', {\n        assumedBy: new ServicePrincipal('appsync.amazonaws.com'),\n      });\n    }\n  }\n\n  private validateAuthorizationProps(modes: AuthorizationMode[]) {\n    if (modes.filter((mode) => mode.authorizationType === AuthorizationType.LAMBDA).length > 1) {\n      throw new ValidationError('You can only have a single AWS Lambda function configured to authorize your API.', this);\n    }\n    modes.map((mode) => {\n      if (mode.authorizationType === AuthorizationType.OIDC && !mode.openIdConnectConfig) {\n        throw new ValidationError('Missing OIDC Configuration', this);\n      }\n      if (mode.authorizationType === AuthorizationType.USER_POOL && !mode.userPoolConfig) {\n        throw new ValidationError('Missing User Pool Configuration', this);\n      }\n      if (mode.authorizationType === AuthorizationType.LAMBDA && !mode.lambdaAuthorizerConfig) {\n        throw new ValidationError('Missing Lambda Configuration', this);\n      }\n    });\n    if (modes.filter((mode) => mode.authorizationType === AuthorizationType.API_KEY).length > 1) {\n      throw new ValidationError('You can\\'t duplicate API_KEY configuration. See https://docs.aws.amazon.com/appsync/latest/devguide/security.html', this);\n    }\n    if (modes.filter((mode) => mode.authorizationType === AuthorizationType.IAM).length > 1) {\n      throw new ValidationError('You can\\'t duplicate IAM configuration. See https://docs.aws.amazon.com/appsync/latest/devguide/security.html', this);\n    }\n  }\n\n  /**\n   * Add schema dependency to a given construct\n   *\n   * @param construct the dependee\n   */\n  @MethodMetadata()\n  public addSchemaDependency(construct: CfnResource): boolean {\n    if (this.schemaResource) {\n      construct.addDependency(this.schemaResource);\n    }\n    return true;\n  }\n\n  /**\n   * Add an environment variable to the construct.\n   */\n  @MethodMetadata()\n  public addEnvironmentVariable(key: string, value: string) {\n    if (this.definition.sourceApiOptions) {\n      throw new ValidationError('Environment variables are not supported for merged APIs', this);\n    }\n    if (!Token.isUnresolved(key) && !/^[A-Za-z]+\\w*$/.test(key)) {\n      throw new ValidationError(`Key '${key}' must begin with a letter and can only contain letters, numbers, and underscores`, this);\n    }\n    if (!Token.isUnresolved(key) && (key.length < 2 || key.length > 64)) {\n      throw new ValidationError(`Key '${key}' must be between 2 and 64 characters long, got ${key.length}`, this);\n    }\n    if (!Token.isUnresolved(value) && value.length > 512) {\n      throw new ValidationError(`Value for '${key}' is too long. Values can be up to 512 characters long, got ${value.length}`, this);\n    }\n\n    this.environmentVariables[key] = value;\n  }\n\n  private validateEnvironmentVariables() {\n    const errors: string[] = [];\n    const entries = Object.entries(this.environmentVariables);\n    if (entries.length > 50) {\n      errors.push(`Only 50 environment variables can be set, got ${entries.length}`);\n    }\n    return errors;\n  }\n\n  private renderEnvironmentVariables() {\n    return Object.entries(this.environmentVariables).length > 0 ? this.environmentVariables : undefined;\n  }\n\n  private setupLogConfig(config?: LogConfig) {\n    if (!config) return undefined;\n    const logsRoleArn: string = config.role?.roleRef.roleArn ?? new Role(this, 'ApiLogsRole', {\n      assumedBy: new ServicePrincipal('appsync.amazonaws.com'),\n      managedPolicies: [\n        ManagedPolicy.fromAwsManagedPolicyName('service-role/AWSAppSyncPushToCloudWatchLogs'),\n      ],\n    }).roleArn;\n    const fieldLogLevel: FieldLogLevel = config.fieldLogLevel ?? FieldLogLevel.NONE;\n    return {\n      cloudWatchLogsRoleArn: logsRoleArn,\n      excludeVerboseContent: config.excludeVerboseContent,\n      fieldLogLevel: fieldLogLevel,\n    };\n  }\n\n  private setupOpenIdConnectConfig(config?: OpenIdConnectConfig) {\n    if (!config) return undefined;\n    return {\n      authTtl: config.tokenExpiryFromAuth,\n      clientId: config.clientId,\n      iatTtl: config.tokenExpiryFromIssue,\n      issuer: config.oidcProvider,\n    };\n  }\n\n  private setupUserPoolConfig(config?: UserPoolConfig) {\n    if (!config) return undefined;\n    return {\n      userPoolId: config.userPool.userPoolId,\n      awsRegion: config.userPool.env.region,\n      appIdClientRegex: config.appIdClientRegex,\n      defaultAction: config.defaultAction || UserPoolDefaultAction.ALLOW,\n    };\n  }\n\n  private setupLambdaAuthorizerConfig(config?: LambdaAuthorizerConfig) {\n    if (!config) return undefined;\n    return {\n      authorizerResultTtlInSeconds: config.resultsCacheTtl?.toSeconds(),\n      authorizerUri: config.handler.functionArn,\n      identityValidationExpression: config.validationRegex,\n    };\n  }\n\n  private setupAdditionalAuthorizationModes(modes?: AuthorizationMode[]) {\n    if (!modes || modes.length === 0) return undefined;\n    return modes.reduce<CfnGraphQLApi.AdditionalAuthenticationProviderProperty[]>((acc, mode) => [\n      ...acc, {\n        authenticationType: mode.authorizationType,\n        userPoolConfig: this.setupUserPoolConfig(mode.userPoolConfig),\n        openIdConnectConfig: this.setupOpenIdConnectConfig(mode.openIdConnectConfig),\n        lambdaAuthorizerConfig: this.setupLambdaAuthorizerConfig(mode.lambdaAuthorizerConfig),\n      },\n    ], []);\n  }\n\n  private createAPIKey(config?: ApiKeyConfig) {\n    if (config?.expires?.isBefore(Duration.days(1)) || config?.expires?.isAfter(Duration.days(365))) {\n      throw Error('API key expiration must be between 1 and 365 days.');\n    }\n    const expires = config?.expires ? config?.expires.toEpoch() : undefined;\n    return new CfnApiKey(this, `${config?.name || 'Default'}ApiKey`, {\n      expires,\n      description: config?.description,\n      apiId: this.apiId,\n    });\n  }\n\n  /**\n   * The AppSyncDomainName of the associated custom domain\n   */\n  public get appSyncDomainName(): string {\n    if (!this.domainNameResource) {\n      throw new ValidationError('Cannot retrieve the appSyncDomainName without a domainName configuration', this);\n    }\n    return this.domainNameResource.attrAppSyncDomainName;\n  }\n}", "language": "typescript"}
{"input": "Lambda code from an S3 archive.", "output": "export class S3Code extends Code {\n  public readonly isInline = false;\n  private bucketName: string;\n\n  constructor(bucket: s3.IBucket, private key: string, private objectVersion?: string) {\n    super();\n\n    if (!bucket.bucketName) {\n      throw new ValidationError('bucketName is undefined for the provided bucket', bucket);\n    }\n\n    this.bucketName = bucket.bucketName;\n  }\n\n  public bind(_scope: Construct): CodeConfig {\n    return {\n      s3Location: {\n        bucketName: this.bucketName,\n        objectKey: this.key,\n        objectVersion: this.objectVersion,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function checkParsingPair", "output": "const checkParsingPair = (\n      statistic: string,\n      statPrefix: string,\n      statName: string,\n      isPercent: boolean,\n      canBeSingleStat: boolean,\n      asSingleStatStr?: string,\n      lower?: number,\n      upper?: number,\n    ) => {\n      const parsed = parseStatistic(statistic);\n      expect(parsed.type).toEqual('pair');\n      expect((parsed as PairStatistic).isPercent).toEqual(isPercent);\n      expect((parsed as PairStatistic).lower).toEqual(lower);\n      expect((parsed as PairStatistic).upper).toEqual(upper);\n      expect((parsed as PairStatistic).canBeSingleStat).toEqual(canBeSingleStat);\n      expect((parsed as PairStatistic).asSingleStatStr).toEqual(asSingleStatStr);\n      expect((parsed as PairStatistic).statPrefix).toEqual(statPrefix);\n      expect((parsed as PairStatistic).statName).toEqual(statName);\n    }", "language": "typescript"}
{"input": "Represents an existing file system used as the destination file system for ReplicationConfiguration.", "output": "class ExistingFileSystem extends ReplicationConfiguration {\n  constructor(props: ExistingFileSystemProps) {\n    super(props);\n  }\n}", "language": "typescript"}
{"input": "A Step Functions Task to invoke a model in Bedrock.", "output": "export class BedrockInvokeModel extends sfn.TaskStateBase {\n  /**\n   * A Step Functions Task using JSONPath to invoke a model in Bedrock.\n   */\n  public static jsonPath(scope: Construct, id: string, props: BedrockInvokeModelJsonPathProps) {\n    return new BedrockInvokeModel(scope, id, props);\n  }\n  /**\n   * A Step Functions Task using JSONata to invoke a model in Bedrock.\n   */\n  public static jsonata(scope: Construct, id: string, props: BedrockInvokeModelJsonataProps) {\n    return new BedrockInvokeModel(scope, id, {\n      ...props,\n      queryLanguage: sfn.QueryLanguage.JSONATA,\n    });\n  }\n  private static readonly SUPPORTED_INTEGRATION_PATTERNS: sfn.IntegrationPattern[] = [\n    sfn.IntegrationPattern.REQUEST_RESPONSE,\n  ];\n\n  protected readonly taskMetrics: sfn.TaskMetricsConfig | undefined;\n  protected readonly taskPolicies: iam.PolicyStatement[] | undefined;\n\n  private readonly integrationPattern: sfn.IntegrationPattern;\n  private readonly modelOutput?: BedrockInvokeModelOutputProps;\n\n  constructor(scope: Construct, id: string, private readonly props: BedrockInvokeModelProps) {\n    super(scope, id, props);\n\n    this.modelOutput = props.output;\n    this.integrationPattern = props.integrationPattern ?? sfn.IntegrationPattern.REQUEST_RESPONSE;\n\n    validatePatternSupported(this.integrationPattern, BedrockInvokeModel.SUPPORTED_INTEGRATION_PATTERNS);\n\n    const useNewS3UriParamsForTask = FeatureFlags.of(this).isEnabled(cxapi.USE_NEW_S3URI_PARAMETERS_FOR_BEDROCK_INVOKE_MODEL_TASK);\n\n    const isBodySpecified = props.body !== undefined;\n\n    let isInputSpecified: boolean;\n    if (!useNewS3UriParamsForTask) {\n      isInputSpecified = (props.input !== undefined && props.input.s3Location !== undefined) || (props.inputPath !== undefined);\n    } else {\n      // Either specific props.input with bucket name and object key or input s3 path\n      isInputSpecified = props.input !== undefined ? props.input?.s3Location !== undefined || props.input?.s3InputUri !== undefined : false;\n    }\n\n    if (isBodySpecified && isInputSpecified) {\n      throw new ValidationError('Either `body` or `input` must be specified, but not both.', this);\n    }\n    if (!isBodySpecified && !isInputSpecified) {\n      throw new ValidationError('Either `body` or `input` must be specified.', this);\n    }\n    if (props.input?.s3Location?.objectVersion !== undefined) {\n      throw new ValidationError('Input S3 object version is not supported.', this);\n    }\n    if (props.output?.s3Location?.objectVersion !== undefined) {\n      throw new ValidationError('Output S3 object version is not supported.', this);\n    }\n    if (props.input?.s3InputUri && props.input.s3Location || props.output?.s3OutputUri && props.output.s3Location) {\n      throw new ValidationError('Either specify S3 Uri or S3 location, but not both.', this);\n    }\n    if (useNewS3UriParamsForTask && (props.input?.s3InputUri === '' || props.output?.s3OutputUri === '')) {\n      throw new ValidationError('S3 Uri cannot be an empty string', this);\n    }\n\n    // Warning to let users know about the newly introduced props\n    if (props.inputPath || props.outputPath && !useNewS3UriParamsForTask) {\n      Annotations.of(scope).addWarningV2('aws-cdk-lib/aws-stepfunctions-taks',\n        'These props will set the value of inputPath/outputPath as s3 URI under input/output field in state machine JSON definition. To modify the behaviour set feature flag `@aws-cdk/aws-stepfunctions-tasks:useNewS3UriParametersForBedrockInvokeModelTask\": true` and use props input.s3InputUri/output.s3OutputUri');\n    }\n\n    this.taskPolicies = this.renderPolicyStatements();\n  }\n\n  private renderPolicyStatements(): iam.PolicyStatement[] {\n    const useNewS3UriParamsForTask = FeatureFlags.of(this).isEnabled(cxapi.USE_NEW_S3URI_PARAMETERS_FOR_BEDROCK_INVOKE_MODEL_TASK);\n    const policyStatements = [\n      new iam.PolicyStatement({\n        actions: ['bedrock:InvokeModel'],\n        resources: [this.props.model.modelArn],\n      }),\n    ];\n\n    // For Compatibility with existing behaviour of input path\n    if (this.props.input?.s3InputUri !== undefined || (!useNewS3UriParamsForTask && this.props.inputPath !== undefined)) {\n      policyStatements.push(\n        new iam.PolicyStatement({\n          actions: ['s3:GetObject'],\n          resources: [\n            Stack.of(this).formatArn({\n              region: '',\n              account: '',\n              service: 's3',\n              resource: '*',\n            }),\n          ],\n        }),\n      );\n    } else if (this.props.input !== undefined && this.props.input.s3Location !== undefined) {\n      policyStatements.push(\n        new iam.PolicyStatement({\n          actions: ['s3:GetObject'],\n          resources: [\n            Stack.of(this).formatArn({\n              region: '',\n              account: '',\n              service: 's3',\n              resource: this.props.input?.s3Location?.bucketName,\n              resourceName: this.props.input?.s3Location?.objectKey,\n            }),\n          ],\n        }),\n      );\n    }\n\n    // For Compatibility with existing behaviour of output path\n    if (this.modelOutput?.s3OutputUri !== undefined || (!useNewS3UriParamsForTask && this.props.outputPath !== undefined)) {\n      policyStatements.push(\n        new iam.PolicyStatement({\n          actions: ['s3:PutObject'],\n          resources: [\n            Stack.of(this).formatArn({\n              region: '',\n              account: '',\n              service: 's3',\n              resource: '*',\n            }),\n          ],\n        }),\n      );\n    } else if (this.modelOutput !== undefined && this.modelOutput.s3Location !== undefined) {\n      policyStatements.push(\n        new iam.PolicyStatement({\n          actions: ['s3:PutObject'],\n          resources: [\n            Stack.of(this).formatArn({\n              region: '',\n              account: '',\n              service: 's3',\n              resource: this.modelOutput?.s3Location?.bucketName,\n              resourceName: this.modelOutput?.s3Location?.objectKey,\n            }),\n          ],\n        }),\n      );\n    }\n\n    if (this.props.guardrail) {\n      const isArn = this.props.guardrail.guardrailIdentifier.startsWith('arn:');\n      policyStatements.push(\n        new iam.PolicyStatement({\n          actions: ['bedrock:ApplyGuardrail'],\n          resources: [\n            isArn\n              ? this.props.guardrail.guardrailIdentifier\n              : Stack.of(this).formatArn({\n                service: 'bedrock',\n                resource: 'guardrail',\n                resourceName: this.props.guardrail.guardrailIdentifier,\n              }),\n          ],\n        }),\n      );\n    }\n\n    return policyStatements;\n  }\n\n  /**\n   * Provides the Bedrock InvokeModel service integration task configuration\n   *\n   * @internal\n   */\n  protected _renderTask(topLevelQueryLanguage?: sfn.QueryLanguage): any {\n    const queryLanguage = sfn._getActualQueryLanguage(topLevelQueryLanguage, this.props.queryLanguage);\n    const useNewS3UriParamsForTask = FeatureFlags.of(this).isEnabled(cxapi.USE_NEW_S3URI_PARAMETERS_FOR_BEDROCK_INVOKE_MODEL_TASK);\n    const inputSource = this.getInputSource(this.props.input, this.props.inputPath, useNewS3UriParamsForTask);\n    const outputSource = this.getOutputSource(this.props.output, this.props.outputPath, useNewS3UriParamsForTask);\n    return {\n      Resource: integrationResourceArn('bedrock', 'invokeModel'),\n      ...this._renderParametersOrArguments({\n        ModelId: this.props.model.modelArn,\n        Accept: this.props.accept,\n        ContentType: this.props.contentType,\n        Body: this.props.body?.value,\n        Input: inputSource ? { S3Uri: inputSource } : undefined,\n        Output: outputSource ? { S3Uri: outputSource } : undefined,\n        GuardrailIdentifier: this.props.guardrail?.guardrailIdentifier,\n        GuardrailVersion: this.props.guardrail?.guardrailVersion,\n        Trace: this.props.traceEnabled === undefined\n          ? undefined\n          : this.props.traceEnabled\n            ? 'ENABLED'\n            : 'DISABLED',\n      }, queryLanguage),\n    };\n  }\n\n  private getInputSource(props?: BedrockInvokeModelInputProps, inputPath?: string, useNewS3UriParamsForTask?: boolean): string | undefined {\n    if (props?.s3Location) {\n      return `s3://${props.s3Location.bucketName}/${props.s3Location.objectKey}`;\n    } else if (useNewS3UriParamsForTask && props?.s3InputUri) {\n      return props.s3InputUri;\n    } else if (!useNewS3UriParamsForTask && inputPath) {\n      return inputPath;\n    }\n    return undefined;\n  }\n\n  private getOutputSource(props?: BedrockInvokeModelOutputProps, outputPath?: string, useNewS3UriParamsForTask?: boolean): string | undefined {\n    if (props?.s3Location) {\n      return `s3://${props.s3Location.bucketName}/${props.s3Location.objectKey}`;\n    } else if (useNewS3UriParamsForTask && props?.s3OutputUri) {\n      return props.s3OutputUri;\n    } else if (!useNewS3UriParamsForTask && outputPath) {\n      return outputPath;\n    }\n    return undefined;\n  }\n}", "language": "typescript"}
{"input": "Types of PII in the domain of IT (Information Technology).", "output": "export class InformationTechnologyPIIType extends PIIType {\n  /**\n   * A web address, such as www.example.com.\n   */\n  public static readonly URL = new InformationTechnologyPIIType('URL');\n  /**\n   * An IPv4 address, such as 198.51.100.0.\n   */\n  public static readonly IP_ADDRESS = new InformationTechnologyPIIType('IP_ADDRESS');\n  /**\n   * A media access control (MAC) address assigned to a network interface.\n   */\n  public static readonly MAC_ADDRESS = new InformationTechnologyPIIType('MAC_ADDRESS');\n  /**\n   * A unique identifier that's associated with a secret access key. You use\n   * the access key ID and secret access key to sign programmatic AWS requests\n   * cryptographically.\n   */\n  public static readonly AWS_ACCESS_KEY = new InformationTechnologyPIIType('AWS_ACCESS_KEY');\n  /**\n   * A unique identifier that's associated with a secret access key. You use\n   * the access key ID and secret access key to sign programmatic AWS requests\n   * cryptographically.\n   */\n  public static readonly AWS_SECRET_KEY = new InformationTechnologyPIIType('AWS_SECRET_KEY');\n\n  private constructor(value: string) { super(value); }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, IAM, WAF resources", "output": "export class OpenSearchSetupStack extends Stack {\n    \n    private readonly STACK_NAMING_PREFIX: string = 'cw-to-os';\n    private readonly STACK_RESOURCE_NAMING_PREFIX: string = 'OpenSearchSetup';\n    private readonly COLLECTION_NAME: string = `${this.STACK_NAMING_PREFIX}-col`;\n    private readonly DATA_ACCESS_POLICY_NAME: string = `${this.STACK_NAMING_PREFIX}-data-pol`;\n    private readonly NETWORK_POLICY_NAME: string = `${this.STACK_NAMING_PREFIX}-net-pol`;\n    private readonly ENCRYPTION_POLICY_NAME: string = `${this.STACK_NAMING_PREFIX}-enc-pol`;\n    private readonly VPC_ENDPOINT_NAME: string = `${this.STACK_NAMING_PREFIX}-vpc`;\n    private readonly PIPELINE_NAME: string = `${this.STACK_NAMING_PREFIX}-pipe`;\n\n    public readonly ingestionEndPointURL: string;\n    \n    constructor(scope: Construct, id: string, props?: StackProps) {\n        super(scope, id, props);\n\n        // Create VPC\n        const vpc = new Vpc(this, `${this.STACK_RESOURCE_NAMING_PREFIX}-vpc`);\n\n        // Create Security Group\n        const securityGroup = new SecurityGroup(this, `${this.STACK_RESOURCE_NAMING_PREFIX}-security-group`, {\n            description: 'Security group for OpenSearch',\n            vpc: vpc,\n            allowAllOutbound: true,\n            });\n\n        securityGroup.addIngressRule(Peer.anyIpv4(), Port.tcp(443));\n        securityGroup.connections.allowFrom(\n            securityGroup,\n            Port.allTraffic(),\n            'Allow ingress from the same SecurityGroup',\n        );\n        \n        // Create VPC Endpoint\n        const vpcEndpoint = new CfnVpcEndpoint(this, `${this.STACK_RESOURCE_NAMING_PREFIX}VpcEndpoint`, {\n            name: this.VPC_ENDPOINT_NAME,\n            vpcId: vpc.vpcId,\n            subnetIds: vpc.privateSubnets.map((subnet) => subnet.subnetId),\n            securityGroupIds: [securityGroup.securityGroupId],\n        });\n        \n        // Create OpenSearch Serverless network security policy\n        const cfnNetworkAccessPolicy = new CfnSecurityPolicy(this, `${this.STACK_RESOURCE_NAMING_PREFIX}NetworkPolicy`, {\n          name: this.NETWORK_POLICY_NAME,\n          type: 'network',\n          policy: JSON.stringify([\n              {\n              AllowFromPublic: false,\n              Rules: [\n                  {\n                  ResourceType: 'collection',\n                  Resource: [`collection/${this.COLLECTION_NAME}`],\n                  },\n              ],\n              SourceVPCEs: [vpcEndpoint.attrId],\n              },\n              {\n              AllowFromPublic: true,\n              Rules: [\n                  {\n                  ResourceType: 'dashboard',\n                  Resource: [`collection/${this.COLLECTION_NAME}`],\n                  },\n              ],\n              },\n          ]),\n      });\n\n      // Create OpenSearch Serverless encryption policy\n      const cfnEncryptionPolicy = new CfnSecurityPolicy(this, `${this.STACK_RESOURCE_NAMING_PREFIX}EncryptionPolicy`, {\n            name: this.ENCRYPTION_POLICY_NAME,\n            type: 'encryption',\n            policy: JSON.stringify({\n            Rules: [\n                {\n                ResourceType: 'collection',\n                Resource: [`collection/${this.COLLECTION_NAME}`],\n                }\n            ],\n            AWSOwnedKey: true\n            })\n        });\n\n        // Create OpenSearch Serverless collection\n        const cfnCollection = new CfnCollection(\n            this,\n            `${this.COLLECTION_NAME}Collection`,\n            {\n            name: this.COLLECTION_NAME,\n            description: 'OpenSearch serverless collection to be used for search from CDK',\n            type: 'SEARCH',\n            },\n        );\n\n        cfnCollection.addDependency(cfnEncryptionPolicy);\n        cfnCollection.addDependency(cfnNetworkAccessPolicy);\n\n        // Create IAM role for OpenSearch Ingestion pipeline\n        const pipelineRole = new Role(this, `${this.STACK_RESOURCE_NAMING_PREFIX}PipelineRole`, {\n            roleName: `${this.STACK_RESOURCE_NAMING_PREFIX}PipelineRole`,\n            assumedBy: new ServicePrincipal('osis-pipelines.amazonaws.com'),\n            inlinePolicies: {\n            'OSISPipelineRolePolicy': this.pipelinePolicies(cfnCollection.attrArn)\n            }\n        });   \n\n        // Create OpenSearch Ingestion pipeline        \n        const cfnPipeline = new CfnPipeline(this, `${this.STACK_RESOURCE_NAMING_PREFIX}Pipeline`, {\n            maxUnits: 4,\n            minUnits: 2,\n            bufferOptions: {\n              persistentBufferEnabled: true\n            },\n            pipelineConfigurationBody: this.getPipelineConfiguration(pipelineRole.roleArn, cfnCollection.attrCollectionEndpoint),\n            pipelineName: this.PIPELINE_NAME,\n        });\n\n        this.ingestionEndPointURL = Fn.select(0, cfnPipeline.attrIngestEndpointUrls);\n\n        cfnPipeline.addDependency(cfnCollection);\n\n        // Create a dashboard access role\n        const dashboardAccessRole = new Role(this, `${this.STACK_RESOURCE_NAMING_PREFIX}DashboardAccessRole`, {\n          assumedBy: new AccountPrincipal(this.account) ,\n        });\n    \n        dashboardAccessRole.attachInlinePolicy(\n          new Policy(this, `${this.STACK_RESOURCE_NAMING_PREFIX}DashboardAccessPolicy`, {\n            statements: [\n              new PolicyStatement({\n                effect: Effect.ALLOW,\n                resources: ['*'],\n                actions: ['aoss:*'],\n              }),\n            ],\n          }),\n        );\n\n        // Create OpenSearch Serverless data access policy\n        const data_access_policy_arns: string[] = [pipelineRole.roleArn, dashboardAccessRole.roleArn];\n\n        const cfnDataAccessPolicy = new CfnAccessPolicy(this, `${this.STACK_NAMING_PREFIX}AccessPolicy`, {\n            name: this.DATA_ACCESS_POLICY_NAME,\n            type: 'data',\n            policy: JSON.stringify([\n                {\n                Rules: [\n                    {\n                    ResourceType: 'index',\n                    Resource: [`index/${this.COLLECTION_NAME}/*`],\n                    Permission: [\n                        'aoss:CreateIndex',\n                        'aoss:DescribeIndex',\n                        'aoss:ReadDocument',\n                        'aoss:WriteDocument',\n                        'aoss:UpdateIndex',\n                        'aoss:DeleteIndex',\n                    ],\n                    },\n                    {\n                    ResourceType: 'collection',\n                    Resource: [`collection/${this.COLLECTION_NAME}`],\n                    Permission: [\n                        'aoss:CreateCollectionItems',\n                        'aoss:DeleteCollectionItems',\n                        'aoss:UpdateCollectionItems',\n                        'aoss:DescribeCollectionItems',\n                    ],\n                    },\n                ],\n                Principal: data_access_policy_arns,\n                },\n            ]),\n        });\n        \n        cfnDataAccessPolicy.addDependency(cfnCollection);\n        cfnDataAccessPolicy.addDependency(cfnPipeline);\n    }\n\n    pipelinePolicies(collectionArn: string) {\n      const policyDocument = new PolicyDocument();\n      policyDocument.addStatements(\n        new PolicyStatement({\n          'effect': Effect.ALLOW,\n          \"resources\": [\"*\"],\n          \"actions\": [\n            \"aoss:BatchGetCollection\"\n          ]\n      }));\n      policyDocument.addStatements(\n        new PolicyStatement({\n          'effect': Effect.ALLOW,\n          \"resources\": [collectionArn],\n          \"actions\": [\n            \"aoss:APIAccessAll\"\n          ]\n      }));\n      policyDocument.addStatements(\n        new PolicyStatement({\n          'effect': Effect.ALLOW,\n          \"resources\": [`arn:aws:aoss:*:${this.account}:dashboards/default`],\n          \"actions\": [\n            \"aoss:DashboardsAccessAll\"\n          ]\n      }));\n      policyDocument.addStatements(\n        new PolicyStatement({\n          'effect': Effect.ALLOW,\n          \"resources\": [\"*\"],\n          \"actions\": [\n            \"aoss:CreateSecurityPolicy\",\n            \"aoss:GetSecurityPolicy\",\n            \"aoss:UpdateSecurityPolicy\"\n          ],\n          \"conditions\": {\n            \"StringEquals\": {\n              \"aoss:collection\": this.COLLECTION_NAME\n            }\n          }\n      }));\n      return policyDocument;\n    }\n\n    getPipelineConfiguration(roleArn: string, collectionEndPoint: string) {\n      let pipelineConfigurationTemplate = readFileSync('resources/pipeline/configuration.yaml').toString()\n\n      const formattedPipelineConfiguration = \n      pipelineConfigurationTemplate\n        .replace('<COLLECTION_ENDPOINT>', collectionEndPoint)\n        .replace('<ROLE_ARN>', roleArn)\n        .replace('<REGION>', this.region)\n        .replace('<NETWORK_POLICY_NAME>', this.NETWORK_POLICY_NAME);\n\n      return formattedPipelineConfiguration;\n    }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, IAM, KMS, WAF resources", "output": "class TestStack extends Stack {\n  public readonly sourceBucket: s3.Bucket;\n  public readonly destinationBucket: s3.Bucket;\n  public readonly replicationRole: iam.Role;\n\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    this.destinationBucket = new s3.Bucket(this, 'DestinationBucket', {\n      versioned: true,\n      autoDeleteObjects: true,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const destinationKmsKey = new kms.Key(this, 'DestinationKmsKey', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n    const sourceKmsKey = new kms.Key(this, 'SourceKmsKey', {\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    this.replicationRole = new iam.Role(this, 'ReplicationRole', {\n      assumedBy: new iam.ServicePrincipal('s3.amazonaws.com'),\n    });\n\n    this.sourceBucket = new s3.Bucket(this, 'SourceBucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n      versioned: true,\n      encryptionKey: sourceKmsKey,\n      replicationRole: this.replicationRole,\n      replicationRules: [\n        {\n          destination: this.destinationBucket,\n          priority: 2,\n          sseKmsEncryptedObjects: true,\n          kmsKey: destinationKmsKey,\n          replicationTimeControl: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n          metrics: s3.ReplicationTimeValue.FIFTEEN_MINUTES,\n        },\n      ],\n    });\n\n    this.sourceBucket.grantReplicationPermission(this.replicationRole, {\n      sourceDecryptionKey: sourceKmsKey,\n      destinations: [\n        { encryptionKey: destinationKmsKey, bucket: this.destinationBucket },\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class MyCode for AWS resource management", "output": "class MyCode extends lambda.Code {\n      public readonly isInline: boolean;\n      constructor(private readonly config: lambda.CodeConfig) {\n        super();\n        this.isInline = 'inlineCode' in config;\n      }\n\n      public bind(_scope: constructs.Construct): lambda.CodeConfig {\n        return this.config;\n      }\n    }", "language": "typescript"}
{"input": "CDK class Domain for AWS resource management", "output": "export class Domain extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-amplify-alpha.Domain';\n  /**\n   * The ARN of the domain\n   *\n   * @attribute\n   */\n  public readonly arn: string;\n\n  /**\n   * The DNS Record for certificate verification\n   *\n   * @attribute\n   */\n  public readonly certificateRecord: string;\n\n  /**\n   * The name of the domain\n   *\n   * @attribute\n   */\n  public readonly domainName: string;\n\n  /**\n   * The status of the domain association\n   *\n   * @attribute\n   */\n  public readonly domainStatus: string;\n\n  /**\n   * The reason for the current status of the domain\n   *\n   * @attribute\n   */\n  public readonly statusReason: string;\n\n  /**\n   * Branch patterns for the automatically created subdomain.\n   *\n   * @attribute\n   */\n  public readonly domainAutoSubDomainCreationPatterns: string[];\n\n  /**\n   * The IAM service role for the subdomain.\n   *\n   * @attribute\n   */\n  public readonly domainAutoSubDomainIamRole: string;\n\n  /**\n   * Specifies whether the automated creation of subdomains for branches is enabled.\n   *\n   * @attribute\n   */\n  public readonly domainEnableAutoSubDomain: IResolvable;\n\n  private readonly subDomains: SubDomain[];\n\n  constructor(scope: Construct, id: string, props: DomainProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.subDomains = props.subDomains || [];\n\n    const domainName = props.domainName || id;\n    if (!Token.isUnresolved(domainName) && domainName.length > 255) {\n      throw new ValidationError(`Domain name must be 255 characters or less, got: ${domainName.length} characters.`, this);\n    }\n    if (!Token.isUnresolved(domainName) && !/^(((?!-)[A-Za-z0-9-]{0,62}[A-Za-z0-9])\\.)+((?!-)[A-Za-z0-9-]{1,62}[A-Za-z0-9])(\\.)?$/.test(domainName)) {\n      throw new ValidationError(`Domain name must be a valid hostname, got: ${domainName}.`, this);\n    }\n\n    const domain = new CfnDomain(this, 'Resource', {\n      appId: props.app.appId,\n      domainName,\n      subDomainSettings: Lazy.any({ produce: () => this.renderSubDomainSettings() }, { omitEmptyArray: true }),\n      enableAutoSubDomain: !!props.enableAutoSubdomain,\n      autoSubDomainCreationPatterns: props.autoSubdomainCreationPatterns || ['*', 'pr*'],\n      autoSubDomainIamRole: props.autoSubDomainIamRole?.roleArn,\n      certificateSettings: props.customCertificate ? {\n        certificateType: 'CUSTOM',\n        customCertificateArn: props.customCertificate.certificateArn,\n      } : undefined,\n    });\n\n    this.arn = domain.attrArn;\n    this.certificateRecord = domain.attrCertificateRecord;\n    this.domainName = domain.attrDomainName;\n    this.domainStatus = domain.attrDomainStatus;\n    this.statusReason = domain.attrStatusReason;\n    this.domainAutoSubDomainCreationPatterns = domain.attrAutoSubDomainCreationPatterns;\n    this.domainAutoSubDomainIamRole = domain.attrAutoSubDomainIamRole;\n    this.domainEnableAutoSubDomain = domain.attrEnableAutoSubDomain;\n\n    this.node.addValidation({ validate: () => this.validateDomain() });\n  }\n\n  /**\n   * Maps a branch to a sub domain\n   *\n   * @param branch The branch\n   * @param prefix The prefix. Use '' to map to the root of the domain. Defaults to branch name.\n   */\n  @MethodMetadata()\n  public mapSubDomain(branch: IBranch, prefix?: string) {\n    this.subDomains.push({ branch, prefix });\n    return this;\n  }\n\n  /**\n   * Maps a branch to the domain root\n   */\n  @MethodMetadata()\n  public mapRoot(branch: IBranch) {\n    return this.mapSubDomain(branch, '');\n  }\n\n  private validateDomain() {\n    if (this.subDomains.length === 0) {\n      return ['The domain doesn\\'t contain any subdomains'];\n    }\n\n    return [];\n  }\n\n  private renderSubDomainSettings() {\n    return this.subDomains.map(s => ({\n      branchName: s.branch.branchName,\n      prefix: s.prefix ?? s.branch.branchName,\n    }));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates CloudWatch Logs, CloudFormation resources", "output": "class LogRetentionRetriesStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    for (let i = 0; i < 25; i++) {\n      new logs.LogRetention(this, `LogRetention${i}`, {\n        logGroupName: `/${id}/group${i}`,\n        retention: logs.RetentionDays.ONE_WEEK,\n        removalPolicy: RemovalPolicy.DESTROY,\n      });\n    }\n  }\n}", "language": "typescript"}
{"input": "A database of regional information.", "output": "export class Fact {\n  /**\n   * @returns the list of names of AWS Regions for which there is at least one registered fact. This\n   *          includes Regions defined in AWS_REGIONS plus custom defined regions.\n   */\n  public static get regions(): string[] {\n    // Return the union of regions in AWS_REGIONS and custom defined regions.\n    return [...new Set([...AWS_REGIONS, ...Object.keys(this.database)])];\n  }\n\n  /**\n   * Returns the list of names of registered facts.\n   *\n   * All facts will be present in at least one region.\n   */\n  public static get names(): string[] {\n    return [...new Set(Object.values(this.database).flatMap(regionFacts => Object.keys(regionFacts)))];\n  }\n\n  /**\n   * Return all pairs of (region, factName) that are defined\n   */\n  public static definedFacts(): Array<string[]> {\n    return Object.entries(this.database)\n      .flatMap(([regionName, regionFacts]) =>\n        Object.keys(regionFacts).map((factName) =>\n          [regionName, factName] satisfies [string, string]));\n  }\n\n  /**\n   * Retrieves a fact from this Fact database.\n   *\n   * @param region the name of the region (e.g: `us-east-1`)\n   * @param name   the name of the fact being looked up (see the `FactName` class for details)\n   *\n   * @returns the fact value if it is known, and `undefined` otherwise.\n   */\n  public static find(region: string, name: string): string | undefined {\n    const regionFacts = this.database[region];\n    return regionFacts && regionFacts[name];\n  }\n\n  /**\n   * Retrieve a fact from the Fact database. (retrieval will fail if the specified region or\n   * fact name does not exist.)\n   *\n   * @param region the name of the region (e.g: `us-east-1`)\n   * @param name the name of the fact being looked up (see the `FactName` class for details)\n   */\n  public static requireFact(region: string, name: string): string {\n    const foundFact = this.find(region, name);\n\n    if (!foundFact) {\n      throw new RegionFactError(`No fact ${name} could be found for region: ${region} and name: ${name}.`);\n    }\n\n    return foundFact;\n  }\n\n  /**\n   * Registers a new fact in this Fact database.\n   *\n   * @param fact           the new fact to be registered.\n   * @param allowReplacing whether new facts can replace existing facts or not.\n   */\n  public static register(fact: IFact, allowReplacing = false): void {\n    const regionFacts = this.database[fact.region] || (this.database[fact.region] = {});\n    if (fact.name in regionFacts && regionFacts[fact.name] !== fact.value && !allowReplacing) {\n      throw new RegionFactError(`Region ${fact.region} already has a fact ${fact.name}, with value ${regionFacts[fact.name]}`);\n    }\n    if (fact.value !== undefined) {\n      regionFacts[fact.name] = fact.value;\n    }\n  }\n\n  /**\n   * Removes a fact from the database.\n   * @param region the region for which the fact is to be removed.\n   * @param name   the name of the fact to remove.\n   * @param value  the value that should be removed (removal will fail if the value is specified, but does not match the\n   *               current stored value).\n   */\n  public static unregister(region: string, name: string, value?: string): void {\n    const regionFacts = this.database[region] || {};\n    if (name in regionFacts && value && regionFacts[name] !== value) {\n      throw new RegionFactError(`Attempted to remove ${name} from ${region} with value ${value}, but the fact's value is ${regionFacts[name]}`);\n    }\n    delete regionFacts[name];\n  }\n\n  private static readonly database: { [region: string]: { [name: string]: string } } = {};\n\n  private constructor() {\n    // this should never happen, so throw a regular error here\n    /* eslint-disable-next-line @cdklabs/no-throw-default-error */\n    throw new Error('Use the static methods of Fact instead!');\n  }\n}", "language": "typescript"}
{"input": "Verify that all packages have a description", "output": "export class DescriptionIsRequired extends ValidationRule {\n  public readonly name = 'package-info/require-description';\n\n  public validate(pkg: PackageJson): void {\n    if (!pkg.json.description) {\n      pkg.report({ ruleName: this.name, message: 'Description is required' });\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for CloudFormation operations", "output": "const workflowArn = (() => {\n      if (attrs.workflowArn !== undefined) {\n        return attrs.workflowArn;\n      }\n\n      return cdk.Stack.of(scope).formatArn({\n        service: 'imagebuilder',\n        resource: 'workflow',\n        resourceName: `${attrs.workflowType!.toLowerCase()}/${attrs.workflowName!}/${attrs.workflowVersion ?? LATEST_VERSION}`,\n      });\n    }", "language": "typescript"}
{"input": "CDK Stack that creates S3, KMS, CloudFormation, CodePipeline resources", "output": "class PipelineStack extends Stack {\n  constructor(scope: Construct, id: string, stateMachine: sfn.IStateMachine, props?: StackProps) {\n    super(scope, id, props);\n\n    const sourceBucketKey = new Key(this, 'SourceBucketKey', {\n      description: 'SourceBucketKey',\n    });\n    const bucket = new s3.Bucket(this, 'SourceBucket', {\n      removalPolicy: RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n      versioned: true,\n      encryptionKey: sourceBucketKey,\n    });\n\n    const bucketDeployment = new s3deploy.BucketDeployment(this, 'BucketDeployment', {\n      sources: [s3deploy.Source.asset(path.join(__dirname, 'assets', 'nodejs.zip'))],\n      destinationBucket: bucket,\n      extract: false,\n    });\n    const zipKey = Fn.select(0, bucketDeployment.objectKeys);\n\n    const sourceOutput = new codepipeline.Artifact('SourceArtifact');\n    const sourceAction = new codepipeline_actions.S3SourceAction({\n      actionName: 'Source',\n      output: sourceOutput,\n      bucket,\n      bucketKey: zipKey,\n    });\n    const buildOutput = new codepipeline.Artifact('BuildOutput');\n\n    // Create the pipeline\n    const pipeline = new codepipeline.Pipeline(this, 'CrossAccountStepFunctionsPipeline', {\n      pipelineName: 'cross-account-sfn-pipeline',\n      crossAccountKeys: true,\n      artifactBucket: new s3.Bucket(this, 'ArtifactBucket', {\n        encryption: s3.BucketEncryption.KMS,\n        removalPolicy: RemovalPolicy.DESTROY,\n        autoDeleteObjects: true,\n      }),\n    });\n\n    // Add the source stage\n    pipeline.addStage({\n      stageName: 'Source',\n      actions: [\n        sourceAction,\n      ],\n    });\n\n    // Add a build stage\n    pipeline.addStage({\n      stageName: 'Build',\n      actions: [\n        new codepipeline_actions.CodeBuildAction({\n          actionName: 'BuildAction',\n          project: new codebuild.PipelineProject(this, 'BuildProject', {\n            environment: {\n              buildImage: codebuild.LinuxArmBuildImage.AMAZON_LINUX_2_STANDARD_3_0,\n              computeType: codebuild.ComputeType.SMALL,\n            },\n            buildSpec: codebuild.BuildSpec.fromObject({\n              version: '0.2',\n              phases: {\n                install: {\n                  commands: [\n                    'npm install -y jq',\n                  ],\n                },\n                build: {\n                  commands: [\n                    'echo \"Starting build...\"',\n                  ],\n                },\n              },\n            }),\n          }),\n          input: sourceOutput,\n          outputs: [buildOutput],\n        }),\n      ],\n    });\n\n    // Add the Step Function invoke stage\n    pipeline.addStage({\n      stageName: 'InvokeStepFunction',\n      actions: [\n        new codepipeline_actions.StepFunctionInvokeAction({\n          actionName: 'InvokeStateMachine',\n          stateMachine,\n          stateMachineInput: codepipeline_actions.StateMachineInput.literal({\n            source: 'codepipeline',\n          }),\n        }),\n      ],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class MxRecord for AWS resource management", "output": "export class MxRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.MxRecord';\n\n  constructor(scope: Construct, id: string, props: MxRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.MX,\n      target: RecordTarget.fromValues(...props.values.map(v => `${v.priority} ${v.hostName}`)),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK class ReplicaProvider for AWS resource management", "output": "export class ReplicaProvider extends NestedStack {\n  /**\n   * Creates a stack-singleton resource provider nested stack.\n   */\n  public static getOrCreate(scope: Construct, props: ReplicaProviderProps) {\n    const stack = Stack.of(scope);\n    const uid = '@aws-cdk/aws-dynamodb.ReplicaProvider';\n    return stack.node.tryFindChild(uid) as ReplicaProvider ?? new ReplicaProvider(stack, uid, props);\n  }\n\n  /**\n   * The custom resource provider.\n   */\n  public readonly provider: cr.Provider;\n\n  /**\n   * The onEvent handler\n   */\n  public readonly onEventHandler: lambda.Function;\n\n  /**\n   * The isComplete handler\n   */\n  public readonly isCompleteHandler: lambda.Function;\n\n  private constructor(scope: Construct, id: string, props: ReplicaProviderProps) {\n    super(scope, id);\n\n    // Issues UpdateTable API calls\n    this.onEventHandler = new ReplicaOnEventFunction(this, 'OnEventHandler', {\n      timeout: Duration.minutes(5),\n    });\n\n    // Checks if table is back to `ACTIVE` state\n    this.isCompleteHandler = new ReplicaIsCompleteFunction(this, 'IsCompleteHandler', {\n      timeout: Duration.seconds(30),\n    });\n\n    // Allows the creation of the `AWSServiceRoleForDynamoDBReplication` service linked role\n    this.onEventHandler.addToRolePolicy(\n      new iam.PolicyStatement({\n        actions: ['iam:CreateServiceLinkedRole'],\n        resources: [Stack.of(this).formatArn({\n          service: 'iam',\n          region: '', // IAM is region-less\n          resource: 'role',\n          resourceName: 'aws-service-role/replication.dynamodb.amazonaws.com/AWSServiceRoleForDynamoDBReplication',\n        })],\n      }),\n    );\n\n    // Required for replica table creation\n    this.onEventHandler.addToRolePolicy(\n      new iam.PolicyStatement({\n        actions: ['dynamodb:DescribeLimits'],\n        resources: ['*'],\n      }),\n    );\n\n    // Required for replica table deletion\n    let resources: string[] = [];\n    props.regions.forEach((region) => {\n      resources.push(`arn:${Aws.PARTITION}:dynamodb:${region}:${this.account}:table/${props.tableName}`);\n    });\n\n    this.onEventHandler.addToRolePolicy(\n      new iam.PolicyStatement({\n        actions: ['dynamodb:DeleteTable', 'dynamodb:DeleteTableReplica'],\n        resources: resources,\n      }),\n    );\n\n    const disableLogging = props.disableLogging ?? true;\n\n    this.provider = new cr.Provider(this, 'Provider', {\n      onEventHandler: this.onEventHandler,\n      isCompleteHandler: this.isCompleteHandler,\n      queryInterval: Duration.seconds(10),\n      totalTimeout: props.timeout,\n      disableWaiterStateMachineLogging: disableLogging,\n      // If logging is not disabled use default INFO level logging for provider lambdas\n      ...(disableLogging ? {} : {\n        frameworkLambdaLoggingLevel: lambda.ApplicationLogLevel.INFO,\n      }),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Step Functions, CloudFormation, Glue resources", "output": "class StepFunctionsTaskCreateTransformJobIntegStack extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const task = new SageMakerCreateTransformJob(this, 'BatchInferenceTask', {\n      transformJobName: 'MyTransformJob',\n      modelName: 'MyModelName',\n      transformInput: {\n        transformDataSource: {\n          s3DataSource: {\n            s3Uri: 's3://inputbucket/prefix',\n            s3DataType: S3DataType.S3_PREFIX,\n          },\n        },\n      },\n      transformOutput: {\n        s3OutputPath: 's3://outputbucket/result',\n      },\n      transformResources: {\n        instanceCount: 1,\n        instanceType: InstanceType.of(InstanceClass.M4, InstanceSize.XLARGE),\n      },\n      integrationPattern: IntegrationPattern.RUN_JOB,\n    });\n\n    new StateMachine(this, 'SimpleStateMachine', {\n      definitionBody: DefinitionBody.fromChainable(task),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Config operations", "output": "const validator = (config: Config) => {\n        const errors: string[] = [];\n        if (!config.name) {\n          errors.push('Name is required');\n        }\n        if (config.value < 0) {\n          errors.push('Value must be positive');\n        }\n        return errors;\n      }", "language": "typescript"}
{"input": "Represents an `if` condition in the component document", "output": "export class ComponentStepIfCondition {\n  /**\n   * Creates the `if` value from an object, for the component step\n   *\n   * @param ifObject The object containing the `if` condition\n   */\n  public static fromObject(ifObject: { [key: string]: any }): ComponentStepIfCondition {\n    return new ComponentStepIfCondition(ifObject);\n  }\n\n  /**\n   * The rendered input value\n   */\n  public readonly ifCondition: any;\n\n  protected constructor(ifCondition: any) {\n    this.ifCondition = ifCondition;\n  }\n}", "language": "typescript"}
{"input": "CDK class SecretValue for AWS resource management", "output": "export class SecretValue extends Intrinsic {\n  /**\n   * Test whether an object is a SecretValue\n   */\n  public static isSecretValue(x: any): x is SecretValue {\n    return typeof x === 'object' && x && SECRET_VALUE_SYM in x;\n  }\n\n  /**\n   * Construct a literal secret value for use with secret-aware constructs\n   *\n   * Do not use this method for any secrets that you care about! The value\n   * will be visible to anyone who has access to the CloudFormation template\n   * (via the AWS Console, SDKs, or CLI).\n   *\n   * The only reasonable use case for using this method is when you are testing.\n   *\n   * @deprecated Use `unsafePlainText()` instead.\n   */\n  public static plainText(secret: string): SecretValue {\n    return new SecretValue(secret);\n  }\n\n  /**\n   * Construct a literal secret value for use with secret-aware constructs\n   *\n   * Do not use this method for any secrets that you care about! The value\n   * will be visible to anyone who has access to the CloudFormation template\n   * (via the AWS Console, SDKs, or CLI).\n   *\n   * The primary use case for using this method is when you are testing.\n   *\n   * The other use case where this is appropriate is when constructing a JSON secret.\n   * For example, a JSON secret might have multiple fields where only some are actual\n   * secret values.\n   *\n   * @example\n   * declare const secret: SecretValue;\n   * const jsonSecret = {\n   *   username: SecretValue.unsafePlainText('myUsername'),\n   *   password: secret,\n   * };\n   */\n  public static unsafePlainText(secret: string): SecretValue {\n    return new SecretValue(secret);\n  }\n\n  /**\n   * Creates a `SecretValue` with a value which is dynamically loaded from AWS Secrets Manager.\n   *\n   * If you rotate the value in the Secret, you must also change at least one property\n   * on the resource where you are using the secret, to force CloudFormation to re-read the secret.\n   *\n   * @param secretId The ID or ARN of the secret\n   * @param options Options\n   */\n  public static secretsManager(secretId: string, options: SecretsManagerSecretOptions = {}): SecretValue {\n    const dyref = new CfnDynamicReference(CfnDynamicReferenceService.SECRETS_MANAGER, SecretValue.cfnDynamicReferenceKey(secretId, options));\n    return this.cfnDynamicReference(dyref);\n  }\n\n  /**\n   * Returns a key which can be used within an AWS CloudFormation dynamic reference to dynamically load a\n   * secret from AWS Secrets Manager\n   *\n   * @see https://docs.aws.amazon.com/secretsmanager/latest/userguide/cfn-example_reference-secret.html\n   *\n   * @param secretId The ID or ARN of the secret\n   * @param options Options\n   */\n  public static cfnDynamicReferenceKey(secretId: string, options: SecretsManagerSecretOptions = {}): string {\n    if (!secretId) {\n      throw new UnscopedValidationError('secretId cannot be empty');\n    }\n\n    if (!Token.isUnresolved(secretId) && !secretId.startsWith('arn:') && secretId.includes(':')) {\n      throw new UnscopedValidationError(`secret id \"${secretId}\" is not an ARN but contains \":\"`);\n    }\n\n    if (options.versionStage && options.versionId) {\n      throw new UnscopedValidationError(`versionStage: '${options.versionStage}' and versionId: '${options.versionId}' were both provided but only one is allowed`);\n    }\n\n    const parts = [\n      secretId,\n      'SecretString',\n      options.jsonField || '',\n      options.versionStage || '',\n      options.versionId || '',\n    ];\n\n    return parts.join(':');\n  }\n\n  /**\n   * Use a secret value stored from a Systems Manager (SSM) parameter.\n   *\n   * This secret source in only supported in a limited set of resources and\n   * properties. [Click here for the list of supported\n   * properties](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/dynamic-references.html#template-parameters-dynamic-patterns-resources).\n   *\n   * @param parameterName The name of the parameter in the Systems Manager\n   * Parameter Store. The parameter name is case-sensitive.\n   *\n   * @param version An integer that specifies the version of the parameter to\n   * use. If you don't specify the exact version, AWS CloudFormation uses the\n   * latest version of the parameter.\n   */\n  public static ssmSecure(parameterName: string, version?: string): SecretValue {\n    return this.cfnDynamicReference(\n      new CfnDynamicReference(CfnDynamicReferenceService.SSM_SECURE,\n        version ? `${parameterName}:${version}` : parameterName));\n  }\n\n  /**\n   * Obtain the secret value through a CloudFormation dynamic reference.\n   *\n   * If possible, use `SecretValue.ssmSecure` or `SecretValue.secretsManager` directly.\n   *\n   * @param ref The dynamic reference to use.\n   */\n  public static cfnDynamicReference(ref: CfnDynamicReference) {\n    return new SecretValue(ref);\n  }\n\n  /**\n   * Obtain the secret value through a CloudFormation parameter.\n   *\n   * Generally, this is not a recommended approach. AWS Secrets Manager is the\n   * recommended way to reference secrets.\n   *\n   * @param param The CloudFormation parameter to use.\n   */\n  public static cfnParameter(param: CfnParameter) {\n    if (!param.noEcho) {\n      throw new UnscopedValidationError('CloudFormation parameter must be configured with \"NoEcho\"');\n    }\n\n    return new SecretValue(param.value);\n  }\n\n  /**\n   * Use a resource's output as secret value\n   */\n  public static resourceAttribute(attr: string) {\n    const resolved = Tokenization.reverseCompleteString(attr);\n    if (!resolved || !CfnReference.isCfnReference(resolved) || !CfnResource.isCfnResource(resolved.target)) {\n      throw new UnscopedValidationError('SecretValue.resourceAttribute() must be used with a resource attribute');\n    }\n\n    return new SecretValue(attr);\n  }\n\n  private readonly rawValue: any;\n\n  /**\n   * Construct a SecretValue (do not use!)\n   *\n   * Do not use the constructor directly: use one of the factory functions on the class\n   * instead.\n   */\n  constructor(protectedValue: any, options?: IntrinsicProps) {\n    super(protectedValue, options);\n    this.rawValue = protectedValue;\n  }\n\n  /**\n   * Disable usage protection on this secret\n   *\n   * Call this to indicate that you want to use the secret value held by this\n   * object in an unchecked way. If you don't call this method, using the secret\n   * value directly in a string context or as a property value somewhere will\n   * produce an error.\n   *\n   * This method has 'unsafe' in the name on purpose! Make sure that the\n   * construct property you are using the returned value in is does not end up\n   * in a place in your AWS infrastructure where it could be read by anyone\n   * unexpected.\n   *\n   * When in doubt, don't call this method and only pass the object to constructs that\n   * accept `SecretValue` parameters.\n   */\n  public unsafeUnwrap() {\n    return Token.asString(this.rawValue);\n  }\n\n  /**\n   * Resolve the secret\n   *\n   * If the feature flag is not set, resolve as normal. Otherwise, throw a descriptive\n   * error that the usage guard is missing.\n   */\n  public resolve(context: IResolveContext) {\n    if (FeatureFlags.of(context.scope).isEnabled(CHECK_SECRET_USAGE)) {\n      throw new UnscopedValidationError(\n        `Synthing a secret value to ${context.documentPath.join('/')}. Using a SecretValue here risks exposing your secret. Only pass SecretValues to constructs that accept a SecretValue property, or call AWS Secrets Manager directly in your runtime code. Call 'secretValue.unsafeUnwrap()' if you understand and accept the risks.`,\n      );\n    }\n    return super.resolve(context);\n  }\n}", "language": "typescript"}
{"input": "CDK class AutoScalingFargateService for AWS resource management", "output": "class AutoScalingFargateService(Stack):\n\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Create a cluster\n        vpc = ec2.Vpc(\n            self, \"Vpc\",\n            max_azs=2\n        )\n\n        cluster = ecs.Cluster(\n            self, 'fargate-service-autoscaling',\n            vpc=vpc\n        )\n\n        # Create Fargate Service\n        fargate_service = ecs_patterns.NetworkLoadBalancedFargateService(\n            self, \"sample-app\",\n            cluster=cluster,\n            task_image_options=ecs_patterns.NetworkLoadBalancedTaskImageOptions(\n                image=ecs.ContainerImage.from_registry(\"amazon/amazon-ecs-sample\")\n            )\n        )\n\n        fargate_service.service.connections.security_groups[0].add_ingress_rule(\n            peer = ec2.Peer.ipv4(vpc.vpc_cidr_block),\n            connection = ec2.Port.tcp(80),\n            description=\"Allow http inbound from VPC\"\n        )\n\n        # Setup AutoScaling policy\n        scaling = fargate_service.service.auto_scale_task_count(\n            max_capacity=2\n        )\n        scaling.scale_on_cpu_utilization(\n            \"CpuScaling\",\n            target_utilization_percent=50,\n            scale_in_cooldown=Duration.seconds(60),\n            scale_out_cooldown=Duration.seconds(60),\n        )\n\n        CfnOutput(\n            self, \"LoadBalancerDNS\",\n            value=fargate_service.load_balancer.load_balancer_dns_name\n        )", "language": "python"}
{"input": "CDK class LambdaWithKinesisTrigger for AWS resource management", "output": "class LambdaWithKinesisTrigger(Stack):\n    def __init__(self, app: App, id: str) -> None:\n        super().__init__(app, id)\n\n        with open(\"lambda-handler.py\", encoding=\"utf8\") as fp:\n            handler_code = fp.read()\n\n        # Creates reference to already existing kinesis stream\n        kinesis_stream = kinesis.Stream.from_stream_arn(\n            self, 'KinesisStream',\n            Arn.format(\n                ArnComponents(\n                    resource='stream',\n                    service='kinesis',\n                    resource_name='my-stream'\n                ),\n                self\n            )\n        )\n\n        lambdaFn = lambda_.Function(\n            self, 'Singleton',\n            handler='index.main',\n            code=lambda_.InlineCode(handler_code),\n            runtime=lambda_.Runtime.PYTHON_3_7,\n            timeout=Duration.seconds(300)\n        )\n\n        # Update Lambda Permissions To Use Stream\n        kinesis_stream.grant_read(lambdaFn)\n\n        # Create New Kinesis Event Source\n        kinesis_event_source = event_sources.KinesisEventSource(\n            stream=kinesis_stream,\n            starting_position=lambda_.StartingPosition.LATEST,\n            batch_size=1\n        )\n\n        # Attach New Event Source To Lambda\n        lambdaFn.add_event_source(kinesis_event_source)", "language": "python"}
{"input": "CDK class DeploymentStage for AWS resource management", "output": "export class DeploymentStage extends Stage {\n  constructor(scope: Construct, id: string, props: DeploymentStageProps) {\n    super(scope, id, props);\n\n    var synth = new DefaultStackSynthesizer();\n    if (props.environmentAbbreviation == 'dev') {\n      synth = new DefaultStackSynthesizer({\n        qualifier: 'dev',\n      });\n    }\n    new LambdaStack(\n      this, `${props.environmentAbbreviation}-lambda-stack`, {\n        env: {\n          region: props.region,\n        },\n        synthesizer: synth,\n      },\n    );\n  }\n}", "language": "typescript"}
{"input": "example tests. To run these tests, uncomment this file along with the example resource in opensearch_simple_domain/opensearch_simple_domain_stack.py", "output": "def test_sqs_queue_created():\n    app = core.App()\n    stack = OpensearchSimpleDomainStack(app, \"opensearch-simple-domain\")\n    template = assertions.Template.from_stack(stack)", "language": "python"}
{"input": "CDK Stack that creates S3, CloudFormation resources", "output": "class DataSyncS3toS3Stack(Stack):\n    \n    # Function to create Datasync Task\n    def create_datasync_s3_task(self, s3_src_location, s3_dest_location):\n        task = datasync.CfnTask(\n            self,\n            'DataSyncS3toS3Task',\n            destination_location_arn=s3_src_location.attr_location_arn,\n            source_location_arn=s3_dest_location.attr_location_arn)\n        \n        CfnOutput(self, 'task_arn', value=task.attr_task_arn)\n    \n        return task\n    \n    # Function to create a S3 bucket using CDK\n    def create_bucket(self, name):\n        bucket = s3.Bucket(self, name, bucket_name = name)\n        return bucket\n    \n    # Function to get bucket ARN\n    def get_bucket_arn(self, config):\n        bucket_name = config[\"bucketName\"]\n        bucket_arn = \"\"\n        \n        if config[\"create\"]:\n           bucket = self.create_bucket(bucket_name)\n           bucket_arn = bucket.bucket_arn\n        else:\n           bucket_arn = \"arn:aws:s3:::\" + bucket_name\n        \n        return bucket_arn\n    \n    # Function to create Datasync S3 locations\n    def create_datasync_s3_locations(self, bucket_configs):\n        # Create the locations\n        i=0\n\n        s3_locations_dict = {}\n        for bc in bucket_configs:\n            role_name_export =\"CDKDataSyncS3Access-\" + bc[\"bucketName\"]\n            \n            location = datasync.CfnLocationS3(\n                self,\n                'DataSyncS3Location'+str(i),\n                s3_bucket_arn=bc[\"arn\"],\n                s3_config=datasync.CfnLocationS3.S3ConfigProperty(\n                    bucket_access_role_arn=Fn.import_value(role_name_export))\n                )\n                \n            # Add remaining configs if present\n            if \"subDirectory\" in bc:\n                location.subdirectory=bc[\"subDirectory\"]\n            if \"storageClass\" in bc:\n                location.s3_storage_class=bc[\"storageClass\"]\n\n            # TODO: Add tags support\n            #            if \"tags\" in bc and len(bc[\"tags\"]) > 0:\n            #                location.tags = bc[\"tags\"]\n            \n            # Add this location to the result dict\n            s3_locations_dict[bc[\"bucketName\"]] = location\n            i+=1\n        \n        return s3_locations_dict\n    \n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n        super().__init__(scope, construct_id, **kwargs)\n        \n        # Process the bucket configurations\n        bucket_configs = self.node.try_get_context(\"S3_datasync_locations\")\n        if bucket_configs:\n            # Add the arn to bucket_config, if it is not provided already. Creates S3 buckets if needed\n            for b in bucket_configs:\n                if not \"arn\" in b:\n                    b[\"arn\"] = self.get_bucket_arn(b)\n        else:\n            print(\"ERROR: Please set a context variable for S3_datasync_locations\")\n        \n        \n        # Create the locations\n        s3_locations_dict = self.create_datasync_s3_locations(bucket_configs)\n        \n        \n        # Process the task configurations\n        datasync_tasks = self.node.try_get_context(\"S3_datasync_tasks\")\n        if datasync_tasks:\n            for task in datasync_tasks:\n                self.create_datasync_s3_task(s3_locations_dict[task[\"source\"]],s3_locations_dict[task[\"destination\"]])\n        else:\n            print(\"ERROR: Please set a context variable for S3_datasync_locations\")", "language": "python"}
{"input": "CDK helper function for EC2, ELB / ALB / NLB operations", "output": "def __init__(self, scope: Construct, id: str, props, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        userdata_file = open(\"./userdata.sh\", \"rb\").read()\n\n        # Creates a userdata object for Linux hosts\n        userdata = ec2.UserData.for_linux()\n        # Adds one or more commands to the userdata object.\n        userdata.add_commands(str(userdata_file, 'utf-8'))\n\n\n        asg = autoscaling.AutoScalingGroup(\n            self,\n            \"app-asg\",\n            vpc=props['vpc'],\n            instance_type=ec2.InstanceType.of(\n                ec2.InstanceClass.MEMORY5, ec2.InstanceSize.XLARGE\n            ),\n            machine_image=ec2.AmazonLinuxImage(\n                generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2\n                ),\n            key_name=\"evan\",\n            vpc_subnets=ec2.SubnetSelection(subnet_type=SubnetType.PRIVATE_WITH_NAT),\n            user_data=userdata,\n        )\n\n        # Creates a security group for our application\n        sg_nextcloud = ec2.SecurityGroup(\n                self,\n                id=\"sg_nextcloud\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_nextcloud\"\n        )\n\n        # Allows only the IP of \"123.123.123.123\"\n        # to access this security group for SSH\n        sg_nextcloud.add_ingress_rule(\n            peer=ec2.Peer.ipv4(\"151.66.226.30/32\"),\n            connection=ec2.Port.tcp(22)\n        )\n\n        # Creates a security group for the application load balancer\n        sg_alb = ec2.SecurityGroup(\n                self,\n                id=\"sg_alb\",\n                vpc=props['vpc'],\n                security_group_name=\"sg_alb\"\n        )\n\n        # Allows connections from security group \"sg_alb\"\n        # inside the \"sg_nextcloud\" security group to access port 8080\n        # where our app listens\n        sg_nextcloud.connections.allow_from(\n                sg_alb, ec2.Port.tcp(8080), \"Ingress\")\n\n        # Adds the security group 'sg_nextcloud' to the autoscaling group\n        asg.add_security_group(sg_nextcloud)\n\n        # Creates an application load balance\n        lb = elbv2.ApplicationLoadBalancer(\n                self,\n                \"ALB\",\n                vpc=props['vpc'],\n                security_group=sg_alb,\n                internet_facing=True)\n\n        listener = lb.add_listener(\"Listener\", port=80)\n        # Adds the autoscaling group's (asg) instance to be registered\n        # as targets on port 8080\n        listener.add_targets(\"Target\", port=8080, targets=[asg])\n        # This creates a \"0.0.0.0/0\" rule to allow every one to access the\n        # application\n        listener.connections.allow_default_port_from_any_ipv4(\n                \"Open to the world\"\n                )", "language": "python"}
{"input": "CDK class AgentAlias for AWS resource management", "output": "export class AgentAlias extends AgentAliasBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-bedrock-alpha.AgentAlias';\n  // ------------------------------------------------------\n  // Imports\n  // ------------------------------------------------------\n  /**\n   * Brings an Agent Alias from an existing one created outside of CDK.\n   */\n  public static fromAttributes(\n    scope: Construct,\n    id: string,\n    attrs: AgentAliasAttributes,\n  ): IAgentAlias {\n    class Import extends AgentAliasBase {\n      public readonly agent = attrs.agent;\n      public readonly aliasId = attrs.aliasId;\n      public readonly aliasName = attrs.aliasName;\n      public readonly aliasArn = Stack.of(scope).formatArn({\n        resource: 'agent-alias',\n        service: 'bedrock',\n        resourceName: `${attrs.agent.agentId}/${attrs.aliasId}`,\n        arnFormat: ArnFormat.SLASH_RESOURCE_NAME,\n      });\n    }\n    return new Import(scope, id);\n  }\n\n  // ----------------------------------------\n  // Inherited Attributes\n  // ----------------------------------------\n  public readonly agent: IAgent;\n  public readonly aliasId: string;\n  public readonly aliasArn: string;\n  /**\n   * The name of the agent alias.\n   * This is either provided by the user or generated from a hash.\n   */\n  public readonly aliasName: string;\n\n  // ------------------------------------------------------\n  // CONSTRUCTOR\n  // ------------------------------------------------------\n  constructor(scope: Construct, id: string, props: AgentAliasProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // ------------------------------------------------------\n    // Set properties or defaults\n    // ------------------------------------------------------\n    // see https://github.com/awslabs/generative-ai-cdk-constructs/issues/947 - The default name without any version update may result in this error.\n    // see https://github.com/awslabs/generative-ai-cdk-constructs/pull/1116 - If no agent version is provided then update the agent description for a new version.\n    this.aliasName = props.agentAliasName ?? 'latest';\n    this.agent = props.agent;\n\n    // ------------------------------------------------------\n    // L1 Instantiation\n    // ------------------------------------------------------\n    const alias = new bedrock.CfnAgentAlias(this, 'Resource', {\n      agentAliasName: this.aliasName,\n      agentId: this.agent.agentId,\n      description: props.description,\n      routingConfiguration: props.agentVersion\n        ? [\n          {\n            agentVersion: props.agentVersion,\n          },\n        ]\n        : undefined,\n    });\n\n    this.aliasId = alias.attrAgentAliasId;\n    this.aliasArn = alias.attrAgentAliasArn;\n  }\n}", "language": "typescript"}
{"input": "CDK class DashboardVariablesIntegrationTest for AWS resource management", "output": "class DashboardVariablesIntegrationTest extends Stack {\n  constructor(scope: App, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const dashboard = new cloudwatch.Dashboard(this, 'Dash', {\n      variables: [new cloudwatch.DashboardVariable({\n        type: cloudwatch.VariableType.PATTERN,\n        value: 'RegionPlaceholder',\n        inputType: cloudwatch.VariableInputType.RADIO,\n        id: 'region3',\n        label: 'RegionPatternWithValues',\n        defaultValue: cloudwatch.DefaultValue.value('us-east-1'),\n        visible: true,\n        values: cloudwatch.Values.fromValues({ label: 'IAD', value: 'us-east-1' }, { label: 'DUB', value: 'us-west-2' }),\n      })],\n    });\n\n    dashboard.addWidgets(new cloudwatch.TextWidget({\n      markdown: 'The dashboard is showing RegionPlaceholder region',\n      background: cloudwatch.TextWidgetBackground.TRANSPARENT,\n    }));\n\n    const widget = new cloudwatch.GraphWidget({\n      title: 'My fancy graph',\n      left: [\n        new cloudwatch.Metric({\n          namespace: 'AWS/S3',\n          metricName: 'BucketSizeBytes',\n          label: '[BucketName: ${PROP(\\'Dim.BucketName\\')}] BucketSizeBytes',\n          statistic: cloudwatch.Stats.MAXIMUM,\n          dimensionsMap: { StorageType: 'StandardStorage', BucketName: 'my-bucket' },\n        }),\n      ],\n    });\n\n    // The dashboard variable which changes BucketName property on the dashboard\n    dashboard.addVariable(new cloudwatch.DashboardVariable({\n      defaultValue: cloudwatch.DefaultValue.FIRST,\n      id: 'BucketName',\n      label: 'BucketName',\n      inputType: cloudwatch.VariableInputType.SELECT,\n      type: cloudwatch.VariableType.PROPERTY,\n      value: 'BucketName',\n      values: cloudwatch.Values.fromSearchComponents({\n        namespace: 'AWS/S3',\n        dimensions: ['BucketName', 'StorageType'],\n        metricName: 'BucketSizeBytes',\n        populateFrom: 'BucketName',\n      }),\n      visible: true,\n    }));\n\n    dashboard.addWidgets(widget);\n  }\n}", "language": "typescript"}
{"input": "Main entry point for applying mixins.", "output": "export class Mixins {\n  /**\n   * Creates a MixinApplicator for the given scope.\n   */\n  static of(scope: IConstruct, selector?: IConstructSelector): MixinApplicator {\n    return new MixinApplicator(scope, selector);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, VPC resources", "output": "class OpenSearchVpcProvisionStack(Stack):\n    def __init__(self, scope: Construct, id: str, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        ################################################################################\n        # VPC\n        vpc = ec2.Vpc(self, \"OpenSearch VPC\", max_azs=3)\n\n        ################################################################################\n        # Amazon OpenSearch Service domain\n        es_sec_grp = ec2.SecurityGroup(\n            self,\n            \"OpenSearchSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"OpenSearchSecGrp\",\n        )\n\n        vpc_subnets = ec2.SubnetSelection(subnet_type=ec2.SubnetType.PRIVATE_WITH_NAT)\n        domain = opensearch.Domain(\n            self,\n            \"opensearch-stack-demo\",\n            version=opensearch.EngineVersion.OPENSEARCH_1_3,  # Upgrade when CDK upgrades\n            domain_name=DOMAIN_NAME,\n            removal_policy=RemovalPolicy.DESTROY,\n            capacity=opensearch.CapacityConfig(\n                data_node_instance_type=DOMAIN_DATA_NODE_INSTANCE_TYPE,\n                data_nodes=DOMAIN_DATA_NODE_INSTANCE_COUNT,\n                master_node_instance_type=DOMAIN_MASTER_NODE_INSTANCE_TYPE,\n                master_nodes=DOMAIN_MASTER_NODE_INSTANCE_COUNT,\n                warm_instance_type=DOMAIN_UW_NODE_INSTANCE_TYPE,\n                warm_nodes=DOMAIN_UW_NODE_INSTANCE_COUNT,\n            ),\n            ebs=opensearch.EbsOptions(\n                enabled=True,\n                volume_size=DOMAIN_INSTANCE_VOLUME_SIZE,\n                volume_type=ec2.EbsDeviceVolumeType.GP3,\n            ),\n            vpc=vpc,\n            vpc_subnets=[vpc_subnets],\n            security_groups=[es_sec_grp],\n            zone_awareness=opensearch.ZoneAwarenessConfig(\n                enabled=True, availability_zone_count=DOMAIN_AZ_COUNT\n            ),\n            enforce_https=True,\n            node_to_node_encryption=True,\n            encryption_at_rest={\"enabled\": True},\n            use_unsigned_basic_auth=True,\n            fine_grained_access_control={\n                \"master_user_name\": DOMAIN_ADMIN_UNAME,\n                \"master_user_password\": SecretValue.unsafe_plain_text(DOMAIN_ADMIN_PW),\n            },\n        )\n\n        CfnOutput(\n            self,\n            \"MasterUser\",\n            value=DOMAIN_ADMIN_UNAME,\n            description=\"Master User Name for Amazon OpenSearch Service\",\n        )\n\n        CfnOutput(\n            self,\n            \"MasterPW\",\n            value=DOMAIN_ADMIN_PW,\n            description=\"Master User Password for Amazon OpenSearch Service\",\n        )\n\n        ################################################################################\n        # Jump host to setup nginx proxy\n        sn_public = ec2.SubnetSelection(subnet_type=ec2.SubnetType.PUBLIC)\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            edition=ec2.AmazonLinuxEdition.STANDARD,\n            virtualization=ec2.AmazonLinuxVirt.HVM,\n            storage=ec2.AmazonLinuxStorage.GENERAL_PURPOSE,\n        )\n\n        # Instance Role and SSM Managed Policy\n        role = iam.Role(\n            self,\n            \"OpenSearchInstanceSSM\",\n            assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"),\n        )\n        role.add_managed_policy(\n            iam.ManagedPolicy.from_aws_managed_policy_name(\n                \"service-role/AmazonEC2RoleforSSM\"\n            )\n        )\n        role.add_managed_policy(\n            iam.ManagedPolicy.from_aws_managed_policy_name(\n                \"AmazonSSMManagedInstanceCore\"\n            )\n        )\n\n        proxy_instance_sec_grp = ec2.SecurityGroup(\n            self,\n            \"OpenSearchProxyInstanceSecGrp\",\n            vpc=vpc,\n            allow_all_outbound=True,\n            security_group_name=\"OpenSearchProxyInstanceSecGrp\",\n        )\n        proxy_instance_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(80))\n        proxy_instance_sec_grp.add_ingress_rule(ec2.Peer.any_ipv4(), ec2.Port.tcp(443))\n\n        es_sec_grp.add_ingress_rule(proxy_instance_sec_grp, ec2.Port.tcp(80))\n        es_sec_grp.add_ingress_rule(proxy_instance_sec_grp, ec2.Port.tcp(443))\n\n        instance = ec2.Instance(\n            self,\n            \"opensearch-proxy-instance\",\n            instance_type=ec2.InstanceType(EC2_INSTANCE_TYPE),\n            vpc=vpc,\n            machine_image=amzn_linux,\n            vpc_subnets=sn_public,\n            role=role,\n            security_group=proxy_instance_sec_grp\n\n        )\n\n        stmt = iam.PolicyStatement(actions=[\"es:*\"], resources=[domain.domain_arn])\n        instance.add_to_role_policy(stmt)\n\n        # Create SNS topic, subscription for alerting\n        sns_topic = sns.Topic(self, \"opensearch_demo_topic\")\n\n        sns_topic.add_subscription(\n            subscriptions.EmailSubscription(SNS_NOTIFICATION_EMAIL)\n        )\n\n        sns_policy_statement = iam.PolicyStatement(\n            actions=[\"sns:publish\"],\n            resources=[sns_topic.topic_arn],\n            effect=iam.Effect.ALLOW,\n        )\n        sns_policy = iam.ManagedPolicy(self, \"opensearch_demo_policy\")\n        sns_policy.add_statements(sns_policy_statement)\n\n        sns_role = iam.Role(\n            self,\n            \"opensearch_demo_sns_role\",\n            assumed_by=iam.ServicePrincipal(\"es.amazonaws.com\"),\n        )\n        sns_role.add_managed_policy(sns_policy)\n\n        # Add custom files which needs to be used as an asset\n        # Generally used for running post deployment commands such as to create index templates, manage ISM policy, create alerts etc\n        dirname = os.path.dirname(__file__)\n\n        # Add dashboards assets, Shows sample to import default dashboard for Sample web logs\n        dashboards_asset = Asset(\n            self,\n            \"DashboardsAsset\",\n            path=os.path.join(\n                dirname, \"../confs/export_opensearch_dashboards_web_logs.ndjson\"\n            ),\n        )\n        dashboards_asset.grant_read(instance.role)\n        dashboards_asset_path = instance.user_data.add_s3_download_command(\n            bucket=dashboards_asset.bucket,\n            bucket_key=dashboards_asset.s3_object_key,\n        )\n\n        # Configuration for nginx proxy\n        nginx_asset = Asset(\n            self,\n            \"NginxAsset\",\n            path=os.path.join(dirname, \"../confs/nginx_opensearch.conf\"),\n        )\n        nginx_asset.grant_read(instance.role)\n        nginx_asset_path = instance.user_data.add_s3_download_command(\n            bucket=nginx_asset.bucket,\n            bucket_key=nginx_asset.s3_object_key,\n        )\n\n        # Adhoc script to show samples for creating ISM, Alerts, Users etc\n        post_deployment_asset = Asset(\n            self,\n            \"PostDeploymentAsset\",\n            path=os.path.join(dirname, \"../confs/post_deployment_objects.sh\"),\n        )\n        post_deployment_asset.grant_read(instance.role)\n        post_deployment_asset_path = instance.user_data.add_s3_download_command(\n            bucket=post_deployment_asset.bucket,\n            bucket_key=post_deployment_asset.s3_object_key,\n        )\n\n        instance.user_data.add_commands(\n            \"yum update -y\",\n            \"yum install jq -y\",\n            \"amazon-linux-extras install nginx1.12\",\n            \"mkdir -p /home/ec2-user/assets\",\n            \"cd /home/ec2-user/assets\",\n            \"mv {} export_opensearch_dashboards_web_logs.ndjson\".format(\n                dashboards_asset_path\n            ),\n            \"mv {} nginx_opensearch.conf\".format(nginx_asset_path),\n            \"mv {} post_deployment_objects.sh\".format(post_deployment_asset_path),\n            \"pip install opensearch-py==1.0.0\",\n            \"wget https://raw.githubusercontent.com/aiven/demo-opensearch-python/main/full_format_recipes.json\",\n            \"openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/nginx/cert.key -out /etc/nginx/cert.crt -subj /C=US/ST=./L=./O=./CN=.\\n\"\n            \"cp nginx_opensearch.conf /etc/nginx/conf.d/\",\n            \"sed -i 's/DOMAIN_ENDPOINT/\"\n            + domain.domain_endpoint\n            + \"/g' /etc/nginx/conf.d/nginx_opensearch.conf\",\n            \"sed -i 's/DOMAIN_ENDPOINT/\"\n            + domain.domain_endpoint\n            + \"/g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=SNS_ROLE_ARN=\"\n            + sns_role.role_arn\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's/SNS_TOPIC_ARN/\"\n            + sns_topic.topic_arn\n            + \"/g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=DOMAIN_ADMIN_UNAME=\"\n            + DOMAIN_ADMIN_UNAME\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"sed -i 's=DOMAIN_ADMIN_PW=\"\n            + DOMAIN_ADMIN_PW\n            + \"=g' /home/ec2-user/assets/post_deployment_objects.sh\",\n            \"systemctl restart nginx.service\",\n            \"chmod 500 post_deployment_objects.sh\",\n            \"sleep 5\",\n            \"bash --verbose post_deployment_objects.sh\",\n        )\n\n        CfnOutput(\n            self,\n            \"Dashboards URL (via Jump host)\",\n            value=\"https://\" + instance.instance_public_ip,\n            description=\"Dashboards URL via Jump host\",\n        )\n\n        CfnOutput(\n            self,\n            \"SNS Subscription Alert Message\",\n            value=SNS_NOTIFICATION_EMAIL,\n            description=\"Please confirm your SNS subscription received at\",\n        )", "language": "python"}
{"input": "Aspects can be applied to CDK tree scopes and can operate on the tree before synthesis.", "output": "export class Aspects {\n  /**\n   * Returns the `Aspects` object associated with a construct scope.\n   * @param scope The scope for which these aspects will apply.\n   */\n  public static of(scope: IConstruct): Aspects {\n    let aspects = (scope as any)[ASPECTS_SYMBOL];\n    if (!aspects) {\n      aspects = new Aspects(scope);\n\n      Object.defineProperty(scope, ASPECTS_SYMBOL, {\n        value: aspects,\n        configurable: false,\n        enumerable: false,\n      });\n    }\n    return aspects;\n  }\n\n  private readonly _scope: IConstruct;\n  private readonly _appliedAspects: AspectApplication[];\n\n  private constructor(scope: IConstruct) {\n    this._appliedAspects = [];\n    this._scope = scope;\n  }\n\n  /**\n   * Adds an aspect to apply this scope before synthesis.\n   * @param aspect The aspect to add.\n   * @param options Options to apply on this aspect.\n   */\n  public add(aspect: IAspect, options?: AspectOptions) {\n    const newApplication = new AspectApplication(this._scope, aspect, options?.priority ?? AspectPriority.DEFAULT);\n    if (this._appliedAspects.some(a => a.aspect === newApplication.aspect && a.priority === newApplication.priority)) {\n      return;\n    }\n    this._appliedAspects.push(newApplication);\n    bumpAspectTreeRevision(this._scope);\n  }\n\n  /**\n   * The list of aspects which were directly applied on this scope.\n   */\n  public get all(): IAspect[] {\n    return this._appliedAspects.map(application => application.aspect);\n  }\n\n  /**\n   * The list of aspects with priority which were directly applied on this scope.\n   *\n   * Also returns inherited Aspects of this node.\n   */\n  public get applied(): AspectApplication[] {\n    return [...this._appliedAspects];\n  }\n}", "language": "typescript"}
{"input": "CDK class Oracle for AWS resource management", "output": "class Oracle(Stack):\n\n  def __init__(self, scope:Construct, id:str,\n                vpc_id:str,                 ## vpc id\n                subnet_ids:list,            ## list of subnet ids\n                db_name:str,                ## database name\n                instance_type = ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.LARGE), ## ec2.InstanceType\n                ##\n                ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/OracleEngineVersion.html#aws_cdk.aws_rds.OracleEngineVersion\n                ##\n                engine_version = rds.OracleEngineVersion.VER_19_0_0_0_2021_04_R1,\n                oracle_username:str=\"dbadmin\",\n                backup_retention_days:int=14,\n                backup_window:str=\"00:15-01:15\",\n                preferred_maintenance_window:str=\"Sun:23:45-Mon:00:15\",\n                ingress_sources:list=[],    ## A security group object or a network subnet\n                                            ##   ec2.Peer.ipv4(\"0.0.0.0/0\")\n                                            ##   ec2.SecurityGroup\n                **kwargs) -> None:\n    super().__init__(scope, id, **kwargs)\n\n\n\n    ############################################\n    ##\n    ## CDK Nag - https://pypi.org/project/cdk-nag/\n    ##           https://github.com/cdklabs/cdk-nag\n    ##\n    ## CDK Nag Checks for AWS Engagement Solutions Secuirty Rules:\n    ##   https://github.com/cdklabs/cdk-nag/blob/main/RULES.md#awssolutions\n    ## Also checks for:\n    ##   HIPAA Security\n    ##   NIST 800-53 rev 4\n    ##   NIST 800-53 rev 5\n    ##\n    ############################################\n    Aspects.of(self).add(AwsSolutionsChecks())\n    ##\n    ## Supressed Errors\n    ##\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-IAM4\", \"reason\":\"TODO: Stop using AWS managed policies.\"}])\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-IAM5\", \"reason\":\"TODO: Remove Wildcards in IAM roles.\"}])\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-RDS11\",\"reason\":\"Default Oracle ports is fine.\"}])\n    ##\n    ## Supressed Warnings\n    ##\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-RDS16\", \"reason\":\"parameter referencing an intrinsic function\"}])\n    NagSuppressions.add_stack_suppressions(self, [{\"id\":\"AwsSolutions-SMG4\", \"reason\":\"Don't rotate secrets. Remove in prod\"}])\n\n\n    azs = Fn.get_azs()\n\n    vpc = ec2.Vpc.from_vpc_attributes(self, 'ExistingVPC', availability_zones=azs, vpc_id=vpc_id)\n    subnets = list()\n    for subnet_id in subnet_ids:\n      subnets.append(ec2.Subnet.from_subnet_attributes(self, subnet_id.replace(\"-\", \"\").replace(\"_\", \"\").replace(\" \", \"\"), subnet_id=subnet_id))\n\n    vpc_subnets = ec2.SubnetSelection(subnets=subnets)\n\n    allAll  = ec2.Port(protocol=ec2.Protocol(\"ALL\"), string_representation=\"ALL\")\n    tcp1521 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=1521, to_port=1521, string_representation=\"tcp1521 Oracle\")\n    tcp1526 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=1526, to_port=1526, string_representation=\"tcp1526 Oracle\")\n    tcp1575 = ec2.Port(protocol=ec2.Protocol(\"TCP\"), from_port=1575, to_port=1575, string_representation=\"tcp1575 Oracle\")\n\n\n    dbsg = ec2.SecurityGroup(self, \"DatabaseSecurityGroup\",\n             vpc                 = vpc,\n             allow_all_outbound  = True,\n             description         = id + \" Database\",\n             security_group_name = id + \" Database\",\n           )\n    dbsg.add_ingress_rule(\n      peer       =dbsg,\n      connection =allAll,\n      description=\"all from self\"\n    )\n    dbsg.add_egress_rule(\n      peer       =ec2.Peer.ipv4(\"0.0.0.0/0\"),\n      connection =allAll,\n      description=\"all out\"\n    )\n\n    oracle_connection_ports = [\n      {\"port\":tcp1521, \"description\":\"tcp1521 Oracle\"},\n      {\"port\":tcp1526, \"description\":\"tcp1526 Oracle\"},\n      {\"port\":tcp1575, \"description\":\"tcp1575 Oracle\"},\n    ]\n    db_subnet_group = None\n    for ingress_source in ingress_sources:\n      for c in oracle_connection_ports:\n        dbsg.add_ingress_rule(\n          peer       =ingress_source,\n          connection =c[\"port\"],\n          description=c[\"description\"]\n        )\n\n      db_subnet_group = rds.SubnetGroup(self,\n                         id          = \"DatabaseSubnetGroup\",\n                         vpc         = vpc,\n                         description = id + \" subnet group\",\n                         vpc_subnets = vpc_subnets,\n                         subnet_group_name=id + \"subnet group\"\n      )\n\n    ##\n    ## Oracle Database\n    ##\n    oracle_secret = secretsmanager.Secret(self, \"OracleCredentials\",\n    secret_name           =db_name + \"OracleCredentials\",\n    description           =db_name + \" Oracle Database Credentials\",\n    generate_secret_string=secretsmanager.SecretStringGenerator(\n      exclude_characters    =\"\\\"@/\\\\ '\",\n      generate_string_key   =\"password\",\n      password_length       =30,\n      secret_string_template='{\"username\":\"'+ oracle_username+'\"}'),\n    )\n\n    oracle_credentials = rds.Credentials.from_secret(oracle_secret, oracle_username)\n\n    ##\n    ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/ParameterGroup.html\n    ##\n    db_parameter_group = rds.ParameterGroup(self, \"ParameterGroup\",\n      engine=rds.DatabaseInstanceEngine.oracle_ee(version=engine_version),\n      parameters={\"open_cursors\": \"2500\"}\n    )\n\n    ##\n    ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/OptionGroup.html\n    ##\n    db_option_group = rds.OptionGroup(self, \"OptionGroup\",\n      engine=rds.DatabaseInstanceEngine.oracle_ee(version=engine_version),\n      configurations=[\n        rds.OptionConfiguration(name=\"LOCATOR\"),\n        rds.OptionConfiguration(name=\"OEM\",port=1158,vpc=vpc)\n      ]\n    )\n\n    ##\n    ## https://docs.aws.amazon.com/cdk/api/v2/python/aws_cdk.aws_rds/DatabaseInstance.html\n    ##\n    oracle_instance = rds.DatabaseInstance(self, \"OracleDatabase\",\n      database_name               = db_name,\n      instance_identifier         = db_name,\n      credentials                 = oracle_credentials,\n      engine                      = rds.DatabaseInstanceEngine.oracle_ee(version=engine_version),\n      backup_retention            = Duration.days(7),\n      allocated_storage           = 20,\n      security_groups             = [dbsg],\n      license_model               = rds.LicenseModel.BRING_YOUR_OWN_LICENSE,\n      allow_major_version_upgrade = True,\n      auto_minor_version_upgrade  = True,\n      instance_type               = instance_type,\n      vpc_subnets                 = vpc_subnets,\n      vpc                         = vpc,\n      removal_policy              = RemovalPolicy.RETAIN,\n      multi_az                    = True,\n      storage_encrypted           = True,\n      monitoring_interval         = Duration.seconds(60),\n      enable_performance_insights = True,\n      cloudwatch_logs_exports     = [\"trace\", \"audit\", \"alert\", \"listener\"],\n      cloudwatch_logs_retention   = logs.RetentionDays.ONE_MONTH,\n      #option_group                = db_option_group,\n      parameter_group             = db_parameter_group,\n      subnet_group                = db_subnet_group,\n      preferred_backup_window     = backup_window,\n      preferred_maintenance_window= preferred_maintenance_window,\n      publicly_accessible         = False,\n    ) ## rds.DatabaseInstance\n\n\n    # Rotate the master user password every 30 days\n    oracle_instance.add_rotation_single_user()\n\n\n\n    Tags.of(oracle_instance).add(\"Name\", \"OracleDatabase\", priority=300)\n\n\n\n    CfnOutput(self, \"OracleEndpoint\",\n      export_name=\"OracleEndpoint\",\n      value      =oracle_instance.db_instance_endpoint_address)\n    CfnOutput(self, \"OracleUsername\",\n      export_name=\"OracleUsername\",\n      value      =oracle_username)\n    CfnOutput(self, \"OracleDbName\",\n      export_name=\"OracleDbName\",\n      value      =db_name)", "language": "python"}
{"input": "CDK class MyStage for AWS resource management", "output": "class MyStage extends Stage {\n  constructor(scope: Construct, id: string, props?: StageProps) {\n    super(scope, id, props);\n\n    const stack = new Stack(this, 'Stack', {\n      ...props,\n      synthesizer: new DefaultStackSynthesizer(),\n    });\n\n    new PlainStackApp(stack, 'MyApp');\n  }\n}", "language": "typescript"}
{"input": "CDK class TestCodeBuildProject for AWS resource management", "output": "class TestCodeBuildProject extends Project {\n  constructor(scope: Construct, id: string, props: ProjectProps) {\n    const projectProps: ProjectProps = {\n      role: props.role,\n      buildSpec: BuildSpec.fromObject({\n        version: '0.2',\n        phases: {\n          build: {\n            commands: [\n              `aws ssm put-parameter --overwrite --name ${payload.Name} --value ${payload.Value}`,\n            ],\n          },\n        },\n      }),\n      environment: {\n        buildImage: LinuxBuildImage.STANDARD_7_0,\n        computeType: ComputeType.SMALL,\n      },\n    };\n    super(scope, id, projectProps);\n  }\n}", "language": "typescript"}
{"input": "Helper function to update dependencies", "output": "const updateDeps = (\n      depType: 'dependencies' | 'devDependencies',\n      updates: Record<string, string>\n    ) => {\n      if (!content[depType]) return;\n\n      for (const [pkg, version] of Object.entries(updates)) {\n        if (content[depType]![pkg] && content[depType]![pkg] !== version) {\n          content[depType]![pkg] = version;\n          console.log(`Updated ${pkg} to ${version} in ${filePath}`);\n          updated = true;\n        }\n      }\n    }", "language": "typescript"}
{"input": "PortMap ValueObjectClass having by ContainerDefinition", "output": "export class PortMap {\n  /**\n   * The networking mode to use for the containers in the task.\n   */\n  readonly networkmode: NetworkMode;\n\n  /**\n   * Port mappings allow containers to access ports on the host container instance to send or receive traffic.\n   */\n  readonly portmapping: PortMapping;\n\n  constructor(networkmode: NetworkMode, pm: PortMapping) {\n    this.networkmode = networkmode;\n    this.portmapping = pm;\n  }\n\n  /**\n   * validate invalid portmapping and networkmode parameters.\n   * throw Error when invalid parameters.\n   */\n  public validate(): void {\n    if (!this.isvalidPortName()) {\n      throw new UnscopedValidationError('Port mapping name cannot be an empty string.');\n    }\n\n    if (this.portmapping.containerPort === ContainerDefinition.CONTAINER_PORT_USE_RANGE && this.portmapping.containerPortRange === undefined) {\n      throw new UnscopedValidationError(`The containerPortRange must be set when containerPort is equal to ${ContainerDefinition.CONTAINER_PORT_USE_RANGE}`);\n    }\n\n    if (this.portmapping.containerPort !== ContainerDefinition.CONTAINER_PORT_USE_RANGE && this.portmapping.containerPortRange !== undefined) {\n      throw new UnscopedValidationError('Cannot set \"containerPort\" and \"containerPortRange\" at the same time.');\n    }\n\n    if (this.portmapping.containerPort !== ContainerDefinition.CONTAINER_PORT_USE_RANGE) {\n      if ((this.networkmode === NetworkMode.AWS_VPC || this.networkmode === NetworkMode.HOST)\n          && this.portmapping.hostPort !== undefined && this.portmapping.hostPort !== this.portmapping.containerPort) {\n        throw new UnscopedValidationError('The host port must be left out or must be the same as the container port for AwsVpc or Host network mode.');\n      }\n    }\n\n    if (this.portmapping.containerPortRange !== undefined) {\n      if (cdk.Token.isUnresolved(this.portmapping.containerPortRange)) {\n        throw new UnscopedValidationError('The value of containerPortRange must be concrete (no Tokens)');\n      }\n\n      if (this.portmapping.hostPort !== undefined) {\n        throw new UnscopedValidationError('Cannot set \"hostPort\" while using a port range for the container.');\n      }\n\n      if (this.networkmode !== NetworkMode.BRIDGE && this.networkmode !== NetworkMode.AWS_VPC) {\n        throw new UnscopedValidationError('Either AwsVpc or Bridge network mode is required to set a port range for the container.');\n      }\n\n      if (!/^\\d+-\\d+$/.test(this.portmapping.containerPortRange)) {\n        throw new UnscopedValidationError('The containerPortRange must be a string in the format [start port]-[end port].');\n      }\n    }\n  }\n\n  private isvalidPortName(): boolean {\n    if (this.portmapping.name === '') {\n      return false;\n    }\n    return true;\n  }\n}", "language": "typescript"}
{"input": "Network configuration for the Code Interpreter tool.", "output": "export class CodeInterpreterNetworkConfiguration extends NetworkConfiguration {\n  /**\n   * Creates a public network configuration.\n   * @returns A CodeInterpreterNetworkConfiguration.\n   * Run this tool to operate in a public environment with internet access, suitable for less sensitive or open-use scenarios.\n   */\n  public static usingPublicNetwork(): CodeInterpreterNetworkConfiguration {\n    return new CodeInterpreterNetworkConfiguration('PUBLIC');\n  }\n\n  /**\n   * Creates a sandbox network configuration.\n   * @returns A CodeInterpreterNetworkConfiguration.\n   * Run this tool in a restricted environment with limited Permissions and Encryption to enhance safety and reduce potential risks.\n   */\n  public static usingSandboxNetwork(): CodeInterpreterNetworkConfiguration {\n    return new CodeInterpreterNetworkConfiguration('SANDBOX');\n  }\n\n  /**\n   * Creates a network configuration from a VPC configuration.\n   * @param vpcConfig - The VPC configuration.\n   * @returns A CodeInterpreterNetworkConfiguration.\n   */\n  public static usingVpc(scope: Construct, vpcConfig: VpcConfigProps): CodeInterpreterNetworkConfiguration {\n    return new CodeInterpreterNetworkConfiguration('VPC', scope, vpcConfig);\n  }\n\n  /**\n   * Renders the network configuration as a CloudFormation property.\n   * @param codeInterpreterConnections - The connections object to the code interpreter.\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public _render(codeInterpreterConnections?: ec2.Connections): CfnCodeInterpreterCustom.CodeInterpreterNetworkConfigurationProperty {\n    return {\n      networkMode: this.networkMode,\n      vpcConfig: (this.networkMode === 'VPC' && codeInterpreterConnections) ? {\n        subnets: this.vpcSubnets?.subnets?.map(subnet => subnet.subnetId) ?? [],\n        securityGroups: codeInterpreterConnections?.securityGroups?.map(s => s.securityGroupId) ?? [],\n      } : undefined,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class ProxyResource for AWS resource management", "output": "export class ProxyResource extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-apigateway.ProxyResource';\n  /**\n   * If `props.anyMethod` is `true`, this will be the reference to the 'ANY'\n   * method associated with this proxy resource.\n   */\n  public readonly anyMethod?: Method;\n\n  constructor(scope: Construct, id: string, props: ProxyResourceProps) {\n    super(scope, id, {\n      parent: props.parent,\n      pathPart: '{proxy+}',\n      defaultIntegration: props.defaultIntegration,\n      defaultMethodOptions: props.defaultMethodOptions,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const anyMethod = props.anyMethod ?? true;\n    if (anyMethod) {\n      this.anyMethod = this.addMethod('ANY');\n    }\n  }\n\n  @MethodMetadata()\n  public addMethod(httpMethod: string, integration?: Integration, options?: MethodOptions): Method {\n    // In case this proxy is mounted under the root, also add this method to\n    // the root so that empty paths are proxied as well.\n    if (this.parentResource && this.parentResource.path === '/') {\n      // skip if the root resource already has this method defined\n      if (!(this.parentResource.node.tryFindChild(httpMethod) instanceof Method)) {\n        this.parentResource.addMethod(httpMethod, integration, options);\n      }\n    }\n    return super.addMethod(httpMethod, integration, options);\n  }\n}", "language": "typescript"}
{"input": "CDK class ClientVpnRoute for AWS resource management", "output": "export class ClientVpnRoute extends Resource {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.ClientVpnRoute';\n\n  constructor(scope: Construct, id: string, props: ClientVpnRouteProps) {\n    if (!props.clientVpnEndoint && !props.clientVpnEndpoint) {\n      throw new ValidationError(\n        'ClientVpnRoute: either clientVpnEndpoint or clientVpnEndoint (deprecated) must be specified', scope,\n      );\n    }\n    if (props.clientVpnEndoint && props.clientVpnEndpoint) {\n      throw new ValidationError(\n        'ClientVpnRoute: either clientVpnEndpoint or clientVpnEndoint (deprecated) must be specified' +\n          ', but not both',\n        scope,\n      );\n    }\n    const clientVpnEndpoint = props.clientVpnEndoint || props.clientVpnEndpoint;\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n    const route = new CfnClientVpnRoute(this, 'Resource', {\n      clientVpnEndpointId: clientVpnEndpoint!.endpointId,\n      description: props.description,\n      destinationCidrBlock: props.cidr,\n      targetVpcSubnetId: props.target.subnetId,\n    });\n\n    // See https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-clientvpnroute.html\n    route.node.addDependency(clientVpnEndpoint!.targetNetworksAssociated);\n  }\n}", "language": "typescript"}
{"input": "A construct that adds CloudWatch Agent as a container to an ECS task definition.", "output": "export class CloudWatchAgentIntegration extends Construct {\n  private static readonly DEFAULT_CONFIG = {\n    logs: {\n      metrics_collected: {\n        application_signals: {\n          enabled: true,\n        },\n      },\n    },\n    traces: {\n      traces_collected: {\n        application_signals: {\n          enabled: true,\n        },\n      },\n    },\n  };\n\n  /**\n   * The CloudWatch Agent container definition.\n   */\n  readonly agentContainer: ecs.ContainerDefinition;\n\n  /**\n   * Creates a new CloudWatch Agent integration.\n   * @param scope - The construct scope\n   * @param id - The construct ID\n   * @param props - Configuration properties\n   */\n  constructor(scope: Construct,\n    id: string,\n    props: CloudWatchAgentIntegrationProps,\n  ) {\n    super(scope, id);\n\n    props.taskDefinition.taskRole.addManagedPolicy(ManagedPolicy.fromAwsManagedPolicyName('CloudWatchAgentServerPolicy'));\n\n    this.agentContainer = props.taskDefinition.addContainer(props.containerName, {\n      image: ecs.ContainerImage.fromRegistry(CloudWatchAgentVersion.getCloudWatchAgentImage(props.operatingSystemFamily)),\n      cpu: props.cpu,\n      essential: props.essential? props.essential:true,\n      memoryLimitMiB: props.memoryLimitMiB,\n      memoryReservationMiB: props.memoryReservationMiB,\n      logging: props.enableLogging? new ecs.AwsLogDriver({\n        streamPrefix: props.containerName,\n      }): undefined,\n      user: '0:1338',\n      portMappings: props.portMappings,\n      environment: {\n        CW_CONFIG_CONTENT: props.agentConfig ? props.agentConfig: JSON.stringify(CloudWatchAgentIntegration.DEFAULT_CONFIG),\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "The HTTP methods that the Behavior will cache requests on.", "output": "export class CachedMethods {\n  /** HEAD and GET */\n  public static readonly CACHE_GET_HEAD = new CachedMethods(['GET', 'HEAD']);\n  /** HEAD, GET, and OPTIONS */\n  public static readonly CACHE_GET_HEAD_OPTIONS = new CachedMethods(['GET', 'HEAD', 'OPTIONS']);\n\n  /** HTTP methods supported */\n  public readonly methods: string[];\n\n  private constructor(methods: string[]) { this.methods = methods; }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, VPC, WAF resources", "output": "class NatInstanceStack extends cdk.Stack {\n  public readonly apiUrl: string;\n  public readonly bucketName: string;\n\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n    this.node.setContext(EC2_RESTRICT_DEFAULT_SECURITY_GROUP, false);\n\n    const bucket = new s3.Bucket(this, 'Bucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    const keyPair = new ec2.KeyPair(this, 'KeyPair');\n    const userData = ec2.UserData.forLinux();\n    userData.addCommands(\n      ...ec2.NatInstanceProviderV2.DEFAULT_USER_DATA_COMMANDS,\n      'echo \"hello world!\" > hello.txt',\n      `aws s3 cp hello.txt s3://${bucket.bucketName}`,\n    );\n\n    const natGatewayProvider = ec2.NatProvider.instanceV2({\n      instanceType: new ec2.InstanceType('t3.small'),\n      creditSpecification: ec2.CpuCredits.UNLIMITED,\n      defaultAllowedTraffic: ec2.NatTrafficDirection.NONE,\n      keyPair,\n      userData,\n    });\n\n    const vpc = new ec2.Vpc(this, 'MyVpc', { natGatewayProvider });\n\n    const securityGroup = new ec2.SecurityGroup(this, 'SecurityGroup', {\n      vpc,\n      allowAllOutbound: false,\n    });\n    securityGroup.addEgressRule(ec2.Peer.anyIpv4(), ec2.Port.tcp(443), 'Allow egress to S3');\n    for (const gateway of natGatewayProvider.gatewayInstances) {\n      bucket.grantWrite(gateway);\n      gateway.addSecurityGroup(securityGroup);\n    }\n\n    Array.isArray(vpc);\n    Array.isArray(natGatewayProvider.configuredGateways);\n\n    const loadBalancer = new elbv2.ApplicationLoadBalancer(this, 'ALB', { vpc });\n    const listener = loadBalancer.addListener('listener', { port: 80 });\n    listener.addTargets('target', { port: 80 });\n    listener.addAction('response', { action: elbv2.ListenerAction.fixedResponse(200) });\n\n    const httpApi = new apigwv2.HttpApi(this, 'HttpProxyPrivateApi', {\n      defaultIntegration: new integrations.HttpAlbIntegration('DefaultIntegration', listener),\n      createDefaultStage: true,\n    });\n\n    assert(httpApi.url, 'httpApi.url cannot be empty');\n    this.apiUrl = httpApi.url;\n    this.bucketName = bucket.bucketName;\n  }\n}", "language": "typescript"}
{"input": "Bootstrapped role specifier. These roles must exist already. This class does not create new IAM Roles.", "output": "export class BootstrapRole {\n  /**\n   * Use the currently assumed role/credentials\n   */\n  public static cliCredentials() {\n    return new BootstrapRole(BootstrapRole.CLI_CREDS);\n  }\n\n  /**\n   * Specify an existing IAM Role to assume\n   */\n  public static fromRoleArn(arn: string) {\n    StringSpecializer.validateNoTokens(arn, 'BootstrapRole ARN');\n    return new BootstrapRole(arn);\n  }\n\n  private static CLI_CREDS = 'cli-credentials';\n\n  private constructor(private readonly roleArn: string) {}\n\n  /**\n   * Whether or not this is object was created using BootstrapRole.cliCredentials()\n   */\n  public isCliCredentials() {\n    return this.roleArn === BootstrapRole.CLI_CREDS;\n  }\n\n  /**\n   * @internal\n   */\n  public _arnForCloudFormation() {\n    return this.isCliCredentials() ? undefined : translateAssetTokenToCfnToken(this.roleArn);\n  }\n\n  /**\n   * @internal\n   */\n  public _arnForCloudAssembly() {\n    return this.isCliCredentials() ? undefined : translateCfnTokenToAssetToken(this.roleArn);\n  }\n\n  /**\n   * @internal\n   */\n  public _specialize(spec: StringSpecializer) {\n    return new BootstrapRole(spec.specialize(this.roleArn));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates IAM, CloudFormation resources", "output": "class TestStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const provider = new iam.SamlProvider(this, 'Provider', {\n      metadataDocument: iam.SamlMetadataDocument.fromFile(path.join(__dirname, 'saml-metadata-document.xml')),\n    });\n\n    new iam.Role(this, 'Role', {\n      assumedBy: new iam.SamlConsolePrincipal(provider),\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK helper function checkParsingSingle", "output": "const checkParsingSingle = (statistic: string, statPrefix: string, statName: string, value: number) => {\n      const parsed = parseStatistic(statistic);\n      expect(parsed.type).toEqual('single');\n      expect((parsed as SingleStatistic).value).toEqual(value);\n      expect((parsed as SingleStatistic).statPrefix).toEqual(statPrefix);\n      expect((parsed as SingleStatistic).statName).toEqual(statName);\n    }", "language": "typescript"}
{"input": "Base abstract class for all schema types used in Bedrock AgentCore Gateway Targets. This provides a common interface for both API schemas and tool schemas. @internal", "output": "class TargetSchema {\n  /**\n   * Format as CFN properties\n   *\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public abstract _render(): any;\n\n  /**\n   * Bind the schema to a construct\n   */\n  public abstract bind(scope: Construct): void;\n\n  /**\n   * Grant permissions to the role\n   *\n   */\n  public abstract grantPermissionsToRole(role: IRole): void;\n}", "language": "typescript"}
{"input": "Represents the source from local assets.", "output": "export class AssetSource extends Source {\n  private readonly props: AssetProps;\n  constructor(props: AssetProps) {\n    super();\n    this.props = props;\n  }\n  public bind(_scope: Construct): SourceConfig {\n    return {\n      imageRepository: {\n        imageConfiguration: this.props.imageConfiguration,\n        imageIdentifier: this.props.asset.imageUri,\n        imageRepositoryType: ImageRepositoryType.ECR,\n      },\n      ecrRepository: this.props.asset.repository,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class MutualTls for AWS resource management", "output": "class MutualTls extends Stack {\n  constructor(scope: Construct, id: string, props: MutualTlsStackProps) {\n    super(scope, id);\n\n    const bucket = new s3.Bucket(this, 'Bucket', {\n      autoDeleteObjects: true,\n      removalPolicy: RemovalPolicy.DESTROY,\n    });\n\n    const deploy = new s3deploy.BucketDeployment(this, 'DeployCaCert', {\n      sources: [s3deploy.Source.asset(path.join(__dirname, 'mtls'))],\n      destinationBucket: bucket,\n    });\n\n    const vpc = new ec2.Vpc(this, 'Stack');\n\n    const hostedZone = route53.PublicHostedZone.fromHostedZoneAttributes(this, 'HostedZone', {\n      hostedZoneId: props.hostedZoneId,\n      zoneName: props.hostedZoneName,\n    });\n    const certificate = new acm.Certificate(this, 'Certificate', {\n      domainName: props.domainName,\n      validation: acm.CertificateValidation.fromDns(hostedZone),\n    });\n\n    const lb = new elbv2.ApplicationLoadBalancer(this, 'LB', {\n      vpc,\n      internetFacing: true,\n    });\n\n    const trustStore = new elbv2.TrustStore(this, 'Store', {\n      bucket,\n      key: 'rootCA_cert.pem',\n    });\n\n    trustStore.node.addDependency(deploy);\n\n    const trustStoreRevocation = new elbv2.TrustStoreRevocation(this, 'Revocation', {\n      trustStore,\n      revocationContents: [\n        {\n          bucket,\n          key: 'crl.pem',\n        },\n      ],\n    });\n\n    trustStoreRevocation.node.addDependency(deploy);\n\n    lb.addListener('Listener', {\n      port: 443,\n      protocol: elbv2.ApplicationProtocol.HTTPS,\n      certificates: [certificate],\n      mutualAuthentication: {\n        advertiseTrustStoreCaNames: true,\n        ignoreClientCertificateExpiry: false,\n        mutualAuthenticationMode: elbv2.MutualAuthenticationMode.VERIFY,\n        trustStore,\n      },\n      defaultAction: elbv2.ListenerAction.fixedResponse(200,\n        { contentType: 'text/plain', messageBody: 'Success mTLS' }),\n    });\n\n    new route53.ARecord(this, 'ARecord', {\n      target: route53.RecordTarget.fromAlias(new route53targets.LoadBalancerTarget(lb)),\n      zone: hostedZone,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class LogsDeliveryBuilderServiceModule for AWS resource management", "output": "class LogsDeliveryBuilderServiceModule extends BaseServiceSubmodule {\n  public readonly constructLibModule: ExternalModule;\n\n  public constructor(props: ServiceSubmoduleProps) {\n    super(props);\n    this.constructLibModule = new ExternalModule(`aws-cdk-lib/${props.submoduleName}`);\n  }\n}", "language": "typescript"}
{"input": "The mode of evaluation for the rule.", "output": "export class EvaluationMode {\n  /**\n   * Evaluate resources that have already been deployed\n   */\n  public static readonly DETECTIVE = new EvaluationMode(['DETECTIVE']);\n  /**\n   * Evaluate resources before they have been deployed\n   */\n  public static readonly PROACTIVE = new EvaluationMode(['PROACTIVE']);\n  /**\n   * Evaluate resources that have already been deployed and before they have been deployed\n   */\n  public static readonly DETECTIVE_AND_PROACTIVE = new EvaluationMode(['DETECTIVE', 'PROACTIVE']);\n\n  /**\n   * @param modes The modes of evaluation for the rule\n   */\n  protected constructor(public readonly modes: string[]) {}\n}", "language": "typescript"}
{"input": "CDK class CdkInternalHelpers for AWS resource management", "output": "export class CdkInternalHelpers extends ExternalModule {\n  public readonly FromCloudFormationOptions = Type.fromName(this, 'FromCloudFormationOptions');\n  public readonly FromCloudFormationResult = $T(Type.fromName(this, 'FromCloudFormationResult'));\n  public readonly FromCloudFormation = $T(Type.fromName(this, 'FromCloudFormation'));\n  public readonly FromCloudFormationPropertyObject = Type.fromName(this, 'FromCloudFormationPropertyObject');\n  public readonly TemplateString = Type.fromName(this, 'TemplateString');\n\n  constructor(parent: CdkCore) {\n    super(`${parent.fqn}/core/lib/helpers-internal`);\n  }\n}", "language": "typescript"}
{"input": "A service that got generated into a submodule. (This will be used by cfn2ts later to generate all kinds of codegen metadata)", "output": "export class BaseServiceSubmodule {\n  /**\n   * The name of the submodule of aws-cdk-lib where these service resources got written\n   */\n  public readonly submoduleName: string;\n\n  /**\n   * The service this submodule is for\n   */\n  public readonly service: Service;\n\n  /**\n   * Map of CloudFormation resource name to generated type declaration\n   */\n  public readonly resources: Map<string, TypeDeclaration> = new Map();\n\n  public get locatedModules(): LocatedModule<Module>[] {\n    return this.modules;\n  }\n\n  private modules: LocatedModule<Module>[] = [];\n\n  public constructor(props: ServiceSubmoduleProps) {\n    this.submoduleName = props.submoduleName;\n    this.service = props.service;\n  }\n\n  public registerModule(mod: LocatedModule<Module>) {\n    this.modules.push(mod);\n  }\n\n  public registerResource(cfnResourceName: string, type: TypeDeclaration) {\n    this.resources.set(cfnResourceName, type);\n  }\n}", "language": "typescript"}
{"input": "API Key location within the request", "output": "export class ApiKeyCredentialLocation {\n  /**\n   * Create a header-based API key credential location\n   * @param config - Optional configuration for the credential location\n   * @returns ApiKeyCredentialLocation configured for header placement\n   */\n  public static header(config?: ApiKeyAdditionalConfiguration) {\n    return new ApiKeyCredentialLocation(\n      ApiKeyCredentialLocationType.HEADER,\n      config?.credentialParameterName ?? 'Authorization',\n      config?.credentialPrefix ?? 'Bearer ',\n    );\n  }\n\n  /**\n   * Create a query parameter-based API key credential location\n   * @param config - Optional configuration for the credential location\n   * @returns ApiKeyCredentialLocation configured for query parameter placement\n   */\n  public static queryParameter(config?: ApiKeyAdditionalConfiguration) {\n    return new ApiKeyCredentialLocation(\n      ApiKeyCredentialLocationType.QUERY_PARAMETER,\n      config?.credentialParameterName ?? 'api_key',\n      config?.credentialPrefix,\n    );\n  }\n\n  /**\n   * The name of the credential parameter\n   */\n  public readonly credentialParameterName: string;\n  /**\n   * The prefix for the credential value\n   */\n  public readonly credentialPrefix?: string;\n  /**\n   * The type of credential location (HEADER or QUERY_PARAMETER)\n   */\n  public readonly credentialLocationType: string;\n\n  private constructor(\n    credentialLocationType: string,\n    credentialParameterName: string,\n    credentialPrefix?: string,\n  ) {\n    this.credentialLocationType = credentialLocationType;\n    this.credentialParameterName = credentialParameterName;\n    this.credentialPrefix = credentialPrefix;\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for Lambda, Step Functions operations", "output": "def __init__(self, app: App, id: str, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n\n        # Lambda Handlers Definitions\n\n        submit_lambda = _lambda.Function(self, 'submitLambda',\n                                         handler='lambda_function.lambda_handler',\n                                         runtime=_lambda.Runtime.PYTHON_3_9,\n                                         code=_lambda.Code.from_asset('lambdas/submit'))\n\n        status_lambda = _lambda.Function(self, 'statusLambda',\n                                         handler='lambda_function.lambda_handler',\n                                         runtime=_lambda.Runtime.PYTHON_3_9,\n                                         code=_lambda.Code.from_asset('lambdas/status'))\n\n        # Step functions Definition\n\n        submit_job = _aws_stepfunctions_tasks.LambdaInvoke(\n            self, \"Submit Job\",\n            lambda_function=submit_lambda,\n            output_path=\"$.Payload\",\n        )\n\n        wait_job = _aws_stepfunctions.Wait(\n            self, \"Wait 30 Seconds\",\n            time=_aws_stepfunctions.WaitTime.duration(\n                Duration.seconds(30))\n        )\n\n        status_job = _aws_stepfunctions_tasks.LambdaInvoke(\n            self, \"Get Status\",\n            lambda_function=status_lambda,\n            output_path=\"$.Payload\",\n        )\n\n        fail_job = _aws_stepfunctions.Fail(\n            self, \"Fail\",\n            cause='AWS Batch Job Failed',\n            error='DescribeJob returned FAILED'\n        )\n\n        succeed_job = _aws_stepfunctions.Succeed(\n            self, \"Succeeded\",\n            comment='AWS Batch Job succeeded'\n        )\n\n        # Create Chain\n\n        chain = submit_job.next(wait_job)\\\n            .next(status_job)\\\n            .next(_aws_stepfunctions.Choice(self, 'Job Complete?')\n                  .when(_aws_stepfunctions.Condition.string_equals('$.status', 'FAILED'), fail_job)\n                  .when(_aws_stepfunctions.Condition.string_equals('$.status', 'SUCCEEDED'), succeed_job)\n                  .otherwise(wait_job))\n\n        # Create state machine\n        sm = _aws_stepfunctions.StateMachine(\n            self, \"StateMachine\",\n            definition_body=_aws_stepfunctions.DefinitionBody.from_chainable(chain),\n            timeout=Duration.minutes(5),\n        )", "language": "python"}
{"input": "CDK class NsRecord for AWS resource management", "output": "export class NsRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.NsRecord';\n\n  constructor(scope: Construct, id: string, props: NsRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.NS,\n      target: RecordTarget.fromValues(...props.values),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates EC2, VPC, Secrets Manager, CloudFormation resources", "output": "class AdFsxStack extends cdk.Stack {\n  constructor(app: cdk.App, id: string, adDnsDomainName: string) {\n    super(app, id);\n\n    const vpc = new ec2.Vpc(this, 'VPC', {});\n\n    const privateSubnets = vpc.privateSubnets.slice(0,2).map(x => x.subnetId)\n\n    const templatedSecret = new sm.Secret(this, adDnsDomainName + '_credentials', {\n      generateSecretString: {\n        secretStringTemplate: JSON.stringify({ username: 'admin' }),\n        generateStringKey: 'password'\n      },\n    });\n\n    const mad = new ad.CfnMicrosoftAD(this, 'ad', {\n      name: adDnsDomainName,\n      password: templatedSecret.secretValueFromJson('password').toString(),\n      vpcSettings: {\n        vpcId: vpc.vpcId,\n        subnetIds: privateSubnets\n      }\n    })\n\n    const dhcpOptions = new ec2.CfnDHCPOptions(this, 'dhcpOptions', {\n      domainName: adDnsDomainName,\n      domainNameServers: mad.attrDnsIpAddresses,\n    })\n\n    new ec2.CfnVPCDHCPOptionsAssociation(this, 'dhcpOptionsAssoc', {\n      dhcpOptionsId: dhcpOptions.ref,\n      vpcId: vpc.vpcId\n    })\n    \n    const fs = new fsx.CfnFileSystem(this, 'fs', {\n      fileSystemType: 'WINDOWS',\n      subnetIds: privateSubnets,\n      storageType: 'SSD',\n      storageCapacity: 32, \n      windowsConfiguration: {\n        activeDirectoryId: mad.ref,\n        throughputCapacity: 8,\n        deploymentType: 'MULTI_AZ_1',\n        preferredSubnetId: privateSubnets[0]\n      }\n    })\n    \n    const outputs = [\n      {\"name\":\"directoryAlias\",\"value\":mad.attrAlias},\n      {\"name\":\"directoryDns\",\"value\":cdk.Fn.join(',',mad.attrDnsIpAddresses)},\n      {\"name\":\"fsType\", \"value\": fs.fileSystemType},\n      {\"name\":\"subnetIds\", \"value\": cdk.Fn.join(',',privateSubnets)},\n      {\"name\":\"vpcId\", \"value\":vpc.vpcId}\n    ]\n    \n    outputs.forEach((x) => { \n      if (x.value) {\n        new cdk.CfnOutput(this, x.name, {value: x.value})\n      }\n    })\n  }\n}", "language": "typescript"}
{"input": "CDK class HandlerFrameworkClass for AWS resource management", "output": "class HandlerFrameworkClass extends ClassType {\n  /**\n   * Builds a code generated Lambda function class.\n   */\n  public static buildFunction(scope: HandlerFrameworkModule, props: HandlerFrameworkClassProps): HandlerFrameworkClass {\n    return new (class Function extends HandlerFrameworkClass {\n      public constructor() {\n        super(scope, {\n          name: props.name,\n          extends: LAMBDA_MODULE.Function,\n          export: true,\n        });\n\n        if (scope.isAlphaModule) {\n          scope.registerImport(LAMBDA_MODULE, { fromLocation: ALPHA_MODULE_LAMBDA_IMPORT_PATH });\n        } else {\n          scope.registerImport(LAMBDA_MODULE);\n        }\n\n        const superProps = new ObjectLiteral([\n          new Splat(expr.ident('props')),\n          ['code', $T(LAMBDA_MODULE.Code).fromAsset(\n            PATH_MODULE.join.call(expr.directCode(`__dirname, '${props.codeDirectory}'`)),\n          )],\n          ['handler', expr.lit(props.handler)],\n          ['runtime', this.buildRuntimeProperty(scope, { runtime: props.runtime })],\n        ]);\n        const metadataStatements: Statement[] = [\n          stmt.directCode(`this.node.addMetadata('${CUSTOM_RESOURCE_RUNTIME_FAMILY}', this.runtime.family)`),\n        ];\n        this.buildConstructor({\n          constructorPropsType: LAMBDA_MODULE.FunctionOptions,\n          superProps,\n          optionalConstructorProps: true,\n          constructorVisibility: MemberVisibility.Public,\n          statements: metadataStatements,\n        });\n      }\n    })();\n  }\n\n  /**\n   * Builds a code generated Lambda singleton function class.\n   */\n  public static buildSingletonFunction(scope: HandlerFrameworkModule, props: HandlerFrameworkClassProps): HandlerFrameworkClass {\n    return new (class SingletonFunction extends HandlerFrameworkClass {\n      public constructor() {\n        super(scope, {\n          name: props.name,\n          extends: LAMBDA_MODULE.SingletonFunction,\n          export: true,\n        });\n\n        if (scope.isAlphaModule) {\n          scope.registerImport(LAMBDA_MODULE, { fromLocation: ALPHA_MODULE_LAMBDA_IMPORT_PATH });\n        } else {\n          scope.registerImport(LAMBDA_MODULE);\n        }\n\n        const isEvalNodejsProvider = this.fqn.includes('eval-nodejs-provider');\n\n        scope.registerImport(LAMBDA_MODULE);\n\n        const uuid: PropertySpec = {\n          name: 'uuid',\n          type: Type.STRING,\n          immutable: true,\n          docs: {\n            summary: 'A unique identifier to identify this Lambda.\\n\\nThe identifier should be unique across all custom resource providers.\\nWe recommend generating a UUID per provider.',\n          },\n        };\n        const lambdaPurpose: PropertySpec = {\n          name: 'lambdaPurpose',\n          type: Type.STRING,\n          immutable: true,\n          optional: true,\n          docs: {\n            summary: 'A descriptive name for the purpose of this Lambda.\\n\\nIf the Lambda does not have a physical name, this string will be\\nreflected in its generated name. The combination of lambdaPurpose\\nand uuid must be unique.',\n            docTags: {\n              default: 'SingletonLambda',\n            },\n          },\n        };\n        const properties = [uuid, lambdaPurpose];\n        // eval nodejs provider is a one off scenario where the provider makes its runtime property configurable - to maintain this\n        // functionality we need to expose it as well\n        if (isEvalNodejsProvider) {\n          const runtime: PropertySpec = {\n            name: 'runtime',\n            type: LAMBDA_MODULE.Runtime,\n            immutable: true,\n            optional: true,\n            docs: {\n              summary: 'The runtime that this Lambda will use.',\n              docTags: {\n                default: '- the latest Lambda node runtime available in your region.',\n              },\n            },\n          };\n          properties.push(runtime);\n        }\n        const _interface = this.getOrCreateInterface(scope, {\n          name: `${this.name}Props`,\n          export: true,\n          extends: [LAMBDA_MODULE.FunctionOptions],\n          properties,\n          docs: {\n            summary: `Initialization properties for ${this.name}`,\n          },\n        });\n\n        const superProps = new ObjectLiteral([\n          new Splat(expr.ident('props')),\n          ['code', $T(LAMBDA_MODULE.Code).fromAsset(\n            PATH_MODULE.join.call(expr.directCode(`__dirname, '${props.codeDirectory}'`)),\n          )],\n          ['handler', expr.lit(props.handler)],\n          ['runtime', this.buildRuntimeProperty(scope, { runtime: props.runtime, isEvalNodejsProvider })],\n        ]);\n        const metadataStatements: Statement[] = [\n          stmt.directCode(`this.addMetadata('${CUSTOM_RESOURCE_SINGLETON}', true)`),\n          stmt.directCode(`this.addMetadata('${CUSTOM_RESOURCE_RUNTIME_FAMILY}', this.runtime.family)`),\n          stmt.directCode(`if (props?.logGroup) { this.logGroup.node.addMetadata('${CUSTOM_RESOURCE_SINGLETON_LOG_GROUP}', true) }`),\n          // We need to access the private `_logRetention` custom resource, the only public property - `logGroup` - provides an ARN reference to the resource, instead of the resource itself.\n          stmt.directCode(`if (props?.logRetention) { ((this as any).lambdaFunction as lambda.Function)._logRetention?.node.addMetadata('${CUSTOM_RESOURCE_SINGLETON_LOG_RETENTION}', true) }`),\n        ];\n        this.buildConstructor({\n          constructorPropsType: _interface.type,\n          superProps,\n          constructorVisibility: MemberVisibility.Public,\n          statements: metadataStatements,\n        });\n      }\n    })();\n  }\n\n  /**\n   * Builds a code generated custom resource provider class.\n   */\n  public static buildCustomResourceProvider(scope: HandlerFrameworkModule, props: HandlerFrameworkClassProps): HandlerFrameworkClass {\n    return new (class CustomResourceProvider extends HandlerFrameworkClass {\n      public constructor() {\n        super(scope, {\n          name: props.name,\n          extends: CORE_MODULE.CustomResourceProviderBase,\n          export: true,\n        });\n\n        if (scope.isCoreInternal) {\n          scope.registerImport(CORE_MODULE, {\n            targets: [CORE_MODULE.Stack],\n            fromLocation: CORE_INTERNAL_STACK_IMPORT_PATH,\n          });\n          scope.registerImport(CORE_MODULE, {\n            targets: [\n              CORE_MODULE.CustomResourceProviderBase,\n              CORE_MODULE.CustomResourceProviderOptions,\n            ],\n            fromLocation: CORE_INTERNAL_CUSTOM_RESOURCE_PROVIDER_IMPORT_PATH,\n          });\n        } else {\n          scope.registerImport(CORE_MODULE, {\n            targets: [\n              CORE_MODULE.Stack,\n              CORE_MODULE.CustomResourceProviderBase,\n              CORE_MODULE.CustomResourceProviderOptions,\n            ],\n          });\n        }\n\n        const getOrCreateMethod = this.addMethod({\n          name: 'getOrCreate',\n          static: true,\n          returnType: Type.STRING,\n          docs: {\n            summary: 'Returns a stack-level singleton ARN (service token) for the custom resource provider.',\n          },\n        });\n        getOrCreateMethod.addParameter({\n          name: 'scope',\n          type: CONSTRUCTS_MODULE.Construct,\n        });\n        getOrCreateMethod.addParameter({\n          name: 'uniqueid',\n          type: Type.STRING,\n        });\n        getOrCreateMethod.addParameter({\n          name: 'props',\n          type: CORE_MODULE.CustomResourceProviderOptions,\n          optional: true,\n        });\n        getOrCreateMethod.addBody(\n          stmt.ret(expr.directCode('this.getOrCreateProvider(scope, uniqueid, props).serviceToken')),\n        );\n\n        const getOrCreateProviderMethod = this.addMethod({\n          name: 'getOrCreateProvider',\n          static: true,\n          returnType: this.type,\n          docs: {\n            summary: 'Returns a stack-level singleton for the custom resource provider.',\n          },\n        });\n        const _scope = getOrCreateProviderMethod.addParameter({\n          name: 'scope',\n          type: CONSTRUCTS_MODULE.Construct,\n        });\n        getOrCreateProviderMethod.addParameter({\n          name: 'uniqueid',\n          type: Type.STRING,\n        });\n        getOrCreateProviderMethod.addParameter({\n          name: 'props',\n          type: CORE_MODULE.CustomResourceProviderOptions,\n          optional: true,\n        });\n        getOrCreateProviderMethod.addBody(\n          stmt.constVar(expr.ident('id'), expr.directCode('`${uniqueid}CustomResourceProvider`')),\n          stmt.constVar(expr.ident('stack'), $T(CORE_MODULE.Stack).of(expr.directCode(_scope.spec.name))),\n          stmt.constVar(expr.ident('existing'), expr.directCode(`stack.node.tryFindChild(id) as ${this.type}`)),\n          stmt.ret(expr.directCode(`existing ?? new ${this.name}(stack, id, props)`)),\n        );\n\n        const superProps = new ObjectLiteral([\n          new Splat(expr.ident('props')),\n          ['codeDirectory', PATH_MODULE.join.call(expr.directCode(`__dirname, '${props.codeDirectory}'`))],\n          ['runtimeName', this.buildRuntimeProperty(scope, {\n            runtime: props.runtime,\n            isCustomResourceProvider: true,\n          })],\n        ]);\n        const metadataStatements: Statement[] = [stmt.directCode(`this.node.addMetadata('${CUSTOM_RESOURCE_PROVIDER}', true)`)];\n        this.buildConstructor({\n          constructorPropsType: CORE_MODULE.CustomResourceProviderOptions,\n          superProps,\n          constructorVisibility: props.constructorVisibility ?? MemberVisibility.Private,\n          optionalConstructorProps: true,\n          statements: metadataStatements,\n        });\n      }\n    })();\n  }\n\n  protected constructor(scope: HandlerFrameworkModule, spec: ClassSpec) {\n    super(scope, spec);\n    scope.registerImport(PATH_MODULE);\n    scope.registerImport(CONSTRUCTS_MODULE, {\n      targets: [CONSTRUCTS_MODULE.Construct],\n    });\n  }\n\n  private getOrCreateInterface(scope: HandlerFrameworkModule, spec: InterfaceSpec) {\n    const existing = scope.getInterface(spec.name);\n    if (existing) {\n      return existing;\n    }\n\n    const _interface = new InterfaceType(scope, { ...spec });\n    scope.registerInterface(_interface);\n    return _interface;\n  }\n\n  private buildConstructor(props: ConstructorBuildProps) {\n    const init = this.addInitializer({\n      visibility: props.constructorVisibility,\n    });\n    const scope = init.addParameter({\n      name: 'scope',\n      type: CONSTRUCTS_MODULE.Construct,\n    });\n    const id = init.addParameter({\n      name: 'id',\n      type: Type.STRING,\n    });\n    init.addParameter({\n      name: 'props',\n      type: props.constructorPropsType,\n      optional: props.optionalConstructorProps,\n    });\n\n    const superInitializerArgs: Expression[] = [scope, id, props.superProps];\n    init.addBody(new SuperInitializer(...superInitializerArgs));\n    if (props.statements) {\n      for (const statement of props.statements) {\n        init.addBody(statement);\n      }\n    }\n  }\n\n  private buildRuntimeProperty(scope: HandlerFrameworkModule, options: BuildRuntimePropertyOptions = {}) {\n    const { runtime, isCustomResourceProvider, isEvalNodejsProvider } = options;\n\n    if (runtime) {\n      return isCustomResourceProvider ? expr.lit(runtime) : expr.directCode(toLambdaRuntime(runtime));\n    }\n\n    if (isCustomResourceProvider) {\n      scope.registerImport(CORE_MODULE, {\n        targets: [CORE_MODULE.determineLatestNodeRuntimeName],\n        fromLocation: scope.isCoreInternal\n          ? CORE_INTERNAL_CUSTOM_RESOURCE_PROVIDER_IMPORT_PATH\n          : CORE_MODULE.fqn,\n      });\n    }\n\n    const _scope = expr.ident('scope');\n    const call = isCustomResourceProvider\n      ? CORE_MODULE.determineLatestNodeRuntimeName.call(_scope)\n      : LAMBDA_MODULE.determineLatestNodeRuntime.call(_scope);\n\n    return isEvalNodejsProvider\n      ? expr.cond(expr.directCode('props.runtime'), expr.directCode('props.runtime'), call)\n      : call;\n  }\n}", "language": "typescript"}
{"input": "Endpoint access characteristics.", "output": "export class EndpointAccess {\n  /**\n   * The cluster endpoint is accessible from outside of your VPC.\n   * Worker node traffic will leave your VPC to connect to the endpoint.\n   *\n   * By default, the endpoint is exposed to all adresses. You can optionally limit the CIDR blocks that can access the public endpoint using the `PUBLIC.onlyFrom` method.\n   * If you limit access to specific CIDR blocks, you must ensure that the CIDR blocks that you\n   * specify include the addresses that worker nodes and Fargate pods (if you use them)\n   * access the public endpoint from.\n   *\n   * @param cidr The CIDR blocks.\n   */\n  public static readonly PUBLIC = new EndpointAccess({ privateAccess: false, publicAccess: true });\n\n  /**\n   * The cluster endpoint is only accessible through your VPC.\n   * Worker node traffic to the endpoint will stay within your VPC.\n   */\n  public static readonly PRIVATE = new EndpointAccess({ privateAccess: true, publicAccess: false });\n\n  /**\n   * The cluster endpoint is accessible from outside of your VPC.\n   * Worker node traffic to the endpoint will stay within your VPC.\n   *\n   * By default, the endpoint is exposed to all adresses. You can optionally limit the CIDR blocks that can access the public endpoint using the `PUBLIC_AND_PRIVATE.onlyFrom` method.\n   * If you limit access to specific CIDR blocks, you must ensure that the CIDR blocks that you\n   * specify include the addresses that worker nodes and Fargate pods (if you use them)\n   * access the public endpoint from.\n   *\n   * @param cidr The CIDR blocks.\n   */\n  public static readonly PUBLIC_AND_PRIVATE = new EndpointAccess({ privateAccess: true, publicAccess: true });\n\n  private constructor(\n    /**\n     * Configuration properties.\n     *\n     * @internal\n     */\n    public readonly _config: EndpointAccessConfig) {\n    if (!_config.publicAccess && _config.publicCidrs && _config.publicCidrs.length > 0) {\n      throw new Error('CIDR blocks can only be configured when public access is enabled');\n    }\n  }\n\n  /**\n   * Restrict public access to specific CIDR blocks.\n   * If public access is disabled, this method will result in an error.\n   *\n   * @param cidr CIDR blocks.\n   */\n  public onlyFrom(...cidr: string[]) {\n    if (!this._config.privateAccess) {\n      // when private access is disabled, we can't restric public\n      // access since it will render the kubectl provider unusable.\n      throw new Error('Cannot restric public access to endpoint when private access is disabled. Use PUBLIC_AND_PRIVATE.onlyFrom() instead.');\n    }\n    return new EndpointAccess({\n      ...this._config,\n      // override CIDR\n      publicCidrs: cidr,\n    });\n  }\n}\n\n/**\n * Options for configuring EKS Auto Mode compute settings.\n * When enabled, EKS will automatically manage compute resources like node groups and Fargate profiles.\n */\nexport interface ComputeConfig {\n  /**\n   * Names of nodePools to include in Auto Mode.\n   * You cannot modify the built in system and general-purpose node pools. You can only enable or disable them.\n   * Node pool values are case-sensitive and must be `general-purpose` and/or `system`.\n   *\n   * @see - https://docs.aws.amazon.com/eks/latest/userguide/create-node-pool.html\n   *\n   * @default - ['system', 'general-purpose']\n   */\n  readonly nodePools?: string[];\n\n  /**\n   * IAM role for the nodePools.\n   *\n   * @see - https://docs.aws.amazon.com/eks/latest/userguide/create-node-role.html\n   *\n   * @default - generated by the CDK\n   */\n  readonly nodeRole?: iam.IRole;\n\n}\n\n/**\n * Properties for configuring a standard EKS cluster (non-Fargate)\n */\nexport interface ClusterProps extends ClusterCommonOptions {\n  /**\n   * Configuration for compute settings in Auto Mode.\n   * When enabled, EKS will automatically manage compute resources.\n   * @default - Auto Mode compute disabled\n   */\n  readonly compute?: ComputeConfig;\n\n  /**\n   * Number of instances to allocate as an initial capacity for this cluster.\n   * Instance type can be configured through `defaultCapacityInstanceType`,\n   * which defaults to `m5.large`.\n   *\n   * Use `cluster.addAutoScalingGroupCapacity` to add additional customized capacity. Set this\n   * to `0` is you wish to avoid the initial capacity allocation.\n   *\n   * @default 2\n   */\n  readonly defaultCapacity?: number;\n\n  /**\n   * The instance type to use for the default capacity. This will only be taken\n   * into account if `defaultCapacity` is > 0.\n   *\n   * @default m5.large\n   */\n  readonly defaultCapacityInstance?: ec2.InstanceType;\n\n  /**\n   * The default capacity type for the cluster.\n   *\n   * @default AUTOMODE\n   */\n  readonly defaultCapacityType?: DefaultCapacityType;\n\n  /**\n   * Whether or not IAM principal of the cluster creator was set as a cluster admin access entry\n   * during cluster creation time.\n   *\n   * Changing this value after the cluster has been created will result in the cluster being replaced.\n   *\n   * @default true\n   */\n  readonly bootstrapClusterCreatorAdminPermissions?: boolean;\n\n  /**\n   * Determines whether a CloudFormation output with the `aws eks\n   * update-kubeconfig` command will be synthesized. This command will include\n   * the cluster name and, if applicable, the ARN of the masters IAM role.\n   *\n   * @default true\n   */\n  readonly outputConfigCommand?: boolean;\n}\n\n/**\n * Kubernetes cluster version\n * @see https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar\n */\nexport class KubernetesVersion {\n  /**\n   * Kubernetes version 1.25\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV25Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v25`.\n   */\n  public static readonly V1_25 = KubernetesVersion.of('1.25');\n\n  /**\n   * Kubernetes version 1.26\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV26Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v26`.\n   */\n  public static readonly V1_26 = KubernetesVersion.of('1.26');\n\n  /**\n   * Kubernetes version 1.27\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV27Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v27`.\n   */\n  public static readonly V1_27 = KubernetesVersion.of('1.27');\n\n  /**\n   * Kubernetes version 1.28\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV28Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v28`.\n   */\n  public static readonly V1_28 = KubernetesVersion.of('1.28');\n\n  /**\n   * Kubernetes version 1.29\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV29Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v29`.\n   */\n  public static readonly V1_29 = KubernetesVersion.of('1.29');\n\n  /**\n   * Kubernetes version 1.30\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV30Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v30`.\n   */\n  public static readonly V1_30 = KubernetesVersion.of('1.30');\n\n  /**\n   * Kubernetes version 1.31\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV31Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v31`.\n   */\n  public static readonly V1_31 = KubernetesVersion.of('1.31');\n\n  /**\n   * Kubernetes version 1.32\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV32Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v32`.\n   */\n  public static readonly V1_32 = KubernetesVersion.of('1.32');\n\n  /**\n   * Kubernetes version 1.33\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV33Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v33`.\n   */\n  public static readonly V1_33 = KubernetesVersion.of('1.33');\n\n  /**\n   * Kubernetes version 1.34\n   *\n   * When creating a `Cluster` with this version, you need to also specify the\n   * `kubectlLayer` property with a `KubectlV34Layer` from\n   * `@aws-cdk/lambda-layer-kubectl-v34`.\n   */\n  public static readonly V1_34 = KubernetesVersion.of('1.34');\n\n  /**\n   * Custom cluster version\n   * @param version custom version number\n   */\n  public static of(version: string) { return new KubernetesVersion(version); }\n  /**\n   *\n   * @param version cluster version number\n   */\n  private constructor(public readonly version: string) { }\n}\n\n// Shared definition with packages/@aws-cdk/custom-resource-handlers/test/aws-eks/compare-log.test.ts\n/**\n * EKS cluster logging types\n */\nexport enum ClusterLoggingTypes {\n  /**\n   * Logs pertaining to API requests to the cluster.\n   */\n  API = 'api',\n  /**\n   * Logs pertaining to cluster access via the Kubernetes API.\n   */\n  AUDIT = 'audit',\n  /**\n   * Logs pertaining to authentication requests into the cluster.\n   */\n  AUTHENTICATOR = 'authenticator',\n  /**\n   * Logs pertaining to state of cluster controllers.\n   */\n  CONTROLLER_MANAGER = 'controllerManager',\n  /**\n   * Logs pertaining to scheduling decisions.\n   */\n  SCHEDULER = 'scheduler',\n}\n\n/**\n * EKS cluster IP family.\n */\nexport enum IpFamily {\n  /**\n   * Use IPv4 for pods and services in your cluster.\n   */\n  IP_V4 = 'ipv4',\n  /**\n   * Use IPv6 for pods and services in your cluster.\n   */\n  IP_V6 = 'ipv6',\n}\n\nabstract class ClusterBase extends Resource implements ICluster {\n  public abstract readonly connections: ec2.Connections;\n  public abstract readonly vpc: ec2.IVpc;\n  public abstract readonly clusterName: string;\n  public abstract readonly clusterArn: string;\n  public abstract readonly clusterEndpoint: string;\n  public abstract readonly clusterCertificateAuthorityData: string;\n  public abstract readonly clusterSecurityGroupId: string;\n  public abstract readonly clusterSecurityGroup: ec2.ISecurityGroup;\n  public abstract readonly clusterEncryptionConfigKeyArn: string;\n  public abstract readonly ipFamily?: IpFamily;\n  public abstract readonly prune: boolean;\n  public abstract readonly openIdConnectProvider: iam.IOpenIdConnectProvider;\n\n  /**\n   * Defines a Kubernetes resource in this cluster.\n   *\n   * The manifest will be applied/deleted using kubectl as needed.\n   *\n   * @param id logical id of this manifest\n   * @param manifest a list of Kubernetes resource specifications\n   * @returns a `KubernetesResource` object.\n   */\n  public addManifest(id: string, ...manifest: Record<string, any>[]): KubernetesManifest {\n    return new KubernetesManifest(this, `manifest-${id}`, { cluster: this, manifest });\n  }\n\n  /**\n   * Defines a Helm chart in this cluster.\n   *\n   * @param id logical id of this chart.\n   * @param options options of this chart.\n   * @returns a `HelmChart` construct\n   */\n  public addHelmChart(id: string, options: HelmChartOptions): HelmChart {\n    return new HelmChart(this, `chart-${id}`, { cluster: this, ...options });\n  }\n\n  /**\n   * Defines a CDK8s chart in this cluster.\n   *\n   * @param id logical id of this chart.\n   * @param chart the cdk8s chart.\n   * @returns a `KubernetesManifest` construct representing the chart.\n   */\n  public addCdk8sChart(id: string, chart: Construct, options: KubernetesManifestOptions = {}): KubernetesManifest {\n    const cdk8sChart = chart as any;\n\n    // see https://github.com/awslabs/cdk8s/blob/master/packages/cdk8s/src/chart.ts#L84\n    if (typeof cdk8sChart.toJson !== 'function') {\n      throw new Error(`Invalid cdk8s chart. Must contain a 'toJson' method, but found ${typeof cdk8sChart.toJson}`);\n    }\n\n    const manifest = new KubernetesManifest(this, id, {\n      cluster: this,\n      manifest: cdk8sChart.toJson(),\n      ...options,\n    });\n\n    return manifest;\n  }\n\n  public addServiceAccount(id: string, options: ServiceAccountOptions = {}): ServiceAccount {\n    return new ServiceAccount(this, id, {\n      ...options,\n      cluster: this,\n    });\n  }\n\n  /**\n   * Connect capacity in the form of an existing AutoScalingGroup to the EKS cluster.\n   *\n   * The AutoScalingGroup must be running an EKS-optimized AMI containing the\n   * /etc/eks/bootstrap.sh script. This method will configure Security Groups,\n   * add the right policies to the instance role, apply the right tags, and add\n   * the required user data to the instance's launch configuration.\n   *\n   * Prefer to use `addAutoScalingGroupCapacity` if possible.\n   *\n   * @see https://docs.aws.amazon.com/eks/latest/userguide/launch-workers.html\n   * @param autoScalingGroup [disable-awslint:ref-via-interface]\n   * @param options options for adding auto scaling groups, like customizing the bootstrap script\n   */\n  public connectAutoScalingGroupCapacity(autoScalingGroup: autoscaling.AutoScalingGroup, options: AutoScalingGroupOptions) {\n    // self rules\n    autoScalingGroup.connections.allowInternally(ec2.Port.allTraffic());\n\n    // Cluster to:nodes rules\n    autoScalingGroup.connections.allowFrom(this, ec2.Port.tcp(443));\n    autoScalingGroup.connections.allowFrom(this, ec2.Port.tcpRange(1025, 65535));\n\n    // Allow HTTPS from Nodes to Cluster\n    autoScalingGroup.connections.allowTo(this, ec2.Port.tcp(443));\n\n    // Allow all node outbound traffic\n    autoScalingGroup.connections.allowToAnyIpv4(ec2.Port.allTcp());\n    autoScalingGroup.connections.allowToAnyIpv4(ec2.Port.allUdp());\n    autoScalingGroup.connections.allowToAnyIpv4(ec2.Port.allIcmp());\n\n    // allow traffic to/from managed node groups (eks attaches this security group to the managed nodes)\n    autoScalingGroup.addSecurityGroup(this.clusterSecurityGroup);\n\n    const bootstrapEnabled = options.bootstrapEnabled ?? true;\n    if (options.bootstrapOptions && !bootstrapEnabled) {\n      throw new Error('Cannot specify \"bootstrapOptions\" if \"bootstrapEnabled\" is false');\n    }\n\n    if (bootstrapEnabled) {\n      const userData = options.machineImageType === MachineImageType.BOTTLEROCKET ?\n        renderBottlerocketUserData(this) :\n        renderAmazonLinuxUserData(this, autoScalingGroup, options.bootstrapOptions);\n      autoScalingGroup.addUserData(...userData);\n    }\n\n    autoScalingGroup.role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEKSWorkerNodePolicy'));\n    autoScalingGroup.role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEKS_CNI_Policy'));\n    autoScalingGroup.role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEC2ContainerRegistryReadOnly'));\n\n    // EKS Required Tags\n    // https://docs.aws.amazon.com/eks/latest/userguide/worker.html\n    Tags.of(autoScalingGroup).add(`kubernetes.io/cluster/${this.clusterName}`, 'owned', {\n      applyToLaunchedInstances: true,\n      // exclude security groups to avoid multiple \"owned\" security groups.\n      // (the cluster security group already has this tag)\n      excludeResourceTypes: ['AWS::EC2::SecurityGroup'],\n    });\n\n    // since we are not mapping the instance role to RBAC, synthesize an\n    // output so it can be pasted into `aws-auth-cm.yaml`\n    new CfnOutput(autoScalingGroup, 'InstanceRoleARN', {\n      value: autoScalingGroup.role.roleArn,\n    });\n\n    if (this instanceof Cluster && this.albController) {\n      // the controller runs on the worker nodes so they cannot\n      // be deleted before the controller.\n      Node.of(this.albController).addDependency(autoScalingGroup);\n    }\n  }\n}\n\n/**\n * Options for fetching a ServiceLoadBalancerAddress.\n */\nexport interface ServiceLoadBalancerAddressOptions {\n\n  /**\n   * Timeout for waiting on the load balancer address.\n   *\n   * @default Duration.minutes(5)\n   */\n  readonly timeout?: Duration;\n\n  /**\n   * The namespace the service belongs to.\n   *\n   * @default 'default'\n   */\n  readonly namespace?: string;\n\n}\n\n/**\n * Options for fetching an IngressLoadBalancerAddress.\n */\nexport interface IngressLoadBalancerAddressOptions extends ServiceLoadBalancerAddressOptions {}\n\n/**\n * A Cluster represents a managed Kubernetes Service (EKS)\n *\n * This is a fully managed cluster of API Servers (control-plane)\n * The user is still required to create the worker nodes.\n * @resource AWS::EKS::Cluster\n */\n@propertyInjectable\nexport class Cluster extends ClusterBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-eks-v2-alpha.Cluster';\n\n  /**\n   * Import an existing cluster\n   *\n   * @param scope the construct scope, in most cases 'this'\n   * @param id the id or name to import as\n   * @param attrs the cluster properties to use for importing information\n   */\n  public static fromClusterAttributes(scope: Construct, id: string, attrs: ClusterAttributes): ICluster {\n    return new ImportedCluster(scope, id, attrs);\n  }\n\n  private accessEntries: Map<string, IAccessEntry> = new Map();\n\n  /**\n   * The VPC in which this Cluster was created\n   */\n  public readonly vpc: ec2.IVpc;\n\n  /**\n   * The Name of the created EKS Cluster\n   */\n  public readonly clusterName: string;\n\n  /**\n   * The AWS generated ARN for the Cluster resource\n   *\n   * For example, `arn:aws:eks:us-west-2:666666666666:cluster/prod`\n   */\n  public readonly clusterArn: string;\n\n  /**\n   * The endpoint URL for the Cluster\n   *\n   * This is the URL inside the kubeconfig file to use with kubectl\n   *\n   * For example, `https://5E1D0CEXAMPLEA591B746AFC5AB30262.yl4.us-west-2.eks.amazonaws.com`\n   */\n  public readonly clusterEndpoint: string;\n\n  /**\n   * The certificate-authority-data for your cluster.\n   */\n  public readonly clusterCertificateAuthorityData: string;\n\n  /**\n   * The id of the cluster security group that was created by Amazon EKS for the cluster.\n   */\n  public readonly clusterSecurityGroupId: string;\n\n  /**\n   * The cluster security group that was created by Amazon EKS for the cluster.\n   */\n  public readonly clusterSecurityGroup: ec2.ISecurityGroup;\n\n  /**\n   * Amazon Resource Name (ARN) or alias of the customer master key (CMK).\n   */\n  public readonly clusterEncryptionConfigKeyArn: string;\n\n  /**\n   * Manages connection rules (Security Group Rules) for the cluster\n   *\n   * @type {ec2.Connections}\n   * @memberof Cluster\n   */\n  public readonly connections: ec2.Connections;\n\n  /**\n   * IAM role assumed by the EKS Control Plane\n   */\n  public readonly role: iam.IRole;\n\n  /**\n   * The auto scaling group that hosts the default capacity for this cluster.\n   * This will be `undefined` if the `defaultCapacityType` is not `EC2` or\n   * `defaultCapacityType` is `EC2` but default capacity is set to 0.\n   */\n  public readonly defaultCapacity?: autoscaling.AutoScalingGroup;\n\n  /**\n   * The node group that hosts the default capacity for this cluster.\n   * This will be `undefined` if the `defaultCapacityType` is `EC2` or\n   * `defaultCapacityType` is `NODEGROUP` but default capacity is set to 0.\n   */\n  public readonly defaultNodegroup?: Nodegroup;\n\n  /**\n   * Specify which IP family is used to assign Kubernetes pod and service IP addresses.\n   *\n   * @default IpFamily.IP_V4\n   * @see https://docs.aws.amazon.com/eks/latest/APIReference/API_KubernetesNetworkConfigRequest.html#AmazonEKS-Type-KubernetesNetworkConfigRequest-ipFamily\n   */\n  public readonly ipFamily?: IpFamily;\n\n  /**\n   * If the cluster has one (or more) FargateProfiles associated, this array\n   * will hold a reference to each.\n   */\n  private readonly _fargateProfiles: FargateProfile[] = [];\n\n  /**\n   * an Open ID Connect Provider instance\n   */\n  private _openIdConnectProvider?: iam.IOpenIdConnectProvider;\n\n  /**\n   * an EKS Pod Identity Agent instance\n   */\n  private _eksPodIdentityAgent?: IAddon;\n\n  /**\n   * Determines if Kubernetes resources can be pruned automatically.\n   */\n  public readonly prune: boolean;\n\n  /**\n   * The ALB Controller construct defined for this cluster.\n   * Will be undefined if `albController` wasn't configured.\n   */\n  public readonly albController?: AlbController;\n\n  private readonly _clusterResource: CfnCluster;\n\n  private _neuronDevicePlugin?: KubernetesManifest;\n\n  private readonly endpointAccess: EndpointAccess;\n\n  private readonly vpcSubnets: ec2.SubnetSelection[];\n\n  private readonly version: KubernetesVersion;\n\n  // TODO: revisit logging format\n  private readonly logging?: { [key: string]: { [key:string]: any} };\n\n  /**\n   * A dummy CloudFormation resource that is used as a wait barrier which\n   * represents that the cluster is ready to receive \"kubectl\" commands.\n   *\n   * Specifically, all fargate profiles are automatically added as a dependency\n   * of this barrier, which means that it will only be \"signaled\" when all\n   * fargate profiles have been successfully created.\n   *\n   * When kubectl resources call `_attachKubectlResourceScope()`, this resource\n   * is added as their dependency which implies that they can only be deployed\n   * after the cluster is ready.\n   */\n  private readonly _kubectlReadyBarrier: CfnResource;\n\n  private readonly _kubectlProviderOptions?: KubectlProviderOptions;\n\n  private readonly _kubectlProvider?: IKubectlProvider;\n\n  private readonly _clusterAdminAccess?: AccessEntry;\n\n  /**\n   * Initiates an EKS Cluster with the supplied arguments\n   *\n   * @param scope a Construct, most likely a cdk.Stack created\n   * @param id the id of the Construct to create\n   * @param props properties in the IClusterProps interface\n   */\n  constructor(scope: Construct, id: string, props: ClusterProps) {\n    super(scope, id, {\n      physicalName: props.clusterName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.prune = props.prune ?? true;\n    this.vpc = props.vpc || new ec2.Vpc(this, 'DefaultVpc');\n    this.version = props.version;\n\n    this._kubectlProviderOptions = props.kubectlProviderOptions;\n\n    this.tagSubnets();\n\n    // this is the role used by EKS when interacting with AWS resources\n    this.role = props.role || new iam.Role(this, 'Role', {\n      assumedBy: new iam.ServicePrincipal('eks.amazonaws.com'),\n      managedPolicies: [\n        iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEKSClusterPolicy'),\n      ],\n    });\n\n    // validate all automode relevant configurations\n    const autoModeEnabled = this.isValidAutoModeConfig(props);\n\n    if (autoModeEnabled) {\n      // attach required managed policy for the cluster role in EKS Auto Mode\n      // see - https://docs.aws.amazon.com/eks/latest/userguide/auto-cluster-iam-role.html\n      ['AmazonEKSComputePolicy',\n        'AmazonEKSBlockStoragePolicy',\n        'AmazonEKSLoadBalancingPolicy',\n        'AmazonEKSNetworkingPolicy'].forEach((policyName) => {\n        this.role.addManagedPolicy(iam.ManagedPolicy.fromAwsManagedPolicyName(policyName));\n      });\n\n      // sts:TagSession is required for EKS Auto Mode or when using EKS Pod Identity features.\n      // see https://docs.aws.amazon.com/eks/latest/userguide/pod-id-role.html\n      // https://docs.aws.amazon.com/eks/latest/userguide/automode-get-started-cli.html#_create_an_eks_auto_mode_cluster_iam_role\n      if (this.role instanceof iam.Role) {\n        this.role.assumeRolePolicy?.addStatements(\n          new iam.PolicyStatement({\n            effect: iam.Effect.ALLOW,\n            principals: [new iam.ServicePrincipal('eks.amazonaws.com')],\n            actions: ['sts:TagSession'],\n          }),\n        );\n      }\n    }\n\n    const securityGroup = props.securityGroup || new ec2.SecurityGroup(this, 'ControlPlaneSecurityGroup', {\n      vpc: this.vpc,\n      description: 'EKS Control Plane Security Group',\n    });\n\n    this.vpcSubnets = props.vpcSubnets ?? [{ subnetType: ec2.SubnetType.PUBLIC }, { subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS }];\n\n    const selectedSubnetIdsPerGroup = this.vpcSubnets.map(s => this.vpc.selectSubnets(s).subnetIds);\n    if (selectedSubnetIdsPerGroup.some(Token.isUnresolved) && selectedSubnetIdsPerGroup.length > 1) {\n      throw new Error('eks.Cluster: cannot select multiple subnet groups from a VPC imported from list tokens with unknown length. Select only one subnet group, pass a length to Fn.split, or switch to Vpc.fromLookup.');\n    }\n\n    // Get subnetIds for all selected subnets\n    const subnetIds = Array.from(new Set(flatten(selectedSubnetIdsPerGroup)));\n\n    this.logging = props.clusterLogging ? {\n      clusterLogging: {\n        enabledTypes: props.clusterLogging.map((type) => ({ type })),\n      },\n    } : undefined;\n\n    this.endpointAccess = props.endpointAccess ?? EndpointAccess.PUBLIC_AND_PRIVATE;\n    this.ipFamily = props.ipFamily ?? IpFamily.IP_V4;\n\n    const privateSubnets = this.selectPrivateSubnets().slice(0, 16);\n    const publicAccessDisabled = !this.endpointAccess._config.publicAccess;\n    const publicAccessRestricted = !publicAccessDisabled\n      && this.endpointAccess._config.publicCidrs\n      && this.endpointAccess._config.publicCidrs.length !== 0;\n\n    // validate endpoint access configuration\n\n    if (privateSubnets.length === 0 && publicAccessDisabled) {\n      // no private subnets and no public access at all, no good.\n      throw new Error('Vpc must contain private subnets when public endpoint access is disabled');\n    }\n\n    if (privateSubnets.length === 0 && publicAccessRestricted) {\n      // no private subnets and public access is restricted, no good.\n      throw new Error('Vpc must contain private subnets when public endpoint access is restricted');\n    }\n\n    if (props.serviceIpv4Cidr && props.ipFamily == IpFamily.IP_V6) {\n      throw new Error('Cannot specify serviceIpv4Cidr with ipFamily equal to IpFamily.IP_V6');\n    }\n\n    const resource = this._clusterResource = new CfnCluster(this, 'Resource', {\n      name: this.physicalName,\n      roleArn: this.role.roleArn,\n      version: props.version.version,\n      accessConfig: {\n        authenticationMode: 'API',\n        bootstrapClusterCreatorAdminPermissions: props.bootstrapClusterCreatorAdminPermissions,\n      },\n      computeConfig: {\n        enabled: autoModeEnabled,\n        // If the computeConfig enabled flag is set to false when creating a cluster with Auto Mode,\n        // the request must not include values for the nodeRoleArn or nodePools fields.\n        // Also, if nodePools is empty, nodeRoleArn should not be included to prevent deployment failures\n        nodePools: !autoModeEnabled ? undefined : props.compute?.nodePools ?? ['system', 'general-purpose'],\n        nodeRoleArn: !autoModeEnabled || (props.compute?.nodePools && props.compute.nodePools.length === 0) ?\n          undefined :\n          props.compute?.nodeRole?.roleArn ?? this.addNodePoolRole(`${id}nodePoolRole`).roleArn,\n      },\n      storageConfig: {\n        blockStorage: {\n          enabled: autoModeEnabled,\n        },\n      },\n      kubernetesNetworkConfig: {\n        ipFamily: this.ipFamily,\n        serviceIpv4Cidr: props.serviceIpv4Cidr,\n        elasticLoadBalancing: {\n          enabled: autoModeEnabled,\n        },\n      },\n      resourcesVpcConfig: {\n        securityGroupIds: [securityGroup.securityGroupId],\n        subnetIds,\n        endpointPrivateAccess: this.endpointAccess._config.privateAccess,\n        endpointPublicAccess: this.endpointAccess._config.publicAccess,\n        publicAccessCidrs: this.endpointAccess._config.publicCidrs,\n      },\n      ...(props.secretsEncryptionKey ? {\n        encryptionConfig: [{\n          provider: {\n            keyArn: props.secretsEncryptionKey.keyRef.keyArn,\n          },\n          resources: ['secrets'],\n        }],\n      } : {}),\n      tags: Object.keys(props.tags ?? {}).map(k => ({ key: k, value: props.tags![k] })),\n      logging: this.logging,\n    });\n\n    let kubectlSubnets = this._kubectlProviderOptions?.privateSubnets;\n\n    if (this.endpointAccess._config.privateAccess && privateSubnets.length !== 0) {\n      // when private access is enabled and the vpc has private subnets, lets connect\n      // the provider to the vpc so that it will work even when restricting public access.\n\n      // validate VPC properties according to: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html\n      if (this.vpc instanceof ec2.Vpc && !(this.vpc.dnsHostnamesEnabled && this.vpc.dnsSupportEnabled)) {\n        throw new Error('Private endpoint access requires the VPC to have DNS support and DNS hostnames enabled. Use `enableDnsHostnames: true` and `enableDnsSupport: true` when creating the VPC.');\n      }\n\n      kubectlSubnets = privateSubnets;\n\n      // the vpc must exist in order to properly delete the cluster (since we run `kubectl delete`).\n      // this ensures that.\n      this._clusterResource.node.addDependency(this.vpc);\n    }\n\n    // we use an SSM parameter as a barrier because it's free and fast.\n    this._kubectlReadyBarrier = new CfnResource(this, 'KubectlReadyBarrier', {\n      type: 'AWS::SSM::Parameter',\n      properties: {\n        Type: 'String',\n        Value: 'aws:cdk:eks:kubectl-ready',\n      },\n    });\n\n    // add the cluster resource itself as a dependency of the barrier\n    this._kubectlReadyBarrier.node.addDependency(this._clusterResource);\n\n    this.clusterName = this.getResourceNameAttribute(resource.ref);\n    this.clusterArn = this.getResourceArnAttribute(resource.attrArn, clusterArnComponents(this.physicalName));\n\n    this.clusterEndpoint = resource.attrEndpoint;\n    this.clusterCertificateAuthorityData = resource.attrCertificateAuthorityData;\n    this.clusterSecurityGroupId = resource.attrClusterSecurityGroupId;\n    this.clusterEncryptionConfigKeyArn = resource.attrEncryptionConfigKeyArn;\n\n    this.clusterSecurityGroup = ec2.SecurityGroup.fromSecurityGroupId(this, 'ClusterSecurityGroup', this.clusterSecurityGroupId);\n\n    this.connections = new ec2.Connections({\n      securityGroups: [this.clusterSecurityGroup, securityGroup],\n      defaultPort: ec2.Port.tcp(443), // Control Plane has an HTTPS API\n    });\n\n    const stack = Stack.of(this);\n    const updateConfigCommandPrefix = `aws eks update-kubeconfig --name ${this.clusterName}`;\n    const getTokenCommandPrefix = `aws eks get-token --cluster-name ${this.clusterName}`;\n    const commonCommandOptions = [`--region ${stack.region}`];\n\n    if (props.kubectlProviderOptions) {\n      this._kubectlProvider = new KubectlProvider(this, 'KubectlProvider', {\n        cluster: this,\n        role: this._kubectlProviderOptions?.role,\n        awscliLayer: this._kubectlProviderOptions?.awscliLayer,\n        kubectlLayer: this._kubectlProviderOptions!.kubectlLayer,\n        environment: this._kubectlProviderOptions?.environment,\n        memory: this._kubectlProviderOptions?.memory,\n        privateSubnets: kubectlSubnets,\n      });\n\n      // give the handler role admin access to the cluster\n      // so it can deploy/query any resource.\n      this._clusterAdminAccess = this.grantClusterAdmin('ClusterAdminRoleAccess', this._kubectlProvider?.role!.roleArn);\n    }\n\n    // do not create a masters role if one is not provided. Trusting the accountRootPrincipal() is too permissive.\n    if (props.mastersRole) {\n      const mastersRole = props.mastersRole;\n      this.grantAccess('mastersRoleAccess', props.mastersRole.roleArn, [\n        AccessPolicy.fromAccessPolicyName('AmazonEKSClusterAdminPolicy', {\n          accessScopeType: AccessScopeType.CLUSTER,\n        }),\n      ]);\n\n      commonCommandOptions.push(`--role-arn ${mastersRole.roleArn}`);\n    }\n\n    if (props.albController) {\n      this.albController = AlbController.create(this, { ...props.albController, cluster: this });\n    }\n\n    // if any of defaultCapacity* properties are set, we need a default capacity(nodegroup)\n    if (props.defaultCapacity !== undefined ||\n        props.defaultCapacityType !== undefined ||\n        props.defaultCapacityInstance !== undefined) {\n      const minCapacity = props.defaultCapacity ?? DEFAULT_CAPACITY_COUNT;\n      if (minCapacity > 0) {\n        const instanceType = props.defaultCapacityInstance || DEFAULT_CAPACITY_TYPE;\n        // If defaultCapacityType is undefined, use AUTOMODE as the default\n        const capacityType = props.defaultCapacityType ?? DefaultCapacityType.AUTOMODE;\n\n        // Only create EC2 or Nodegroup capacity if not using AUTOMODE\n        if (capacityType === DefaultCapacityType.EC2) {\n          this.defaultCapacity = this.addAutoScalingGroupCapacity('DefaultCapacity', { instanceType, minCapacity });\n        } else if (capacityType === DefaultCapacityType.NODEGROUP) {\n          this.defaultNodegroup = this.addNodegroupCapacity('DefaultCapacity', { instanceTypes: [instanceType], minSize: minCapacity });\n        }\n        // For AUTOMODE, we don't create any explicit capacity as it's managed by EKS\n      }\n    }\n\n    // ensure FARGATE still applies here\n    if (props.coreDnsComputeType === CoreDnsComputeType.FARGATE) {\n      this.defineCoreDnsComputeType(CoreDnsComputeType.FARGATE);\n    }\n\n    const outputConfigCommand = (props.outputConfigCommand ?? true) && props.mastersRole;\n    if (outputConfigCommand) {\n      const postfix = commonCommandOptions.join(' ');\n      new CfnOutput(this, 'ConfigCommand', { value: `${updateConfigCommandPrefix} ${postfix}` });\n      new CfnOutput(this, 'GetTokenCommand', { value: `${getTokenCommandPrefix} ${postfix}` });\n    }\n  }\n\n  /**\n   * Grants the specified IAM principal access to the EKS cluster based on the provided access policies.\n   *\n   * This method creates an `AccessEntry` construct that grants the specified IAM principal the access permissions\n   * defined by the provided `IAccessPolicy` array. This allows the IAM principal to perform the actions permitted\n   * by the access policies within the EKS cluster.\n   * [disable-awslint:no-grants]\n   *\n   * @param id - The ID of the `AccessEntry` construct to be created.\n   * @param principal - The IAM principal (role or user) to be granted access to the EKS cluster.\n   * @param accessPolicies - An array of `IAccessPolicy` objects that define the access permissions to be granted to the IAM principal.\n   */\n  @MethodMetadata()\n  public grantAccess(id: string, principal: string, accessPolicies: IAccessPolicy[]) {\n    this.addToAccessEntry(id, principal, accessPolicies);\n  }\n\n  /**\n   * Grants the specified IAM principal cluster admin access to the EKS cluster.\n   *\n   * This method creates an `AccessEntry` construct that grants the specified IAM principal the cluster admin\n   * access permissions. This allows the IAM principal to perform the actions permitted\n   * by the cluster admin acces.\n   * [disable-awslint:no-grants]\n   *\n   * @param id - The ID of the `AccessEntry` construct to be created.\n   * @param principal - The IAM principal (role or user) to be granted access to the EKS cluster.\n   * @returns the access entry construct\n   */\n  @MethodMetadata()\n  public grantClusterAdmin(id: string, principal: string): AccessEntry {\n    const newEntry = new AccessEntry(this, id, {\n      principal,\n      cluster: this,\n      accessPolicies: [\n        AccessPolicy.fromAccessPolicyName('AmazonEKSClusterAdminPolicy', {\n          accessScopeType: AccessScopeType.CLUSTER,\n        }),\n      ],\n    });\n    this.accessEntries.set(principal, newEntry);\n    return newEntry;\n  }\n\n  /**\n   * Fetch the load balancer address of a service of type 'LoadBalancer'.\n   *\n   * @param serviceName The name of the service.\n   * @param options Additional operation options.\n   */\n  @MethodMetadata()\n  public getServiceLoadBalancerAddress(serviceName: string, options: ServiceLoadBalancerAddressOptions = {}): string {\n    const loadBalancerAddress = new KubernetesObjectValue(this, `${serviceName}LoadBalancerAddress`, {\n      cluster: this,\n      objectType: 'service',\n      objectName: serviceName,\n      objectNamespace: options.namespace,\n      jsonPath: '.status.loadBalancer.ingress[0].hostname',\n      timeout: options.timeout,\n    });\n\n    return loadBalancerAddress.value;\n  }\n\n  /**\n   * Fetch the load balancer address of an ingress backed by a load balancer.\n   *\n   * @param ingressName The name of the ingress.\n   * @param options Additional operation options.\n   */\n  @MethodMetadata()\n  public getIngressLoadBalancerAddress(ingressName: string, options: IngressLoadBalancerAddressOptions = {}): string {\n    const loadBalancerAddress = new KubernetesObjectValue(this, `${ingressName}LoadBalancerAddress`, {\n      cluster: this,\n      objectType: 'ingress',\n      objectName: ingressName,\n      objectNamespace: options.namespace,\n      jsonPath: '.status.loadBalancer.ingress[0].hostname',\n      timeout: options.timeout,\n    });\n\n    return loadBalancerAddress.value;\n  }\n\n  /**\n   * Add nodes to this EKS cluster\n   *\n   * The nodes will automatically be configured with the right VPC and AMI\n   * for the instance type and Kubernetes version.\n   *\n   * Note that if you specify `updateType: RollingUpdate` or `updateType: ReplacingUpdate`, your nodes might be replaced at deploy\n   * time without notice in case the recommended AMI for your machine image type has been updated by AWS.\n   * The default behavior for `updateType` is `None`, which means only new instances will be launched using the new AMI.\n   *\n   */\n  @MethodMetadata()\n  public addAutoScalingGroupCapacity(id: string, options: AutoScalingGroupCapacityOptions): autoscaling.AutoScalingGroup {\n    if (options.machineImageType === MachineImageType.BOTTLEROCKET && options.bootstrapOptions !== undefined) {\n      throw new Error('bootstrapOptions is not supported for Bottlerocket');\n    }\n    const asg = new autoscaling.AutoScalingGroup(this, id, {\n      ...options,\n      vpc: this.vpc,\n      machineImage: options.machineImageType === MachineImageType.BOTTLEROCKET ?\n        new BottleRocketImage({\n          kubernetesVersion: this.version.version,\n        }) :\n        new EksOptimizedImage({\n          nodeType: nodeTypeForInstanceType(options.instanceType),\n          cpuArch: cpuArchForInstanceType(options.instanceType),\n          kubernetesVersion: this.version.version,\n        }),\n    });\n\n    this.connectAutoScalingGroupCapacity(asg, {\n      bootstrapOptions: options.bootstrapOptions,\n      bootstrapEnabled: options.bootstrapEnabled,\n      machineImageType: options.machineImageType,\n    });\n\n    if (nodeTypeForInstanceType(options.instanceType) === NodeType.INFERENTIA ||\n      nodeTypeForInstanceType(options.instanceType) === NodeType.TRAINIUM) {\n      this.addNeuronDevicePlugin();\n    }\n\n    return asg;\n  }\n\n  /**\n   * Add managed nodegroup to this Amazon EKS cluster\n   *\n   * This method will create a new managed nodegroup and add into the capacity.\n   *\n   * @see https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html\n   * @param id The ID of the nodegroup\n   * @param options options for creating a new nodegroup\n   */\n  @MethodMetadata()\n  public addNodegroupCapacity(id: string, options?: NodegroupOptions): Nodegroup {\n    const hasInferentiaOrTrainiumInstanceType = [\n      options?.instanceType,\n      ...options?.instanceTypes ?? [],\n    ].some(i => i && (nodeTypeForInstanceType(i) === NodeType.INFERENTIA ||\n      nodeTypeForInstanceType(i) === NodeType.TRAINIUM));\n\n    if (hasInferentiaOrTrainiumInstanceType) {\n      this.addNeuronDevicePlugin();\n    }\n    return new Nodegroup(this, `Nodegroup${id}`, {\n      cluster: this,\n      ...options,\n    });\n  }\n\n  /**\n   * If this cluster is kubectl-enabled, returns the OpenID Connect issuer url.\n   * If this cluster is not kubectl-enabled (i.e. uses the\n   * stock `CfnCluster`), this is `undefined`.\n   * @attribute\n   */\n  public get clusterOpenIdConnectIssuerUrl(): string {\n    return this._clusterResource.attrOpenIdConnectIssuerUrl;\n  }\n\n  /**\n   * An `OpenIdConnectProvider` resource associated with this cluster, and which can be used\n   * to link this cluster to AWS IAM.\n   *\n   * A provider will only be defined if this property is accessed (lazy initialization).\n   */\n  public get openIdConnectProvider() {\n    if (!this._openIdConnectProvider) {\n      this._openIdConnectProvider = new OpenIdConnectProvider(this, 'OpenIdConnectProvider', {\n        url: this.clusterOpenIdConnectIssuerUrl,\n      });\n    }\n\n    return this._openIdConnectProvider;\n  }\n\n  public get kubectlProvider() {\n    return this._kubectlProvider;\n  }\n\n  /**\n   * Retrieves the EKS Pod Identity Agent addon for the EKS cluster.\n   *\n   * The EKS Pod Identity Agent is responsible for managing the temporary credentials\n   * used by pods in the cluster to access AWS resources. It runs as a DaemonSet on\n   * each node and provides the necessary credentials to the pods based on their\n   * associated service account.\n   *\n   */\n  public get eksPodIdentityAgent(): IAddon | undefined {\n    if (!this._eksPodIdentityAgent) {\n      this._eksPodIdentityAgent = new Addon(this, 'EksPodIdentityAgentAddon', {\n        cluster: this,\n        addonName: 'eks-pod-identity-agent',\n      });\n    }\n\n    return this._eksPodIdentityAgent;\n  }\n\n  /**\n   * Adds a Fargate profile to this cluster.\n   * @see https://docs.aws.amazon.com/eks/latest/userguide/fargate-profile.html\n   *\n   * @param id the id of this profile\n   * @param options profile options\n   */\n  @MethodMetadata()\n  public addFargateProfile(id: string, options: FargateProfileOptions) {\n    return new FargateProfile(this, `fargate-profile-${id}`, {\n      ...options,\n      cluster: this,\n    });\n  }\n\n  /**\n   * Internal API used by `FargateProfile` to keep inventory of Fargate profiles associated with\n   * this cluster, for the sake of ensuring the profiles are created sequentially.\n   *\n   * @returns the list of FargateProfiles attached to this cluster, including the one just attached.\n   * @internal\n   */\n  public _attachFargateProfile(fargateProfile: FargateProfile): FargateProfile[] {\n    this._fargateProfiles.push(fargateProfile);\n\n    // add all profiles as a dependency of the \"kubectl-ready\" barrier because all kubectl-\n    // resources can only be deployed after all fargate profiles are created.\n    this._kubectlReadyBarrier.node.addDependency(fargateProfile);\n\n    return this._fargateProfiles;\n  }\n\n  /**\n   * validate all autoMode relevant configurations to ensure they are correct and throw\n   * errors if they are not.\n   *\n   * @param props ClusterProps\n   *\n   */\n  private isValidAutoModeConfig(props: ClusterProps): boolean {\n    const autoModeEnabled = props.defaultCapacityType === undefined || props.defaultCapacityType == DefaultCapacityType.AUTOMODE;\n    // if using AUTOMODE\n    if (autoModeEnabled) {\n      // When using AUTOMODE, nodePools values are case-sensitive and must be general-purpose and/or system\n      if (props.compute?.nodePools) {\n        const validNodePools = ['general-purpose', 'system'];\n        const invalidPools = props.compute.nodePools.filter(pool => !validNodePools.includes(pool));\n        if (invalidPools.length > 0) {\n          throw new Error(`Invalid node pool values: ${invalidPools.join(', ')}. Valid values are: ${validNodePools.join(', ')}`);\n        }\n      }\n\n      // When using AUTOMODE, defaultCapacity and defaultCapacityInstance cannot be specified\n      if (props.defaultCapacity !== undefined || props.defaultCapacityInstance !== undefined) {\n        throw new Error('Cannot specify defaultCapacity or defaultCapacityInstance when using Auto Mode. Auto Mode manages compute resources automatically.');\n      }\n    } else {\n      // if NOT using AUTOMODE\n      if (props.compute) {\n        // When not using AUTOMODE, compute must be undefined\n        throw new Error('Cannot specify compute without using DefaultCapacityType.AUTOMODE');\n      }\n    }\n\n    return autoModeEnabled;\n  }\n\n  private addNodePoolRole(id: string): iam.Role {\n    const role = new iam.Role(this, id, {\n      assumedBy: new iam.ServicePrincipal('ec2.amazonaws.com'),\n      // to be able to access the AWSLoadBalancerController\n      managedPolicies: [\n        // see https://docs.aws.amazon.com/eks/latest/userguide/automode-get-started-cli.html#auto-mode-create-roles\n        iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEKSWorkerNodePolicy'),\n        iam.ManagedPolicy.fromAwsManagedPolicyName('AmazonEC2ContainerRegistryReadOnly'),\n      ],\n    });\n\n    return role;\n  }\n\n  /**\n   * Adds an access entry to the cluster's access entries map.\n   *\n   * If an entry already exists for the given principal, it adds the provided access policies to the existing entry.\n   * If no entry exists for the given principal, it creates a new access entry with the provided access policies.\n   *\n   * @param principal - The principal (e.g., IAM user or role) for which the access entry is being added.\n   * @param policies - An array of access policies to be associated with the principal.\n   *\n   * @throws {Error} If the uniqueName generated for the new access entry is not unique.\n   *\n   * @returns {void}\n   */\n  private addToAccessEntry(id: string, principal: string, policies: IAccessPolicy[]) {\n    const entry = this.accessEntries.get(principal);\n    if (entry) {\n      (entry as AccessEntry).addAccessPolicies(policies);\n    } else {\n      const newEntry = new AccessEntry(this, id, {\n        principal,\n        cluster: this,\n        accessPolicies: policies,\n      });\n      this.accessEntries.set(principal, newEntry);\n    }\n  }\n\n  /**\n   * Adds a resource scope that requires `kubectl` to this cluster and returns\n   *\n   * @internal\n   */\n  public _dependOnKubectlBarrier(resource: Construct) {\n    resource.node.addDependency(this._kubectlReadyBarrier);\n  }\n\n  private selectPrivateSubnets(): ec2.ISubnet[] {\n    const privateSubnets: ec2.ISubnet[] = [];\n    const vpcPrivateSubnetIds = this.vpc.privateSubnets.map(s => s.subnetId);\n    const vpcPublicSubnetIds = this.vpc.publicSubnets.map(s => s.subnetId);\n\n    for (const placement of this.vpcSubnets) {\n      for (const subnet of this.vpc.selectSubnets(placement).subnets) {\n        if (vpcPrivateSubnetIds.includes(subnet.subnetId)) {\n          // definitely private, take it.\n          privateSubnets.push(subnet);\n          continue;\n        }\n\n        if (vpcPublicSubnetIds.includes(subnet.subnetId)) {\n          // definitely public, skip it.\n          continue;\n        }\n\n        // neither public and nor private - what is it then? this means its a subnet instance that was explicitly passed\n        // in the subnet selection. since ISubnet doesn't contain information on type, we have to assume its private and let it\n        // fail at deploy time :\\ (its better than filtering it out and preventing a possibly successful deployment)\n        privateSubnets.push(subnet);\n      }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates API Gateway, Step Functions, CloudFormation resources", "output": "class SfnRestApiWithoutDefaultMethodResponsesStack extends cdk.Stack {\n  constructor(scope: Construct) {\n    super(scope, 'SfnRestApiWithoutDefaultMethodResponses');\n\n    const passTask = new sfn.Pass(this, 'PassTask', {\n      result: { value: 'Hello' },\n    });\n\n    const stateMachine = new sfn.StateMachine(this, 'StateMachine', {\n      definition: passTask,\n      stateMachineType: sfn.StateMachineType.EXPRESS,\n    });\n\n    const api = new apigw.StepFunctionsRestApi(this, 'StepFunctionsRestApi', {\n      stateMachine: stateMachine,\n      useDefaultMethodResponses: false,\n    });\n\n    new cdk.CfnOutput(this, 'ApiEndpoint', {\n      value: api.url,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, MSK (Kafka) resources", "output": "class CdkRdsStack(Stack):\n\n    def __init__(self, scope: Construct, id: str, vpc, asg_security_groups, **kwargs) -> None:\n        super().__init__(scope, id, **kwargs)\n\n        # Ceate Aurora Cluster with 2 instances with CDK High Level API\n        # Secrets Manager auto generate and keep the password, don't put password in cdk code directly\n        # db_Aurora_cluster = rds.DatabaseCluster(self, \"MyAurora\",\n        #                                         default_database_name=\"MyAurora\",\n        #                                         engine=rds.DatabaseClusterEngine.arora_mysql(\n        #                                             version=rds.AuroraMysqlEngineVersion.VER_5_7_12\n        #                                         )\n        #                                         instance_props=rds.InstanceProps(\n        #                                             vpc=vpc,\n        #                                             vpc_subnets=ec2.SubnetSelection(subnet_group_name=\"DB\"),\n        #                                             instance_type=ec2.InstanceType(instance_type_identifier=\"t2.small\")\n        #                                         ),\n        #                                         instances=2,\n        #                                         parameter_group=rds.ClusterParameterGroup.from_parameter_group_name(\n        #                                             self, \"para-group-aurora\",\n        #                                             parameter_group_name=\"default.aurora-mysql5.7\"\n        #                                         ),\n        #                                         )\n        # for asg_sg in asg_security_groups:\n        #     db_Aurora_cluster.connections.allow_default_port_from(asg_sg, \"EC2 Autoscaling Group access Aurora\")\n\n        # Alternatively, create MySQL RDS with CDK High Level API\n        db_mysql_easy = rds.DatabaseInstance(self, \"MySQL_DB_easy\",\n                                             engine=rds.DatabaseInstanceEngine.mysql(\n                                                 version=rds.MysqlEngineVersion.VER_5_7_30\n                                             ),\n                                             instance_type=ec2.InstanceType.of(\n                                                 ec2.InstanceClass.BURSTABLE2, ec2.InstanceSize.SMALL),\n                                             vpc=vpc,\n                                             vpc_subnets=ec2.SubnetSelection(subnet_group_name=\"DB\"),\n                                             multi_az=True,\n                                             allocated_storage=100,\n                                             storage_type=rds.StorageType.GP2,\n                                             cloudwatch_logs_exports=[\"audit\", \"error\", \"general\", \"slowquery\"],\n                                             deletion_protection=False,\n                                             delete_automated_backups=False,\n                                             backup_retention=Duration.days(7),\n                                             parameter_group=rds.ParameterGroup.from_parameter_group_name(\n                                                 self, \"para-group-mysql\",\n                                                 parameter_group_name=\"default.mysql5.7\"\n                                             )\n                                             )\n        for asg_sg in asg_security_groups:\n            db_mysql_easy.connections.allow_default_port_from(asg_sg, \"EC2 Autoscaling Group access MySQL\")", "language": "python"}
{"input": "CDK class Create for AWS resource management", "output": "class Create extends cdk.Stack {\n  public usagePlan: IUsagePlan;\n\n  constructor(scope: cdk.App, id: string) {\n    super(scope, id);\n\n    this.usagePlan = new apigateway.UsagePlan(this, 'myusageplan');\n  }\n}", "language": "typescript"}
{"input": "Represents the function's source code as inline code", "output": "class InlineCode extends FunctionCode {\n  constructor(private code: string) {\n    super();\n  }\n\n  public render(): string {\n    return this.code;\n  }\n}", "language": "typescript"}
{"input": "CDK class Volume for AWS resource management", "output": "export class Volume extends VolumeBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ec2.Volume';\n\n  /**\n   * Import an existing EBS Volume into the Stack.\n   *\n   * @param scope the scope of the import.\n   * @param id    the ID of the imported Volume in the construct tree.\n   * @param attrs the attributes of the imported Volume\n   */\n  public static fromVolumeAttributes(scope: Construct, id: string, attrs: VolumeAttributes): IVolume {\n    class Import extends VolumeBase {\n      public readonly volumeId = attrs.volumeId;\n      public readonly availabilityZone = attrs.availabilityZone;\n      public readonly encryptionKey = attrs.encryptionKey;\n    }\n    // Check that the provided volumeId looks like it could be valid.\n    if (!Token.isUnresolved(attrs.volumeId) && !/^vol-[0-9a-fA-F]+$/.test(attrs.volumeId)) {\n      throw new ValidationError('`volumeId` does not match expected pattern. Expected `vol-<hexadecmial value>` (ex: `vol-05abe246af`) or a Token', scope);\n    }\n    return new Import(scope, id);\n  }\n\n  public readonly volumeId: string;\n  public readonly availabilityZone: string;\n  public readonly encryptionKey?: IKey;\n\n  constructor(scope: Construct, id: string, props: VolumeProps) {\n    super(scope, id, {\n      physicalName: props.volumeName,\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.validateProps(props);\n\n    const resource = new CfnVolume(this, 'Resource', {\n      availabilityZone: props.availabilityZone,\n      autoEnableIo: props.autoEnableIo,\n      encrypted: props.encrypted,\n      kmsKeyId: props.encryptionKey?.keyArn,\n      iops: props.iops,\n      multiAttachEnabled: props.enableMultiAttach ?? false,\n      size: props.size?.toGibibytes({ rounding: SizeRoundingBehavior.FAIL }),\n      snapshotId: props.snapshotId,\n      throughput: props.throughput,\n      volumeType: props.volumeType ??\n        (FeatureFlags.of(this).isEnabled(cxapi.EBS_DEFAULT_GP3) ?\n          EbsDeviceVolumeType.GENERAL_PURPOSE_SSD_GP3 : EbsDeviceVolumeType.GENERAL_PURPOSE_SSD),\n      volumeInitializationRate: props.volumeInitializationRate?.toMebibytes(),\n    });\n    resource.applyRemovalPolicy(props.removalPolicy);\n\n    if (props.volumeName) Tags.of(resource).add('Name', props.volumeName);\n\n    this.volumeId = resource.ref;\n    this.availabilityZone = props.availabilityZone;\n    this.encryptionKey = props.encryptionKey;\n\n    if (this.encryptionKey) {\n      // Per: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html#ebs-encryption-requirements\n      const principal =\n        new ViaServicePrincipal(`ec2.${Stack.of(this).region}.amazonaws.com`, new AccountRootPrincipal()).withConditions({\n          StringEquals: {\n            'kms:CallerAccount': Stack.of(this).account,\n          },\n        });\n      const grant = this.encryptionKey.grant(principal,\n        // Describe & Generate are required to be able to create the CMK-encrypted Volume.\n        'kms:DescribeKey',\n        'kms:GenerateDataKeyWithoutPlainText',\n      );\n      if (props.snapshotId) {\n        // ReEncrypt is required for when re-encrypting from an encrypted snapshot.\n        grant.principalStatement?.addActions('kms:ReEncrypt*');\n      }\n    }\n  }\n\n  protected validateProps(props: VolumeProps) {\n    if (!(props.size || props.snapshotId)) {\n      throw new ValidationError('Must provide at least one of `size` or `snapshotId`', this);\n    }\n\n    if (props.snapshotId && !Token.isUnresolved(props.snapshotId) && !/^snap-[0-9a-fA-F]+$/.test(props.snapshotId)) {\n      throw new ValidationError('`snapshotId` does not match expected pattern. Expected `snap-<hexadecmial value>` (ex: `snap-05abe246af`) or Token', this);\n    }\n\n    if (props.encryptionKey && !props.encrypted) {\n      throw new ValidationError('`encrypted` must be true when providing an `encryptionKey`.', this);\n    }\n\n    if (\n      props.volumeType &&\n      [\n        EbsDeviceVolumeType.PROVISIONED_IOPS_SSD,\n        EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2,\n      ].includes(props.volumeType) &&\n      !props.iops\n    ) {\n      throw new ValidationError(\n        '`iops` must be specified if the `volumeType` is `PROVISIONED_IOPS_SSD` or `PROVISIONED_IOPS_SSD_IO2`.',\n        this,\n      );\n    }\n\n    if (props.iops) {\n      const volumeType = props.volumeType ?? EbsDeviceVolumeType.GENERAL_PURPOSE_SSD;\n      if (\n        ![\n          EbsDeviceVolumeType.PROVISIONED_IOPS_SSD,\n          EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2,\n          EbsDeviceVolumeType.GENERAL_PURPOSE_SSD_GP3,\n        ].includes(volumeType)\n      ) {\n        throw new ValidationError(\n          '`iops` may only be specified if the `volumeType` is `PROVISIONED_IOPS_SSD`, `PROVISIONED_IOPS_SSD_IO2` or `GENERAL_PURPOSE_SSD_GP3`.',\n          this,\n        );\n      }\n      // Enforce minimum & maximum IOPS:\n      // https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-volume.html\n      const iopsRanges: { [key: string]: { Min: number; Max: number } } = {};\n      iopsRanges[EbsDeviceVolumeType.GENERAL_PURPOSE_SSD_GP3] = { Min: 3000, Max: 80000 };\n      iopsRanges[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD] = { Min: 100, Max: 64000 };\n      iopsRanges[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2] = { Min: 100, Max: 256000 };\n      const { Min, Max } = iopsRanges[volumeType];\n      if (props.iops < Min || props.iops > Max) {\n        throw new ValidationError(`\\`${volumeType}\\` volumes iops must be between ${Min} and ${Max}.`, this);\n      }\n\n      // Enforce maximum ratio of IOPS/GiB:\n      // https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html\n      const maximumRatios: { [key: string]: number } = {};\n      maximumRatios[EbsDeviceVolumeType.GENERAL_PURPOSE_SSD_GP3] = 500;\n      maximumRatios[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD] = 50;\n      maximumRatios[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2] = 500;\n      const maximumRatio = maximumRatios[volumeType];\n      if (props.size && (props.iops > maximumRatio * props.size.toGibibytes({ rounding: SizeRoundingBehavior.FAIL }))) {\n        throw new ValidationError(`\\`${volumeType}\\` volumes iops has a maximum ratio of ${maximumRatio} IOPS/GiB.`, this);\n      }\n\n      const maximumThroughputRatios: { [key: string]: number } = {};\n      maximumThroughputRatios[EbsDeviceVolumeType.GP3] = 0.25;\n      const maximumThroughputRatio = maximumThroughputRatios[volumeType];\n      if (props.throughput && props.iops) {\n        const iopsRatio = (props.throughput / props.iops);\n        if (iopsRatio > maximumThroughputRatio) {\n          throw new ValidationError(`Throughput (MiBps) to iops ratio of ${iopsRatio} is too high; maximum is ${maximumThroughputRatio} MiBps per iops`, this);\n        }\n      }\n    }\n\n    if (props.enableMultiAttach) {\n      const volumeType = props.volumeType ?? EbsDeviceVolumeType.GENERAL_PURPOSE_SSD;\n      if (\n        ![\n          EbsDeviceVolumeType.PROVISIONED_IOPS_SSD,\n          EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2,\n        ].includes(volumeType)\n      ) {\n        throw new ValidationError('multi-attach is supported exclusively on `PROVISIONED_IOPS_SSD` and `PROVISIONED_IOPS_SSD_IO2` volumes.', this);\n      }\n    }\n\n    if (props.size) {\n      const size = props.size.toGibibytes({ rounding: SizeRoundingBehavior.FAIL });\n      // Enforce minimum & maximum volume size:\n      // https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-volume.html\n      const sizeRanges: { [key: string]: { Min: number; Max: number } } = {};\n      sizeRanges[EbsDeviceVolumeType.GENERAL_PURPOSE_SSD] = { Min: 1, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.GENERAL_PURPOSE_SSD_GP3] = { Min: 1, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD] = { Min: 4, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.PROVISIONED_IOPS_SSD_IO2] = { Min: 4, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.THROUGHPUT_OPTIMIZED_HDD] = { Min: 125, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.COLD_HDD] = { Min: 125, Max: 16384 };\n      sizeRanges[EbsDeviceVolumeType.MAGNETIC] = { Min: 1, Max: 1024 };\n      const volumeType = props.volumeType ?? EbsDeviceVolumeType.GENERAL_PURPOSE_SSD;\n      const { Min, Max } = sizeRanges[volumeType];\n      if (size < Min || size > Max) {\n        throw new ValidationError(`\\`${volumeType}\\` volumes must be between ${Min} GiB and ${Max} GiB in size.`, this);\n      }\n    }\n\n    if (props.throughput) {\n      const throughputRange = { Min: 125, Max: 2000 };\n      const { Min, Max } = throughputRange;\n      if (props.volumeType != EbsDeviceVolumeType.GP3) {\n        throw new ValidationError(\n          'throughput property requires volumeType: EbsDeviceVolumeType.GP3',\n          this,\n        );\n      }\n      if (props.throughput < Min || props.throughput > Max) {\n        throw new ValidationError(\n          `throughput property takes a minimum of ${Min} and a maximum of ${Max}`,\n          this,\n        );\n      }\n    }\n\n    if (props.volumeInitializationRate) {\n      if (!props.snapshotId) {\n        throw new ValidationError('volumeInitializationRate can only be specified when creating a volume from a snapshot.', this);\n      }\n\n      if (!props.volumeInitializationRate.isUnresolved()) {\n        const rateMiBs = props.volumeInitializationRate.toMebibytes({ rounding: SizeRoundingBehavior.NONE });\n        if (rateMiBs < 100 || rateMiBs > 300) {\n          throw new ValidationError(`volumeInitializationRate must be between 100 and 300 MiB/s, got: ${rateMiBs} MiB/s`, this);\n        }\n      }\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates Lambda, WAF, EventBridge, CloudFormation resources", "output": "export class LambdaCronStack extends cdk.Stack {\n  constructor(app: cdk.App, id: string) {\n    super(app, id);\n\n    const lambdaFn = new lambda.Function(this, 'Singleton', {\n      code: new lambda.InlineCode(fs.readFileSync('lambda-handler.py', { encoding: 'utf-8' })),\n      handler: 'index.main',\n      timeout: cdk.Duration.seconds(300),\n      runtime: lambda.Runtime.PYTHON_3_9,\n    });\n\n    // Run 6:00 PM UTC every Monday through Friday\n    // See https://docs.aws.amazon.com/lambda/latest/dg/tutorial-scheduled-events-schedule-expressions.html\n    const rule = new events.Rule(this, 'Rule', {\n      schedule: events.Schedule.expression('cron(0 18 ? * MON-FRI *)')\n    });\n\n    rule.addTarget(new targets.LambdaFunction(lambdaFn));\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, DynamoDB, IAM resources", "output": "class DdbToAossZeroEtlStack(Stack):\n\n  def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:\n    super().__init__(scope, construct_id, **kwargs)\n\n    global network_security_policy, encryption_security_policy, data_access_policy\n    global COLLECTION_NAME, PIPELINE_NAME, DYNAMO_TABLE_NAME, S3_EXPORT_BUCKET_FOR_DDB, NETWORK_POLICY_NAME\n\n    random_id = random.randint(0, 100)\n    STACK_NAMING_PREFIX = f'ddb-to-aoss-{random_id}'\n\n    STACK_RESOURCE_NAMING_PREFIX = 'DdbAossZetl'\n\n    COLLECTION_NAME = f'{STACK_NAMING_PREFIX}-col'\n    PIPELINE_NAME = f'{STACK_NAMING_PREFIX}-pipe'\n    DYNAMO_TABLE_NAME = f'{STACK_NAMING_PREFIX}-table'\n    S3_EXPORT_BUCKET_FOR_DDB = f'{STACK_NAMING_PREFIX}-buck'\n    NETWORK_POLICY_NAME = f'{COLLECTION_NAME}-net-pol'\n    ENCRYPTION_POLICY_NAME = f'{COLLECTION_NAME}-encr-pol'\n    DATA_ACCESS_POLICY_NAME = f\"{COLLECTION_NAME}-data-pol\"\n\n    USER_ARN = self.node.try_get_context('iam_user_arn')\n    if not USER_ARN:\n      print(\n        'Specify the IAM role or user that will be used to access OpenSearch Dashboards by adding '\n        '\"-c iam_user_arn=\\'<my-iam-arn>\\'\" to your cdk commands')\n\n    ################################################################################\n    # Create OpenSearch Serverless network access policy\n\n    network_security_policy = json.dumps([{\n      \"Rules\": [\n        {\n          \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n          \"ResourceType\": \"dashboard\"\n        }\n      ],\n      \"AllowFromPublic\": True\n    }], indent=2)\n\n    cfn_network_security_policy = opss.CfnSecurityPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}NetPolicy',\n                                                         policy=network_security_policy,\n                                                         name=NETWORK_POLICY_NAME,\n                                                         type=\"network\"\n                                                         )\n\n    ################################################################################\n    # Create OpenSearch Serverless encryption policy\n\n    encryption_security_policy = json.dumps({\n      \"Rules\": [{\n        \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n        \"ResourceType\": \"collection\"\n      }],\n      \"AWSOwnedKey\": True\n    }, indent=2)\n\n    cfn_encryption_security_policy = opss.CfnSecurityPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}EncPolicy',\n                                                            policy=encryption_security_policy,\n                                                            name=ENCRYPTION_POLICY_NAME,\n                                                            type=\"encryption\"\n                                                            )\n\n    ################################################################################\n    # Create OpenSearch Serverless collection\n\n    cfn_collection = opss.CfnCollection(self, f'{STACK_RESOURCE_NAMING_PREFIX}Collection',\n                                        name=COLLECTION_NAME,\n                                        description=\"Collection to be used for search from CDK\",\n                                        type=\"SEARCH\"\n                                        )\n    cfn_collection.add_dependency(cfn_network_security_policy)\n    cfn_collection.add_dependency(cfn_encryption_security_policy)\n\n    ################################################################################\n    # Create IAM role for OpenSearch Ingestion pipeline\n\n    pipeline_role = iam.Role(self, f'{STACK_RESOURCE_NAMING_PREFIX}PipelineRole',\n                             role_name=f'{STACK_RESOURCE_NAMING_PREFIX}PipelineRole',\n                             assumed_by=iam.ServicePrincipal('osis-pipelines.amazonaws.com'),\n                             inline_policies={\n                               'collection-pipeline-policy': self.collection_pipeline_policy_doc(\n                                 cfn_collection.attr_arn)\n                             }\n                             )\n\n    ################################################################################\n    # Create S3 Bucket for export\n\n    s3_bucket = s3.Bucket(self, f'{STACK_RESOURCE_NAMING_PREFIX}Bucket',\n                          block_public_access=s3.BlockPublicAccess.BLOCK_ALL,\n                          bucket_name=S3_EXPORT_BUCKET_FOR_DDB,\n                          encryption=s3.BucketEncryption.S3_MANAGED,\n                          enforce_ssl=True,\n                          versioned=True,\n                          removal_policy=cdk.RemovalPolicy.DESTROY\n                          )\n\n    s3_bucket_policy_statement = iam.PolicyStatement(\n      effect=iam.Effect.ALLOW,\n      resources=[f'arn:aws:s3:::{S3_EXPORT_BUCKET_FOR_DDB}/*'],\n      actions=[\n        \"s3:GetObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ],\n      principals=[iam.ArnPrincipal(pipeline_role.role_arn)]\n    )\n\n    # Add the policy to the bucket\n    s3_bucket.add_to_resource_policy(s3_bucket_policy_statement)\n\n    ################################################################################\n    # Create DynamoDB Table\n\n    dynamo_db_table = ddb.TableV2(self, f'{STACK_RESOURCE_NAMING_PREFIX}Table',\n                                  partition_key=ddb.Attribute(name=\"id\", type=ddb.AttributeType.STRING),\n                                  sort_key=ddb.Attribute(name=\"timestamp\", type=ddb.AttributeType.NUMBER),\n                                  table_name=DYNAMO_TABLE_NAME,\n                                  billing=ddb.Billing.on_demand(),\n                                  point_in_time_recovery=True,\n                                  dynamo_stream=ddb.StreamViewType.NEW_IMAGE,\n                                  removal_policy=cdk.RemovalPolicy.DESTROY\n                                  )\n\n    ################################################################################\n    # Create OpenSearch Ingestion pipeline\n\n    log_group_name = f\"/aws/vendedlogs/OpenSearchIngestion/{PIPELINE_NAME}/audit-logs\"\n    osis_pipeline_log_group = aws_logs.LogGroup(self, f'{STACK_RESOURCE_NAMING_PREFIX}LogGroup',\n                                                log_group_name=log_group_name,\n                                                retention=aws_logs.RetentionDays.THREE_DAYS,\n                                                removal_policy=cdk.RemovalPolicy.DESTROY\n                                                )\n\n    pipeline_configuration_body = self.get_pipeline_configuration(table_arn=dynamo_db_table.table_arn,\n                                                             role_arn=pipeline_role.role_arn,\n                                                             collection_endpoint=cfn_collection.attr_collection_endpoint)\n\n    cfn_pipeline = osi.CfnPipeline(self, f'{STACK_RESOURCE_NAMING_PREFIX}Pipeline',\n                                   max_units=4,\n                                   min_units=1,\n                                   pipeline_configuration_body=pipeline_configuration_body,\n                                   pipeline_name=PIPELINE_NAME,\n                                   log_publishing_options=osi.CfnPipeline.LogPublishingOptionsProperty(\n                                     cloud_watch_log_destination=osi.CfnPipeline.CloudWatchLogDestinationProperty(\n                                       log_group=log_group_name,\n                                     ),\n                                     is_logging_enabled=True\n                                   )\n                                   )\n    cfn_pipeline.add_dependency(cfn_collection)\n\n    ################################################################################\n    # Create OpenSearch Serverless data access policy\n\n    data_access_policy_principals = [pipeline_role.role_arn]\n    if USER_ARN:\n      data_access_policy_principals.append(USER_ARN)\n\n    data_access_policy = json.dumps([{\n      \"Rules\": [\n        {\n          \"Resource\": [f\"collection/{COLLECTION_NAME}\"],\n          \"Permission\": [\n            \"aoss:CreateCollectionItems\",\n            \"aoss:DeleteCollectionItems\",\n            \"aoss:UpdateCollectionItems\",\n            \"aoss:DescribeCollectionItems\"\n          ],\n          \"ResourceType\": \"collection\"\n        },\n        {\n          \"Resource\": [f\"index/{COLLECTION_NAME}/*\"],\n          \"Permission\": [\n            \"aoss:CreateIndex\",\n            \"aoss:DeleteIndex\",\n            \"aoss:UpdateIndex\",\n            \"aoss:DescribeIndex\",\n            \"aoss:ReadDocument\",\n            \"aoss:WriteDocument\"\n          ],\n          \"ResourceType\": \"index\"\n        }\n      ],\n      \"Principal\": data_access_policy_principals,\n      \"Description\": \"data-access-rule\"\n    }], indent=2)\n\n    cfn_access_policy = opss.CfnAccessPolicy(self, f'{STACK_RESOURCE_NAMING_PREFIX}DataPolicy',\n                                             name=DATA_ACCESS_POLICY_NAME,\n                                             description=\"Policy for data access\",\n                                             policy=data_access_policy,\n                                             type=\"data\"\n                                             )\n    cfn_access_policy.add_dependency(cfn_collection)\n    cfn_access_policy.add_dependency(cfn_pipeline)\n\n  def collection_pipeline_policy_doc(self, collection_arn):\n    collection_pipeline_policy_doc = iam.PolicyDocument()\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [\"*\"],\n      \"actions\": [\n        \"aoss:BatchGetCollection\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [collection_arn],\n      \"actions\": [\n        \"aoss:APIAccessAll\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [\"*\"],\n      \"actions\": [\n        \"aoss:CreateSecurityPolicy\",\n        \"aoss:GetSecurityPolicy\",\n        \"aoss:UpdateSecurityPolicy\"\n      ],\n      \"conditions\": {\n        \"StringEquals\": {\n          \"aoss:collection\": COLLECTION_NAME\n        }\n      }\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}/export/*'],\n      \"actions\": [\n        \"dynamodb:DescribeExport\",\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}/stream/*'],\n      \"actions\": [\n        \"dynamodb:DescribeStream\",\n        \"dynamodb:GetRecords\",\n        \"dynamodb:GetShardIterator\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:dynamodb:{cdk.Aws.REGION}:{cdk.Aws.ACCOUNT_ID}:table/{DYNAMO_TABLE_NAME}'],\n      \"actions\": [\n        \"dynamodb:DescribeTable\",\n        \"dynamodb:DescribeContinuousBackups\",\n        \"dynamodb:ExportTableToPointInTime\"\n      ]\n    }))\n    collection_pipeline_policy_doc.add_statements(iam.PolicyStatement(**{\n      \"effect\": iam.Effect.ALLOW,\n      \"resources\": [f'arn:aws:s3:::{S3_EXPORT_BUCKET_FOR_DDB}/{DYNAMO_TABLE_NAME}/*'],\n      \"actions\": [\n        \"s3:GetObject\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:PutObject\",\n        \"s3:PutObjectAcl\"\n      ]\n    }))\n    return collection_pipeline_policy_doc\n\n  def get_pipeline_configuration(self, table_arn, role_arn, collection_endpoint):\n\n    replacements = [\n      lambda x: x.replace(\"%%%DYNAMODB_TABLE_ARN%%%\", table_arn),\n      lambda x: x.replace(\"%%%S3_BUCKET_NAME%%%\", S3_EXPORT_BUCKET_FOR_DDB),\n      lambda x: x.replace(\"%%%REGION%%%\", cdk.Aws.REGION),\n      lambda x: x.replace(\"%%%DYNAMODB_TABLE_NAME%%%\", table_arn),\n      lambda x: x.replace(\"%%%ROLE_ARN%%%\", role_arn),\n      lambda x: x.replace(\"%%%COLLECTION_ENDPOINT%%%\", collection_endpoint),\n      lambda x: x.replace(\"%%%NETWORK_POLICY_NAME%%%\", NETWORK_POLICY_NAME)\n    ]\n\n    with open(\"resources/pipeline_configuration.yaml\", 'r') as pipeline_configuration_file:\n      pipeline_configuration_format = pipeline_configuration_file.read()\n      formatted_pipeline_configuration = pipeline_configuration_format\n\n      for replace in replacements:\n        formatted_pipeline_configuration = replace(formatted_pipeline_configuration)\n\n      return formatted_pipeline_configuration", "language": "python"}
{"input": "CDK class SvcbRecord for AWS resource management", "output": "export class SvcbRecord extends RecordSet {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-route53.SvcbRecord';\n\n  constructor(scope: Construct, id: string, props: SvcbRecordProps) {\n    super(scope, id, {\n      ...props,\n      recordType: RecordType.SVCB,\n      target: RecordTarget.fromValues(...props.values.map((v) => v.toString())),\n    });\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for WAF, CloudFormation operations", "output": "const validationReport = (data: ValidationReportData[]) => {\n  const result = data.flatMap(d => {\n    if (d.status === 'failure') {\n      const title = reset(red(bright(`${d.title} (1 occurrences)`)));\n      return [\n        expect.stringMatching(new RegExp('Validation Report')),\n        expect.stringMatching(new RegExp('-----------------')),\n        expect.stringMatching(new RegExp(`Plugin: ${d.pluginName}`)),\n        expect.stringMatching(new RegExp(`Version: ${d.version ?? 'N/A'}`)),\n        expect.stringMatching(new RegExp(`Status: ${d.status}`)),\n        expect.stringMatching(new RegExp('\\\\(Violations\\\\)')),\n        title,\n        ...d.severity ? [expect.stringMatching(new RegExp(`Severity: ${d.severity}`))] : [],\n        expect.stringMatching(new RegExp('  Occurrences:')),\n        expect.stringMatching(new RegExp(`    - Construct Path: ${d.constructPath}`)),\n        expect.stringMatching(new RegExp(`    - Template Path: ${d.templatePath}`)),\n        expect.stringMatching(new RegExp('    - Creation Stack:')),\n        ...d.creationStack ?? [],\n        expect.stringMatching(new RegExp(`    - Resource ID: ${d.resourceLogicalId}`)),\n        expect.stringMatching(new RegExp('    - Template Locations:')),\n        expect.stringMatching(new RegExp('      > test-location')),\n        expect.stringMatching(new RegExp(`  Description: ${d.description ?? 'test recommendation'}`)),\n        ...d.ruleMetadata ? [expect.stringMatching('  Rule Metadata:'), ...Object.entries(d.ruleMetadata).flatMap(([key, value]) => expect.stringMatching(`${key}: ${value}`))] : [],\n      ];\n    }\n    return [];\n  });\n  result.push(\n    expect.stringMatching(new RegExp('Policy Validation Report Summary')),\n    ...data.map(d => expect.stringMatching(new RegExp(`.*${d.pluginName}.*${d.status}.*`))),\n  );\n  return result;\n}", "language": "typescript"}
{"input": "CDK helper function for SSM Parameter Store, CodePipeline operations", "output": "def __init__(self, app: App, id: str, props, **kwargs) -> None:\n        super().__init__(app, id, **kwargs)\n        # define the s3 artifact\n        source_output = aws_codepipeline.Artifact(artifact_name='source')\n        # define the pipeline\n        pipeline = aws_codepipeline.Pipeline(\n            self, \"Pipeline\",\n            pipeline_name=f\"{props['namespace']}\",\n            artifact_bucket=props['bucket'],\n            stages=[\n                aws_codepipeline.StageProps(\n                    stage_name='Source',\n                    actions=[\n                        aws_codepipeline_actions.S3SourceAction(\n                            bucket=props['bucket'],\n                            bucket_key='source.zip',\n                            action_name='S3Source',\n                            run_order=1,\n                            output=source_output,\n                            trigger=aws_codepipeline_actions.S3Trigger.POLL\n                        ),\n                    ]\n                ),\n                aws_codepipeline.StageProps(\n                    stage_name='Build',\n                    actions=[\n                        aws_codepipeline_actions.CodeBuildAction(\n                            action_name='DockerBuildImages',\n                            input=source_output,\n                            project=props['cb_docker_build'],\n                            run_order=1,\n                        )\n                    ]\n                )\n            ]\n\n        )\n        # give pipelinerole read write to the bucket\n        props['bucket'].grant_read_write(pipeline.role)\n\n        #pipeline param to get the\n        pipeline_param = aws_ssm.StringParameter(\n            self, \"PipelineParam\",\n            parameter_name=f\"{props['namespace']}-pipeline\",\n            string_value=pipeline.pipeline_name,\n            description='cdk pipeline bucket'\n        )\n        # cfn output\n        CfnOutput(\n            self, \"PipelineOut\",\n            description=\"Pipeline\",\n            value=pipeline.pipeline_name\n        )", "language": "python"}
{"input": "Represents the concept of an API Schema for a Gateway Target.", "output": "class ApiSchema extends TargetSchema {\n  /**\n   * Creates an API Schema from a local file.\n   * @param path - the path to the local file containing the OpenAPI schema for the action group\n   */\n  public static fromLocalAsset(path: string): AssetApiSchema {\n    return new AssetApiSchema(path);\n  }\n\n  /**\n   * Creates an API Schema from an inline string.\n   * @param schema - the JSON or YAML payload defining the schema (OpenAPI or Smithy)\n   */\n  public static fromInline(schema: string): InlineApiSchema {\n    return new InlineApiSchema(schema);\n  }\n\n  /**\n   * Creates an API Schema from an S3 File\n   * @param bucket - the bucket containing the local file containing the OpenAPI schema for the action group\n   * @param objectKey - object key in the bucket\n   * @param bucketOwnerAccountId - optional The account ID of the Amazon S3 bucket owner. This ID is used for cross-account access to the bucket.\n   */\n  public static fromS3File(bucket: IBucket, objectKey: string, bucketOwnerAccountId?: string): S3ApiSchema {\n    return new S3ApiSchema(\n      {\n        bucketName: bucket.bucketName,\n        objectKey: objectKey,\n      },\n      bucketOwnerAccountId,\n    );\n  }\n\n  /**\n   * The S3 location of the API schema file, if using an S3-based schema.\n   * Contains the bucket name and object key information.\n   */\n  public readonly s3File?: Location;\n\n  /**\n   * The inline OpenAPI schema definition as a string, if using an inline schema.\n   * Can be in JSON or YAML format.\n   */\n  public readonly inlineSchema?: string;\n\n  /**\n   * The account ID of the S3 bucket owner for cross-account access\n   */\n  public readonly bucketOwnerAccountId?: string;\n\n  protected constructor(s3File?: Location, bucketOwnerAccountId?: string, inlineSchema?: string) {\n    super();\n    this.s3File = s3File;\n    this.inlineSchema = inlineSchema;\n    this.bucketOwnerAccountId = bucketOwnerAccountId;\n  }\n\n  /**\n   * Format as CFN properties\n   * @internal This is an internal core function and should not be called directly.\n   */\n  public abstract _render(): any;\n}", "language": "typescript"}
{"input": "CDK class PySparkFlexEtlJob for AWS resource management", "output": "export class PySparkFlexEtlJob extends SparkJob {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-glue-alpha.PySparkFlexEtlJob';\n  public readonly jobArn: string;\n  public readonly jobName: string;\n\n  /**\n   * PySparkFlexEtlJob constructor\n   */\n  constructor(scope: Construct, id: string, props: PySparkFlexEtlJobProps) {\n    super(scope, id, props);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    // Combine command line arguments into a single line item\n    const defaultArguments = {\n      ...this.executableArguments(props),\n      ...this.nonExecutableCommonArguments(props),\n    };\n\n    const jobResource = new CfnJob(this, 'Resource', {\n      name: props.jobName,\n      description: props.description,\n      role: this.role.roleArn,\n      command: {\n        name: JobType.ETL,\n        scriptLocation: this.codeS3ObjectUrl(props.script),\n        pythonVersion: PythonVersion.THREE,\n      },\n      glueVersion: props.glueVersion ? props.glueVersion : GlueVersion.V3_0,\n      workerType: props.workerType ? props.workerType : WorkerType.G_1X,\n      numberOfWorkers: props.numberOfWorkers ? props.numberOfWorkers : 10,\n      maxRetries: props.maxRetries,\n      executionProperty: props.maxConcurrentRuns ? { maxConcurrentRuns: props.maxConcurrentRuns } : undefined,\n      notificationProperty: props.notifyDelayAfter ? { notifyDelayAfter: props.notifyDelayAfter.toMinutes() } : undefined,\n      timeout: props.timeout?.toMinutes(),\n      connections: props.connections ? { connections: props.connections.map((connection) => connection.connectionName) } : undefined,\n      securityConfiguration: props.securityConfiguration?.securityConfigurationName,\n      tags: props.tags,\n      executionClass: ExecutionClass.FLEX,\n      jobRunQueuingEnabled: false,\n      defaultArguments,\n\n    });\n\n    const resourceName = this.getResourceNameAttribute(jobResource.ref);\n    this.jobArn = this.buildJobArn(this, resourceName);\n    this.jobName = resourceName;\n  }\n\n  /**\n   *Set the executable arguments with best practices enabled by default\n   *\n   * @returns An array of arguments for Glue to use on execution\n   */\n  private executableArguments(props: PySparkFlexEtlJobProps) {\n    const args: { [key: string]: string } = {};\n    args['--job-language'] = JobLanguage.PYTHON;\n    this.setupExtraCodeArguments(args, props);\n    return args;\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates DynamoDB, KMS, Kinesis, CloudFormation resources", "output": "class TestStack extends Stack {\n  public constructor(scope: Construct, id: string, props: StackProps) {\n    super(scope, id, props);\n\n    const stream = new Stream(this, 'Stream');\n\n    new TableV2(this, 'GlobalTable', {\n      tableName: 'my-global-table',\n      partitionKey: { name: 'pk', type: AttributeType.STRING },\n      sortKey: { name: 'sk', type: AttributeType.NUMBER },\n      billing: Billing.onDemand(),\n      encryption: TableEncryptionV2.awsManagedKey(),\n      contributorInsights: true,\n      pointInTimeRecovery: true,\n      tableClass: TableClass.STANDARD_INFREQUENT_ACCESS,\n      timeToLiveAttribute: 'attr',\n      removalPolicy: RemovalPolicy.DESTROY,\n      kinesisStream: stream,\n      replicas: [\n        {\n          region: 'eu-west-1',\n          maxReadRequestUnits: 222,\n        },\n      ],\n      globalSecondaryIndexes: [\n        {\n          indexName: 'gsi1',\n          partitionKey: { name: 'pk', type: AttributeType.STRING },\n          maxReadRequestUnits: 1002,\n        },\n        {\n          indexName: 'gsi2',\n          partitionKey: { name: 'pk', type: AttributeType.STRING },\n          maxReadRequestUnits: 2001,\n          maxWriteRequestUnits: 2001,\n        },\n      ],\n      localSecondaryIndexes: [\n        {\n          indexName: 'lsi',\n          sortKey: { name: 'sk', type: AttributeType.NUMBER },\n        },\n      ],\n      tags: [{ key: 'primaryTableTagKey', value: 'primaryTableTagValue' }],\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class PortfolioStage for AWS resource management", "output": "class PortfolioStage extends cdk.Stage {\n      constructor(scope: Construct, id: string) {\n        super(scope, id);\n\n        const portfolioStack: cdk.Stack = new cdk.Stack(this, 'NestedStack');\n\n        const testAssetBucket = new s3.Bucket(portfolioStack, 'TestAssetBucket', {\n          bucketName: 'test-asset-bucket',\n        });\n        const productStack = new servicecatalog.ProductStack(portfolioStack, 'MyProductStack', {\n          assetBucket: testAssetBucket,\n        });\n\n        new lambda.Function(productStack, 'HelloHandler', {\n          runtime: lambda.Runtime.PYTHON_3_9,\n          code: lambda.Code.fromAsset(path.join(__dirname, 'assets')),\n          handler: 'index.handler',\n        });\n\n        expect(productStack._getAssetBucket()).toBeDefined();\n        templateFileUrl = productStack.templateFile;\n      }\n    }", "language": "typescript"}
{"input": "CDK Stack that creates S3, EC2, WAF, CloudFormation resources", "output": "class TestStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const build = new gamelift.Build(this, 'Build', {\n      content: gamelift.Content.fromAsset(path.join(__dirname, 'my-game-build')),\n      operatingSystem: gamelift.OperatingSystem.AMAZON_LINUX_2,\n    });\n\n    new gamelift.BuildFleet(this, 'BuildFleet', {\n      fleetName: 'test-fleet',\n      content: build,\n      ingressRules: [{\n        source: gamelift.Peer.anyIpv4(),\n        port: gamelift.Port.tcp(1935),\n      }],\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.C5, ec2.InstanceSize.LARGE),\n      runtimeConfiguration: {\n        gameSessionActivationTimeout: Duration.seconds(300),\n        maxConcurrentGameSessionActivations: 1,\n        serverProcesses: [{\n          launchPath: '/local/game/TestApplicationServer',\n          parameters: 'port:1935 gameSessionLengthSeconds:20',\n          concurrentExecutions: 1,\n        }],\n      },\n    });\n  }\n}", "language": "typescript"}
{"input": "Agent GenAI resource configuration for prompts.", "output": "class AgentGenAiResource extends PromptGenAiResource {\n  constructor(private readonly props: AgentGenAiResourceProps) {\n    super();\n  }\n\n  public _render(): bedrock.CfnPrompt.PromptGenAiResourceProperty {\n    return {\n      agent: {\n        agentIdentifier: this.props.agentAlias.aliasArn,\n      },\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK class FirewallRuleAction for AWS resource management", "output": "class FirewallRuleAction {\n  /**\n   * Permit the request to go through\n   */\n  public static allow(): FirewallRuleAction {\n    return { action: 'ALLOW' };\n  }\n\n  /**\n   * Permit the request to go through but send an alert to the logs\n   */\n  public static alert(): FirewallRuleAction {\n    return { action: 'ALERT' };\n  }\n\n  /**\n   * Disallow the request\n   *\n   * @param [response=DnsBlockResponse.noData()] The way that you want DNS Firewall to block the request\n   */\n  public static block(response?: DnsBlockResponse): FirewallRuleAction {\n    return {\n      action: 'BLOCK',\n      blockResponse: response ?? DnsBlockResponse.noData(),\n    };\n  }\n\n  /**\n   * The action that DNS Firewall should take on a DNS query when it matches\n   * one of the domains in the rule's domain list\n   */\n  public abstract readonly action: string;\n\n  /**\n   * The way that you want DNS Firewall to block the request\n   */\n  public abstract readonly blockResponse?: DnsBlockResponse;\n}\n\n/**\n * The way that you want DNS Firewall to block the request\n */\nexport abstract class DnsBlockResponse {\n  /**\n   * Respond indicating that the query was successful, but no\n   * response is available for it.\n   */\n  public static noData(): DnsBlockResponse {\n    return { blockResponse: 'NODATA' };\n  }\n\n  /**\n   * Respond indicating that the domain name that's in the query\n   * doesn't exist.\n   */\n  public static nxDomain(): DnsBlockResponse {\n    return { blockResponse: 'NXDOMAIN' };\n  }\n\n  /**\n   * Provides a custom override response to the query\n   *\n   * @param domain The custom DNS record to send back in response to the query\n   * @param [ttl=0] The recommended amount of time for the DNS resolver or\n   *   web browser to cache the provided override record\n   */\n  public static override(domain: string, ttl?: Duration): DnsBlockResponse {\n    return {\n      blockResponse: 'OVERRIDE',\n      blockOverrideDnsType: 'CNAME',\n      blockOverrideDomain: domain,\n      blockOverrideTtl: ttl ?? Duration.seconds(0),\n    };\n  }\n\n  /** The DNS record's type */\n  public abstract readonly blockOverrideDnsType?: string;\n\n  /** The custom DNS record to send back in response to the query */\n  public abstract readonly blockOverrideDomain?: string;\n\n  /**\n   * The recommended amount of time for the DNS resolver or\n   * web browser to cache the provided override record\n   */\n  public abstract readonly blockOverrideTtl?: Duration;\n\n  /** The way that you want DNS Firewall to block the request */\n  public abstract readonly blockResponse?: string;\n}", "language": "typescript"}
{"input": "Schedule for scheduled scaling actions", "output": "class Schedule {\n  /**\n   * Construct a schedule from a literal schedule expression\n   *\n   * @param expression The expression to use. Must be in a format that Application AutoScaling will recognize\n   */\n  public static expression(expression: string): Schedule {\n    return new LiteralSchedule(expression);\n  }\n\n  /**\n   * Construct a schedule from an interval and a time unit\n   */\n  public static rate(duration: Duration): Schedule {\n    if (duration.isUnresolved()) {\n      const validDurationUnit = ['minute', 'minutes', 'hour', 'hours', 'day', 'days'];\n      if (!validDurationUnit.includes(duration.unitLabel())) {\n        throw new UnscopedValidationError(\"Allowed units for scheduling are: 'minute', 'minutes', 'hour', 'hours', 'day' or 'days'\");\n      }\n      return new LiteralSchedule(`rate(${duration.formatTokenToNumber()})`);\n    }\n    if (duration.toSeconds() === 0) {\n      throw new UnscopedValidationError('Duration cannot be 0');\n    }\n\n    let rate = maybeRate(duration.toDays({ integral: false }), 'day');\n    if (rate === undefined) { rate = maybeRate(duration.toHours({ integral: false }), 'hour'); }\n    if (rate === undefined) { rate = makeRate(duration.toMinutes({ integral: true }), 'minute'); }\n    return new LiteralSchedule(rate);\n  }\n\n  /**\n   * Construct a Schedule from a moment in time\n   */\n  public static at(moment: Date): Schedule {\n    return new LiteralSchedule(`at(${formatISO(moment)})`);\n  }\n\n  /**\n   * Create a schedule from a set of cron fields\n   */\n  public static cron(options: CronOptions): Schedule {\n    if (options.weekDay !== undefined && options.day !== undefined) {\n      throw new UnscopedValidationError('Cannot supply both \\'day\\' and \\'weekDay\\', use at most one');\n    }\n\n    const minute = fallback(options.minute, '*');\n    const hour = fallback(options.hour, '*');\n    const month = fallback(options.month, '*');\n    const year = fallback(options.year, '*');\n\n    // Weekday defaults to '?' if not supplied. If it is supplied, day must become '?'\n    const day = fallback(options.day, options.weekDay !== undefined ? '?' : '*');\n    const weekDay = fallback(options.weekDay, '?');\n\n    return new class extends Schedule {\n      public readonly expressionString: string = `cron(${minute} ${hour} ${day} ${month} ${weekDay} ${year})`;\n      public _bind(scope: Construct) {\n        if (!options.minute) {\n          Annotations.of(scope).addWarningV2('@aws-cdk/aws-applicationautoscaling:defaultRunEveryMinute', 'cron: If you don\\'t pass \\'minute\\', by default the event runs every minute. Pass \\'minute: \\'*\\'\\' if that\\'s what you intend, or \\'minute: 0\\' to run once per hour instead.');\n        }\n        return new LiteralSchedule(this.expressionString);\n      }\n    };\n  }\n\n  /**\n   * Retrieve the expression for this schedule\n   */\n  public abstract readonly expressionString: string;\n\n  protected constructor() {}\n\n  /**\n   *\n   * @internal\n   */\n  public abstract _bind(scope: Construct): void;\n}", "language": "typescript"}
{"input": "CDK Stack that creates S3, Lambda, IAM, CloudFormation resources", "output": "export class SharedStack extends cdk.Stack {\n  public readonly bucketName: string;\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const bucket = new s3.Bucket(this, 'SampleBucket', {\n      removalPolicy: cdk.RemovalPolicy.DESTROY\n    });\n    this.bucketName = bucket.bucketName;\n\n    const fn = new lambda.Function(this, 'S3EventNotificationsLambda', {\n      runtime: lambda.Runtime.NODEJS_18_X,\n      functionName: 'S3EventNotificationsManager',\n      handler: 'manage-s3-event-notifications.handler',\n      code: lambda.Code.fromAsset(path.join(__dirname, '../lambda')),\n      reservedConcurrentExecutions: 1,\n      timeout: cdk.Duration.seconds(300)\n    });\n\n    fn.addToRolePolicy(\n      new iam.PolicyStatement({\n        actions: ['s3:GetBucketNotification', 's3:PutBucketNotification'],\n        effect: iam.Effect.ALLOW,\n        resources: [ bucket.bucketArn ]\n      })\n    );\n  }\n}", "language": "typescript"}
{"input": "CDK class AssetImage for AWS resource management", "output": "class AssetImage extends ContainerImage {\n  private asset?: assets.DockerImageAsset;\n\n  constructor(private readonly directory: string, private readonly options: assets.DockerImageAssetOptions = {}) {\n    super();\n  }\n\n  public bind(scope: Construct, model: Model): ContainerImageConfig {\n    // Retain the first instantiation of this asset\n    if (!this.asset) {\n      this.asset = new assets.DockerImageAsset(scope, `ModelImage${hashcode(this.directory)}`, {\n        directory: this.directory,\n        ...this.options,\n      });\n    }\n\n    this.asset.repository.grantPull(model);\n\n    return {\n      imageName: this.asset.imageUri,\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK Stack that creates RDS, EC2, VPC, Secrets Manager resources", "output": "class DatabaseInstanceStack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    const vpc = new ec2.Vpc(this, 'Vpc', { restrictDefaultSecurityGroup: false });\n\n    new rds.DatabaseInstance(this, 'Instance', {\n      engine: rds.DatabaseInstanceEngine.mysql({ version: rds.MysqlEngineVersion.VER_8_0_21 }),\n      instanceType: ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE3, ec2.InstanceSize.SMALL),\n      credentials: rds.Credentials.fromGeneratedSecret('admin', { excludeCharacters: '!&*^#@()' }),\n      vpc,\n      databaseName: 'CDKDB',\n      storageEncrypted: true,\n      backupRetention: cdk.Duration.days(0),\n      deleteAutomatedBackups: true,\n    });\n  }\n}", "language": "typescript"}
{"input": "CDK class TransitGateway for AWS resource management", "output": "export class TransitGateway extends TransitGatewayBase {\n  /** Uniquely identifies this class. */\n  public static readonly PROPERTY_INJECTION_ID: string = '@aws-cdk.aws-ec2-alpha.TransitGateway';\n  public readonly routerType: RouterType;\n  public readonly routerTargetId: string;\n  public readonly transitGatewayId: string;\n  public readonly transitGatewayArn: string;\n  public readonly defaultRouteTable: ITransitGatewayRouteTable;\n  public readonly defaultRouteTableAssociation: boolean;\n  public readonly defaultRouteTablePropagation: boolean;\n  public readonly dnsSupport: boolean;\n  public readonly securityGroupReferencingSupport: boolean;\n\n  constructor(scope: Construct, id: string, props: TransitGatewayProps = {}) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    const resource = new CfnTransitGateway(this, id, {\n      amazonSideAsn: props.amazonSideAsn ?? undefined,\n      autoAcceptSharedAttachments: getFeatureStatus(props.autoAcceptSharedAttachments),\n      // Default Association/Propagation will always be false when creating the L1 to prevent EC2 from creating the default route table.\n      // Instead, CDK will create a custom default route table and use the properties to mimic the automatic assocation/propagation behaviour.\n      defaultRouteTableAssociation: TransitGatewayFeatureStatus.DISABLE,\n      defaultRouteTablePropagation: TransitGatewayFeatureStatus.DISABLE,\n      transitGatewayCidrBlocks: props.transitGatewayCidrBlocks,\n      description: props.description,\n      dnsSupport: getFeatureStatus(props.dnsSupport),\n      securityGroupReferencingSupport: getFeatureStatus(props.securityGroupReferencingSupport),\n    });\n\n    this.node.defaultChild = resource;\n    this.transitGatewayId = resource.attrId;\n    this.routerTargetId = resource.attrId;\n    this.routerType = RouterType.TRANSIT_GATEWAY;\n    this.transitGatewayArn = resource.attrTransitGatewayArn;\n    this.dnsSupport = props.dnsSupport ?? true;\n    this.securityGroupReferencingSupport = props.securityGroupReferencingSupport ?? false;\n\n    this.defaultRouteTable = new TransitGatewayRouteTable(this, 'DefaultRouteTable', {\n      transitGateway: this,\n    });\n\n    this.defaultRouteTableAssociation = props.defaultRouteTableAssociation ?? true;\n    this.defaultRouteTablePropagation = props.defaultRouteTablePropagation ?? true;\n  }\n}", "language": "typescript"}
{"input": "CDK class ExampleComIntegration for AWS resource management", "output": "class ExampleComIntegration extends apigatewayv2.HttpRouteIntegration {\n  public bind(): apigatewayv2.HttpRouteIntegrationConfig {\n    return {\n      type: apigatewayv2.HttpIntegrationType.HTTP_PROXY,\n      payloadFormatVersion: apigatewayv2.PayloadFormatVersion.VERSION_1_0,\n      method: apigatewayv2.HttpMethod.GET,\n      uri: 'https://www.example.com/',\n    };\n  }\n}", "language": "typescript"}
{"input": "CDK helper function for EC2, VPC operations", "output": "def __init__(self, scope: Construct, id: str):\n        super().__init__(scope, id)\n\n        # VPC\n        vpc = ec2.Vpc(self, \"VPC\",\n            nat_gateways=0,\n            subnet_configuration=[ec2.SubnetConfiguration(name=\"public\",subnet_type=ec2.SubnetType.PUBLIC,cidr_mask=24)],\n        )\n\n        # Instance Role and SSM Managed Policy\n        role = iam.Role(self, \"ec2Role\", assumed_by=iam.ServicePrincipal(\"ec2.amazonaws.com\"))\n\n        role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name(\"AmazonSSMManagedInstanceCore\"))\n\n        # AMI\n        amzn_linux = ec2.MachineImage.latest_amazon_linux(\n            generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2,\n            cpu_type=ec2.AmazonLinuxCpuType.ARM_64,\n        )\n\n        # EC2 Instance Type parameter\n        ec2_instance_type = CfnParameter(self, \"InstanceType\",\n            type=\"String\",\n            description=\"The instance type of an EC2 instance.\",\n        )\n\n        # Instance\n        instance = ec2.Instance(self, \"Instance\",\n            instance_type=ec2.InstanceType(ec2_instance_type.value_as_string),\n            machine_image=amzn_linux,\n            allow_all_outbound=True,\n            vpc=vpc,\n            role=role,\n        )\n        instance.connections.allow_from_any_ipv4(ec2.Port.tcp(22), \"Allow SSH Access\")\n\n        # Create outputs for connecting\n        CfnOutput(self, \"IP Address\", value=instance.instance_public_ip)\n        CfnOutput(self, \"Download Key Command\", value=\"aws secretsmanager get-secret-value --secret-id ec2-ssh-key/cdk-keypair/private --query SecretString --output text > cdk-key.pem && chmod 400 cdk-key.pem\")\n        CfnOutput(self, \"ssh command\", value=\"ssh -i cdk-key.pem -o IdentitiesOnly=yes ec2-user@\" + instance.instance_public_ip)", "language": "python"}
{"input": "CDK class TaskDefinition for AWS resource management", "output": "export class TaskDefinition extends TaskDefinitionBase {\n  /**\n   * Uniquely identifies this class.\n   */\n  public static readonly PROPERTY_INJECTION_ID: string = 'aws-cdk-lib.aws-ecs.TaskDefinition';\n\n  /**\n   * Imports a task definition from the specified task definition ARN.\n   *\n   * The task will have a compatibility of EC2+Fargate.\n   */\n  public static fromTaskDefinitionArn(scope: Construct, id: string, taskDefinitionArn: string): ITaskDefinition {\n    return new ImportedTaskDefinition(scope, id, { taskDefinitionArn: taskDefinitionArn });\n  }\n\n  /**\n   * Create a task definition from a task definition reference\n   */\n  public static fromTaskDefinitionAttributes(scope: Construct, id: string, attrs: TaskDefinitionAttributes): ITaskDefinition {\n    return new ImportedTaskDefinition(scope, id, {\n      taskDefinitionArn: attrs.taskDefinitionArn,\n      compatibility: attrs.compatibility,\n      networkMode: attrs.networkMode,\n      taskRole: attrs.taskRole,\n      executionRole: attrs.executionRole,\n    });\n  }\n\n  /**\n   * The name of a family that this task definition is registered to.\n   * A family groups multiple versions of a task definition.\n   */\n  public readonly family: string;\n\n  /**\n   * The full Amazon Resource Name (ARN) of the task definition.\n   * @attribute\n   */\n  public readonly taskDefinitionArn: string;\n\n  /**\n   * The name of the IAM role that grants containers in the task permission to call AWS APIs on your behalf.\n   */\n  public readonly taskRole: iam.IRole;\n\n  /**\n   * The networking mode to use for the containers in the task.\n   */\n  public readonly networkMode: NetworkMode;\n\n  /**\n   * Default container for this task\n   *\n   * Load balancers will send traffic to this container. The first\n   * essential container that is added to this task will become the default\n   * container.\n   */\n  public defaultContainer?: ContainerDefinition;\n\n  /**\n   * The task launch type compatibility requirement.\n   */\n  public readonly compatibility: Compatibility;\n\n  /**\n   * The amount (in GiB) of ephemeral storage to be allocated to the task.\n   *\n   * Only supported in Fargate platform version 1.4.0 or later.\n   */\n  public readonly ephemeralStorageGiB?: number;\n\n  /**\n   * The process namespace to use for the containers in the task.\n   *\n   * Only supported for tasks that are hosted on AWS Fargate if the tasks\n   * are using platform version 1.4.0 or later (Linux). Not supported in\n   * Windows containers. If pidMode is specified for a Fargate task,\n   * then runtimePlatform.operatingSystemFamily must also be specified.  For more\n   * information, see [Task Definition Parameters](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#task_definition_pidmode).\n   */\n  public readonly pidMode?: PidMode;\n\n  /**\n   * The container definitions.\n   */\n  protected readonly containers = new Array<ContainerDefinition>();\n\n  /**\n   * All volumes\n   */\n  private readonly volumes: Volume[] = [];\n\n  /**\n   * Placement constraints for task instances\n   */\n  private readonly placementConstraints = new Array<CfnTaskDefinition.TaskDefinitionPlacementConstraintProperty>();\n\n  /**\n   * Inference accelerators for task instances\n   */\n  private readonly _inferenceAccelerators: InferenceAccelerator[] = [];\n\n  private _executionRole?: iam.IRole;\n\n  private _passRoleStatement?: iam.PolicyStatement;\n\n  private runtimePlatform?: RuntimePlatform;\n\n  private readonly _cpu?: string;\n\n  private readonly _memory?: string;\n\n  /**\n   * Constructs a new instance of the TaskDefinition class.\n   */\n  constructor(scope: Construct, id: string, props: TaskDefinitionProps) {\n    super(scope, id);\n    // Enhanced CDK Analytics Telemetry\n    addConstructMetadata(this, props);\n\n    this.family = props.family || Names.uniqueId(this);\n    this.compatibility = props.compatibility;\n\n    if (props.volumes) {\n      props.volumes.forEach(v => this.addVolume(v));\n    }\n\n    this.networkMode = props.networkMode ??\n      (this.isFargateCompatible || this.isManagedInstancesCompatible ? NetworkMode.AWS_VPC : NetworkMode.BRIDGE);\n    if (this.isFargateCompatible && this.networkMode !== NetworkMode.AWS_VPC) {\n      throw new ValidationError(`Fargate tasks can only have AwsVpc network mode, got: ${this.networkMode}`, this);\n    }\n    if (props.proxyConfiguration && this.networkMode !== NetworkMode.AWS_VPC) {\n      throw new ValidationError(`ProxyConfiguration can only be used with AwsVpc network mode, got: ${this.networkMode}`, this);\n    }\n    if (props.placementConstraints && props.placementConstraints.length > 0 && this.isFargateCompatible) {\n      throw new ValidationError('Cannot set placement constraints on tasks that run on Fargate', this);\n    }\n\n    if (this.isFargateCompatible && (!props.cpu || !props.memoryMiB)) {\n      throw new ValidationError(`Fargate-compatible tasks require both CPU (${props.cpu}) and memory (${props.memoryMiB}) specifications`, this);\n    }\n\n    if (props.inferenceAccelerators && props.inferenceAccelerators.length > 0 && this.isFargateCompatible) {\n      throw new ValidationError('Cannot use inference accelerators on tasks that run on Fargate', this);\n    }\n\n    if (this.isExternalCompatible && ![NetworkMode.BRIDGE, NetworkMode.HOST, NetworkMode.NONE].includes(this.networkMode)) {\n      throw new ValidationError(`External tasks can only have Bridge, Host or None network mode, got: ${this.networkMode}`, this);\n    }\n\n    // Managed Instances validations\n    if (this.isManagedInstancesCompatible) {\n      // Managed Instances only support awsvpc and host network modes\n      if (![NetworkMode.AWS_VPC, NetworkMode.HOST].includes(this.networkMode)) {\n        throw new ValidationError(`Managed Instances tasks can only have AwsVpc or Host network mode, got: ${this.networkMode}`, this);\n      }\n\n      // Managed Instances don't support inference accelerators\n      if (props.inferenceAccelerators && props.inferenceAccelerators.length > 0) {\n        throw new ValidationError('Cannot use inference accelerators on tasks that run on Managed Instances', this);\n      }\n\n      // Managed Instances don't support ephemeral storage\n      if (props.ephemeralStorageGiB) {\n        throw new ValidationError('Ephemeral storage is not supported for tasks running on Managed Instances', this);\n      }\n\n      // Managed Instances don't support IPC mode\n      if (props.ipcMode) {\n        throw new ValidationError('IPC mode is not supported for tasks running on Managed Instances', this);\n      }\n\n      // Managed Instances don't support proxy configuration\n      if (props.proxyConfiguration) {\n        throw new ValidationError('Proxy configuration is not supported for tasks running on Managed Instances', this);\n      }\n\n      // Managed Instances only support LINUX operating system family\n      if (props.runtimePlatform?.operatingSystemFamily && !props.runtimePlatform.operatingSystemFamily.isLinux()) {\n        throw new ValidationError(`Managed Instances tasks only support LINUX operating system family, got: ${props.runtimePlatform.operatingSystemFamily._operatingSystemFamily}`, this);\n      }\n    }\n\n    if (!this.isFargateCompatible && !this.isManagedInstancesCompatible && props.runtimePlatform) {\n      throw new ValidationError('Cannot specify runtimePlatform in non-Fargate and non-Managed Instances compatible tasks', this);\n    }\n\n    // https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fault-injection.html\n    if (props.enableFaultInjection && ![NetworkMode.AWS_VPC, NetworkMode.HOST].includes(this.networkMode)) {\n      throw new ValidationError(`Only AWS_VPC and HOST Network Modes are supported for enabling Fault Injection, got ${this.networkMode} mode.`, this);\n    }\n\n    this._executionRole = props.executionRole;\n\n    this.taskRole = props.taskRole || new iam.Role(this, 'TaskRole', {\n      assumedBy: new iam.ServicePrincipal('ecs-tasks.amazonaws.com'),\n    });\n\n    if (props.inferenceAccelerators) {\n      props.inferenceAccelerators.forEach(ia => this.addInferenceAccelerator(ia));\n    }\n\n    this.ephemeralStorageGiB = props.ephemeralStorageGiB;\n    this.pidMode = props.pidMode;\n\n    // validate the cpu and memory size for the Windows operation system family.\n    if (props.runtimePlatform?.operatingSystemFamily?.isWindows()) {\n      // We know that props.cpu and props.memoryMiB are defined because an error would have been thrown previously if they were not.\n      // But, typescript is not able to figure this out, so using the `!` operator here to let the type-checker know they are defined.\n      this.checkFargateWindowsBasedTasksSize(props.cpu!, props.memoryMiB!, props.runtimePlatform!);\n    }\n\n    this.runtimePlatform = props.runtimePlatform;\n    this._cpu = props.cpu;\n    this._memory = props.memoryMiB;\n\n    let taskDefProps: CfnTaskDefinitionProps = {\n      containerDefinitions: Lazy.any({ produce: () => this.renderContainers() }, { omitEmptyArray: true }),\n      volumes: Lazy.any({ produce: () => this.renderVolumes() }, { omitEmptyArray: true }),\n      executionRoleArn: Lazy.string({ produce: () => this.executionRole && this.executionRole.roleArn }),\n      family: this.family,\n      taskRoleArn: this.taskRole.roleArn,\n      requiresCompatibilities: [\n        ...(isEc2Compatible(props.compatibility) ? ['EC2'] : []),\n        ...(isFargateCompatible(props.compatibility) ? ['FARGATE'] : []),\n        ...(isExternalCompatible(props.compatibility) ? ['EXTERNAL'] : []),\n        ...(isManagedInstancesCompatible(props.compatibility) ? ['MANAGED_INSTANCES'] : []),\n      ],\n      networkMode: this.renderNetworkMode(this.networkMode),\n      placementConstraints: Lazy.any({\n        produce: () =>\n          !isFargateCompatible(this.compatibility) && !isManagedInstancesCompatible(this.compatibility) ? this.placementConstraints : undefined,\n      }, { omitEmptyArray: true }),\n      proxyConfiguration: props.proxyConfiguration ? props.proxyConfiguration.bind(this.stack, this) : undefined,\n      cpu: props.cpu,\n      memory: props.memoryMiB,\n      ipcMode: props.ipcMode,\n      pidMode: this.pidMode,\n      ephemeralStorage: this.ephemeralStorageGiB ? {\n        sizeInGiB: this.ephemeralStorageGiB,\n      } : undefined,\n      runtimePlatform: (this.isFargateCompatible || this.isManagedInstancesCompatible) && this.runtimePlatform ? {\n        cpuArchitecture: this.runtimePlatform?.cpuArchitecture?._cpuArchitecture,\n        operatingSystemFamily: this.runtimePlatform?.operatingSystemFamily?._operatingSystemFamily,\n      } : undefined,\n      enableFaultInjection: props.enableFaultInjection,\n    };\n\n    if (props.inferenceAccelerators) {\n      taskDefProps = {\n        ...taskDefProps,\n        inferenceAccelerators: Lazy.any({\n          produce: () =>\n            this.renderInferenceAccelerators(),\n        }),\n      };\n    }\n\n    const taskDef = new CfnTaskDefinition(this, 'Resource', taskDefProps);\n\n    if (props.placementConstraints) {\n      props.placementConstraints.forEach(pc => this.addPlacementConstraint(pc));\n    }\n\n    this.taskDefinitionArn = taskDef.ref;\n    this.node.addValidation({ validate: () => this.validateTaskDefinition() });\n  }\n\n  public get executionRole(): iam.IRole | undefined {\n    return this._executionRole;\n  }\n\n  /**\n   * Public getter method to access list of inference accelerators attached to the instance.\n   */\n  public get inferenceAccelerators(): InferenceAccelerator[] {\n    return this._inferenceAccelerators;\n  }\n\n  private renderVolumes(): CfnTaskDefinition.VolumeProperty[] {\n    return this.volumes.map(renderVolume);\n\n    function renderVolume(spec: Volume): CfnTaskDefinition.VolumeProperty {\n      return {\n        host: spec.host,\n        name: spec.name,\n        configuredAtLaunch: spec.configuredAtLaunch,\n        dockerVolumeConfiguration: spec.dockerVolumeConfiguration && {\n          autoprovision: spec.dockerVolumeConfiguration.autoprovision,\n          driver: spec.dockerVolumeConfiguration.driver,\n          driverOpts: spec.dockerVolumeConfiguration.driverOpts,\n          labels: spec.dockerVolumeConfiguration.labels,\n          scope: spec.dockerVolumeConfiguration.scope,\n        },\n        efsVolumeConfiguration: spec.efsVolumeConfiguration && {\n          filesystemId: spec.efsVolumeConfiguration.fileSystemId,\n          authorizationConfig: spec.efsVolumeConfiguration.authorizationConfig,\n          rootDirectory: spec.efsVolumeConfiguration.rootDirectory,\n          transitEncryption: spec.efsVolumeConfiguration.transitEncryption,\n          transitEncryptionPort: spec.efsVolumeConfiguration.transitEncryptionPort,\n\n        },\n      };\n    }\n  }\n\n  private renderInferenceAccelerators(): CfnTaskDefinition.InferenceAcceleratorProperty[] {\n    return this._inferenceAccelerators.map(renderInferenceAccelerator);\n\n    function renderInferenceAccelerator(inferenceAccelerator: InferenceAccelerator): CfnTaskDefinition.InferenceAcceleratorProperty {\n      return {\n        deviceName: inferenceAccelerator.deviceName,\n        deviceType: inferenceAccelerator.deviceType,\n      };\n    }\n  }\n\n  /**\n   * Validate the existence of the input target and set default values.\n   *\n   * @internal\n   */\n  public _validateTarget(options: LoadBalancerTargetOptions): LoadBalancerTarget {\n    const targetContainer = this.findContainer(options.containerName);\n    if (targetContainer === undefined) {\n      throw new ValidationError(`No container named '${options.containerName}'. Did you call \"addContainer()\"?`, this);\n    }\n    const targetProtocol = options.protocol || Protocol.TCP;\n    const targetContainerPort = options.containerPort || targetContainer.containerPort;\n    const portMapping = targetContainer.findPortMapping(targetContainerPort, targetProtocol);\n    if (portMapping === undefined) {\n      throw new ValidationError(`Container '${targetContainer}' has no mapping for port ${options.containerPort} and protocol ${targetProtocol}. Did you call \"container.addPortMappings()\"?`, this);\n    }\n    return {\n      containerName: options.containerName,\n      portMapping,\n    };\n  }\n\n  /**\n   * Returns the port range to be opened that match the provided container name and container port.\n   *\n   * @internal\n   */\n  public _portRangeFromPortMapping(portMapping: PortMapping): ec2.Port {\n    if (portMapping.hostPort !== undefined && portMapping.hostPort !== 0) {\n      return portMapping.protocol === Protocol.UDP ? ec2.Port.udp(portMapping.hostPort) : ec2.Port.tcp(portMapping.hostPort);\n    }\n    if (this.networkMode === NetworkMode.BRIDGE || this.networkMode === NetworkMode.NAT) {\n      return EPHEMERAL_PORT_RANGE;\n    }\n    if (portMapping.containerPort !== ContainerDefinition.CONTAINER_PORT_USE_RANGE) {\n      return portMapping.protocol === Protocol.UDP ? ec2.Port.udp(portMapping.containerPort) : ec2.Port.tcp(portMapping.containerPort);\n    }\n    const [startPort, endPort] = portMapping.containerPortRange!.split('-', 2).map(v => Number(v));\n    return portMapping.protocol === Protocol.UDP ? ec2.Port.udpRange(startPort, endPort) : ec2.Port.tcpRange(startPort, endPort);\n  }\n\n  /**\n   * Adds a policy statement to the task IAM role.\n   */\n  @MethodMetadata()\n  public addToTaskRolePolicy(statement: iam.PolicyStatement) {\n    this.taskRole.addToPrincipalPolicy(statement);\n  }\n\n  /**\n   * Adds a policy statement to the task execution IAM role.\n   */\n  @MethodMetadata()\n  public addToExecutionRolePolicy(statement: iam.PolicyStatement) {\n    this.obtainExecutionRole().addToPrincipalPolicy(statement);\n  }\n\n  /**\n   * Adds a new container to the task definition.\n   */\n  @MethodMetadata()\n  public addContainer(id: string, props: ContainerDefinitionOptions) {\n    return new ContainerDefinition(this, id, { taskDefinition: this, ...props });\n  }\n\n  /**\n   * Adds a firelens log router to the task definition.\n   */\n  @MethodMetadata()\n  public addFirelensLogRouter(id: string, props: FirelensLogRouterDefinitionOptions) {\n    // only one firelens log router is allowed in each task.\n    if (this.containers.find(x => x instanceof FirelensLogRouter)) {\n      throw new ValidationError('Firelens log router is already added in this task.', this);\n    }\n\n    return new FirelensLogRouter(this, id, { taskDefinition: this, ...props });\n  }\n\n  /**\n   * Links a container to this task definition.\n   * @internal\n   */\n  public _linkContainer(container: ContainerDefinition) {\n    if (this._cpu) {\n      const taskCpu = Number(this._cpu);\n      const sumOfContainerCpu = [...this.containers, container].map(c => c.cpu).filter((cpu): cpu is number => typeof cpu === 'number').reduce((a, c) => a + c, 0);\n      if (taskCpu < sumOfContainerCpu) {\n        throw new ValidationError('The sum of all container cpu values cannot be greater than the value of the task cpu', this);\n      }\n    }\n\n    this.containers.push(container);\n    if (this.defaultContainer === undefined && container.essential) {\n      this.defaultContainer = container;\n    }\n  }\n\n  /**\n   * Adds a volume to the task definition.\n   */\n  @MethodMetadata()\n  public addVolume(volume: Volume) {\n    this.validateVolume(volume);\n    this.volumes.push(volume);\n  }\n\n  private validateVolume(volume: Volume): void {\n    if (volume.configuredAtLaunch !== true) {\n      // Validate DockerVolumeConfiguration is not used with Managed Instances\n      if (this.isManagedInstancesCompatible && volume.dockerVolumeConfiguration) {\n        throw new ValidationError(`DockerVolumeConfiguration is not supported for tasks running on Managed Instances. Volume '${volume.name}' cannot use dockerVolumeConfiguration`, this);\n      }\n      return;\n    }\n\n    // Other volume configurations must not be specified.\n    if (volume.host || volume.dockerVolumeConfiguration || volume.efsVolumeConfiguration) {\n      throw new ValidationError(`Volume Configurations must not be specified for '${volume.name}' when 'configuredAtLaunch' is set to true`, this);\n    }\n  }\n\n  /**\n   * Adds the specified placement constraint to the task definition.\n   */\n  @MethodMetadata()\n  public addPlacementConstraint(constraint: PlacementConstraint) {\n    if (isFargateCompatible(this.compatibility)) {\n      throw new ValidationError('Cannot set placement constraints on tasks that run on Fargate', this);\n    }\n    this.placementConstraints.push(...constraint.toJson());\n  }\n\n  /**\n   * Adds the specified extension to the task definition.\n   *\n   * Extension can be used to apply a packaged modification to\n   * a task definition.\n   */\n  @MethodMetadata()\n  public addExtension(extension: ITaskDefinitionExtension) {\n    extension.extend(this);\n  }\n\n  /**\n   * Adds an inference accelerator to the task definition.\n   * @deprecated ECS TaskDefinition's inferenceAccelerator is EOL since April 2024\n   */\n  @MethodMetadata()\n  public addInferenceAccelerator(inferenceAccelerator: InferenceAccelerator) {\n    if (isFargateCompatible(this.compatibility)) {\n      throw new ValidationError('Cannot use inference accelerators on tasks that run on Fargate', this);\n    }\n    this._inferenceAccelerators.push(inferenceAccelerator);\n  }\n\n  /**\n   * Grants permissions to run this task definition\n   *\n   * This will grant the following permissions:\n   *\n   *   - ecs:RunTask\n   *   - iam:PassRole\n   *\n   * [disable-awslint:no-grants]\n   *\n   * @param grantee Principal to grant consume rights to\n   */\n  @MethodMetadata()\n  public grantRun(grantee: iam.IGrantable) {\n    grantee.grantPrincipal.addToPrincipalPolicy(this.passRoleStatement);\n    return iam.Grant.addToPrincipal({\n      grantee,\n      actions: ['ecs:RunTask'],\n      resourceArns: [this.taskDefinitionArn],\n    });\n  }\n\n  /**\n   * Creates the task execution IAM role if it doesn't already exist.\n   */\n  @MethodMetadata()\n  public obtainExecutionRole(): iam.IRole {\n    if (!this._executionRole) {\n      this._executionRole = new iam.Role(this, 'ExecutionRole', {\n        assumedBy: new iam.ServicePrincipal('ecs-tasks.amazonaws.com'),\n        // needed for cross-account access with TagParameterContainerImage\n        roleName: PhysicalName.GENERATE_IF_NEEDED,\n      });\n      this.passRoleStatement.addResources(this._executionRole.roleArn);\n    }\n    return this._executionRole;\n  }\n\n  /**\n   * Whether this task definition has at least a container that references a\n   * specific JSON field of a secret stored in Secrets Manager.\n   */\n  public get referencesSecretJsonField(): boolean | undefined {\n    for (const container of this.containers) {\n      if (container.referencesSecretJsonField) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * Validates the task definition.\n   */\n  private validateTaskDefinition(): string[] {\n    const ret = new Array<string>();\n\n    if (isEc2Compatible(this.compatibility)) {\n      // EC2 mode validations\n\n      // Container sizes\n      if (!this._memory) {\n        for (const container of this.containers) {\n          if (!container.memoryLimitSpecified) {\n            ret.push(`ECS Container ${container.containerName} must have at least one of 'memoryLimitMiB' or 'memoryReservationMiB' specified`);\n          }\n        }\n      }\n    }\n\n    // Validate that there are no named port mapping conflicts for Service Connect.\n    const portMappingNames = new Map<string, string>(); // Map from port mapping name to most recent container it appears in.\n    this.containers.forEach(container => {\n      for (const pm of container.portMappings) {\n        if (pm.name) {\n          if (portMappingNames.has(pm.name)) {\n            ret.push(`Port mapping name '${pm.name}' cannot appear in both '${container.containerName}' and '${portMappingNames.get(pm.name)}'`);\n          }\n          portMappingNames.set(pm.name, container.containerName);\n        }\n      }\n    });\n    // Validate if multiple volumes configured with configuredAtLaunch.\n    const runtimeVolumes = this.volumes.filter(vol => vol.configuredAtLaunch);\n    if (runtimeVolumes.length > 1) {\n      const volumeNames = runtimeVolumes.map(vol => vol.name).join(',');\n      ret.push(`More than one volume is configured at launch: [${volumeNames}]`);\n    }\n\n    // Validate that volume with configuredAtLaunch set to true is mounted by at least one container.\n    for (const volume of this.volumes) {\n      if (volume.configuredAtLaunch) {\n        const isVolumeMounted = this.containers.some(container => {\n          return container.mountPoints.some(mp => mp.sourceVolume === volume.name);\n        });\n\n        if (!isVolumeMounted) {\n          ret.push(`Volume '${volume.name}' should be mounted by at least one container when 'configuredAtLaunch' is true`);\n        }\n      }\n    }\n    return ret;\n  }\n\n  /**\n   * Determine the existing port mapping for the provided name.\n   * @param name: port mapping name\n   * @returns PortMapping for the provided name, if it exists.\n   */\n  @MethodMetadata()\n  public findPortMappingByName(name: string): PortMapping | undefined {\n    let portMapping;\n\n    this.containers.forEach(container => {\n      const pm = container.findPortMappingByName(name);\n      if (pm) {\n        portMapping = pm;\n      }\n    });\n\n    return portMapping;\n  }\n\n  /**\n   * Returns the container that match the provided containerName.\n   */\n  @MethodMetadata()\n  public findContainer(containerName: string): ContainerDefinition | undefined {\n    return this.containers.find(c => c.containerName === containerName);\n  }\n\n  private get passRoleStatement() {\n    if (!this._passRoleStatement) {\n      this._passRoleStatement = new iam.PolicyStatement({\n        effect: iam.Effect.ALLOW,\n        actions: ['iam:PassRole'],\n        resources: this.executionRole ? [this.taskRole.roleArn, this.executionRole.roleArn] : [this.taskRole.roleArn],\n        conditions: {\n          StringLike: { 'iam:PassedToService': 'ecs-tasks.amazonaws.com' },\n        },\n      });\n    }\n\n    return this._passRoleStatement;\n  }\n\n  private renderNetworkMode(networkMode: NetworkMode): string | undefined {\n    return (networkMode === NetworkMode.NAT) ? undefined : networkMode;\n  }\n\n  private renderContainers() {\n    // add firelens log router container if any application container is using firelens log driver,\n    // also check if already created log router container\n    for (const container of this.containers) {\n      if (container.logDriverConfig && container.logDriverConfig.logDriver === 'awsfirelens'\n        && !this.containers.find(x => x instanceof FirelensLogRouter)) {\n        this.addFirelensLogRouter('log-router', {\n          image: obtainDefaultFluentBitECRImage(this, container.logDriverConfig),\n          firelensConfig: {\n            type: FirelensLogRouterType.FLUENTBIT,\n          },\n          logging: new AwsLogDriver({ streamPrefix: 'firelens' }),\n          memoryReservationMiB: 50,\n        });\n\n        break;\n      }\n    }\n\n    return this.containers.map(x => x.renderContainerDefinition());\n  }\n\n  private checkFargateWindowsBasedTasksSize(cpu: string, memory: string, runtimePlatform: RuntimePlatform) {\n    if (Number(cpu) === 1024) {\n      if (Number(memory) < 1024 || Number(memory) > 8192 || (Number(memory) % 1024 !== 0)) {\n        throw new ValidationError(`If provided cpu is ${cpu}, then memoryMiB must have a min of 1024 and a max of 8192, in 1024 increments. Provided memoryMiB was ${Number(memory)}.`, this);\n      }\n    } else if (Number(cpu) === 2048) {\n      if (Number(memory) < 4096 || Number(memory) > 16384 || (Number(memory) % 1024 !== 0)) {\n        throw new ValidationError(`If provided cpu is ${cpu}, then memoryMiB must have a min of 4096 and max of 16384, in 1024 increments. Provided memoryMiB ${Number(memory)}.`, this);\n      }\n    } else if (Number(cpu) === 4096) {\n      if (Number(memory) < 8192 || Number(memory) > 30720 || (Number(memory) % 1024 !== 0)) {\n        throw new ValidationError(`If provided cpu is ${cpu}, then memoryMiB must have a min of 8192 and a max of 30720, in 1024 increments.Provided memoryMiB was ${Number(memory)}.`, this);\n      }\n    } else {\n      throw new ValidationError(`If operatingSystemFamily is ${runtimePlatform.operatingSystemFamily!._operatingSystemFamily}, then cpu must be in 1024 (1 vCPU), 2048 (2 vCPU), or 4096 (4 vCPU). Provided value was: ${cpu}`, this);\n    }\n  }\n}", "language": "typescript"}
{"input": "CDK helper function deployIntegrationTest", "output": "export const deployIntegrationTest = async (env: NodeJS.ProcessEnv, snapshotPaths: string[]) => {\n  console.log(`Deploying snapshots:\\n${snapshotPaths.join('\\n')}`);\n\n  const spawnProcess = spawn('yarn', ['integ-runner', '--disable-update-workflow', '--strict', '--directory', 'packages', '--force', ...snapshotPaths], {\n    stdio: ['ignore', 'inherit', 'inherit'],\n    env,\n  });\n\n  return new Promise<void>((resolve, reject) => spawnProcess.on('close', (code) => {\n    if (code == 0) resolve();\n    else reject(new Error(`Integration tests failed with exit code ${code}`));\n  }));\n}", "language": "typescript"}
{"input": "Supported types of gateway responses. @see https://docs.aws.amazon.com/apigateway/latest/developerguide/supported-gateway-response-types.html", "output": "export class ResponseType {\n  /**\n   * The gateway response for authorization failure.\n   */\n  public static readonly ACCESS_DENIED = new ResponseType('ACCESS_DENIED');\n\n  /**\n   * The gateway response for an invalid API configuration.\n   */\n  public static readonly API_CONFIGURATION_ERROR = new ResponseType('API_CONFIGURATION_ERROR');\n\n  /**\n   * The gateway response when a custom or Amazon Cognito authorizer failed to authenticate the caller.\n   */\n  public static readonly AUTHORIZER_FAILURE = new ResponseType('AUTHORIZER_FAILURE');\n\n  /**\n   * The gateway response for failing to connect to a custom or Amazon Cognito authorizer.\n   */\n  public static readonly AUTHORIZER_CONFIGURATION_ERROR = new ResponseType('AUTHORIZER_CONFIGURATION_ERROR');\n\n  /**\n   * The gateway response when the request parameter cannot be validated according to an enabled request validator.\n   */\n  public static readonly BAD_REQUEST_PARAMETERS = new ResponseType('BAD_REQUEST_PARAMETERS');\n\n  /**\n   * The gateway response when the request body cannot be validated according to an enabled request validator.\n   */\n  public static readonly BAD_REQUEST_BODY = new ResponseType('BAD_REQUEST_BODY');\n\n  /**\n   * The default gateway response for an unspecified response type with the status code of 4XX.\n   */\n  public static readonly DEFAULT_4XX = new ResponseType('DEFAULT_4XX');\n\n  /**\n   * The default gateway response for an unspecified response type with a status code of 5XX.\n   */\n  public static readonly DEFAULT_5XX = new ResponseType('DEFAULT_5XX');\n\n  /**\n   * The gateway response for an AWS authentication token expired error.\n   */\n  public static readonly EXPIRED_TOKEN = new ResponseType('EXPIRED_TOKEN');\n\n  /**\n   * The gateway response for an invalid AWS signature error.\n   */\n  public static readonly INVALID_SIGNATURE = new ResponseType('INVALID_SIGNATURE');\n\n  /**\n   * The gateway response for an integration failed error.\n   */\n  public static readonly INTEGRATION_FAILURE = new ResponseType('INTEGRATION_FAILURE');\n\n  /**\n   * The gateway response for an integration timed out error.\n   */\n  public static readonly INTEGRATION_TIMEOUT = new ResponseType('INTEGRATION_TIMEOUT');\n\n  /**\n   * The gateway response for an invalid API key submitted for a method requiring an API key.\n   */\n  public static readonly INVALID_API_KEY = new ResponseType('INVALID_API_KEY');\n\n  /**\n   * The gateway response for a missing authentication token error,\n   * including the cases when the client attempts to invoke an unsupported API method or resource.\n   */\n  public static readonly MISSING_AUTHENTICATION_TOKEN = new ResponseType('MISSING_AUTHENTICATION_TOKEN');\n\n  /**\n   * The gateway response for the usage plan quota exceeded error.\n   */\n  public static readonly QUOTA_EXCEEDED = new ResponseType('QUOTA_EXCEEDED');\n\n  /**\n   * The gateway response for the request too large error.\n   */\n  public static readonly REQUEST_TOO_LARGE = new ResponseType('REQUEST_TOO_LARGE');\n\n  /**\n   * The gateway response when API Gateway cannot find the specified resource\n   * after an API request passes authentication and authorization.\n   */\n  public static readonly RESOURCE_NOT_FOUND = new ResponseType('RESOURCE_NOT_FOUND');\n\n  /**\n   * The gateway response when usage plan, method, stage, or account level throttling limits exceeded.\n   */\n  public static readonly THROTTLED = new ResponseType('THROTTLED');\n\n  /**\n   * The gateway response when the custom or Amazon Cognito authorizer failed to authenticate the caller.\n   */\n  public static readonly UNAUTHORIZED = new ResponseType('UNAUTHORIZED');\n\n  /**\n   * The gateway response when a payload is of an unsupported media type, if strict passthrough behavior is enabled.\n   */\n  public static readonly UNSUPPORTED_MEDIA_TYPE = new ResponseType('UNSUPPORTED_MEDIA_TYPE');\n\n  /**\n   * The gateway response when a request is blocked by AWS WAF.\n   */\n  public static readonly WAF_FILTERED = new ResponseType('WAF_FILTERED');\n\n  /** A custom response type to support future cases. */\n  public static of(type: string): ResponseType {\n    return new ResponseType(type.toUpperCase());\n  }\n\n  /**\n   * Valid value of response type.\n   */\n  public readonly responseType: string;\n\n  private constructor(type: string) {\n    this.responseType = type;\n  }\n}", "language": "typescript"}
{"input": "An allow list receipt filter. @deprecated use `AllowListReceiptFilter`", "output": "export class WhiteListReceiptFilter extends AllowListReceiptFilter {\n  constructor(scope: Construct, id: string, props: WhiteListReceiptFilterProps) {\n    super(scope, id, props);\n  }\n}", "language": "typescript"}
{"input": "A user in a Redshift cluster.", "output": "export class User extends UserBase {\n  /**\n   * Specify a Redshift user using credentials that already exist.\n   */\n  static fromUserAttributes(scope: Construct, id: string, attrs: UserAttributes): IUser {\n    return new class extends UserBase {\n      readonly username = attrs.username;\n      readonly password = attrs.password;\n      readonly cluster = attrs.cluster;\n      readonly databaseName = attrs.databaseName;\n      protected readonly databaseProps = attrs;\n    }(scope, id);\n  }\n\n  readonly username: string;\n  readonly password: cdk.SecretValue;\n  readonly cluster: ICluster;\n  readonly databaseName: string;\n  protected databaseProps: DatabaseOptions;\n\n  /**\n   * The Secrets Manager secret of the user.\n   * @attribute\n   */\n  public readonly secret: secretsmanager.ISecret;\n\n  private resource: DatabaseQuery<UserHandlerProps>;\n\n  constructor(scope: Construct, id: string, props: UserProps) {\n    super(scope, id);\n\n    this.databaseProps = props;\n    this.cluster = props.cluster;\n    this.databaseName = props.databaseName;\n\n    const username = props.username ?? cdk.Names.uniqueId(this).toLowerCase();\n    const secret = new DatabaseSecret(this, 'Secret', {\n      username,\n      encryptionKey: props.encryptionKey,\n      excludeCharacters: props.excludeCharacters,\n    });\n    const attachedSecret = secret.attach(props.cluster);\n    this.password = attachedSecret.secretValueFromJson('password');\n\n    this.resource = new DatabaseQuery<UserHandlerProps>(this, 'Resource', {\n      ...this.databaseProps,\n      handler: HandlerName.User,\n      properties: {\n        username,\n        passwordSecretArn: attachedSecret.secretArn,\n      },\n    });\n    attachedSecret.grantRead(this.resource);\n\n    this.username = this.resource.getAttString('username');\n    this.secret = secret;\n  }\n\n  /**\n   * Apply the given removal policy to this resource\n   *\n   * The Removal Policy controls what happens to this resource when it stops\n   * being managed by CloudFormation, either because you've removed it from the\n   * CDK application or because you've made a change that requires the resource\n   * to be replaced.\n   *\n   * The resource can be destroyed (`RemovalPolicy.DESTROY`), or left in your AWS\n   * account for data recovery and cleanup later (`RemovalPolicy.RETAIN`).\n   *\n   * This resource is destroyed by default.\n   */\n  public applyRemovalPolicy(policy: cdk.RemovalPolicy): void {\n    this.resource.applyRemovalPolicy(policy);\n  }\n}", "language": "typescript"}
