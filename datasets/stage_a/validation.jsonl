{"input": "Recursively injects environment variables into TOML values", "output": "def inject_environment_variables(self, d):\n        \"\"\"\n        Recursively injects environment variables into TOML values\n        \"\"\"\n\n        if not d:\n            return d\n        if isinstance(d, six.string_types):\n            return os.path.expandvars(d)\n        for k, v in d.items():\n            if isinstance(v, six.string_types):\n                d[k] = os.path.expandvars(v)\n            elif isinstance(v, dict):\n                d[k] = self.inject_environment_variables(v)\n            elif isinstance(v, list):\n                d[k] = [self.inject_environment_variables(e) for e in v]\n\n        return d", "language": "python"}
{"input": "Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).\n    Use this for downloads of >100 images. Requires `selenium`.", "output": "def _fetch_img_tuples_webdriver(url:str, format:str='jpg', n_images:int=150) -> list:\n    \"\"\"\n    Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).\n    Use this for downloads of >100 images. Requires `selenium`.\n    \"\"\"\n    try:\n        from selenium import webdriver\n        from selenium.webdriver.common.keys import Keys\n    except:\n        print(\"\"\"Looks like you're trying to download > 100 images and `selenium`\n                is not installed. Try running `pip install selenium` to fix this. \n                You'll also need chrome and `chromedriver` installed.\"\"\")\n    options = webdriver.ChromeOptions()\n    options.add_argument(\"--headless\")\n    try: driver = webdriver.Chrome(chrome_options=options)\n    except: print(\"\"\"Error initializing chromedriver. \n                    Check if it's in your path by running `which chromedriver`\"\"\")\n    driver.set_window_size(1440, 900)\n    driver.get(url)\n\n    for i in range(n_images // 100 + 1):\n        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n        time.sleep(0.5 + random.random()/2.0)\n\n    n_available = len(driver.find_elements_by_css_selector(\"div.rg_meta\"))\n    if n_available < n_images:\n        raise ValueError(f\"Requested {n_images} images, but only found {n_available}.\")\n\n    html = driver.page_source\n    driver.close()\n    return _html_to_img_tuples(html, format=format, n_images=n_images)", "language": "python"}
{"input": "Load scrollbar styling based on whether or not theme scrollbars are enabled.\n\n@param {ThemeManager.Theme} theme Is the theme object with the corresponding scrollbar style\nto be updated", "output": "function updateScrollbars(theme) {\n        theme = theme || {};\n        if (prefs.get(\"themeScrollbars\")) {\n            var scrollbar = (theme.scrollbar || []).join(\" \");\n            $scrollbars.text(scrollbar || \"\");\n        } else {\n            $scrollbars.text(\"\");\n        }\n    }", "language": "javascript"}
{"input": "Extend schema of component given a partial schema.\n\nSome components might want to mutate their schema based on certain properties.\ne.g., Material component changes its schema based on `shader` to account for different\nuniforms\n\n@param {object} schemaAddon - Schema chunk that extend base schema.", "output": "function (schemaAddon) {\n    var extendedSchema;\n    // Clone base schema.\n    extendedSchema = utils.extend({}, components[this.name].schema);\n    // Extend base schema with new schema chunk.\n    utils.extend(extendedSchema, schemaAddon);\n    this.schema = processSchema(extendedSchema);\n    this.el.emit('schemachanged', this.evtDetail);\n  }", "language": "javascript"}
{"input": "Verifies that the meta.docs.description property follows our internal conventions.\n\n@param {RuleContext} context The ESLint rule context.\n@param {ASTNode} exportsNode ObjectExpression node that the rule exports.\n@returns {void}", "output": "function checkMetaDocsDescription(context, exportsNode) {\n    if (exportsNode.type !== \"ObjectExpression\") {\n\n        // if the exported node is not the correct format, \"internal-no-invalid-meta\" will already report this.\n        return;\n    }\n\n    const metaProperty = getPropertyFromObject(\"meta\", exportsNode);\n    const metaDocs = metaProperty && getPropertyFromObject(\"docs\", metaProperty.value);\n    const metaDocsDescription = metaDocs && getPropertyFromObject(\"description\", metaDocs.value);\n\n    if (!metaDocsDescription) {\n\n        // if there is no `meta.docs.description` property, \"internal-no-invalid-meta\" will already report this.\n        return;\n    }\n\n    const description = metaDocsDescription.value.value;\n\n    if (typeof description !== \"string\") {\n        context.report({\n            node: metaDocsDescription.value,\n            message: \"`meta.docs.description` should be a string.\"\n        });\n        return;\n    }\n\n    if (description === \"\") {\n        context.report({\n            node: metaDocsDescription.value,\n            message: \"`meta.docs.description` should not be empty.\"\n        });\n        return;\n    }\n\n    if (description.indexOf(\" \") === 0) {\n        context.report({\n            node: metaDocsDescription.value,\n            message: \"`meta.docs.description` should not start with whitespace.\"\n        });\n        return;\n    }\n\n    const firstWord = description.split(\" \")[0];\n\n    if (ALLOWED_FIRST_WORDS.indexOf(firstWord) === -1) {\n        context.report({\n            node: metaDocsDescription.value,\n            message: \"`meta.docs.description` should start with one of the following words: {{ allowedWords }}. Started with \\\"{{ firstWord }}\\\" instead.\",\n            data: {\n                allowedWords: ALLOWED_FIRST_WORDS.join(\", \"),\n                firstWord\n            }\n        });\n    }\n}", "language": "javascript"}
{"input": "This moves the selected or focus index left or right. This is used by the keydown handler.\n@param {number} inc amount to increment\n@param {boolean} focus true to increment the focus index, false to increment the selected index", "output": "function incrementIndex (inc, focus) {\n    var newIndex,\n        key   = focus ? 'focusIndex' : 'selectedIndex',\n        index = ctrl[ key ];\n    for (newIndex = index + inc;\n         ctrl.tabs[ newIndex ] && ctrl.tabs[ newIndex ].scope.disabled;\n         newIndex += inc) { /* do nothing */ }\n\n    newIndex = (index + inc + ctrl.tabs.length) % ctrl.tabs.length;\n\n    if (ctrl.tabs[ newIndex ]) {\n      ctrl[ key ] = newIndex;\n    }\n  }", "language": "javascript"}
{"input": "Restore the original SIGINT handler after finishing.\n\n        This should happen regardless of whether the progress display finishes\n        normally, or gets interrupted.", "output": "def finish(self):\n        \"\"\"\n        Restore the original SIGINT handler after finishing.\n\n        This should happen regardless of whether the progress display finishes\n        normally, or gets interrupted.\n        \"\"\"\n        super(InterruptibleMixin, self).finish()\n        signal(SIGINT, self.original_handler)", "language": "python"}
{"input": "Appends lines to a buffer.\n\n    Parameters\n    ----------\n    buf\n        The buffer to write to\n    lines\n        The lines to append.", "output": "def buffer_put_lines(buf, lines):\n    \"\"\"\n    Appends lines to a buffer.\n\n    Parameters\n    ----------\n    buf\n        The buffer to write to\n    lines\n        The lines to append.\n    \"\"\"\n    if any(isinstance(x, str) for x in lines):\n        lines = [str(x) for x in lines]\n    buf.write('\\n'.join(lines))", "language": "python"}
{"input": "Fix the spacing between the given 2 tokens.\n@param {RuleFixer} fixer The fixer to fix.\n@param {Token} left The left token of fix range.\n@param {Token} right The right token of fix range.\n@param {boolean} spacing The spacing style. `true` if there should be a space.\n@returns {Fix|null} The fix object.", "output": "function fix(fixer, left, right, spacing) {\n            if (commentsExistBetween(left, right)) {\n                return null;\n            }\n            if (spacing) {\n                return fixer.insertTextAfter(left, \" \");\n            }\n            return fixer.removeRange([left.range[1], right.range[0]]);\n        }", "language": "javascript"}
{"input": "Recursive Tree Traversal\n@param {object} oNode the current node\n@param {boolean} bIgnore a flag to indicate if the node should be mapped\n@param {object} oParent the parent node of oNode\n@param {int} iPositionInParent the position of oNode in the children-array of oParent", "output": "function (oNode, bIgnore, oParent, iPositionInParent, oIgnoreRemoveForNode) {\n\t\t\t// ignore node if it was already mapped or is removed (except if it was reinserted, denoted by oIgnoreRemoveForNode)\n\t\t\tif (!bIgnore) {\n\t\t\t\tif (!oNode.nodeState.removed || oIgnoreRemoveForNode == oNode) {\n\t\t\t\t\tfnMap(oNode, oRecursionBreaker, \"positionInParent\", iPositionInParent, oParent);\n\t\t\t\t\tif (oRecursionBreaker.broken) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tfnCheckNodeForAddedSubtrees(oNode);\n\t\t\tif (oRecursionBreaker.broken) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// if the node also has children AND is expanded, dig deeper\n\t\t\tif (oNode && oNode.children && oNode.nodeState.expanded) {\n\t\t\t\tfor (var i = 0; i < oNode.children.length; i++) {\n\t\t\t\t\tvar oChildNode = oNode.children[i];\n\t\t\t\t\t// Make sure that the level of all child nodes are adapted to the parent level,\n\t\t\t\t\t// this is necessary if the parent node was placed in a different leveled subtree.\n\t\t\t\t\t// Ignore removed nodes, which are not re-inserted.\n\t\t\t\t\t// Re-inserted deep nodes will be regarded in fnTraverseAddedSubtree.\n\t\t\t\t\tif (oChildNode && !oChildNode.nodeState.removed && !oChildNode.nodeState.reinserted) {\n\t\t\t\t\t\toChildNode.level = oNode.level + 1;\n\t\t\t\t\t}\n\t\t\t\t\t// only dive deeper if we have a gap (entry which has to be loaded) or a defined node is NOT removed\n\t\t\t\t\tif (oChildNode && !oChildNode.nodeState.removed) {\n\t\t\t\t\t\tfnTraverseDeepSubtree(oChildNode, false, oNode, i, oIgnoreRemoveForNode);\n\t\t\t\t\t} else if (!oChildNode) {\n\t\t\t\t\t\tfnMap(oChildNode, oRecursionBreaker, \"positionInParent\", i, oNode);\n\t\t\t\t\t}\n\t\t\t\t\tif (oRecursionBreaker.broken) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "See ``PlaceholderType.resolve``", "output": "def resolve(self, other: Type) -> Type:\n        \"\"\"See ``PlaceholderType.resolve``\"\"\"\n        if not isinstance(other, NltkComplexType):\n            return None\n        resolved_second = NUMBER_TYPE.resolve(other.second)\n        if not resolved_second:\n            return None\n        return CountType(other.first)", "language": "python"}
{"input": "Find all expressions in the parentBlockStatement that are same as expn\n@param {!ASTNode} parentBlockStatement\n@param {!ASTNode} expn\n@param {!string} text - text of the expression\n@return {!Array.<ASTNode>}", "output": "function findAllExpressions(parentBlockStatement, expn, text) {\n        var doc   = session.editor.document,\n            obj   = {},\n            expns = [];\n\n        // find all references of the expression\n        obj[expn.type] = function(node) {\n            if (text === doc.getText().substr(node.start, node.end - node.start)) {\n                expns.push(node);\n            }\n        };\n        ASTWalker.simple(parentBlockStatement, obj);\n\n        return expns;\n    }", "language": "javascript"}
{"input": "Updates the position of the popper, computing the new offsets and applying\nthe new style.<br />\nPrefer `scheduleUpdate` over `update` because of performance reasons.\n@method\n@memberof Popper", "output": "function update() {\n  // if popper is destroyed, don't perform any further update\n  if (this.state.isDestroyed) {\n    return;\n  }\n\n  var data = {\n    instance: this,\n    styles: {},\n    arrowStyles: {},\n    attributes: {},\n    flipped: false,\n    offsets: {}\n  };\n\n  // compute reference element offsets\n  data.offsets.reference = getReferenceOffsets(this.state, this.popper, this.reference, this.options.positionFixed);\n\n  // compute auto placement, store placement inside the data object,\n  // modifiers will be able to edit `placement` if needed\n  // and refer to originalPlacement to know the original value\n  data.placement = computeAutoPlacement(this.options.placement, data.offsets.reference, this.popper, this.reference, this.options.modifiers.flip.boundariesElement, this.options.modifiers.flip.padding);\n\n  // store the computed placement inside `originalPlacement`\n  data.originalPlacement = data.placement;\n\n  data.positionFixed = this.options.positionFixed;\n\n  // compute the popper offsets\n  data.offsets.popper = getPopperOffsets(this.popper, data.offsets.reference, data.placement);\n  data.offsets.popper.position = this.options.positionFixed ? 'fixed' : 'absolute';\n\n  // run the modifiers\n  data = runModifiers(this.modifiers, data);\n\n  // the first `update` will call `onCreate` callback\n  // the other ones will call `onUpdate` callback\n  if (!this.state.isCreated) {\n    this.state.isCreated = true;\n    this.options.onCreate(data);\n  } else {\n    this.options.onUpdate(data);\n  }\n}", "language": "javascript"}
{"input": "Bottom transformation for embedding video bitwise.", "output": "def video_bitwise_bottom(x, model_hparams, vocab_size):\n  \"\"\"Bottom transformation for embedding video bitwise.\"\"\"\n  pixel_embedding_size = 64\n  inputs = x\n  with tf.variable_scope(\"video_modality_bitwise\", reuse=tf.AUTO_REUSE):\n    common_layers.summarize_video(inputs, \"bottom\")\n    # Embed bitwise.\n    assert vocab_size == 256\n    embedded = discretization.int_to_bit_embed(inputs, 8,\n                                               pixel_embedding_size)\n    # Project.\n    return tf.layers.dense(\n        embedded,\n        model_hparams.hidden_size,\n        name=\"merge_pixel_embedded_frames\")", "language": "python"}
{"input": "Helper function to convert DataFrame and Series to matplotlib.table\n\n    Parameters\n    ----------\n    ax : Matplotlib axes object\n    data : DataFrame or Series\n        data for table contents\n    kwargs : keywords, optional\n        keyword arguments which passed to matplotlib.table.table.\n        If `rowLabels` or `colLabels` is not specified, data index or column\n        name will be used.\n\n    Returns\n    -------\n    matplotlib table object", "output": "def table(ax, data, rowLabels=None, colLabels=None, **kwargs):\n    \"\"\"\n    Helper function to convert DataFrame and Series to matplotlib.table\n\n    Parameters\n    ----------\n    ax : Matplotlib axes object\n    data : DataFrame or Series\n        data for table contents\n    kwargs : keywords, optional\n        keyword arguments which passed to matplotlib.table.table.\n        If `rowLabels` or `colLabels` is not specified, data index or column\n        name will be used.\n\n    Returns\n    -------\n    matplotlib table object\n    \"\"\"\n    if isinstance(data, ABCSeries):\n        data = data.to_frame()\n    elif isinstance(data, ABCDataFrame):\n        pass\n    else:\n        raise ValueError('Input data must be DataFrame or Series')\n\n    if rowLabels is None:\n        rowLabels = data.index\n\n    if colLabels is None:\n        colLabels = data.columns\n\n    cellText = data.values\n\n    import matplotlib.table\n    table = matplotlib.table.table(ax, cellText=cellText,\n                                   rowLabels=rowLabels,\n                                   colLabels=colLabels, **kwargs)\n    return table", "language": "python"}
{"input": "Drain excess inactive sounds from the pool.", "output": "function() {\n      var self = this;\n      var limit = self._pool;\n      var cnt = 0;\n      var i = 0;\n\n      // If there are less sounds than the max pool size, we are done.\n      if (self._sounds.length < limit) {\n        return;\n      }\n\n      // Count the number of inactive sounds.\n      for (i=0; i<self._sounds.length; i++) {\n        if (self._sounds[i]._ended) {\n          cnt++;\n        }\n      }\n\n      // Remove excess inactive sounds, going in reverse order.\n      for (i=self._sounds.length - 1; i>=0; i--) {\n        if (cnt <= limit) {\n          return;\n        }\n\n        if (self._sounds[i]._ended) {\n          // Disconnect the audio source when using Web Audio.\n          if (self._webAudio && self._sounds[i]._node) {\n            self._sounds[i]._node.disconnect(0);\n          }\n\n          // Remove sounds until we have the pool size.\n          self._sounds.splice(i, 1);\n          cnt--;\n        }\n      }\n    }", "language": "javascript"}
{"input": "Groupby iterator\n\n        Returns\n        -------\n        Generator yielding sequence of (name, subsetted object)\n        for each group", "output": "def get_iterator(self, data, axis=0):\n        \"\"\"\n        Groupby iterator\n\n        Returns\n        -------\n        Generator yielding sequence of (name, subsetted object)\n        for each group\n        \"\"\"\n        splitter = self._get_splitter(data, axis=axis)\n        keys = self._get_group_keys()\n        for key, (i, group) in zip(keys, splitter):\n            yield key, group", "language": "python"}
{"input": "### Model Query\nMake the call to the Model layer\n@param {Object} options\n@returns {Object} options", "output": "function doQuery(options) {\n            return models.Tag.add(options.data.tags[0], _.omit(options, ['data']))\n                .then((model) => {\n                    return {\n                        tags: [urlsForTag(model.id, model.toJSON(options), options)]\n                    };\n                });\n        }", "language": "javascript"}
{"input": "make localized dispatch, commit, getters and state\nif there is no namespace, just use root ones", "output": "function makeLocalContext (store, namespace, path) {\n  const noNamespace = namespace === ''\n\n  const local = {\n    dispatch: noNamespace ? store.dispatch : (_type, _payload, _options) => {\n      const args = unifyObjectStyle(_type, _payload, _options)\n      const { payload, options } = args\n      let { type } = args\n\n      if (!options || !options.root) {\n        type = namespace + type\n        if (process.env.NODE_ENV !== 'production' && !store._actions[type]) {\n          console.error(`[vuex] unknown local action type: ${args.type}, global type: ${type}`)\n          return\n        }\n      }\n\n      return store.dispatch(type, payload)\n    },\n\n    commit: noNamespace ? store.commit : (_type, _payload, _options) => {\n      const args = unifyObjectStyle(_type, _payload, _options)\n      const { payload, options } = args\n      let { type } = args\n\n      if (!options || !options.root) {\n        type = namespace + type\n        if (process.env.NODE_ENV !== 'production' && !store._mutations[type]) {\n          console.error(`[vuex] unknown local mutation type: ${args.type}, global type: ${type}`)\n          return\n        }\n      }\n\n      store.commit(type, payload, options)\n    }\n  }\n\n  // getters and state object must be gotten lazily\n  // because they will be changed by vm update\n  Object.defineProperties(local, {\n    getters: {\n      get: noNamespace\n        ? () => store.getters\n        : () => makeLocalGetters(store, namespace)\n    },\n    state: {\n      get: () => getNestedState(store.state, path)\n    }\n  })\n\n  return local\n}", "language": "javascript"}
{"input": "Verifies that the meta.docs.url property is present and has the correct value.\n\n@param {RuleContext} context The ESLint rule context.\n@param {ASTNode} exportsNode ObjectExpression node that the rule exports.\n@returns {void}", "output": "function checkMetaDocsUrl(context, exportsNode) {\n    if (exportsNode.type !== \"ObjectExpression\") {\n\n        // if the exported node is not the correct format, \"internal-no-invalid-meta\" will already report this.\n        return;\n    }\n\n    const metaProperty = getPropertyFromObject(\"meta\", exportsNode);\n    const metaDocs = metaProperty && getPropertyFromObject(\"docs\", metaProperty.value);\n    const metaDocsUrl = metaDocs && getPropertyFromObject(\"url\", metaDocs.value);\n\n    if (!metaDocs) {\n        context.report({\n            node: metaProperty,\n            message: \"Rule is missing a meta.docs property\"\n        });\n        return;\n    }\n\n    if (!metaDocsUrl) {\n        context.report({\n            node: metaDocs,\n            message: \"Rule is missing a meta.docs.url property\"\n        });\n        return;\n    }\n\n    const ruleId = path.basename(context.getFilename().replace(/.js$/u, \"\"));\n    const expected = `https://eslint.org/docs/rules/${ruleId}`;\n    const url = metaDocsUrl.value.value;\n\n    if (url !== expected) {\n        context.report({\n            node: metaDocsUrl.value,\n            message: `Incorrect url. Expected \"${expected}\" but got \"${url}\"`\n        });\n    }\n\n}", "language": "javascript"}
{"input": "@method removeWhile\n\n@param {Node} node\n@param {Function} pred", "output": "function removeWhile(node, pred) {\n  while (node) {\n    if (isEditable(node) || !pred(node)) {\n      break;\n    }\n\n    const parent = node.parentNode;\n    remove(node);\n    node = parent;\n  }\n}", "language": "javascript"}
{"input": "Function: getMainEvent\n\nReturns the touch or mouse event that contains the mouse coordinates.", "output": "function(e)\n\t{\n\t\tif ((e.type == 'touchstart' || e.type == 'touchmove') && e.touches != null && e.touches[0] != null)\n\t\t{\n\t\t\te = e.touches[0];\n\t\t}\n\t\telse if (e.type == 'touchend' && e.changedTouches != null && e.changedTouches[0] != null)\n\t\t{\n\t\t\te = e.changedTouches[0];\n\t\t}\n\t\t\n\t\treturn e;\n\t}", "language": "javascript"}
{"input": "Loads and preprocessed data for the MR dataset.\n    Returns input vectors, labels, vocabulary, and inverse vocabulary.", "output": "def load_data():\n    \"\"\"Loads and preprocessed data for the MR dataset.\n    Returns input vectors, labels, vocabulary, and inverse vocabulary.\n    \"\"\"\n    # Load and preprocess data\n    sentences, labels = load_data_and_labels()\n    sentences_padded = pad_sentences(sentences)\n    vocabulary, vocabulary_inv = build_vocab(sentences_padded)\n    x, y = build_input_data(sentences_padded, labels, vocabulary)\n    return [x, y, vocabulary, vocabulary_inv]", "language": "python"}
{"input": "Returns trials in the lower and upper `quantile` of the population.\n\n        If there is not enough data to compute this, returns empty lists.", "output": "def _quantiles(self):\n        \"\"\"Returns trials in the lower and upper `quantile` of the population.\n\n        If there is not enough data to compute this, returns empty lists.\"\"\"\n\n        trials = []\n        for trial, state in self._trial_state.items():\n            if state.last_score is not None and not trial.is_finished():\n                trials.append(trial)\n        trials.sort(key=lambda t: self._trial_state[t].last_score)\n\n        if len(trials) <= 1:\n            return [], []\n        else:\n            return (trials[:int(math.ceil(len(trials) * PBT_QUANTILE))],\n                    trials[int(math.floor(-len(trials) * PBT_QUANTILE)):])", "language": "python"}
{"input": "/* [XLS] old spec", "output": "function parse_PtgSheet(blob, length, opts) {\n\tblob.l += 5;\n\tblob.l += 2;\n\tblob.l += (opts.biff == 2 ? 1 : 4);\n\treturn [\"PTGSHEET\"];\n}", "language": "javascript"}
{"input": "Checks if the given meta path contains a dot in its first segment.\n\n@param {string} sMetaPath The meta path\n@returns {boolean} Whether the given meta path contains a dot in its first segment", "output": "function startsWithQualifiedName(sMetaPath) {\n\t\t\tvar iDotPos = sMetaPath.indexOf(\".\"),\n\t\t\t\tiSlashPos = sMetaPath.indexOf(\"/\");\n\n\t\t\treturn iDotPos > 0 && (iSlashPos < 0 || iDotPos < iSlashPos);\n\t\t}", "language": "javascript"}
{"input": "Create and/or show the editor for the specified document\n@param {!Document} document - document to edit\n@param {!Pane} pane - pane to show it in\n@param {!Object} editorOptions - If specified, contains\neditor options that can be passed to CodeMirror\n@private", "output": "function _showEditor(document, pane, editorOptions) {\n        // Ensure a main editor exists for this document to show in the UI\n        var createdNewEditor = false,\n            editor = document._masterEditor;\n\n        // Check if a master editor is not set already or the current master editor doesn't belong\n        // to the pane container requested - to support creation of multiple full editors\n        // This check is required as _masterEditor is the active full editor for the document\n        // and there can be existing full editor created for other panes\n        if (editor && editor._paneId && editor._paneId !== pane.id) {\n            editor = document._checkAssociatedEditorForPane(pane.id);\n        }\n\n        if (!editor) {\n            // Performance (see #4757) Chrome wastes time messing with selection\n            // that will just be changed at end, so clear it for now\n            if (window.getSelection && window.getSelection().empty) {  // Chrome\n                window.getSelection().empty();\n            }\n\n            // Editor doesn't exist: populate a new Editor with the text\n            editor = _createFullEditorForDocument(document, pane, editorOptions);\n            createdNewEditor = true;\n        } else if (editor.$el.parent()[0] !== pane.$content[0]) {\n            // editor does exist but is not a child of the pane so add it to the\n            //  pane (which will switch the view's container as well)\n            pane.addView(editor);\n        }\n\n        // show the view\n        pane.showView(editor);\n\n        if (MainViewManager.getActivePaneId() === pane.id) {\n            // give it focus\n            editor.focus();\n        }\n\n        if (createdNewEditor) {\n            _restoreEditorViewState(editor);\n        }\n    }", "language": "javascript"}
{"input": "Sets the value of the given property and triggers Dom change if\npossible.\n\n@private", "output": "function(oThis, sProp, oValue, sChangeType) {\n\t\tvar bHasDomRef = !!oThis.getDomRef();\n\t\toThis.setProperty(sProp, oValue, bHasDomRef);\n\t\tif (bHasDomRef) {\n\t\t\toThis.contentChanged(null, sChangeType);\n\t\t}\n\t\treturn oThis;\n\t}", "language": "javascript"}
{"input": "Get symbol of mnist", "output": "def get_mnist_sym(output_op=None, num_hidden=400):\n    \"\"\"Get symbol of mnist\"\"\"\n    net = mx.symbol.Variable('data')\n    net = mx.symbol.FullyConnected(data=net, name='mnist_fc1', num_hidden=num_hidden)\n    net = mx.symbol.Activation(data=net, name='mnist_relu1', act_type=\"relu\")\n    net = mx.symbol.FullyConnected(data=net, name='mnist_fc2', num_hidden=num_hidden)\n    net = mx.symbol.Activation(data=net, name='mnist_relu2', act_type=\"relu\")\n    net = mx.symbol.FullyConnected(data=net, name='mnist_fc3', num_hidden=10)\n    if output_op is None:\n        net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n    else:\n        net = output_op(data=net, name='softmax')\n    return net", "language": "python"}
{"input": "/*\nModifies the labels and descriptions of a column header cell.\n@see ExtensionHelper.performCellModifications", "output": "function($Cell) {\n\t\t\tvar oTable = this.getTable(),\n\t\t\t\toColumn = sap.ui.getCore().byId($Cell.attr(\"data-sap-ui-colid\")),\n\t\t\t\tmAttributes = ExtensionHelper.getAriaAttributesFor(this, TableAccExtension.ELEMENTTYPES.COLUMNHEADER, {\n\t\t\t\t\theaderId: $Cell.attr(\"id\"),\n\t\t\t\t\tcolumn: oColumn,\n\t\t\t\t\tindex: $Cell.attr(\"data-sap-ui-colindex\")\n\t\t\t\t}),\n\t\t\t\tsText = ExtensionHelper.getColumnTooltip(oColumn),\n\t\t\t\taLabels = [oTable.getId() + \"-colnumberofcols\"].concat(mAttributes[\"aria-labelledby\"]),\n\t\t\t\toCellInfo = TableUtils.getCellInfo($Cell),\n\t\t\t\tiSpan = oCellInfo.columnSpan;\n\n\t\t\tif (iSpan > 1) {\n\t\t\t\taLabels.push(oTable.getId() + \"-ariacolspan\");\n\t\t\t\t// Update Span information\n\t\t\t\toTable.$(\"ariacolspan\").text(TableUtils.getResourceText(\"TBL_COL_DESC_SPAN\", [\"\" + iSpan]));\n\t\t\t}\n\n\t\t\tif (sText) {\n\t\t\t\taLabels.push(oTable.getId() + \"-cellacc\");\n\t\t\t}\n\n\t\t\tif (iSpan <= 1 && oColumn && oColumn.getSorted()) {\n\t\t\t\taLabels.push(oTable.getId() + (oColumn.getSortOrder() === \"Ascending\" ? \"-ariacolsortedasc\" : \"-ariacolsorteddes\"));\n\t\t\t}\n\t\t\tif (iSpan <= 1 && oColumn && oColumn.getFiltered()) {\n\t\t\t\taLabels.push(oTable.getId() + \"-ariacolfiltered\");\n\t\t\t}\n\n\t\t\tif (Device.browser.msie) {\n\t\t\t\tif (iSpan <= 1 && $Cell.attr(\"aria-haspopup\") === \"true\") {\n\t\t\t\t\taLabels.push(oTable.getId() + \"-ariacolmenu\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tExtensionHelper.performCellModifications(this, $Cell, mAttributes[\"aria-labelledby\"], mAttributes[\"aria-describedby\"],\n\t\t\t\taLabels, mAttributes[\"aria-describedby\"], sText\n\t\t\t);\n\t\t}", "language": "javascript"}
{"input": "Add the series or dataframe only operations to the cls; evaluate\n        the doc strings again.", "output": "def _add_series_or_dataframe_operations(cls):\n        \"\"\"\n        Add the series or dataframe only operations to the cls; evaluate\n        the doc strings again.\n        \"\"\"\n\n        from pandas.core import window as rwindow\n\n        @Appender(rwindow.rolling.__doc__)\n        def rolling(self, window, min_periods=None, center=False,\n                    win_type=None, on=None, axis=0, closed=None):\n            axis = self._get_axis_number(axis)\n            return rwindow.rolling(self, window=window,\n                                   min_periods=min_periods,\n                                   center=center, win_type=win_type,\n                                   on=on, axis=axis, closed=closed)\n\n        cls.rolling = rolling\n\n        @Appender(rwindow.expanding.__doc__)\n        def expanding(self, min_periods=1, center=False, axis=0):\n            axis = self._get_axis_number(axis)\n            return rwindow.expanding(self, min_periods=min_periods,\n                                     center=center, axis=axis)\n\n        cls.expanding = expanding\n\n        @Appender(rwindow.ewm.__doc__)\n        def ewm(self, com=None, span=None, halflife=None, alpha=None,\n                min_periods=0, adjust=True, ignore_na=False,\n                axis=0):\n            axis = self._get_axis_number(axis)\n            return rwindow.ewm(self, com=com, span=span, halflife=halflife,\n                               alpha=alpha, min_periods=min_periods,\n                               adjust=adjust, ignore_na=ignore_na, axis=axis)\n\n        cls.ewm = ewm", "language": "python"}
{"input": "Calls the icon providers to get the collection of icons (most likely just one) for\nthe current file or directory.\n\n@return {Array.<PreactComponent>} icon components to render", "output": "function () {\n            var result,\n                extensions = this.props.extensions;\n\n            if (extensions && extensions.get(\"icons\")) {\n                var data = this.getDataForExtension();\n                result = extensions.get(\"icons\").map(function (callback) {\n                    try {\n                        var result = callback(data);\n                        if (result && !Preact.isValidElement(result)) {\n                            result = Preact.DOM.span({\n                                dangerouslySetInnerHTML: {\n                                    __html: $(result)[0].outerHTML\n                                }\n                            });\n                        }\n                        return result;  // by this point, returns either undefined or a Preact object\n                    } catch (e) {\n                        console.error(\"Exception thrown in FileTreeView icon provider: \" + e, e.stack);\n                    }\n                }).filter(isDefined).toArray();\n            }\n\n            if (!result || result.length === 0) {\n                result = [DOM.ins({\n                    className: \"jstree-icon\"\n                }, \" \")];\n            }\n            return result;\n        }", "language": "javascript"}
{"input": "r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response", "output": "def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault('allow_redirects', False)\n        return self.request('HEAD', url, **kwargs)", "language": "python"}
{"input": "Returns label text to indicate the search scope. Already HTML-escaped.\n@param {?Entry} scope\n@return {string}", "output": "function labelForScope(scope) {\n        if (scope) {\n            return StringUtils.format(\n                Strings.FIND_IN_FILES_SCOPED,\n                StringUtils.breakableUrl(\n                    ProjectManager.makeProjectRelativeIfPossible(scope.fullPath)\n                )\n            );\n        } else {\n            return Strings.FIND_IN_FILES_NO_SCOPE;\n        }\n    }", "language": "javascript"}
{"input": "Function: fit\n\nMakes sure the given node is inside the visible area of the window. This\nis done by setting the left and top in the style.", "output": "function(node)\n\t{\n\t\tvar ds = mxUtils.getDocumentSize();\n\t\tvar left = parseInt(node.offsetLeft);\n\t\tvar width = parseInt(node.offsetWidth);\n\t\t\t\n\t\tvar offset = mxUtils.getDocumentScrollOrigin(node.ownerDocument);\n\t\tvar sl = offset.x;\n\t\tvar st = offset.y;\n\n\t\tvar b = document.body;\n\t\tvar d = document.documentElement;\n\t\tvar right = (sl) + ds.width;\n\t\t\n\t\tif (left + width > right)\n\t\t{\n\t\t\tnode.style.left = Math.max(sl, right - width) + 'px';\n\t\t}\n\t\t\n\t\tvar top = parseInt(node.offsetTop);\n\t\tvar height = parseInt(node.offsetHeight);\n\t\t\n\t\tvar bottom = st + ds.height;\n\t\t\n\t\tif (top + height > bottom)\n\t\t{\n\t\t\tnode.style.top = Math.max(st, bottom - height) + 'px';\n\t\t}\n\t}", "language": "javascript"}
{"input": "Load ndarray file and return as list of numpy array.\n\n    Parameters\n    ----------\n    nd_bytes : str or bytes\n        The internal ndarray bytes\n\n    Returns\n    -------\n    out : dict of str to numpy array or list of numpy array\n        The output list or dict, depending on whether the saved type is list or dict.", "output": "def load_ndarray_file(nd_bytes):\n    \"\"\"Load ndarray file and return as list of numpy array.\n\n    Parameters\n    ----------\n    nd_bytes : str or bytes\n        The internal ndarray bytes\n\n    Returns\n    -------\n    out : dict of str to numpy array or list of numpy array\n        The output list or dict, depending on whether the saved type is list or dict.\n    \"\"\"\n    handle = NDListHandle()\n    olen = mx_uint()\n    nd_bytes = bytearray(nd_bytes)\n    ptr = (ctypes.c_char * len(nd_bytes)).from_buffer(nd_bytes)\n    _check_call(_LIB.MXNDListCreate(\n        ptr, len(nd_bytes),\n        ctypes.byref(handle), ctypes.byref(olen)))\n    keys = []\n    arrs = []\n\n    for i in range(olen.value):\n        key = ctypes.c_char_p()\n        cptr = mx_float_p()\n        pdata = ctypes.POINTER(mx_uint)()\n        ndim = mx_uint()\n        _check_call(_LIB.MXNDListGet(\n            handle, mx_uint(i), ctypes.byref(key),\n            ctypes.byref(cptr), ctypes.byref(pdata), ctypes.byref(ndim)))\n        shape = tuple(pdata[:ndim.value])\n        dbuffer = (mx_float * np.prod(shape)).from_address(ctypes.addressof(cptr.contents))\n        ret = np.frombuffer(dbuffer, dtype=np.float32).reshape(shape)\n        ret = np.array(ret, dtype=np.float32)\n        keys.append(py_str(key.value))\n        arrs.append(ret)\n    _check_call(_LIB.MXNDListFree(handle))\n\n    if len(keys) == 0 or len(keys[0]) == 0:\n        return arrs\n    else:\n        return {keys[i] : arrs[i] for i in range(len(keys))}", "language": "python"}
{"input": "Convert percentage offset on slide to equivalent model value\n@param percent\n@returns {*}", "output": "function percentToValue(percent) {\n      var adjustedPercent = invert ? (1 - percent) : percent;\n      return (min + adjustedPercent * (max - min));\n    }", "language": "javascript"}
{"input": "assign the nodes a depth and index", "output": "function assignDepthsAt(i) {\n    var eles = depths[i];\n\n    for (var j = 0; j < eles.length; j++) {\n      var _ele2 = eles[j];\n\n      if (_ele2 == null) {\n        eles.splice(j, 1);\n        j--;\n        continue;\n      }\n\n      setInfo(_ele2, {\n        depth: i,\n        index: j\n      });\n    }\n  }", "language": "javascript"}
{"input": "Synchronize the size of the map with the size of the container. Suitable in situations where the size of the container is changed programmatically or container is shown after it became visible.", "output": "function(){\n    this.width = this.container.width();\n    this.height = this.container.height();\n    this.resize();\n    this.canvas.setSize(this.width, this.height);\n    this.applyTransform();\n  }", "language": "javascript"}
{"input": "remove table keywords from kwargs and return\n        raise if any keywords are passed which are not-None", "output": "def validate_read(self, kwargs):\n        \"\"\"\n        remove table keywords from kwargs and return\n        raise if any keywords are passed which are not-None\n        \"\"\"\n        kwargs = copy.copy(kwargs)\n\n        columns = kwargs.pop('columns', None)\n        if columns is not None:\n            raise TypeError(\"cannot pass a column specification when reading \"\n                            \"a Fixed format store. this store must be \"\n                            \"selected in its entirety\")\n        where = kwargs.pop('where', None)\n        if where is not None:\n            raise TypeError(\"cannot pass a where specification when reading \"\n                            \"from a Fixed format store. this store must be \"\n                            \"selected in its entirety\")\n        return kwargs", "language": "python"}
{"input": "Logs shell output to the `output`.\n\n    Works like unix script command with `-f` flag.", "output": "def shell_logger(output):\n    \"\"\"Logs shell output to the `output`.\n\n    Works like unix script command with `-f` flag.\n\n    \"\"\"\n    if not os.environ.get('SHELL'):\n        logs.warn(\"Shell logger doesn't support your platform.\")\n        sys.exit(1)\n\n    fd = os.open(output, os.O_CREAT | os.O_TRUNC | os.O_RDWR)\n    os.write(fd, b'\\x00' * const.LOG_SIZE_IN_BYTES)\n    buffer = mmap.mmap(fd, const.LOG_SIZE_IN_BYTES, mmap.MAP_SHARED, mmap.PROT_WRITE)\n    return_code = _spawn(os.environ['SHELL'], partial(_read, buffer))\n\n    sys.exit(return_code)", "language": "python"}
{"input": "The model for the ExtensionManagerView that is responsible for handling previously-installed extensions.\nThis extends ExtensionManagerViewModel.\nMust be disposed with dispose() when done.\n\nEvents:\n- change - triggered when the data for a given extension changes. Second parameter is the extension id.\n- filter - triggered whenever the filtered set changes (including on initialize).\n\n@constructor", "output": "function InstalledViewModel() {\n        ExtensionManagerViewModel.call(this);\n\n        // when registry is downloaded, sort extensions again - those with updates will be before others\n        var self = this;\n        ExtensionManager.on(\"registryDownload.\" + this.source, function () {\n            self._sortFullSet();\n            self._setInitialFilter();\n        });\n    }", "language": "javascript"}
{"input": "Checks if a given string is an url", "output": "def is_valid_url(url):\n    \"\"\"Checks if a given string is an url\"\"\"\n    pieces = urlparse(url)\n    return all([pieces.scheme, pieces.netloc])", "language": "python"}
{"input": "Saves a screenshot of the current element to a PNG image file. Returns\n           False if there is any IOError, else returns True. Use full paths in\n           your filename.\n\n        :Args:\n         - filename: The full path you wish to save your screenshot to. This\n           should end with a `.png` extension.\n\n        :Usage:\n            ::\n\n                element.screenshot('/Screenshots/foo.png')", "output": "def screenshot(self, filename):\n        \"\"\"\n        Saves a screenshot of the current element to a PNG image file. Returns\n           False if there is any IOError, else returns True. Use full paths in\n           your filename.\n\n        :Args:\n         - filename: The full path you wish to save your screenshot to. This\n           should end with a `.png` extension.\n\n        :Usage:\n            ::\n\n                element.screenshot('/Screenshots/foo.png')\n        \"\"\"\n        if not filename.lower().endswith('.png'):\n            warnings.warn(\"name used for saved screenshot does not match file \"\n                          \"type. It should end with a `.png` extension\", UserWarning)\n        png = self.screenshot_as_png\n        try:\n            with open(filename, 'wb') as f:\n                f.write(png)\n        except IOError:\n            return False\n        finally:\n            del png\n        return True", "language": "python"}
{"input": "Create the param or return type.\n@param {!Object} param Parameter.\n@return {string} Escaped param string with links to the types.", "output": "function(param) {\n  var str = param.typeExpression;\n  var type = param.type;\n  if (!type) {\n    return escape(str);\n  }\n\n  var replaceWithLinkIfPresent = function(type) {\n    if (type.name) {\n      str = str.replace(type.name, toMarkdownLinkFormat(type.name));\n    }\n  };\n\n  if (type.type === 'FunctionType') {\n    _.each(type.params, replaceWithLinkIfPresent);\n  } else if (type.type === 'TypeApplication') {\n    // Is this an Array.<type>?\n    var match = str.match(/Array\\.<(.*)>/);\n    if (match) {\n      var typeInsideArray = match[1];\n      str = str.replace(typeInsideArray, toMarkdownLinkFormat(typeInsideArray));\n    }\n  } else if (type.type === 'NameExpression') {\n    replaceWithLinkIfPresent(type);\n  }\n\n  return escape(str);\n}", "language": "javascript"}
{"input": "Wrap the deprecated function to print out deprecation warnings", "output": "def _wrap_deprecated_function(func, message):\n    \"\"\" Wrap the deprecated function to print out deprecation warnings\"\"\"\n    def _(col):\n        warnings.warn(message, DeprecationWarning)\n        return func(col)\n    return functools.wraps(func)(_)", "language": "python"}
{"input": "Read imports and follow them until all files have been handled", "output": "function discoverAndReadFiles(options) {\n    const FILES = {};\n    const in_queue = Object.create(null);\n    const queue = [];\n    const enqueue = (moduleId) => {\n        if (in_queue[moduleId]) {\n            return;\n        }\n        in_queue[moduleId] = true;\n        queue.push(moduleId);\n    };\n    options.entryPoints.forEach((entryPoint) => enqueue(entryPoint));\n    while (queue.length > 0) {\n        const moduleId = queue.shift();\n        const dts_filename = path.join(options.sourcesRoot, moduleId + '.d.ts');\n        if (fs.existsSync(dts_filename)) {\n            const dts_filecontents = fs.readFileSync(dts_filename).toString();\n            FILES[`${moduleId}.d.ts`] = dts_filecontents;\n            continue;\n        }\n        const js_filename = path.join(options.sourcesRoot, moduleId + '.js');\n        if (fs.existsSync(js_filename)) {\n            // This is an import for a .js file, so ignore it...\n            continue;\n        }\n        let ts_filename;\n        if (options.redirects[moduleId]) {\n            ts_filename = path.join(options.sourcesRoot, options.redirects[moduleId] + '.ts');\n        }\n        else {\n            ts_filename = path.join(options.sourcesRoot, moduleId + '.ts');\n        }\n        const ts_filecontents = fs.readFileSync(ts_filename).toString();\n        const info = ts.preProcessFile(ts_filecontents);\n        for (let i = info.importedFiles.length - 1; i >= 0; i--) {\n            const importedFileName = info.importedFiles[i].fileName;\n            if (options.importIgnorePattern.test(importedFileName)) {\n                // Ignore vs/css! imports\n                continue;\n            }\n            let importedModuleId = importedFileName;\n            if (/(^\\.\\/)|(^\\.\\.\\/)/.test(importedModuleId)) {\n                importedModuleId = path.join(path.dirname(moduleId), importedModuleId);\n            }\n            enqueue(importedModuleId);\n        }\n        FILES[`${moduleId}.ts`] = ts_filecontents;\n    }\n    return FILES;\n}", "language": "javascript"}
{"input": "/* 21.2 DrawingML - Charts", "output": "function parse_chart(data/*:?string*/, name/*:string*/, opts, rels, wb, csheet) {\n\tvar cs/*:Worksheet*/ = ((csheet || {\"!type\":\"chart\"})/*:any*/);\n\tif(!data) return csheet;\n\t/* 21.2.2.27 chart CT_Chart */\n\n\tvar C = 0, R = 0, col = \"A\";\n\tvar refguess = {s: {r:2000000, c:2000000}, e: {r:0, c:0} };\n\n\t/* 21.2.2.120 numCache CT_NumData */\n\t(data.match(/<c:numCache>[\\s\\S]*?<\\/c:numCache>/gm)||[]).forEach(function(nc) {\n\t\tvar cache = parse_numCache(nc);\n\t\trefguess.s.r = refguess.s.c = 0;\n\t\trefguess.e.c = C;\n\t\tcol = encode_col(C);\n\t\tcache[0].forEach(function(n,i) {\n\t\t\tcs[col + encode_row(i)] = {t:'n', v:n, z:cache[1] };\n\t\t\tR = i;\n\t\t});\n\t\tif(refguess.e.r < R) refguess.e.r = R;\n\t\t++C;\n\t});\n\tif(C > 0) cs[\"!ref\"] = encode_range(refguess);\n\treturn cs;\n}", "language": "javascript"}
{"input": "Switch the model, if `gen_mode` is provided, in the desired mode.", "output": "def switch(self, gen_mode:bool=None):\n        \"Switch the model, if `gen_mode` is provided, in the desired mode.\"\n        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_critic.opt\n        self._set_trainable()\n        self.model.switch(gen_mode)\n        self.loss_func.switch(gen_mode)", "language": "python"}
{"input": "internal factory method to simplify creating one type of ParseException\n        from another - avoids having __init__ signature conflicts among subclasses", "output": "def _from_exception(cls, pe):\n        \"\"\"\n        internal factory method to simplify creating one type of ParseException\n        from another - avoids having __init__ signature conflicts among subclasses\n        \"\"\"\n        return cls(pe.pstr, pe.loc, pe.msg, pe.parserElement)", "language": "python"}
{"input": "/* =========================================================== /* lifecycle methods /* ===========================================================", "output": "function () {\n\t\t\t\tthis.getRouter().getRoute(\"sample\").attachPatternMatched(this._onSampleMatched, this);\n\n\t\t\t\tthis._viewModel = new JSONModel({\n\t\t\t\t\tshowNavButton : true,\n\t\t\t\t\tshowNewTab: false\n\t\t\t\t});\n\n\t\t\t\tthis._sId = null; // Used to hold sample ID\n\t\t\t\tthis._sEntityId = null; // Used to hold entity ID for the sample currently shown\n\n\t\t\t\t// Load runtime authoring asynchronously\n\t\t\t\tPromise.all([\n\t\t\t\t\tsap.ui.getCore().loadLibrary(\"sap.ui.fl\", {async: true}),\n\t\t\t\t\tsap.ui.getCore().loadLibrary(\"sap.ui.rta\", {async: true})\n\t\t\t\t]).then(this._loadRTA.bind(this));\n\n\t\t\t\tthis.getView().setModel(this._viewModel);\n\t\t\t}", "language": "javascript"}
{"input": "Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).", "output": "def _fetch_img_tuples(url:str, format:str='jpg', n_images:int=10) -> list:\n    \"Parse the Google Images Search for urls and return the image metadata as tuples (fname, url).\"\n    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'}\n    html = requests.get(url, headers=headers).text\n    return _html_to_img_tuples(html, format=format, n_images=n_images)", "language": "python"}
{"input": "Get the gradients of the image.\n\n    Parameters:\n    ----------\n    net: Block\n        Network to use for visualization.\n    image: NDArray\n        Preprocessed image to use for visualization.\n    class_id: int\n        Category ID this image belongs to. If not provided,\n        network's prediction will be used.", "output": "def get_image_grad(net, image, class_id=None):\n    \"\"\"Get the gradients of the image.\n\n    Parameters:\n    ----------\n    net: Block\n        Network to use for visualization.\n    image: NDArray\n        Preprocessed image to use for visualization.\n    class_id: int\n        Category ID this image belongs to. If not provided,\n        network's prediction will be used.\"\"\"\n    return _get_grad(net, image, class_id, image_grad=True)", "language": "python"}
{"input": "Verify that this gitbook version satisfies a requirement\nWe can't directly use samver.satisfies since it will break all plugins when gitbook version is a prerelease (beta, alpha)\n\n@param {String} condition\n@return {Boolean}", "output": "function satisfies(condition) {\n    // Test with real version\n    if (semver.satisfies(VERSION, condition)) return true;\n\n    // Test with future stable release\n    return semver.satisfies(VERSION_STABLE, condition);\n}", "language": "javascript"}
{"input": "Implements XPathEngine.", "output": "function JavascriptXPathEngine() {\n// private\n    var engineDoc = document;\n\n// public\n    // Override\n    this.isAvailable = function() { return true; };\n\n    // Override\n    this.selectNodes = function(xpath, contextNode, namespaceResolver) {\n        if (contextNode != this.doc) {\n            // Regarding use of the second argument to document.evaluate():\n            // http://groups.google.com/group/comp.lang.javascript/browse_thread/thread/a59ce20639c74ba1/a9d9f53e88e5ebb5\n            xpath = '.' + xpath;\n        }\n\n        var nodes = [];\n\n        try {\n            // When using the new and faster javascript-xpath library, we'll\n            // use the TestRunner's document object, not the App-Under-Test's\n            // document. The new library only modifies the TestRunner document\n            // with the new functionality.\n            var xpathResult = engineDoc.evaluate(xpath, contextNode,\n                namespaceResolver, 0, null);\n        }\n        catch (e) {\n            var msg = extractExceptionMessage(e);\n            throw new SeleniumError(\"Invalid xpath [1]: \" + msg);\n        }\n        finally {\n            if (xpathResult == null) {\n                // If the result is null, we should still throw an Error.\n                throw new SeleniumError(\"Invalid xpath [2]: \" + xpath);\n            }\n        }\n\n        var node = xpathResult.iterateNext();\n\n        while (node) {\n            nodes.push(node);\n            node = xpathResult.iterateNext();\n        }\n\n        return nodes;\n    };\n}", "language": "javascript"}
{"input": "Formats the description of annotations\n@param description - the description of the annotation\n@param since - the since version information of the annotation\n@returns string - the formatted description", "output": "function (description, since) {\n\t\t\tvar result = description || \"\";\n\n\t\t\tresult += '<br>For more information, see ' + this.handleExternalUrl(this.ANNOTATIONS_LINK, \"OData v4 Annotations\");\n\n\t\t\tif (since) {\n\t\t\t\tresult += '<br><br><i>Since: ' + since + '.</i>';\n\t\t\t}\n\n\t\t\tresult = this._preProcessLinksInTextBlock(result);\n\t\t\treturn result;\n\t\t}", "language": "javascript"}
{"input": "Return a rolling grouper, providing rolling functionality per group.", "output": "def rolling(self, *args, **kwargs):\n        \"\"\"\n        Return a rolling grouper, providing rolling functionality per group.\n        \"\"\"\n        from pandas.core.window import RollingGroupby\n        return RollingGroupby(self, *args, **kwargs)", "language": "python"}
{"input": "Select the given category\n\n@param {object} aSpec\nInformation for selecting a category\nElements: category - Category element\nwaitFor  - Wait until the category has been selected\n[optional - default: true]", "output": "function addonsManager_setCategory(aSpec) {\n    var spec = aSpec || { };\n    var category = spec.category;\n    var waitFor = (spec.waitFor == undefined) ? true : spec.waitFor;\n\n    if (!category)\n      throw new Error(arguments.callee.name + \": Category not specified.\");\n\n    this._controller.click(category);\n\n    if (waitFor)\n      this.waitForCategory({category: category});\n  }", "language": "javascript"}
{"input": "Print info about spaCy installation. If a model shortcut link is\n    speficied as an argument, print model information. Flag --markdown\n    prints details in Markdown for easy copy-pasting to GitHub issues.", "output": "def info(model=None, markdown=False, silent=False):\n    \"\"\"\n    Print info about spaCy installation. If a model shortcut link is\n    speficied as an argument, print model information. Flag --markdown\n    prints details in Markdown for easy copy-pasting to GitHub issues.\n    \"\"\"\n    msg = Printer()\n    if model:\n        if util.is_package(model):\n            model_path = util.get_package_path(model)\n        else:\n            model_path = util.get_data_path() / model\n        meta_path = model_path / \"meta.json\"\n        if not meta_path.is_file():\n            msg.fail(\"Can't find model meta.json\", meta_path, exits=1)\n        meta = srsly.read_json(meta_path)\n        if model_path.resolve() != model_path:\n            meta[\"link\"] = path2str(model_path)\n            meta[\"source\"] = path2str(model_path.resolve())\n        else:\n            meta[\"source\"] = path2str(model_path)\n        if not silent:\n            title = \"Info about model '{}'\".format(model)\n            model_meta = {\n                k: v for k, v in meta.items() if k not in (\"accuracy\", \"speed\")\n            }\n            if markdown:\n                print_markdown(model_meta, title=title)\n            else:\n                msg.table(model_meta, title=title)\n        return meta\n    data = {\n        \"spaCy version\": about.__version__,\n        \"Location\": path2str(Path(__file__).parent.parent),\n        \"Platform\": platform.platform(),\n        \"Python version\": platform.python_version(),\n        \"Models\": list_models(),\n    }\n    if not silent:\n        title = \"Info about spaCy\"\n        if markdown:\n            print_markdown(data, title=title)\n        else:\n            msg.table(data, title=title)\n    return data", "language": "python"}
{"input": "Invokes a language-specific block-comment/uncomment handler\n@param {?Editor} editor If unspecified, applies to the currently focused editor", "output": "function blockComment(editor) {\n        editor = editor || EditorManager.getFocusedEditor();\n        if (!editor) {\n            return;\n        }\n\n        var edits = [],\n            lineCommentSels = [];\n        _.each(editor.getSelections(), function (sel) {\n            var mode = editor.getModeForRange(sel.start, sel.end),\n                edit = {edit: [], selection: [sel]}; // default edit in case we don't have a mode for this selection\n            if (mode) {\n                var language = editor.document.getLanguage().getLanguageForMode(mode.name || mode);\n\n                if (language.hasBlockCommentSyntax()) {\n                    // getLineCommentPrefixes always return an array, and will be empty if no line comment syntax is defined\n                    edit = _getBlockCommentPrefixSuffixEdit(editor, language.getBlockCommentPrefix(), language.getBlockCommentSuffix(),\n                                                            language.getLineCommentPrefixes(), sel);\n                    if (!edit) {\n                        // This is only null if the block comment code found that the selection is within a line-commented line.\n                        // Add this to the list of line-comment selections we need to handle. Since edit is null, we'll skip\n                        // pushing anything onto the edit list for this selection.\n                        lineCommentSels.push(sel);\n                    }\n                }\n            }\n            if (edit) {\n                edits.push(edit);\n            }\n        });\n\n        // Handle any line-comment edits. It's okay if these are out-of-order with the other edits, since\n        // they shouldn't overlap, and `doMultipleEdits()` will take care of sorting the edits so the\n        // selections can be tracked appropriately.\n        edits.push.apply(edits, _getLineCommentEdits(editor, lineCommentSels, \"block\"));\n\n        editor.setSelections(editor.document.doMultipleEdits(edits));\n    }", "language": "javascript"}
{"input": "------------------------------------------------------------------------------", "output": "function output(string) {\n    var element = document.createElement(\"div\")\n    element.innerHTML = string\n    outputElement.appendChild(element)\n}", "language": "javascript"}
{"input": "Block for \"advanced\" math ops on a number.\n@this Blockly.Block", "output": "function() {\n    this.jsonInit({\n      \"message0\": Blockly.Msg.OPERATORS_MATHOP,\n      \"args0\": [\n        {\n          \"type\": \"field_dropdown\",\n          \"name\": \"OPERATOR\",\n          \"options\": [\n            [Blockly.Msg.OPERATORS_MATHOP_ABS, 'abs'],\n            [Blockly.Msg.OPERATORS_MATHOP_FLOOR, 'floor'],\n            [Blockly.Msg.OPERATORS_MATHOP_CEILING, 'ceiling'],\n            [Blockly.Msg.OPERATORS_MATHOP_SQRT, 'sqrt'],\n            [Blockly.Msg.OPERATORS_MATHOP_SIN, 'sin'],\n            [Blockly.Msg.OPERATORS_MATHOP_COS, 'cos'],\n            [Blockly.Msg.OPERATORS_MATHOP_TAN, 'tan'],\n            [Blockly.Msg.OPERATORS_MATHOP_ASIN, 'asin'],\n            [Blockly.Msg.OPERATORS_MATHOP_ACOS, 'acos'],\n            [Blockly.Msg.OPERATORS_MATHOP_ATAN, 'atan'],\n            [Blockly.Msg.OPERATORS_MATHOP_LN, 'ln'],\n            [Blockly.Msg.OPERATORS_MATHOP_LOG, 'log'],\n            [Blockly.Msg.OPERATORS_MATHOP_EEXP, 'e ^'],\n            [Blockly.Msg.OPERATORS_MATHOP_10EXP, '10 ^']\n          ]\n        },\n        {\n          \"type\": \"input_value\",\n          \"name\": \"NUM\"\n        }\n      ],\n      \"category\": Blockly.Categories.operators,\n      \"extensions\": [\"colours_operators\", \"output_number\"]\n    });\n  }", "language": "javascript"}
{"input": "Gets the file size in bytes.\n@param   {string} fileName The name of the file to get the size\n@returns {Number} the file size in bytes", "output": "function getFilesizeInBytes(fileName) {\n    try {\n        var stats = fs.statSync(fileName);\n        return stats.size || 0;\n    } catch (ex) {\n        console.log(ex);\n        return 0;\n    }\n}", "language": "javascript"}
{"input": "Returns public and private key paths for a given key_name.", "output": "def key_pair_paths(key_name):\n    \"\"\"Returns public and private key paths for a given key_name.\"\"\"\n    public_key_path = os.path.expanduser(\"~/.ssh/{}.pub\".format(key_name))\n    private_key_path = os.path.expanduser(\"~/.ssh/{}.pem\".format(key_name))\n    return public_key_path, private_key_path", "language": "python"}
{"input": "Resumes PAUSED trials. This is a blocking call.", "output": "def resume_trial(self, trial):\n        \"\"\"Resumes PAUSED trials. This is a blocking call.\"\"\"\n\n        assert trial.status == Trial.PAUSED, trial.status\n        self.start_trial(trial)", "language": "python"}
{"input": "Finishes up building the current message and resets parser state", "output": "function finishMessage() {\n    if (parser.tag_ < Parser.PADDING_TAG_) {\n      var message = {};\n      message[parser.tag_] = parser.messageBuffer_;\n      parser.result_.push(message);\n    }\n    parser.state_ = Parser.State_.INIT;\n  }", "language": "javascript"}
{"input": "Update insert/overwrite label\n@param {Event} event (unused)\n@param {Editor} editor Current editor\n@param {string} newstate New overwrite state\n@param {boolean=} doNotAnimate True if state should not be animated", "output": "function _updateOverwriteLabel(event, editor, newstate, doNotAnimate) {\n        if ($statusOverwrite.text() === (newstate ? Strings.STATUSBAR_OVERWRITE : Strings.STATUSBAR_INSERT)) {\n            // label already up-to-date\n            return;\n        }\n\n        $statusOverwrite.text(newstate ? Strings.STATUSBAR_OVERWRITE : Strings.STATUSBAR_INSERT);\n\n        if (!doNotAnimate) {\n            AnimationUtils.animateUsingClass($statusOverwrite[0], \"flash\", 1500);\n        }\n    }", "language": "javascript"}
{"input": "Controller for the nav-bar component.\nAccessibility functionality is implemented as a tablist\n(https://www.w3.org/TR/wai-aria-1.0/complete#tablist) and\ntabs (https://www.w3.org/TR/wai-aria-1.0/complete#tab).\n\n@param {!angular.JQLite} $element\n@param {!angular.Scope} $scope\n@param {!angular.Timeout} $timeout\n@param {!Object} $mdConstant\n@constructor\n@final\n@ngInject", "output": "function MdNavBarController($element, $scope, $timeout, $mdConstant) {\n  // Injected variables\n  /** @private @const {!angular.Timeout} */\n  this._$timeout = $timeout;\n\n  /** @private @const {!angular.Scope} */\n  this._$scope = $scope;\n\n  /** @private @const {!Object} */\n  this._$mdConstant = $mdConstant;\n\n  // Data-bound variables.\n  /** @type {string} */\n  this.mdSelectedNavItem;\n\n  /** @type {string} */\n  this.navBarAriaLabel;\n\n  // State variables.\n\n  /** @type {?angular.JQLite} */\n  this._navBarEl = $element[0];\n\n  /** @type {?angular.JQLite} */\n  this._inkbar;\n\n  var self = this;\n  // need to wait for transcluded content to be available\n  var deregisterTabWatch = this._$scope.$watch(function() {\n    return self._navBarEl.querySelectorAll('._md-nav-button').length;\n  },\n  function(newLength) {\n    if (newLength > 0) {\n      self._initTabs();\n      deregisterTabWatch();\n    }\n  });\n}", "language": "javascript"}
{"input": "Check to see if the node is part of the multi-line variable declaration.\nAlso if its on the same line as the varNode\n@param {ASTNode} node node to check\n@param {ASTNode} varNode variable declaration node to check against\n@returns {boolean} True if all the above condition satisfy", "output": "function isNodeInVarOnTop(node, varNode) {\n            return varNode &&\n                varNode.parent.loc.start.line === node.loc.start.line &&\n                varNode.parent.declarations.length > 1;\n        }", "language": "javascript"}
{"input": "Retrieve recorded computation history as `Symbol`.\n\n    Parameters\n    ----------\n    x : NDArray\n        Array representing the head of computation graph.\n\n    Returns\n    -------\n    Symbol\n        The retrieved Symbol.", "output": "def get_symbol(x):\n    \"\"\"Retrieve recorded computation history as `Symbol`.\n\n    Parameters\n    ----------\n    x : NDArray\n        Array representing the head of computation graph.\n\n    Returns\n    -------\n    Symbol\n        The retrieved Symbol.\n    \"\"\"\n    hdl = SymbolHandle()\n    check_call(_LIB.MXAutogradGetSymbol(x.handle, ctypes.byref(hdl)))\n    return Symbol(hdl)", "language": "python"}
{"input": "return a slice of my values", "output": "def _slice(self, slicer):\n        \"\"\" return a slice of my values \"\"\"\n        if isinstance(slicer, tuple):\n            col, loc = slicer\n            if not com.is_null_slice(col) and col != 0:\n                raise IndexError(\"{0} only contains one item\".format(self))\n            return self.values[loc]\n        return self.values[slicer]", "language": "python"}
{"input": "Retrieve hashes for a specific ``InstallRequirement`` instance.\n\n        :param ireq: An ``InstallRequirement`` to retrieve hashes for\n        :type ireq: :class:`~pip_shims.InstallRequirement`\n        :return: A set of hashes.\n        :rtype: Set", "output": "def get_hash(self, ireq, ireq_hashes=None):\n        \"\"\"\n        Retrieve hashes for a specific ``InstallRequirement`` instance.\n\n        :param ireq: An ``InstallRequirement`` to retrieve hashes for\n        :type ireq: :class:`~pip_shims.InstallRequirement`\n        :return: A set of hashes.\n        :rtype: Set\n        \"\"\"\n\n        # We _ALWAYS MUST PRIORITIZE_ the inclusion of hashes from local sources\n        # PLEASE *DO NOT MODIFY THIS* TO CHECK WHETHER AN IREQ ALREADY HAS A HASH\n        # RESOLVED. The resolver will pull hashes from PyPI and only from PyPI.\n        # The entire purpose of this approach is to include missing hashes.\n        # This fixes a race condition in resolution for missing dependency caches\n        # see pypa/pipenv#3289\n        if not self._should_include_hash(ireq):\n            return set()\n        elif self._should_include_hash(ireq) and (\n            not ireq_hashes or ireq.link.scheme == \"file\"\n        ):\n            if not ireq_hashes:\n                ireq_hashes = set()\n            new_hashes = self.resolver.repository._hash_cache.get_hash(ireq.link)\n            ireq_hashes = add_to_set(ireq_hashes, new_hashes)\n        else:\n            ireq_hashes = set(ireq_hashes)\n        # The _ONLY CASE_ where we flat out set the value is if it isn't present\n        # It's a set, so otherwise we *always* need to do a union update\n        if ireq not in self.hashes:\n            return ireq_hashes\n        else:\n            return self.hashes[ireq] | ireq_hashes", "language": "python"}
{"input": "Adds the owning frame's CSS selector onto each instance of DqElement\n@private\n@param\t{Array} resultSet `nodes` array on a `RuleResult`\n@param\t{HTMLElement} frameElement\tThe frame element\n@param\t{String} frameSelector\t\t Unique CSS selector for the frame", "output": "function pushFrame(resultSet, options, frameElement, frameSelector) {\n\t'use strict';\n\tvar frameXpath = axe.utils.getXpath(frameElement);\n\tvar frameSpec = {\n\t\telement: frameElement,\n\t\tselector: frameSelector,\n\t\txpath: frameXpath\n\t};\n\n\tresultSet.forEach(function(res) {\n\t\tres.node = axe.utils.DqElement.fromFrame(res.node, options, frameSpec);\n\n\t\tvar checks = axe.utils.getAllChecks(res);\n\t\tif (checks.length) {\n\t\t\tchecks.forEach(function(check) {\n\t\t\t\tcheck.relatedNodes = check.relatedNodes.map(node =>\n\t\t\t\t\taxe.utils.DqElement.fromFrame(node, options, frameSpec)\n\t\t\t\t);\n\t\t\t});\n\t\t}\n\t});\n}", "language": "javascript"}
{"input": "Convert the color expression into an object with scope-interpolated values\nThen calculate the rgba() values based on the theme color parts\n@param {Object} themeColors json object, keys are css properties and values are string of\nthe wanted color, for example: `{color: 'red-A200-0.3'}`.\n@return {Object} Hashmap of CSS properties with associated `rgba()` string values", "output": "function interpolateColors(themeColors) {\n      var rgbColors = {};\n\n      var hasColorProperty = themeColors.hasOwnProperty('color');\n\n      angular.forEach(themeColors, function (value, key) {\n        var color = extractColorOptions(value);\n        var hasBackground = key.indexOf('background') > -1;\n\n        rgbColors[key] = parseColor(color);\n        if (hasBackground && !hasColorProperty) {\n          rgbColors.color = parseColor(color, true);\n        }\n      });\n\n      return rgbColors;\n    }", "language": "javascript"}
{"input": "Return a flat int32 tensor of shape [1, batch_size*length, 1].", "output": "def get_batch_coordinate(x, axis=0):\n  \"\"\"Return a flat int32 tensor of shape [1, batch_size*length, 1].\"\"\"\n  # Compute the batch coordinate before flattening all batches\n  batch_coordinate = tf.expand_dims(\n      common_attention.coordinate_tensor(tf.shape(x)[:-1], axis=axis), axis=-1)\n  return batch_coordinate", "language": "python"}
{"input": "Terminates a set of nodes. May be overridden with a batch method.", "output": "def terminate_nodes(self, node_ids):\n        \"\"\"Terminates a set of nodes. May be overridden with a batch method.\"\"\"\n        for node_id in node_ids:\n            logger.info(\"NodeProvider: \"\n                        \"{}: Terminating node\".format(node_id))\n            self.terminate_node(node_id)", "language": "python"}
{"input": "Hide magnifying glass in search bar", "output": "function() {\n\t\tlet search_box = document.getElementById(\"search-input\")\n\t\tsearch_box.onclick = function() {\n\t\t\tdocument.getElementById(\"search-image\").style.display = \"none\";\n\t\t\tsearch_box.style.outline = \"none\";\n\t\t\tsearch_box.placeholder = \"Search\";\n\t\t\tsearch_box.style.paddingLeft = \"2px\";\n\t\t}\n\t}", "language": "javascript"}
{"input": "Constructs a residual version of layers, summing input to layers output.", "output": "def Residual(*layers, **kwargs):\n  \"\"\"Constructs a residual version of layers, summing input to layers output.\"\"\"\n  shortcut = kwargs.get('shortcut', Identity())  # pylint: disable=no-value-for-parameter\n  if len(layers) > 1:\n    return Serial(\n        Branch(),  # pylint: disable=no-value-for-parameter\n        Parallel(Serial(*layers), shortcut),\n        SumBranches()  # pylint: disable=no-value-for-parameter\n    )\n  elif len(layers) == 1:\n    return Serial(\n        Branch(),  # pylint: disable=no-value-for-parameter\n        Parallel(layers[0], shortcut),\n        SumBranches()  # pylint: disable=no-value-for-parameter\n    )\n  else:\n    raise ValueError('Empty residual combinator.')", "language": "python"}
{"input": "Add listeners to track events that might change the search result set", "output": "function _addListeners() {\n        // Avoid adding duplicate listeners - e.g. if a 2nd search is run without closing the old results panel first\n        _removeListeners();\n\n        DocumentModule.on(\"documentChange\", _documentChangeHandler);\n        FileSystem.on(\"change\", _debouncedFileSystemChangeHandler);\n        DocumentManager.on(\"fileNameChange\",  _fileNameChangeHandler);\n    }", "language": "javascript"}
{"input": "Generates Unicode strings, one for each <seg> in a ParaCrawl data file.\n\n  Also decodes some of the most common HTML entities found in ParaCrawl data.\n\n  Args:\n    paracrawl_file: A ParaCrawl V3.0 en-.. data file.\n  Yields:\n    One Unicode string for each <seg> element in the ParaCrawl data file.", "output": "def _raw_sentences(paracrawl_file):\n  \"\"\"Generates Unicode strings, one for each <seg> in a ParaCrawl data file.\n\n  Also decodes some of the most common HTML entities found in ParaCrawl data.\n\n  Args:\n    paracrawl_file: A ParaCrawl V3.0 en-.. data file.\n  Yields:\n    One Unicode string for each <seg> element in the ParaCrawl data file.\n  \"\"\"\n  for line_utf8 in paracrawl_file:\n    line_uni = line_utf8.decode('UTF-8')\n    text_match = re.match(r' +<seg>(.*)</seg>$', line_uni)\n    if text_match:\n      txt = text_match.group(1)\n      txt = re.sub(r'&amp;', r'&', txt)\n      txt = re.sub(r'& ?amp;', r'&', txt)\n      txt = re.sub(r'& ?apos;', r\"'\", txt)\n      txt = re.sub(r'& ?quot;', r'\"', txt)\n      txt = re.sub(r'& ?lt;', r'<', txt)\n      txt = re.sub(r'& ?gt;', r'>', txt)\n      yield txt", "language": "python"}
{"input": "Start server/scheduler.", "output": "def _init_kvstore_server_module():\n    \"\"\"Start server/scheduler.\"\"\"\n    is_worker = ctypes.c_int()\n    check_call(_LIB.MXKVStoreIsWorkerNode(ctypes.byref(is_worker)))\n    if is_worker.value == 0:\n        kvstore = create('dist')\n        server = KVStoreServer(kvstore)\n        server.run()\n        sys.exit()", "language": "python"}
{"input": "Checks whether the request of a response has been a HEAD-request.\n    Handles the quirks of AppEngine.\n\n    :param conn:\n    :type conn: :class:`httplib.HTTPResponse`", "output": "def is_response_to_head(response):\n    \"\"\"\n    Checks whether the request of a response has been a HEAD-request.\n    Handles the quirks of AppEngine.\n\n    :param conn:\n    :type conn: :class:`httplib.HTTPResponse`\n    \"\"\"\n    # FIXME: Can we do this somehow without accessing private httplib _method?\n    method = response._method\n    if isinstance(method, int):  # Platform-specific: Appengine\n        return method == 3\n    return method.upper() == 'HEAD'", "language": "python"}
{"input": "Perform a modified LU decomposition of a matrix.\n\n    This takes a matrix q with orthonormal columns, returns l, u, s such that\n    q - s = l * u.\n\n    Args:\n        q: A two dimensional orthonormal matrix q.\n\n    Returns:\n        A tuple of a lower triangular matrix l, an upper triangular matrix u,\n            and a a vector representing a diagonal matrix s such that\n            q - s = l * u.", "output": "def modified_lu(q):\n    \"\"\"Perform a modified LU decomposition of a matrix.\n\n    This takes a matrix q with orthonormal columns, returns l, u, s such that\n    q - s = l * u.\n\n    Args:\n        q: A two dimensional orthonormal matrix q.\n\n    Returns:\n        A tuple of a lower triangular matrix l, an upper triangular matrix u,\n            and a a vector representing a diagonal matrix s such that\n            q - s = l * u.\n    \"\"\"\n    q = q.assemble()\n    m, b = q.shape[0], q.shape[1]\n    S = np.zeros(b)\n\n    q_work = np.copy(q)\n\n    for i in range(b):\n        S[i] = -1 * np.sign(q_work[i, i])\n        q_work[i, i] -= S[i]\n        # Scale ith column of L by diagonal element.\n        q_work[(i + 1):m, i] /= q_work[i, i]\n        # Perform Schur complement update.\n        q_work[(i + 1):m, (i + 1):b] -= np.outer(q_work[(i + 1):m, i],\n                                                 q_work[i, (i + 1):b])\n\n    L = np.tril(q_work)\n    for i in range(b):\n        L[i, i] = 1\n    U = np.triu(q_work)[:b, :]\n    # TODO(rkn): Get rid of the put below.\n    return ray.get(core.numpy_to_dist.remote(ray.put(L))), U, S", "language": "python"}
{"input": "### Handle Permissions\nWe need to be an authorised user to perform this action\n@param {Object} options\n@returns {Object} options", "output": "function handlePermissions(options) {\n            if (permissions.parseContext(options.context).internal) {\n                return Promise.resolve(options);\n            }\n\n            return canThis(options.context).add.notification().then(() => {\n                return options;\n            }, () => {\n                return Promise.reject(new common.errors.NoPermissionError({\n                    message: common.i18n.t('errors.api.notifications.noPermissionToAddNotif')\n                }));\n            });\n        }", "language": "javascript"}
{"input": "Extract rule configuration into eslint:recommended where possible.\n\nThis will return a new config with `\"extends\": \"eslint:recommended\"` and\nonly the rules which have configurations different from the recommended config.\n\n@param   {Object} config config object\n@returns {Object}        config object using `\"extends\": \"eslint:recommended\"`", "output": "function extendFromRecommended(config) {\n    const newConfig = Object.assign({}, config);\n\n    ConfigOps.normalizeToStrings(newConfig);\n\n    const recRules = Object.keys(recConfig.rules).filter(ruleId => ConfigOps.isErrorSeverity(recConfig.rules[ruleId]));\n\n    recRules.forEach(ruleId => {\n        if (lodash.isEqual(recConfig.rules[ruleId], newConfig.rules[ruleId])) {\n            delete newConfig.rules[ruleId];\n        }\n    });\n    newConfig.extends = RECOMMENDED_CONFIG_NAME;\n    return newConfig;\n}", "language": "javascript"}
{"input": "Resolves to the appropriate git tag to serve as the base for a minor or patch release. The base for minor releases is the latest minor release (*.0). The base for patch releases is the latest patch release.", "output": "async function getBaseTag(mode) {\n  const tags = await simpleGit.tags();\n  // Filter old independent-versioned tags and pre-releases.\n  // If cherry-picking for a minor release, ignore patch releases to work from the latest major or minor release.\n  const filteredTags = tags.all.filter((tag) => /^v/.test(tag) && !/-/.test(tag) &&\n      (mode !== 'minor' || /\\.0$/.test(tag)));\n\n  return filteredTags[filteredTags.length - 1];\n}", "language": "javascript"}
{"input": "Update the internal evaluation with named label and pred\n\n        Parameters\n        ----------\n        labels : OrderedDict of str -> NDArray\n            name to array mapping for labels.\n\n        preds : OrderedDict of str -> NDArray\n            name to array mapping of predicted outputs.", "output": "def update_dict(self, label, pred):\n        \"\"\"Update the internal evaluation with named label and pred\n\n        Parameters\n        ----------\n        labels : OrderedDict of str -> NDArray\n            name to array mapping for labels.\n\n        preds : OrderedDict of str -> NDArray\n            name to array mapping of predicted outputs.\n        \"\"\"\n        if self.output_names is not None:\n            pred = [pred[name] for name in self.output_names]\n        else:\n            pred = list(pred.values())\n\n        if self.label_names is not None:\n            label = [label[name] for name in self.label_names]\n        else:\n            label = list(label.values())\n\n        self.update(label, pred)", "language": "python"}
{"input": "Saves optimizer (updater) state to a file.\n\n        Parameters\n        ----------\n        fname : str\n            Path to output states file.", "output": "def save_optimizer_states(self, fname):\n        \"\"\"Saves optimizer (updater) state to a file.\n\n        Parameters\n        ----------\n        fname : str\n            Path to output states file.\n        \"\"\"\n        assert self.optimizer_initialized\n\n        if self._update_on_kvstore:\n            self._kvstore.save_optimizer_states(fname)\n        else:\n            with open(fname, 'wb') as fout:\n                fout.write(self._updater.get_states())", "language": "python"}
{"input": "By default, `visual` is applied to style (to support visualMap).\n`visual.color` is applied at `fill`. If user want apply visual.color on `stroke`,\nit can be implemented as:\n`api.style({stroke: api.visual('color'), fill: null})`;\n@public\n@param {Object} [extra]\n@param {number} [dataIndexInside=currDataIndexInside]", "output": "function style(extra, dataIndexInside) {\n        dataIndexInside == null && (dataIndexInside = currDataIndexInside);\n        updateCache(dataIndexInside);\n\n        var itemStyle = currItemModel.getModel(ITEM_STYLE_NORMAL_PATH).getItemStyle();\n\n        currVisualColor != null && (itemStyle.fill = currVisualColor);\n        var opacity = data.getItemVisual(dataIndexInside, 'opacity');\n        opacity != null && (itemStyle.opacity = opacity);\n\n        graphicUtil.setTextStyle(itemStyle, currLabelNormalModel, null, {\n            autoColor: currVisualColor,\n            isRectText: true\n        });\n\n        itemStyle.text = currLabelNormalModel.getShallow('show')\n            ? zrUtil.retrieve2(\n                customSeries.getFormattedLabel(dataIndexInside, 'normal'),\n                getDefaultLabel(data, dataIndexInside)\n            )\n            : null;\n\n        extra && zrUtil.extend(itemStyle, extra);\n        return itemStyle;\n    }", "language": "javascript"}
{"input": "Motion path", "output": "function getParentSvgEl(el) {\n  var parentEl = el.parentNode;\n  while (is.svg(parentEl)) {\n    parentEl = parentEl.parentNode;\n    if (!is.svg(parentEl.parentNode)) { break; }\n  }\n  return parentEl;\n}", "language": "javascript"}
{"input": "{'type': 'boolean'}", "output": "def _validate_empty(self, empty, field, value):\n        \"\"\" {'type': 'boolean'} \"\"\"\n        if isinstance(value, Iterable) and len(value) == 0:\n            self._drop_remaining_rules(\n                'allowed', 'forbidden', 'items', 'minlength', 'maxlength',\n                'regex', 'validator')\n            if not empty:\n                self._error(field, errors.EMPTY_NOT_ALLOWED)", "language": "python"}
{"input": "All labels present in the match patterns.\n\n        RETURNS (set): The string labels.\n\n        DOCS: https://spacy.io/api/entityruler#labels", "output": "def labels(self):\n        \"\"\"All labels present in the match patterns.\n\n        RETURNS (set): The string labels.\n\n        DOCS: https://spacy.io/api/entityruler#labels\n        \"\"\"\n        all_labels = set(self.token_patterns.keys())\n        all_labels.update(self.phrase_patterns.keys())\n        return tuple(all_labels)", "language": "python"}
{"input": "/*\nAssumes that the given annotation term applies to all <EntitySet>s using the current\n<EntityType>. The term's value is a record that contains an array-valued property with\nthe given name. Pushes the annotation object to that array.\n@param {string} sTerm The V4 annotation term starting with '@'\n@param {string} sProperty The name of the array-valued property\n@param {object} oAnnotation The V4 annotation object", "output": "function pushPropertyPath(sTerm, sProperty, oAnnotation) {\n\t\t\tvHere = that.getOrCreateObject(that.mEntityType2EntitySetAnnotation, that.sTypeName);\n\t\t\tvHere = that.getOrCreateObject(vHere, sTerm);\n\t\t\tvHere = that.getOrCreateArray(vHere, sProperty);\n\t\t\tvHere.push(oAnnotation);\n\t\t}", "language": "javascript"}
{"input": "Format a URL by replacing all placeholders\n\n@param {string} prefName\nThe preference name which contains the URL\n@return The formatted URL\n@type string", "output": "function formatUrlPref(prefName) {\n  var formatter = Cc[\"@mozilla.org/toolkit/URLFormatterService;1\"]\n                     .getService(Ci.nsIURLFormatter);\n\n  return formatter.formatURLPref(prefName);\n}", "language": "javascript"}
{"input": "@private\n\nIf a default file extension or name was overridden by a pref, restore it.\n\n@param {string} name Extension or filename that should be restored\n@param {{overridden: string, add: string}} prefState object for the pref that is currently being updated", "output": "function _restoreOverriddenDefault(name, state) {\n        if (state.overridden[name]) {\n            var language = getLanguage(state.overridden[name]);\n            language[state.add](name);\n            delete state.overridden[name];\n        }\n    }", "language": "javascript"}
{"input": "decodes all entities into regular string\n@param value\n@returns {string} A string with decoded entities.", "output": "function decodeEntities(value) {\n  if (!value) {\n    return '';\n  }\n\n  hiddenPre.innerHTML = value.replace(/</g, \"&lt;\");\n  // innerText depends on styling as it doesn't display hidden elements.\n  // Therefore, it's better to use textContent not to cause unnecessary reflows.\n  return hiddenPre.textContent;\n}", "language": "javascript"}
{"input": "Decode changes from a JS API to a config object\n\n@param {Config} config\n@param {Object} result: result from API\n@return {Config}", "output": "function decodeGlobal(config, result) {\n    var values = result.values;\n\n    delete values.generator;\n    delete values.output;\n\n    return config.updateValues(values);\n}", "language": "javascript"}
{"input": "Opens a dialog with debug package selection options", "output": "function () {\n\t\t\tvar oModel = this._oDialog.getModel(\"view\"),\n\t\t\t\toTreeResults;\n\n\t\t\t// early out if already open\n\t\t\tif (this._oDebugPopover && this._oDebugPopover.isOpen()) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// fill and bind the tree structure from the currently loaded modules\n\t\t\toTreeResults = this._treeHelper.toTreeModel(this._oModuleSystemInfo);\n\t\t\toModel.setProperty(\"/DebugModules\", [oTreeResults.tree]);\n\t\t\tthis._updateTreeInfos();\n\n\t\t\t// create dialog lazily\n\t\t\tif (!this._oDebugPopover) {\n\t\t\t\tthis._oDebugPopover = sap.ui.xmlfragment(this._DEBUG_MODULES_ID, \"sap.ui.core.support.techinfo.TechnicalInfoDebugDialog\", this);\n\t\t\t\tthis._oDialog.addDependent(this._oDebugPopover);\n\t\t\t\tsyncStyleClass(this._getContentDensityClass(), this._oDialog, this._oDebugPopover);\n\t\t\t\tvar oControl = this._getControl(\"customDebugValue\", this._DEBUG_MODULES_ID);\n\t\t\t\ttry {\n\t\t\t\t\tthis._validateCustomDebugValue(oControl.getValue());\n\t\t\t\t} catch (oException)  {\n\t\t\t\t\tthis._showError(oControl, oException.message);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// adopt tree depth to the deepest currently selected module\n\t\t\tthis._getControl(\"tree\", this._DEBUG_MODULES_ID).expandToLevel(Math.max(this._MIN_EXPAND_LEVEL_DEBUG_MODULES, oTreeResults.depth));\n\n\t\t\t// open dialog\n\t\t\tthis._oDebugPopover.open();\n\t\t}", "language": "javascript"}
{"input": "Validates the template and parameter values and raises exceptions if there's an issue\n\n        :param dict sam_template: SAM template\n        :param dict parameter_values: Dictionary of parameter values provided by the user", "output": "def _validate(self, sam_template, parameter_values):\n        \"\"\" Validates the template and parameter values and raises exceptions if there's an issue\n\n        :param dict sam_template: SAM template\n        :param dict parameter_values: Dictionary of parameter values provided by the user\n        \"\"\"\n        if parameter_values is None:\n            raise ValueError(\"`parameter_values` argument is required\")\n\n        if (\"Resources\" not in sam_template or not isinstance(sam_template[\"Resources\"], dict) or not\n                sam_template[\"Resources\"]):\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\"'Resources' section is required\")])\n\n        if (not all(isinstance(sam_resource, dict) for sam_resource in sam_template[\"Resources\"].values())):\n            raise InvalidDocumentException(\n                [InvalidTemplateException(\n                    \"All 'Resources' must be Objects. If you're using YAML, this may be an \"\n                    \"indentation issue.\"\n                )])\n\n        sam_template_instance = SamTemplate(sam_template)\n\n        for resource_logical_id, sam_resource in sam_template_instance.iterate():\n            # NOTE: Properties isn't required for SimpleTable, so we can't check\n            # `not isinstance(sam_resources.get(\"Properties\"), dict)` as this would be a breaking change.\n            # sam_resource.properties defaults to {} in SamTemplate init\n            if (not isinstance(sam_resource.properties, dict)):\n                raise InvalidDocumentException(\n                    [InvalidResourceException(resource_logical_id,\n                                              \"All 'Resources' must be Objects and have a 'Properties' Object. If \"\n                                              \"you're using YAML, this may be an indentation issue.\"\n                                              )])\n\n        SamTemplateValidator.validate(sam_template)", "language": "python"}
{"input": "On submit.", "output": "function() {\n        // We sign in the user through the normal federated sign-in flow,\n        // and the callback handler will take care of linking the\n        // pending credential to the successfully signed in user.\n        // Pass the email since some OAuth providers support OAuth flow\n        // with a specified email.\n        firebaseui.auth.widget.handler.common.federatedSignIn(app, component,\n            providerId, email);\n      }", "language": "javascript"}
{"input": "Given an ``nltk.Tree`` representing the syntax tree that generates a logical form, this method\n    produces the actual (lisp-like) logical form, with all of the non-terminal symbols converted\n    into the correct number of parentheses.\n\n    This is used in the logic that converts action sequences back into logical forms.  It's very\n    unlikely that you will need this anywhere else.", "output": "def nltk_tree_to_logical_form(tree: Tree) -> str:\n    \"\"\"\n    Given an ``nltk.Tree`` representing the syntax tree that generates a logical form, this method\n    produces the actual (lisp-like) logical form, with all of the non-terminal symbols converted\n    into the correct number of parentheses.\n\n    This is used in the logic that converts action sequences back into logical forms.  It's very\n    unlikely that you will need this anywhere else.\n    \"\"\"\n    # nltk.Tree actually inherits from `list`, so you use `len()` to get the number of children.\n    # We're going to be explicit about checking length, instead of using `if tree:`, just to avoid\n    # any funny business nltk might have done (e.g., it's really odd if `if tree:` evaluates to\n    # `False` if there's a single leaf node with no children).\n    if len(tree) == 0:  # pylint: disable=len-as-condition\n        return tree.label()\n    if len(tree) == 1:\n        return tree[0].label()\n    return '(' + ' '.join(nltk_tree_to_logical_form(child) for child in tree) + ')'", "language": "python"}
{"input": "Set this RDD's storage level to persist its values across operations\n        after the first time it is computed. This can only be used to assign\n        a new storage level if the RDD does not have a storage level set yet.\n        If no storage level is specified defaults to (C{MEMORY_ONLY}).\n\n        >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n        >>> rdd.persist().is_cached\n        True", "output": "def persist(self, storageLevel=StorageLevel.MEMORY_ONLY):\n        \"\"\"\n        Set this RDD's storage level to persist its values across operations\n        after the first time it is computed. This can only be used to assign\n        a new storage level if the RDD does not have a storage level set yet.\n        If no storage level is specified defaults to (C{MEMORY_ONLY}).\n\n        >>> rdd = sc.parallelize([\"b\", \"a\", \"c\"])\n        >>> rdd.persist().is_cached\n        True\n        \"\"\"\n        self.is_cached = True\n        javaStorageLevel = self.ctx._getJavaStorageLevel(storageLevel)\n        self._jrdd.persist(javaStorageLevel)\n        return self", "language": "python"}
{"input": "Executes all available handlers which are defined in the config object\n\n@param {object} oCfg config to handle\n@param {map} mHandlers all available handlers", "output": "function handleConfigObject(oCfg, mHandlers) {\n\n\t\tfunction processConfig(key, value) {\n\t\t\tvar handler = mHandlers[key];\n\t\t\tif ( typeof handler === 'function' ) {\n\t\t\t\tif ( handler.length === 1) {\n\t\t\t\t\thandler(value);\n\t\t\t\t} else if ( value != null ) {\n\t\t\t\t\tforEach(value, handler);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.warning(\"configuration option \" + key + \" not supported (ignored)\");\n\t\t\t}\n\t\t}\n\n\t\t// Make sure the 'baseUrl' handler is called first as\n\t\t// other handlers (e.g. paths) depend on it\n\t\tif (oCfg.baseUrl) {\n\t\t\tprocessConfig(\"baseUrl\", oCfg.baseUrl);\n\t\t}\n\n\t\tforEach(oCfg, function(key, value) {\n\t\t\t// Ignore \"baseUrl\" here as it will be handled above\n\t\t\tif (key !== \"baseUrl\") {\n\t\t\t\tprocessConfig(key, value);\n\t\t\t}\n\t\t});\n\t}", "language": "javascript"}
{"input": "Compute nearest neighbors and loss for training the embeddings.\n\n    Args:\n        x: Batch of encoder continuous latent states sliced/projected into\n        shape\n        [-1, num_blocks, block_dim].\n        means: Embedding means.\n\n    Returns:\n        The nearest neighbor in one hot form, the nearest neighbor\n        itself, the\n        commitment loss, embedding training loss.", "output": "def embedding_lookup(self, x, means):\n    \"\"\"Compute nearest neighbors and loss for training the embeddings.\n\n    Args:\n        x: Batch of encoder continuous latent states sliced/projected into\n        shape\n        [-1, num_blocks, block_dim].\n        means: Embedding means.\n\n    Returns:\n        The nearest neighbor in one hot form, the nearest neighbor\n        itself, the\n        commitment loss, embedding training loss.\n    \"\"\"\n    x_means_hot = self.nearest_neighbor(x, means)\n    x_means_hot_flat = tf.reshape(\n        x_means_hot, [-1, self.hparams.num_blocks, self.hparams.block_v_size])\n    x_means = tf.matmul(tf.transpose(x_means_hot_flat, perm=[1, 0, 2]), means)\n    x_means = tf.transpose(x_means, [1, 0, 2])\n    q_loss = tf.reduce_mean(\n        tf.squared_difference(tf.stop_gradient(x), x_means))\n    e_loss = tf.reduce_mean(\n        tf.squared_difference(x, tf.stop_gradient(x_means)))\n    return x_means_hot, x_means, q_loss, e_loss", "language": "python"}
{"input": "Compiles CSS file and writes it to a file.\n\n@param {CompileOptions} compileOptions\n@param {int[]} startTime\n@return {Promise}", "output": "function buildToFile(compileOptions, startTime) {\n  utils.header()\n  utils.log()\n  utils.log(emoji.go, 'Building...', chalk.bold.cyan(compileOptions.inputFile))\n\n  return compile(compileOptions).then(result => {\n    utils.writeFile(compileOptions.outputFile, result.css)\n\n    const prettyTime = prettyHrtime(process.hrtime(startTime))\n\n    utils.log()\n    utils.log(emoji.yes, 'Finished in', chalk.bold.magenta(prettyTime))\n    utils.log(emoji.pack, 'Size:', chalk.bold.magenta(bytes(result.css.length)))\n    utils.log(emoji.disk, 'Saved to', chalk.bold.cyan(compileOptions.outputFile))\n    utils.footer()\n  })\n}", "language": "javascript"}
{"input": "Corrects request region if bucket's cached region is different\n\n@api private", "output": "function correctBucketRegionFromCache(req) {\n    var bucket = req.params.Bucket || null;\n    if (bucket) {\n      var service = req.service;\n      var requestRegion = req.httpRequest.region;\n      var cachedRegion = service.bucketRegionCache[bucket];\n      if (cachedRegion && cachedRegion !== requestRegion) {\n        service.updateReqBucketRegion(req, cachedRegion);\n      }\n    }\n  }", "language": "javascript"}
{"input": "sync state context.", "output": "def sync_state_context(self, state, context):\n        \"\"\"sync state context.\"\"\"\n        if isinstance(state, NDArray):\n            return state.as_in_context(context)\n        elif isinstance(state, (tuple, list)):\n            synced_state = (self.sync_state_context(i, context) for i in state)\n            if isinstance(state, tuple):\n                return tuple(synced_state)\n            else:\n                return list(synced_state)\n        else:\n            return state", "language": "python"}
{"input": "Save the PyPI access configuration. You must have set ``username`` and\n        ``password`` attributes before calling this method.\n\n        Again, distutils is used to do the actual work.", "output": "def save_configuration(self):\n        \"\"\"\n        Save the PyPI access configuration. You must have set ``username`` and\n        ``password`` attributes before calling this method.\n\n        Again, distutils is used to do the actual work.\n        \"\"\"\n        self.check_credentials()\n        # get distutils to do the work\n        c = self._get_pypirc_command()\n        c._store_pypirc(self.username, self.password)", "language": "python"}
{"input": "/*\nValidates whether the given value is a valid Edm.Decimal value.\n\n@param {string} sValue\nthe constraint minimum or maximum value\n@param {string} sName\nname for logging\n@returns {string}\nthe validated value or undefined", "output": "function validateDecimal(sValue, sName) {\n\t\t\tif (sValue) {\n\t\t\t\tif (sValue.match(rDecimal)) {\n\t\t\t\t\treturn sValue;\n\t\t\t\t}\n\t\t\t\tlogWarning(sValue, sName);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Sets the Accept header to application/json.\n\n@api private", "output": "function setAcceptHeader(req) {\n    var httpRequest = req.httpRequest;\n    if (!httpRequest.headers.Accept) {\n      httpRequest.headers['Accept'] = 'application/json';\n    }\n  }", "language": "javascript"}
{"input": "Only match the outer-most `aria-hidden=true` element\n@param {HTMLElement} el the HTMLElement to verify\n@return {Boolean}", "output": "function shouldMatchElement(el) {\n\tif (!el) {\n\t\treturn true;\n\t}\n\tif (el.getAttribute('aria-hidden') === 'true') {\n\t\treturn false;\n\t}\n\treturn shouldMatchElement(getComposedParent(el));\n}", "language": "javascript"}
{"input": "Determines the set of contributors of the given borrowed members.\nThe contributors are sorted according to the inheritance hierarchy:\nfirst the base class of symbol, then the base class of the base class etc.\nAny contributors that can not be found in the hierarchy are appended\nto the set.\n\n@param {Symbol} symbol of which these are the members\n@param {array} aBorrowedMembers set of borrowed members to determine the contributors for\n@return {array} sorted array of contributors", "output": "function groupByContributors(symbol, aBorrowedMembers) {\n\n\tvar MAX_ORDER = 1000, // a sufficiently large number\n\t\tmContributors = {},\n\t\taSortedContributors = [],\n\t\ti,order;\n\n\taBorrowedMembers.forEach(function($) {\n\t\t$ = lookup($.inherits);\n\t\tif ($ && mContributors[$.memberof] == null) {\n\t\t\tmContributors[$.memberof] = { order : MAX_ORDER, items : [$] };\n\t\t} else {\n\t\t\tmContributors[$.memberof].items.push($);\n\t\t}\n\t});\n\n\t// order contributors according to their distance in the inheritance hierarchy\n\torder = 0;\n\t(function handleAugments(oSymbol) {\n\t\tvar i,oTarget,aParentsToVisit;\n\t\tif ( oSymbol.augments ) {\n\t\t\taParentsToVisit = [];\n\t\t\t// first assign an order\n\t\t\tfor (i = 0; i < oSymbol.augments.length; i++) {\n\t\t\t\tif ( mContributors[oSymbol.augments[i]] != null && mContributors[oSymbol.augments[i]].order === MAX_ORDER ) {\n\t\t\t\t\tmContributors[oSymbol.augments[i]].order = ++order;\n\t\t\t\t\taParentsToVisit.push(oSymbol.augments[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t\t// only then dive into parents (breadth first search)\n\t\t\tfor (i = 0; i < aParentsToVisit.length; i++) {\n\t\t\t\toTarget = lookup(aParentsToVisit);\n\t\t\t\tif ( oTarget ) {\n\t\t\t\t\thandleAugments(oTarget);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}(symbol));\n\n\t// convert to an array and sort by order\n\tfor (i in mContributors) {\n\t\taSortedContributors.push(mContributors[i]);\n\t}\n\taSortedContributors.sort(function (a,b) { return a.order - b.order; });\n\n\treturn aSortedContributors;\n\n}", "language": "javascript"}
{"input": "Return the missing value for `values`\n\n    Parameters\n    ----------\n    values : ndarray\n    axis : int or None\n        axis for the reduction\n\n    Returns\n    -------\n    result : scalar or ndarray\n        For 1-D values, returns a scalar of the correct missing type.\n        For 2-D values, returns a 1-D array where each element is missing.", "output": "def _na_for_min_count(values, axis):\n    \"\"\"Return the missing value for `values`\n\n    Parameters\n    ----------\n    values : ndarray\n    axis : int or None\n        axis for the reduction\n\n    Returns\n    -------\n    result : scalar or ndarray\n        For 1-D values, returns a scalar of the correct missing type.\n        For 2-D values, returns a 1-D array where each element is missing.\n    \"\"\"\n    # we either return np.nan or pd.NaT\n    if is_numeric_dtype(values):\n        values = values.astype('float64')\n    fill_value = na_value_for_dtype(values.dtype)\n\n    if values.ndim == 1:\n        return fill_value\n    else:\n        result_shape = (values.shape[:axis] +\n                        values.shape[axis + 1:])\n        result = np.empty(result_shape, dtype=values.dtype)\n        result.fill(fill_value)\n        return result", "language": "python"}
{"input": "Sets up any watchers used by autocomplete", "output": "function configureWatchers () {\n    var wait = parseInt($scope.delay, 10) || 0;\n\n    $attrs.$observe('disabled', function (value) { ctrl.isDisabled = $mdUtil.parseAttributeBoolean(value, false); });\n    $attrs.$observe('required', function (value) { ctrl.isRequired = $mdUtil.parseAttributeBoolean(value, false); });\n    $attrs.$observe('readonly', function (value) { ctrl.isReadonly = $mdUtil.parseAttributeBoolean(value, false); });\n\n    $scope.$watch('searchText', wait ? $mdUtil.debounce(handleSearchText, wait) : handleSearchText);\n    $scope.$watch('selectedItem', selectedItemChange);\n\n    angular.element($window).on('resize', debouncedOnResize);\n\n    $scope.$on('$destroy', cleanup);\n  }", "language": "javascript"}
{"input": "Retrieve the `Config` in `fpath`.", "output": "def get(cls, fpath=None, create_missing=True):\n        \"Retrieve the `Config` in `fpath`.\"\n        fpath = _expand_path(fpath or cls.DEFAULT_CONFIG_PATH)\n        if not fpath.exists() and create_missing: cls.create(fpath)\n        assert fpath.exists(), f'Could not find config at: {fpath}. Please create'\n        with open(fpath, 'r') as yaml_file: return yaml.safe_load(yaml_file)", "language": "python"}
{"input": "Find variables in the current scope.\n@param {ASTNode} node The node of the current scope.\n@returns {void}\n@private", "output": "function checkForBlock(node) {\n            const scope = context.getScope();\n\n            /*\n             * In ES5, some node type such as `BlockStatement` doesn't have that scope.\n             * `scope.block` is a different node in such a case.\n             */\n            if (scope.block === node) {\n                findVariablesInScope(scope);\n            }\n        }", "language": "javascript"}
{"input": "calculate grid layer cell size in lat lon based on world unit size\nand current latitude\n@param {number} cellSize\n@param {number} latitude\n@returns {object} - lat delta and lon delta", "output": "function calculateGridLatLonOffset(cellSize, latitude) {\n  const yOffset = calculateLatOffset(cellSize);\n  const xOffset = calculateLonOffset(latitude, cellSize);\n  return {yOffset, xOffset};\n}", "language": "javascript"}
{"input": "Returns true if the provided token was previously marked as removed.", "output": "function isRemovedToken(context, token) {\n  var removedNodes = context.removedNodes;\n  var nodeIdx = removedNodes.length - 1;\n\n  // Find the last removed node which could possibly contain this token.\n  while (nodeIdx >= 0 && startOf(removedNodes[nodeIdx]) > startOf(token)) {\n    nodeIdx--;\n  }\n\n  var node = removedNodes[nodeIdx];\n\n  // This token couldn't be removed if not contained within the removed node.\n  if (nodeIdx === -1 || endOf(node) < endOf(token)) {\n    return false;\n  }\n\n  // Iterate through the tokens contained by the removed node to find a match.\n  var tokens = context.ast.tokens;\n  var tokenIdx = findTokenIndex(tokens, startOf(node));\n  while (endOf(tokens[tokenIdx]) <= endOf(node)) {\n    if (token === tokens[tokenIdx]) {\n      return true;\n    }\n    tokenIdx++;\n  }\n\n  return false;\n}", "language": "javascript"}
{"input": "Returns True if `find` is a subtree of `expr`.", "output": "def is_in_expr(expr, find):\n  \"\"\"Returns True if `find` is a subtree of `expr`.\"\"\"\n  return expr == find or (isinstance(expr, ExprNode) and expr.is_in(find))", "language": "python"}
{"input": "Adds an item to the queue.\n\n        Uses polling if block=True, so there is no guarantee of order if\n        multiple producers put to the same full queue.\n\n        Raises:\n            Full if the queue is full and blocking is False.", "output": "def put(self, item, block=True, timeout=None):\n        \"\"\"Adds an item to the queue.\n\n        Uses polling if block=True, so there is no guarantee of order if\n        multiple producers put to the same full queue.\n\n        Raises:\n            Full if the queue is full and blocking is False.\n        \"\"\"\n        if self.maxsize <= 0:\n            self.actor.put.remote(item)\n        elif not block:\n            if not ray.get(self.actor.put.remote(item)):\n                raise Full\n        elif timeout is None:\n            # Polling\n            # Use a not_full condition variable or promise?\n            while not ray.get(self.actor.put.remote(item)):\n                # Consider adding time.sleep here\n                pass\n        elif timeout < 0:\n            raise ValueError(\"'timeout' must be a non-negative number\")\n        else:\n            endtime = time.time() + timeout\n            # Polling\n            # Use a condition variable or switch to promise?\n            success = False\n            while not success and time.time() < endtime:\n                success = ray.get(self.actor.put.remote(item))\n            if not success:\n                raise Full", "language": "python"}
{"input": "Kill the browser.\n\n        This is useful when the browser is stuck.", "output": "def kill(self):\n        \"\"\"Kill the browser.\n\n        This is useful when the browser is stuck.\n        \"\"\"\n        if self.process:\n            self.process.kill()\n            self.process.wait()", "language": "python"}
{"input": "Ask For Clusters Mode", "output": "function askForClustersMode() {\n    if (this.regenerate) return;\n\n    const clusteredDbApps = [];\n    this.appConfigs.forEach((appConfig, index) => {\n        if (appConfig.prodDatabaseType === 'mongodb' || appConfig.prodDatabaseType === 'couchbase') {\n            clusteredDbApps.push(this.appsFolders[index]);\n        }\n    });\n    if (clusteredDbApps.length === 0) return;\n\n    const done = this.async();\n\n    const prompts = [\n        {\n            type: 'checkbox',\n            name: 'clusteredDbApps',\n            message: 'Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)?',\n            choices: clusteredDbApps,\n            default: this.clusteredDbApps\n        }\n    ];\n\n    this.prompt(prompts).then(props => {\n        this.clusteredDbApps = props.clusteredDbApps;\n        setClusteredApps.call(this);\n\n        done();\n    });\n}", "language": "javascript"}
{"input": "Extract name, version, python version from a filename (no extension)\n\n    Return name, version, pyver or None", "output": "def split_filename(filename, project_name=None):\n    \"\"\"\n    Extract name, version, python version from a filename (no extension)\n\n    Return name, version, pyver or None\n    \"\"\"\n    result = None\n    pyver = None\n    filename = unquote(filename).replace(' ', '-')\n    m = PYTHON_VERSION.search(filename)\n    if m:\n        pyver = m.group(1)\n        filename = filename[:m.start()]\n    if project_name and len(filename) > len(project_name) + 1:\n        m = re.match(re.escape(project_name) + r'\\b', filename)\n        if m:\n            n = m.end()\n            result = filename[:n], filename[n + 1:], pyver\n    if result is None:\n        m = PROJECT_NAME_AND_VERSION.match(filename)\n        if m:\n            result = m.group(1), m.group(3), pyver\n    return result", "language": "python"}
{"input": "Generates matrix of relative positions between inputs.", "output": "def _generate_relative_positions_matrix(length_q, length_k,\n                                        max_relative_position,\n                                        cache=False):\n  \"\"\"Generates matrix of relative positions between inputs.\"\"\"\n  if not cache:\n    if length_q == length_k:\n      range_vec_q = range_vec_k = tf.range(length_q)\n    else:\n      range_vec_k = tf.range(length_k)\n      range_vec_q = range_vec_k[-length_q:]\n    distance_mat = range_vec_k[None, :] - range_vec_q[:, None]\n  else:\n    distance_mat = tf.expand_dims(tf.range(-length_k+1, 1, 1), 0)\n  distance_mat_clipped = tf.clip_by_value(distance_mat, -max_relative_position,\n                                          max_relative_position)\n  # Shift values to be >= 0. Each integer still uniquely identifies a relative\n  # position difference.\n  final_mat = distance_mat_clipped + max_relative_position\n  return final_mat", "language": "python"}
{"input": "Plugin Definition =================", "output": "function Plugin(option) {\n    return this.each(function () {\n      var $this = $(this);\n      var data  = $this.data(DataKey);\n\n      if (!data) {\n        var options = $.extend({}, Default, $this.data(), typeof option == 'object' && option);\n        $this.data(DataKey, (data = new BoxRefresh($this, options)));\n      }\n\n      if (typeof data == 'string') {\n        if (typeof data[option] == 'undefined') {\n          throw new Error('No method named ' + option);\n        }\n        data[option]();\n      }\n    });\n  }", "language": "javascript"}
{"input": "Init node children by order and update visual\n\n@param {TreeNode} node  root node\n@param {boolean}  isAsc if is in ascendant order", "output": "function initChildren(node, isAsc) {\n    var children = node.children || [];\n\n    node.children = sort(children, isAsc);\n\n    // Init children recursively\n    if (children.length) {\n        zrUtil.each(node.children, function (child) {\n            initChildren(child, isAsc);\n        });\n    }\n}", "language": "javascript"}
{"input": "Specialization of expect()", "output": "function expectChar(arg, msg) {\n        if (input.charAt(i) === arg) {\n            skipWhitespace(1);\n            return arg;\n        }\n        error(msg || \"expected '\" + arg + \"' got '\" + input.charAt(i) + \"'\");\n    }", "language": "javascript"}
{"input": "Do the powershell completion\n\n    Parameters\n    ----------\n    cli : click.Command\n        The main click Command of the program\n    prog_name : str\n        The program name on the command line\n\n    Returns\n    -------\n    bool\n        True if the completion was successful, False otherwise", "output": "def do_powershell_complete(cli, prog_name):\n    \"\"\"Do the powershell completion\n\n    Parameters\n    ----------\n    cli : click.Command\n        The main click Command of the program\n    prog_name : str\n        The program name on the command line\n\n    Returns\n    -------\n    bool\n        True if the completion was successful, False otherwise\n    \"\"\"\n    commandline = os.environ['COMMANDLINE']\n    args = split_args(commandline)[1:]\n    quote = single_quote\n    incomplete = ''\n    if args and not commandline.endswith(' '):\n        incomplete = args[-1]\n        args = args[:-1]\n        quote_pos = commandline.rfind(incomplete) - 1\n        if quote_pos >= 0 and commandline[quote_pos] == '\"':\n            quote = double_quote\n\n    for item, help in get_choices(cli, prog_name, args, incomplete):\n        echo(quote(item))\n\n    return True", "language": "python"}
{"input": "Set label of Dataset.\n\n        Parameters\n        ----------\n        label : list, numpy 1-D array, pandas Series / one-column DataFrame or None\n            The label information to be set into Dataset.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with set label.", "output": "def set_label(self, label):\n        \"\"\"Set label of Dataset.\n\n        Parameters\n        ----------\n        label : list, numpy 1-D array, pandas Series / one-column DataFrame or None\n            The label information to be set into Dataset.\n\n        Returns\n        -------\n        self : Dataset\n            Dataset with set label.\n        \"\"\"\n        self.label = label\n        if self.handle is not None:\n            label = list_to_1d_numpy(_label_from_pandas(label), name='label')\n            self.set_field('label', label)\n        return self", "language": "python"}
{"input": "Handle active editor change event\n@param {Event} event (unused)\n@param {Editor} current Current editor\n@param {Editor} previous Previous editor", "output": "function _onActiveEditorChange(event, current, previous) {\n        if (previous) {\n            previous.off(\".statusbar\");\n            previous.document.off(\".statusbar\");\n            previous.document.releaseRef();\n        }\n\n        if (!current) {\n            StatusBar.hideAllPanes();\n        } else {\n            var fullPath = current.document.file.fullPath;\n            StatusBar.showAllPanes();\n\n            current.on(\"cursorActivity.statusbar\", _updateCursorInfo);\n            current.on(\"optionChange.statusbar\", function () {\n                _updateIndentType(fullPath);\n                _updateIndentSize(fullPath);\n            });\n            current.on(\"change.statusbar\", function () {\n                // async update to keep typing speed smooth\n                window.setTimeout(function () { _updateFileInfo(current); }, 0);\n            });\n            current.on(\"overwriteToggle.statusbar\", _updateOverwriteLabel);\n\n            current.document.addRef();\n            current.document.on(\"languageChanged.statusbar\", function () {\n                _updateLanguageInfo(current);\n            });\n\n            _updateCursorInfo(null, current);\n            _updateLanguageInfo(current);\n            _updateEncodingInfo(current);\n            _updateFileInfo(current);\n            _initOverwriteMode(current);\n            _updateIndentType(fullPath);\n            _updateIndentSize(fullPath);\n        }\n    }", "language": "javascript"}
{"input": "Checks if any update triggers have changed also calls callback to invalidate attributes accordingly.", "output": "function diffUpdateTriggers(props, oldProps) {\n  if (oldProps === null) {\n    return 'oldProps is null, initial diff';\n  }\n\n  // If the 'all' updateTrigger fires, ignore testing others\n  if ('all' in props.updateTriggers) {\n    const diffReason = diffUpdateTrigger(props, oldProps, 'all');\n    if (diffReason) {\n      return {all: true};\n    }\n  }\n\n  const triggerChanged = {};\n  let reason = false;\n  // If the 'all' updateTrigger didn't fire, need to check all others\n  for (const triggerName in props.updateTriggers) {\n    if (triggerName !== 'all') {\n      const diffReason = diffUpdateTrigger(props, oldProps, triggerName);\n      if (diffReason) {\n        triggerChanged[triggerName] = true;\n        reason = triggerChanged;\n      }\n    }\n  }\n\n  return reason;\n}", "language": "javascript"}
{"input": "This method should return one epoch worth of batches.", "output": "def _create_batches(self, instances: Iterable[Instance], shuffle: bool) -> Iterable[Batch]:\n        \"\"\"\n        This method should return one epoch worth of batches.\n        \"\"\"\n        raise NotImplementedError", "language": "python"}
{"input": "/*\nWrite the table header.\n\n`browserPlatformType` is either \"mobile\", \"desktop\" or \"webextensions\"", "output": "function writeTableHead(browserPlatformType) {\n  let browserNameKeys = Object.keys(browsers[browserPlatformType]);\n  let output = '';\n  if (browserPlatformType === 'webextensions') {\n    output = '<table class=\"webext-summary-compat-table\"><thead><tr><th style=\"width: 40%\"></th>'\n    let browserColumnWidth = 60/browserNameKeys.length;\n    for (let browserNameKey of browserNameKeys) {\n      output += `<th style=\"width:${browserColumnWidth}%\">${browsers[browserPlatformType][browserNameKey]}</th>`;\n    }\n    output += \"<tr></thead>\";\n  } else {\n    output = `<div id=\"compat-${browserPlatformType}\"><table class=\"compat-table\"><thead><tr>`;\n    output +=  '<th>Feature</th>';\n    for (let browserNameKey of browserNameKeys) {\n      output += `<th>${browsers[browserPlatformType][browserNameKey]}</th>`;\n    }\n    output += '</tr></thead>';\n  }\n  return output;\n}", "language": "javascript"}
{"input": "construct a JavaScript expression which leads to my frame (i.e., the frame containing the window in which this code is operating)", "output": "function makeAddressToAUTFrame(w, frameNavigationalJSexpression)\n{\n    if (w == null)\n    {\n        w = top;\n        frameNavigationalJSexpression = \"top\";\n    }\n\n    if (w == selenium.browserbot.getCurrentWindow())\n    {\n        return frameNavigationalJSexpression;\n    }\n    for (var j = 0; j < w.frames.length; j++)\n    {\n        var t = makeAddressToAUTFrame(w.frames[j], frameNavigationalJSexpression + \".frames[\" + j + \"]\");\n        if (t != null)\n        {\n            return t;\n        }\n    }\n    return null;\n}", "language": "javascript"}
{"input": "To get brew default commands on local environment", "output": "def _get_brew_commands(brew_path_prefix):\n    \"\"\"To get brew default commands on local environment\"\"\"\n    brew_cmd_path = brew_path_prefix + BREW_CMD_PATH\n\n    return [name[:-3] for name in os.listdir(brew_cmd_path)\n            if name.endswith(('.rb', '.sh'))]", "language": "python"}
{"input": "Render a UI5 Filter as OData condition.\n\n@param {string} oUI5Filter The filter object to render (must not be a multi filter)\n@returns {string} The $filter value for the given UI5 filter\n@private", "output": "function(oUI5Filter) {\n\t\t\tvar sFilterExpression = null,\n\t\t\t\toProperty = this._oEntityType.findPropertyByName(oUI5Filter.sPath);\n\n\t\t\tif (oProperty == null) {\n\t\t\t\tthrow \"Cannot add filter condition for unknown property name \" + oUI5Filter.sPath; // TODO\n\t\t\t}\n\n\t\t\tswitch (oUI5Filter.sOperator) {\n\t\t\tcase FilterOperator.BT:\n\t\t\t\tsFilterExpression = \"(\" + oUI5Filter.sPath + \" ge \"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue1, oProperty.type)\n\t\t\t\t\t+ \" and \" + oUI5Filter.sPath + \" le \"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue2, oProperty.type)\n\t\t\t\t\t+ \")\";\n\t\t\t\tbreak;\n\t\t\tcase FilterOperator.NB:\n\t\t\t\tsFilterExpression = \"(\" + oUI5Filter.sPath + \" lt \"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue1, oProperty.type)\n\t\t\t\t\t+ \" or \" + oUI5Filter.sPath + \" gt \"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue2, oProperty.type)\n\t\t\t\t\t+ \")\";\n\t\t\t\tbreak;\n\t\t\tcase FilterOperator.Contains:\n\t\t\tcase FilterOperator.NotContains:\n\t\t\t\tsFilterExpression = (oUI5Filter.sOperator[0] === \"N\" ? \"not \" : \"\") + \"substringof(\"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue1, \"Edm.String\")\n\t\t\t\t\t+ \",\" +  oUI5Filter.sPath + \")\";\n\t\t\t\tbreak;\n\t\t\tcase FilterOperator.StartsWith:\n\t\t\tcase FilterOperator.EndsWith:\n\t\t\tcase FilterOperator.NotStartsWith:\n\t\t\tcase FilterOperator.NotEndsWith:\n\t\t\t\tsFilterExpression = oUI5Filter.sOperator.toLowerCase().replace(\"not\", \"not \") + \"(\"\n\t\t\t\t\t+ oUI5Filter.sPath + \",\"\n\t\t\t\t\t+ this._renderPropertyFilterValue(oUI5Filter.oValue1, \"Edm.String\") + \")\";\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tsFilterExpression = oUI5Filter.sPath + \" \" + oUI5Filter.sOperator.toLowerCase()\n\t\t\t\t\t+ \" \" + this._renderPropertyFilterValue(oUI5Filter.oValue1, oProperty.type);\n\t\t\t}\n\n\t\t\treturn sFilterExpression;\n\t\t}", "language": "javascript"}
{"input": "Special case handling to make the common case of downloading from GitHub easier; modifies 'urlInfo' as\nneeded. Converts a bare GitHub repo URL to the corresponding master ZIP URL; or if given a direct\nmaster ZIP URL already, sets a nicer download filename (both cases use the repo name).\n\n@param {{url:string, parsed:Array.<string>, filenameHint:string}} urlInfo", "output": "function githubURLFilter(urlInfo) {\n        if (urlInfo.parsed.hostname === \"github.com\" || urlInfo.parsed.hostname === \"www.github.com\") {\n            // Is it a URL to the root of a repo? (/user/repo)\n            var match = /^\\/[^\\/?]+\\/([^\\/?]+)(\\/?)$/.exec(urlInfo.parsed.pathname);\n            if (match) {\n                if (!match[2]) {\n                    urlInfo.url += \"/\";\n                }\n                urlInfo.url += \"archive/master.zip\";\n                urlInfo.filenameHint = match[1] + \".zip\";\n\n            } else {\n                // Is it a URL directly to the repo's 'master.zip'? (/user/repo/archive/master.zip)\n                match = /^\\/[^\\/?]+\\/([^\\/?]+)\\/archive\\/master.zip$/.exec(urlInfo.parsed.pathname);\n                if (match) {\n                    urlInfo.filenameHint = match[1] + \".zip\";\n                }\n            }\n        }\n    }", "language": "javascript"}
{"input": "Run command.", "output": "def run(self):\n        \"\"\"Run command.\"\"\"\n        wanted_groups = self.parse()\n\n        deps = []\n        invalid_groups = []\n        for grp in wanted_groups:\n            if grp in dep_groups: deps.extend(dep_groups[grp])\n            else:                 invalid_groups.append(grp)\n\n        if invalid_groups or not wanted_groups:\n            print(\"Available dependency groups:\", \", \".join(sorted(dep_groups.keys())))\n            if invalid_groups:\n                print(f\"Error: Invalid group name(s): {', '.join(invalid_groups)}\")\n                exit(1)\n        else:\n            # prepare for shell word splitting (no whitespace in items)\n            deps = [re.sub(\" \", \"\", x, 0) for x in sorted(set(deps))]\n            if self.dep_conda:\n                for i in range(len(deps)):\n                    # strip pip-specific syntax\n                    deps[i] = re.sub(r';.*',     '',         deps[i])\n                    # rename mismatching package names\n                    deps[i] = re.sub(r'^torch>', 'pytorch>', deps[i])\n            if self.dep_quote:\n                # for manual copy-n-paste (assuming no \" in vars)\n                print(\" \".join(map(lambda x: f'\"{x}\"', deps)))\n            else:\n                # if fed directly to `pip install` via backticks/$() don't quote\n                print(\" \".join(deps))", "language": "python"}
{"input": "Remove an guest-embedder relationship.", "output": "function (embedder, guestInstanceId) {\n  const guestInstance = guestInstances[guestInstanceId]\n  if (embedder !== guestInstance.embedder) {\n    return\n  }\n\n  webViewManager.removeGuest(embedder, guestInstanceId)\n  delete guestInstances[guestInstanceId]\n\n  const key = `${embedder.id}-${guestInstance.elementInstanceId}`\n  delete embedderElementsMap[key]\n}", "language": "javascript"}
{"input": "Writes model histograms to Tensorboard.", "output": "def write(self, model:nn.Module, iteration:int, tbwriter:SummaryWriter, name:str='model')->None:\n        \"Writes model histograms to Tensorboard.\"\n        request = HistogramTBRequest(model=model, iteration=iteration, tbwriter=tbwriter, name=name)\n        asyncTBWriter.request_write(request)", "language": "python"}
{"input": "/* =============================================================================================================\nTimegrid\n=============================================================================================================", "output": "function _createTimelineGrid(filterOptions) {\n\t\t\tvar gridParent = document.getElementById('sapUiSupportPerfHeaderTimelineBarWrapper');\n\t\t\tvar gridLineNumbers = Math.round(gridParent.offsetWidth / 10);\n\t\t\tvar filteredDuration = filterOptions.filterByTime.end - filterOptions.filterByTime.start;\n\t\t\tvar gridLineStepInTime = parseInt(filteredDuration / gridLineNumbers);\n\n\t\t\tif (document.getElementById('grid')) {\n\t\t\t\tdocument.getElementById('grid').parentNode.removeChild(document.getElementById('grid'));\n\t\t\t}\n\n\t\t\tvar grid = document.createElement('div');\n\t\t\tgrid.innerHTML = '<div class=\"header\"></div><div class=\"body\"></div>';\n\t\t\tgrid.id = 'grid';\n\n\t\t\tfor (var i = 1; i <= gridLineNumbers; i++) {\n\t\t\t\tvar divForBorder = document.createElement('div');\n\t\t\t\tvar divForText = document.createElement('div');\n\n\t\t\t\tif (i % 5 === 0 || i === 1) {\n\t\t\t\t\tvar time = parseInt(filterOptions.filterByTime.start);\n\n\t\t\t\t\tif (i !== 1) {\n\t\t\t\t\t\ttime += i * gridLineStepInTime;\n\t\t\t\t\t}\n\t\t\t\t\t//to String\n\t\t\t\t\ttime = time > 500 ? (time / 1000).toFixed(2) + ' s' : time + ' ms';\n\n\t\t\t\t\tdivForText.setAttribute('data-time', time);\n\t\t\t\t}\n\n\t\t\t\tgrid.querySelector('.body').appendChild(divForBorder);\n\t\t\t\tgrid.querySelector('.header').appendChild(divForText);\n\t\t\t}\n\n\t\t\tdocument.querySelector('#sapUiSupportPerf').appendChild(grid);\n\t\t}", "language": "javascript"}
{"input": "Private component, representing a list of years in the calendar.", "output": "function calendarDirective() {\n    return {\n      template:\n        '<div class=\"md-calendar-scroll-mask\">' +\n          '<md-virtual-repeat-container class=\"md-calendar-scroll-container\">' +\n            '<table role=\"grid\" tabindex=\"0\" class=\"md-calendar\" aria-readonly=\"true\">' +\n              '<tbody ' +\n                  'md-calendar-year-body ' +\n                  'role=\"rowgroup\" ' +\n                  'md-virtual-repeat=\"i in yearCtrl.items\" ' +\n                  'md-year-offset=\"$index\" class=\"md-calendar-year\" ' +\n                  'md-start-index=\"yearCtrl.getFocusedYearIndex()\" ' +\n                  'md-item-size=\"' + TBODY_HEIGHT + '\">' +\n                // The <tr> ensures that the <tbody> will have the proper\n                // height, even though it may be empty.\n                '<tr aria-hidden=\"true\" md-force-height=\"\\'' + TBODY_HEIGHT + 'px\\'\"></tr>' +\n              '</tbody>' +\n            '</table>' +\n          '</md-virtual-repeat-container>' +\n        '</div>',\n      require: ['^^mdCalendar', 'mdCalendarYear'],\n      controller: CalendarYearCtrl,\n      controllerAs: 'yearCtrl',\n      bindToController: true,\n      link: function(scope, element, attrs, controllers) {\n        var calendarCtrl = controllers[0];\n        var yearCtrl = controllers[1];\n        yearCtrl.initialize(calendarCtrl);\n      }\n    };\n  }", "language": "javascript"}
{"input": "Raise exception with existing traceback.\n    If traceback is not passed, uses sys.exc_info() to get traceback.", "output": "def raise_with_traceback(exc, traceback=Ellipsis):\n    \"\"\"\n    Raise exception with existing traceback.\n    If traceback is not passed, uses sys.exc_info() to get traceback.\n    \"\"\"\n    if traceback == Ellipsis:\n        _, _, traceback = sys.exc_info()\n    raise exc.with_traceback(traceback)", "language": "python"}
{"input": "This splits a command line into a list of arguments. It splits arguments\n    on spaces, but handles embedded quotes, doublequotes, and escaped\n    characters. It's impossible to do this with a regular expression, so I\n    wrote a little state machine to parse the command line.", "output": "def split_command_line(command_line):\n\n    '''This splits a command line into a list of arguments. It splits arguments\n    on spaces, but handles embedded quotes, doublequotes, and escaped\n    characters. It's impossible to do this with a regular expression, so I\n    wrote a little state machine to parse the command line. '''\n\n    arg_list = []\n    arg = ''\n\n    # Constants to name the states we can be in.\n    state_basic = 0\n    state_esc = 1\n    state_singlequote = 2\n    state_doublequote = 3\n    # The state when consuming whitespace between commands.\n    state_whitespace = 4\n    state = state_basic\n\n    for c in command_line:\n        if state == state_basic or state == state_whitespace:\n            if c == '\\\\':\n                # Escape the next character\n                state = state_esc\n            elif c == r\"'\":\n                # Handle single quote\n                state = state_singlequote\n            elif c == r'\"':\n                # Handle double quote\n                state = state_doublequote\n            elif c.isspace():\n                # Add arg to arg_list if we aren't in the middle of whitespace.\n                if state == state_whitespace:\n                    # Do nothing.\n                    None\n                else:\n                    arg_list.append(arg)\n                    arg = ''\n                    state = state_whitespace\n            else:\n                arg = arg + c\n                state = state_basic\n        elif state == state_esc:\n            arg = arg + c\n            state = state_basic\n        elif state == state_singlequote:\n            if c == r\"'\":\n                state = state_basic\n            else:\n                arg = arg + c\n        elif state == state_doublequote:\n            if c == r'\"':\n                state = state_basic\n            else:\n                arg = arg + c\n\n    if arg != '':\n        arg_list.append(arg)\n    return arg_list", "language": "python"}
{"input": "Imports all files in index.d.ts and compiles a bundled .d.ts file for UMD bundles.", "output": "function dtsBundler() {\n  const packageDirectories = fs.readdirSync(D_TS_DIRECTORY);\n  packageDirectories.forEach((packageDirectory) => {\n    const packagePath = path.join(PACKAGES_DIRECTORY, packageDirectory);\n    const name = JSON.parse(fs.readFileSync(path.join(packagePath, 'package.json'), 'utf8')).name;\n    const main = path.join(D_TS_DIRECTORY, packageDirectory, './index.d.ts');\n    const isAllInOne = packageDirectory === ALL_IN_ONE_PACKAGE;\n    const destBasename = isAllInOne ? packageDirectory : `mdc.${toCamelCase(packageDirectory.replace(/^mdc-/, ''))}`;\n    const destFilename = path.join(packagePath, 'dist', `${destBasename}.d.ts`);\n\n    console.log(`Writing UMD declarations in ${destFilename.replace(process.cwd() + '/', '')}`);\n    dts.bundle({\n      name,\n      main,\n      out: destFilename,\n    });\n  });\n}", "language": "javascript"}
{"input": "Transform list into a heap, in-place, in O(len(x)) time.", "output": "def heapify(x):\n    \"\"\"Transform list into a heap, in-place, in O(len(x)) time.\"\"\"\n    n = len(x)\n    # Transform bottom-up.  The largest index there's any point to looking at\n    # is the largest with a child index in-range, so must have 2*i + 1 < n,\n    # or i < (n-1)/2.  If n is even = 2*j, this is (2*j-1)/2 = j-1/2 so\n    # j-1 is the largest, which is n//2 - 1.  If n is odd = 2*j+1, this is\n    # (2*j+1-1)/2 = j so j-1 is the largest, and that's again n//2-1.\n    for i in reversed(range(n//2)):\n        _siftup(x, i)", "language": "python"}
{"input": "Retrieve decoded information to authenticate to Docker with AWS credentials.\n@returns {Promise} Returns a promise that resolves when the informations are retrieved.", "output": "function getDockerLogin() {\n    return spinner(\n        new Promise((resolve, reject) =>\n            _getAuthorizationToken().then(authToken =>\n                sts\n                    .getCallerIdentity({})\n                    .promise()\n                    .then(data => {\n                        const decoded = utils.decodeBase64(authToken.authorizationToken);\n                        const splitResult = decoded.split(':');\n                        resolve({\n                            username: splitResult[0],\n                            password: splitResult[1],\n                            accountId: data.Account\n                        });\n                    })\n                    .catch(() => reject(new Error(\"Couldn't retrieve the user informations\")))\n            )\n        )\n    );\n}", "language": "javascript"}
{"input": "computes the empirical correlation coefficient", "output": "def corr(label, pred):\n    \"\"\"computes the empirical correlation coefficient\"\"\"\n    numerator1 = label - np.mean(label, axis=0)\n    numerator2 = pred - np.mean(pred, axis = 0)\n    numerator = np.mean(numerator1 * numerator2, axis=0)\n    denominator = np.std(label, axis=0) * np.std(pred, axis=0)\n    return np.mean(numerator / denominator)", "language": "python"}
{"input": "Inform Metrics class that experience collection is done.", "output": "def end_experience_collection_timer(self):\n        \"\"\"\n        Inform Metrics class that experience collection is done.\n        \"\"\"\n        if self.time_start_experience_collection:\n            curr_delta = time() - self.time_start_experience_collection\n            if self.delta_last_experience_collection is None:\n                self.delta_last_experience_collection = curr_delta\n            else:\n                self.delta_last_experience_collection += curr_delta\n        self.time_start_experience_collection = None", "language": "python"}
{"input": "A transform that inlines fragment spreads with the @relay(mask: false)\ndirective.", "output": "function relayMaskTransform(context: CompilerContext): CompilerContext {\n  return IRTransformer.transform(\n    context,\n    {\n      FragmentSpread: visitFragmentSpread,\n      Fragment: visitFragment,\n    },\n    () => ({\n      reachableArguments: [],\n    }),\n  );\n}", "language": "javascript"}
{"input": "Implementation of Neural GPU: https://arxiv.org/abs/1702.08727.\n\n  Args:\n    feature_depth: Number of memory channels\n    steps: Number of times depthwise recurrence steps.\n    vocab_size: Vocabulary size.\n\n  Returns:\n    A NeuralGPU Stax model.", "output": "def NeuralGPU(feature_depth=96, steps=16, vocab_size=2):\n  \"\"\"Implementation of Neural GPU: https://arxiv.org/abs/1702.08727.\n\n  Args:\n    feature_depth: Number of memory channels\n    steps: Number of times depthwise recurrence steps.\n    vocab_size: Vocabulary size.\n\n  Returns:\n    A NeuralGPU Stax model.\n  \"\"\"\n  xs = []\n  xs.append(\n      layers.Embedding(feature_depth=feature_depth, vocab_size=vocab_size))\n  core = ConvDiagonalGRU(units=feature_depth)\n  xs.extend([core] * steps)\n  xs.append(layers.Dense(vocab_size))\n  xs.append(layers.LogSoftmax())\n\n  return layers.Serial(*xs)", "language": "python"}
{"input": "Merge an arbitrary number of objects into one.", "output": "function extend(target) {\n\tfor(var i = 1; i < arguments.length; i++) {\n\t\ttarget = _mergeProperties(target, arguments[i]);\n\t}\n\n\treturn target;\n}", "language": "javascript"}
{"input": "reduce 2D array to TSV rows\n@param {Array.<Array.<string>>} arr - 2d array\n@returns {Array.<string>} - TSV row array\n@ignore", "output": "function _reduceToTSV(arr) {\n  // 2D array => quoted TSV row array\n  // [['a', 'b b'], [1, 2]] => ['a\\t\"b b\"', '1\\t2']\n  return arr.reduce((acc, row) => {\n    // ['a', 'b b', 'c c'] => ['a', '\"b b\"', '\"c c\"']\n    const quoted = row.map(text => {\n      if (!isNumeric(text) && text.indexOf(' ') >= 0) {\n        text = `\"${text}\"`;\n      }\n\n      return text;\n    });\n    // ['a', '\"b b\"', '\"c c\"'] => 'a\\t\"b b\"\\t\"c c\"'\n    acc.push(quoted.join('\\t'));\n\n    return acc;\n  }, []);\n}", "language": "javascript"}
{"input": "execute test or hook synchronously\n@param  {Function} fn         spec or hook method\n@param  {Number}   repeatTest number of retries\n@return {Promise}             that gets resolved once test/hook is done or was retried enough", "output": "function (fn, repeatTest = 0, args = []) {\n    /**\n     * if a new hook gets executed we can assume that all commands should have finised\n     * with exception of timeouts where `commandIsRunning` will never be reset but here\n     */\n    // commandIsRunning = false\n\n    return new Promise((resolve, reject) => {\n        try {\n            const res = fn.apply(this, args)\n            resolve(res)\n        } catch (e) {\n            if (repeatTest) {\n                return resolve(executeSync(fn, --repeatTest, args))\n            }\n\n            /**\n             * no need to modify stack if no stack available\n             */\n            if (!e.stack) {\n                return reject(e)\n            }\n\n            e.stack = e.stack.split('\\n').filter(STACKTRACE_FILTER_FN).join('\\n')\n            reject(e)\n        }\n    })\n}", "language": "javascript"}
{"input": "Delete cached copies of this broadcast on the executors. If the\n        broadcast is used after this is called, it will need to be\n        re-sent to each executor.\n\n        :param blocking: Whether to block until unpersisting has completed", "output": "def unpersist(self, blocking=False):\n        \"\"\"\n        Delete cached copies of this broadcast on the executors. If the\n        broadcast is used after this is called, it will need to be\n        re-sent to each executor.\n\n        :param blocking: Whether to block until unpersisting has completed\n        \"\"\"\n        if self._jbroadcast is None:\n            raise Exception(\"Broadcast can only be unpersisted in driver\")\n        self._jbroadcast.unpersist(blocking)", "language": "python"}
{"input": "Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`", "output": "def _db_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    \"Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`\"\n    self.train_ds.x.after_open = compose(train_tfm)\n    self.valid_ds.x.after_open = compose(valid_tfm)\n    return self", "language": "python"}
{"input": "We have to process scale caused by dataZoom manually, although it might be not accurate.", "output": "function getScales(xyMinMaxCurr, xyMinMaxOrigin) {\n    var sizeCurr = getSize(xyMinMaxCurr);\n    var sizeOrigin = getSize(xyMinMaxOrigin);\n    var scales = [sizeCurr[0] / sizeOrigin[0], sizeCurr[1] / sizeOrigin[1]];\n    isNaN(scales[0]) && (scales[0] = 1);\n    isNaN(scales[1]) && (scales[1] = 1);\n    return scales;\n}", "language": "javascript"}
{"input": "Adds a textInsert edit for a newly created text node.", "output": "function () {\n            newEdit = {\n                type: \"textInsert\",\n                content: newChild.content,\n                parentID: newChild.parent.tagID\n            };\n\n            // text changes will generally have afterID and beforeID, but we make\n            // special note if it's the first child.\n            if (textAfterID) {\n                newEdit.afterID = textAfterID;\n            } else {\n                newEdit.firstChild = true;\n            }\n            newEdits.push(newEdit);\n\n            // The text node is in the new tree, so we move to the next new tree item\n            newIndex++;\n        }", "language": "javascript"}
{"input": "Creates a template object from a module.  This is used by the\n        module loader to create a template object.\n\n        .. versionadded:: 2.4", "output": "def from_module_dict(cls, environment, module_dict, globals):\n        \"\"\"Creates a template object from a module.  This is used by the\n        module loader to create a template object.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        return cls._from_namespace(environment, module_dict, globals)", "language": "python"}
{"input": "Cleans up and unifies a SQL query. This involves unifying quoted strings\n    and splitting brackets which aren't formatted consistently in the data.", "output": "def clean_and_split_sql(sql: str) -> List[str]:\n    \"\"\"\n    Cleans up and unifies a SQL query. This involves unifying quoted strings\n    and splitting brackets which aren't formatted consistently in the data.\n    \"\"\"\n    sql_tokens: List[str] = []\n    for token in sql.strip().split():\n        token = token.replace('\"', \"'\").replace(\"%\", \"\")\n        if token.endswith(\"(\") and len(token) > 1:\n            sql_tokens.extend(split_table_and_column_names(token[:-1]))\n            sql_tokens.extend(split_table_and_column_names(token[-1]))\n        else:\n            sql_tokens.extend(split_table_and_column_names(token))\n    return sql_tokens", "language": "python"}
{"input": "Sets the learning rate to the initial LR decayed by 10 every 30 epochs", "output": "def adjust_learning_rate(optimizer, epoch, gammas, schedule):\n  \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n  lr = args.learning_rate\n  assert len(gammas) == len(schedule), \"length of gammas and schedule should be equal\"\n  for (gamma, step) in zip(gammas, schedule):\n    if (epoch >= step):\n      lr = lr * gamma\n    else:\n      break\n  for param_group in optimizer.param_groups:\n    param_group['lr'] = lr\n  return lr", "language": "python"}
{"input": "Check if the stack event contains the name a Nested Stack name.\n@param stack The StackEvent object.\n@returns {boolean} true if the object contain a Nested Stack name, false otherwise.\n@private", "output": "function _doesEventContainsNestedStackId(stack) {\n    if (stack.ResourceType !== 'AWS::CloudFormation::Stack') {\n        return false;\n    }\n    if (stack.ResourceStatusReason !== 'Resource creation Initiated') {\n        return false;\n    }\n    if (stack.ResourceStatus !== 'CREATE_IN_PROGRESS') {\n        return false;\n    }\n    if (_.isNil(stack.PhysicalResourceId)) {\n        return false;\n    }\n\n    return _hasLabelNestedStackName(stack.PhysicalResourceId);\n}", "language": "javascript"}
{"input": "Slice encoder hidden state into block_dim.\n\n    Args:\n        x: Encoder hidden state of shape [-1, hidden_size].\n\n    Returns:\n        Sliced states of shape [-1, num_blocks, block_dim].", "output": "def slice_hidden(self, x):\n    \"\"\"Slice encoder hidden state into block_dim.\n\n    Args:\n        x: Encoder hidden state of shape [-1, hidden_size].\n\n    Returns:\n        Sliced states of shape [-1, num_blocks, block_dim].\n    \"\"\"\n    x_sliced = tf.reshape(\n        x, shape=[-1, self.hparams.num_blocks, self.hparams.block_dim])\n    return x_sliced", "language": "python"}
{"input": "Resolve cacher by name\n\n@param {object|string} opt\n@returns {Cacher}", "output": "function resolve(opt) {\n\tif (opt instanceof Cachers.Base) {\n\t\treturn opt;\n\t} else if (opt === true) {\n\t\treturn new Cachers.Memory();\n\t} else if (_.isString(opt)) {\n\t\tlet CacherClass = getByName(opt);\n\t\tif (CacherClass)\n\t\t\treturn new CacherClass();\n\n\t\tif (opt.startsWith(\"redis://\"))\n\t\t\tCacherClass = Cachers.Redis;\n\n\t\tif (CacherClass)\n\t\t\treturn new CacherClass(opt);\n\t\telse\n\t\t\tthrow new BrokerOptionsError(`Invalid cacher type '${opt}'.`, { type: opt });\n\n\t} else if (_.isObject(opt)) {\n\t\tlet CacherClass = getByName(opt.type || \"Memory\");\n\t\tif (CacherClass)\n\t\t\treturn new CacherClass(opt.options);\n\t\telse\n\t\t\tthrow new BrokerOptionsError(`Invalid cacher type '${opt.type}'.`, { type: opt.type });\n\t}\n\n\treturn null;\n}", "language": "javascript"}
{"input": "require they keys to be the same type as the index (so we don't\n        fallback)", "output": "def _convert_key(self, key, is_setter=False):\n        \"\"\" require they keys to be the same type as the index (so we don't\n        fallback)\n        \"\"\"\n\n        # allow arbitrary setting\n        if is_setter:\n            return list(key)\n\n        for ax, i in zip(self.obj.axes, key):\n            if ax.is_integer():\n                if not is_integer(i):\n                    raise ValueError(\"At based indexing on an integer index \"\n                                     \"can only have integer indexers\")\n            else:\n                if is_integer(i) and not ax.holds_integer():\n                    raise ValueError(\"At based indexing on an non-integer \"\n                                     \"index can only have non-integer \"\n                                     \"indexers\")\n        return key", "language": "python"}
{"input": "Checks whether it is safe to apply a fix to a given return statement.\n\nThe fix is not considered safe if the given return statement has leading comments,\nas we cannot safely determine if the newline should be added before or after the comments.\nFor more information, see: https://github.com/eslint/eslint/issues/5958#issuecomment-222767211\n\n@param {ASTNode} node - The return statement node to check.\n@returns {boolean} `true` if it can fix the node.\n@private", "output": "function canFix(node) {\n            const leadingComments = sourceCode.getCommentsBefore(node);\n            const lastLeadingComment = leadingComments[leadingComments.length - 1];\n            const tokenBefore = sourceCode.getTokenBefore(node);\n\n            if (leadingComments.length === 0) {\n                return true;\n            }\n\n            /*\n             * if the last leading comment ends in the same line as the previous token and\n             * does not share a line with the `return` node, we can consider it safe to fix.\n             * Example:\n             * function a() {\n             *     var b; //comment\n             *     return;\n             * }\n             */\n            if (lastLeadingComment.loc.end.line === tokenBefore.loc.end.line &&\n                lastLeadingComment.loc.end.line !== node.loc.start.line) {\n                return true;\n            }\n\n            return false;\n        }", "language": "javascript"}
{"input": "Prepares the given HTTP auth data.", "output": "def prepare_auth(self, auth, url=''):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)", "language": "python"}
{"input": "Function: getStylenames\n\nReturns the stylenames in a style of the form [(stylename|key=value);]\nor an empty array if the given style does not contain any stylenames.\n\nParameters:\n\nstyle - String of the form [(stylename|key=value);].", "output": "function(style)\n\t{\n\t\tvar result = [];\n\t\t\n\t\tif (style != null)\n\t\t{\n\t\t\tvar pairs = style.split(';');\n\t\t\t\n\t\t\tfor (var i = 0; i < pairs.length; i++)\n\t\t\t{\n\t\t\t\tif (pairs[i].indexOf('=') < 0)\n\t\t\t\t{\n\t\t\t\t\tresult.push(pairs[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\t\t\n\t\treturn result;\n\t}", "language": "javascript"}
{"input": "Escapes a CSS string.\n@param {string} css the string to escape.\n@return {string} the escaped string.\n@throws {TypeError} if the input value is not a string.\n@throws {InvalidCharacterError} if the string contains an invalid character.\n@see https://drafts.csswg.org/cssom/#serialize-an-identifier", "output": "function escapeCss(css) {\n  if (typeof css !== 'string') {\n    throw new TypeError('input must be a string');\n  }\n  let ret = '';\n  const n = css.length;\n  for (let i = 0; i  < n; i++) {\n    const c = css.charCodeAt(i);\n    if (c == 0x0) {\n      throw new InvalidCharacterError();\n    }\n\n    if ((c >= 0x0001 && c <= 0x001F)\n        || c == 0x007F\n        || (i == 0 && c >= 0x0030 && c <= 0x0039)\n        || (i == 1 && c >= 0x0030 && c <= 0x0039\n            && css.charCodeAt(0) == 0x002D)) {\n      ret += '\\\\' + c.toString(16) + ' ';\n      continue;\n    }\n\n    if (i == 0 && c == 0x002D && n == 1) {\n      ret += '\\\\' + css.charAt(i);\n      continue;\n    }\n\n    if (c >= 0x0080\n        || c == 0x002D                      // -\n        || c == 0x005F                      // _\n        || (c >= 0x0030 && c <= 0x0039)     // [0-9]\n        || (c >= 0x0041 && c <= 0x005A)     // [A-Z]\n        || (c >= 0x0061 && c <= 0x007A)) {  // [a-z]\n      ret += css.charAt(i);\n      continue;\n    }\n\n    ret += '\\\\' + css.charAt(i);\n  }\n  return ret;\n}", "language": "javascript"}
{"input": "Checks whether a given Identifier node becomes a VariableDeclaration or not.\n\n@param {ASTNode} identifier - An Identifier node to check.\n@returns {boolean} `true` if the node can become a VariableDeclaration.", "output": "function canBecomeVariableDeclaration(identifier) {\n    let node = identifier.parent;\n\n    while (PATTERN_TYPE.test(node.type)) {\n        node = node.parent;\n    }\n\n    return (\n        node.type === \"VariableDeclarator\" ||\n        (\n            node.type === \"AssignmentExpression\" &&\n            node.parent.type === \"ExpressionStatement\" &&\n            DECLARATION_HOST_TYPE.test(node.parent.parent.type)\n        )\n    );\n}", "language": "javascript"}
{"input": "Function: replaceTrailingNewlines\n\nReplaces each trailing newline with the given pattern.", "output": "function(str, pattern)\n\t{\n\t\t// LATER: Check is this can be done with a regular expression\n\t\tvar postfix = '';\n\t\t\n\t\twhile (str.length > 0 && str.charAt(str.length - 1) == '\\n')\n\t\t{\n\t\t\tstr = str.substring(0, str.length - 1);\n\t\t\tpostfix += pattern;\n\t\t}\n\t\t\n\t\treturn str + postfix;\n\t}", "language": "javascript"}
{"input": "A leaf ordering is under-defined, this picks the ordering that keeps nearby samples similar.", "output": "def hclust_ordering(X, metric=\"sqeuclidean\"):\n    \"\"\" A leaf ordering is under-defined, this picks the ordering that keeps nearby samples similar.\n    \"\"\"\n    \n    # compute a hierarchical clustering\n    D = sp.spatial.distance.pdist(X, metric)\n    cluster_matrix = sp.cluster.hierarchy.complete(D)\n    \n    # merge clusters, rotating them to make the end points match as best we can\n    sets = [[i] for i in range(X.shape[0])]\n    for i in range(cluster_matrix.shape[0]):\n        s1 = sets[int(cluster_matrix[i,0])]\n        s2 = sets[int(cluster_matrix[i,1])]\n        \n        # compute distances between the end points of the lists\n        d_s1_s2 = pdist(np.vstack([X[s1[-1],:], X[s2[0],:]]), metric)[0]\n        d_s2_s1 = pdist(np.vstack([X[s1[0],:], X[s2[-1],:]]), metric)[0]\n        d_s1r_s2 = pdist(np.vstack([X[s1[0],:], X[s2[0],:]]), metric)[0]\n        d_s1_s2r = pdist(np.vstack([X[s1[-1],:], X[s2[-1],:]]), metric)[0]\n\n        # concatenete the lists in the way the minimizes the difference between\n        # the samples at the junction\n        best = min(d_s1_s2, d_s2_s1, d_s1r_s2, d_s1_s2r)\n        if best == d_s1_s2:\n            sets.append(s1 + s2)\n        elif best == d_s2_s1:\n            sets.append(s2 + s1)\n        elif best == d_s1r_s2:\n            sets.append(list(reversed(s1)) + s2)\n        else:\n            sets.append(s1 + list(reversed(s2)))\n    \n    return sets[-1]", "language": "python"}
{"input": "Helper to push or concat based on if the 2nd parameter is an array or not", "output": "function pushOrConcat(base, toPush) {\n\tif (toPush) {\n\t\tif (helpers.isArray(toPush)) {\n\t\t\t// base = base.concat(toPush);\n\t\t\tArray.prototype.push.apply(base, toPush);\n\t\t} else {\n\t\t\tbase.push(toPush);\n\t\t}\n\t}\n\n\treturn base;\n}", "language": "javascript"}
{"input": "r'''\n    This routine beam search decodes a mini-batch and calculates the loss and mean edit distance.\n    Next to total and average loss it returns the mean edit distance,\n    the decoded result and the batch's original Y.", "output": "def calculate_mean_edit_distance_and_loss(iterator, dropout, reuse):\n    r'''\n    This routine beam search decodes a mini-batch and calculates the loss and mean edit distance.\n    Next to total and average loss it returns the mean edit distance,\n    the decoded result and the batch's original Y.\n    '''\n    # Obtain the next batch of data\n    (batch_x, batch_seq_len), batch_y = iterator.get_next()\n\n    # Calculate the logits of the batch\n    logits, _ = create_model(batch_x, batch_seq_len, dropout, reuse=reuse)\n\n    # Compute the CTC loss using TensorFlow's `ctc_loss`\n    total_loss = tf.nn.ctc_loss(labels=batch_y, inputs=logits, sequence_length=batch_seq_len)\n\n    # Calculate the average loss across the batch\n    avg_loss = tf.reduce_mean(total_loss)\n\n    # Finally we return the average loss\n    return avg_loss", "language": "python"}
{"input": "Process parse_dates argument for read_sql functions", "output": "def _process_parse_dates_argument(parse_dates):\n    \"\"\"Process parse_dates argument for read_sql functions\"\"\"\n    # handle non-list entries for parse_dates gracefully\n    if parse_dates is True or parse_dates is None or parse_dates is False:\n        parse_dates = []\n\n    elif not hasattr(parse_dates, '__iter__'):\n        parse_dates = [parse_dates]\n    return parse_dates", "language": "python"}
{"input": "Compare two digests of equal length in constant time.\n\n    The digests must be of type str/bytes.\n    Returns True if the digests match, and False otherwise.", "output": "def _const_compare_digest_backport(a, b):\n    \"\"\"\n    Compare two digests of equal length in constant time.\n\n    The digests must be of type str/bytes.\n    Returns True if the digests match, and False otherwise.\n    \"\"\"\n    result = abs(len(a) - len(b))\n    for l, r in zip(bytearray(a), bytearray(b)):\n        result |= l ^ r\n    return result == 0", "language": "python"}
{"input": "Construct a plain object from the meta.", "output": "function metaToPlainObject (meta) {\n  const obj = (() => meta.type === 'error' ? new Error() : {})()\n  for (let i = 0; i < meta.members.length; i++) {\n    const { name, value } = meta.members[i]\n    obj[name] = value\n  }\n  return obj\n}", "language": "javascript"}
{"input": "Import From File\nThe main method of the ImportManager, call this to kick everything off!\n@param {File} file\n@param {importOptions} importOptions to allow override of certain import features such as locking a user\n@returns {Promise}", "output": "function (file, importOptions = {}) {\n        var self = this;\n\n        // Step 1: Handle converting the file to usable data\n        return this.loadFile(file).then(function (importData) {\n            // Step 2: Let the importers pre-process the data\n            return self.preProcess(importData);\n        }).then(function (importData) {\n            // Step 3: Actually do the import\n            // @TODO: It would be cool to have some sort of dry run flag here\n            return self.doImport(importData, importOptions);\n        }).then(function (importData) {\n            // Step 4: Report on the import\n            return self.generateReport(importData);\n        }).finally(() => self.cleanUp()); // Step 5: Cleanup any files\n    }", "language": "javascript"}
{"input": "Will be called if scrolled vertically. Updates the visualized data by applying the first visible row from the vertical scrollbar.\n\n@param {jQuery.Event} oEvent The event object.", "output": "function(oEvent) {\n\t\t\t// For interaction detection.\n\t\t\tInteraction.notifyScrollEvent && Interaction.notifyScrollEvent(oEvent);\n\n\t\t\tif (internal(this).bIsScrolledVerticallyByKeyboard) {\n\t\t\t\t// When scrolling with the keyboard the first visible row is already correct and does not need adjustment.\n\t\t\t\tlog(\"Vertical scroll event handler: Aborted - Scrolled by keyboard\", this);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Do not scroll in action mode, if scrolling was not initiated by a keyboard action!\n\t\t\t// Might cause loss of user input and other undesired behavior.\n\t\t\tthis._getKeyboardExtension().setActionMode(false);\n\n\t\t\tvar nNewScrollTop = oEvent.target.scrollTop; // Can be a float if zoomed in Chrome.\n\t\t\tvar nOldScrollTop = oEvent.target._scrollTop; // This will be set in VerticalScrollingHelper#updateScrollPosition.\n\t\t\tvar bScrollWithScrollbar = nNewScrollTop !== nOldScrollTop;\n\n\t\t\tif (bScrollWithScrollbar) {\n\t\t\t\tlog(\"Vertical scroll event handler: Scroll position changed by scrolling with the scrollbar:\"\n\t\t\t\t\t+ \" From \" + internal(this).nVerticalScrollPosition + \" to \" + nNewScrollTop, this);\n\t\t\t\tdelete oEvent.target._scrollTop;\n\t\t\t\tVerticalScrollingHelper.updateScrollPosition(this, nNewScrollTop, ScrollTrigger.SCROLLBAR);\n\t\t\t} else {\n\t\t\t\tlog(\"Vertical scroll event handler: Scroll position changed by scrolling with VerticalScrollingHelper#updateScrollPosition\", this);\n\t\t\t}\n\n\t\t\tinternal(this).bIsScrolledVerticallyByWheel = false;\n\t\t}", "language": "javascript"}
{"input": "Extract content locally from the file system used fs.readFile()\n\n@param {String} fileName - fullpath of the document\n@param {Function} callback - callback handle to post the content back", "output": "function _readFile(fileName, callback) {\n    fs.readFile(fileName, \"utf8\", function (err, data) {\n        var content = \"\";\n        if (!err) {\n            content = data;\n        }\n        callback.apply(null, [fileName, content]);\n    });\n}", "language": "javascript"}
{"input": "Convert timestamp to timezone-naive in the specified timezone or local timezone\n\n    :param s: a pandas.Series\n    :param from_timezone: the timezone to convert from. if None then use local timezone\n    :param to_timezone: the timezone to convert to. if None then use local timezone\n    :return pandas.Series where if it is a timestamp, has been converted to tz-naive", "output": "def _check_series_convert_timestamps_localize(s, from_timezone, to_timezone):\n    \"\"\"\n    Convert timestamp to timezone-naive in the specified timezone or local timezone\n\n    :param s: a pandas.Series\n    :param from_timezone: the timezone to convert from. if None then use local timezone\n    :param to_timezone: the timezone to convert to. if None then use local timezone\n    :return pandas.Series where if it is a timestamp, has been converted to tz-naive\n    \"\"\"\n    from pyspark.sql.utils import require_minimum_pandas_version\n    require_minimum_pandas_version()\n\n    import pandas as pd\n    from pandas.api.types import is_datetime64tz_dtype, is_datetime64_dtype\n    from_tz = from_timezone or _get_local_timezone()\n    to_tz = to_timezone or _get_local_timezone()\n    # TODO: handle nested timestamps, such as ArrayType(TimestampType())?\n    if is_datetime64tz_dtype(s.dtype):\n        return s.dt.tz_convert(to_tz).dt.tz_localize(None)\n    elif is_datetime64_dtype(s.dtype) and from_tz != to_tz:\n        # `s.dt.tz_localize('tzlocal()')` doesn't work properly when including NaT.\n        return s.apply(\n            lambda ts: ts.tz_localize(from_tz, ambiguous=False).tz_convert(to_tz).tz_localize(None)\n            if ts is not pd.NaT else pd.NaT)\n    else:\n        return s", "language": "python"}
{"input": "/* Get a setting value, defaulting if necessary.", "output": "function(inst, name) {\n\t\treturn inst.settings[name] !== undefined ?\n\t\t\tinst.settings[name] : this._defaults[name];\n\t}", "language": "javascript"}
{"input": "Create HTTP error", "output": "function createError(status, message) {\n  var err = new Error(message);\n  err.status = status;\n  return err;\n}", "language": "javascript"}
{"input": "Returns the uri of the main service specified in the app manifest\n\n@param {object} oManifest - Manifest of the component\n@returns {string} Returns the uri if the manifest is available, otherwise an empty string\n@public", "output": "function (oManifest) {\n\t\t\tvar sUri = \"\";\n\t\t\tif (oManifest){\n\t\t\t\tvar oSapApp = (oManifest.getEntry) ? oManifest.getEntry(\"sap.app\") : oManifest[\"sap.app\"];\n\t\t\t\tif (oSapApp && oSapApp.dataSources && oSapApp.dataSources.mainService && oSapApp.dataSources.mainService.uri){\n\t\t\t\t\tsUri = oSapApp.dataSources.mainService.uri;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis.log.warning(\"No Manifest received.\");\n\t\t\t}\n\t\t\treturn sUri;\n\t\t}", "language": "javascript"}
{"input": "Creates the underlying option parser for this command.", "output": "def make_parser(self, ctx):\n        \"\"\"Creates the underlying option parser for this command.\"\"\"\n        parser = OptionParser(ctx)\n        for param in self.get_params(ctx):\n            param.add_to_parser(parser, ctx)\n        return parser", "language": "python"}
{"input": "/*\nFilter function to reduce a list of roles to a valid list of roles for a nodetype", "output": "function(set, role) {\n\t\tvar validForNodeType = function(implicitNodeTypeSelector) {\n\t\t\treturn axe.utils.matchesSelector(node, implicitNodeTypeSelector);\n\t\t};\n\n\t\tif (role.implicit && role.implicit.some(validForNodeType)) {\n\t\t\tset.push(role.name);\n\t\t}\n\n\t\treturn set;\n\t}", "language": "javascript"}
{"input": "Compare the value monitored to its best score and maybe save the model.", "output": "def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n        \"Compare the value monitored to its best score and maybe save the model.\"\n        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n        else: #every=\"improvement\"\n            current = self.get_monitor_value()\n            if current is not None and self.operator(current, self.best):\n                print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n                self.best = current\n                self.learn.save(f'{self.name}')", "language": "python"}
{"input": "Build using CMake", "output": "def build(args) -> None:\n    \"\"\"Build using CMake\"\"\"\n    venv_exe = shutil.which('virtualenv')\n    pyexe = shutil.which(args.pyexe)\n    if not venv_exe:\n        logging.warn(\"virtualenv wasn't found in path, it's recommended to install virtualenv to manage python environments\")\n    if not pyexe:\n        logging.warn(\"Python executable %s not found in path\", args.pyexe)\n    if args.cmake_options:\n        cmake = CMake(args.cmake_options)\n    else:\n        cmake = CMake()\n    cmake()\n    create_virtualenv(venv_exe, pyexe, args.venv)", "language": "python"}
{"input": "Set the random seed from flag everywhere.", "output": "def set_random_seed():\n  \"\"\"Set the random seed from flag everywhere.\"\"\"\n  tf.set_random_seed(FLAGS.random_seed)\n  random.seed(FLAGS.random_seed)\n  np.random.seed(FLAGS.random_seed)", "language": "python"}
{"input": "Description : training for LipNet", "output": "def train(self, data, label, batch_size):\n        \"\"\"\n        Description : training for LipNet\n        \"\"\"\n        # pylint: disable=no-member\n        sum_losses = 0\n        len_losses = 0\n        with autograd.record():\n            losses = [self.loss_fn(self.net(X), Y) for X, Y in zip(data, label)]\n        for loss in losses:\n            sum_losses += mx.nd.array(loss).sum().asscalar()\n            len_losses += len(loss)\n            loss.backward()\n        self.trainer.step(batch_size)\n        return sum_losses, len_losses", "language": "python"}
{"input": "Validate that the where statement is of the right type.\n\n    The type may either be String, Expr, or list-like of Exprs.\n\n    Parameters\n    ----------\n    w : String term expression, Expr, or list-like of Exprs.\n\n    Returns\n    -------\n    where : The original where clause if the check was successful.\n\n    Raises\n    ------\n    TypeError : An invalid data type was passed in for w (e.g. dict).", "output": "def _validate_where(w):\n    \"\"\"\n    Validate that the where statement is of the right type.\n\n    The type may either be String, Expr, or list-like of Exprs.\n\n    Parameters\n    ----------\n    w : String term expression, Expr, or list-like of Exprs.\n\n    Returns\n    -------\n    where : The original where clause if the check was successful.\n\n    Raises\n    ------\n    TypeError : An invalid data type was passed in for w (e.g. dict).\n    \"\"\"\n\n    if not (isinstance(w, (Expr, str)) or is_list_like(w)):\n        raise TypeError(\"where must be passed as a string, Expr, \"\n                        \"or list-like of Exprs\")\n\n    return w", "language": "python"}
{"input": "Check if a provided path exists and is readonly.\n\n    Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`", "output": "def is_readonly_path(fn):\n    \"\"\"Check if a provided path exists and is readonly.\n\n    Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`\n    \"\"\"\n\n    fn = fs_encode(fn)\n    if os.path.exists(fn):\n        file_stat = os.stat(fn).st_mode\n        return not bool(file_stat & stat.S_IWRITE) or not os.access(fn, os.W_OK)\n    return False", "language": "python"}
{"input": "Compute median of groups, excluding missing values.\n\n        For multiple groupings, the result index will be a MultiIndex", "output": "def median(self, **kwargs):\n        \"\"\"\n        Compute median of groups, excluding missing values.\n\n        For multiple groupings, the result index will be a MultiIndex\n        \"\"\"\n        try:\n            return self._cython_agg_general('median', **kwargs)\n        except GroupByError:\n            raise\n        except Exception:  # pragma: no cover\n\n            def f(x):\n                if isinstance(x, np.ndarray):\n                    x = Series(x)\n                return x.median(axis=self.axis, **kwargs)\n            with _group_selection_context(self):\n                return self._python_agg_general(f)", "language": "python"}
{"input": "Rewrite JSON file\n\n@param {string} filePath file path\n@param {function} rewriteFile rewriteFile function\n@param {object} generator reference to the generator", "output": "function rewriteJSONFile(filePath, rewriteFile, generator) {\n    const jsonObj = generator.fs.readJSON(filePath);\n    rewriteFile(jsonObj, generator);\n    generator.fs.writeJSON(filePath, jsonObj, null, 2);\n}", "language": "javascript"}
{"input": "Return necessary plugins, configs, parsers, etc. based on the config\n@param   {Object} config  config object\n@param   {boolean} [installESLint=true]  If `false` is given, it does not install eslint.\n@returns {string[]} An array of modules to be installed.", "output": "function getModulesList(config, installESLint) {\n    const modules = {};\n\n    // Create a list of modules which should be installed based on config\n    if (config.plugins) {\n        for (const plugin of config.plugins) {\n            modules[`eslint-plugin-${plugin}`] = \"latest\";\n        }\n    }\n    if (config.extends && config.extends.indexOf(\"eslint:\") === -1) {\n        const moduleName = `eslint-config-${config.extends}`;\n\n        modules[moduleName] = \"latest\";\n        Object.assign(\n            modules,\n            getPeerDependencies(`${moduleName}@latest`)\n        );\n    }\n\n    if (installESLint === false) {\n        delete modules.eslint;\n    } else {\n        const installStatus = npmUtils.checkDevDeps([\"eslint\"]);\n\n        // Mark to show messages if it's new installation of eslint.\n        if (installStatus.eslint === false) {\n            log.info(\"Local ESLint installation not found.\");\n            modules.eslint = modules.eslint || \"latest\";\n            config.installedESLint = true;\n        }\n    }\n\n    return Object.keys(modules).map(name => `${name}@${modules[name]}`);\n}", "language": "javascript"}
{"input": "Check if cron is in crons.", "output": "function(id, crons) {\n  for(var i=0, l=crons.length; i<l; i++) {\n    if(id === crons[i].id) {\n      return true;\n    }\n  }\n  return false;\n}", "language": "javascript"}
{"input": "Write the PID in the named PID file.\n\n        Get the numeric process ID (\u201cPID\u201d) of the current process\n        and write it to the named file as a line of text.", "output": "def write_pid_to_pidfile(pidfile_path):\n    \"\"\" Write the PID in the named PID file.\n\n        Get the numeric process ID (\u201cPID\u201d) of the current process\n        and write it to the named file as a line of text.\n\n        \"\"\"\n    open_flags = (os.O_CREAT | os.O_EXCL | os.O_WRONLY)\n    open_mode = 0o644\n    pidfile_fd = os.open(pidfile_path, open_flags, open_mode)\n    pidfile = os.fdopen(pidfile_fd, 'w')\n\n    # According to the FHS 2.3 section on PID files in /var/run:\n    #\n    #   The file must consist of the process identifier in\n    #   ASCII-encoded decimal, followed by a newline character. For\n    #   example, if crond was process number 25, /var/run/crond.pid\n    #   would contain three characters: two, five, and newline.\n\n    pid = os.getpid()\n    pidfile.write(\"%s\\n\" % pid)\n    pidfile.close()", "language": "python"}
{"input": "Send Analytics data to Server", "output": "function sendAnalyticsDataToServer(eventParams) {\n        var result = new $.Deferred();\n\n        var analyticsData = getAnalyticsData(eventParams);\n        $.ajax({\n            url: brackets.config.analyticsDataServerURL,\n            type: \"POST\",\n            data: JSON.stringify({events: [analyticsData]}),\n            headers: {\n                \"Content-Type\": \"application/json\",\n                \"x-api-key\": brackets.config.serviceKey\n            }\n        })\n            .done(function () {\n                result.resolve();\n            })\n            .fail(function (jqXHR, status, errorThrown) {\n                console.error(\"Error in sending Adobe Analytics Data. Response : \" + jqXHR.responseText + \". Status : \" + status + \". Error : \" + errorThrown);\n                result.reject();\n            });\n\n        return result.promise();\n    }", "language": "javascript"}
{"input": "Convert a list of strings to a list of Values\n\n    Args:\n        original_strings (list[basestring])\n        corenlp_values (list[basestring or None])\n    Returns:\n        list[Value]", "output": "def to_value_list(original_strings, corenlp_values=None):\n    \"\"\"Convert a list of strings to a list of Values\n\n    Args:\n        original_strings (list[basestring])\n        corenlp_values (list[basestring or None])\n    Returns:\n        list[Value]\n    \"\"\"\n    assert isinstance(original_strings, (list, tuple, set))\n    if corenlp_values is not None:\n        assert isinstance(corenlp_values, (list, tuple, set))\n        assert len(original_strings) == len(corenlp_values)\n        return list(set(to_value(x, y) for (x, y)\n                        in zip(original_strings, corenlp_values)))\n    else:\n        return list(set(to_value(x) for x in original_strings))", "language": "python"}
{"input": "Wait until the specified category has been selected\n\n@param {object} aSpec\nObject with parameters for customization\nElements: category - Category element to wait for\ntimeout - Duration to wait for the target state\n[optional - default: 5s]", "output": "function addonsManager_waitForCategory(aSpec) {\n    var spec = aSpec || { };\n    var category = spec.category;\n    var timeout = (spec.timeout == undefined) ? TIMEOUT : spec.timeout;\n\n    if (!category)\n      throw new Error(arguments.callee.name + \": Category not specified.\");\n\n    // TODO: restore after 1.5.1 has landed\n    // var self = this;\n    // mozmill.utils.waitFor(function () {\n    //   return self.selectedCategory.getNode() == category.getNode();\n    // }, timeout, 100, \"Category '\" + category.getNode().id + \"' has been set\");\n    \n    mozmill.utils.waitForEval(\"subject.self.selectedCategory.getNode() == subject.aCategory.getNode()\",\n                               timeout, 100, \n                               {self: this, aCategory: category});\n  }", "language": "javascript"}
{"input": "Moves the given context backwards by one token.\n@param {!{editor:!CodeMirror, pos:!{ch:number, line:number}, token:Object}} ctx\n@param {boolean=} precise If code is being edited, use true (default) for accuracy.\nIf parsing unchanging code, use false to use cache for performance.\n@return {boolean} whether the context changed", "output": "function movePrevToken(ctx, precise) {\n        if (precise === undefined) {\n            precise = true;\n        }\n\n        if (ctx.pos.ch <= 0 || ctx.token.start <= 0) {\n            //move up a line\n            if (ctx.pos.line <= 0) {\n                return false; //at the top already\n            }\n            ctx.pos.line--;\n            ctx.pos.ch = ctx.editor.getLine(ctx.pos.line).length;\n        } else {\n            ctx.pos.ch = ctx.token.start;\n        }\n        ctx.token = getTokenAt(ctx.editor, ctx.pos, precise);\n        return true;\n    }", "language": "javascript"}
{"input": "Determine if a path can potentially be installed", "output": "def is_installable_file(path):\n    # type: (PipfileType) -> bool\n    \"\"\"Determine if a path can potentially be installed\"\"\"\n    from packaging import specifiers\n\n    if isinstance(path, Mapping):\n        path = convert_entry_to_path(path)\n\n    # If the string starts with a valid specifier operator, test if it is a valid\n    # specifier set before making a path object (to avoid breaking windows)\n    if any(path.startswith(spec) for spec in \"!=<>~\"):\n        try:\n            specifiers.SpecifierSet(path)\n        # If this is not a valid specifier, just move on and try it as a path\n        except specifiers.InvalidSpecifier:\n            pass\n        else:\n            return False\n\n    parsed = urlparse(path)\n    is_local = (\n        not parsed.scheme\n        or parsed.scheme == \"file\"\n        or (len(parsed.scheme) == 1 and os.name == \"nt\")\n    )\n    if parsed.scheme and parsed.scheme == \"file\":\n        path = vistir.compat.fs_decode(vistir.path.url_to_path(path))\n    normalized_path = vistir.path.normalize_path(path)\n    if is_local and not os.path.exists(normalized_path):\n        return False\n\n    is_archive = pip_shims.shims.is_archive_file(normalized_path)\n    is_local_project = os.path.isdir(normalized_path) and is_installable_dir(\n        normalized_path\n    )\n    if is_local and is_local_project or is_archive:\n        return True\n\n    if not is_local and pip_shims.shims.is_archive_file(parsed.path):\n        return True\n\n    return False", "language": "python"}
{"input": "convert from mxnet's opts to dmlc's opts", "output": "def dmlc_opts(opts):\n    \"\"\"convert from mxnet's opts to dmlc's opts\n    \"\"\"\n    args = ['--num-workers', str(opts.num_workers),\n            '--num-servers', str(opts.num_servers),\n            '--cluster', opts.launcher,\n            '--host-file', opts.hostfile,\n            '--sync-dst-dir', opts.sync_dst_dir]\n\n    # convert to dictionary\n    dopts = vars(opts)\n    for key in ['env_server', 'env_worker', 'env']:\n        for v in dopts[key]:\n            args.append('--' + key.replace(\"_\",\"-\"))\n            args.append(v)\n    args += opts.command\n    try:\n        from dmlc_tracker import opts\n    except ImportError:\n        print(\"Can't load dmlc_tracker package.  Perhaps you need to run\")\n        print(\"    git submodule update --init --recursive\")\n        raise\n    dmlc_opts = opts.get_opts(args)\n    return dmlc_opts", "language": "python"}
{"input": "Performs update on model.\n        :param mini_batch: Batch of experiences.\n        :param num_sequences: Number of sequences to process.\n        :return: Results of update.", "output": "def update(self, mini_batch, num_sequences):\n        \"\"\"\n        Performs update on model.\n        :param mini_batch: Batch of experiences.\n        :param num_sequences: Number of sequences to process.\n        :return: Results of update.\n        \"\"\"\n\n        feed_dict = {self.model.dropout_rate: self.update_rate,\n                     self.model.batch_size: num_sequences,\n                     self.model.sequence_length: self.sequence_length}\n        if self.use_continuous_act:\n            feed_dict[self.model.true_action] = mini_batch['actions']. \\\n                reshape([-1, self.brain.vector_action_space_size[0]])\n        else:\n            feed_dict[self.model.true_action] = mini_batch['actions'].reshape(\n                [-1, len(self.brain.vector_action_space_size)])\n            feed_dict[self.model.action_masks] = np.ones(\n                (num_sequences, sum(self.brain.vector_action_space_size)))\n        if self.use_vec_obs:\n            apparent_obs_size = self.brain.vector_observation_space_size * \\\n                                self.brain.num_stacked_vector_observations\n            feed_dict[self.model.vector_in] = mini_batch['vector_obs'] \\\n                .reshape([-1,apparent_obs_size])\n        for i, _ in enumerate(self.model.visual_in):\n            visual_obs = mini_batch['visual_obs%d' % i]\n            feed_dict[self.model.visual_in[i]] = visual_obs\n        if self.use_recurrent:\n            feed_dict[self.model.memory_in] = np.zeros([num_sequences, self.m_size])\n        run_out = self._execute_model(feed_dict, self.update_dict)\n        return run_out", "language": "python"}
{"input": "Fire event created to attached listeners.\n\n@param {object} [mArguments] the arguments to pass along with the event.\n@return {sap.ui.core.routing.Target} <code>this</code> to allow method chaining\n@protected", "output": "function(mArguments) {\n\t\t\t\tvar sTitle = this._oTitleProvider && this._oTitleProvider.getTitle();\n\t\t\t\tif (sTitle) {\n\t\t\t\t\tthis.fireTitleChanged({\n\t\t\t\t\t\tname: this._oOptions._name,\n\t\t\t\t\t\ttitle: sTitle\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tthis._bIsDisplayed = true;\n\n\t\t\t\treturn this.fireEvent(this.M_EVENTS.DISPLAY, mArguments);\n\t\t\t}", "language": "javascript"}
{"input": "Relabel images by moving from parent dir with old label `class_old` to parent dir with new label `class_new`.", "output": "def relabel(self, change):\n        \"Relabel images by moving from parent dir with old label `class_old` to parent dir with new label `class_new`.\"\n        class_new,class_old,file_path = change.new,change.old,change.owner.file_path\n        fp = Path(file_path)\n        parent = fp.parents[1]\n        self._csv_dict[fp] = class_new", "language": "python"}
{"input": "Callback iterator using `_find`", "output": "function _findEach(src, match, quotes, comments, callback) {\n        var from = 0;\n        var to;\n        while (from < src.length) {\n            to = _find(src, match, from, quotes, comments);\n            if (to < 0) {\n                to = src.length;\n            }\n            callback(src.substr(from, to - from));\n            from = to + 1;\n        }\n    }", "language": "javascript"}
{"input": "Install monitor on all executors.", "output": "def install_monitor(self, monitor):\n        \"\"\"Install monitor on all executors.\"\"\"\n        if self.sym_gen is not None:\n            raise NotImplementedError(\"Monitoring is not implemented for bucketing\")\n\n        for train_exec in self.execgrp.train_execs:\n            monitor.install(train_exec)", "language": "python"}
{"input": "Set up the profiler state to 'run' or 'stop'.\n\n    Parameters\n    ----------\n    state : string, optional\n        Indicates whether to run the profiler, can\n        be 'stop' or 'run'. Default is `stop`.\n    profile_process : string\n        whether to profile kvstore `server` or `worker`.\n        server can only be profiled when kvstore is of type dist.\n        if this is not passed, defaults to `worker`", "output": "def set_state(state='stop', profile_process='worker'):\n    \"\"\"Set up the profiler state to 'run' or 'stop'.\n\n    Parameters\n    ----------\n    state : string, optional\n        Indicates whether to run the profiler, can\n        be 'stop' or 'run'. Default is `stop`.\n    profile_process : string\n        whether to profile kvstore `server` or `worker`.\n        server can only be profiled when kvstore is of type dist.\n        if this is not passed, defaults to `worker`\n    \"\"\"\n    state2int = {'stop': 0, 'run': 1}\n    profile_process2int = {'worker': 0, 'server': 1}\n    check_call(_LIB.MXSetProcessProfilerState(ctypes.c_int(state2int[state]),\n                                              profile_process2int[profile_process],\n                                              profiler_kvstore_handle))", "language": "python"}
{"input": "Removes a given key from the given .env\n\n    If the .env path given doesn't exist, fails\n    If the given key doesn't exist in the .env, fails", "output": "def unset_key(dotenv_path, key_to_unset, quote_mode=\"always\"):\n    \"\"\"\n    Removes a given key from the given .env\n\n    If the .env path given doesn't exist, fails\n    If the given key doesn't exist in the .env, fails\n    \"\"\"\n    if not os.path.exists(dotenv_path):\n        warnings.warn(\"can't delete from %s - it doesn't exist.\" % dotenv_path)\n        return None, key_to_unset\n\n    removed = False\n    with rewrite(dotenv_path) as (source, dest):\n        for mapping in parse_stream(source):\n            if mapping.key == key_to_unset:\n                removed = True\n            else:\n                dest.write(mapping.original)\n\n    if not removed:\n        warnings.warn(\"key %s not removed from %s - key doesn't exist.\" % (key_to_unset, dotenv_path))\n        return None, key_to_unset\n\n    return removed, key_to_unset", "language": "python"}
{"input": "Softmax function.", "output": "def softmax(attrs, inputs, proto_obj):\n    \"\"\"Softmax function.\"\"\"\n    if 'axis' not in attrs:\n        attrs = translation_utils._add_extra_attributes(attrs, {'axis': 1})\n    return 'softmax', attrs, inputs", "language": "python"}
{"input": "val2 ~ day or month", "output": "function (chrs, buffer, pos, strict, opts) {\n                        var frontValue = buffer.join('').substr(0, 3);\n                        if (frontValue.indexOf(opts.placeholder[0]) != -1) frontValue = \"01\" + opts.separator;\n                        var isValid = opts.regex.val2(opts.separator).test(frontValue + chrs);\n                        if (!strict && !isValid) {\n                            if (chrs.charAt(1) == opts.separator || \"-./\".indexOf(chrs.charAt(1)) != -1) {\n                                isValid = opts.regex.val2(opts.separator).test(frontValue + \"0\" + chrs.charAt(0));\n                                if (isValid) {\n                                    buffer[pos - 1] = \"0\";\n                                    return { \"pos\": pos, \"c\": chrs.charAt(0) };\n                                }\n                            }\n                        }\n                        return isValid;\n                    }", "language": "javascript"}
{"input": "evaluate the where condition cond on a and b\n\n        Parameters\n        ----------\n\n        cond : a boolean array\n        a :    return if cond is True\n        b :    return if cond is False\n        use_numexpr : whether to try to use numexpr (default True)", "output": "def where(cond, a, b, use_numexpr=True):\n    \"\"\" evaluate the where condition cond on a and b\n\n        Parameters\n        ----------\n\n        cond : a boolean array\n        a :    return if cond is True\n        b :    return if cond is False\n        use_numexpr : whether to try to use numexpr (default True)\n        \"\"\"\n\n    if use_numexpr:\n        return _where(cond, a, b)\n    return _where_standard(cond, a, b)", "language": "python"}
{"input": "/*\nChecks whether the node is a qualified name (a.b.c) and if so,\nreturns the leftmost identifier a", "output": "function getLeftmostName(node) {\n\twhile ( node.type === Syntax.MemberExpression ) {\n\t\tnode = node.object;\n\t}\n\tif ( node.type === Syntax.Identifier ) {\n\t\treturn node.name;\n\t}\n\t// return undefined;\n}", "language": "javascript"}
{"input": "get session for current connection", "output": "function(self, socket) {\n  var app = self.app,\n    sid = socket.id;\n  var session = self.session.get(sid);\n  if (session) {\n    return session;\n  }\n\n  session = self.session.create(sid, app.getServerId(), socket);\n  logger.debug('[%s] getSession session is created with session id: %s', app.getServerId(), sid);\n\n  // bind events for session\n  socket.on('disconnect', session.closed.bind(session));\n  socket.on('error', session.closed.bind(session));\n  session.on('closed', onSessionClose.bind(null, app));\n  session.on('bind', function(uid) {\n    logger.debug('session on [%s] bind with uid: %s', self.app.serverId, uid);\n    // update connection statistics if necessary\n    if (self.connection) {\n      self.connection.addLoginedUser(uid, {\n        loginTime: Date.now(),\n        uid: uid,\n        address: socket.remoteAddress.ip + ':' + socket.remoteAddress.port\n      });\n    }\n    self.app.event.emit(events.BIND_SESSION, session);\n  });\n\n  session.on('unbind', function(uid) {\n    if (self.connection) {\n      self.connection.removeLoginedUser(uid);\n    }\n    self.app.event.emit(events.UNBIND_SESSION, session);\n  });\n\n  return session;\n}", "language": "javascript"}
{"input": "Builds and normalize material data, normalizing stuff along the way.\n\n@param {object} data - Material data.\n@param {object} materialData - Object to use.\n@returns {object} Updated materialData.", "output": "function getMaterialData (data, materialData) {\n  materialData.color.set(data.color);\n  materialData.emissive.set(data.emissive);\n  materialData.emissiveIntensity = data.emissiveIntensity;\n  materialData.fog = data.fog;\n  materialData.metalness = data.metalness;\n  materialData.roughness = data.roughness;\n  materialData.wireframe = data.wireframe;\n  materialData.wireframeLinewidth = data.wireframeLinewidth;\n\n  if (data.normalMap) { materialData.normalScale = data.normalScale; }\n\n  if (data.ambientOcclusionMap) {\n    materialData.aoMapIntensity = data.ambientOcclusionMapIntensity;\n  }\n\n  if (data.displacementMap) {\n    materialData.displacementScale = data.displacementScale;\n    materialData.displacementBias = data.displacementBias;\n  }\n\n  return materialData;\n}", "language": "javascript"}
{"input": "Find an installed distribution that satisfies or conflicts\n        with this requirement, and set self.satisfied_by or\n        self.conflicts_with appropriately.", "output": "def check_if_exists(self, use_user_site):\n        # type: (bool) -> bool\n        \"\"\"Find an installed distribution that satisfies or conflicts\n        with this requirement, and set self.satisfied_by or\n        self.conflicts_with appropriately.\n        \"\"\"\n        if self.req is None:\n            return False\n        try:\n            # get_distribution() will resolve the entire list of requirements\n            # anyway, and we've already determined that we need the requirement\n            # in question, so strip the marker so that we don't try to\n            # evaluate it.\n            no_marker = Requirement(str(self.req))\n            no_marker.marker = None\n            self.satisfied_by = pkg_resources.get_distribution(str(no_marker))\n            if self.editable and self.satisfied_by:\n                self.conflicts_with = self.satisfied_by\n                # when installing editables, nothing pre-existing should ever\n                # satisfy\n                self.satisfied_by = None\n                return True\n        except pkg_resources.DistributionNotFound:\n            return False\n        except pkg_resources.VersionConflict:\n            existing_dist = pkg_resources.get_distribution(\n                self.req.name\n            )\n            if use_user_site:\n                if dist_in_usersite(existing_dist):\n                    self.conflicts_with = existing_dist\n                elif (running_under_virtualenv() and\n                        dist_in_site_packages(existing_dist)):\n                    raise InstallationError(\n                        \"Will not install to the user site because it will \"\n                        \"lack sys.path precedence to %s in %s\" %\n                        (existing_dist.project_name, existing_dist.location)\n                    )\n            else:\n                self.conflicts_with = existing_dist\n        return True", "language": "python"}
{"input": "Write a file to the output folder,\nIt creates the required folder\n\n@param {String} fileName\n@param {Buffer} content\n@return {Promise}", "output": "function(fileName, content) {\n                return Promise()\n                .then(function() {\n                    var filePath = PathUtils.resolveInRoot(outputFolder, fileName);\n\n                    return fs.ensureFile(filePath)\n                    .then(function() {\n                        return fs.writeFile(filePath, content);\n                    });\n                });\n            }", "language": "javascript"}
{"input": "Normalize UNIX path to a native path.", "output": "def normpath(path):\n    \"\"\"Normalize UNIX path to a native path.\"\"\"\n    normalized = os.path.join(*path.split(\"/\"))\n    if os.path.isabs(path):\n        return os.path.abspath(\"/\") + normalized\n    else:\n        return normalized", "language": "python"}
{"input": "Add an accessible message to the page that will be announced to\nusers who have spoken feedback on, but will be invisible to all\nother users. It's removed right away so it doesn't clutter the DOM.\n@param {string} msg The text to be pronounced.", "output": "function announceAccessibleMessage(msg) {\n  var element = document.createElement('div');\n  element.setAttribute('aria-live', 'polite');\n  element.style.position = 'relative';\n  element.style.left = '-9999px';\n  element.style.height = '0px';\n  element.innerText = msg;\n  document.body.appendChild(element);\n  window.setTimeout(function() {\n    document.body.removeChild(element);\n  }, 0);\n}", "language": "javascript"}
{"input": "Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.", "output": "def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return str('')\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors='replace')\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors='replace')\n\n        return content", "language": "python"}
{"input": "Returns a list of provider for given file path, if available.\nDecision is made depending on the file extension.\n\n@param {!string} filePath\n@return {Array.<{name:string, scanFileAsync:?function(string, string):!{$.Promise}, scanFile:?function(string, string):?{errors:!Array, aborted:boolean}}>}", "output": "function getProvidersForPath(filePath) {\n        var language            = LanguageManager.getLanguageForPath(filePath).getId(),\n            context             = PreferencesManager._buildContext(filePath, language),\n            installedProviders  = getProvidersForLanguageId(language),\n            preferredProviders,\n\n            prefPreferredProviderNames  = prefs.get(PREF_PREFER_PROVIDERS, context),\n            prefPreferredOnly           = prefs.get(PREF_PREFERRED_ONLY, context),\n\n            providers;\n\n        if (prefPreferredProviderNames && prefPreferredProviderNames.length) {\n            if (typeof prefPreferredProviderNames === \"string\") {\n                prefPreferredProviderNames = [prefPreferredProviderNames];\n            }\n            preferredProviders = prefPreferredProviderNames.reduce(function (result, key) {\n                var provider = _.find(installedProviders, {name: key});\n                if (provider) {\n                    result.push(provider);\n                }\n                return result;\n            }, []);\n            if (prefPreferredOnly) {\n                providers = preferredProviders;\n            } else {\n                providers = _.union(preferredProviders, installedProviders);\n            }\n        } else {\n            providers = installedProviders;\n        }\n        return providers;\n    }", "language": "javascript"}
{"input": "Returns descriptors of enabled plugins for the given chart.\n@returns {object[]} [{ plugin, options }]\n@private", "output": "function(chart) {\n\t\tvar cache = chart.$plugins || (chart.$plugins = {});\n\t\tif (cache.id === this._cacheId) {\n\t\t\treturn cache.descriptors;\n\t\t}\n\n\t\tvar plugins = [];\n\t\tvar descriptors = [];\n\t\tvar config = (chart && chart.config) || {};\n\t\tvar options = (config.options && config.options.plugins) || {};\n\n\t\tthis._plugins.concat(config.plugins || []).forEach(function(plugin) {\n\t\t\tvar idx = plugins.indexOf(plugin);\n\t\t\tif (idx !== -1) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tvar id = plugin.id;\n\t\t\tvar opts = options[id];\n\t\t\tif (opts === false) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (opts === true) {\n\t\t\t\topts = helpers.clone(defaults.global.plugins[id]);\n\t\t\t}\n\n\t\t\tplugins.push(plugin);\n\t\t\tdescriptors.push({\n\t\t\t\tplugin: plugin,\n\t\t\t\toptions: opts || {}\n\t\t\t});\n\t\t});\n\n\t\tcache.descriptors = descriptors;\n\t\tcache.id = this._cacheId;\n\t\treturn descriptors;\n\t}", "language": "javascript"}
{"input": "Focus with tabIndex\n\n@param e {Object} event object", "output": "function (e) {\n            if (!this.target) {\n                var x;\n                var $handle;\n\n                if (this.options.type === \"single\") {\n                    $handle = this.$cache.single;\n                } else {\n                    $handle = this.$cache.from;\n                }\n\n                x = $handle.offset().left;\n                x += ($handle.width() / 2) - 1;\n\n                this.pointerClick(\"single\", {preventDefault: function () {}, pageX: x});\n            }\n        }", "language": "javascript"}
{"input": "Merge intervals in the form of a list.", "output": "def merge_intervals(intervals):\n    \"\"\" Merge intervals in the form of a list. \"\"\"\n    if intervals is None:\n        return None\n    intervals.sort(key=lambda i: i[0])\n    out = [intervals.pop(0)]\n    for i in intervals:\n        if out[-1][-1] >= i[0]:\n            out[-1][-1] = max(out[-1][-1], i[-1])\n        else:\n            out.append(i)\n    return out", "language": "python"}
{"input": "Formats an array of schema validation errors.\n@param {Array} errors An array of error messages to format.\n@returns {string} Formatted error message", "output": "function formatErrors(errors) {\n    return errors.map(error => {\n        if (error.keyword === \"additionalProperties\") {\n            const formattedPropertyPath = error.dataPath.length ? `${error.dataPath.slice(1)}.${error.params.additionalProperty}` : error.params.additionalProperty;\n\n            return `Unexpected top-level property \"${formattedPropertyPath}\"`;\n        }\n        if (error.keyword === \"type\") {\n            const formattedField = error.dataPath.slice(1);\n            const formattedExpectedType = Array.isArray(error.schema) ? error.schema.join(\"/\") : error.schema;\n            const formattedValue = JSON.stringify(error.data);\n\n            return `Property \"${formattedField}\" is the wrong type (expected ${formattedExpectedType} but got \\`${formattedValue}\\`)`;\n        }\n\n        const field = error.dataPath[0] === \".\" ? error.dataPath.slice(1) : error.dataPath;\n\n        return `\"${field}\" ${error.message}. Value: ${JSON.stringify(error.data)}`;\n    }).map(message => `\\t- ${message}.\\n`).join(\"\");\n}", "language": "javascript"}
{"input": "Process a comment to determine if it needs to be reported.\n\n@param {ASTNode} comment The comment node to process.\n@returns {void}", "output": "function processComment(comment) {\n            const options = normalizedOptions[comment.type],\n                commentValid = isCommentValid(comment, options);\n\n            if (!commentValid) {\n                const messageId = capitalize === \"always\"\n                    ? \"unexpectedLowercaseComment\"\n                    : \"unexpectedUppercaseComment\";\n\n                context.report({\n                    node: null, // Intentionally using loc instead\n                    loc: comment.loc,\n                    messageId,\n                    fix(fixer) {\n                        const match = comment.value.match(LETTER_PATTERN);\n\n                        return fixer.replaceTextRange(\n\n                            // Offset match.index by 2 to account for the first 2 characters that start the comment (// or /*)\n                            [comment.range[0] + match.index + 2, comment.range[0] + match.index + 3],\n                            capitalize === \"always\" ? match[0].toLocaleUpperCase() : match[0].toLocaleLowerCase()\n                        );\n                    }\n                });\n            }\n        }", "language": "javascript"}
{"input": "Update a single aggregation with the array of contexts. Reuse existing children and just append or remove at the end, if some are missing or too many.", "output": "function update(oControl, aContexts, fnBefore, fnAfter) {\n\t\t\tvar aChildren = oControl[oAggregationInfo._sGetter]() || [],\n\t\t\t\toContext,\n\t\t\t\toClone;\n\t\t\tif (aChildren.length > aContexts.length) {\n\t\t\t\tfor (var i = aContexts.length; i < aChildren.length; i++) {\n\t\t\t\t\toClone = aChildren[i];\n\t\t\t\t\toControl[oAggregationInfo._sRemoveMutator](oClone);\n\t\t\t\t\toClone.destroy(\"KeepDom\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (var i = 0; i < aContexts.length; i++) {\n\t\t\t\toContext = aContexts[i];\n\t\t\t\toClone = aChildren[i];\n\t\t\t\tif (fnBefore) {\n\t\t\t\t\tfnBefore(oContext);\n\t\t\t\t}\n\t\t\t\tif (oClone) {\n\t\t\t\t\toClone.setBindingContext(oContext, oBindingInfo.model);\n\t\t\t\t} else {\n\t\t\t\t\toClone = fnFactory(getIdSuffix(oControl, i), oContext);\n\t\t\t\t\toClone.setBindingContext(oContext, oBindingInfo.model);\n\t\t\t\t\toControl[oAggregationInfo._sMutator](oClone);\n\t\t\t\t}\n\t\t\t\tif (fnAfter) {\n\t\t\t\t\tfnAfter(oContext, oClone);\n\t\t\t\t}\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Executes a shell script with the form \"./pathToScript param1 param2\"\n@param {string} shellScriptPath\n@param {string} icoSrc input .ico\n@param {string} dest has to be a .ico path", "output": "function iconShellHelper(shellScriptPath, icoSrc, dest) {\n  return new Promise((resolve, reject) => {\n    if (isWindows()) {\n      reject(new Error('OSX or Linux is required'));\n      return;\n    }\n\n    shell.exec(\n      `\"${shellScriptPath}\" \"${icoSrc}\" \"${dest}\"`,\n      { silent: true },\n      (exitCode, stdOut, stdError) => {\n        if (exitCode) {\n          // eslint-disable-next-line prefer-promise-reject-errors\n          reject({\n            stdOut,\n            stdError,\n          });\n          return;\n        }\n\n        resolve(dest);\n      },\n    );\n  });\n}", "language": "javascript"}
{"input": "Pure transformer-style multi-headed attention.\n\n  Args:\n    x: inputs ((q, k, v), mask)\n    params: parameters (none)\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate\n    mode: str: 'train' or 'eval'\n    **kwargs: other arguments including the rng\n\n  Returns:\n    Pure Multi-headed attention layer (no Dense transforms on input).", "output": "def PureMultiHeadedAttention(x, params, num_heads=8, dropout=0.0,\n                             mode='train', **kwargs):\n  \"\"\"Pure transformer-style multi-headed attention.\n\n  Args:\n    x: inputs ((q, k, v), mask)\n    params: parameters (none)\n    num_heads: int: number of attention heads\n    dropout: float: dropout rate\n    mode: str: 'train' or 'eval'\n    **kwargs: other arguments including the rng\n\n  Returns:\n    Pure Multi-headed attention layer (no Dense transforms on input).\n  \"\"\"\n  del params\n  rng = kwargs.get('rng', None)\n  (q, k, v), mask = x\n  feature_depth = q.shape[-1]\n  assert feature_depth % num_heads == 0\n  head_depth = feature_depth // num_heads\n  nbatch = np.shape(q)[0]\n  # nbatch, seqlen, feature_depth --> nbatch, num_heads, seqlen, head_depth\n  def SplitHeads(x):\n    return np.transpose(\n        np.reshape(x, (nbatch, -1, num_heads, head_depth)), (0, 2, 1, 3))\n  # nbatch, num_heads, seqlen, head_depth --> nbatch, seqlen, feature_depth\n  def JoinHeads(x):  # pylint: disable=invalid-name\n    return np.reshape(\n        np.transpose(x, (0, 2, 1, 3)), (nbatch, -1, num_heads*head_depth))\n  # Split heads, dot-product attention, rejoin heads.\n  return JoinHeads(\n      DotProductAttention(\n          SplitHeads(q), SplitHeads(k), SplitHeads(v), mask,\n          dropout=dropout, mode=mode, rng=rng))", "language": "python"}
{"input": "Returns locale-independent string identifier of resource type (primarily for use in extension API). The IDs need to be kept in sync with webInspector.resoureces.Types object in ExtensionAPI.js.", "output": "function(type)\n    {\n        switch (type) {\n            case this.Document:\n                return \"document\";\n            case this.Stylesheet:\n                return \"stylesheet\";\n            case this.Image:\n                return \"image\";\n            case this.Font:\n                return \"font\";\n            case this.Script:\n                return \"script\";\n            case this.XHR:\n                return \"xhr\";\n            case this.WebSocket:\n                return \"websocket\";\n            case this.Other:\n            default:\n                return \"other\";\n        }\n    }", "language": "javascript"}
{"input": "@private\n\nSee FileTreeViewModel.deleteAtPath", "output": "function _deleteAtPath(treeData, path) {\n        var objectPath = _filePathToObjectPath(treeData, path);\n\n        if (!objectPath) {\n            return;\n        }\n\n        var originalName = _.last(objectPath);\n\n        // Back up to the parent directory\n        objectPath.pop();\n\n        treeData = treeData.updateIn(objectPath, function (directory) {\n            directory = directory.delete(originalName);\n            return directory;\n        });\n\n        return treeData;\n    }", "language": "javascript"}
{"input": "Validates a list of arguments or parameters\n@param {Object} parens An object with keys `leftParen` for the left paren token, and `rightParen` for the right paren token\n@param {ASTNode[]} elements The arguments or parameters in the list\n@returns {void}", "output": "function validateArguments(parens, elements) {\n            const leftParen = parens.leftParen;\n            const tokenAfterLeftParen = sourceCode.getTokenAfter(leftParen);\n            const hasLeftNewline = !astUtils.isTokenOnSameLine(leftParen, tokenAfterLeftParen);\n            const needsNewlines = shouldHaveNewlines(elements, hasLeftNewline);\n\n            for (let i = 0; i <= elements.length - 2; i++) {\n                const currentElement = elements[i];\n                const nextElement = elements[i + 1];\n                const hasNewLine = currentElement.loc.end.line !== nextElement.loc.start.line;\n\n                if (!hasNewLine && needsNewlines) {\n                    context.report({\n                        node: currentElement,\n                        messageId: \"expectedBetween\",\n                        fix: fixer => fixer.insertTextBefore(nextElement, \"\\n\")\n                    });\n                }\n            }\n        }", "language": "javascript"}
{"input": "Create a SparseMatrix", "output": "def sparse(numRows, numCols, colPtrs, rowIndices, values):\n        \"\"\"\n        Create a SparseMatrix\n        \"\"\"\n        return SparseMatrix(numRows, numCols, colPtrs, rowIndices, values)", "language": "python"}
{"input": "Encode an output to JSON\n\n@param {Output}\n@return {Object}", "output": "function encodeOutputToJson(output) {\n    var book = output.getBook();\n    var generator = output.getGenerator();\n    var options = output.getOptions();\n\n    var result = encodeBook(book);\n\n    result.output = {\n        name: generator\n    };\n\n    result.options = options.toJS();\n\n    return result;\n}", "language": "javascript"}
{"input": "Convert falsy value in csv including `'', 'null', 'NULL', 'Null', 'NaN'` to `null`,\nso that type-analyzer won't detect it as string\n\n@param {Array<Array>} rows", "output": "function cleanUpFalsyCsvValue(rows) {\n  for (let i = 0; i < rows.length; i++) {\n    for (let j = 0; j < rows[i].length; j++) {\n      // analyzer will set any fields to 'string' if there are empty values\n      // which will be parsed as '' by d3.csv\n      // here we parse empty data as null\n      // TODO: create warning when deltect `CSV_NULLS` in the data\n      if (!rows[i][j] || CSV_NULLS.includes(rows[i][j])) {\n        rows[i][j] = null;\n      }\n    }\n  }\n}", "language": "javascript"}
{"input": "Synchronizes the current rules selection with the current selection preset\n@param {Array} aSelectedRulesPlain The plain list of selected rules (same format as in the presets json file)", "output": "function (aSelectedRulesPlain) {\n\t\t\tvar oPreset = this.model.getProperty(\"/selectionPresetsCurrent\");\n\n\t\t\toPreset.selections = aSelectedRulesPlain;\n\n\t\t\tif (!(oPreset.isModified || oPreset.isMySelection)) {\n\t\t\t\toPreset.isModified = true;\n\t\t\t\toPreset.title = oPreset.title + \" *\";\n\t\t\t}\n\n\t\t\tthis.model.setProperty(\"/selectionPresetsCurrent\", oPreset);\n\n\t\t\tif (PresetsUtils.isPersistingAllowed()) {\n\t\t\t\tPresetsUtils.persistSelectionPresets();\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Color Blending ref: http://www.w3.org/TR/compositing-1", "output": "function colorBlend(mode, color1, color2) {\n    var ab = color1.alpha, cb, // backdrop\n        as = color2.alpha, cs, // source\n        ar, cr, r = [];        // result\n\n    ar = as + ab * (1 - as);\n    for (var i = 0; i < 3; i++) {\n        cb = color1.rgb[i] / 255;\n        cs = color2.rgb[i] / 255;\n        cr = mode(cb, cs);\n        if (ar) {\n            cr = (as * cs + ab * (cb\n                - as * (cb + cs - cr))) / ar;\n        }\n        r[i] = cr * 255;\n    }\n\n    return new(tree.Color)(r, ar);\n}", "language": "javascript"}
{"input": "Creates a new inline Editor instance for the given Document.\nThe editor is not yet visible or attached to a host editor.\n@param {!Document} doc  Document for the Editor's content\n@param {?{startLine:Number, endLine:Number}} range  If specified, all lines outside the given\nrange are hidden from the editor. Range is inclusive. Line numbers start at 0.\n@param {HTMLDivContainer} inlineContent\n@param  {function(inlineWidget)} closeThisInline\n\n@return {{content:DOMElement, editor:Editor}}", "output": "function createInlineEditorForDocument(doc, range, inlineContent) {\n        // Hide the container for the editor before creating it so that CodeMirror doesn't do extra work\n        // when initializing the document. When we construct the editor, we have to set its text and then\n        // set the (small) visible range that we show in the editor. If the editor is visible, CM has to\n        // render a large portion of the document before setting the visible range. By hiding the editor\n        // first and showing it after the visible range is set, we avoid that initial render.\n        $(inlineContent).hide();\n        var inlineEditor = _createEditorForDocument(doc, false, inlineContent, range);\n        inlineEditor._hostEditor = getCurrentFullEditor();\n        $(inlineContent).show();\n\n        return { content: inlineContent, editor: inlineEditor };\n    }", "language": "javascript"}
{"input": "Case-insensitive scan of current elements only (do not descend).", "output": "function scanLevel(element) {\n        if (element) {\n          for (var i = 0, len = element.length; i < len; i++) {\n            if (element[i].nodeName.toLowerCase() === nodeName) {\n              return element[i];\n            }\n          }\n        }\n        return null;\n      }", "language": "javascript"}
{"input": "A special case for _generate_range_overflow_safe where `periods * stride`\n    can be calculated without overflowing int64 bounds.", "output": "def _generate_range_overflow_safe_signed(endpoint, periods, stride, side):\n    \"\"\"\n    A special case for _generate_range_overflow_safe where `periods * stride`\n    can be calculated without overflowing int64 bounds.\n    \"\"\"\n    assert side in ['start', 'end']\n    if side == 'end':\n        stride *= -1\n\n    with np.errstate(over=\"raise\"):\n        addend = np.int64(periods) * np.int64(stride)\n        try:\n            # easy case with no overflows\n            return np.int64(endpoint) + addend\n        except (FloatingPointError, OverflowError):\n            # with endpoint negative and addend positive we risk\n            #  FloatingPointError; with reversed signed we risk OverflowError\n            pass\n\n        # if stride and endpoint had opposite signs, then endpoint + addend\n        #  should never overflow.  so they must have the same signs\n        assert (stride > 0 and endpoint >= 0) or (stride < 0 and endpoint <= 0)\n\n        if stride > 0:\n            # watch out for very special case in which we just slightly\n            #  exceed implementation bounds, but when passing the result to\n            #  np.arange will get a result slightly within the bounds\n            assert endpoint >= 0\n            result = np.uint64(endpoint) + np.uint64(addend)\n            i64max = np.uint64(np.iinfo(np.int64).max)\n            assert result > i64max\n            if result <= i64max + np.uint64(stride):\n                return result\n\n    raise OutOfBoundsDatetime('Cannot generate range with '\n                              '{side}={endpoint} and '\n                              'periods={periods}'\n                              .format(side=side, endpoint=endpoint,\n                                      periods=periods))", "language": "python"}
{"input": "Returns a :class:`SparkJobInfo` object, or None if the job info\n        could not be found or was garbage collected.", "output": "def getJobInfo(self, jobId):\n        \"\"\"\n        Returns a :class:`SparkJobInfo` object, or None if the job info\n        could not be found or was garbage collected.\n        \"\"\"\n        job = self._jtracker.getJobInfo(jobId)\n        if job is not None:\n            return SparkJobInfo(jobId, job.stageIds(), str(job.status()))", "language": "python"}
{"input": "Generate pages from a list of .7z encoded history dumps.\n\n  Args:\n    corpus_files: a list of strings\n    tmp_dir: a string\n    max_page_size_exp: an integer\n\n  Yields:\n    strings", "output": "def corpus_page_generator(corpus_files, tmp_dir, max_page_size_exp):\n  \"\"\"Generate pages from a list of .7z encoded history dumps.\n\n  Args:\n    corpus_files: a list of strings\n    tmp_dir: a string\n    max_page_size_exp: an integer\n\n  Yields:\n    strings\n  \"\"\"\n  for remote_filepath in corpus_files:\n\n    filepath = maybe_copy_file_to_directory(remote_filepath, tmp_dir)\n    tf.logging.info(\"Reading from \" + filepath)\n\n    command = [\"7z\", \"x\", \"-so\", filepath]\n    tf.logging.info(\"Running command: %s\", command)\n\n    p = subprocess.Popen(command, stdout=subprocess.PIPE, bufsize=-1)\n\n    for page in file_page_generator(p.stdout, 2**max_page_size_exp):\n      yield page", "language": "python"}
{"input": "We check if our original element and the target is the backdrop because if the original was the backdrop and the target was inside the dialog we don't want to dialog to close.", "output": "function(ev) {\n          if (sourceElem === target[0] && ev.target === target[0]) {\n            ev.stopPropagation();\n            ev.preventDefault();\n\n            smartClose();\n          }\n        }", "language": "javascript"}
{"input": "When binding to the simulated event with prefix is done through jQuery, this function is called and redirect the registration to the original events. Doing in this way we can simulate the event from listening to the original events.", "output": "function(oHandle) {\n\t\t\t\tvar that = this,\n\t\t\t\t\t$this = jQuery(this),\n\t\t\t\t\toAdditionalConfig = {\n\t\t\t\t\t\tdomRef: that,\n\t\t\t\t\t\teventName: sSimEventName,\n\t\t\t\t\t\tsapEventName: sSapSimEventName,\n\t\t\t\t\t\teventHandle: oHandle\n\t\t\t\t\t};\n\n\t\t\t\tvar fnHandlerWrapper = function(oEvent) {\n\t\t\t\t\tfnHandler(oEvent, oAdditionalConfig);\n\t\t\t\t};\n\n\t\t\t\toHandle.__sapSimulatedEventHandler = fnHandlerWrapper;\n\t\t\t\tfor (var i = 0; i < aOrigEvents.length; i++) {\n\t\t\t\t\t$this.on(aOrigEvents[i], fnHandlerWrapper);\n\t\t\t\t}\n\t\t\t}", "language": "javascript"}
{"input": "+'s are replaced with spaces when used in query params, this returns them to +'s, then removes remaining whitespace. https://github.com/badges/shields/pull/1546", "output": "function decodeDataUrlFromQueryParam(value) {\n  if (typeof value !== 'string') {\n    return undefined\n  }\n  const maybeDataUrl = prependPrefix(value, 'data:')\n    .replace(/ /g, '+')\n    .replace(/\\s/g, '')\n  return isDataUrl(maybeDataUrl) ? maybeDataUrl : undefined\n}", "language": "javascript"}
{"input": "Given a :class:`~packaging.requirements.Requirement` instance with markers defining\n    *extra == 'name'*, strip out the extras from the markers and return the cleaned\n    requirement\n\n    :param PackagingRequirement req: A packaging requirement to clean\n    :return: A cleaned requirement\n    :rtype: PackagingRequirement", "output": "def strip_extras_markers_from_requirement(req):\n    # type: (TRequirement) -> TRequirement\n    \"\"\"\n    Given a :class:`~packaging.requirements.Requirement` instance with markers defining\n    *extra == 'name'*, strip out the extras from the markers and return the cleaned\n    requirement\n\n    :param PackagingRequirement req: A packaging requirement to clean\n    :return: A cleaned requirement\n    :rtype: PackagingRequirement\n    \"\"\"\n    if req is None:\n        raise TypeError(\"Must pass in a valid requirement, received {0!r}\".format(req))\n    if getattr(req, \"marker\", None) is not None:\n        marker = req.marker  # type: TMarker\n        marker._markers = _strip_extras_markers(marker._markers)\n        if not marker._markers:\n            req.marker = None\n        else:\n            req.marker = marker\n    return req", "language": "python"}
{"input": "/* =========================================================== /* lifecycle methods /* ===========================================================", "output": "function () {\n\t\t\t\tthis.oPage = this.byId(\"topicDetailPage\");\n\t\t\t\tthis.oPage.addStyleClass('docuPage');\n\n\t\t\t\tif ( !window.prettyPrint ) {\n\t\t\t\t\t//TODO: global jquery call found\n\t\t\t\t\tjQuery.sap.require(\"sap.ui.documentation.sdk.thirdparty.google-code-prettify.prettify\");\n\t\t\t\t}\n\n\t\t\t\tthis.getRouter().getRoute(\"topicId\").attachPatternMatched(this._onTopicMatched, this);\n\t\t\t\tthis._oConfig = this.getConfig();\n\n\t\t\t\tthis.jsonDefModel = new JSONModel();\n\t\t\t\tthis.getView().setModel(this.jsonDefModel);\n\t\t\t}", "language": "javascript"}
{"input": "Run calculations on pixel data.\n@param {Array} pixels List of pixels (one per source).\n@param {Object} data User data object.\n@return {Array} The output pixel.", "output": "function(pixels, data) {\n    const pixel = pixels[0];\n    const value = vgi(pixel);\n    summarize(value, data.counts);\n    if (value >= data.threshold) {\n      pixel[0] = 0;\n      pixel[1] = 255;\n      pixel[2] = 0;\n      pixel[3] = 128;\n    } else {\n      pixel[3] = 0;\n    }\n    return pixel;\n  }", "language": "javascript"}
{"input": "Reset cached properties. If ``key`` is passed, only clears that key.", "output": "def _reset_cache(self, key=None):\n        \"\"\"\n        Reset cached properties. If ``key`` is passed, only clears that key.\n        \"\"\"\n        if getattr(self, '_cache', None) is None:\n            return\n        if key is None:\n            self._cache.clear()\n        else:\n            self._cache.pop(key, None)", "language": "python"}
{"input": "Lex the given sourcecode and return a generator that yields\n        tokens as tuples in the form ``(lineno, token_type, value)``.\n        This can be useful for :ref:`extension development <writing-extensions>`\n        and debugging templates.\n\n        This does not perform preprocessing.  If you want the preprocessing\n        of the extensions to be applied you have to filter source through\n        the :meth:`preprocess` method.", "output": "def lex(self, source, name=None, filename=None):\n        \"\"\"Lex the given sourcecode and return a generator that yields\n        tokens as tuples in the form ``(lineno, token_type, value)``.\n        This can be useful for :ref:`extension development <writing-extensions>`\n        and debugging templates.\n\n        This does not perform preprocessing.  If you want the preprocessing\n        of the extensions to be applied you have to filter source through\n        the :meth:`preprocess` method.\n        \"\"\"\n        source = text_type(source)\n        try:\n            return self.lexer.tokeniter(source, name, filename)\n        except TemplateSyntaxError:\n            exc_info = sys.exc_info()\n        self.handle_exception(exc_info, source_hint=source)", "language": "python"}
{"input": "Determines whether a predicate expression contains a \"positional selector\".\nA positional selector filters nodes from the nodelist input based on their\nposition within that list. When such selectors are encountered, the\nevaluation of the predicate cannot be depth-first, because the positional\nselector may be based on the result of evaluating predicates that precede\nit.", "output": "function predicateExprHasPositionalSelector(expr, isRecursiveCall) {\n  if (!expr) {\n    return false;\n  }\n  if (!isRecursiveCall && exprReturnsNumberValue(expr)) {\n    // this is a \"proximity position\"-based predicate\n    return true;\n  }\n  if (expr instanceof FunctionCallExpr) {\n    var value = expr.name.value;\n    return (value == 'last' || value == 'position');\n  }\n  if (expr instanceof BinaryExpr) {\n    return (\n      predicateExprHasPositionalSelector(expr.expr1, true) ||\n      predicateExprHasPositionalSelector(expr.expr2, true));\n  }\n  return false;\n}", "language": "javascript"}
{"input": "Loop over provided script tags and get the content, via innerHTML if an\ninline script, or by using XHR. Transforms are applied if needed. The scripts\nare executed in the order they are found on the page.", "output": "function loadScripts(transformFn, scripts) {\n  const result = [];\n  const count = scripts.length;\n\n  function check() {\n    let script, i;\n\n    for (i = 0; i < count; i++) {\n      script = result[i];\n\n      if (script.loaded && !script.executed) {\n        script.executed = true;\n        run(transformFn, script);\n      } else if (!script.loaded && !script.error && !script.async) {\n        break;\n      }\n    }\n  }\n\n  scripts.forEach((script, i) => {\n    const scriptData = {\n      // script.async is always true for non-JavaScript script tags\n      async: script.hasAttribute(\"async\"),\n      error: false,\n      executed: false,\n      plugins: getPluginsOrPresetsFromScript(script, \"data-plugins\"),\n      presets: getPluginsOrPresetsFromScript(script, \"data-presets\"),\n    };\n\n    if (script.src) {\n      result[i] = {\n        ...scriptData,\n        content: null,\n        loaded: false,\n        url: script.src,\n      };\n\n      load(\n        script.src,\n        content => {\n          result[i].loaded = true;\n          result[i].content = content;\n          check();\n        },\n        () => {\n          result[i].error = true;\n          check();\n        },\n      );\n    } else {\n      result[i] = {\n        ...scriptData,\n        content: script.innerHTML,\n        loaded: true,\n        url: script.getAttribute(\"data-module\") || null,\n      };\n    }\n  });\n\n  check();\n}", "language": "javascript"}
{"input": "Check if an URI is bookmarked within the specified folder\n\n@param (nsIURI) uri\nURI of the bookmark\n@param {String} folderId\nFolder in which the search has to take place\n@return Returns if the URI exists in the given folder\n@type Boolean", "output": "function isBookmarkInFolder(uri, folderId)\n{\n  var ids = bookmarksService.getBookmarkIdsForURI(uri, {});\n  for (let i = 0; i < ids.length; i++) {\n    if (bookmarksService.getFolderIdForItem(ids[i]) == folderId)\n      return true;\n  }\n\n  return false;\n}", "language": "javascript"}
{"input": "Convert a ctypes int pointer array to a numpy array.", "output": "def cint8_array_to_numpy(cptr, length):\n    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int8)):\n        return np.fromiter(cptr, dtype=np.int8, count=length)\n    else:\n        raise RuntimeError('Expected int pointer')", "language": "python"}
{"input": "Hack to hide noise generated by `setup.py develop`.\n\n    There isn't a good way to suppress them now, so let's monky-patch.\n    See https://bugs.python.org/issue25392.", "output": "def _suppress_distutils_logs():\n    \"\"\"Hack to hide noise generated by `setup.py develop`.\n\n    There isn't a good way to suppress them now, so let's monky-patch.\n    See https://bugs.python.org/issue25392.\n    \"\"\"\n    f = distutils.log.Log._log\n\n    def _log(log, level, msg, args):\n        if level >= distutils.log.ERROR:\n            f(log, level, msg, args)\n\n    distutils.log.Log._log = _log\n    yield\n    distutils.log.Log._log = f", "language": "python"}
{"input": "Constructor for BezierCurveEditor Object. This control may be used standalone\nor within an InlineTimingFunctionEditor inline widget.\n\n@param {!jQuery} $parent  DOM node into which to append the root of the bezier curve editor UI\n@param {!RegExpMatch} bezierCurve  RegExp match object of initially selected bezierCurve\n@param {!function(string)} callback  Called whenever selected bezierCurve changes", "output": "function BezierCurveEditor($parent, bezierCurve, callback) {\n        // Create the DOM structure, filling in localized strings via Mustache\n        this.$element = $(Mustache.render(BezierCurveEditorTemplate, Strings));\n        $parent.append(this.$element);\n\n        this._callback = callback;\n        this.dragElement = null;\n\n        // current cubic-bezier() function params\n        this._cubicBezierCoords = this._getCubicBezierCoords(bezierCurve);\n\n        this.hint = {};\n        this.hint.elem = $(\".hint\", this.$element);\n        // If function was auto-corrected, then originalString holds the original function,\n        // and an informational message needs to be shown\n        if (bezierCurve.originalString) {\n            TimingFunctionUtils.showHideHint(this.hint, true, bezierCurve.originalString, \"cubic-bezier(\" + this._cubicBezierCoords.join(\", \") + \")\");\n        } else {\n            TimingFunctionUtils.showHideHint(this.hint, false);\n        }\n\n        this.P1 = this.$element.find(\".P1\")[0];\n        this.P2 = this.$element.find(\".P2\")[0];\n        this.curve = this.$element.find(\".curve\")[0];\n\n        this.P1.bezierEditor = this.P2.bezierEditor = this.curve.bezierEditor = this;\n\n        this.bezierCanvas = new BezierCanvas(this.curve, null, [0, 0]);\n\n        // redraw canvas\n        this._updateCanvas();\n\n        $(this.curve)\n            .on(\"click\", _curveClick)\n            .on(\"mousemove\", _curveMouseMove);\n        $(this.P1)\n            .on(\"mousemove\", _pointMouseMove)\n            .on(\"mousedown\", _pointMouseDown)\n            .on(\"mouseup\", _pointMouseUp)\n            .on(\"keydown\", _pointKeyDown);\n        $(this.P2)\n            .on(\"mousemove\", _pointMouseMove)\n            .on(\"mousedown\", _pointMouseDown)\n            .on(\"mouseup\", _pointMouseUp)\n            .on(\"keydown\", _pointKeyDown);\n    }", "language": "javascript"}
{"input": "Test program for verifying this files functionality.", "output": "def main():\n    \"\"\"Test program for verifying this files functionality.\"\"\"\n    global __verbose\n    # Parse CMD args\n    parser = argparse.ArgumentParser(description='DFU Python Util')\n    #parser.add_argument(\"path\", help=\"file path\")\n    parser.add_argument(\n        \"-l\", \"--list\",\n        help=\"list available DFU devices\",\n        action=\"store_true\",\n        default=False\n    )\n    parser.add_argument(\n        \"-m\", \"--mass-erase\",\n        help=\"mass erase device\",\n        action=\"store_true\",\n        default=False\n    )\n    parser.add_argument(\n        \"-u\", \"--upload\",\n        help=\"read file from DFU device\",\n        dest=\"path\",\n        default=False\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\",\n        help=\"increase output verbosity\",\n        action=\"store_true\",\n        default=False\n    )\n    args = parser.parse_args()\n\n    __verbose = args.verbose\n\n    if args.list:\n        list_dfu_devices(idVendor=__VID, idProduct=__PID)\n        return\n\n    init()\n\n    if args.mass_erase:\n        print (\"Mass erase...\")\n        mass_erase()\n\n    if args.path:\n        elements = read_dfu_file(args.path)\n        if not elements:\n            return\n        print(\"Writing memory...\")\n        write_elements(elements, args.mass_erase, progress=cli_progress)\n\n        print(\"Exiting DFU...\")\n        exit_dfu()\n        return\n\n    print(\"No command specified\")", "language": "python"}
{"input": "Get the next or previous file in the working set, in MRU order (relative to currentDocument). May\nreturn currentDocument itself if working set is length 1.\n@deprecated use MainViewManager.traverseToNextViewByMRU() instead", "output": "function getNextPrevFile(inc) {\n        DeprecationWarning.deprecationWarning(\"Use MainViewManager.traverseToNextViewByMRU() instead of DocumentManager.getNextPrevFile()\", true);\n        var result = MainViewManager.traverseToNextViewByMRU(inc);\n        if (result) {\n            return result.file;\n        }\n        return null;\n    }", "language": "javascript"}
{"input": "Grabs all fields in the dialog and puts them in key=>value style in an object which\nthen gets returned", "output": "function() {\n      var data    = this.elementToChange || {},\n          fields  = this.container.querySelectorAll(SELECTOR_FIELDS),\n          length  = fields.length,\n          i       = 0;\n\n      for (; i<length; i++) {\n        data[fields[i].getAttribute(ATTRIBUTE_FIELDS)] = fields[i].value;\n      }\n      return data;\n    }", "language": "javascript"}
{"input": "Start a new kernel, and return its Manager and Client", "output": "def start_new_kernel(startup_timeout=60, kernel_name='python', **kwargs):\n    \"\"\"Start a new kernel, and return its Manager and Client\"\"\"\n    logger.debug('Starting new kernel: \"%s\"' % kernel_name)\n    km = KernelManager(kernel_name=kernel_name,\n                       kernel_spec_manager=NbvalKernelspecManager())\n    km.start_kernel(**kwargs)\n    kc = km.client()\n    kc.start_channels()\n    try:\n        kc.wait_for_ready(timeout=startup_timeout)\n    except RuntimeError:\n        logger.exception('Failure starting kernel \"%s\"', kernel_name)\n        kc.stop_channels()\n        km.shutdown_kernel()\n        raise\n\n    return km, kc", "language": "python"}
{"input": "Return a list of installed Distribution objects.\n\n    If ``local_only`` is True (default), only return installations\n    local to the current virtualenv, if in a virtualenv.\n\n    ``skip`` argument is an iterable of lower-case project names to\n    ignore; defaults to stdlib_pkgs\n\n    If ``include_editables`` is False, don't report editables.\n\n    If ``editables_only`` is True , only report editables.\n\n    If ``user_only`` is True , only report installations in the user\n    site directory.", "output": "def get_installed_distributions(local_only=True,\n                                skip=stdlib_pkgs,\n                                include_editables=True,\n                                editables_only=False,\n                                user_only=False):\n    # type: (bool, Container[str], bool, bool, bool) -> List[Distribution]\n    \"\"\"\n    Return a list of installed Distribution objects.\n\n    If ``local_only`` is True (default), only return installations\n    local to the current virtualenv, if in a virtualenv.\n\n    ``skip`` argument is an iterable of lower-case project names to\n    ignore; defaults to stdlib_pkgs\n\n    If ``include_editables`` is False, don't report editables.\n\n    If ``editables_only`` is True , only report editables.\n\n    If ``user_only`` is True , only report installations in the user\n    site directory.\n\n    \"\"\"\n    if local_only:\n        local_test = dist_is_local\n    else:\n        def local_test(d):\n            return True\n\n    if include_editables:\n        def editable_test(d):\n            return True\n    else:\n        def editable_test(d):\n            return not dist_is_editable(d)\n\n    if editables_only:\n        def editables_only_test(d):\n            return dist_is_editable(d)\n    else:\n        def editables_only_test(d):\n            return True\n\n    if user_only:\n        user_test = dist_in_usersite\n    else:\n        def user_test(d):\n            return True\n\n    # because of pkg_resources vendoring, mypy cannot find stub in typeshed\n    return [d for d in pkg_resources.working_set  # type: ignore\n            if local_test(d) and\n            d.key not in skip and\n            editable_test(d) and\n            editables_only_test(d) and\n            user_test(d)\n            ]", "language": "python"}
{"input": "Identifies the best prediction given the results from the submodels.\n\n    Parameters\n    ----------\n    subresults : List[Dict[str, torch.Tensor]]\n        Results of each submodel.\n\n    Returns\n    -------\n    The index of the best submodel.", "output": "def ensemble(subresults: List[Dict[str, torch.Tensor]]) -> torch.Tensor:\n    \"\"\"\n    Identifies the best prediction given the results from the submodels.\n\n    Parameters\n    ----------\n    subresults : List[Dict[str, torch.Tensor]]\n        Results of each submodel.\n\n    Returns\n    -------\n    The index of the best submodel.\n    \"\"\"\n\n    # Choose the highest average confidence span.\n\n    span_start_probs = sum(subresult['span_start_probs'] for subresult in subresults) / len(subresults)\n    span_end_probs = sum(subresult['span_end_probs'] for subresult in subresults) / len(subresults)\n    return get_best_span(span_start_probs.log(), span_end_probs.log())", "language": "python"}
{"input": "Evaluates the given `inputs` sequentially and returns the first defined value.\n@param {Array} inputs - An array of values, falling back to the last value.\n@param {object} [context] - If defined and the current value is a function, the value\nis called with `context` as first argument and the result becomes the new input.\n@param {number} [index] - If defined and the current value is an array, the value\nat `index` become the new input.\n@since 2.7.0", "output": "function(inputs, context, index) {\n\t\tvar i, ilen, value;\n\n\t\tfor (i = 0, ilen = inputs.length; i < ilen; ++i) {\n\t\t\tvalue = inputs[i];\n\t\t\tif (value === undefined) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (context !== undefined && typeof value === 'function') {\n\t\t\t\tvalue = value(context);\n\t\t\t}\n\t\t\tif (index !== undefined && helpers_core.isArray(value)) {\n\t\t\t\tvalue = value[index];\n\t\t\t}\n\t\t\tif (value !== undefined) {\n\t\t\t\treturn value;\n\t\t\t}\n\t\t}\n\t}", "language": "javascript"}
{"input": "/* Attach the date picker to a jQuery selection.\n@param  target\telement - the target input field or division or span\n@param  settings  object - the new settings to use for this date picker instance (anonymous)", "output": "function(target, settings) {\n\t\tvar nodeName, inline, inst;\n\t\tnodeName = target.nodeName.toLowerCase();\n\t\tinline = (nodeName === \"div\" || nodeName === \"span\");\n\t\tif (!target.id) {\n\t\t\tthis.uuid += 1;\n\t\t\ttarget.id = \"dp\" + this.uuid;\n\t\t}\n\t\tinst = this._newInst($(target), inline);\n\t\tinst.settings = $.extend({}, settings || {});\n\t\tif (nodeName === \"input\") {\n\t\t\tthis._connectDatepicker(target, inst);\n\t\t} else if (inline) {\n\t\t\tthis._inlineDatepicker(target, inst);\n\t\t}\n\t}", "language": "javascript"}
{"input": "Checks if the next token of a given token is a closing parenthesis.\n@param {Token} token The token to check.\n@returns {boolean} Whether or not the next token of a given token is a closing parenthesis.", "output": "function isBeforeClosingParen(token) {\n            const nextToken = sourceCode.getTokenAfter(token);\n\n            return (nextToken && astUtils.isClosingBraceToken(nextToken) || astUtils.isClosingParenToken(nextToken));\n        }", "language": "javascript"}
{"input": "Previewer constructor\n@param {string} type Unique previewer type\n@param {function} updater Function that will be called on mouseover.\n@param {string[]|string=} supportedLanguages Aliases of the languages this previewer must be enabled for. Defaults to \"*\", all languages.\n@param {function=} initializer Function that will be called on initialization.\n@constructor", "output": "function (type, updater, supportedLanguages, initializer) {\n\t\tthis._elt = null;\n\t\tthis._type = type;\n\t\tthis._clsRegexp = RegExp('(?:^|\\\\s)' + type + '(?=$|\\\\s)');\n\t\tthis._token = null;\n\t\tthis.updater = updater;\n\t\tthis._mouseout = this.mouseout.bind(this);\n\t\tthis.initializer = initializer;\n\n\t\tvar self = this;\n\n\t\tif (!supportedLanguages) {\n\t\t\tsupportedLanguages = ['*'];\n\t\t}\n\t\tif (!Array.isArray(supportedLanguages)) {\n\t\t\tsupportedLanguages = [supportedLanguages];\n\t\t}\n\t\tsupportedLanguages.forEach(function (lang) {\n\t\t\tif (typeof lang !== 'string') {\n\t\t\t\tlang = lang.lang;\n\t\t\t}\n\t\t\tif (!Previewer.byLanguages[lang]) {\n\t\t\t\tPreviewer.byLanguages[lang] = [];\n\t\t\t}\n\t\t\tif (Previewer.byLanguages[lang].indexOf(self) < 0) {\n\t\t\t\tPreviewer.byLanguages[lang].push(self);\n\t\t\t}\n\t\t});\n\t\tPreviewer.byType[type] = this;\n\t}", "language": "javascript"}
{"input": "check if overlap with any gt box is larger than threshold", "output": "def _check_satisfy(self, rand_box, gt_boxes):\n        \"\"\"\n        check if overlap with any gt box is larger than threshold\n        \"\"\"\n        l, t, r, b = rand_box\n        num_gt = gt_boxes.shape[0]\n        ls = np.ones(num_gt) * l\n        ts = np.ones(num_gt) * t\n        rs = np.ones(num_gt) * r\n        bs = np.ones(num_gt) * b\n        mask = np.where(ls < gt_boxes[:, 1])[0]\n        ls[mask] = gt_boxes[mask, 1]\n        mask = np.where(ts < gt_boxes[:, 2])[0]\n        ts[mask] = gt_boxes[mask, 2]\n        mask = np.where(rs > gt_boxes[:, 3])[0]\n        rs[mask] = gt_boxes[mask, 3]\n        mask = np.where(bs > gt_boxes[:, 4])[0]\n        bs[mask] = gt_boxes[mask, 4]\n        w = rs - ls\n        w[w < 0] = 0\n        h = bs - ts\n        h[h < 0] = 0\n        inter_area = h * w\n        union_area = np.ones(num_gt) * max(0, r - l) * max(0, b - t)\n        union_area += (gt_boxes[:, 3] - gt_boxes[:, 1]) * (gt_boxes[:, 4] - gt_boxes[:, 2])\n        union_area -= inter_area\n        ious = inter_area / union_area\n        ious[union_area <= 0] = 0\n        max_iou = np.amax(ious)\n        if max_iou < self.min_overlap:\n            return None\n        # check ground-truth constraint\n        if self.config['gt_constraint'] == 'center':\n            for i in range(ious.shape[0]):\n                if ious[i] > 0:\n                    gt_x = (gt_boxes[i, 1] + gt_boxes[i, 3]) / 2.0\n                    gt_y = (gt_boxes[i, 2] + gt_boxes[i, 4]) / 2.0\n                    if gt_x < l or gt_x > r or gt_y < t or gt_y > b:\n                        return None\n        elif self.config['gt_constraint'] == 'corner':\n            for i in range(ious.shape[0]):\n                if ious[i] > 0:\n                    if gt_boxes[i, 1] < l or gt_boxes[i, 3] > r \\\n                        or gt_boxes[i, 2] < t or gt_boxes[i, 4] > b:\n                        return None\n        return ious", "language": "python"}
{"input": "\"Go to front/back\" Block.\n@this Blockly.Block", "output": "function() {\n    this.jsonInit({\n      \"message0\": Blockly.Msg.LOOKS_GOTOFRONTBACK,\n      \"args0\": [\n        {\n          \"type\": \"field_dropdown\",\n          \"name\": \"FRONT_BACK\",\n          \"options\": [\n            [Blockly.Msg.LOOKS_GOTOFRONTBACK_FRONT, 'front'],\n            [Blockly.Msg.LOOKS_GOTOFRONTBACK_BACK, 'back']\n          ]\n        }\n      ],\n      \"category\": Blockly.Categories.looks,\n      \"extensions\": [\"colours_looks\", \"shape_statement\"]\n    });\n  }", "language": "javascript"}
{"input": "Reformats the query into the create table as query.\n\n        Works only for the single select SQL statements, in all other cases\n        the sql query is not modified.\n        :param superset_query: string, sql query that will be executed\n        :param table_name: string, will contain the results of the\n            query execution\n        :param overwrite, boolean, table table_name will be dropped if true\n        :return: string, create table as query", "output": "def as_create_table(self, table_name, overwrite=False):\n        \"\"\"Reformats the query into the create table as query.\n\n        Works only for the single select SQL statements, in all other cases\n        the sql query is not modified.\n        :param superset_query: string, sql query that will be executed\n        :param table_name: string, will contain the results of the\n            query execution\n        :param overwrite, boolean, table table_name will be dropped if true\n        :return: string, create table as query\n        \"\"\"\n        exec_sql = ''\n        sql = self.stripped()\n        if overwrite:\n            exec_sql = f'DROP TABLE IF EXISTS {table_name};\\n'\n        exec_sql += f'CREATE TABLE {table_name} AS \\n{sql}'\n        return exec_sql", "language": "python"}
{"input": "Potentially wrap any results.", "output": "def _wrap_result(self, result):\n        \"\"\"\n        Potentially wrap any results.\n        \"\"\"\n        if isinstance(result, ABCSeries) and self._selection is not None:\n            result.name = self._selection\n\n        if isinstance(result, ABCSeries) and result.empty:\n            obj = self.obj\n            if isinstance(obj.index, PeriodIndex):\n                result.index = obj.index.asfreq(self.freq)\n            else:\n                result.index = obj.index._shallow_copy(freq=self.freq)\n            result.name = getattr(obj, 'name', None)\n\n        return result", "language": "python"}
{"input": "Enhance raw values to represent valid css stylings...", "output": "function(raw) {\n      var css = { };\n      var lookups = 'left top right bottom width height x y min-width min-height max-width max-height';\n\n      angular.forEach(raw, function(value,key) {\n        if (angular.isUndefined(value)) return;\n\n        if (lookups.indexOf(key) >= 0) {\n          css[key] = value + 'px';\n        } else {\n          switch (key) {\n            case 'transition':\n              convertToVendor(key, $mdConstant.CSS.TRANSITION, value);\n              break;\n            case 'transform':\n              convertToVendor(key, $mdConstant.CSS.TRANSFORM, value);\n              break;\n            case 'transformOrigin':\n              convertToVendor(key, $mdConstant.CSS.TRANSFORM_ORIGIN, value);\n              break;\n            case 'font-size':\n              css['font-size'] = value; // font sizes aren't always in px\n              break;\n          }\n        }\n      });\n\n      return css;\n\n      function convertToVendor(key, vendor, value) {\n        angular.forEach(vendor.split(' '), function (key) {\n          css[key] = value;\n        });\n      }\n    }", "language": "javascript"}
{"input": "Sends a key press only, without releasing it.\n           Should only be used with modifier keys (Control, Alt and Shift).\n\n        :Args:\n         - value: The modifier key to send. Values are defined in `Keys` class.\n         - element: The element to send keys.\n           If None, sends a key to current focused element.\n\n        Example, pressing ctrl+c::\n\n            ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()", "output": "def key_down(self, value, element=None):\n        \"\"\"\n        Sends a key press only, without releasing it.\n           Should only be used with modifier keys (Control, Alt and Shift).\n\n        :Args:\n         - value: The modifier key to send. Values are defined in `Keys` class.\n         - element: The element to send keys.\n           If None, sends a key to current focused element.\n\n        Example, pressing ctrl+c::\n\n            ActionChains(driver).key_down(Keys.CONTROL).send_keys('c').key_up(Keys.CONTROL).perform()\n\n        \"\"\"\n        if element:\n            self.click(element)\n        if self._driver.w3c:\n            self.w3c_actions.key_action.key_down(value)\n            self.w3c_actions.pointer_action.pause()\n        else:\n            self._actions.append(lambda: self._driver.execute(\n                Command.SEND_KEYS_TO_ACTIVE_ELEMENT,\n                {\"value\": keys_to_typing(value)}))\n        return self", "language": "python"}
{"input": "Function will get element by id starting from specified node.\nAuthor: Renato Bebi\u0107 <renato.bebic@gmail.com>\n\nThe material getter below borked if there is e.g. a scene node with the same name as the material.\nThis is used to fix that by only looking for materials in the library_materials element.", "output": "function getChildElementById( dNode, id ) {\n\n\tvar dResult = null;\n\n\tif ( dNode.getAttribute('id') == id )\n\t\treturn dNode;\n\n\tfor ( var i = 0; i < dNode.childNodes.length; i++ ) {\n\t\tif ( dNode.childNodes[i].nodeType == 1 ) {\n                        dResult = getChildElementById( dNode.childNodes[i], id ); //note: 1-level deep would suffice here, doesn't need to recurse into further childs. but this works.\n                        if ( dResult != null )\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn dResult;\n}", "language": "javascript"}
{"input": "Strips everything after the first <EOS> token, which is normally 1.", "output": "def _save_until_eos(ids, skip=False):\n  \"\"\"Strips everything after the first <EOS> token, which is normally 1.\"\"\"\n  ids = ids.flatten()\n  if skip:\n    return ids\n  try:\n    index = list(ids).index(text_encoder.EOS_ID)\n    return ids[0:index]\n  except ValueError:\n    # No EOS_ID: return the array as-is.\n    return ids", "language": "python"}
{"input": "check if text resembles a number", "output": "def like_num(text):\n    \"\"\"\n    check if text resembles a number\n    \"\"\"\n    text = (\n        text.replace(\",\", \"\")\n        .replace(\".\", \"\")\n        .replace(\"\u060c\", \"\")\n        .replace(\"\u066b\", \"\")\n        .replace(\"/\", \"\")\n    )\n    if text.isdigit():\n        return True\n    if text in _num_words:\n        return True\n    if text in _ordinal_words:\n        return True\n    return False", "language": "python"}
{"input": "Comparison function used for sorting that does a case-insensitive string comparison on the \"value\" field of both objects. Unlike a normal string comparison, however, this sorts leading \"_\" to the bottom, given that a leading \"_\" usually denotes a private value.", "output": "function penalizeUnderscoreValueCompare(a, b) {\n        var aName = a.value.toLowerCase(), bName = b.value.toLowerCase();\n        // this sort function will cause _ to sort lower than lower case\n        // alphabetical letters\n        if (aName[0] === \"_\" && bName[0] !== \"_\") {\n            return 1;\n        } else if (bName[0] === \"_\" && aName[0] !== \"_\") {\n            return -1;\n        }\n        if (aName < bName) {\n            return -1;\n        } else if (aName > bName) {\n            return 1;\n        }\n        return 0;\n    }", "language": "javascript"}
{"input": "Compute the length of each sequence in the batch.\n\n  Args:\n    emb: a sequence embedding Tensor with shape [batch, max_time, 1, depth].\n  Returns:\n    a Tensor with shape [batch].", "output": "def length_from_embedding(emb):\n  \"\"\"Compute the length of each sequence in the batch.\n\n  Args:\n    emb: a sequence embedding Tensor with shape [batch, max_time, 1, depth].\n  Returns:\n    a Tensor with shape [batch].\n  \"\"\"\n  return tf.cast(tf.reduce_sum(mask_from_embedding(emb), [1, 2, 3]), tf.int32)", "language": "python"}
{"input": "### Model Query\nMake the call to the Model layer\n@param {Object} options\n@returns {Object} options", "output": "function modelQuery(options) {\n            return models.Post.edit(options.data.posts[0], omit(options, ['data']))\n                .then((model) => {\n                    if (!model) {\n                        return Promise.reject(new common.errors.NotFoundError({\n                            message: common.i18n.t('errors.api.posts.postNotFound')\n                        }));\n                    }\n\n                    const post = urlsForPost(model.id, model.toJSON(options), options);\n\n                    // If previously was not published and now is (or vice versa), signal the change\n                    // @TODO: `statusChanged` get's added for the API headers only. Reconsider this.\n                    post.statusChanged = false;\n                    if (model.previous('status') !== model.get('status')) {\n                        post.statusChanged = true;\n                    }\n\n                    return {\n                        posts: [post]\n                    };\n                });\n        }", "language": "javascript"}
{"input": "Replace word repetitions in `t`.", "output": "def replace_wrep(t:str) -> str:\n    \"Replace word repetitions in `t`.\"\n    def _replace_wrep(m:Collection[str]) -> str:\n        c,cc = m.groups()\n        return f' {TK_WREP} {len(cc.split())+1} {c} '\n    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n    return re_wrep.sub(_replace_wrep, t)", "language": "python"}
{"input": "Returns the currency code which is corresponded with the given currency symbol.\n\n@param {string} sCurrencySymbol The currency symbol which needs to be converted to currency code\n@return {string} The corresponded currency code defined for the given currency symbol. The given currency symbol is returned if no currency code can be found by using the given currency symbol.\n@public\n@since 1.27.0", "output": "function(sCurrencySymbol) {\n\t\t\tvar oCurrencySymbols = this._get(\"currencySymbols\"), sCurrencyCode;\n\t\t\tfor (sCurrencyCode in oCurrencySymbols) {\n\t\t\t\tif (oCurrencySymbols[sCurrencyCode] === sCurrencySymbol) {\n\t\t\t\t\treturn sCurrencyCode;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sCurrencySymbol;\n\t\t}", "language": "javascript"}
{"input": "Extract pages from an xml dump.\n\n  Args:\n    dump: a unicode string\n  Returns:\n    a list of unicode strings", "output": "def _dump_to_pages(dump):\n  \"\"\"Extract pages from an xml dump.\n\n  Args:\n    dump: a unicode string\n  Returns:\n    a list of unicode strings\n  \"\"\"\n  pos = 0\n  ret = []\n  start_tag = u\"<page>\\n\"\n  end_tag = u\"</page>\\n\"\n  while True:\n    start_pos = dump.find(start_tag, pos)\n    if start_pos == -1:\n      break\n    start_pos += len(start_tag)\n    end_pos = dump.find(end_tag, start_pos)\n    if end_pos == -1:\n      break\n    ret.append(dump[start_pos:end_pos])\n    pos = end_pos + len(end_tag)\n  return ret", "language": "python"}
{"input": "arr0 is source array, arr1 is target array. Do some preprocess to avoid error happened when interpolating from arr0 to arr1", "output": "function fillArr(arr0, arr1, arrDim) {\n    var arr0Len = arr0.length;\n    var arr1Len = arr1.length;\n    if (arr0Len !== arr1Len) {\n        // FIXME Not work for TypedArray\n        var isPreviousLarger = arr0Len > arr1Len;\n        if (isPreviousLarger) {\n            // Cut the previous\n            arr0.length = arr1Len;\n        }\n        else {\n            // Fill the previous\n            for (var i = arr0Len; i < arr1Len; i++) {\n                arr0.push(\n                    arrDim === 1 ? arr1[i] : arraySlice.call(arr1[i])\n                );\n            }\n        }\n    }\n    // Handling NaN value\n    var len2 = arr0[0] && arr0[0].length;\n    for (var i = 0; i < arr0.length; i++) {\n        if (arrDim === 1) {\n            if (isNaN(arr0[i])) {\n                arr0[i] = arr1[i];\n            }\n        }\n        else {\n            for (var j = 0; j < len2; j++) {\n                if (isNaN(arr0[i][j])) {\n                    arr0[i][j] = arr1[i][j];\n                }\n            }\n        }\n    }\n}", "language": "javascript"}
{"input": "Checks and handles the update success and failure scenarios", "output": "function checkUpdateStatus() {\n        var filesToCache = ['.logs'],\n            downloadCompleted = updateJsonHandler.get(\"downloadCompleted\"),\n            updateInitiatedInPrevSession = updateJsonHandler.get(\"updateInitiatedInPrevSession\");\n\n        if (downloadCompleted && updateInitiatedInPrevSession) {\n            var isNewVersion = checkIfVersionUpdated();\n            updateJsonHandler.reset();\n            if (isNewVersion) {\n                // We get here if the update was successful\n                UpdateInfoBar.showUpdateBar({\n                    type: \"success\",\n                    title: Strings.UPDATE_SUCCESSFUL,\n                    description: \"\"\n                });\n                HealthLogger.sendAnalyticsData(\n                    autoUpdateEventNames.AUTOUPDATE_INSTALLATION_SUCCESS,\n                    \"autoUpdate\",\n                    \"install\",\n                    \"complete\",\n                    \"\"\n                );\n            } else {\n                // We get here if the update started but failed\n                checkInstallationStatus();\n                UpdateInfoBar.showUpdateBar({\n                    type: \"error\",\n                    title: Strings.UPDATE_FAILED,\n                    description: Strings.GO_TO_SITE\n                });\n            }\n        } else if (downloadCompleted && !updateInitiatedInPrevSession) {\n            // We get here if the download was complete and user selected UpdateLater\n            if (brackets.platform === \"mac\") {\n                filesToCache = ['.dmg', '.json'];\n            } else if (brackets.platform === \"win\") {\n                filesToCache = ['.msi', '.json'];\n            }\n        }\n\n        postMessageToNode(MessageIds.PERFORM_CLEANUP, filesToCache);\n    }", "language": "javascript"}
{"input": "Resolve the root folder containing for node_modules\nsince gitbook can be used as a library and dependency can be flattened.\n\n@return {String} folderPath", "output": "function locateRootFolder() {\n    var firstDefaultPlugin = DEFAULT_PLUGINS.first();\n    var pluginPath = resolve.sync(firstDefaultPlugin.getNpmID() + '/package.json', {\n        basedir: __dirname\n    });\n    var nodeModules = path.resolve(pluginPath, '../../..');\n\n    return nodeModules;\n}", "language": "javascript"}
{"input": "Function: relativeCcw\n\nReturns 1 if the given point on the right side of the segment, 0 if its\non the segment, and -1 if the point is on the left side of the segment.\n\nParameters:\n\nx1 - X-coordinate of the startpoint of the segment.\ny1 - Y-coordinate of the startpoint of the segment.\nx2 - X-coordinate of the endpoint of the segment.\ny2 - Y-coordinate of the endpoint of the segment.\npx - X-coordinate of the point.\npy - Y-coordinate of the point.", "output": "function(x1, y1, x2, y2, px, py)\n    {\n\t\tx2 -= x1;\n\t\ty2 -= y1;\n\t\tpx -= x1;\n\t\tpy -= y1;\n\t\tvar ccw = px * y2 - py * x2;\n\t\t\n\t\tif (ccw == 0.0)\n\t\t{\n\t\t    ccw = px * x2 + py * y2;\n\t\t    \n\t\t    if (ccw > 0.0)\n\t\t    {\n\t\t\t\tpx -= x2;\n\t\t\t\tpy -= y2;\n\t\t\t\tccw = px * x2 + py * y2;\n\t\t\t\t\n\t\t\t\tif (ccw < 0.0)\n\t\t\t\t{\n\t\t\t\t    ccw = 0.0;\n\t\t\t\t}\n\t\t    }\n\t\t}\n\t\t\n\t\treturn (ccw < 0.0) ? -1 : ((ccw > 0.0) ? 1 : 0);\n    }", "language": "javascript"}
{"input": "========================================================================= Write", "output": "function(zip, model) {\n    return PromishLib.Promish.all(model.media.map(function(medium) {\n      if (medium.type === 'image') {\n        var filename = 'xl/media/' + medium.name + '.' + medium.extension;\n        if (medium.filename) {\n          return fsReadFileAsync(medium.filename)\n            .then(function(data) {\n              zip.append(data, {name: filename});\n            });\n        }\n        if (medium.buffer) {\n          return new PromishLib.Promish(function(resolve) {\n            zip.append(medium.buffer, {name: filename});\n            resolve();\n          });\n        }\n        if (medium.base64) {\n          return new PromishLib.Promish(function(resolve) {\n            var dataimg64 = medium.base64;\n            var content = dataimg64.substring(dataimg64.indexOf(',') + 1);\n            zip.append(content, { name: filename, base64: true });\n            resolve();\n          });\n        }\n      }\n      return PromishLib.Promish.reject(new Error('Unsupported media'));\n    }));\n  }", "language": "javascript"}
{"input": "Prepend prefix defined by API model to endpoint that's already\nconstructed. This feature does not apply to operations using\nendpoint discovery and can be disabled.\n@api private", "output": "function populateHostPrefix(request)  {\n  var enabled = request.service.config.hostPrefixEnabled;\n  if (!enabled) return request;\n  var operationModel = request.service.api.operations[request.operation];\n  //don't marshal host prefix when operation has endpoint discovery traits\n  if (hasEndpointDiscover(request)) return request;\n  if (operationModel.endpoint && operationModel.endpoint.hostPrefix) {\n    var hostPrefixNotation = operationModel.endpoint.hostPrefix;\n    var hostPrefix = expandHostPrefix(hostPrefixNotation, request.params, operationModel.input);\n    prependEndpointPrefix(request.httpRequest.endpoint, hostPrefix);\n    validateHostname(request.httpRequest.endpoint.hostname);\n  }\n  return request;\n}", "language": "javascript"}
{"input": "Send the inputs to the experts.\n\n    Args:\n      inp: a `Tensor` of shape \"[batch, length, depth]`\n    Returns:\n      a tensor with shape [batch, num_experts, expert_capacity, depth]", "output": "def dispatch(self, inp):\n    \"\"\"Send the inputs to the experts.\n\n    Args:\n      inp: a `Tensor` of shape \"[batch, length, depth]`\n    Returns:\n      a tensor with shape [batch, num_experts, expert_capacity, depth]\n    \"\"\"\n    inp = tf.reshape(inp, [self._batch * self._length, -1])\n    # [batch, num_experts, expert_capacity, depth]\n    ret = tf.gather(inp, self._flat_indices)\n    return ret", "language": "python"}
{"input": "Adds `tf.summary`s to all terms in the losses dictionary.", "output": "def _summarize_losses(self, losses_dict):\n    \"\"\"Adds `tf.summary`s to all terms in the losses dictionary.\"\"\"\n    if common_layers.should_generate_summaries():\n      with tf.name_scope(\"losses\"):\n        for loss_name, loss_val in sorted(losses_dict.items()):\n          tf.summary.scalar(loss_name, loss_val)", "language": "python"}
{"input": "Finds which pane a document belongs to\n@param {!Document} document - the document to locate\n@return {?Pane} the pane where the document lives or NULL if it isn't in a pane\n@private", "output": "function _findPaneForDocument(document) {\n        // First check for an editor view of the document\n        var pane = _getPaneFromElement($(document._masterEditor.$el.parent().parent()));\n\n        if (!pane) {\n            // No view of the document, it may be in a working set and not yet opened\n            var info = findInAllWorkingSets(document.file.fullPath).shift();\n            if (info) {\n                pane = _panes[info.paneId];\n            }\n        }\n\n        return pane;\n    }", "language": "javascript"}
{"input": "provide concatenation of an sparse/dense array of arrays each of which is a\n    single dtype\n\n    Parameters\n    ----------\n    to_concat : array of arrays\n    axis : axis to provide concatenation\n    typs : set of to_concat dtypes\n\n    Returns\n    -------\n    a single array, preserving the combined dtypes", "output": "def _concat_sparse(to_concat, axis=0, typs=None):\n    \"\"\"\n    provide concatenation of an sparse/dense array of arrays each of which is a\n    single dtype\n\n    Parameters\n    ----------\n    to_concat : array of arrays\n    axis : axis to provide concatenation\n    typs : set of to_concat dtypes\n\n    Returns\n    -------\n    a single array, preserving the combined dtypes\n    \"\"\"\n\n    from pandas.core.arrays import SparseArray\n\n    fill_values = [x.fill_value for x in to_concat\n                   if isinstance(x, SparseArray)]\n    fill_value = fill_values[0]\n\n    # TODO: Fix join unit generation so we aren't passed this.\n    to_concat = [x if isinstance(x, SparseArray)\n                 else SparseArray(x.squeeze(), fill_value=fill_value)\n                 for x in to_concat]\n\n    return SparseArray._concat_same_type(to_concat)", "language": "python"}
{"input": "Save the currentin-memory state.", "output": "def save(self):\n        # type: () -> None\n        \"\"\"Save the currentin-memory state.\n        \"\"\"\n        self._ensure_have_load_only()\n\n        for fname, parser in self._modified_parsers:\n            logger.info(\"Writing to %s\", fname)\n\n            # Ensure directory exists.\n            ensure_dir(os.path.dirname(fname))\n\n            with open(fname, \"w\") as f:\n                parser.write(f)", "language": "python"}
{"input": "Creates a default toolbar providing basic buttons and functionality.\n\n@param {sap.ui.table.CreationRow} oCreationRow The creation row to get the settings for the toolbar creation from.\n@returns {sap.m.OverflowToolbar} The default toolbar.", "output": "function createDefaultToolbar(oCreationRow) {\n\t\treturn new OverflowToolbar({\n\t\t\tcontent: [\n\t\t\t\tnew ToolbarSpacer(),\n\t\t\t\tnew Button({\n\t\t\t\t\ttext: TableUtils.getResourceText(\"TBL_CREATIONROW_APPLY\"),\n\t\t\t\t\ttype: MLibrary.ButtonType.Emphasized,\n\t\t\t\t\tenabled: oCreationRow.getApplyEnabled(),\n\t\t\t\t\tpress: function() {\n\t\t\t\t\t\toCreationRow._fireApply();\n\t\t\t\t\t}\n\t\t\t\t})\n\t\t\t],\n\t\t\tstyle: MLibrary.ToolbarStyle.Clear,\n\t\t\tariaLabelledBy: [oCreationRow.getId() + \"-label\"]\n\t\t});\n\t}", "language": "javascript"}
{"input": "Scans all the files in the working set that do not have Documents (and thus were not scanned\nby findExternalChanges()). If any were deleted on disk, removes them from the working set.", "output": "function syncUnopenWorkingSet() {\n        // We only care about working set entries that have never been open (have no Document).\n        var unopenWorkingSetFiles = MainViewManager.getWorkingSet(MainViewManager.ALL_PANES).filter(function (wsFile) {\n            return !DocumentManager.getOpenDocumentForPath(wsFile.fullPath);\n        });\n\n        function checkWorkingSetFile(file) {\n            var result = new $.Deferred();\n\n            file.stat(function (err, stat) {\n                if (!err) {\n                    // File still exists\n                    result.resolve();\n                } else {\n                    // File has been deleted externally\n                    if (err === FileSystemError.NOT_FOUND) {\n                        DocumentManager.notifyFileDeleted(file);\n                        result.resolve();\n                    } else {\n                        // Some other error fetching metadata: treat as a real error\n                        console.log(\"Error checking for deletion of \" + file.fullPath, err);\n                        result.reject();\n                    }\n                }\n            });\n            return result.promise();\n        }\n\n        // Check all these files in parallel\n        return Async.doInParallel(unopenWorkingSetFiles, checkWorkingSetFile, false);\n    }", "language": "javascript"}
{"input": "Start learning rate finder for given args", "output": "def find_learning_rate_from_args(args: argparse.Namespace) -> None:\n    \"\"\"\n    Start learning rate finder for given args\n    \"\"\"\n    params = Params.from_file(args.param_path, args.overrides)\n    find_learning_rate_model(params, args.serialization_dir,\n                             start_lr=args.start_lr,\n                             end_lr=args.end_lr,\n                             num_batches=args.num_batches,\n                             linear_steps=args.linear,\n                             stopping_factor=args.stopping_factor,\n                             force=args.force)", "language": "python"}
{"input": "TODO: Strip off query/hash strings from URL (see CSSAgent._canonicalize()) WebInspector Event: Debugger.scriptParsed", "output": "function _onScriptParsed(event, res) {\n        // res = {scriptId, url, startLine, startColumn, endLine, endColumn, isContentScript, sourceMapURL}\n        _idToScript[res.scriptId] = res;\n        _urlToScript[res.url] = res;\n    }", "language": "javascript"}
{"input": "Some examples in the text2sql datasets use ID as a column reference to the\n    column of a table which has a primary key. This causes problems if you are trying\n    to constrain a grammar to only produce the column names directly, because you don't\n    know what ID refers to. So instead of dealing with that, we just replace it.", "output": "def resolve_primary_keys_in_schema(sql_tokens: List[str],\n                                   schema: Dict[str, List[TableColumn]]) -> List[str]:\n    \"\"\"\n    Some examples in the text2sql datasets use ID as a column reference to the\n    column of a table which has a primary key. This causes problems if you are trying\n    to constrain a grammar to only produce the column names directly, because you don't\n    know what ID refers to. So instead of dealing with that, we just replace it.\n    \"\"\"\n    primary_keys_for_tables = {name: max(columns, key=lambda x: x.is_primary_key).name\n                               for name, columns in schema.items()}\n    resolved_tokens = []\n    for i, token in enumerate(sql_tokens):\n        if i > 2:\n            table_name = sql_tokens[i - 2]\n            if token == \"ID\" and table_name in primary_keys_for_tables.keys():\n                token = primary_keys_for_tables[table_name]\n        resolved_tokens.append(token)\n    return resolved_tokens", "language": "python"}
{"input": "Determine the dataset sized given a dataset_split.\n\n    Args:\n      dataset_split: A problem.DatasetSplit.\n\n    Returns:\n      The desired number of samples for this dataset_split.", "output": "def num_samples(self, dataset_split):\n    \"\"\"Determine the dataset sized given a dataset_split.\n\n    Args:\n      dataset_split: A problem.DatasetSplit.\n\n    Returns:\n      The desired number of samples for this dataset_split.\n    \"\"\"\n    return {\n        problem.DatasetSplit.TRAIN: 1000000,\n        problem.DatasetSplit.EVAL: 10000,\n        problem.DatasetSplit.TEST: 10000\n    }[dataset_split]", "language": "python"}
{"input": "More flexible, faster check like ``is`` but that works through views.\n\n        Note: this is *not* the same as ``Index.identical()``, which checks\n        that metadata is also the same.\n\n        Parameters\n        ----------\n        other : object\n            other object to compare against.\n\n        Returns\n        -------\n        True if both have same underlying data, False otherwise : bool", "output": "def is_(self, other):\n        \"\"\"\n        More flexible, faster check like ``is`` but that works through views.\n\n        Note: this is *not* the same as ``Index.identical()``, which checks\n        that metadata is also the same.\n\n        Parameters\n        ----------\n        other : object\n            other object to compare against.\n\n        Returns\n        -------\n        True if both have same underlying data, False otherwise : bool\n        \"\"\"\n        # use something other than None to be clearer\n        return self._id is getattr(\n            other, '_id', Ellipsis) and self._id is not None", "language": "python"}
{"input": "Checks whether a provided object takes in any positional arguments.\n    Similar to takes_arg, we do this for both the __init__ function of\n    the class or a function / method\n    Otherwise, we raise an error", "output": "def takes_kwargs(obj) -> bool:\n    \"\"\"\n    Checks whether a provided object takes in any positional arguments.\n    Similar to takes_arg, we do this for both the __init__ function of\n    the class or a function / method\n    Otherwise, we raise an error\n    \"\"\"\n    if inspect.isclass(obj):\n        signature = inspect.signature(obj.__init__)\n    elif inspect.ismethod(obj) or inspect.isfunction(obj):\n        signature = inspect.signature(obj)\n    else:\n        raise ConfigurationError(f\"object {obj} is not callable\")\n    return bool(any([p.kind == inspect.Parameter.VAR_KEYWORD  # type: ignore\n                     for p in signature.parameters.values()]))", "language": "python"}
{"input": "val1 ~ day or month", "output": "function (chrs, buffer, pos, strict, opts) {\n                        var isValid = opts.regex.val1.test(chrs);\n                        if (!strict && !isValid) {\n                            if (chrs.charAt(1) == opts.separator || \"-./\".indexOf(chrs.charAt(1)) != -1) {\n                                isValid = opts.regex.val1.test(\"0\" + chrs.charAt(0));\n                                if (isValid) {\n                                    buffer[pos - 1] = \"0\";\n                                    return { \"pos\": pos, \"c\": chrs.charAt(0) };\n                                }\n                            }\n                        }\n                        return isValid;\n                    }", "language": "javascript"}
{"input": "Reads an array of geometries and creates arrays for common geometry\nproperties. Then sets them to the multi geometry.\n@param {MultiPoint|MultiLineString|MultiPolygon} multiGeometry A multi-geometry.\n@param {Array<import(\"../geom/Geometry.js\").default>} geometries List of geometries.", "output": "function setCommonGeometryProperties(multiGeometry, geometries) {\n  const ii = geometries.length;\n  const extrudes = new Array(geometries.length);\n  const tessellates = new Array(geometries.length);\n  const altitudeModes = new Array(geometries.length);\n  let hasExtrude, hasTessellate, hasAltitudeMode;\n  hasExtrude = hasTessellate = hasAltitudeMode = false;\n  for (let i = 0; i < ii; ++i) {\n    const geometry = geometries[i];\n    extrudes[i] = geometry.get('extrude');\n    tessellates[i] = geometry.get('tessellate');\n    altitudeModes[i] = geometry.get('altitudeMode');\n    hasExtrude = hasExtrude || extrudes[i] !== undefined;\n    hasTessellate = hasTessellate || tessellates[i] !== undefined;\n    hasAltitudeMode = hasAltitudeMode || altitudeModes[i];\n  }\n  if (hasExtrude) {\n    multiGeometry.set('extrude', extrudes);\n  }\n  if (hasTessellate) {\n    multiGeometry.set('tessellate', tessellates);\n  }\n  if (hasAltitudeMode) {\n    multiGeometry.set('altitudeMode', altitudeModes);\n  }\n}", "language": "javascript"}
{"input": "Triggered when the content of the document changes. When the entire content of the document\nis changed - e.g., changes made from a different editor, the same lineFolds are kept only if\nthey are still valid in the context of the new document content.\n@param {!CodeMirror} cm the CodeMirror instance for the active editor\n@param {!Object} changeObj detailed information about the change that occurred in the document", "output": "function onChange(cm, changeObj) {\n        if (changeObj.origin === \"setValue\") {//text content has changed outside of brackets\n            var folds = cm.getValidFolds(cm._lineFolds);\n            cm._lineFolds = folds;\n            Object.keys(folds).forEach(function (line) {\n                cm.foldCode(+line);\n            });\n        } else {\n            var state = cm.state.foldGutter;\n            var lineChanges = changeObj.text.length - changeObj.removed.length;\n            // for undo actions that add new line(s) to the document first update the folds cache as normal\n            // and then update the folds cache with any line folds that exist in the new lines\n            if (changeObj.origin === \"undo\" && lineChanges > 0) {\n                updateFoldsCache(cm, changeObj.from.line, lineChanges);\n                syncDocToFoldsCache(cm, changeObj.from.line, lineChanges);\n            } else {\n                updateFoldsCache(cm, changeObj.from.line, lineChanges);\n            }\n            if (lineChanges !== 0) {\n                updateFoldInfo(cm, Math.max(0, changeObj.from.line + lineChanges), Math.max(0, changeObj.from.line + lineChanges) + 1);\n            }\n            state.from = changeObj.from.line;\n            state.to = 0;\n            window.clearTimeout(state.changeUpdate);\n            state.changeUpdate = window.setTimeout(function () {\n                updateInViewport(cm);\n            }, 600);\n        }\n    }", "language": "javascript"}
{"input": "Returns true if the column can be moved to the desired position.\n\nNote: The index must be given for the current table setup (which includes the column itself).\n\n@param {sap.ui.table.Column} oColumn Column of the table.\n@param {int} iNewIndex the desired new index of the column in the current table setup.\n@returns {boolean} Whether the column can be moved to the desired position.", "output": "function(oColumn, iNewIndex) {\n\t\t\tvar oTable = oColumn.getParent();\n\n\t\t\tif (!oTable || iNewIndex === undefined || !TableColumnUtils.isColumnMovable(oColumn)) {\n\t\t\t\t// Column is not movable at all\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tiNewIndex = TableColumnUtils.normalizeColumnMoveTargetIndex(oColumn, iNewIndex);\n\n\t\t\tif (iNewIndex < oTable.getComputedFixedColumnCount() || iNewIndex < oTable._iFirstReorderableIndex) {\n\t\t\t\t// No movement of fixed columns or e.g. the first column in the TreeTable\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tvar iCurrentIndex = oTable.indexOfColumn(oColumn),\n\t\t\t\taColumns = oTable.getColumns();\n\n\t\t\tif (iNewIndex > iCurrentIndex) { // Column moved to higher index\n\t\t\t\t// The column to be moved will appear after this column.\n\t\t\t\tvar oBeforeColumn = aColumns[iNewIndex >= aColumns.length ? aColumns.length - 1 : iNewIndex];\n\t\t\t\tvar oTargetBoundaries = TableColumnUtils.getColumnBoundaries(oTable, oBeforeColumn.getId());\n\t\t\t\tif (TableColumnUtils.hasHeaderSpan(oBeforeColumn) || oTargetBoundaries.endIndex > iNewIndex) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tvar oAfterColumn = aColumns[iNewIndex]; // The column to be moved will appear before this column.\n\t\t\t\tif (TableColumnUtils.getParentSpannedColumns(oTable, oAfterColumn.getId()).length != 0) {\n\t\t\t\t\t// If column which is currently at the desired target position is spanned by previous columns\n\t\t\t\t\t// also the column to reorder would be spanned after the move.\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn true;\n\t\t}", "language": "javascript"}
{"input": "Return dotenv as dict", "output": "def dict(self):\n        \"\"\"Return dotenv as dict\"\"\"\n        if self._dict:\n            return self._dict\n\n        values = OrderedDict(self.parse())\n        self._dict = resolve_nested_variables(values)\n        return self._dict", "language": "python"}
{"input": "Mark the RDD as non-persistent, and remove all blocks for it from\n        memory and disk.\n\n        .. versionchanged:: 3.0.0\n           Added optional argument `blocking` to specify whether to block until all\n           blocks are deleted.", "output": "def unpersist(self, blocking=False):\n        \"\"\"\n        Mark the RDD as non-persistent, and remove all blocks for it from\n        memory and disk.\n\n        .. versionchanged:: 3.0.0\n           Added optional argument `blocking` to specify whether to block until all\n           blocks are deleted.\n        \"\"\"\n        self.is_cached = False\n        self._jrdd.unpersist(blocking)\n        return self", "language": "python"}
{"input": "Returns `True` when alias already in shell config.", "output": "def _is_already_configured(configuration_details):\n    \"\"\"Returns `True` when alias already in shell config.\"\"\"\n    path = Path(configuration_details.path).expanduser()\n    with path.open('r') as shell_config:\n        return configuration_details.content in shell_config.read()", "language": "python"}
{"input": "write a 0-len array", "output": "def write_array_empty(self, key, value):\n        \"\"\" write a 0-len array \"\"\"\n\n        # ugly hack for length 0 axes\n        arr = np.empty((1,) * value.ndim)\n        self._handle.create_array(self.group, key, arr)\n        getattr(self.group, key)._v_attrs.value_type = str(value.dtype)\n        getattr(self.group, key)._v_attrs.shape = value.shape", "language": "python"}
{"input": "Resolves to an array of commits after the given tag, from earliest to latest (for proper cherry-picking).", "output": "async function getCommitsAfter(commit) {\n  if (!args.includes('--no-fetch')) {\n    await simpleGit.fetch();\n  }\n  const log = await simpleGit.log({\n    from: commit,\n    to: 'origin/master',\n    format: logFormat,\n    splitter: logSplitter,\n  });\n  return log.all.reverse();\n}", "language": "javascript"}
{"input": "Find the length of the longest substring\n    without repeating characters.", "output": "def longest_non_repeat_v1(string):\n    \"\"\"\n    Find the length of the longest substring\n    without repeating characters.\n    \"\"\"\n    if string is None:\n        return 0\n    dict = {}\n    max_length = 0\n    j = 0\n    for i in range(len(string)):\n        if string[i] in dict:\n            j = max(dict[string[i]], j)\n        dict[string[i]] = i + 1\n        max_length = max(max_length, i - j + 1)\n    return max_length", "language": "python"}
{"input": "Write vocab file to disk.\n\n    Vocab files have one token per line. The file ends in a newline. Reserved\n    tokens are written to the vocab file as well.\n\n    Args:\n      filename: Full path of the file to store the vocab to.", "output": "def store_to_file(self, filename):\n    \"\"\"Write vocab file to disk.\n\n    Vocab files have one token per line. The file ends in a newline. Reserved\n    tokens are written to the vocab file as well.\n\n    Args:\n      filename: Full path of the file to store the vocab to.\n    \"\"\"\n    with tf.gfile.Open(filename, \"w\") as f:\n      for i in range(len(self._id_to_token)):\n        f.write(self._id_to_token[i] + \"\\n\")", "language": "python"}
{"input": "Returns `True` if command is call to one of passed app names.", "output": "def is_app(command, *app_names, **kwargs):\n    \"\"\"Returns `True` if command is call to one of passed app names.\"\"\"\n\n    at_least = kwargs.pop('at_least', 0)\n    if kwargs:\n        raise TypeError(\"got an unexpected keyword argument '{}'\".format(kwargs.keys()))\n\n    if len(command.script_parts) > at_least:\n        return command.script_parts[0] in app_names\n\n    return False", "language": "python"}
{"input": "Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made", "output": "def ints_to_td64ns(data, unit=\"ns\"):\n    \"\"\"\n    Convert an ndarray with integer-dtype to timedelta64[ns] dtype, treating\n    the integers as multiples of the given timedelta unit.\n\n    Parameters\n    ----------\n    data : numpy.ndarray with integer-dtype\n    unit : str, default \"ns\"\n        The timedelta unit to treat integers as multiples of.\n\n    Returns\n    -------\n    numpy.ndarray : timedelta64[ns] array converted from data\n    bool : whether a copy was made\n    \"\"\"\n    copy_made = False\n    unit = unit if unit is not None else \"ns\"\n\n    if data.dtype != np.int64:\n        # converting to int64 makes a copy, so we can avoid\n        # re-copying later\n        data = data.astype(np.int64)\n        copy_made = True\n\n    if unit != \"ns\":\n        dtype_str = \"timedelta64[{unit}]\".format(unit=unit)\n        data = data.view(dtype_str)\n\n        # TODO: watch out for overflows when converting from lower-resolution\n        data = data.astype(\"timedelta64[ns]\")\n        # the astype conversion makes a copy, so we can avoid re-copying later\n        copy_made = True\n\n    else:\n        data = data.view(\"timedelta64[ns]\")\n\n    return data, copy_made", "language": "python"}
{"input": "Change the appearance of a button. Omit text to remove any extra text; omit style to return to default styling;\nomit tooltip to leave tooltip unchanged.", "output": "function _setLabel($btn, text, style, tooltip) {\n        // Clear text/styles from previous status\n        $(\"span\", $btn).remove();\n        $btn.removeClass(_allStatusStyles);\n\n        // Set text/styles for new status\n        if (text && text.length > 0) {\n            $(\"<span class=\\\"label\\\">\")\n                .addClass(style)\n                .text(text)\n                .appendTo($btn);\n        } else {\n            $btn.addClass(style);\n        }\n\n        if (tooltip) {\n            $btn.attr(\"title\", tooltip);\n        }\n    }", "language": "javascript"}
{"input": "Return the output from the experts.\n\n    When one example goes to multiple experts, the outputs are summed.\n\n    Args:\n      x: a Tensor with shape [batch, num_experts, expert_capacity, depth]\n\n    Returns:\n      a `Tensor` with shape `[batch, length, depth]", "output": "def combine(self, x):\n    \"\"\"Return the output from the experts.\n\n    When one example goes to multiple experts, the outputs are summed.\n\n    Args:\n      x: a Tensor with shape [batch, num_experts, expert_capacity, depth]\n\n    Returns:\n      a `Tensor` with shape `[batch, length, depth]\n    \"\"\"\n    depth = tf.shape(x)[-1]\n    x *= tf.expand_dims(self._nonpadding, -1)\n    ret = tf.unsorted_segment_sum(\n        x, self._flat_indices, num_segments=self._batch * self._length)\n    ret = tf.reshape(ret, [self._batch, self._length, depth])\n    return ret", "language": "python"}
{"input": "For 256x256.", "output": "def imagetransformerpp_base_5l_8h_big_uncond_dr00_dan_g_bs1():\n  \"\"\"For 256x256.\"\"\"\n  hparams = imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_g()\n  # TODO(trandustin): I forgot to set this in the runs! Maybe it's not used in\n  # image transformer training implementation?\n  # hparams.img_len = 256\n  hparams.max_length = 66000  # allow for 256x256\n  hparams.batch_size = 1\n  hparams.num_decoder_layers = 5\n  hparams.hidden_size = 128\n  hparams.filter_size = 128\n  hparams.attention_key_channels = 64\n  hparams.attention_value_channels = 64\n  hparams.layer_prepostprocess_dropout = 0.0\n  return hparams", "language": "python"}
{"input": "Function: addStylename\n\nAdds the specified stylename to the given style if it does not already\ncontain the stylename.", "output": "function(style, stylename)\n\t{\n\t\tif (mxUtils.indexOfStylename(style, stylename) < 0)\n\t\t{\n\t\t\tif (style == null)\n\t\t\t{\n\t\t\t\tstyle = '';\n\t\t\t}\n\t\t\telse if (style.length > 0 && style.charAt(style.length - 1) != ';')\n\t\t\t{\n\t\t\t\tstyle += ';';\n\t\t\t}\n\t\t\t\n\t\t\tstyle += stylename;\n\t\t}\n\t\t\n\t\treturn style;\n\t}", "language": "javascript"}
{"input": "Simple vector quantized discrete bottleneck.", "output": "def vq_discrete_bottleneck(x,\n                           bottleneck_bits,\n                           beta=0.25,\n                           decay=0.999,\n                           epsilon=1e-5,\n                           soft_em=False,\n                           num_samples=10):\n  \"\"\"Simple vector quantized discrete bottleneck.\"\"\"\n  bottleneck_size = 2**bottleneck_bits\n  x_means_hot, e_loss, _ = vq_body(\n      x,\n      bottleneck_size,\n      beta=beta,\n      decay=decay,\n      epsilon=epsilon,\n      soft_em=soft_em,\n      num_samples=num_samples)\n  return x_means_hot, e_loss", "language": "python"}
{"input": "Checks the parens of a function node\n@param {ASTNode} node A function node\n@returns {void}", "output": "function checkFunction(node) {\n            const functionConfig = getConfigForFunction(node);\n\n            if (functionConfig === \"ignore\") {\n                return;\n            }\n\n            const rightToken = sourceCode.getFirstToken(node, astUtils.isOpeningParenToken);\n            const leftToken = sourceCode.getTokenBefore(rightToken);\n            const hasSpacing = sourceCode.isSpaceBetweenTokens(leftToken, rightToken);\n\n            if (hasSpacing && functionConfig === \"never\") {\n                context.report({\n                    node,\n                    loc: leftToken.loc.end,\n                    message: \"Unexpected space before function parentheses.\",\n                    fix: fixer => fixer.removeRange([leftToken.range[1], rightToken.range[0]])\n                });\n            } else if (!hasSpacing && functionConfig === \"always\") {\n                context.report({\n                    node,\n                    loc: leftToken.loc.end,\n                    message: \"Missing space before function parentheses.\",\n                    fix: fixer => fixer.insertTextAfter(leftToken, \" \")\n                });\n            }\n        }", "language": "javascript"}
{"input": "Compute accuracy after expanding `y_true` to the size of `y_pred`.", "output": "def accuracy_thresh_expand(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True)->Rank0Tensor:\n    \"Compute accuracy after expanding `y_true` to the size of `y_pred`.\"\n    if sigmoid: y_pred = y_pred.sigmoid()\n    return ((y_pred>thresh)==y_true[:,None].expand_as(y_pred).byte()).float().mean()", "language": "python"}
{"input": "Whether this `meta` ObjectExpression has a `docs.description` property defined or not.\n\n@param {ASTNode} metaPropertyNode The `meta` ObjectExpression for this rule.\n@returns {boolean} `true` if a `docs.description` property exists.", "output": "function hasMetaDocsDescription(metaPropertyNode) {\n    const metaDocs = getPropertyFromObject(\"docs\", metaPropertyNode.value);\n\n    return metaDocs && getPropertyFromObject(\"description\", metaDocs.value);\n}", "language": "javascript"}
{"input": "Expand table range by merge properties like colspan, rowspan.\n@param {Array.<Array.<object>>} tableData - table data\n@param {{\nstart: {rowIndex: number, colIndex: number},\nend: {rowIndex: number, colIndex: number}\n}} tableRange - table range\n@returns {{\nstart: {rowIndex: number, colIndex: number},\nend: {rowIndex: number, colIndex: number}\n}}\n@private", "output": "function _expandMergedRange(tableData, tableRange) {\n  let rangeStr = '';\n\n  while (rangeStr !== JSON.stringify(tableRange)) {\n    rangeStr = JSON.stringify(tableRange);\n\n    _expandRowMergedRange(tableData, tableRange, 'start');\n    _expandRowMergedRange(tableData, tableRange, 'end');\n\n    util.range(tableRange.start.rowIndex, tableRange.end.rowIndex + 1).forEach(rowIndex => {\n      _expandColMergedRange(tableData, tableRange, rowIndex, tableRange.start.colIndex);\n      _expandColMergedRange(tableData, tableRange, rowIndex, tableRange.end.colIndex);\n    });\n  }\n\n  return tableRange;\n}", "language": "javascript"}
{"input": "Parameters\n        ----------\n        method : string {'backfill', 'bfill', 'pad', 'ffill'}\n            method for upsampling\n        limit : int, default None\n            Maximum size gap to fill when reindexing\n        fill_value : scalar, default None\n            Value to use for missing values\n\n        See Also\n        --------\n        .fillna", "output": "def _upsample(self, method, limit=None, fill_value=None):\n        \"\"\"\n        Parameters\n        ----------\n        method : string {'backfill', 'bfill', 'pad', 'ffill'}\n            method for upsampling\n        limit : int, default None\n            Maximum size gap to fill when reindexing\n        fill_value : scalar, default None\n            Value to use for missing values\n\n        See Also\n        --------\n        .fillna\n\n        \"\"\"\n\n        # we may need to actually resample as if we are timestamps\n        if self.kind == 'timestamp':\n            return super()._upsample(method, limit=limit,\n                                     fill_value=fill_value)\n\n        self._set_binner()\n        ax = self.ax\n        obj = self.obj\n        new_index = self.binner\n\n        # Start vs. end of period\n        memb = ax.asfreq(self.freq, how=self.convention)\n\n        # Get the fill indexer\n        indexer = memb.get_indexer(new_index, method=method, limit=limit)\n        return self._wrap_result(_take_new_index(\n            obj, indexer, new_index, axis=self.axis))", "language": "python"}
{"input": "Function: writeln\n\nAdds the specified strings to the console, appending a linefeed at the\nend of each string.", "output": "function()\n\t{\n\t\tvar string = '';\n\t\t\n\t\tfor (var i = 0; i < arguments.length; i++)\n\t\t{\n\t\t\tstring += arguments[i];\n\t\t\t\n\t\t\tif (i < arguments.length - 1)\n\t\t\t{\n\t\t\t\tstring += ' ';\n\t\t\t}\n\t\t}\n\n\t\tmxLog.write(string + '\\n');\n\t}", "language": "javascript"}
{"input": "Decides whether or not the document is reader-able without parsing the whole thing.\n\n@return boolean Whether or not we suspect parse() will suceeed at returning an article object.", "output": "function(helperIsVisible) {\n    var nodes = this._getAllNodesWithTag(this._doc, [\"p\", \"pre\"]);\n\n    // Get <div> nodes which have <br> node(s) and append them into the `nodes` variable.\n    // Some articles' DOM structures might look like\n    // <div>\n    //   Sentences<br>\n    //   <br>\n    //   Sentences<br>\n    // </div>\n    var brNodes = this._getAllNodesWithTag(this._doc, [\"div > br\"]);\n    if (brNodes.length) {\n      var set = new Set();\n      [].forEach.call(brNodes, function(node) {\n        set.add(node.parentNode);\n      });\n      nodes = [].concat.apply(Array.from(set), nodes);\n    }\n\n    // FIXME we should have a fallback for helperIsVisible, but this is\n    // problematic because of jsdom's elem.style handling - see\n    // https://github.com/mozilla/readability/pull/186 for context.\n\n    var score = 0;\n    // This is a little cheeky, we use the accumulator 'score' to decide what to return from\n    // this callback:\n    return this._someNode(nodes, function(node) {\n      if (helperIsVisible && !helperIsVisible(node))\n        return false;\n      var matchString = node.className + \" \" + node.id;\n\n      if (this.REGEXPS.unlikelyCandidates.test(matchString) &&\n          !this.REGEXPS.okMaybeItsACandidate.test(matchString)) {\n        return false;\n      }\n\n      if (node.matches && node.matches(\"li p\")) {\n        return false;\n      }\n\n      var textContentLength = node.textContent.trim().length;\n      if (textContentLength < 140) {\n        return false;\n      }\n\n      score += Math.sqrt(textContentLength - 140);\n\n      if (score > 20) {\n        return true;\n      }\n      return false;\n    });\n  }", "language": "javascript"}
{"input": "Serialize a in-memory proto to bytes\n\n    @params\n    proto is a in-memory proto, such as a ModelProto, TensorProto, etc\n\n    @return\n    Serialized proto in bytes", "output": "def _serialize(proto):  # type: (Union[bytes, google.protobuf.message.Message]) -> bytes\n    '''\n    Serialize a in-memory proto to bytes\n\n    @params\n    proto is a in-memory proto, such as a ModelProto, TensorProto, etc\n\n    @return\n    Serialized proto in bytes\n    '''\n    if isinstance(proto, bytes):\n        return proto\n    elif hasattr(proto, 'SerializeToString') and callable(proto.SerializeToString):\n        result = proto.SerializeToString()\n        return result\n    else:\n        raise ValueError('No SerializeToString method is detected. '\n                         'neither proto is a str.\\ntype is {}'.format(type(proto)))", "language": "python"}
{"input": "Create this file with the given access mode, if it doesn't exist.", "output": "def touch(self, mode=0o666, exist_ok=True):\n        \"\"\"\n        Create this file with the given access mode, if it doesn't exist.\n        \"\"\"\n        if self._closed:\n            self._raise_closed()\n        if exist_ok:\n            # First try to bump modification time\n            # Implementation note: GNU touch uses the UTIME_NOW option of\n            # the utimensat() / futimens() functions.\n            try:\n                self._accessor.utime(self, None)\n            except OSError:\n                # Avoid exception chaining\n                pass\n            else:\n                return\n        flags = os.O_CREAT | os.O_WRONLY\n        if not exist_ok:\n            flags |= os.O_EXCL\n        fd = self._raw_open(flags, mode)\n        os.close(fd)", "language": "python"}
{"input": "Dump all timers to a logger\n\n@param {Logger} logger", "output": "function dump(logger) {\n    var prefix = '    > ';\n    var measured = 0;\n    var totalDuration = Date.now() - startDate;\n\n    // Enable debug logging\n    var logLevel = logger.getLevel();\n    logger.setLevel('debug');\n\n    Immutable.Map(timers)\n        .valueSeq()\n        .sortBy(function(timer) {\n            measured += timer.total;\n            return timer.total;\n        })\n        .forEach(function(timer) {\n            var percent = (timer.total * 100) / totalDuration;\n\n\n            logger.debug.ln((percent.toFixed(1)) + '% of time spent in \"' + timer.type + '\" (' + timer.count + ' times) :');\n            logger.debug.ln(prefix + 'Total: ' + time(timer.total)+ ' | Average: ' + time(timer.total / timer.count));\n            logger.debug.ln(prefix + 'Min: ' + time(timer.min) + ' | Max: ' + time(timer.max));\n            logger.debug.ln('---------------------------');\n        });\n\n\n    logger.debug.ln(time(totalDuration - measured) + ' spent in non-mesured sections');\n\n    // Rollback to previous level\n    logger.setLevel(logLevel);\n}", "language": "javascript"}
{"input": "/*\n(Recursively) rejects the request(s) with the given error\n\n@param {Error} oError\n@param {object|object[]} vRequest", "output": "function reject(oError, vRequest) {\n\t\t\tif (Array.isArray(vRequest)) {\n\t\t\t\tvRequest.forEach(reject.bind(null, oError));\n\t\t\t} else {\n\t\t\t\tvRequest.$reject(oError);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": ":return: a dict that can be used as part of a cloudformation template", "output": "def to_dict(self):\n        \"\"\"\n        :return: a dict that can be used as part of a cloudformation template\n        \"\"\"\n        dict_with_nones = self._asdict()\n        codedeploy_lambda_alias_update_dict = dict((k, v) for k, v in dict_with_nones.items()\n                                                   if v != ref(None) and v is not None)\n        return {'CodeDeployLambdaAliasUpdate': codedeploy_lambda_alias_update_dict}", "language": "python"}
{"input": "Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`\n        and establish the tunnel if proxy is used.", "output": "def _prepare_conn(self, conn):\n        \"\"\"\n        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`\n        and establish the tunnel if proxy is used.\n        \"\"\"\n\n        if isinstance(conn, VerifiedHTTPSConnection):\n            conn.set_cert(key_file=self.key_file,\n                          cert_file=self.cert_file,\n                          cert_reqs=self.cert_reqs,\n                          ca_certs=self.ca_certs,\n                          ca_cert_dir=self.ca_cert_dir,\n                          assert_hostname=self.assert_hostname,\n                          assert_fingerprint=self.assert_fingerprint)\n            conn.ssl_version = self.ssl_version\n        return conn", "language": "python"}
{"input": "Returns a visually shorter representation of a given system path.", "output": "def shorten_path(location, bold=False):\n    \"\"\"Returns a visually shorter representation of a given system path.\"\"\"\n    original = location\n    short = os.sep.join(\n        [s[0] if len(s) > (len(\"2long4\")) else s for s in location.split(os.sep)]\n    )\n    short = short.split(os.sep)\n    short[-1] = original.split(os.sep)[-1]\n    if bold:\n        short[-1] = str(crayons.normal(short[-1], bold=True))\n    return os.sep.join(short)", "language": "python"}
{"input": "Removes the change listener which is attached to the lists attribute.", "output": "function(oList) {\n\t\tvar oAttr = oList._getAtt();\n\t\tif (oAttr && oAttr.getChangeListener() && oAttr.getChangeListener().id === oList.getId()) {\n\t\t\toAttr.setChangeListener(null);\n\t\t}\n\t}", "language": "javascript"}
{"input": "Strip all definitions generated by requirejs\nConvert \"var\" modules to var declarations\n\"var module\" means the module only contains a return\nstatement that should be converted to a var declaration\nThis is indicated by including the file in any \"var\" folder\n@param {String} name\n@param {String} path\n@param {String} contents The contents to be written (including their AMD wrappers)", "output": "function convert( name, path, contents ) {\n\t\tvar amdName;\n\n\t\t// Convert var modules\n\t\tif ( /.\\/var\\//.test( path.replace( process.cwd(), \"\" ) ) ) {\n\t\t\tcontents = contents\n\t\t\t\t.replace(\n\t\t\t\t\t/define\\([\\w\\W]*?return/,\n\t\t\t\t\t\"var \" +\n\t\t\t\t\t( /var\\/([\\w-]+)/.exec( name )[ 1 ] ) +\n\t\t\t\t\t\" =\"\n\t\t\t\t)\n\t\t\t\t.replace( rdefineEnd, \"\" );\n\n\t\t// Sizzle treatment\n\t\t} else if ( /\\/sizzle$/.test( name ) ) {\n\t\t\tcontents = \"var Sizzle =\\n\" + contents\n\n\t\t\t\t// Remove EXPOSE lines from Sizzle\n\t\t\t\t.replace( /\\/\\/\\s*EXPOSE[\\w\\W]*\\/\\/\\s*EXPOSE/, \"return Sizzle;\" );\n\n\t\t} else {\n\n\t\t\tcontents = contents\n\t\t\t\t.replace( /\\s*return\\s+[^\\}]+(\\}\\s*?\\);[^\\w\\}]*)$/, \"$1\" )\n\n\t\t\t\t// Multiple exports\n\t\t\t\t.replace( /\\s*exports\\.\\w+\\s*=\\s*\\w+;/g, \"\" );\n\n\t\t\t// Remove define wrappers, closure ends, and empty declarations\n\t\t\tcontents = contents\n\t\t\t\t.replace( /define\\([^{]*?{\\s*(?:(\"|')use strict\\1(?:;|))?/, \"\" )\n\t\t\t\t.replace( rdefineEnd, \"\" );\n\n\t\t\t// Remove anything wrapped with\n\t\t\t// /* ExcludeStart */ /* ExcludeEnd */\n\t\t\t// or a single line directly after a // BuildExclude comment\n\t\t\tcontents = contents\n\t\t\t\t.replace( /\\/\\*\\s*ExcludeStart\\s*\\*\\/[\\w\\W]*?\\/\\*\\s*ExcludeEnd\\s*\\*\\//ig, \"\" )\n\t\t\t\t.replace( /\\/\\/\\s*BuildExclude\\n\\r?[\\w\\W]*?\\n\\r?/ig, \"\" );\n\n\t\t\t// Remove empty definitions\n\t\t\tcontents = contents\n\t\t\t\t.replace( /define\\(\\[[^\\]]*\\]\\)[\\W\\n]+$/, \"\" );\n\t\t}\n\n\t\t// AMD Name\n\t\tif ( ( amdName = grunt.option( \"amd\" ) ) != null && /^exports\\/amd$/.test( name ) ) {\n\t\t\tif ( amdName ) {\n\t\t\t\tgrunt.log.writeln( \"Naming jQuery with AMD name: \" + amdName );\n\t\t\t} else {\n\t\t\t\tgrunt.log.writeln( \"AMD name now anonymous\" );\n\t\t\t}\n\n\t\t\t// Remove the comma for anonymous defines\n\t\t\tcontents = contents\n\t\t\t\t.replace( /(\\s*)\"jquery\"(\\,\\s*)/, amdName ? \"$1\\\"\" + amdName + \"\\\"$2\" : \"\" );\n\n\t\t}\n\t\treturn contents;\n\t}", "language": "javascript"}
{"input": "Check if the current element is a landmark", "output": "function isRegion(virtualNode) {\n\tconst node = virtualNode.actualNode;\n\tconst explicitRole = axe.commons.aria.getRole(node, { noImplicit: true });\n\tconst ariaLive = (node.getAttribute('aria-live') || '').toLowerCase().trim();\n\n\tif (explicitRole) {\n\t\treturn explicitRole === 'dialog' || landmarkRoles.includes(explicitRole);\n\t}\n\t// Ignore content inside of aria-live\n\tif (['assertive', 'polite'].includes(ariaLive)) {\n\t\treturn true;\n\t}\n\n\t// Check if the node matches any of the CSS selectors of implicit landmarks\n\treturn implicitLandmarks.some(implicitSelector => {\n\t\tlet matches = axe.utils.matchesSelector(node, implicitSelector);\n\t\tif (node.nodeName.toUpperCase() === 'FORM') {\n\t\t\tlet titleAttr = node.getAttribute('title');\n\t\t\tlet title =\n\t\t\t\ttitleAttr && titleAttr.trim() !== ''\n\t\t\t\t\t? axe.commons.text.sanitize(titleAttr)\n\t\t\t\t\t: null;\n\t\t\treturn matches && (!!aria.labelVirtual(virtualNode) || !!title);\n\t\t}\n\t\treturn matches;\n\t});\n}", "language": "javascript"}
{"input": "Check that the value is nonnegative.", "output": "def check_nonnegative(value):\n  \"\"\"Check that the value is nonnegative.\"\"\"\n  if isinstance(value, tf.Tensor):\n    with tf.control_dependencies([tf.assert_greater_equal(value, 0)]):\n      value = tf.identity(value)\n  elif value < 0:\n    raise ValueError(\"Value must be non-negative.\")\n  return value", "language": "python"}
{"input": "The player from which we cast the rays.\n@param {Number} x     Starting x-position.\n@param {Number} y     Starting y-position.\n@param {Number} dir   Direction they are facing in radians.\n@param {Number} speed Speed they walk at.", "output": "function(x, y, dir, speed) {\n  this.x = x;\n  this.y = y;\n  this.dir = dir;\n  this.speed = speed || 3;\n  this.steps = 0;\n  this.hand = new Texture('./assets/gun.png', 512, 360);\n\n  // Update the position of the audio listener.\n  Howler.pos(this.x, this.y, -0.5);\n\n  // Update the direction and orientation.\n  this.rotate(dir);\n}", "language": "javascript"}
{"input": "@api private\n\n@param {Buffer} message", "output": "function splitMessage(message) {\n    if (!util.Buffer.isBuffer(message)) message = toBuffer(message);\n\n    if (message.length < MINIMUM_MESSAGE_LENGTH) {\n        throw new Error('Provided message too short to accommodate event stream message overhead');\n    }\n\n    if (message.length !== message.readUInt32BE(0)) {\n        throw new Error('Reported message length does not match received message length');\n    }\n\n    var expectedPreludeChecksum = message.readUInt32BE(PRELUDE_LENGTH);\n\n    if (\n        expectedPreludeChecksum !== util.crypto.crc32(\n            message.slice(0, PRELUDE_LENGTH)\n        )\n    ) {\n        throw new Error(\n            'The prelude checksum specified in the message (' +\n            expectedPreludeChecksum +\n            ') does not match the calculated CRC32 checksum.'\n        );\n    }\n\n    var expectedMessageChecksum = message.readUInt32BE(message.length - CHECKSUM_LENGTH);\n\n    if (\n        expectedMessageChecksum !== util.crypto.crc32(\n            message.slice(0, message.length - CHECKSUM_LENGTH)\n        )\n    ) {\n        throw new Error(\n            'The message checksum did not match the expected value of ' +\n                expectedMessageChecksum\n        );\n    }\n\n    var headersStart = PRELUDE_LENGTH + CHECKSUM_LENGTH;\n    var headersEnd = headersStart + message.readUInt32BE(PRELUDE_MEMBER_LENGTH);\n\n    return {\n        headers: message.slice(headersStart, headersEnd),\n        body: message.slice(headersEnd, message.length - CHECKSUM_LENGTH),\n    };\n}", "language": "javascript"}
{"input": "Apply a linear transform to a vertex.  The provided vertex is modified in\nplace.\n\n@param {import(\"../coordinate.js\").Coordinate} vertex Vertex.\n@param {Array<number>} scale Scale for each dimension.\n@param {Array<number>} translate Translation for each dimension.", "output": "function transformVertex(vertex, scale, translate) {\n  vertex[0] = vertex[0] * scale[0] + translate[0];\n  vertex[1] = vertex[1] * scale[1] + translate[1];\n}", "language": "javascript"}
{"input": "Update merged cell data to basic cell data.\n@param {Array.<Array.<object>>} tableData - table data\n@param {number} startRowIndex - start row index\n@param {number} startColIndex - start col index\n@param {number} rowspan - rowspan property of merger cell\n@param {number} colspan - colspan property of merger cell\n@private", "output": "function _updateMergedCells(tableData, startRowIndex, startColIndex, rowspan, colspan) {\n  const limitRowIndex = startRowIndex + rowspan;\n  const limitColIndex = startColIndex + colspan;\n  const colRange = util.range(startColIndex, limitColIndex);\n\n  util.range(startRowIndex, limitRowIndex).forEach(rowIndex => {\n    const rowData = tableData[rowIndex];\n    const startIndex = (rowIndex === startRowIndex) ? 1 : 0;\n\n    colRange.slice(startIndex).forEach(colIndex => {\n      rowData[colIndex] = dataHandler.createBasicCell(rowIndex, colIndex, rowData[colIndex].nodeName);\n    });\n  });\n}", "language": "javascript"}
{"input": "Sleep an incremental amount of time after each attempt, starting at\n        wait_incrementing_start and incrementing by wait_incrementing_increment", "output": "def incrementing_sleep(self, previous_attempt_number, delay_since_first_attempt_ms):\n        \"\"\"\n        Sleep an incremental amount of time after each attempt, starting at\n        wait_incrementing_start and incrementing by wait_incrementing_increment\n        \"\"\"\n        result = self._wait_incrementing_start + (self._wait_incrementing_increment * (previous_attempt_number - 1))\n        if result < 0:\n            result = 0\n        return result", "language": "python"}
{"input": "Determines if the left side of a node can be safely fixed (i.e. if it activates the same getters/setters and)\ntoString calls regardless of whether assignment shorthand is used)\n@param {ASTNode} node The node on the left side of the expression\n@returns {boolean} `true` if the node can be fixed", "output": "function canBeFixed(node) {\n    return node.type === \"Identifier\" ||\n        node.type === \"MemberExpression\" && node.object.type === \"Identifier\" && (!node.computed || node.property.type === \"Literal\");\n}", "language": "javascript"}
{"input": "Set the slider value.", "output": "function valueSet ( input, fireSetEvent ) {\n\n            var values = asArray(input);\n            var isInit = scope_Locations[0] === undefined;\n\n            // Event fires by default\n            fireSetEvent = (fireSetEvent === undefined ? true : !!fireSetEvent);\n\n            values.forEach(setValue);\n\n            // Animation is optional.\n            // Make sure the initial values were set before using animated placement.\n            if ( options.animate && !isInit ) {\n                addClassFor(scope_Target, options.cssClasses.tap, options.animationDuration);\n            }\n\n            // Now that all base values are set, apply constraints\n            scope_HandleNumbers.forEach(function(handleNumber){\n                setHandle(handleNumber, scope_Locations[handleNumber], true, false);\n            });\n\n            setZindex();\n\n            scope_HandleNumbers.forEach(function(handleNumber){\n\n                fireEvent('update', handleNumber);\n\n                // Fire the event only for handles that received a new value, as per #579\n                if ( values[handleNumber] !== null && fireSetEvent ) {\n                    fireEvent('set', handleNumber);\n                }\n            });\n        }", "language": "javascript"}
{"input": "Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]", "output": "def plot_val_with_title(self, idxs, y):\n        \"\"\" Displays the images and their probabilities of belonging to a certain class\n\n            Arguments:\n                idxs (numpy.ndarray): indexes of the image samples from the dataset\n                y (int): the selected class\n\n            Returns:\n                Plots the images in n rows [rows = n]\n        \"\"\"\n        # if there are any samples to be displayed\n        if len(idxs) > 0:\n            imgs = np.stack([self.ds[x][0] for x in idxs])\n            title_probs = [self.probs[x,y] for x in idxs]\n\n            return plots(self.ds.denorm(imgs), rows=1, titles=title_probs)\n        # if idxs is empty return false\n        else:\n            return False;", "language": "python"}
{"input": "Small range of hyperparameters.", "output": "def transformer_tpu_range(rhp):\n  \"\"\"Small range of hyperparameters.\"\"\"\n  # After starting from base, set intervals for some parameters.\n  rhp.set_float(\"learning_rate\", 0.3, 3.0, scale=rhp.LOG_SCALE)\n  rhp.set_discrete(\"learning_rate_warmup_steps\",\n                   [1000, 2000, 4000, 8000, 16000])\n  rhp.set_float(\"initializer_gain\", 0.5, 2.0)\n  rhp.set_float(\"optimizer_adam_beta1\", 0.85, 0.95)\n  rhp.set_float(\"optimizer_adam_beta2\", 0.97, 0.99)\n  rhp.set_float(\"weight_decay\", 0.0, 2.0)", "language": "python"}
{"input": "Make sure a valid parser is passed.\n\n    Parameters\n    ----------\n    parser : str\n\n    Raises\n    ------\n    KeyError\n      * If an invalid parser is passed", "output": "def _check_parser(parser):\n    \"\"\"Make sure a valid parser is passed.\n\n    Parameters\n    ----------\n    parser : str\n\n    Raises\n    ------\n    KeyError\n      * If an invalid parser is passed\n    \"\"\"\n    from pandas.core.computation.expr import _parsers\n\n    if parser not in _parsers:\n        raise KeyError('Invalid parser {parser!r} passed, valid parsers are'\n                       ' {valid}'.format(parser=parser, valid=_parsers.keys()))", "language": "python"}
{"input": "Scrolls to an element within a container.\n@param {HTMLElement} oElement A DOM element.\n@param {int} [iTime=0]\nThe duration of animated scrolling in milliseconds. To scroll immediately without animation,\ngive 0 as value.\n@param {int[]} [aOffset=[0,0]]\nSpecifies an additional left and top offset of the target scroll position, relative to\nthe upper left corner of the DOM element\n@returns {sap.ui.core.delegate.ScrollEnablement}\n@protected", "output": "function(oElement, iTime, aOffset) {\n\t\t\t\taOffset = aOffset || [0, 0];\n\n\t\t\t\t// do nothing if _$Container is not a (grand)parent of oElement\n\t\t\t\tif (!this._$Container[0].contains(oElement) ||\n\t\t\t\t\toElement.style.display === \"none\" ||\n\t\t\t\t\toElement.offsetParent.nodeName.toUpperCase() === \"HTML\") {\n\t\t\t\t\t\treturn this;\n\t\t\t\t}\n\n\t\t\t\tvar $Element = jQuery(oElement),\n\t\t\t\t\toScrollPosition = this.getChildPosition($Element),\n\t\t\t\t\tiLeftScroll = this.getScrollLeft() + oScrollPosition.left + aOffset[0],\n\t\t\t\t\tiTopScroll = this.getScrollTop() + oScrollPosition.top + aOffset[1];\n\n\t\t\t\tif (this._bFlipX) {\n\t\t\t\t\t// in IE RTL scrollLeft goes opposite direction\n\t\t\t\t\tiLeftScroll = this.getScrollLeft() - (oScrollPosition.left - this._$Container.width()) - $Element.width();\n\t\t\t\t}\n\n\t\t\t\t// scroll to destination\n\t\t\t\tthis._scrollTo(iLeftScroll, iTopScroll , iTime);\n\n\t\t\t\treturn this;\n\t\t\t}", "language": "javascript"}
{"input": "PrivateFunction: _connect\n_Private_ function that initializes the BOSH connection.\n\nCreates and sends the Request that initializes the BOSH connection.", "output": "function (wait, hold, route)\r\n    {\r\n        this.wait = wait || this.wait;\r\n        this.hold = hold || this.hold;\r\n        this.errors = 0;\r\n\r\n        // build the body tag\r\n        var body = this._buildBody().attrs({\r\n            to: this._conn.domain,\r\n            \"xml:lang\": \"en\",\r\n            wait: this.wait,\r\n            hold: this.hold,\r\n            content: \"text/xml; charset=utf-8\",\r\n            ver: \"1.6\",\r\n            \"xmpp:version\": \"1.0\",\r\n            \"xmlns:xmpp\": Strophe.NS.BOSH\r\n        });\r\n\r\n        if(route){\r\n            body.attrs({\r\n                route: route\r\n            });\r\n        }\r\n\r\n        var _connect_cb = this._conn._connect_cb;\r\n\r\n        this._requests.push(\r\n            new Strophe.Request(body.tree(),\r\n                                this._onRequestStateChange.bind(\r\n                                    this, _connect_cb.bind(this._conn)),\r\n                                body.tree().getAttribute(\"rid\")));\r\n        this._throttledRequestHandler();\r\n    }", "language": "javascript"}
{"input": "Returns a node's parentNode without falling prey to things like\n<form><input name=\"parentNode\"></form>.\n@param {!Node} node\n@return {?Node}", "output": "function getParentNode(node) {\n  return genericPropertyGet(\n      Methods.PARENT_NODE_GETTER, node, 'parentNode', function(parentNode) {\n        // We need to ensure that parentNode is returning the actual parent node\n        // and not a child node that happens to have a name of \"parentNode\".\n        // We check that the node returned by parentNode is itself not named\n        // \"parentNode\" - this could happen legitimately but on IE we have no\n        // better means of avoiding the pitfall.\n        return !(\n            parentNode && typeof parentNode.name == 'string' &&\n            parentNode.name && parentNode.name.toLowerCase() == 'parentnode');\n      });\n}", "language": "javascript"}
{"input": "Recover Doc objects from the annotations, using the given vocab.", "output": "def get_docs(self, vocab):\n        \"\"\"Recover Doc objects from the annotations, using the given vocab.\"\"\"\n        for string in self.strings:\n            vocab[string]\n        orth_col = self.attrs.index(ORTH)\n        for tokens, spaces in zip(self.tokens, self.spaces):\n            words = [vocab.strings[orth] for orth in tokens[:, orth_col]]\n            doc = Doc(vocab, words=words, spaces=spaces)\n            doc = doc.from_array(self.attrs, tokens)\n            yield doc", "language": "python"}
{"input": "Merge entities into a single token.\n\n    doc (Doc): The Doc object.\n    RETURNS (Doc): The Doc object with merged entities.\n\n    DOCS: https://spacy.io/api/pipeline-functions#merge_entities", "output": "def merge_entities(doc):\n    \"\"\"Merge entities into a single token.\n\n    doc (Doc): The Doc object.\n    RETURNS (Doc): The Doc object with merged entities.\n\n    DOCS: https://spacy.io/api/pipeline-functions#merge_entities\n    \"\"\"\n    with doc.retokenize() as retokenizer:\n        for ent in doc.ents:\n            attrs = {\"tag\": ent.root.tag, \"dep\": ent.root.dep, \"ent_type\": ent.label}\n            retokenizer.merge(ent, attrs=attrs)\n    return doc", "language": "python"}
{"input": "Common post process unrelated to data", "output": "def _adorn_subplots(self):\n        \"\"\"Common post process unrelated to data\"\"\"\n        if len(self.axes) > 0:\n            all_axes = self._get_subplots()\n            nrows, ncols = self._get_axes_layout()\n            _handle_shared_axes(axarr=all_axes, nplots=len(all_axes),\n                                naxes=nrows * ncols, nrows=nrows,\n                                ncols=ncols, sharex=self.sharex,\n                                sharey=self.sharey)\n\n        for ax in self.axes:\n            if self.yticks is not None:\n                ax.set_yticks(self.yticks)\n\n            if self.xticks is not None:\n                ax.set_xticks(self.xticks)\n\n            if self.ylim is not None:\n                ax.set_ylim(self.ylim)\n\n            if self.xlim is not None:\n                ax.set_xlim(self.xlim)\n\n            ax.grid(self.grid)\n\n        if self.title:\n            if self.subplots:\n                if is_list_like(self.title):\n                    if len(self.title) != self.nseries:\n                        msg = ('The length of `title` must equal the number '\n                               'of columns if using `title` of type `list` '\n                               'and `subplots=True`.\\n'\n                               'length of title = {}\\n'\n                               'number of columns = {}').format(\n                            len(self.title), self.nseries)\n                        raise ValueError(msg)\n\n                    for (ax, title) in zip(self.axes, self.title):\n                        ax.set_title(title)\n                else:\n                    self.fig.suptitle(self.title)\n            else:\n                if is_list_like(self.title):\n                    msg = ('Using `title` of type `list` is not supported '\n                           'unless `subplots=True` is passed')\n                    raise ValueError(msg)\n                self.axes[0].set_title(self.title)", "language": "python"}
{"input": "moves a working set item from one index to another shifting the items\nafter in the working set up and reinserting it at the desired location\n@param {!string} paneId - id of the pane to sort\n@param {!number} fromIndex - the index of the item to move\n@param {!number} toIndex - the index to move to\n@private", "output": "function _moveWorkingSetItem(paneId, fromIndex, toIndex) {\n        var pane = _getPane(paneId);\n\n        pane.moveWorkingSetItem(fromIndex, toIndex);\n        exports.trigger(\"workingSetSort\", pane.id);\n        exports.trigger(\"_workingSetDisableAutoSort\", pane.id);\n    }", "language": "javascript"}
{"input": "Copyright (c) 2006-2015, JGraph Ltd\nCopyright (c) 2006-2015, Gaudenz Alder\n \nClass: mxVertexHandler\n\nEvent handler for resizing cells. This handler is automatically created in\n<mxGraph.createHandler>.\n\nConstructor: mxVertexHandler\n\nConstructs an event handler that allows to resize vertices\nand groups.\n\nParameters:\n\nstate - <mxCellState> of the cell to be resized.", "output": "function mxVertexHandler(state)\n{\n\tif (state != null)\n\t{\n\t\tthis.state = state;\n\t\tthis.init();\n\t\t\n\t\t// Handles escape keystrokes\n\t\tthis.escapeHandler = mxUtils.bind(this, function(sender, evt)\n\t\t{\n\t\t\tif (this.livePreview && this.index != null)\n\t\t\t{\n\t\t\t\t// Redraws the live preview\n\t\t\t\tthis.state.view.graph.cellRenderer.redraw(this.state, true);\n\t\t\t\t\n\t\t\t\t// Redraws connected edges\n\t\t\t\tthis.state.view.invalidate(this.state.cell);\n\t\t\t\tthis.state.invalid = false;\n\t\t\t\tthis.state.view.validate();\n\t\t\t}\n\t\t\t\n\t\t\tthis.reset();\n\t\t});\n\t\t\n\t\tthis.state.view.graph.addListener(mxEvent.ESCAPE, this.escapeHandler);\n\t}\n}", "language": "javascript"}
{"input": "Iterate over the document. Supports two forms -- with only one argument, it calls that for each line in the document. With three, it iterates over the range given by the first two (with the second being non-inclusive).", "output": "function(from, to, op) {\n    if (op) this.iterN(from - this.first, to - from, op)\n    else this.iterN(this.first, this.first + this.size, from)\n  }", "language": "javascript"}
{"input": "set the values from this selection: take = take ownership", "output": "def convert(self, values, nan_rep, encoding, errors):\n        \"\"\" set the values from this selection: take = take ownership \"\"\"\n\n        self.values = Int64Index(np.arange(self.table.nrows))\n        return self", "language": "python"}
{"input": "must be called before calling withinIncludingScrolloffset, every time the page is scrolled", "output": "function() {\n    this.deltaX =  window.pageXOffset\n                || document.documentElement.scrollLeft\n                || document.body.scrollLeft\n                || 0;\n    this.deltaY =  window.pageYOffset\n                || document.documentElement.scrollTop\n                || document.body.scrollTop\n                || 0;\n  }", "language": "javascript"}
{"input": "Print the informations from installed distributions found.", "output": "def print_results(distributions, list_files=False, verbose=False):\n    \"\"\"\n    Print the informations from installed distributions found.\n    \"\"\"\n    results_printed = False\n    for i, dist in enumerate(distributions):\n        results_printed = True\n        if i > 0:\n            logger.info(\"---\")\n\n        name = dist.get('name', '')\n        required_by = [\n            pkg.project_name for pkg in pkg_resources.working_set\n            if name in [required.name for required in pkg.requires()]\n        ]\n\n        logger.info(\"Name: %s\", name)\n        logger.info(\"Version: %s\", dist.get('version', ''))\n        logger.info(\"Summary: %s\", dist.get('summary', ''))\n        logger.info(\"Home-page: %s\", dist.get('home-page', ''))\n        logger.info(\"Author: %s\", dist.get('author', ''))\n        logger.info(\"Author-email: %s\", dist.get('author-email', ''))\n        logger.info(\"License: %s\", dist.get('license', ''))\n        logger.info(\"Location: %s\", dist.get('location', ''))\n        logger.info(\"Requires: %s\", ', '.join(dist.get('requires', [])))\n        logger.info(\"Required-by: %s\", ', '.join(required_by))\n\n        if verbose:\n            logger.info(\"Metadata-Version: %s\",\n                        dist.get('metadata-version', ''))\n            logger.info(\"Installer: %s\", dist.get('installer', ''))\n            logger.info(\"Classifiers:\")\n            for classifier in dist.get('classifiers', []):\n                logger.info(\"  %s\", classifier)\n            logger.info(\"Entry-points:\")\n            for entry in dist.get('entry_points', []):\n                logger.info(\"  %s\", entry.strip())\n        if list_files:\n            logger.info(\"Files:\")\n            for line in dist.get('files', []):\n                logger.info(\"  %s\", line.strip())\n            if \"files\" not in dist:\n                logger.info(\"Cannot locate installed-files.txt\")\n    return results_printed", "language": "python"}
{"input": "Wrap Series left in the given index_class to delegate the operation op\n    to the index implementation.  DatetimeIndex and TimedeltaIndex perform\n    type checking, timezone handling, overflow checks, etc.\n\n    Parameters\n    ----------\n    op : binary operator (operator.add, operator.sub, ...)\n    left : Series\n    right : object\n    index_class : DatetimeIndex or TimedeltaIndex\n\n    Returns\n    -------\n    result : object, usually DatetimeIndex, TimedeltaIndex, or Series", "output": "def dispatch_to_index_op(op, left, right, index_class):\n    \"\"\"\n    Wrap Series left in the given index_class to delegate the operation op\n    to the index implementation.  DatetimeIndex and TimedeltaIndex perform\n    type checking, timezone handling, overflow checks, etc.\n\n    Parameters\n    ----------\n    op : binary operator (operator.add, operator.sub, ...)\n    left : Series\n    right : object\n    index_class : DatetimeIndex or TimedeltaIndex\n\n    Returns\n    -------\n    result : object, usually DatetimeIndex, TimedeltaIndex, or Series\n    \"\"\"\n    left_idx = index_class(left)\n\n    # avoid accidentally allowing integer add/sub.  For datetime64[tz] dtypes,\n    # left_idx may inherit a freq from a cached DatetimeIndex.\n    # See discussion in GH#19147.\n    if getattr(left_idx, 'freq', None) is not None:\n        left_idx = left_idx._shallow_copy(freq=None)\n    try:\n        result = op(left_idx, right)\n    except NullFrequencyError:\n        # DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\n        # on add/sub of integers (or int-like).  We re-raise as a TypeError.\n        raise TypeError('incompatible type for a datetime/timedelta '\n                        'operation [{name}]'.format(name=op.__name__))\n    return result", "language": "python"}
{"input": "-----------------------------------------------------------------------------", "output": "function reapplyDisplayStyles() {\n    reapplyDisplayStyle(\".show-Idl\",        e_showIdl.checked)\n    reapplyDisplayStyle(\".show-JavaScript\", e_showJavaScript.checked)\n    reapplyDisplayStyle(\".show-Java\",       e_showJava.checked)\n}", "language": "javascript"}
{"input": "Writes model gradient statistics to Tensorboard.", "output": "def write(self)->None:\n        \"Writes model gradient statistics to Tensorboard.\"\n        if len(self.gradients) == 0: return\n        norms = [x.data.norm() for x in self.gradients]\n        self._write_avg_norm(norms=norms)\n        self._write_median_norm(norms=norms)\n        self._write_max_norm(norms=norms)\n        self._write_min_norm(norms=norms)\n        self._write_num_zeros()\n        self._write_avg_gradient()\n        self._write_median_gradient()\n        self._write_max_gradient()\n        self._write_min_gradient()", "language": "python"}
{"input": "updateLayout: function (markAreaModel, ecModel, api) { ecModel.eachSeries(function (seriesModel) { var maModel = seriesModel.markAreaModel; if (maModel) { var areaData = maModel.getData(); areaData.each(function (idx) { var points = zrUtil.map(dimPermutations, function (dim) { return getSingleMarkerEndPoint(areaData, idx, dim, seriesModel, api); }); // Layout areaData.setItemLayout(idx, points); var el = areaData.getItemGraphicEl(idx); el.setShape('points', points); }); } }, this); },", "output": "function (markAreaModel, ecModel, api) {\n        ecModel.eachSeries(function (seriesModel) {\n            var maModel = seriesModel.markAreaModel;\n            if (maModel) {\n                var areaData = maModel.getData();\n                areaData.each(function (idx) {\n                    var points = zrUtil.map(dimPermutations, function (dim) {\n                        return getSingleMarkerEndPoint(areaData, idx, dim, seriesModel, api);\n                    });\n                    // Layout\n                    areaData.setItemLayout(idx, points);\n                    var el = areaData.getItemGraphicEl(idx);\n                    el.setShape('points', points);\n                });\n            }\n        }, this);\n    }", "language": "javascript"}
{"input": "************************************ internal functions ************************************", "output": "function onMenuKeyDown(ev) {\n          var handled;\n          switch (ev.keyCode) {\n            case $mdConstant.KEY_CODE.ESCAPE:\n              opts.mdMenuCtrl.close(false, { closeAll: true });\n              handled = true;\n              break;\n            case $mdConstant.KEY_CODE.TAB:\n              opts.mdMenuCtrl.close(false, { closeAll: true });\n              // Don't prevent default or stop propagation on this event as we want tab\n              // to move the focus to the next focusable element on the page.\n              handled = false;\n              break;\n            case $mdConstant.KEY_CODE.UP_ARROW:\n              if (!focusMenuItem(ev, opts.menuContentEl, opts, -1) && !opts.nestLevel) {\n                opts.mdMenuCtrl.triggerContainerProxy(ev);\n              }\n              handled = true;\n              break;\n            case $mdConstant.KEY_CODE.DOWN_ARROW:\n              if (!focusMenuItem(ev, opts.menuContentEl, opts, 1) && !opts.nestLevel) {\n                opts.mdMenuCtrl.triggerContainerProxy(ev);\n              }\n              handled = true;\n              break;\n            case $mdConstant.KEY_CODE.LEFT_ARROW:\n              if (opts.nestLevel) {\n                opts.mdMenuCtrl.close();\n              } else {\n                opts.mdMenuCtrl.triggerContainerProxy(ev);\n              }\n              handled = true;\n              break;\n            case $mdConstant.KEY_CODE.RIGHT_ARROW:\n              var parentMenu = $mdUtil.getClosest(ev.target, 'MD-MENU');\n              if (parentMenu && parentMenu != opts.parent[0]) {\n                ev.target.click();\n              } else {\n                opts.mdMenuCtrl.triggerContainerProxy(ev);\n              }\n              handled = true;\n              break;\n          }\n          if (handled) {\n            ev.preventDefault();\n            ev.stopImmediatePropagation();\n          }\n        }", "language": "javascript"}
{"input": "Generate data for a problem in _SUPPORTED_PROBLEM_GENERATORS.", "output": "def generate_data_for_problem(problem):\n  \"\"\"Generate data for a problem in _SUPPORTED_PROBLEM_GENERATORS.\"\"\"\n  training_gen, dev_gen, test_gen = _SUPPORTED_PROBLEM_GENERATORS[problem]\n\n  num_train_shards = FLAGS.num_shards or 10\n  tf.logging.info(\"Generating training data for %s.\", problem)\n  train_output_files = generator_utils.train_data_filenames(\n      problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n      num_train_shards)\n  generator_utils.generate_files(training_gen(), train_output_files,\n                                 FLAGS.max_cases)\n  num_dev_shards = int(num_train_shards * 0.1)\n  tf.logging.info(\"Generating development data for %s.\", problem)\n  dev_output_files = generator_utils.dev_data_filenames(\n      problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n      num_dev_shards)\n  generator_utils.generate_files(dev_gen(), dev_output_files)\n  num_test_shards = int(num_train_shards * 0.1)\n  test_output_files = []\n  test_gen_data = test_gen()\n  if test_gen_data is not None:\n    tf.logging.info(\"Generating test data for %s.\", problem)\n    test_output_files = generator_utils.test_data_filenames(\n        problem + generator_utils.UNSHUFFLED_SUFFIX, FLAGS.data_dir,\n        num_test_shards)\n    generator_utils.generate_files(test_gen_data, test_output_files)\n  all_output_files = train_output_files + dev_output_files + test_output_files\n  generator_utils.shuffle_dataset(all_output_files)", "language": "python"}
{"input": "Translate any partial string timestamp matches in key, returning the\n        new key (GH 10331)", "output": "def _get_partial_string_timestamp_match_key(self, key, labels):\n        \"\"\"Translate any partial string timestamp matches in key, returning the\n        new key (GH 10331)\"\"\"\n        if isinstance(labels, MultiIndex):\n            if (isinstance(key, str) and labels.levels[0].is_all_dates):\n                # Convert key '2016-01-01' to\n                # ('2016-01-01'[, slice(None, None, None)]+)\n                key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))\n\n            if isinstance(key, tuple):\n                # Convert (..., '2016-01-01', ...) in tuple to\n                # (..., slice('2016-01-01', '2016-01-01', None), ...)\n                new_key = []\n                for i, component in enumerate(key):\n                    if (isinstance(component, str) and\n                            labels.levels[i].is_all_dates):\n                        new_key.append(slice(component, component, None))\n                    else:\n                        new_key.append(component)\n                key = tuple(new_key)\n\n        return key", "language": "python"}
{"input": "Validate Booster and data's feature_names are identical.\n        Set feature_names and feature_types from DMatrix", "output": "def _validate_features(self, data):\n        \"\"\"\n        Validate Booster and data's feature_names are identical.\n        Set feature_names and feature_types from DMatrix\n        \"\"\"\n        if self.feature_names is None:\n            self.feature_names = data.feature_names\n            self.feature_types = data.feature_types\n        else:\n            # Booster can't accept data with different feature names\n            if self.feature_names != data.feature_names:\n                dat_missing = set(self.feature_names) - set(data.feature_names)\n                my_missing = set(data.feature_names) - set(self.feature_names)\n\n                msg = 'feature_names mismatch: {0} {1}'\n\n                if dat_missing:\n                    msg += ('\\nexpected ' + ', '.join(str(s) for s in dat_missing) +\n                            ' in input data')\n\n                if my_missing:\n                    msg += ('\\ntraining data did not have the following fields: ' +\n                            ', '.join(str(s) for s in my_missing))\n\n                raise ValueError(msg.format(self.feature_names,\n                                            data.feature_names))", "language": "python"}
{"input": "Subtract ImageNet mean pixel-wise from a BGR image.", "output": "def subtract_imagenet_mean_preprocess_batch(batch):\n    \"\"\"Subtract ImageNet mean pixel-wise from a BGR image.\"\"\"\n    batch = F.swapaxes(batch,0, 1)\n    (r, g, b) = F.split(batch, num_outputs=3, axis=0)\n    r = r - 123.680\n    g = g - 116.779\n    b = b - 103.939\n    batch = F.concat(b, g, r, dim=0)\n    batch = F.swapaxes(batch,0, 1)\n    return batch", "language": "python"}
{"input": "Overrides the default whitespace chars", "output": "def setWhitespaceChars( self, chars ):\n        \"\"\"\n        Overrides the default whitespace chars\n        \"\"\"\n        self.skipWhitespace = True\n        self.whiteChars = chars\n        self.copyDefaultWhiteChars = False\n        return self", "language": "python"}
{"input": "GEXF File Parser http://gexf.net/1.2draft/gexf-12draft-primer.pdf", "output": "function parse(xml) {\n    var doc;\n    if (typeof xml === 'string') {\n        var parser = new DOMParser();\n        doc = parser.parseFromString(xml, 'text/xml');\n    }\n    else {\n        doc = xml;\n    }\n    if (!doc || doc.getElementsByTagName('parsererror').length) {\n        return null;\n    }\n\n    var gexfRoot = getChildByTagName(doc, 'gexf');\n\n    if (!gexfRoot) {\n        return null;\n    }\n\n    var graphRoot = getChildByTagName(gexfRoot, 'graph');\n\n    var attributes = parseAttributes(getChildByTagName(graphRoot, 'attributes'));\n    var attributesMap = {};\n    for (var i = 0; i < attributes.length; i++) {\n        attributesMap[attributes[i].id] = attributes[i];\n    }\n\n    return {\n        nodes: parseNodes(getChildByTagName(graphRoot, 'nodes'), attributesMap),\n        links: parseEdges(getChildByTagName(graphRoot, 'edges'))\n    };\n}", "language": "javascript"}
{"input": "Abstraction layer for different transport layers, including fleegix/jQuery/Zepto  Object `opts` include  - `url`: url to ajax query  - `async`: true for asynchronous, false otherwise. If false, return value will be response from URL. This is true by default  - `success`: success callback function  - `error`: error callback function Returns response from URL if async is false, otherwise the AJAX request object itself", "output": "function (opts) {\n    if ((!fleegix || typeof fleegix.xhr === 'undefined') && (!$ || typeof $.ajax === 'undefined')) {\n      throw new Error('Please use the Fleegix.js XHR module, jQuery ajax, Zepto ajax, or define your own transport mechanism for downloading zone files.');\n    }\n    if (!opts) return;\n    if (!opts.url) throw new Error ('URL must be specified');\n    if (!('async' in opts)) opts.async = true;\n    if (!opts.async) {\n      return fleegix && fleegix.xhr\n      ? fleegix.xhr.doReq({ url: opts.url, async: false })\n      : $.ajax({ url : opts.url, async : false }).responseText;\n    }\n    return fleegix && fleegix.xhr\n    ? fleegix.xhr.send({\n      url : opts.url,\n      method : 'get',\n      handleSuccess : opts.success,\n      handleErr : opts.error\n    })\n    : $.ajax({\n      url : opts.url,\n      dataType: 'text',\n      method : 'GET',\n      error : opts.error,\n      success : opts.success\n    });\n  }", "language": "javascript"}
{"input": "Lower text and remove punctuation, articles and extra whitespace.", "output": "def _normalize_answer(text: str) -> str:\n    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n\n    parts = [_white_space_fix(_remove_articles(_normalize_number(_remove_punc(_lower(token)))))\n             for token in _tokenize(text)]\n    parts = [part for part in parts if part.strip()]\n    normalized = ' '.join(parts).strip()\n    return normalized", "language": "python"}
{"input": "Override dropbox cloud-providers url\nhttps://www.dropbox.com/s/bxwwdb81z0jg7pb/keplergl_2018-11-01T23%3A22%3A43.940Z.json?dl=0\n->\nhttps://dl.dropboxusercontent.com/s/bxwwdb81z0jg7pb/keplergl_2018-11-01T23%3A22%3A43.940Z.json\n@param metadata\n@returns {DropboxTypes.sharing.FileLinkMetadataReference}", "output": "function overrideUrl(url) {\n  return url ? url.slice(0, url.indexOf('?')).replace(DOMAIN, CORS_FREE_DOMAIN) : null;\n}", "language": "javascript"}
{"input": "Return a new :class:`DataFrame` containing rows only in\n        both this frame and another frame.\n\n        This is equivalent to `INTERSECT` in SQL.", "output": "def intersect(self, other):\n        \"\"\" Return a new :class:`DataFrame` containing rows only in\n        both this frame and another frame.\n\n        This is equivalent to `INTERSECT` in SQL.\n        \"\"\"\n        return DataFrame(self._jdf.intersect(other._jdf), self.sql_ctx)", "language": "python"}
{"input": "Renames a control.\n\n@param {sap.ui.fl.Change} oChange change wrapper object with instructions to be applied on the control map\n@param {sap.ui.core.Control} oControl Control that matches the change selector for applying the change\n@param {object} mPropertyBag property bag\n@param {object} mPropertyBag.modifier modifier for the controls\n@returns {boolean} true if successful\n@public", "output": "function(oChange, oControl, mPropertyBag) {\n\t\t\t\t\tvar oModifier = mPropertyBag.modifier;\n\t\t\t\t\tvar sPropertyName = mRenameSettings.propertyName;\n\t\t\t\t\tvar oChangeDefinition = oChange.getDefinition();\n\t\t\t\t\tvar sText = oChangeDefinition.texts[mRenameSettings.changePropertyName];\n\t\t\t\t\tvar sValue = sText.value;\n\n\t\t\t\t\tif (oChangeDefinition.texts && sText && typeof (sValue) === \"string\") {\n\t\t\t\t\t\toChange.setRevertData(oModifier.getPropertyBindingOrProperty(oControl, sPropertyName));\n\t\t\t\t\t\toModifier.setPropertyBindingOrProperty(oControl, sPropertyName, sValue);\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tUtils.log.error(\"Change does not contain sufficient information to be applied: [\" + oChangeDefinition.layer + \"]\" + oChangeDefinition.namespace + \"/\" + oChangeDefinition.fileName + \".\" + oChangeDefinition.fileType);\n\t\t\t\t\t\t//however subsequent changes should be applied\n\t\t\t\t\t}\n\t\t\t\t}", "language": "javascript"}
{"input": "accumulate samples and batches", "output": "def on_batch_begin(self, last_input, last_target, **kwargs):\n        \"accumulate samples and batches\"\n        self.acc_samples += last_input.shape[0]\n        self.acc_batches += 1", "language": "python"}
{"input": "Retrieve the tab's title box\n\n@param {object} aSpec\nInformation on which tab to operate on\nElements: tab - Tab\n\n@returns Tab title box\n@type {ElemBase}", "output": "function tabView_getTabTitleBox(aSpec) {\n    var spec = aSpec || {};\n    var tab = spec.tab;\n\n    if (!tab) {\n      throw new Error(arguments.callee.name + \": Tab not specified.\");\n    }\n\n    return this.getElement({\n      type: \"tab_titleBox\",\n      parent: spec.tab\n    });\n  }", "language": "javascript"}
{"input": "Normalize option value.\n\n@param {string|Object|undefined} optionValue - The 1st option value to normalize.\n@returns {Object} The normalized option value.", "output": "function normalizeOptions(optionValue) {\n    if (typeof optionValue === \"string\") {\n        return {\n            arrays: optionValue,\n            objects: optionValue,\n            imports: optionValue,\n            exports: optionValue,\n\n            // For backward compatibility, always ignore functions.\n            functions: \"ignore\"\n        };\n    }\n    if (typeof optionValue === \"object\" && optionValue !== null) {\n        return {\n            arrays: optionValue.arrays || DEFAULT_OPTIONS.arrays,\n            objects: optionValue.objects || DEFAULT_OPTIONS.objects,\n            imports: optionValue.imports || DEFAULT_OPTIONS.imports,\n            exports: optionValue.exports || DEFAULT_OPTIONS.exports,\n            functions: optionValue.functions || DEFAULT_OPTIONS.functions\n        };\n    }\n\n    return DEFAULT_OPTIONS;\n}", "language": "javascript"}
{"input": "Cleanup the dom changes previously done by <code>updateTableRowForGrouping</code>.\n\n@param {sap.ui.table.Table} oTable Instance of the table\n@param {sap.ui.table.Row} oRow Instance of the row", "output": "function(oTable, oRow) {\n\t\t\tvar oDomRefs = oRow.getDomRefs(true);\n\n\t\t\toDomRefs.row.removeAttr(\"data-sap-ui-level\");\n\t\t\toDomRefs.row.removeData(\"sap-ui-level\");\n\n\t\t\tif (TableGrouping.isGroupMode(oTable)) {\n\t\t\t\toDomRefs.row.removeClass(\"sapUiTableGroupHeader sapUiAnalyticalTableSum sapUiAnalyticalTableDummy\");\n\t\t\t\tTableGrouping.setIndent(oTable, oDomRefs.row, oDomRefs.rowSelector, 0);\n\t\t\t}\n\n\t\t\tvar $TreeIcon = null;\n\t\t\tif (TableGrouping.isTreeMode(oTable)) {\n\t\t\t\t$TreeIcon = oDomRefs.row.find(\".sapUiTableTreeIcon\");\n\t\t\t\t$TreeIcon.removeClass(\"sapUiTableTreeIconLeaf\")\n\t\t\t\t\t\t .removeClass(\"sapUiTableTreeIconNodeOpen\")\n\t\t\t\t\t\t .removeClass(\"sapUiTableTreeIconNodeClosed\")\n\t\t\t\t\t\t .css(this._bRtlMode ? \"margin-right\" : \"margin-left\", \"\");\n\t\t\t}\n\n\t\t\toTable._getAccExtension()\n\t\t\t\t  .updateAriaExpandAndLevelState(oRow, oDomRefs.rowScrollPart, oDomRefs.rowSelector, oDomRefs.rowFixedPart, oDomRefs.rowAction, false,\n\t\t\t\t\t  false, -1, $TreeIcon);\n\t\t}", "language": "javascript"}
{"input": "Infer response-type attribute from src.\nDefault is text(default XMLHttpRequest.responseType)\nbut we use arraybuffer for .gltf and .glb files\nbecause of THREE.GLTFLoader specification.\n\n@param {string} src\n@returns {string}", "output": "function inferResponseType (src) {\n  var dotLastIndex = src.lastIndexOf('.');\n  if (dotLastIndex >= 0) {\n    var extension = src.slice(dotLastIndex, src.length);\n    if (extension === '.gltf' || extension === '.glb') {\n      return 'arraybuffer';\n    }\n  }\n  return 'text';\n}", "language": "javascript"}
{"input": "/*\nFires a \"change\" event and refreshes dependent bindings.\n@returns {sap.ui.base.SyncPromise} A promise resolving when the refresh is finished", "output": "function fireChangeAndRefreshDependentBindings() {\n\t\t\tthat._fireChange({reason : ChangeReason.Change});\n\t\t\treturn that.refreshDependentBindings(\"\", oGroupLock.getGroupId(), true);\n\t\t}", "language": "javascript"}
{"input": "Remove the listeners that were tracking potential search result changes", "output": "function _removeListeners() {\n        DocumentModule.off(\"documentChange\", _documentChangeHandler);\n        FileSystem.off(\"change\", _debouncedFileSystemChangeHandler);\n        DocumentManager.off(\"fileNameChange\", _fileNameChangeHandler);\n    }", "language": "javascript"}
{"input": "Instantiate a :class:`Predictor` from an :class:`~allennlp.models.archival.Archive`;\n        that is, from the result of training a model. Optionally specify which `Predictor`\n        subclass; otherwise, the default one for the model will be used.", "output": "def from_archive(cls, archive: Archive, predictor_name: str = None) -> 'Predictor':\n        \"\"\"\n        Instantiate a :class:`Predictor` from an :class:`~allennlp.models.archival.Archive`;\n        that is, from the result of training a model. Optionally specify which `Predictor`\n        subclass; otherwise, the default one for the model will be used.\n        \"\"\"\n        # Duplicate the config so that the config inside the archive doesn't get consumed\n        config = archive.config.duplicate()\n\n        if not predictor_name:\n            model_type = config.get(\"model\").get(\"type\")\n            if not model_type in DEFAULT_PREDICTORS:\n                raise ConfigurationError(f\"No default predictor for model type {model_type}.\\n\"\\\n                                         f\"Please specify a predictor explicitly.\")\n            predictor_name = DEFAULT_PREDICTORS[model_type]\n\n        dataset_reader_params = config[\"dataset_reader\"]\n        dataset_reader = DatasetReader.from_params(dataset_reader_params)\n\n        model = archive.model\n        model.eval()\n\n        return Predictor.by_name(predictor_name)(model, dataset_reader)", "language": "python"}
{"input": "generate loader string to be used with extract text plugin", "output": "function generateLoaders (loader, loaderOptions) {\n    const loaders = options.usePostCSS ? [cssLoader, postcssLoader] : [cssLoader]\n    if (loader) {\n      loaders.push({\n        loader: loader + '-loader',\n        options: Object.assign({}, loaderOptions, {\n          sourceMap: options.sourceMap\n        })\n      })\n    }\n\n    // Extract CSS when that option is specified\n    // (which is the case during production build)\n    if (options.extract) {\n      return ExtractTextPlugin.extract({\n        use: loaders,\n        fallback: 'vue-style-loader'\n      })\n    } else {\n      return ['vue-style-loader'].concat(loaders)\n    }\n  }", "language": "javascript"}
{"input": "Execute SQL statement inserting data\n\n        Parameters\n        ----------\n        conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection\n        keys : list of str\n           Column names\n        data_iter : generator of list\n           Each item contains a list of values to be inserted", "output": "def _execute_insert(self, conn, keys, data_iter):\n        \"\"\"Execute SQL statement inserting data\n\n        Parameters\n        ----------\n        conn : sqlalchemy.engine.Engine or sqlalchemy.engine.Connection\n        keys : list of str\n           Column names\n        data_iter : generator of list\n           Each item contains a list of values to be inserted\n        \"\"\"\n        data = [dict(zip(keys, row)) for row in data_iter]\n        conn.execute(self.table.insert(), data)", "language": "python"}
{"input": "Update mgr._blknos / mgr._blklocs.", "output": "def _rebuild_blknos_and_blklocs(self):\n        \"\"\"\n        Update mgr._blknos / mgr._blklocs.\n        \"\"\"\n        new_blknos = np.empty(self.shape[0], dtype=np.int64)\n        new_blklocs = np.empty(self.shape[0], dtype=np.int64)\n        new_blknos.fill(-1)\n        new_blklocs.fill(-1)\n\n        for blkno, blk in enumerate(self.blocks):\n            rl = blk.mgr_locs\n            new_blknos[rl.indexer] = blkno\n            new_blklocs[rl.indexer] = np.arange(len(rl))\n\n        if (new_blknos == -1).any():\n            raise AssertionError(\"Gaps in blk ref_locs\")\n\n        self._blknos = new_blknos\n        self._blklocs = new_blklocs", "language": "python"}
{"input": "Save Dataset to a text file.\n\n        This format cannot be loaded back in by LightGBM, but is useful for debugging purposes.\n\n        Parameters\n        ----------\n        filename : string\n            Name of the output file.\n\n        Returns\n        -------\n        self : Dataset\n            Returns self.", "output": "def dump_text(self, filename):\n        \"\"\"Save Dataset to a text file.\n\n        This format cannot be loaded back in by LightGBM, but is useful for debugging purposes.\n\n        Parameters\n        ----------\n        filename : string\n            Name of the output file.\n\n        Returns\n        -------\n        self : Dataset\n            Returns self.\n        \"\"\"\n        _safe_call(_LIB.LGBM_DatasetDumpText(\n            self.construct().handle,\n            c_str(filename)))\n        return self", "language": "python"}
{"input": "Show documentation for `ft_name`, see `show_doc`.", "output": "def show_doc_from_name(mod_name, ft_name:str, doc_string:bool=True, arg_comments:dict={}, alt_doc_string:str=''):\n    \"Show documentation for `ft_name`, see `show_doc`.\"\n    mod = import_mod(mod_name)\n    splits = str.split(ft_name, '.')\n    assert hasattr(mod, splits[0]), print(f\"Module {mod_name} doesn't have a function named {splits[0]}.\")\n    elt = getattr(mod, splits[0])\n    for i,split in enumerate(splits[1:]):\n        assert hasattr(elt, split), print(f\"Class {'.'.join(splits[:i+1])} doesn't have a function named {split}.\")\n        elt = getattr(elt, split)\n    show_doc(elt, doc_string, ft_name, arg_comments, alt_doc_string)", "language": "python"}
{"input": "/*\nsets the date in the used Month controls\n@param {boolean} bSkipFocus if set no focus is set to the date", "output": "function _renderTimesRow(bSkipFocus){\n\n\t\tvar oDate = this._getFocusedDate();\n\t\tvar oTimesRow = this.getAggregation(\"timesRow\");\n\n\t\tif (!bSkipFocus) {\n\t\t\toTimesRow.setDate(CalendarUtils._createLocalDate(oDate, true));\n\t\t} else {\n\t\t\toTimesRow.displayDate(CalendarUtils._createLocalDate(oDate, true));\n\t\t}\n\n\t\t// change header buttons\n\t\t_updateHeader.call(this);\n\n\t}", "language": "javascript"}
{"input": "Collect common metadata for each object in the value tree, ensuring that equivalent values have the *same reference* to the same metadata. Note that the hashes generated are not exactly JSON, but still identify equivalent values. Runs in linear time due to hashing in a bottom-up recursion.", "output": "function collectMetadata(value) {\n    if (value == null || typeof value !== 'object') {\n      return JSON.stringify(value);\n    }\n    let hash;\n    if (Array.isArray(value)) {\n      hash = '[';\n      for (let i = 0; i < value.length; i++) {\n        hash += collectMetadata(value[i]) + ',';\n      }\n    } else {\n      hash = '{';\n      for (const k in value) {\n        if (value.hasOwnProperty(k) && value[k] !== undefined) {\n          hash += k + ':' + collectMetadata(value[k]) + ',';\n        }\n      }\n    }\n    let metadata = metadataForHash.get(hash);\n    if (!metadata) {\n      metadata = {value, hash, isDuplicate: false};\n      metadataForHash.set(hash, metadata);\n    }\n    metadataForVal.set(value, metadata);\n    return hash;\n  }", "language": "javascript"}
{"input": "Find the n largest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]", "output": "def nlargest(n, iterable, key=None):\n    \"\"\"Find the n largest elements in a dataset.\n\n    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]\n    \"\"\"\n\n    # Short-cut for n==1 is to use max()\n    if n == 1:\n        it = iter(iterable)\n        sentinel = object()\n        if key is None:\n            result = max(it, default=sentinel)\n        else:\n            result = max(it, default=sentinel, key=key)\n        return [] if result is sentinel else [result]\n\n    # When n>=size, it's faster to use sorted()\n    try:\n        size = len(iterable)\n    except (TypeError, AttributeError):\n        pass\n    else:\n        if n >= size:\n            return sorted(iterable, key=key, reverse=True)[:n]\n\n    # When key is none, use simpler decoration\n    if key is None:\n        it = iter(iterable)\n        result = [(elem, i) for i, elem in zip(range(0, -n, -1), it)]\n        if not result:\n            return result\n        heapify(result)\n        top = result[0][0]\n        order = -n\n        _heapreplace = heapreplace\n        for elem in it:\n            if top < elem:\n                _heapreplace(result, (elem, order))\n                top = result[0][0]\n                order -= 1\n        result.sort(reverse=True)\n        return [r[0] for r in result]\n\n    # General case, slowest method\n    it = iter(iterable)\n    result = [(key(elem), i, elem) for i, elem in zip(range(0, -n, -1), it)]\n    if not result:\n        return result\n    heapify(result)\n    top = result[0][0]\n    order = -n\n    _heapreplace = heapreplace\n    for elem in it:\n        k = key(elem)\n        if top < k:\n            _heapreplace(result, (k, order, elem))\n            top = result[0][0]\n            order -= 1\n    result.sort(reverse=True)\n    return [r[2] for r in result]", "language": "python"}
{"input": "Returns the CloudWatch Logs Subscription Filter and Lambda Permission to which this CloudWatch Logs event source\n        corresponds.\n\n        :param dict kwargs: no existing resources need to be modified\n        :returns: a list of vanilla CloudFormation Resources, to which this push event expands\n        :rtype: list", "output": "def to_cloudformation(self, **kwargs):\n        \"\"\"Returns the CloudWatch Logs Subscription Filter and Lambda Permission to which this CloudWatch Logs event source\n        corresponds.\n\n        :param dict kwargs: no existing resources need to be modified\n        :returns: a list of vanilla CloudFormation Resources, to which this push event expands\n        :rtype: list\n        \"\"\"\n        function = kwargs.get('function')\n\n        if not function:\n            raise TypeError(\"Missing required keyword argument: function\")\n\n        source_arn = self.get_source_arn()\n        permission = self._construct_permission(function, source_arn=source_arn)\n        subscription_filter = self.get_subscription_filter(function, permission)\n        resources = [permission, subscription_filter]\n\n        return resources", "language": "python"}
{"input": ":type nums: List[int]\n    :rtype: List[int]", "output": "def single_number3(nums):\n    \"\"\"\n    :type nums: List[int]\n    :rtype: List[int]\n    \"\"\"\n    # isolate a^b from pairs using XOR\n    ab = 0\n    for n in nums:\n        ab ^= n\n\n    # isolate right most bit from a^b\n    right_most = ab & (-ab)\n\n    # isolate a and b from a^b\n    a, b = 0, 0\n    for n in nums:\n        if n & right_most:\n            a ^= n\n        else:\n            b ^= n\n    return [a, b]", "language": "python"}
{"input": "Return the diabetes data in a nice package.", "output": "def diabetes(display=False):\n    \"\"\" Return the diabetes data in a nice package. \"\"\"\n\n    d = sklearn.datasets.load_diabetes()\n    df = pd.DataFrame(data=d.data, columns=d.feature_names) # pylint: disable=E1101\n    return df, d.target", "language": "python"}
{"input": "Is this an appropriate context to generate summaries.\n\n  Returns:\n    a boolean", "output": "def should_generate_summaries():\n  \"\"\"Is this an appropriate context to generate summaries.\n\n  Returns:\n    a boolean\n  \"\"\"\n  name_scope = tf.contrib.framework.get_name_scope()\n  if name_scope and \"while/\" in name_scope:\n    # Summaries don't work well within tf.while_loop()\n    return False\n  if tf.get_variable_scope().reuse:\n    # Avoid generating separate summaries for different data shards\n    return False\n  return True", "language": "python"}
{"input": "Checks if the input data is a Swagger document\n\n        :param dict data: Data to be validated\n        :return: True, if data is a Swagger", "output": "def is_valid(data):\n        \"\"\"\n        Checks if the input data is a Swagger document\n\n        :param dict data: Data to be validated\n        :return: True, if data is a Swagger\n        \"\"\"\n        return bool(data) and \\\n            isinstance(data, dict) and \\\n            bool(data.get(\"swagger\")) and \\\n            isinstance(data.get('paths'), dict)", "language": "python"}
{"input": "Create HParams suitable for training loop from scoped HParams.\n\n  Args:\n    scoped_overrides: HParams, with keys all scoped by one of HP_SCOPES. These\n      parameters are overrides for the base HParams created by\n      create_loop_hparams.\n    trial_id: str, trial identifier. This is used to register unique HParams\n      names for the underlying model and ppo HParams.\n\n  Returns:\n    HParams suitable for passing to training_loop.", "output": "def training_loop_hparams_from_scoped_overrides(scoped_overrides, trial_id):\n  \"\"\"Create HParams suitable for training loop from scoped HParams.\n\n  Args:\n    scoped_overrides: HParams, with keys all scoped by one of HP_SCOPES. These\n      parameters are overrides for the base HParams created by\n      create_loop_hparams.\n    trial_id: str, trial identifier. This is used to register unique HParams\n      names for the underlying model and ppo HParams.\n\n  Returns:\n    HParams suitable for passing to training_loop.\n  \"\"\"\n  trial_hp_overrides = scoped_overrides.values()\n\n  # Create loop, model, and ppo base HParams\n  loop_hp = create_loop_hparams()\n  model_hp_name = trial_hp_overrides.get(\n      \"loop.generative_model_params\", loop_hp.generative_model_params)\n  model_hp = registry.hparams(model_hp_name).parse(FLAGS.hparams)\n  base_algo_params_name = trial_hp_overrides.get(\n      \"loop.base_algo_params\", loop_hp.base_algo_params)\n  algo_hp = registry.hparams(base_algo_params_name)\n\n  # Merge them and then override with the scoped overrides\n  combined_hp = merge_unscoped_hparams(\n      zip(HP_SCOPES, [loop_hp, model_hp, algo_hp]))\n  combined_hp.override_from_dict(trial_hp_overrides)\n\n  # Split out the component hparams\n  loop_hp, model_hp, algo_hp = (\n      split_scoped_hparams(HP_SCOPES, combined_hp))\n\n  # Dynamic register the model hp and set the new name in loop_hp\n  model_hp_name = \"model_hp_%s\" % str(trial_id)\n  dynamic_register_hparams(model_hp_name, model_hp)\n  loop_hp.generative_model_params = model_hp_name\n\n  # Dynamic register the algo hp and set the new name in loop_hp\n  algo_hp_name = \"algo_hp_%s\" % str(trial_id)\n  dynamic_register_hparams(algo_hp_name, algo_hp)\n  loop_hp.base_algo_params = algo_hp_name\n\n  return loop_hp", "language": "python"}
{"input": "Get the value for the OData system query option $orderby corresponding to\nthis expression.\n\n@param {object} oSelectedPropertyNames Object with properties requested for $select\n\n@returns {string} The $orderby value for the sort expressions\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.SortExpression#getURIOrderByOptionValue", "output": "function(oSelectedPropertyNames) {\n\t\t\tif (this._aSortCondition.length == 0) {\n\t\t\t\treturn \"\";\n\t\t\t}\n\n\t\t\tvar sOrderByOptionString = \"\";\n\t\t\tfor (var i = -1, oCondition; (oCondition = this._aSortCondition[++i]) !== undefined;) {\n\t\t\t\tif (!oSelectedPropertyNames[oCondition.property.name]) {\n\t\t\t\t\tcontinue; // sorting of aggregated entities is meaningful only if the sorted property is also selected\n\t\t\t\t}\n\t\t\t\tsOrderByOptionString += (sOrderByOptionString == \"\" ? \"\" : \",\") + oCondition.property.name + \" \" + oCondition.order;\n\t\t\t}\n\n\t\t\treturn sOrderByOptionString;\n\t\t}", "language": "javascript"}
{"input": "Downloads images in `img_tuples` to `label_path`. \n    If the directory doesn't exist, it'll be created automatically.\n    Uses `parallel` to speed things up in `max_workers` when the system has enough CPU cores.\n    If something doesn't work, try setting up `max_workers=0` to debug.", "output": "def _download_images(label_path:PathOrStr, img_tuples:list, max_workers:int=defaults.cpus, timeout:int=4) -> FilePathList:\n    \"\"\"\n    Downloads images in `img_tuples` to `label_path`. \n    If the directory doesn't exist, it'll be created automatically.\n    Uses `parallel` to speed things up in `max_workers` when the system has enough CPU cores.\n    If something doesn't work, try setting up `max_workers=0` to debug.\n    \"\"\"\n    os.makedirs(Path(label_path), exist_ok=True)\n    parallel( partial(_download_single_image, label_path, timeout=timeout), img_tuples, max_workers=max_workers)\n    return get_image_files(label_path)", "language": "python"}
{"input": "Returns a sorted list of all production rules in the grammar induced by\n        :func:`get_nonterminal_productions`.", "output": "def all_possible_productions(self) -> List[str]:\n        \"\"\"\n        Returns a sorted list of all production rules in the grammar induced by\n        :func:`get_nonterminal_productions`.\n        \"\"\"\n        all_actions = set()\n        for action_set in self.get_nonterminal_productions().values():\n            all_actions.update(action_set)\n        return sorted(all_actions)", "language": "python"}
{"input": "Handler for `mousedown`.\n\n@this {MouseSource}\n@param {MouseEvent} inEvent The in event.", "output": "function mousedown(inEvent) {\n  if (!this.isEventSimulatedFromTouch_(inEvent)) {\n    // TODO(dfreedman) workaround for some elements not sending mouseup\n    // http://crbug/149091\n    if (POINTER_ID.toString() in this.pointerMap) {\n      this.cancel(inEvent);\n    }\n    const e = prepareEvent(inEvent, this.dispatcher);\n    this.pointerMap[POINTER_ID.toString()] = inEvent;\n    this.dispatcher.down(e, inEvent);\n  }\n}", "language": "javascript"}
{"input": "Calculate a single point for a quadratic bezier curve.\nUtility function used by quadraticBezierCurve.\nIgnored from docs since it is not directly exposed.\n\n@ignore\n@private\n@param {number} n1 - first number\n@param {number} n2 - second number\n@param {number} perc - percentage\n@return {number} the result", "output": "function getPt(n1, n2, perc)\n{\n    const diff = n2 - n1;\n\n    return n1 + (diff * perc);\n}", "language": "javascript"}
{"input": "Checks whether or not a given node is allowed as non backtick.\n@param {ASTNode} node - A node to check.\n@returns {boolean} Whether or not the node is allowed as non backtick.\n@private", "output": "function isAllowedAsNonBacktick(node) {\n            const parent = node.parent;\n\n            switch (parent.type) {\n\n                // Directive Prologues.\n                case \"ExpressionStatement\":\n                    return isPartOfDirectivePrologue(node);\n\n                // LiteralPropertyName.\n                case \"Property\":\n                case \"MethodDefinition\":\n                    return parent.key === node && !parent.computed;\n\n                // ModuleSpecifier.\n                case \"ImportDeclaration\":\n                case \"ExportNamedDeclaration\":\n                case \"ExportAllDeclaration\":\n                    return parent.source === node;\n\n                // Others don't allow.\n                default:\n                    return false;\n            }\n        }", "language": "javascript"}
{"input": "Deprecate a property of an object\n\n@param {Book|Output} book\n@param {String} key: unique identitifer for the deprecated\n@param {Object} instance\n@param {String|Function} property\n@param {String} msg: message to print when called\n@return {Function}", "output": "function deprecateField(book, key, instance, property, value, msg) {\n    var store = undefined;\n\n    var prepare = function() {\n        if (!is.undefined(store)) return;\n\n        if (is.fn(value)) store = value();\n        else store = value;\n    };\n\n    var getter = function(){\n        prepare();\n\n        logNotice(book, key, msg);\n        return store;\n    };\n    var setter = function(v) {\n        prepare();\n\n        logNotice(book, key, msg);\n        store = v;\n        return store;\n    };\n\n    Object.defineProperty(instance, property, {\n        get: getter,\n        set: setter,\n        enumerable: true,\n        configurable: true\n    });\n}", "language": "javascript"}
{"input": "Parse string data into swagger 2.0 object (https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md#swagger-object)\n\n@param {string} rawData\n\n@returns {Object|null} Swagger 2.0 object", "output": "async function parseDocument(rawData) {\n  try {\n    return utils.unthrowableParseJson(rawData) || SwaggerParser.YAML.parse(rawData);\n  } catch (err) {\n    return null;\n  }\n}", "language": "javascript"}
{"input": "Get the entire list of labels of the dictionary optionally\n        including the frequency of the individual labels. Unsupervised\n        models use words as labels, which is why get_labels\n        will call and return get_words for this type of\n        model.", "output": "def get_labels(self, include_freq=False, on_unicode_error='strict'):\n        \"\"\"\n        Get the entire list of labels of the dictionary optionally\n        including the frequency of the individual labels. Unsupervised\n        models use words as labels, which is why get_labels\n        will call and return get_words for this type of\n        model.\n        \"\"\"\n        a = self.f.getArgs()\n        if a.model == model_name.supervised:\n            pair = self.f.getLabels(on_unicode_error)\n            if include_freq:\n                return (pair[0], np.array(pair[1]))\n            else:\n                return pair[0]\n        else:\n            return self.get_words(include_freq)", "language": "python"}
{"input": "\u56fe\u8fb9\n@alias module:echarts/data/Graph.Edge\n@param {module:echarts/data/Graph.Node} n1\n@param {module:echarts/data/Graph.Node} n2\n@param {number} [dataIndex=-1]", "output": "function Edge(n1, n2, dataIndex) {\n\n    /**\n     * \u8282\u70b91\uff0c\u5982\u679c\u662f\u6709\u5411\u56fe\u5219\u4e3a\u6e90\u8282\u70b9\n     * @type {module:echarts/data/Graph.Node}\n     */\n    this.node1 = n1;\n\n    /**\n     * \u8282\u70b92\uff0c\u5982\u679c\u662f\u6709\u5411\u56fe\u5219\u4e3a\u76ee\u6807\u8282\u70b9\n     * @type {module:echarts/data/Graph.Node}\n     */\n    this.node2 = n2;\n\n    this.dataIndex = dataIndex == null ? -1 : dataIndex;\n}", "language": "javascript"}
{"input": "Loads a configuration file from the given file path.\n@param {Object} configInfo The value from calling resolve() on a filename or package name.\n@param {Config} configContext Config context\n@returns {Object} The configuration information.", "output": "function loadFromDisk(configInfo, configContext) {\n    const config = loadConfigFile(configInfo);\n\n    // loadConfigFile will return null for a `package.json` file that does not have an `eslintConfig` property.\n    if (config) {\n        return loadObject(configContext, { config, filePath: configInfo.filePath, configFullName: configInfo.configFullName });\n    }\n\n    return null;\n}", "language": "javascript"}
{"input": "Small single parameters.", "output": "def mtf_resnet_base_single():\n  \"\"\"Small single parameters.\"\"\"\n  hparams = mtf_resnet_base()\n  hparams.num_layers = 6\n  hparams.filter_size = 256\n  hparams.block_length = 128\n  hparams.mesh_shape = \"\"\n  hparams.layout = \"\"\n  return hparams", "language": "python"}
{"input": "Input fn for serving export, starting from serialized example.", "output": "def serving_input_fn(self, hparams, decode_hparams=None, use_tpu=False):\n    \"\"\"Input fn for serving export, starting from serialized example.\"\"\"\n    mode = tf.estimator.ModeKeys.PREDICT\n    serialized_example = tf.placeholder(\n        dtype=tf.string, shape=[None], name=\"serialized_example\")\n    dataset = tf.data.Dataset.from_tensor_slices(serialized_example)\n    dataset = dataset.map(self.decode_example)\n    dataset = dataset.map(lambda ex: self.preprocess_example(ex, mode, hparams))\n    dataset = dataset.map(data_reader.cast_ints_to_int32)\n\n    if use_tpu:\n      padded_shapes = data_reader.pad_for_tpu(dataset.output_shapes, hparams,\n                                              hparams.max_length)\n      batch_size = 1 if not decode_hparams else getattr(decode_hparams,\n                                                        \"batch_size\", 1)\n      dataset = dataset.padded_batch(\n          batch_size, padded_shapes, drop_remainder=False)\n      dataset = dataset.map(\n          functools.partial(data_reader.pad_batch, batch_multiple=batch_size))\n    else:\n      dataset = dataset.padded_batch(\n          tf.shape(serialized_example, out_type=tf.int64)[0],\n          dataset.output_shapes)\n\n    dataset = dataset.map(data_reader.standardize_shapes)\n    features = tf.data.experimental.get_single_element(dataset)\n\n    if self.has_inputs:\n      features.pop(\"targets\", None)\n\n    return tf.estimator.export.ServingInputReceiver(\n        features=features, receiver_tensors=serialized_example)", "language": "python"}
{"input": "Figure out the size of the pixmap in order to fit the main widget.", "output": "def scaleFitWindow(self):\n        \"\"\"Figure out the size of the pixmap in order to fit the main widget.\"\"\"\n        e = 2.0  # So that no scrollbars are generated.\n        w1 = self.centralWidget().width() - e\n        h1 = self.centralWidget().height() - e\n        a1 = w1 / h1\n        # Calculate a new scale value based on the pixmap's aspect ratio.\n        w2 = self.canvas.pixmap.width() - 0.0\n        h2 = self.canvas.pixmap.height() - 0.0\n        a2 = w2 / h2\n        return w1 / w2 if a2 >= a1 else h1 / h2", "language": "python"}
{"input": "Returns a copy of 'files' filtered to just those that don't match any of the exclusion globs in the filter.\n\n@param {?string} compiledFilter  'Compiled' filter object as returned by compile(), or null to no-op\n@param {!Array.<File>} files\n@return {!Array.<File>}", "output": "function filterFileList(compiledFilter, files) {\n        if (!compiledFilter) {\n            return files;\n        }\n\n        var re = new RegExp(compiledFilter);\n        return files.filter(function (f) {\n            return !re.test(f.fullPath);\n        });\n    }", "language": "javascript"}
{"input": "Creates a new scope with a breakable statement.\n\n@param {ASTNode} node - A node to create. This is a BreakableStatement.\n@returns {void}", "output": "function enterBreakableStatement(node) {\n            scopeInfo = {\n                label: node.parent.type === \"LabeledStatement\" ? node.parent.label : null,\n                breakable: true,\n                upper: scopeInfo\n            };\n        }", "language": "javascript"}
{"input": "/* [MS-OFFCRYPTO] 2.1.4 Version", "output": "function parse_CRYPTOVersion(blob, length/*:?number*/) {\n\tvar o/*:any*/ = {};\n\to.Major = blob.read_shift(2);\n\to.Minor = blob.read_shift(2);\n\t/*:: if(length == null) return o; */\n\tif(length >= 4) blob.l += length - 4;\n\treturn o;\n}", "language": "javascript"}
{"input": "Report all nodes in an array, except the first, with a given message.\n@param {ASTNode[]} nodes Nodes.\n@param {string} messageId Message id to display.\n@param {boolean} fix `true` if the directive should be fixed (i.e. removed)\n@returns {void}", "output": "function reportAllExceptFirst(nodes, messageId, fix) {\n            reportSlice(nodes, 1, nodes.length, messageId, fix);\n        }", "language": "javascript"}
{"input": "Scale gradients up by `self.loss_scale` to prevent underflow.", "output": "def on_backward_begin(self, last_loss:Rank0Tensor, **kwargs:Any) -> Rank0Tensor:\n        \"Scale gradients up by `self.loss_scale` to prevent underflow.\"\n        #To avoid gradient underflow, we scale the gradients\n        ret_loss = last_loss * self.loss_scale\n        return {'last_loss': ret_loss}", "language": "python"}
{"input": "Helper function to create a svrg optimizer. SVRG optimizer encapsulates two optimizers and\n        will redirect update() to the correct optimizer based on the key.\n\n        Parameters\n        ----------\n        kvstore : str or KVStore\n            Default `'local'`.\n        optimizer: str\n            Name for SVRGOptimizer\n        default_opt : str or Optimizer that was passed in.\n        optimizer_params : dict\n           optimizer params that was passed in.", "output": "def _create_optimizer(self, optimizer, default_opt, kvstore, optimizer_params):\n        \"\"\"Helper function to create a svrg optimizer. SVRG optimizer encapsulates two optimizers and\n        will redirect update() to the correct optimizer based on the key.\n\n        Parameters\n        ----------\n        kvstore : str or KVStore\n            Default `'local'`.\n        optimizer: str\n            Name for SVRGOptimizer\n        default_opt : str or Optimizer that was passed in.\n        optimizer_params : dict\n           optimizer params that was passed in.\n        \"\"\"\n\n        # code partially copied from mxnet module.init_optimizer() to accomodate svrg_optimizer\n        batch_size = self._exec_group.batch_size\n\n        (kv_store, update_on_kvstore) = mx.model._create_kvstore(kvstore, self._ctx_len, self._arg_params)\n        if kv_store and 'dist' in kv_store.type and '_sync' in kv_store.type:\n            batch_size *= kv_store.num_workers\n        rescale_grad = 1.0 / batch_size\n\n        idx2name = {}\n        if update_on_kvstore:\n            idx2name.update(enumerate(self._exec_group.param_names))\n        else:\n            for k in range(self._ctx_len):\n                idx2name.update({i * self._ctx_len + k: n\n                                 for i, n in enumerate(self._exec_group.param_names)})\n\n        # update idx2name to include new keys\n        for key in self._param_dict[0].keys():\n            max_key = max(list(idx2name.keys())) + 1\n            idx2name[max_key] = key + \"_full\"\n\n        optimizer_params = dict(optimizer_params)\n        if 'rescale_grad' not in optimizer_params:\n            optimizer_params['rescale_grad'] = rescale_grad\n        optimizer_params[\"default_optimizer\"] = default_opt\n        optimizer_params[\"param_idx2name\"] = idx2name\n        optimizer = mx.optimizer.create(optimizer, **optimizer_params)\n\n        return optimizer", "language": "python"}
{"input": "Create HParams with data_dir and problem hparams, if kwargs provided.", "output": "def create_hparams(hparams_set,\n                   hparams_overrides_str=\"\",\n                   data_dir=None,\n                   problem_name=None,\n                   hparams_path=None):\n  \"\"\"Create HParams with data_dir and problem hparams, if kwargs provided.\"\"\"\n  hparams = registry.hparams(hparams_set)\n  if hparams_path and tf.gfile.Exists(hparams_path):\n    hparams = create_hparams_from_json(hparams_path, hparams)\n  if data_dir:\n    hparams.add_hparam(\"data_dir\", data_dir)\n  if hparams_overrides_str:\n    tf.logging.info(\"Overriding hparams in %s with %s\", hparams_set,\n                    hparams_overrides_str)\n    hparams = hparams.parse(hparams_overrides_str)\n  if problem_name:\n    add_problem_hparams(hparams, problem_name)\n  return hparams", "language": "python"}
{"input": "/////////////////////////////////////////////////////////////// stat ////////////////////////////////////////////////////////// ///////////////////////////////////////////////////////////////", "output": "function restore (s) {\n    s.blksize = 4096;\n    s.blocks = 0;\n    s.dev = 0;\n    s.gid = 20;\n    s.ino = 0;\n    s.nlink = 0;\n    s.rdev = 0;\n    s.uid = 500;\n\n    s.atime = new Date(EXECSTAT.atime);\n    s.mtime = new Date(EXECSTAT.mtime);\n    s.ctime = new Date(EXECSTAT.ctime);\n    s.birthtime = new Date(EXECSTAT.birthtime);\n\n    s.atimeMs = EXECSTAT.atimeMs;\n    s.mtimeMs = EXECSTAT.mtimeMs;\n    s.ctimeMs = EXECSTAT.ctimeMs;\n    s.birthtimeMs = EXECSTAT.birthtimeMs;\n\n    var isFileValue = s.isFileValue;\n    var isDirectoryValue = s.isDirectoryValue;\n    delete s.isFileValue;\n    delete s.isDirectoryValue;\n\n    s.isFile = function () {\n      return isFileValue;\n    };\n    s.isDirectory = function () {\n      return isDirectoryValue;\n    };\n    s.isSymbolicLink = function () {\n      return false;\n    };\n    s.isFIFO = function () {\n      return false;\n    };\n\n    return s;\n  }", "language": "javascript"}
{"input": "Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given by the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained", "output": "def tfms_from_model(f_model, sz, aug_tfms=None, max_zoom=None, pad=0, crop_type=CropType.RANDOM,\n                    tfm_y=None, sz_y=None, pad_mode=cv2.BORDER_REFLECT, norm_y=True, scale=None):\n    \"\"\" Returns separate transformers of images for training and validation.\n    Transformers are constructed according to the image statistics given by the model. (See tfms_from_stats)\n\n    Arguments:\n        f_model: model, pretrained or not pretrained\n    \"\"\"\n    stats = inception_stats if f_model in inception_models else imagenet_stats\n    return tfms_from_stats(stats, sz, aug_tfms, max_zoom=max_zoom, pad=pad, crop_type=crop_type,\n                           tfm_y=tfm_y, sz_y=sz_y, pad_mode=pad_mode, norm_y=norm_y, scale=scale)", "language": "python"}
{"input": "A generator that generates samples that are encoded.\n\n    Args:\n      data_dir: data directory\n      tmp_dir: temp directory\n      dataset_split: dataset split\n\n    Yields:\n      A dict.", "output": "def generate_encoded_samples(self, data_dir, tmp_dir, dataset_split):\n    \"\"\"A generator that generates samples that are encoded.\n\n    Args:\n      data_dir: data directory\n      tmp_dir: temp directory\n      dataset_split: dataset split\n\n    Yields:\n      A dict.\n\n    \"\"\"\n    generator = self.generate_samples(data_dir, tmp_dir, dataset_split)\n    encoder = self.get_or_create_vocab(data_dir, tmp_dir)\n    label_encoder = self.get_labels_encoder(data_dir)\n    for sample in generator:\n      inputs = encoder.encode(sample[\"inputs\"])\n      inputs.append(text_encoder.EOS_ID)\n      context = encoder.encode(sample[\"context\"])\n      context.append(text_encoder.EOS_ID)\n      targets = label_encoder.encode(sample[\"targets\"])\n      sample[\"targets\"] = targets\n      yield {\"inputs\": inputs, \"context\": context, \"targets\": targets}", "language": "python"}
{"input": "Set of hyperparameters.", "output": "def slicenet_params1():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = common_hparams.basic_params1()\n  hparams.batch_size = 1024\n  hparams.hidden_size = 768\n  hparams.dropout = 0.5\n  hparams.symbol_dropout = 0.2\n  hparams.label_smoothing = 0.1\n  hparams.clip_grad_norm = 2.0\n  hparams.num_hidden_layers = 4\n  hparams.kernel_height = 3\n  hparams.kernel_width = 1\n  hparams.norm_type = \"layer\"\n  hparams.learning_rate_decay_scheme = \"exp\"\n  hparams.learning_rate = 0.05\n  hparams.learning_rate_warmup_steps = 3000\n  hparams.initializer_gain = 1.0\n  hparams.weight_decay = 3.0\n  hparams.num_sampled_classes = 0\n  hparams.sampling_method = \"argmax\"\n  hparams.optimizer_adam_epsilon = 1e-6\n  hparams.optimizer_adam_beta1 = 0.85\n  hparams.optimizer_adam_beta2 = 0.997\n  hparams.add_hparam(\"large_kernel_size\", 15)  # New ones are added like this.\n  hparams.add_hparam(\"separability\", -2)\n  # A dilation scheme, one of _DILATION_SCHEMES.\n  hparams.add_hparam(\"dilation_scheme\", \"1.1.1.1\")\n  # A kernel scheme, one of _KERNEL_SCHEMES; overrides large_kernel_size.\n  hparams.add_hparam(\"kernel_scheme\", \"3.7.15.31\")\n  hparams.add_hparam(\"audio_compression\", 8)\n  # attention-related flags\n  hparams.add_hparam(\"attention_type\", \"simple\")\n  hparams.add_hparam(\"num_heads\", 8)\n  hparams.add_hparam(\"attention_key_channels\", 0)\n  hparams.add_hparam(\"attention_value_channels\", 0)\n  hparams.add_hparam(\"sim_loss_mult\", 0.0)  # Try 10.0 for experiments.\n  hparams.add_hparam(\"attention_dropout\", 0.2)\n  hparams.shared_embedding_and_softmax_weights = True\n  return hparams", "language": "python"}
{"input": "Helper function for reading in next sample.", "output": "def next_sample(self):\n        \"\"\"Helper function for reading in next sample.\"\"\"\n        if self._allow_read is False:\n            raise StopIteration\n        if self.seq is not None:\n            if self.cur < self.num_image:\n                idx = self.seq[self.cur]\n            else:\n                if self.last_batch_handle != 'discard':\n                    self.cur = 0\n                raise StopIteration\n            self.cur += 1\n            if self.imgrec is not None:\n                s = self.imgrec.read_idx(idx)\n                header, img = recordio.unpack(s)\n                if self.imglist is None:\n                    return header.label, img\n                else:\n                    return self.imglist[idx][0], img\n            else:\n                label, fname = self.imglist[idx]\n                return label, self.read_image(fname)\n        else:\n            s = self.imgrec.read()\n            if s is None:\n                if self.last_batch_handle != 'discard':\n                    self.imgrec.reset()\n                raise StopIteration\n            header, img = recordio.unpack(s)\n            return header.label, img", "language": "python"}
{"input": "Determines if problem_name specifies a copy and/or reversal.\n\n  Args:\n    name: str, problem name, possibly with suffixes.\n\n  Returns:\n    ProblemSpec: namedtuple with [\"base_name\", \"was_reversed\", \"was_copy\"]\n\n  Raises:\n    ValueError if name contains multiple suffixes of the same type\n      ('_rev' or '_copy'). One of each is ok.", "output": "def parse_problem_name(name):\n  \"\"\"Determines if problem_name specifies a copy and/or reversal.\n\n  Args:\n    name: str, problem name, possibly with suffixes.\n\n  Returns:\n    ProblemSpec: namedtuple with [\"base_name\", \"was_reversed\", \"was_copy\"]\n\n  Raises:\n    ValueError if name contains multiple suffixes of the same type\n      ('_rev' or '_copy'). One of each is ok.\n  \"\"\"\n  # Recursively strip tags until we reach a base name.\n  if name.endswith(\"_rev\"):\n    base, was_reversed, was_copy = parse_problem_name(name[:-4])\n    if was_reversed:\n      # duplicate rev\n      raise ValueError(\n          \"Invalid problem name %s: multiple '_rev' instances\" % name)\n    return ProblemSpec(base, True, was_copy)\n  elif name.endswith(\"_copy\"):\n    base, was_reversed, was_copy = parse_problem_name(name[:-5])\n    if was_copy:\n      raise ValueError(\n          \"Invalid problem_name %s: multiple '_copy' instances\" % name)\n    return ProblemSpec(base, was_reversed, True)\n  else:\n    return ProblemSpec(name, False, False)", "language": "python"}
{"input": "Make a name consistent regardless of source (environment or file)", "output": "def _normalize_name(name):\n    # type: (str) -> str\n    \"\"\"Make a name consistent regardless of source (environment or file)\n    \"\"\"\n    name = name.lower().replace('_', '-')\n    if name.startswith('--'):\n        name = name[2:]  # only prefer long opts\n    return name", "language": "python"}
{"input": "Move the file or directory at the given path to a system dependent trash\nlocation, calling back asynchronously with a possibly null FileSystemError\nstring. Directories will be moved even when non-empty.\n\n@param {string} path\n@param {function(string)=} callback", "output": "function moveToTrash(path, callback) {\n        appshell.fs.moveToTrash(path, function (err) {\n            callback(_mapError(err));\n        });\n    }", "language": "javascript"}
{"input": "Get sentence", "output": "def sentence(self, padding=75):\n        \"\"\"\n        Get sentence\n        \"\"\"\n        vec = word_to_vector(self.sentence_str)\n        vec += [-1] * (padding - self.sentence_length)\n        return np.array(vec, dtype=np.int32)", "language": "python"}
{"input": "cross entropy loss with a mask", "output": "def cross_entropy_loss(inputs, labels, rescale_loss=1):\n    \"\"\" cross entropy loss with a mask \"\"\"\n    criterion = mx.gluon.loss.SoftmaxCrossEntropyLoss(weight=rescale_loss)\n    loss = criterion(inputs, labels)\n    mask = S.var('mask')\n    loss = loss * S.reshape(mask, shape=(-1,))\n    return S.make_loss(loss.mean())", "language": "python"}
{"input": "Get all the generator configuration from the .yo-rc.json file\n@param {Generator} generator the generator instance to use\n@param {boolean} force force getting direct from file", "output": "function getAllJhipsterConfig(generator, force) {\n    let configuration = generator && generator.config ? generator.config.getAll() || {} : {};\n    if ((force || !configuration.baseName) && jhiCore.FileUtils.doesFileExist('.yo-rc.json')) {\n        const yoRc = JSON.parse(fs.readFileSync('.yo-rc.json', { encoding: 'utf-8' }));\n        configuration = yoRc['generator-jhipster'];\n        // merge the blueprint config if available\n        if (configuration.blueprint) {\n            configuration = { ...configuration, ...yoRc[configuration.blueprint] };\n        }\n    }\n    if (!configuration.get || typeof configuration.get !== 'function') {\n        configuration = {\n            ...configuration,\n            getAll: () => configuration,\n            get: key => configuration[key],\n            set: (key, value) => {\n                configuration[key] = value;\n            }\n        };\n    }\n    return configuration;\n}", "language": "javascript"}
{"input": "Determines whether two nodes are composed of the same tokens.\n@param {ASTNode} nodeA The first node\n@param {ASTNode} nodeB The second node\n@returns {boolean} true if the nodes have identical token representations", "output": "function hasSameTokens(nodeA, nodeB) {\n            const tokensA = sourceCode.getTokens(nodeA);\n            const tokensB = sourceCode.getTokens(nodeB);\n\n            return tokensA.length === tokensB.length &&\n                tokensA.every((token, index) => token.type === tokensB[index].type && token.value === tokensB[index].value);\n        }", "language": "javascript"}
{"input": "Determine whether a link URL from a referring page and with a\n        particular \"rel\" attribute should be queued for scraping.", "output": "def _should_queue(self, link, referrer, rel):\n        \"\"\"\n        Determine whether a link URL from a referring page and with a\n        particular \"rel\" attribute should be queued for scraping.\n        \"\"\"\n        scheme, netloc, path, _, _, _ = urlparse(link)\n        if path.endswith(self.source_extensions + self.binary_extensions +\n                         self.excluded_extensions):\n            result = False\n        elif self.skip_externals and not link.startswith(self.base_url):\n            result = False\n        elif not referrer.startswith(self.base_url):\n            result = False\n        elif rel not in ('homepage', 'download'):\n            result = False\n        elif scheme not in ('http', 'https', 'ftp'):\n            result = False\n        elif self._is_platform_dependent(link):\n            result = False\n        else:\n            host = netloc.split(':', 1)[0]\n            if host.lower() == 'localhost':\n                result = False\n            else:\n                result = True\n        logger.debug('should_queue: %s (%s) from %s -> %s', link, rel,\n                     referrer, result)\n        return result", "language": "python"}
{"input": "r\"\"\"Return location for the pretrained on local file system.\n\n    This function will download from online model zoo when model cannot be found or has mismatch.\n    The root directory will be created if it doesn't exist.\n\n    Parameters\n    ----------\n    name : str\n        Name of the model.\n    root : str, default $MXNET_HOME/models\n        Location for keeping the model parameters.\n\n    Returns\n    -------\n    file_path\n        Path to the requested pretrained model file.", "output": "def get_model_file(name, root=os.path.join(base.data_dir(), 'models')):\n    r\"\"\"Return location for the pretrained on local file system.\n\n    This function will download from online model zoo when model cannot be found or has mismatch.\n    The root directory will be created if it doesn't exist.\n\n    Parameters\n    ----------\n    name : str\n        Name of the model.\n    root : str, default $MXNET_HOME/models\n        Location for keeping the model parameters.\n\n    Returns\n    -------\n    file_path\n        Path to the requested pretrained model file.\n    \"\"\"\n    file_name = '{name}-{short_hash}'.format(name=name,\n                                             short_hash=short_hash(name))\n    root = os.path.expanduser(root)\n    file_path = os.path.join(root, file_name+'.params')\n    sha1_hash = _model_sha1[name]\n    if os.path.exists(file_path):\n        if check_sha1(file_path, sha1_hash):\n            return file_path\n        else:\n            logging.warning('Mismatch in the content of model file detected. Downloading again.')\n    else:\n        logging.info('Model file not found. Downloading to %s.', file_path)\n\n    util.makedirs(root)\n\n    zip_file_path = os.path.join(root, file_name+'.zip')\n    repo_url = os.environ.get('MXNET_GLUON_REPO', apache_repo_url)\n    if repo_url[-1] != '/':\n        repo_url = repo_url + '/'\n    download(_url_format.format(repo_url=repo_url, file_name=file_name),\n             path=zip_file_path,\n             overwrite=True)\n    with zipfile.ZipFile(zip_file_path) as zf:\n        zf.extractall(root)\n    os.remove(zip_file_path)\n\n    if check_sha1(file_path, sha1_hash):\n        return file_path\n    else:\n        raise ValueError('Downloaded file has different hash. Please try again.')", "language": "python"}
{"input": "/* [MS-OFFCRYPTO] 2.1.7 DataSpaceDefinition", "output": "function parse_DataSpaceDefinition(blob) {\n\tvar o = [];\n\tblob.l += 4; // must be 0x8\n\tvar cnt = blob.read_shift(4);\n\twhile(cnt-- > 0) o.push(blob.read_shift(0, 'lpp4'));\n\treturn o;\n}", "language": "javascript"}
{"input": "Match `el` to `selector`.\n\n@param {Element} el\n@param {String} selector\n@return {Boolean}\n@api public", "output": "function match (el, selector) {\n  if (!el || el.nodeType !== 1) return false\n  if (vendor) return vendor.call(el, selector)\n  var nodes = all(selector, el.parentNode)\n  for (var i = 0; i < nodes.length; ++i) {\n    if (nodes[i] === el) return true\n  }\n  return false\n}", "language": "javascript"}
{"input": "creates size snapshot for every bundle that built with webpack", "output": "async function getWebpackSizes() {\n  await fse.mkdirp(path.join(__dirname, 'build'));\n\n  const configPath = path.join(__dirname, 'webpack.config.js');\n  const statsPath = path.join(__dirname, 'build', 'stats.json');\n  await exec(`webpack --config ${configPath} --json > ${statsPath}`);\n\n  const stats = await fse.readJSON(statsPath);\n  const assets = new Map(stats.assets.map(asset => [asset.name, asset]));\n\n  return Object.entries(stats.assetsByChunkName).map(([chunkName, assetName]) => {\n    const parsedSize = assets.get(assetName).size;\n    const gzipSize = assets.get(`${assetName}.gz`).size;\n    return [chunkName, { parsed: parsedSize, gzip: gzipSize }];\n  });\n}", "language": "javascript"}
{"input": "Only returns resources if resources allocated.", "output": "def stop_trial(self, trial, error=False, error_msg=None, stop_logger=True):\n        \"\"\"Only returns resources if resources allocated.\"\"\"\n        prior_status = trial.status\n        self._stop_trial(\n            trial, error=error, error_msg=error_msg, stop_logger=stop_logger)\n        if prior_status == Trial.RUNNING:\n            logger.debug(\"Returning resources for Trial %s.\", str(trial))\n            self._return_resources(trial.resources)\n            out = self._find_item(self._running, trial)\n            for result_id in out:\n                self._running.pop(result_id)", "language": "python"}
{"input": "List all dependencies for a book, including default plugins.\nIt returns a concat with default plugins and remove disabled ones.\n\n@param {List<PluginDependency>} deps\n@return {List<PluginDependency>}", "output": "function listDependencies(deps) {\n    // Extract list of plugins to disable (starting with -)\n    var toRemove = deps\n        .filter(function(plugin) {\n            return !plugin.isEnabled();\n        })\n        .map(function(plugin) {\n            return plugin.getName();\n        });\n\n    // Concat with default plugins\n    deps = deps.concat(DEFAULT_PLUGINS);\n\n    // Remove plugins\n    deps = deps.filterNot(function(plugin) {\n        return toRemove.includes(plugin.getName());\n    });\n\n    // Sort\n    return sortDependencies(deps);\n}", "language": "javascript"}
{"input": "Counts the number of matches matching the queryExpr in the given contents\n@param   {String} contents  The contents to search on\n@param   {Object} queryExpr\n@return {number} number of matches", "output": "function countNumMatches(contents, queryExpr) {\n    if (!contents) {\n        return 0;\n    }\n    var matches = contents.match(queryExpr);\n    return matches ? matches.length : 0;\n}", "language": "javascript"}
{"input": "Using FullyConnected operator in place of linalg_gemm to perform same operation", "output": "def _fix_gemm(op_name, inputs, old_attr, proto_obj):\n    \"\"\"Using FullyConnected operator in place of linalg_gemm to perform same operation\"\"\"\n    op_sym = getattr(symbol, op_name, None)\n    alpha = float(old_attr.get('alpha', 1.0))\n    beta = float(old_attr.get('beta', 1.0))\n    trans_a = int(old_attr.get('transA', 0))\n    trans_b = int(old_attr.get('transB', 0))\n    if trans_a:\n        inputs[0] = symbol.transpose(inputs[0], axes=(1, 0))\n    if not trans_b:\n        inputs[1] = symbol.transpose(inputs[1], axes=(1, 0))\n    new_inputs = [alpha*inputs[0], inputs[1], beta*inputs[2]]\n    new_attr = {'num_hidden' : proto_obj._params[inputs[2].name].shape[0]}\n    return op_sym, new_attr, new_inputs", "language": "python"}
{"input": "Inverse of attention_bias_ignore_padding().\n\n  Args:\n    attention_bias: a `Tensor` with shape [batch, 1, 1, memory_length], as\n      returned by attention_bias_ignore_padding().\n    cast_fn: function used to cast to output type.\n\n  Returns:\n    a Tensor with shape [batch, memory_length] with 1.0 in padding positions\n    and 0.0 in non-padding positions. Type is determined by cast_fn.", "output": "def attention_bias_to_padding(attention_bias, cast_fn=tf.to_float):\n  \"\"\"Inverse of attention_bias_ignore_padding().\n\n  Args:\n    attention_bias: a `Tensor` with shape [batch, 1, 1, memory_length], as\n      returned by attention_bias_ignore_padding().\n    cast_fn: function used to cast to output type.\n\n  Returns:\n    a Tensor with shape [batch, memory_length] with 1.0 in padding positions\n    and 0.0 in non-padding positions. Type is determined by cast_fn.\n  \"\"\"\n  # `attention_bias` is a large negative number in padding positions and 0.0\n  # elsewhere.\n  return tf.squeeze(cast_fn(tf.less(attention_bias, -1)), axis=[1, 2])", "language": "python"}
{"input": "compute the screen offset of an element", "output": "function _screenOffset(element) {\n        var elemBounds = element.getBoundingClientRect(),\n            body = window.document.body,\n            offsetTop,\n            offsetLeft;\n\n        if (window.getComputedStyle(body).position === \"static\") {\n            offsetLeft = elemBounds.left + window.pageXOffset;\n            offsetTop = elemBounds.top + window.pageYOffset;\n        } else {\n            var bodyBounds = body.getBoundingClientRect();\n            offsetLeft = elemBounds.left - bodyBounds.left;\n            offsetTop = elemBounds.top - bodyBounds.top;\n        }\n        return { left: offsetLeft, top: offsetTop };\n    }", "language": "javascript"}
{"input": "Writes the help into the formatter if it exists.\n\n        This calls into the following methods:\n\n        -   :meth:`format_usage`\n        -   :meth:`format_help_text`\n        -   :meth:`format_options`\n        -   :meth:`format_epilog`", "output": "def format_help(self, ctx, formatter):\n        \"\"\"Writes the help into the formatter if it exists.\n\n        This calls into the following methods:\n\n        -   :meth:`format_usage`\n        -   :meth:`format_help_text`\n        -   :meth:`format_options`\n        -   :meth:`format_epilog`\n        \"\"\"\n        self.format_usage(ctx, formatter)\n        self.format_help_text(ctx, formatter)\n        self.format_options(ctx, formatter)\n        self.format_epilog(ctx, formatter)", "language": "python"}
{"input": "Self-attention layer with source as memory antecedent.", "output": "def attend(x, source, hparams, name):\n  \"\"\"Self-attention layer with source as memory antecedent.\"\"\"\n  with tf.variable_scope(name):\n    x = tf.squeeze(x, axis=2)\n    if len(source.get_shape()) > 3:\n      source = tf.squeeze(source, axis=2)\n    source = common_attention.add_timing_signal_1d(source)\n    y = common_attention.multihead_attention(\n        common_layers.layer_preprocess(x, hparams), source, None,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size, hparams.num_heads,\n        hparams.attention_dropout)\n    res = common_layers.layer_postprocess(x, y, hparams)\n    return tf.expand_dims(res, axis=2)", "language": "python"}
{"input": "Is this a valid SAM template dictionary\n\n        :param dict template_dict: Data to be validated\n        :param dict schema: Optional, dictionary containing JSON Schema representing SAM template\n        :return: Empty string if there are no validation errors in template", "output": "def validate(template_dict, schema=None):\n        \"\"\"\n        Is this a valid SAM template dictionary\n\n        :param dict template_dict: Data to be validated\n        :param dict schema: Optional, dictionary containing JSON Schema representing SAM template\n        :return: Empty string if there are no validation errors in template\n        \"\"\"\n\n        if not schema:\n            schema = SamTemplateValidator._read_schema()\n\n        validation_errors = \"\"\n\n        try:\n            jsonschema.validate(template_dict, schema)\n        except ValidationError as ex:\n            # Stringifying the exception will give us useful error message\n            validation_errors = str(ex)\n            # Swallowing expected exception here as our caller is expecting validation errors and\n            # not the valiation exception itself\n            pass\n\n        return validation_errors", "language": "python"}
{"input": "Sub-classes to define. Return a sliced object.\n\n        Parameters\n        ----------\n        key : string / list of selections\n        ndim : 1,2\n            requested ndim of result\n        subset : object, default None\n            subset to act on", "output": "def _gotitem(self, key, ndim, subset=None):\n        \"\"\"\n        Sub-classes to define. Return a sliced object.\n\n        Parameters\n        ----------\n        key : string / list of selections\n        ndim : 1,2\n            requested ndim of result\n        subset : object, default None\n            subset to act on\n        \"\"\"\n        # create a new object to prevent aliasing\n        if subset is None:\n            subset = self.obj\n\n        # we need to make a shallow copy of ourselves\n        # with the same groupby\n        kwargs = {attr: getattr(self, attr) for attr in self._attributes}\n\n        # Try to select from a DataFrame, falling back to a Series\n        try:\n            groupby = self._groupby[key]\n        except IndexError:\n            groupby = self._groupby\n\n        self = self.__class__(subset,\n                              groupby=groupby,\n                              parent=self,\n                              **kwargs)\n        self._reset_cache()\n        if subset.ndim == 2:\n            if is_scalar(key) and key in subset or is_list_like(key):\n                self._selection = key\n        return self", "language": "python"}
{"input": "Left-pad the string column to width `len` with `pad`.\n\n    >>> df = spark.createDataFrame([('abcd',)], ['s',])\n    >>> df.select(lpad(df.s, 6, '#').alias('s')).collect()\n    [Row(s=u'##abcd')]", "output": "def lpad(col, len, pad):\n    \"\"\"\n    Left-pad the string column to width `len` with `pad`.\n\n    >>> df = spark.createDataFrame([('abcd',)], ['s',])\n    >>> df.select(lpad(df.s, 6, '#').alias('s')).collect()\n    [Row(s=u'##abcd')]\n    \"\"\"\n    sc = SparkContext._active_spark_context\n    return Column(sc._jvm.functions.lpad(_to_java_column(col), len, pad))", "language": "python"}
{"input": "Block for when loudness/timer/video motion is greater than the value.\n@this Blockly.Block", "output": "function() {\n    this.jsonInit({\n      \"message0\": Blockly.Msg.EVENT_WHENGREATERTHAN,\n      \"args0\": [\n        {\n          \"type\": \"field_dropdown\",\n          \"name\": \"WHENGREATERTHANMENU\",\n          \"options\": [\n            [Blockly.Msg.EVENT_WHENGREATERTHAN_LOUDNESS, 'LOUDNESS'],\n            [Blockly.Msg.EVENT_WHENGREATERTHAN_TIMER, 'TIMER']\n          ]\n        },\n        {\n          \"type\": \"input_value\",\n          \"name\": \"VALUE\"\n        }\n      ],\n      \"category\": Blockly.Categories.event,\n      \"extensions\": [\"colours_event\", \"shape_hat\"]\n    });\n  }", "language": "javascript"}
{"input": "Return the largest item from the sequence.\n\n    .. sourcecode:: jinja\n\n        {{ [1, 2, 3]|max }}\n            -> 3\n\n    :param case_sensitive: Treat upper and lower case strings as distinct.\n    :param attribute: Get the object with the max value of this attribute.", "output": "def do_max(environment, value, case_sensitive=False, attribute=None):\n    \"\"\"Return the largest item from the sequence.\n\n    .. sourcecode:: jinja\n\n        {{ [1, 2, 3]|max }}\n            -> 3\n\n    :param case_sensitive: Treat upper and lower case strings as distinct.\n    :param attribute: Get the object with the max value of this attribute.\n    \"\"\"\n    return _min_or_max(environment, value, max, case_sensitive, attribute)", "language": "python"}
{"input": "Close a tab\n\n@param {object} aSpec\nInformation about the element to operate on\nElements: tab - Tab to close", "output": "function tabView_closeTab(aSpec) { \n    var spec = aSpec || {};\n    var tab = spec.tab;\n\n    if (!tab) {\n      throw new Error(arguments.callee.name + \": Tab not specified.\");\n    }\n\n    var button = this.getElement({\n      type: \"tab_closeButton\",\n      value: tab}\n    );\n    this._controller.click(button);\n  }", "language": "javascript"}
{"input": "Do not process input images where the number of pixels (width x height) exceeds this limit.\nAssumes image dimensions contained in the input metadata can be trusted.\nThe default limit is 268402689 (0x3FFF x 0x3FFF) pixels.\n@param {(Number|Boolean)} limit - an integral Number of pixels, zero or false to remove limit, true to use default limit.\n@returns {Sharp}\n@throws {Error} Invalid limit", "output": "function limitInputPixels (limit) {\n  // if we pass in false we represent the integer as 0 to disable\n  if (limit === false) {\n    limit = 0;\n  } else if (limit === true) {\n    limit = Math.pow(0x3FFF, 2);\n  }\n  if (is.integer(limit) && limit >= 0) {\n    this.options.limitInputPixels = limit;\n  } else {\n    throw is.invalidParameterError('limitInputPixels', 'integer', limit);\n  }\n  return this;\n}", "language": "javascript"}
{"input": "Determines if there are preference IDs that could change as a result\nof the context change. This implementation considers only changes in\nlanguage.\n\n@param {Object} data Data in the Scope\n@param {{language: string}} oldContext Old context\n@param {{language: string}} newContext New context\n@return {Array.<string>|undefined} list of preference IDs that could have changed", "output": "function (data, oldContext, newContext) {\n            // this function is called only if the language has changed\n            if (newContext.language === undefined) {\n                return _.keys(data[oldContext.language]);\n            }\n            if (oldContext.language === undefined) {\n                return _.keys(data[newContext.language]);\n            }\n\n            return _.union(_.keys(data[newContext.language]), _.keys(data[oldContext.language]));\n        }", "language": "javascript"}
{"input": "Ensures that the directory exists.\n@param {String} dir", "output": "function ensureDir(dir) {\n  return new Promise((resolve, reject) => {\n    try {\n      FS.ensureDirSync(dir);\n      resolve(dir);\n    } catch (err) {\n      reject(err);\n    }\n  });\n}", "language": "javascript"}
{"input": "Schedules a search on search scope/filter changes. Have to schedule as when we listen to this event, the file filters\nmight not have been updated yet.", "output": "function _searchIfRequired() {\n        if (!FindUtils.isInstantSearchDisabled() && _findBar && _findBar._options.multifile && !_findBar._options.replace) {\n            setTimeout(_defferedSearch, 100);\n        }\n    }", "language": "javascript"}
{"input": "Debugging dump of the current subtoken vocabulary.", "output": "def dump(self):\n    \"\"\"Debugging dump of the current subtoken vocabulary.\"\"\"\n    subtoken_strings = [(i, s)\n                        for s, i in six.iteritems(self._subtoken_string_to_id)]\n    print(u\", \".join(u\"{0} : '{1}'\".format(i, s)\n                     for i, s in sorted(subtoken_strings)))", "language": "python"}
{"input": "Reports a given node as self assignments.\n\n@param {ASTNode} node - A node to report. This is an Identifier node.\n@returns {void}", "output": "function report(node) {\n            context.report({\n                node,\n                message: \"'{{name}}' is assigned to itself.\",\n                data: {\n                    name: sourceCode.getText(node).replace(SPACES, \"\")\n                }\n            });\n        }", "language": "javascript"}
{"input": "Visualizes the outputs from the model which are used for decoding poses.\nLimited to visualizing the outputs for a single part.\n\n@param partId The id of the part to visualize", "output": "function visualizeOutputs(\n    partId, drawHeatmaps, drawOffsetVectors, drawDisplacements, ctx) {\n  const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n      modelOutputs;\n  const outputStride = +guiState.outputStride;\n\n  const [height, width] = heatmapScores.shape;\n\n  ctx.globalAlpha = 0;\n  const heatmapScoresArr = heatmapScores.arraySync();\n  const offsetsArr = offsets.arraySync();\n\n  for (let y = 0; y < height; y++) {\n    for (let x = 0; x < width; x++) {\n      const score = heatmapScoresArr[y][x][partId];\n\n      // to save on performance, don't draw anything with a low score.\n      if (score < 0.05) continue;\n\n      // set opacity of drawn elements based on the score\n      ctx.globalAlpha = score;\n\n      if (drawHeatmaps) {\n        drawPoint(ctx, y * outputStride, x * outputStride, 2, 'yellow');\n      }\n\n      const offsetsVectorY = offsetsArr[y][x][partId];\n      const offsetsVectorX = offsetsArr[y][x][partId + 17];\n\n      if (drawOffsetVectors) {\n        drawOffsetVector(\n            ctx, y, x, outputStride, offsetsVectorY, offsetsVectorX);\n      }\n\n      if (drawDisplacements) {\n        // exponentially affect the alpha of the displacements;\n        ctx.globalAlpha *= score;\n\n        drawDisplacementEdgesFrom(\n            ctx, partId, displacementFwd, outputStride, parentToChildEdges, y,\n            x, offsetsVectorY, offsetsVectorX);\n\n        drawDisplacementEdgesFrom(\n            ctx, partId, displacementBwd, outputStride, childToParentEdges, y,\n            x, offsetsVectorY, offsetsVectorX);\n      }\n    }\n\n    ctx.globalAlpha = 1;\n  }\n}", "language": "javascript"}
{"input": "Calculates the position of the fisrt/last step (with fix for Safari in RTL mode) to make the position and scroll calculations running (see comment on getRTLFactor for RTL behavior)", "output": "function(oRoadMap, bLast){\n\t\tvar iScrollWidth = oRoadMap.$(\"steparea\").get(0).scrollWidth;\n\t\tif (sap.ui.getCore().getConfiguration().getRTL() && Device.browser.webkit) {\n\t\t\treturn bLast ? 0 : ( -1) * iScrollWidth;\n\t\t}\n\t\treturn bLast ? iScrollWidth : 0;\n\t}", "language": "javascript"}
{"input": "Single Measurement Entry\n\n@public\n@typedef {object} module:sap/ui/performance/Measurement.Entry\n@property {string} sId ID of the measurement\n@property {string} sInfo Info for the measurement\n@property {int} iStart Start time\n@property {int} iEnd End time\n@property {string | string[]} [aCategories=\"javascript\"] An optional list of categories for the measure", "output": "function Measurement(sId, sInfo, iStart, iEnd, aCategories) {\n\t\t\tthis.id = sId;\n\t\t\tthis.info = sInfo;\n\t\t\tthis.start = iStart;\n\t\t\tthis.end = iEnd;\n\t\t\tthis.pause = 0;\n\t\t\tthis.resume = 0;\n\t\t\tthis.duration = 0; // used time\n\t\t\tthis.time = 0; // time from start to end\n\t\t\tthis.categories = aCategories;\n\t\t\tthis.average = false; //average duration enabled\n\t\t\tthis.count = 0; //average count\n\t\t\tthis.completeDuration = 0; //complete duration\n\t\t}", "language": "javascript"}
{"input": "HTTP method override Interceptor.", "output": "function method (request) {\n\n    if (request.emulateHTTP && /^(PUT|PATCH|DELETE)$/i.test(request.method)) {\n        request.headers.set('X-HTTP-Method-Override', request.method);\n        request.method = 'POST';\n    }\n\n}", "language": "javascript"}
{"input": "Check if name is in orig_ctr or in one of the other type containers.", "output": "def _check_reset_and_type_change(self, name, orig_ctr):\n    \"\"\"Check if name is in orig_ctr or in one of the other type containers.\"\"\"\n    # Resetting a hyperparameter\n    if name in orig_ctr:\n      tf.logging.warning(\"Overwriting hparam %s\", name)\n\n    ctr_names = [\n        (self._categorical_params, \"categorical\"),\n        (self._discrete_params, \"discrete\"),\n        (self._float_params, \"float\"),\n        (self._int_params, \"int\"),\n    ]\n    ctrs, names = list(zip(*ctr_names))\n    orig_name = names[ctrs.index(orig_ctr)]\n\n    for ctr, ctr_name in ctr_names:\n      if ctr is orig_ctr:\n        continue\n\n      # Using a different type for the same hyperparameter name\n      if name in ctr:\n        raise ValueError(\"Setting hyperparameter %s as type %s, but a \"\n                         \"hyperparemeter of the same name was originally \"\n                         \"registered as type %s\" % (name, ctr_name, orig_name))", "language": "python"}
{"input": "Return vector of label values for requested level,\n        equal to the length of the index\n\n        **this is an internal method**\n\n        Parameters\n        ----------\n        level : int level\n        unique : bool, default False\n            if True, drop duplicated values\n\n        Returns\n        -------\n        values : ndarray", "output": "def _get_level_values(self, level, unique=False):\n        \"\"\"\n        Return vector of label values for requested level,\n        equal to the length of the index\n\n        **this is an internal method**\n\n        Parameters\n        ----------\n        level : int level\n        unique : bool, default False\n            if True, drop duplicated values\n\n        Returns\n        -------\n        values : ndarray\n        \"\"\"\n\n        values = self.levels[level]\n        level_codes = self.codes[level]\n        if unique:\n            level_codes = algos.unique(level_codes)\n        filled = algos.take_1d(values._values, level_codes,\n                               fill_value=values._na_value)\n        values = values._shallow_copy(filled)\n        return values", "language": "python"}
{"input": "Batch size in examples per TPU core.\n\n    Args:\n      model_hparams: model hyperparameters\n    Returns:\n      an integer", "output": "def tpu_batch_size_per_shard(self, model_hparams):\n    \"\"\"Batch size in examples per TPU core.\n\n    Args:\n      model_hparams: model hyperparameters\n    Returns:\n      an integer\n    \"\"\"\n    if self.batch_size_means_tokens and not model_hparams.use_fixed_batch_size:\n      return model_hparams.batch_size // self.max_length(model_hparams)\n    else:\n      return model_hparams.batch_size", "language": "python"}
{"input": "Template in place plugin.\n\n@param {Object} files\n@param {Metalsmith} metalsmith\n@param {Function} done", "output": "function renderTemplateFiles (skipInterpolation) {\n  skipInterpolation = typeof skipInterpolation === 'string'\n    ? [skipInterpolation]\n    : skipInterpolation\n  return (files, metalsmith, done) => {\n    const keys = Object.keys(files)\n    const metalsmithMetadata = metalsmith.metadata()\n    async.each(keys, (file, next) => {\n      // skipping files with skipInterpolation option\n      if (skipInterpolation && multimatch([file], skipInterpolation, { dot: true }).length) {\n        return next()\n      }\n      const str = files[file].contents.toString()\n      // do not attempt to render files that do not have mustaches\n      if (!/{{([^{}]+)}}/g.test(str)) {\n        return next()\n      }\n      render(str, metalsmithMetadata, (err, res) => {\n        if (err) {\n          err.message = `[${file}] ${err.message}`\n          return next(err)\n        }\n        files[file].contents = Buffer.from(res)\n        next()\n      })\n    }, done)\n  }\n}", "language": "javascript"}
{"input": "Return a new DStream in which each RDD has a single element generated\n        by counting the number of elements in a window over this DStream.\n        windowDuration and slideDuration are as defined in the window() operation.\n\n        This is equivalent to window(windowDuration, slideDuration).count(),\n        but will be more efficient if window is large.", "output": "def countByWindow(self, windowDuration, slideDuration):\n        \"\"\"\n        Return a new DStream in which each RDD has a single element generated\n        by counting the number of elements in a window over this DStream.\n        windowDuration and slideDuration are as defined in the window() operation.\n\n        This is equivalent to window(windowDuration, slideDuration).count(),\n        but will be more efficient if window is large.\n        \"\"\"\n        return self.map(lambda x: 1).reduceByWindow(operator.add, operator.sub,\n                                                    windowDuration, slideDuration)", "language": "python"}
{"input": "The operator `put` doesn't block waiting the returned promise to resolve. Using `put.resolve` will wait until the promsie resolve/reject before resuming. It will be helpful to organize multi-effects in order, and increase the reusability by seperate the effect in stand-alone pieces. https://github.com/redux-saga/redux-saga/issues/336", "output": "function putResolve(action) {\n    const { type } = action;\n    assertAction(type, 'sagaEffects.put.resolve');\n    return sagaEffects.put.resolve({\n      ...action,\n      type: prefixType(type, model),\n    });\n  }", "language": "javascript"}
{"input": "Given an index, get the corresponding vector of the Input Matrix.", "output": "def get_input_vector(self, ind):\n        \"\"\"\n        Given an index, get the corresponding vector of the Input Matrix.\n        \"\"\"\n        dim = self.get_dimension()\n        b = fasttext.Vector(dim)\n        self.f.getInputVector(b, ind)\n        return np.array(b)", "language": "python"}
{"input": "Resolves a single binding syntax.\n\n@param {string} sBinding The value to resolve.\n@param {sap.ui.model.Model} oModel The model.\n@param {string} [sPath] The path to the referenced entity which is going to be used as a binding context.\n@private\n@returns {*} The resolved value.", "output": "function resolveBinding(sBinding, oModel, sPath) {\n\t\t\tif (!sBinding) {\n\t\t\t\treturn sBinding;\n\t\t\t}\n\t\t\tvar oBindingInfo = ManagedObject.bindingParser(sBinding);\n\n\t\t\tif (!oBindingInfo) {\n\t\t\t\treturn sBinding;\n\t\t\t}\n\n\t\t\tif (!sPath) {\n\t\t\t\tsPath = \"/\";\n\t\t\t}\n\n\t\t\toSimpleControl.setModel(oModel);\n\t\t\toSimpleControl.bindObject(sPath);\n\t\t\toSimpleControl.bindProperty(\"resolved\", oBindingInfo);\n\n\t\t\tvar vValue = oSimpleControl.getResolved();\n\n\t\t\toSimpleControl.unbindProperty(\"resolved\");\n\t\t\toSimpleControl.unbindObject();\n\t\t\toSimpleControl.setModel(null);\n\n\t\t\treturn vValue;\n\t\t}", "language": "javascript"}
{"input": "Show or hide the recent projects dropdown from the toogle command.", "output": "function handleKeyEvent() {\n        if (!$dropdown) {\n            if (!SidebarView.isVisible()) {\n                SidebarView.show();\n            }\n\n            $(\"#project-dropdown-toggle\").trigger(\"click\");\n\n            $dropdown.focus();\n            $links = $dropdown.find(\"a\");\n            // By default, select the most recent project (which is at the top of the list underneath Open Folder),\n            // but if there are none, select Open Folder instead.\n            $dropdownItem = $links.eq($links.length > 1 ? 1 : 0);\n            $dropdownItem.addClass(\"selected\");\n\n            // If focusing the dropdown caused a modal bar to close, we need to refocus the dropdown\n            window.setTimeout(function () {\n                $dropdown.focus();\n            }, 0);\n        }\n    }", "language": "javascript"}
{"input": "Handler for `touchstart`, triggers `pointerover`,\n`pointerenter` and `pointerdown` events.\n\n@this {TouchSource}\n@param {TouchEvent} inEvent The in event.", "output": "function touchstart(inEvent) {\n  this.vacuumTouches_(inEvent);\n  this.setPrimaryTouch_(inEvent.changedTouches[0]);\n  this.dedupSynthMouse_(inEvent);\n  this.clickCount_++;\n  this.processTouches_(inEvent, this.overDown_);\n}", "language": "javascript"}
{"input": "/*\nBuilds the min/max expression for the \"concat\" term (for example\n\"AggregatableProperty with min as UI5min__AggregatableProperty\") and adds a\ncorresponding entry to the optional alias map.\n\n@param {string} sName - An aggregatable property name\n@param {string} sMinOrMax - Either \"min\" or \"max\"", "output": "function processMinOrMax(sName, sMinOrMax) {\n\t\t\t\tvar sAlias = \"UI5\" + sMinOrMax + \"__\" + sName;\n\n\t\t\t\taConcatAggregate.push(sName + \" with \" + sMinOrMax + \" as \" + sAlias);\n\t\t\t\tif (mAlias2MeasureAndMethod) {\n\t\t\t\t\tmAlias2MeasureAndMethod[sAlias] = {\n\t\t\t\t\t\tmeasure : sName,\n\t\t\t\t\t\tmethod : sMinOrMax\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}", "language": "javascript"}
{"input": "Takes a list of rows and a column and returns the most frequent value under\n        that column in those rows.", "output": "def mode_number(self, rows: List[Row], column: NumberColumn) -> Number:\n        \"\"\"\n        Takes a list of rows and a column and returns the most frequent value under\n        that column in those rows.\n        \"\"\"\n        most_frequent_list = self._get_most_frequent_values(rows, column)\n        if not most_frequent_list:\n            return 0.0  # type: ignore\n        most_frequent_value = most_frequent_list[0]\n        if not isinstance(most_frequent_value, Number):\n            raise ExecutionError(f\"Invalid valus for mode_number: {most_frequent_value}\")\n        return most_frequent_value", "language": "python"}
{"input": "Preprocess from frames using mouth detector", "output": "def process_frames_mouth(self, frames):\n        \"\"\"\n        Preprocess from frames using mouth detector\n        \"\"\"\n        self.face = np.array(frames)\n        self.mouth = np.array(frames)\n        self.set_data(frames)", "language": "python"}
{"input": "ROUGE-2 F1 score computation between labels and predictions.\n\n  This is an approximate ROUGE scoring method since we do not glue word pieces\n  or decode the ids and tokenize the output.\n\n  Args:\n    predictions: tensor, model predictions\n    labels: tensor, gold output.\n\n  Returns:\n    rouge2_fscore: approx rouge-2 f1 score.", "output": "def rouge_2_fscore(predictions, labels, **unused_kwargs):\n  \"\"\"ROUGE-2 F1 score computation between labels and predictions.\n\n  This is an approximate ROUGE scoring method since we do not glue word pieces\n  or decode the ids and tokenize the output.\n\n  Args:\n    predictions: tensor, model predictions\n    labels: tensor, gold output.\n\n  Returns:\n    rouge2_fscore: approx rouge-2 f1 score.\n  \"\"\"\n\n  outputs = tf.to_int32(tf.argmax(predictions, axis=-1))\n  # Convert the outputs and labels to a [batch_size, input_length] tensor.\n  outputs = tf.squeeze(outputs, axis=[-1, -2])\n  labels = tf.squeeze(labels, axis=[-1, -2])\n  rouge_2_f_score = tf.py_func(rouge_n, (outputs, labels), tf.float32)\n  return rouge_2_f_score, tf.constant(1.0)", "language": "python"}
{"input": "Returns `true` if the file dependencies of the current childCompiler\nfor the given mainCompilation are outdated.\n\nUses the `hasOutdatedCompilationDependenciesMap` cache if possible.\n\n@param {WebpackCompilation} mainCompilation\n@returns {boolean}", "output": "function hasOutDatedTemplateCache (mainCompilation) {\n  const childCompiler = getChildCompiler(mainCompilation.compiler);\n  /**\n   * @type {WeakMap<HtmlWebpackChildCompiler, boolean>|undefined}\n   */\n  let hasOutdatedChildCompilerDependenciesMap = hasOutdatedCompilationDependenciesMap.get(mainCompilation);\n  // Create map for childCompiler if none exist\n  if (!hasOutdatedChildCompilerDependenciesMap) {\n    hasOutdatedChildCompilerDependenciesMap = new WeakMap();\n    hasOutdatedCompilationDependenciesMap.set(mainCompilation, hasOutdatedChildCompilerDependenciesMap);\n  }\n  // Try to get the `checkChildCompilerCache` result from cache\n  let isOutdated = hasOutdatedChildCompilerDependenciesMap.get(childCompiler);\n  if (isOutdated !== undefined) {\n    return isOutdated;\n  }\n  // If `checkChildCompilerCache` has never been called for the given\n  // `mainCompilation` and `childCompiler` combination call it:\n  isOutdated = isChildCompilerCacheOutdated(mainCompilation, childCompiler);\n  hasOutdatedChildCompilerDependenciesMap.set(childCompiler, isOutdated);\n  return isOutdated;\n}", "language": "javascript"}
{"input": "Returns the current position of write head.\n\n        Examples\n        ---------\n        >>> record = mx.recordio.MXIndexedRecordIO('tmp.idx', 'tmp.rec', 'w')\n        >>> print(record.tell())\n        0\n        >>> for i in range(5):\n        ...     record.write_idx(i, 'record_%d'%i)\n        ...     print(record.tell())\n        16\n        32\n        48\n        64\n        80", "output": "def tell(self):\n        \"\"\"Returns the current position of write head.\n\n        Examples\n        ---------\n        >>> record = mx.recordio.MXIndexedRecordIO('tmp.idx', 'tmp.rec', 'w')\n        >>> print(record.tell())\n        0\n        >>> for i in range(5):\n        ...     record.write_idx(i, 'record_%d'%i)\n        ...     print(record.tell())\n        16\n        32\n        48\n        64\n        80\n        \"\"\"\n        assert self.writable\n        pos = ctypes.c_size_t()\n        check_call(_LIB.MXRecordIOWriterTell(self.handle, ctypes.byref(pos)))\n        return pos.value", "language": "python"}
{"input": "works very well on 4x4.", "output": "def imagetransformer_b12l_4h_b256_uncond_dr03_tpu():\n  \"\"\"works very well on 4x4.\"\"\"\n  hparams = imagetransformer_bas8l_8h_big_uncond_dr03_imgnet()\n  update_hparams_for_tpu(hparams)\n  hparams.batch_size = 4\n  hparams.num_heads = 4   # heads are expensive on tpu\n  hparams.num_decoder_layers = 12\n  hparams.block_length = 256\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.learning_rate = 0.5\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.layer_preprocess_sequence = \"none\"\n  hparams.layer_postprocess_sequence = \"dan\"\n  hparams.layer_prepostprocess_dropout = 0.3\n  hparams.unconditional = True\n  return hparams", "language": "python"}
{"input": "Vuex init hook, injected into each instances init hooks list.", "output": "function vuexInit () {\n    var options = this.$options;\n    // store injection\n    if (options.store) {\n      this.$store = typeof options.store === 'function'\n        ? options.store()\n        : options.store;\n    } else if (options.parent && options.parent.$store) {\n      this.$store = options.parent.$store;\n    }\n  }", "language": "javascript"}
{"input": "format metric string", "output": "def _fmt_metric(value, show_stdv=True):\n    \"\"\"format metric string\"\"\"\n    if len(value) == 2:\n        return '%s:%g' % (value[0], value[1])\n    if len(value) == 3:\n        if show_stdv:\n            return '%s:%g+%g' % (value[0], value[1], value[2])\n        return '%s:%g' % (value[0], value[1])\n    raise ValueError(\"wrong metric value\")", "language": "python"}
{"input": "Map MXNet's Reshape operator attributes to onnx's Reshape operator.\n    Converts output shape attribute to output shape tensor\n    and return multiple created nodes.", "output": "def convert_reshape(node, **kwargs):\n    \"\"\"Map MXNet's Reshape operator attributes to onnx's Reshape operator.\n    Converts output shape attribute to output shape tensor\n    and return multiple created nodes.\n    \"\"\"\n    name, input_nodes, attrs = get_inputs(node, kwargs)\n\n    output_shape_list = convert_string_to_list(attrs[\"shape\"])\n\n    initializer = kwargs[\"initializer\"]\n    output_shape_np = np.array(output_shape_list, dtype='int64')\n    data_type = onnx.mapping.NP_TYPE_TO_TENSOR_TYPE[output_shape_np.dtype]\n    dims = np.shape(output_shape_np)\n\n    output_shape_name = \"reshape_attr_tensor\" + str(kwargs[\"idx\"])\n    tensor_node = onnx.helper.make_tensor_value_info(output_shape_name, data_type, dims)\n\n    initializer.append(\n        onnx.helper.make_tensor(\n            name=output_shape_name,\n            data_type=data_type,\n            dims=dims,\n            vals=output_shape_list,\n            raw=False,\n        )\n    )\n\n    input_nodes.append(output_shape_name)\n\n    not_supported_shape = [-2, -3, -4]\n\n    for val in output_shape_list:\n        if val in not_supported_shape:\n            raise AttributeError(\"Reshape: Shape value not supported in ONNX\", val)\n\n    reshape_node = onnx.helper.make_node(\n        \"Reshape\",\n        input_nodes,\n        [name],\n        name=name\n    )\n\n    return [tensor_node, reshape_node]", "language": "python"}
{"input": "/*\nNormalizes the given acc info object and ensures that all the defaults are set.", "output": "function(oInfo) {\n\t\t\tif (!oInfo) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tif (oInfo._normalized) {\n\t\t\t\treturn oInfo;\n\t\t\t}\n\n\t\t\toInfo.role = oInfo.role || \"\";\n\t\t\toInfo.type = oInfo.type || \"\";\n\t\t\toInfo.description = oInfo.description || \"\";\n\t\t\toInfo.enabled = (oInfo.enabled === true || oInfo.enabled === false) ? oInfo.enabled : null;\n\t\t\toInfo.editable = (oInfo.editable === true || oInfo.editable === false) ? oInfo.editable : null;\n\t\t\toInfo.children = oInfo.children || [];\n\t\t\toInfo._normalized = true;\n\n\t\t\treturn oInfo;\n\t\t}", "language": "javascript"}
{"input": "Waits until the Addons Manager has been opened and returns its controller\n\n@param {object} aSpec\nObject with parameters for customization\nElements: timeout - Duration to wait for the target state\n[optional - default: 5s]\n\n@returns Currently selected tab", "output": "function addonsManager_waitforOpened(aSpec) {\n    var spec = aSpec || { };\n    var timeout = (spec.timeout == undefined) ? TIMEOUT : spec.timeout;\n\n    // TODO: restore after 1.5.1 has landed\n    // var self = this;\n    //\n    // mozmill.utils.waitFor(function() {\n    //   return self.isOpen;\n    // }, timeout, 100, \"Add-ons Manager has been opened\");\n    \n    mozmill.utils.waitForEval(\"subject.isOpen\", timeout, 100, this);\n\n    // The first tab found will be the selected one\n    var tab = this.getTabs()[0];\n    tab.controller.waitForPageLoad();\n\n    return tab;\n  }", "language": "javascript"}
{"input": "Return an JavaRDD of Object by unpickling\n\n    It will convert each Python object into Java object by Pyrolite, whenever the\n    RDD is serialized in batch or not.", "output": "def _to_java_object_rdd(rdd):\n    \"\"\" Return an JavaRDD of Object by unpickling\n\n    It will convert each Python object into Java object by Pyrolite, whenever the\n    RDD is serialized in batch or not.\n    \"\"\"\n    rdd = rdd._reserialize(AutoBatchedSerializer(PickleSerializer()))\n    return rdd.ctx._jvm.org.apache.spark.ml.python.MLSerDe.pythonToJava(rdd._jrdd, True)", "language": "python"}
{"input": "Merge outputs that lives on multiple context into one, so that they look\n    like living on one context.", "output": "def _merge_multi_context(outputs, major_axis):\n    \"\"\"Merge outputs that lives on multiple context into one, so that they look\n    like living on one context.\n    \"\"\"\n    rets = []\n    for tensors, axis in zip(outputs, major_axis):\n        if axis >= 0:\n            # pylint: disable=no-member,protected-access\n            if len(tensors) == 1:\n                rets.append(tensors[0])\n            else:\n                # Concatenate if necessary\n                rets.append(nd.concat(*[tensor.as_in_context(tensors[0].context)\n                                        for tensor in tensors],\n                                      dim=axis))\n            # pylint: enable=no-member,protected-access\n        else:\n            # negative axis means the there is no batch_size axis, and all the\n            # results should be the same on each device. We simply take the\n            # first one, without checking they are actually the same\n            rets.append(tensors[0])\n    return rets", "language": "python"}
{"input": "Constructs a server object that stores request handlers and delegates\nincoming requests to those handlers\n@memberof grpc\n@constructor\n@param {Object=} options Options that should be passed to the internal server\nimplementation\n@example\nvar server = new grpc.Server();\nserver.addProtoService(protobuf_service_descriptor, service_implementation);\nserver.bind('address:port', server_credential);\nserver.start();", "output": "function Server(options) {\n  this.handlers = {};\n  var server = new grpc.Server(options);\n  this._server = server;\n  this.started = false;\n}", "language": "javascript"}
{"input": "Compares two paths segment-by-segment, used for sorting. When two files share a path prefix,\nthe less deeply nested one is sorted earlier in the list. Sorts files within the same parent\nfolder based on `compareFilenames()`.\n@param {string} path1\n@param {string} path2\n@return {number} -1, 0, or 1 depending on whether path1 is less than, equal to, or greater than\npath2 according to this ordering.", "output": "function comparePaths(path1, path2) {\n        var entryName1, entryName2,\n            pathParts1 = path1.split(\"/\"),\n            pathParts2 = path2.split(\"/\"),\n            length     = Math.min(pathParts1.length, pathParts2.length),\n            folders1   = pathParts1.length - 1,\n            folders2   = pathParts2.length - 1,\n            index      = 0;\n\n        while (index < length) {\n            entryName1 = pathParts1[index];\n            entryName2 = pathParts2[index];\n\n            if (entryName1 !== entryName2) {\n                if (index < folders1 && index < folders2) {\n                    return entryName1.toLocaleLowerCase().localeCompare(entryName2.toLocaleLowerCase());\n                } else if (index >= folders1 && index >= folders2) {\n                    return compareFilenames(entryName1, entryName2);\n                }\n                return (index >= folders1 && index < folders2) ? -1 : 1;\n            }\n            index++;\n        }\n        return 0;\n    }", "language": "javascript"}
{"input": "Callback for the start of each file upload request:", "output": "function (e, data) {\n                if (e.isDefaultPrevented()) {\n                    return false;\n                }\n                var that = $(this).data('blueimp-fileupload') ||\n                        $(this).data('fileupload');\n                if (data.context && data.dataType &&\n                        data.dataType.substr(0, 6) === 'iframe') {\n                    // Iframe Transport does not support progress events.\n                    // In lack of an indeterminate progress bar, we set\n                    // the progress to 100%, showing the full animated bar:\n                    data.context\n                        .find('.progress').addClass(\n                            !$.support.transition && 'progress-animated'\n                        )\n                        .attr('aria-valuenow', 100)\n                        .children().first().css(\n                            'width',\n                            '100%'\n                        );\n                }\n                return that._trigger('sent', e, data);\n            }", "language": "javascript"}
{"input": "Generate a set of logarithmic ticks\n@param generationOptions the options used to generate the ticks\n@param dataRange the range of the data\n@returns {number[]} array of tick values", "output": "function generateTicks$1(generationOptions, dataRange) {\n\tvar ticks = [];\n\n\tvar tickVal = valueOrDefault$a(generationOptions.min, Math.pow(10, Math.floor(helpers$1.log10(dataRange.min))));\n\n\tvar endExp = Math.floor(helpers$1.log10(dataRange.max));\n\tvar endSignificand = Math.ceil(dataRange.max / Math.pow(10, endExp));\n\tvar exp, significand;\n\n\tif (tickVal === 0) {\n\t\texp = Math.floor(helpers$1.log10(dataRange.minNotZero));\n\t\tsignificand = Math.floor(dataRange.minNotZero / Math.pow(10, exp));\n\n\t\tticks.push(tickVal);\n\t\ttickVal = significand * Math.pow(10, exp);\n\t} else {\n\t\texp = Math.floor(helpers$1.log10(tickVal));\n\t\tsignificand = Math.floor(tickVal / Math.pow(10, exp));\n\t}\n\tvar precision = exp < 0 ? Math.pow(10, Math.abs(exp)) : 1;\n\n\tdo {\n\t\tticks.push(tickVal);\n\n\t\t++significand;\n\t\tif (significand === 10) {\n\t\t\tsignificand = 1;\n\t\t\t++exp;\n\t\t\tprecision = exp >= 0 ? 1 : precision;\n\t\t}\n\n\t\ttickVal = Math.round(significand * Math.pow(10, exp) * precision) / precision;\n\t} while (exp < endExp || (exp === endExp && significand < endSignificand));\n\n\tvar lastTick = valueOrDefault$a(generationOptions.max, tickVal);\n\tticks.push(lastTick);\n\n\treturn ticks;\n}", "language": "javascript"}
{"input": "Initialization", "output": "function init() {\n        if (api.initialized) {\n            return;\n        }\n        var testRange;\n        var implementsDomRange = false, implementsTextRange = false;\n\n        // First, perform basic feature tests\n\n        if (isHostMethod(document, \"createRange\")) {\n            testRange = document.createRange();\n            if (areHostMethods(testRange, domRangeMethods) && areHostProperties(testRange, domRangeProperties)) {\n                implementsDomRange = true;\n            }\n        }\n\n        var body = getBody(document);\n        if (!body || body.nodeName.toLowerCase() != \"body\") {\n            fail(\"No body element found\");\n            return;\n        }\n\n        if (body && isHostMethod(body, \"createTextRange\")) {\n            testRange = body.createTextRange();\n            if (isTextRange(testRange)) {\n                implementsTextRange = true;\n            }\n        }\n\n        if (!implementsDomRange && !implementsTextRange) {\n            fail(\"Neither Range nor TextRange are available\");\n            return;\n        }\n\n        api.initialized = true;\n        api.features = {\n            implementsDomRange: implementsDomRange,\n            implementsTextRange: implementsTextRange\n        };\n\n        // Initialize modules\n        var module, errorMessage;\n        for (var moduleName in modules) {\n            if ( (module = modules[moduleName]) instanceof Module ) {\n                module.init(module, api);\n            }\n        }\n\n        // Call init listeners\n        for (var i = 0, len = initListeners.length; i < len; ++i) {\n            try {\n                initListeners[i](api);\n            } catch (ex) {\n                errorMessage = \"Rangy init listener threw an exception. Continuing. Detail: \" + getErrorDesc(ex);\n                consoleLog(errorMessage);\n            }\n        }\n    }", "language": "javascript"}
{"input": "Checks whether or not `thisArg` is not changed by `.call()`/`.apply()`.\n@param {ASTNode|null} expectedThis - The node that is the owner of the applied function.\n@param {ASTNode} thisArg - The node that is given to the first argument of the `.call()`/`.apply()`.\n@param {SourceCode} sourceCode - The ESLint source code object.\n@returns {boolean} Whether or not `thisArg` is not changed by `.call()`/`.apply()`.", "output": "function isValidThisArg(expectedThis, thisArg, sourceCode) {\n    if (!expectedThis) {\n        return astUtils.isNullOrUndefined(thisArg);\n    }\n    return astUtils.equalTokens(expectedThis, thisArg, sourceCode);\n}", "language": "javascript"}
{"input": "Helper function for dot_product_unmasked_self_attention_relative_2d.", "output": "def _matmul_with_relative_keys_2d(x, y, heads_share_relative_embedding):\n  \"\"\"Helper function for dot_product_unmasked_self_attention_relative_2d.\"\"\"\n  if heads_share_relative_embedding:\n    ret = tf.einsum(\"bhxyd,md->bhxym\", x, y)\n  else:\n    ret = tf.einsum(\"bhxyd,hmd->bhxym\", x, y)\n  return ret", "language": "python"}
{"input": "Emulates the system's which. Returns None if not found.", "output": "def system_which(command, mult=False):\n    \"\"\"Emulates the system's which. Returns None if not found.\"\"\"\n    _which = \"which -a\" if not os.name == \"nt\" else \"where\"\n    os.environ = {\n        vistir.compat.fs_str(k): vistir.compat.fs_str(val)\n        for k, val in os.environ.items()\n    }\n    result = None\n    try:\n        c = delegator.run(\"{0} {1}\".format(_which, command))\n        try:\n            # Which Not found\u2026\n            if c.return_code == 127:\n                click.echo(\n                    \"{}: the {} system utility is required for Pipenv to find Python installations properly.\"\n                    \"\\n  Please install it.\".format(\n                        crayons.red(\"Warning\", bold=True), crayons.red(_which)\n                    ),\n                    err=True,\n                )\n            assert c.return_code == 0\n        except AssertionError:\n            result = fallback_which(command, allow_global=True)\n    except TypeError:\n        if not result:\n            result = fallback_which(command, allow_global=True)\n    else:\n        if not result:\n            result = next(iter([c.out, c.err]), \"\").split(\"\\n\")\n            result = next(iter(result)) if not mult else result\n            return result\n        if not result:\n            result = fallback_which(command, allow_global=True)\n    result = [result] if mult else result\n    return result", "language": "python"}
{"input": "Adds the given reference URI to the map of reference URIs for schemas.\n\n@param {sap.ui.model.odata.v4.ODataMetaModel} oMetaModel\nThe OData metadata model\n@param {string} sSchema\nA namespace of a schema, for example \"foo.bar.\"\n@param {string} sReferenceUri\nA URI to the metadata document for the given schema\n@param {string} [sDocumentUri]\nThe URI to the metadata document containing the given reference to the given schema\n@throws {Error}\nIf the schema has already been loaded from a different URI", "output": "function addUrlForSchema(oMetaModel, sSchema, sReferenceUri, sDocumentUri) {\n\t\tvar sUrl0,\n\t\t\tmUrls = oMetaModel.mSchema2MetadataUrl[sSchema];\n\n\t\tif (!mUrls) {\n\t\t\tmUrls = oMetaModel.mSchema2MetadataUrl[sSchema] = {};\n\t\t\tmUrls[sReferenceUri] = false;\n\t\t} else if (!(sReferenceUri in mUrls)) {\n\t\t\tsUrl0 = Object.keys(mUrls)[0];\n\t\t\tif (mUrls[sUrl0]) {\n\t\t\t\t// document already processed, no different URLs allowed\n\t\t\t\treportAndThrowError(oMetaModel, \"A schema cannot span more than one document: \"\n\t\t\t\t\t+ sSchema + \" - expected reference URI \" + sUrl0 + \" but instead saw \"\n\t\t\t\t\t+ sReferenceUri, sDocumentUri);\n\t\t\t}\n\t\t\tmUrls[sReferenceUri] = false;\n\t\t}\n\t}", "language": "javascript"}
{"input": "This method warns once if a user implements a model which returns a dictionary with\n        values which we are unable to split back up into elements of the batch. This is controlled\n        by a class attribute ``_warn_for_unseperable_batches`` because it would be extremely verbose\n        otherwise.", "output": "def _maybe_warn_for_unseparable_batches(self, output_key: str):\n        \"\"\"\n        This method warns once if a user implements a model which returns a dictionary with\n        values which we are unable to split back up into elements of the batch. This is controlled\n        by a class attribute ``_warn_for_unseperable_batches`` because it would be extremely verbose\n        otherwise.\n        \"\"\"\n        if  output_key not in self._warn_for_unseparable_batches:\n            logger.warning(f\"Encountered the {output_key} key in the model's return dictionary which \"\n                           \"couldn't be split by the batch size. Key will be ignored.\")\n            # We only want to warn once for this key,\n            # so we set this to false so we don't warn again.\n            self._warn_for_unseparable_batches.add(output_key)", "language": "python"}
{"input": "Parameters\n    ----------\n    values : arraylike\n    dropna : boolean\n\n    Returns\n    -------\n    (uniques, counts)", "output": "def _value_counts_arraylike(values, dropna):\n    \"\"\"\n    Parameters\n    ----------\n    values : arraylike\n    dropna : boolean\n\n    Returns\n    -------\n    (uniques, counts)\n\n    \"\"\"\n    values = _ensure_arraylike(values)\n    original = values\n    values, dtype, ndtype = _ensure_data(values)\n\n    if needs_i8_conversion(dtype):\n        # i8\n\n        keys, counts = htable.value_count_int64(values, dropna)\n\n        if dropna:\n            msk = keys != iNaT\n            keys, counts = keys[msk], counts[msk]\n\n    else:\n        # ndarray like\n\n        # TODO: handle uint8\n        f = getattr(htable, \"value_count_{dtype}\".format(dtype=ndtype))\n        keys, counts = f(values, dropna)\n\n        mask = isna(values)\n        if not dropna and mask.any():\n            if not isna(keys).any():\n                keys = np.insert(keys, 0, np.NaN)\n                counts = np.insert(counts, 0, mask.sum())\n\n    keys = _reconstruct_data(keys, original.dtype, original)\n\n    return keys, counts", "language": "python"}
{"input": "Get the names of all query results (entity sets) offered by the model\n\n@returns {string[]} List of all query result names\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.Model#getAllQueryResultNames", "output": "function() {\n\t\t\tif (this._aQueryResultNames) {\n\t\t\t\treturn this._aQueryResultNames;\n\t\t\t}\n\n\t\t\tthis._aQueryResultNames = new Array(0);\n\n\t\t\tfor ( var sName in this._oQueryResultSet) {\n\t\t\t\tthis._aQueryResultNames.push(this._oQueryResultSet[sName].getName());\n\t\t\t}\n\n\t\t\treturn this._aQueryResultNames;\n\t\t}", "language": "javascript"}
{"input": "Calculates loss and psnr for predictions over multiple timesteps.", "output": "def calc_loss_psnr(gen_images, images, name, hparams=None, use_l1_loss=False):\n  \"\"\"Calculates loss and psnr for predictions over multiple timesteps.\"\"\"\n  del hparams\n  with tf.name_scope(name):\n    loss, error, psnr_all = 0.0, 0.0, 0.0\n    for _, x, gx in zip(range(len(gen_images)), images, gen_images):\n      recon_cost = mean_squared_error(x, gx)\n      if use_l1_loss:\n        recon_cost = l1_error(x, gx)\n\n      error_i = l1_error(x, gx)\n      psnr_i = peak_signal_to_noise_ratio(x, gx)\n      psnr_all += psnr_i\n      error += error_i\n      loss += recon_cost\n\n    psnr_all /= tf.to_float(len(gen_images))\n    loss /= tf.to_float(len(gen_images))\n    error /= tf.to_float(len(gen_images))\n\n    # if not hparams.use_tpu:\n    tf.summary.scalar('psnr_all', psnr_all)\n    tf.summary.scalar('loss', loss)\n\n    return loss, psnr_all", "language": "python"}
{"input": "/*\nModifies the labels and descriptions of a row header cell.\n@see ExtensionHelper.performCellModifications", "output": "function($Cell) {\n\t\t\tvar oTable = this.getTable(),\n\t\t\t\tsTableId = oTable.getId(),\n\t\t\t\tbIsInGroupingRow = TableUtils.Grouping.isInGroupingRow($Cell),\n\t\t\t\tbIsInSumRow = TableUtils.Grouping.isInSumRow($Cell),\n\t\t\t\toRow = oTable.getRows()[$Cell.attr(\"data-sap-ui-rowindex\")],\n\t\t\t\taDefaultLabels = ExtensionHelper.getAriaAttributesFor(this, TableAccExtension.ELEMENTTYPES.ROWHEADER)[\"aria-labelledby\"] || [],\n\t\t\t\taLabels = aDefaultLabels.concat([sTableId + \"-rownumberofrows\"]);\n\n\t\t\tif (!bIsInSumRow && !bIsInGroupingRow) {\n\t\t\t\tif (!$Cell.hasClass(\"sapUiTableRowHidden\")) {\n\t\t\t\t\taLabels.push(oRow.getId() + \"-rowselecttext\");\n\n\t\t\t\t\tif (TableUtils.hasRowHighlights(oTable)) {\n\t\t\t\t\t\taLabels.push(oRow.getId() + \"-highlighttext\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (bIsInGroupingRow) {\n\t\t\t\taLabels.push(sTableId + \"-ariarowgrouplabel\");\n\t\t\t\taLabels.push(sTableId + (oRow._bIsExpanded ? \"-rowcollapsetext\" : \"-rowexpandtext\"));\n\t\t\t\t//aLabels.push(oRow.getId() + \"-groupHeader\"); //Not needed: Screenreader seems to announce this automatically\n\t\t\t}\n\n\t\t\tif (bIsInSumRow) {\n\t\t\t\tvar iLevel = $Cell.data(\"sap-ui-level\");\n\t\t\t\tif (iLevel == 0) {\n\t\t\t\t\taLabels.push(sTableId + \"-ariagrandtotallabel\");\n\t\t\t\t} else if (iLevel > 0) {\n\t\t\t\t\taLabels.push(sTableId + \"-ariagrouptotallabel\");\n\t\t\t\t\t//aLabels.push(oRow.getId() + \"-groupHeader\"); //Not needed: Screenreader seems to announce this automatically\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tExtensionHelper.performCellModifications(this, $Cell, aDefaultLabels, null, aLabels, null, null);\n\t\t}", "language": "javascript"}
{"input": "[Deprecated] Please use save_parameters. Note that if you want load\n        from SymbolBlock later, please use export instead.\n\n        Save parameters to file.\n\n        filename : str\n            Path to file.", "output": "def save_params(self, filename):\n        \"\"\"[Deprecated] Please use save_parameters. Note that if you want load\n        from SymbolBlock later, please use export instead.\n\n        Save parameters to file.\n\n        filename : str\n            Path to file.\n        \"\"\"\n        warnings.warn(\"save_params is deprecated. Please use save_parameters. \"\n                      \"Note that if you want load from SymbolBlock later, please \"\n                      \"use export instead. For details, see \"\n                      \"https://mxnet.incubator.apache.org/tutorials/gluon/save_lo\"\n                      \"ad_params.html\")\n        try:\n            self.collect_params().save(filename, strip_prefix=self.prefix)\n        except ValueError as e:\n            raise ValueError('%s\\nsave_params is deprecated. Using ' \\\n                              'save_parameters may resolve this error.'%e.message)", "language": "python"}
{"input": "Read text out of an input file.\n\n    The default just reads the text, converts to unicode and yields one\n    unicode string.\n\n    Subclasses can override this function in order to preprocess, and can\n    yield any number of strings.\n\n    Args:\n      filepath: a string\n    Yields:\n      unicode strings.", "output": "def filepath_to_unicode_strings(self, filepath):\n    \"\"\"Read text out of an input file.\n\n    The default just reads the text, converts to unicode and yields one\n    unicode string.\n\n    Subclasses can override this function in order to preprocess, and can\n    yield any number of strings.\n\n    Args:\n      filepath: a string\n    Yields:\n      unicode strings.\n    \"\"\"\n    f = tf.gfile.Open(filepath)\n    b = f.read()\n    yield text_encoder.to_unicode_ignore_errors(b)", "language": "python"}
{"input": "ensure the filename passed to html-webpack-plugin is a relative path because it cannot correctly handle absolute paths", "output": "function ensureRelative(outputDir, p) {\n    if (path.isAbsolute(p)) {\n        return path.relative(outputDir, p);\n    } else {\n        return p;\n    }\n}", "language": "javascript"}
{"input": "Initializes the ApplicationVerifier.\n@param {string} submitButtonId The ID of the DOM element of the button to\nwhich we attach the invisible reCAPTCHA. This is required even in visible\nmode.", "output": "function makeApplicationVerifier(submitButtonId) {\n  var container = recaptchaSize === 'invisible' ?\n      submitButtonId :\n      'recaptcha-container';\n  applicationVerifier = new firebase.auth.RecaptchaVerifier(container,\n      {'size': recaptchaSize});\n}", "language": "javascript"}
{"input": "Creates objects with coordinates (x1, y1, x2, y2, cx, cy, width, height)\nto simulate DOM elements on the screen.\nCoords is used by Gridster to create a faux grid with any DOM element can\ncollide.\n\n@class Coords\n@param {HTMLElement|Object} obj The jQuery HTMLElement or a object with: left,\ntop, width and height properties.\n@return {Object} Coords instance.\n@constructor", "output": "function Coords(obj)\n\t{\n\t\tif(obj[0] && $.isPlainObject(obj[0]))\n\t\t{\n\t\t\tthis.data = obj[0];\n\t\t}\n\t\telse\n\t\t{\n\t\t\tthis.el = obj;\n\t\t}\n\n\t\tthis.isCoords = true;\n\t\tthis.coords = {};\n\t\tthis.init();\n\t\treturn this;\n\t}", "language": "javascript"}
{"input": "Convert escaped markup back into a text string. This replaces\n        HTML entities with the characters they represent.\n\n        >>> Markup('Main &raquo; <em>About</em>').unescape()\n        'Main \u00bb <em>About</em>'", "output": "def unescape(self):\n        \"\"\"Convert escaped markup back into a text string. This replaces\n        HTML entities with the characters they represent.\n\n        >>> Markup('Main &raquo; <em>About</em>').unescape()\n        'Main \u00bb <em>About</em>'\n        \"\"\"\n        from ._constants import HTML_ENTITIES\n\n        def handle_match(m):\n            name = m.group(1)\n            if name in HTML_ENTITIES:\n                return unichr(HTML_ENTITIES[name])\n            try:\n                if name[:2] in (\"#x\", \"#X\"):\n                    return unichr(int(name[2:], 16))\n                elif name.startswith(\"#\"):\n                    return unichr(int(name[1:]))\n            except ValueError:\n                pass\n            # Don't modify unexpected input.\n            return m.group()\n\n        return _entity_re.sub(handle_match, text_type(self))", "language": "python"}
{"input": "/*----------------------------------------------------------------------------------------------------------------", "output": "function inspectNode(node) {\n            if (!node) {\n                return \"[No node]\";\n            }\n            if (crashyTextNodes && isBrokenNode(node)) {\n                return \"[Broken node]\";\n            }\n            if (isCharacterDataNode(node)) {\n                return '\"' + node.data + '\"';\n            }\n            if (node.nodeType == 1) {\n                var idAttr = node.id ? ' id=\"' + node.id + '\"' : \"\";\n                return \"<\" + node.nodeName + idAttr + \">[index:\" + getNodeIndex(node) + \",length:\" + node.childNodes.length + \"][\" + (node.innerHTML || \"[innerHTML not supported]\").slice(0, 25) + \"]\";\n            }\n            return node.nodeName;\n        }", "language": "javascript"}
{"input": "Resize the parallel coordinate system.\n@param {module:echarts/coord/parallel/ParallelModel} parallelModel\n@param {module:echarts/ExtensionAPI} api", "output": "function (parallelModel, api) {\n        this._rect = layoutUtil.getLayoutRect(\n            parallelModel.getBoxLayoutParams(),\n            {\n                width: api.getWidth(),\n                height: api.getHeight()\n            }\n        );\n\n        this._layoutAxes();\n    }", "language": "javascript"}
{"input": "Defer a function that may or may not run asynchronously.\n\nFirst parameter should be the function to execute with subsequent\nparameters being passed as arguments to that function", "output": "function(fn) {\n\t\t\t\tif (typeof fn === 'object' && fn.then && fn.catch) {\n\t\t\t\t\tvar defer = fn;\n\t\t\t\t\tfn = function(resolve, reject) {\n\t\t\t\t\t\tdefer.then(resolve).catch(reject);\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t\tfuncGuard(fn);\n\t\t\t\tif (err !== undefined) {\n\t\t\t\t\treturn;\n\t\t\t\t} else if (complete) {\n\t\t\t\t\tthrow new Error('Queue already completed');\n\t\t\t\t}\n\n\t\t\t\ttasks.push(fn);\n\t\t\t\t++remaining;\n\t\t\t\tpop();\n\t\t\t\treturn q;\n\t\t\t}", "language": "javascript"}
{"input": "/* Helpers", "output": "function dragElement(el, events) {\n\n  function getPointer(e) {\n    var x = 'clientX';\n    var y = 'clientY';\n    var evt = e.touches ? e.touches[0] : e;\n    return { x: evt[x], y: evt[y] };\n  }\n\n  var drag = { x: 0, y: 0, deltaX: 0, deltaY: 0, active: true, events: events || {} };\n  var originalX = 0;\n  var originalY = 0;\n  var pointerX = 0;\n  var pointerY = 0;\n\n  function move(e) {\n    if (drag.active) return;\n    drag.deltaX = pointerX - getPointer(e).x;\n    drag.deltaY = pointerY - getPointer(e).y;\n    drag.x = originalX - drag.deltaX;\n    drag.y = originalY - drag.deltaY;\n    if (drag.events.move) drag.events.move(drag);\n  }\n\n  function release(e) {\n    drag.active = true;\n    if (drag.events.release) drag.events.release(drag);\n    document.removeEventListener('mousemove', move, false);\n    document.removeEventListener('mouseup', release, false);\n    document.removeEventListener('touchmove', move, false);\n    document.removeEventListener('touchend', release, false);\n  }\n\n  function start(e) {\n    if (!drag.active) return;\n    e.preventDefault();\n    drag.active = false;\n    pointerX = getPointer(e).x;\n    pointerY = getPointer(e).y;\n    originalX = drag.x;\n    originalY = drag.y;\n    if (drag.events.begin) drag.events.begin(drag);\n    document.addEventListener('mousemove', move, false);\n    document.addEventListener('mouseup', release, false);\n    document.addEventListener('touchmove', move, false);\n    document.addEventListener('touchend', release, false);\n  }\n\n  el.addEventListener('mousedown', start, false);\n  el.addEventListener('touchstart', start, false);\n\n  return drag;\n\n}", "language": "javascript"}
{"input": "Given a list of URLs to stylesheets, loads the first that loads without triggering an error event.", "output": "function loadStylesheetsFallingBack(stylesheets) {\n    var n = stylesheets.length;\n    function load(i) {\n      if (i === n) { return; }\n      var link = doc.createElement('link');\n      link.rel = 'stylesheet';\n      link.type = 'text/css';\n      if (i + 1 < n) {\n        // http://pieisgood.org/test/script-link-events/ indicates that many\n        // versions of IE do not support onerror on <link>s, though\n        // http://msdn.microsoft.com/en-us/library/ie/ms535848(v=vs.85).aspx\n        // indicates that recent IEs do support error.\n        link.error = link.onerror = function () { load(i + 1); };\n      }\n      link.href = stylesheets[i];\n      head.appendChild(link);\n    }\n    load(0);\n  }", "language": "javascript"}
{"input": "Unload and destroy all currently loaded Howl objects.\n@return {Howler}", "output": "function() {\n      var self = this || Howler;\n\n      for (var i=self._howls.length-1; i>=0; i--) {\n        self._howls[i].unload();\n      }\n\n      // Create a new AudioContext to make sure it is fully reset.\n      if (self.usingWebAudio && self.ctx && typeof self.ctx.close !== 'undefined') {\n        self.ctx.close();\n        self.ctx = null;\n        setupAudioContext();\n      }\n\n      return self;\n    }", "language": "javascript"}
{"input": "Helper function: generate a random number as a lower-endian digits list.", "output": "def random_number_lower_endian(length, base):\n  \"\"\"Helper function: generate a random number as a lower-endian digits list.\"\"\"\n  if length == 1:  # Last digit can be 0 only if length is 1.\n    return [np.random.randint(base)]\n  prefix = [np.random.randint(base) for _ in range(length - 1)]\n  return prefix + [np.random.randint(base - 1) + 1]", "language": "python"}
{"input": "Need to re-render if the sort order or the contents change.", "output": "function (nextProps, nextState) {\n            return nextProps.forceRender ||\n                this.props.contents !== nextProps.contents ||\n                this.props.sortDirectoriesFirst !== nextProps.sortDirectoriesFirst ||\n                this.props.extensions !== nextProps.extensions;\n        }", "language": "javascript"}
{"input": "Interface to a `Client` for a given `Namespace`.\n\n@param {Namespace} nsp\n@param {Client} client\n@api public", "output": "function Socket(nsp, client, query){\n  this.nsp = nsp;\n  this.server = nsp.server;\n  this.adapter = this.nsp.adapter;\n  this.id = nsp.name !== '/' ? nsp.name + '#' + client.id : client.id;\n  this.client = client;\n  this.conn = client.conn;\n  this.rooms = {};\n  this.acks = {};\n  this.connected = true;\n  this.disconnected = false;\n  this.handshake = this.buildHandshake(query);\n  this.fns = [];\n  this.flags = {};\n  this._rooms = [];\n}", "language": "javascript"}
{"input": "url: a string, scraper: a function that takes string data at that URL. interval: number in milliseconds. cb: a callback function that takes an error and data returned by the scraper.  To use this from a service:  const { promisify } = require('util') const { regularUpdate } = require('../../core/legacy/regular-update')  function getThing() { return promisify(regularUpdate)({ url: ..., ... }) }  in handle():  const thing = await getThing()", "output": "function regularUpdate(\n  {\n    url,\n    intervalMillis,\n    json = true,\n    scraper = buffer => buffer,\n    options = {},\n    request = require('request'),\n  },\n  cb\n) {\n  const timestamp = Date.now()\n  const cached = regularUpdateCache[url]\n  if (cached != null && timestamp - cached.timestamp < intervalMillis) {\n    cb(null, cached.data)\n    return\n  }\n  request(url, options, (err, res, buffer) => {\n    if (err != null) {\n      cb(\n        new Inaccessible({\n          prettyMessage: 'intermediate resource inaccessible',\n          underlyingError: err,\n        })\n      )\n      return\n    }\n\n    if (res.statusCode < 200 || res.statusCode >= 300) {\n      cb(\n        new InvalidResponse({\n          prettyMessage: 'intermediate resource inaccessible',\n        })\n      )\n    }\n\n    let reqData\n    if (json) {\n      try {\n        reqData = JSON.parse(buffer)\n      } catch (e) {\n        cb(\n          new InvalidResponse({\n            prettyMessage: 'unparseable intermediate json response',\n            underlyingError: e,\n          })\n        )\n        return\n      }\n    } else {\n      reqData = buffer\n    }\n\n    let data\n    try {\n      data = scraper(reqData)\n    } catch (e) {\n      cb(e)\n      return\n    }\n\n    regularUpdateCache[url] = { timestamp, data }\n    cb(null, data)\n  })\n}", "language": "javascript"}
{"input": "Heap Sort that uses a min heap to sort an array in ascending order\n        Complexity: O(n log(n))", "output": "def min_heap_sort(arr, simulation=False):\n    \"\"\" Heap Sort that uses a min heap to sort an array in ascending order\n        Complexity: O(n log(n))\n    \"\"\"\n    iteration = 0\n    if simulation:\n        print(\"iteration\",iteration,\":\",*arr)\n        \n    for i in range(0, len(arr) - 1):\n        iteration = min_heapify(arr, i, simulation, iteration)\n\n    return arr", "language": "python"}
{"input": "Detect the encoding of the given byte string.\n\n    :param byte_str:     The byte sequence to examine.\n    :type byte_str:      ``bytes`` or ``bytearray``", "output": "def detect(byte_str):\n    \"\"\"\n    Detect the encoding of the given byte string.\n\n    :param byte_str:     The byte sequence to examine.\n    :type byte_str:      ``bytes`` or ``bytearray``\n    \"\"\"\n    if not isinstance(byte_str, bytearray):\n        if not isinstance(byte_str, bytes):\n            raise TypeError('Expected object of type bytes or bytearray, got: '\n                            '{0}'.format(type(byte_str)))\n        else:\n            byte_str = bytearray(byte_str)\n    detector = UniversalDetector()\n    detector.feed(byte_str)\n    return detector.close()", "language": "python"}
{"input": "Loads state from a directory. Modifies the object in place and\n        returns it. If the saved `Language` object contains a model, the\n        model will be loaded.\n\n        path (unicode or Path): A path to a directory.\n        exclude (list): Names of components or serialization fields to exclude.\n        RETURNS (Language): The modified `Language` object.\n\n        DOCS: https://spacy.io/api/language#from_disk", "output": "def from_disk(self, path, exclude=tuple(), disable=None):\n        \"\"\"Loads state from a directory. Modifies the object in place and\n        returns it. If the saved `Language` object contains a model, the\n        model will be loaded.\n\n        path (unicode or Path): A path to a directory.\n        exclude (list): Names of components or serialization fields to exclude.\n        RETURNS (Language): The modified `Language` object.\n\n        DOCS: https://spacy.io/api/language#from_disk\n        \"\"\"\n        if disable is not None:\n            deprecation_warning(Warnings.W014)\n            exclude = disable\n        path = util.ensure_path(path)\n        deserializers = OrderedDict()\n        deserializers[\"meta.json\"] = lambda p: self.meta.update(srsly.read_json(p))\n        deserializers[\"vocab\"] = lambda p: self.vocab.from_disk(p) and _fix_pretrained_vectors_name(self)\n        deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(p, exclude=[\"vocab\"])\n        for name, proc in self.pipeline:\n            if name in exclude:\n                continue\n            if not hasattr(proc, \"from_disk\"):\n                continue\n            deserializers[name] = lambda p, proc=proc: proc.from_disk(p, exclude=[\"vocab\"])\n        if not (path / \"vocab\").exists() and \"vocab\" not in exclude:\n            # Convert to list here in case exclude is (default) tuple\n            exclude = list(exclude) + [\"vocab\"]\n        util.from_disk(path, deserializers, exclude)\n        self._path = path\n        return self", "language": "python"}
{"input": "/*\nReturns a sorted and formatted list of hints with the query substring\nhighlighted.\n\n@param {Array.<Object>} hints - the list of hints to format\n@param {string} query - querystring used for highlighting matched\nportions of each hint\n@return {Array.jQuery} sorted Array of jQuery DOM elements to insert", "output": "function formatHints(hints, query) {\n\n        var hasMetadata = hints.some(function (token) {\n            return token.type || token.description;\n        });\n\n        StringMatch.basicMatchSort(hints);\n        return hints.map(function (token) {\n            var $hintItem = $(\"<span>\").addClass(\"brackets-pref-hints\"),\n                $hintObj  = $(\"<span>\").addClass(\"hint-obj\");\n\n            // highlight the matched portion of each hint\n            if (token.stringRanges) {\n                token.stringRanges.forEach(function (item) {\n                    if (item.matched) {\n                        $hintObj.append($(\"<span>\")\n                            .text(item.text)\n                            .addClass(\"matched-hint\"));\n                    } else {\n                        $hintObj.append(item.text);\n                    }\n                });\n            } else {\n                $hintObj.text(token.value);\n            }\n\n            $hintItem.append($hintObj);\n\n            if (hasMetadata) {\n                $hintItem.data(\"type\", token.type);\n                if (token.description) {\n                    $hintItem.append($(\"<span>\")\n                                        .addClass(\"hint-description\")\n                                        .text(token.description));\n                }\n            }\n            return $hintItem;\n        });\n    }", "language": "javascript"}
{"input": "@license\nCopyright Google Inc. All Rights Reserved.\n\nUse of this source code is governed by an MIT-style license that can be\nfound in the LICENSE file at https://angular.io/license", "output": "function file2moduleName(filePath) {\n  return filePath\n      .replace(/\\\\/g, '/')\n      // module name should be relative to `modules` and `tools` folder\n      .replace(/.*\\/modules\\//, '')\n      //  and 'dist' folder\n      .replace(/.*\\/dist\\/js\\/dev\\/es5\\//, '')\n      // module name should not include `lib`, `web` folders\n      // as they are wrapper packages for dart\n      .replace(/\\/web\\//, '/')\n      .replace(/\\/lib\\//, '/')\n      // module name should not have a suffix\n      .replace(/\\.\\w*$/, '');\n}", "language": "javascript"}
{"input": "Find the matching Buddhist date for the given gregorian date\n\n@param {object} oGregorian\n@return {object}", "output": "function toBuddhist(oGregorian) {\n\t\tvar iEraStartYear = UniversalDate.getEraStartDate(CalendarType.Buddhist, 0).year,\n\t\t\tiYear = oGregorian.year - iEraStartYear + 1;\n\t\t// Before 1941 new year started on 1st of April\n\t\tif (oGregorian.year < 1941 && oGregorian.month < 3) {\n\t\t\tiYear -= 1;\n\t\t}\n\t\tif (oGregorian.year === null) {\n\t\t\tiYear = undefined;\n\t\t}\n\t\treturn {\n\t\t\tyear: iYear,\n\t\t\tmonth: oGregorian.month,\n\t\t\tday: oGregorian.day\n\t\t};\n\t}", "language": "javascript"}
{"input": "Compares two decimal values given as strings.\n\n@param {string} sValue1\nthe first value to compare\n@param {string} sValue2\nthe second value to compare\n@return {int}\nthe result of the compare: <code>0</code> if the values are equal, <code>-1</code> if the\nfirst value is smaller, <code>1</code> if the first value is larger, <code>NaN</code> if\nthey cannot be compared", "output": "function decimalCompare(sValue1, sValue2) {\n\t\tvar oDecimal1, oDecimal2, iResult;\n\n\t\tif (sValue1 === sValue2) {\n\t\t\treturn 0;\n\t\t}\n\t\toDecimal1 = parseDecimal(sValue1);\n\t\toDecimal2 = parseDecimal(sValue2);\n\t\tif (!oDecimal1 || !oDecimal2) {\n\t\t\treturn NaN;\n\t\t}\n\t\tif (oDecimal1.sign !== oDecimal2.sign) {\n\t\t\treturn oDecimal1.sign > oDecimal2.sign ? 1 : -1;\n\t\t}\n\t\t// So they have the same sign.\n\t\t// If the number of integer digits equals, we can simply compare the strings\n\t\tiResult = simpleCompare(oDecimal1.integerLength, oDecimal2.integerLength)\n\t\t\t|| simpleCompare(oDecimal1.abs, oDecimal2.abs);\n\t\treturn oDecimal1.sign * iResult;\n\t}", "language": "javascript"}
{"input": "Initialize three.js camera and add it to the entity.\nAdd reference from scene to this entity as the camera.", "output": "function () {\n    var camera;\n    var el = this.el;\n\n    // Create camera.\n    camera = this.camera = new THREE.PerspectiveCamera();\n    el.setObject3D('camera', camera);\n  }", "language": "javascript"}
{"input": "Add handles to all non-container layers in the model.\n        Recursively for non-container layers", "output": "def add_handles(self, model, forward_handle, backward_handle):\n        \"\"\"\n        Add handles to all non-container layers in the model.\n        Recursively for non-container layers\n        \"\"\"\n        handles_list = []\n        for child in model.children():\n            if 'nn.modules.container' in str(type(child)):\n                handles_list.extend(self.add_handles(child, forward_handle, backward_handle))\n            else:\n                handles_list.append(child.register_forward_hook(forward_handle))\n                handles_list.append(child.register_backward_hook(backward_handle))\n        return handles_list", "language": "python"}
{"input": "Coerce *s* to six.text_type.\n\n    For Python 2:\n      - `unicode` -> `unicode`\n      - `str` -> `unicode`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`", "output": "def ensure_text(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to six.text_type.\n\n    For Python 2:\n      - `unicode` -> `unicode`\n      - `str` -> `unicode`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    if isinstance(s, binary_type):\n        return s.decode(encoding, errors)\n    elif isinstance(s, text_type):\n        return s\n    else:\n        raise TypeError(\"not expecting type '%s'\" % type(s))", "language": "python"}
{"input": "Returns the coverage object of pytest-cov.", "output": "def get_cov(config):\n    \"\"\"Returns the coverage object of pytest-cov.\"\"\"\n\n    # Check with hasplugin to avoid getplugin exception in older pytest.\n    if config.pluginmanager.hasplugin('_cov'):\n        plugin = config.pluginmanager.getplugin('_cov')\n        if plugin.cov_controller:\n            return plugin.cov_controller.cov\n    return None", "language": "python"}
{"input": "Open the Tab View", "output": "function tabView_open() {\n    var menuitem = new elementslib.Elem(this._controller.menus['view-menu'].menu_tabview);\n    this._controller.click(menuitem);\n    this.waitForOpened();\n\n    this._tabView = this.getElement({type: \"tabView\"});\n    this._tabViewDoc = this._tabView.getNode().webNavigation.document;\n  }", "language": "javascript"}
{"input": "-----------------------------------------------------------------------------", "output": "function showInterfaceIdl(intf, html) {\n    html.push(\"<div class='show-Idl'><h3>IDL</h3><pre>\")\n    html.push(\"interface {\")\n\n    intf.methods.forEach(function(method){\n        showInterfaceIdlMethod(method, html)\n    })\n\n    if (intf.attributes.length > 0) html.push(\"<table>\")\n    intf.attributes.forEach(function(attribute){\n        showInterfaceIdlAttribute(attribute, html)\n    })\n    if (intf.attributes.length > 0) html.push(\"</table>\")\n\n    html.push(\"};\")\n    html.push(\"</pre></div>\")\n}", "language": "javascript"}
{"input": "Given an iterable of lines from a Metadata file, return\n    the value of the Version field, if present, or None otherwise.", "output": "def _version_from_file(lines):\n    \"\"\"\n    Given an iterable of lines from a Metadata file, return\n    the value of the Version field, if present, or None otherwise.\n    \"\"\"\n    def is_version_line(line):\n        return line.lower().startswith('version:')\n    version_lines = filter(is_version_line, lines)\n    line = next(iter(version_lines), '')\n    _, _, value = line.partition(':')\n    return safe_version(value.strip()) or None", "language": "python"}
{"input": "Returns a target by its name (if you pass myTarget: { view: \"myView\" }) in the config myTarget is the name.\n\n@param {string|string[]} vName the name of a single target or the name of multiple targets\n@return {sap.ui.core.routing.Target|undefined|sap.ui.core.routing.Target[]} The target with the coresponding name or undefined. If an array way passed as name this will return an array with all found targets. Non existing targets will not be returned but will log an error.\n@public", "output": "function (vName) {\n\t\t\t\tvar that = this,\n\t\t\t\t\taResult = [];\n\n\t\t\t\tif (Array.isArray(vName)) {\n\t\t\t\t\tvName.forEach(function (sName) {\n\t\t\t\t\t\tvar oTarget = that._mTargets[sName];\n\n\t\t\t\t\t\tif (oTarget) {\n\t\t\t\t\t\t\taResult.push(oTarget);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tLog.error(\"The target you tried to get \\\"\" + sName + \"\\\" does not exist!\", that);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t\treturn aResult;\n\t\t\t\t}\n\n\t\t\t\treturn this._mTargets[vName];\n\t\t\t}", "language": "javascript"}
{"input": "Returns the :class:`StatCounter` members as a ``dict``.\n\n        >>> sc.parallelize([1., 2., 3., 4.]).stats().asDict()\n        {'count': 4L,\n         'max': 4.0,\n         'mean': 2.5,\n         'min': 1.0,\n         'stdev': 1.2909944487358056,\n         'sum': 10.0,\n         'variance': 1.6666666666666667}", "output": "def asDict(self, sample=False):\n        \"\"\"Returns the :class:`StatCounter` members as a ``dict``.\n\n        >>> sc.parallelize([1., 2., 3., 4.]).stats().asDict()\n        {'count': 4L,\n         'max': 4.0,\n         'mean': 2.5,\n         'min': 1.0,\n         'stdev': 1.2909944487358056,\n         'sum': 10.0,\n         'variance': 1.6666666666666667}\n        \"\"\"\n        return {\n            'count': self.count(),\n            'mean': self.mean(),\n            'sum': self.sum(),\n            'min': self.min(),\n            'max': self.max(),\n            'stdev': self.stdev() if sample else self.sampleStdev(),\n            'variance': self.variance() if sample else self.sampleVariance()\n        }", "language": "python"}
{"input": "return beam-labelings, sorted by probability", "output": "def sort(self):\n        \"\"\"\n        return beam-labelings, sorted by probability\n        \"\"\"\n        beams = [v for (_, v) in self.entries.items()]\n        sortedBeams = sorted(beams, reverse=True, key=lambda x: x.prTotal*x.prText)\n        return [x.labeling for x in sortedBeams]", "language": "python"}
{"input": "Test is a lexical state is in a function call.\n\n@param {Object} lex - lexical state.\n@return {Object | boolean}", "output": "function isInFunctionalCall(lex) {\n            // in a call, or inside array or object brackets that are inside a function.\n            return (lex && (lex.info === \"call\" ||\n                (lex.info === undefined && (lex.type === \"]\" || lex.type === \"}\") &&\n                    lex.prev.info === \"call\")));\n        }", "language": "javascript"}
{"input": "This function creates a screenshot of the window provided in the given\ncontroller and highlights elements from the coordinates provided in the\ngiven boxes-array.\n\n@param {array of array of int} boxes\n@param {MozmillController} controller", "output": "function create(controller, boxes) {\n  var doc = controller.window.document;\n  var maxWidth = doc.documentElement.boxObject.width;\n  var maxHeight = doc.documentElement.boxObject.height;\n  var rect = [];\n  for (var i = 0, j = boxes.length; i < j; ++i) {\n    rect = boxes[i];\n    if (rect[0] + rect[2] > maxWidth) maxWidth = rect[0] + rect[2];\n    if (rect[1] + rect[3] > maxHeight) maxHeight = rect[1] + rect[3];\n  }\n  var canvas = doc.createElementNS(\"http://www.w3.org/1999/xhtml\", \"canvas\");\n  var width = doc.documentElement.boxObject.width;\n  var height = doc.documentElement.boxObject.height;\n  canvas.width = maxWidth;\n  canvas.height = maxHeight;\n  var ctx = canvas.getContext(\"2d\");\n  ctx.clearRect(0,0, canvas.width, canvas.height);\n  ctx.save();\n  ctx.drawWindow(controller.window, 0, 0, width, height, \"rgb(0,0,0)\");\n  ctx.restore();\n  ctx.save();\n  ctx.fillStyle = \"rgba(255,0,0,0.4)\";\n  for (var i = 0, j = boxes.length; i < j; ++i) {\n    rect = boxes[i];\n    ctx.fillRect(rect[0], rect[1], rect[2], rect[3]);\n  }\n  ctx.restore();\n\n  _saveCanvas(canvas);\n}", "language": "javascript"}
{"input": "sub-classes to define\n        return a sliced object\n\n        Parameters\n        ----------\n        key : string / list of selections\n        ndim : 1,2\n            requested ndim of result\n        subset : object, default None\n            subset to act on", "output": "def _gotitem(self, key, ndim, subset=None):\n        \"\"\"\n        sub-classes to define\n        return a sliced object\n\n        Parameters\n        ----------\n        key : string / list of selections\n        ndim : 1,2\n            requested ndim of result\n        subset : object, default None\n            subset to act on\n        \"\"\"\n\n        if ndim == 2:\n            if subset is None:\n                subset = self.obj\n            return DataFrameGroupBy(subset, self.grouper, selection=key,\n                                    grouper=self.grouper,\n                                    exclusions=self.exclusions,\n                                    as_index=self.as_index,\n                                    observed=self.observed)\n        elif ndim == 1:\n            if subset is None:\n                subset = self.obj[key]\n            return SeriesGroupBy(subset, selection=key,\n                                 grouper=self.grouper)\n\n        raise AssertionError(\"invalid ndim for _gotitem\")", "language": "python"}
{"input": "Update the list of log files to monitor.", "output": "def update_log_filenames(self):\n        \"\"\"Update the list of log files to monitor.\"\"\"\n        log_filenames = os.listdir(self.logs_dir)\n\n        for log_filename in log_filenames:\n            full_path = os.path.join(self.logs_dir, log_filename)\n            if full_path not in self.log_filenames:\n                self.log_filenames.add(full_path)\n                self.closed_file_infos.append(\n                    LogFileInfo(\n                        filename=full_path,\n                        size_when_last_opened=0,\n                        file_position=0,\n                        file_handle=None))\n                logger.info(\"Beginning to track file {}\".format(log_filename))", "language": "python"}
{"input": "Defines preference to enable/disable Auto Update", "output": "function setupAutoUpdatePreference() {\n        PreferencesManager.definePreference(\"autoUpdate.AutoUpdate\", \"boolean\", true, {\n            description: Strings.DESCRIPTION_AUTO_UPDATE\n        });\n\n        // Set or unset the auto update, based on preference state change\n        PreferencesManager.on(\"change\", \"autoUpdate.AutoUpdate\", function () {\n            if (_isAutoUpdateEnabled()) {\n                setupAutoUpdate();\n                UpdateNotification.registerUpdateHandler(_updateProcessHandler);\n            } else {\n                unsetAutoUpdate();\n                UpdateNotification.resetToDefaultUpdateHandler();\n            }\n        });\n    }", "language": "javascript"}
{"input": "An object providing sequence-like access to the\n        components in the filesystem path.", "output": "def parts(self):\n        \"\"\"An object providing sequence-like access to the\n        components in the filesystem path.\"\"\"\n        # We cache the tuple to avoid building a new one each time .parts\n        # is accessed.  XXX is this necessary?\n        try:\n            return self._pparts\n        except AttributeError:\n            self._pparts = tuple(self._parts)\n            return self._pparts", "language": "python"}
{"input": "/* [MS-XLS] 2.5.198.32 ; [MS-XLSB] 2.5.97.23", "output": "function parse_PtgArray(blob, length, opts) {\n\tvar type = (blob[blob.l++] & 0x60) >> 5;\n\tblob.l += opts.biff == 2 ? 6 : opts.biff == 12 ? 14 : 7;\n\treturn [type];\n}", "language": "javascript"}
{"input": "Returns indices of the maximum values along an axis", "output": "def argmax(attrs, inputs, proto_obj):\n    \"\"\"Returns indices of the maximum values along an axis\"\"\"\n    axis = attrs.get('axis', 0)\n    keepdims = attrs.get('keepdims', 1)\n    argmax_op = symbol.argmax(inputs[0], axis=axis, keepdims=keepdims)\n    # onnx argmax operator always expects int64 as output type\n    cast_attrs = {'dtype': 'int64'}\n    return 'cast', cast_attrs, argmax_op", "language": "python"}
{"input": "Run the engine on the expression\n\n        This method performs alignment which is necessary no matter what engine\n        is being used, thus its implementation is in the base class.\n\n        Returns\n        -------\n        obj : object\n            The result of the passed expression.", "output": "def evaluate(self):\n        \"\"\"Run the engine on the expression\n\n        This method performs alignment which is necessary no matter what engine\n        is being used, thus its implementation is in the base class.\n\n        Returns\n        -------\n        obj : object\n            The result of the passed expression.\n        \"\"\"\n        if not self._is_aligned:\n            self.result_type, self.aligned_axes = _align(self.expr.terms)\n\n        # make sure no names in resolvers and locals/globals clash\n        res = self._evaluate()\n        return _reconstruct_object(self.result_type, res, self.aligned_axes,\n                                   self.expr.terms.return_type)", "language": "python"}
{"input": "\u7ed1\u5b9a\u4e8b\u4ef6\uff0c\u4e14\u5f53handler\u6267\u884c\u5b8c\u540e\uff0c\u81ea\u52a8\u89e3\u9664\u7ed1\u5b9a\u3002\n@method once\n@grammar once( name, callback[, context] ) => self\n@param  {String}   name     \u4e8b\u4ef6\u540d\n@param  {Function} callback \u4e8b\u4ef6\u5904\u7406\u5668\n@param  {Object}   [context]  \u4e8b\u4ef6\u5904\u7406\u5668\u7684\u4e0a\u4e0b\u6587\u3002\n@return {self} \u8fd4\u56de\u81ea\u8eab\uff0c\u65b9\u4fbf\u94fe\u5f0f\n@chainable", "output": "function( name, callback, context ) {\n                var me = this;\n    \n                if ( !callback ) {\n                    return me;\n                }\n    \n                eachEvent( name, callback, function( name, callback ) {\n                    var once = function() {\n                            me.off( name, once );\n                            return callback.apply( context || me, arguments );\n                        };\n    \n                    once._cb = callback;\n                    me.on( name, once, context );\n                });\n    \n                return me;\n            }", "language": "javascript"}
{"input": "Handle selection preservation and TEXT_CHANGE emission common to modification APIs", "output": "function modify(modifier, source, index, shift) {\n  if (\n    !this.isEnabled() &&\n    source === Emitter.sources.USER &&\n    !this.allowReadOnlyEdits\n  ) {\n    return new Delta();\n  }\n  let range = index == null ? null : this.getSelection();\n  const oldDelta = this.editor.delta;\n  const change = modifier();\n  if (range != null) {\n    if (index === true) {\n      index = range.index; // eslint-disable-line prefer-destructuring\n    }\n    if (shift == null) {\n      range = shiftRange(range, change, source);\n    } else if (shift !== 0) {\n      range = shiftRange(range, index, shift, source);\n    }\n    this.setSelection(range, Emitter.sources.SILENT);\n  }\n  if (change.length() > 0) {\n    const args = [Emitter.events.TEXT_CHANGE, change, oldDelta, source];\n    this.emitter.emit(Emitter.events.EDITOR_CHANGE, ...args);\n    if (source !== Emitter.sources.SILENT) {\n      this.emitter.emit(...args);\n    }\n  }\n  return change;\n}", "language": "javascript"}
{"input": "//////////////////////////////////////////////////////////////////// Wait for container to become ready", "output": "function tryConnect() {\n    if (!seleniumIP) {\n        process.nextTick(buildDriver);\n        return;\n    }\n    const sock = net.connect({\n        host: seleniumIP,\n        port: +seleniumPort,\n    });\n    sock.on(\"connect\", function() {\n        sock.end();\n        attempts = 0;\n        process.nextTick(buildDriver);\n    }).on(\"error\", function() {\n        if (++attempts > 50) {\n            throw new Error(\"Failed to connect selenium server.\");\n        }\n        setTimeout(tryConnect, 200);\n    });\n}", "language": "javascript"}
{"input": "Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.", "output": "def normalize_funcs(mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Callable,Callable]:\n    \"Create normalize/denormalize func using `mean` and `std`, can specify `do_y` and `device`.\"\n    mean,std = tensor(mean),tensor(std)\n    return (partial(_normalize_batch, mean=mean, std=std, do_x=do_x, do_y=do_y),\n            partial(denormalize,      mean=mean, std=std, do_x=do_x))", "language": "python"}
{"input": "Create the runtime initialization statements for a given requested source.\nThese will initialize all of the runtime import/export logic that\ncan't be handled statically by the statements created by\nbuildExportInitializationStatements().", "output": "function buildNamespaceInitStatements(meta, metadata, checkExport) {\n    const statements = [];\n    const {localImportName, localImportDefaultName} = getLocalImportName(metadata);\n\n    for (const exportName of metadata.reexportNamespace) {\n        // Assign export to namespace object.\n        checkExport(exportName);\n        statements.push(buildExport({exportName, localName: localImportName}));\n    }\n\n    // Source code:\n    //      import {color2 as color2Alias, color3, color4, color5} from 'xxx';\n    //      export {default as b} from 'xxx';\n    //      export {color2Alias};\n    //      export {color3};\n    //      let color5Renamed = color5\n    //      export {color5Renamed};\n    // Only two entries in metadata.reexports:\n    //      'color2Alias' => 'color2'\n    //      'color3' => 'color3',\n    //      'b' => 'default'\n    //\n    // And consider:\n    //      export {default as defaultAsBB} from './xx/yy';\n    //      export {exportSingle} from './xx/yy';\n    // No entries in metadata.imports, and 'default' exists in metadata.reexports.\n    for (const entry of metadata.reexports.entries()) {\n        const exportName = entry[0];\n        checkExport(exportName);\n        statements.push(\n            (localImportDefaultName || entry[1] === 'default')\n                ? buildExport({exportName, localName: localImportName})\n                : buildExport({exportName, namespace: localImportName, propName: entry[1]})\n        );\n    }\n\n    if (metadata.reexportAll) {\n        const statement = buildNamespaceReexport(\n            meta,\n            metadata.name,\n            checkExport\n        );\n        statement.loc = metadata.reexportAll.loc;\n\n        // Iterate props creating getter for each prop.\n        statements.push(statement);\n    }\n\n    return statements;\n}", "language": "javascript"}
{"input": "Get a human readable description of where node-sass is running to support\nuser error reporting when something goes wrong\n\n@param  {string} env - The name of the native bindings that is to be parsed\n@return {string} A description of what os, architecture, and Node version\nthat is being run\n\n@api public", "output": "function getHumanEnvironment(env) {\n  var binding = env.replace(/_binding\\.node$/, ''),\n    parts = binding.split('-'),\n    platform = getHumanPlatform(parts[0]),\n    arch = getHumanArchitecture(parts[1]),\n    runtime = getHumanNodeVersion(parts[2]);\n\n  if (parts.length !== 3) {\n    return 'Unknown environment (' + binding + ')';\n  }\n\n  if (!platform) {\n    platform = 'Unsupported platform (' + parts[0] + ')';\n  }\n\n  if (!arch) {\n    arch = 'Unsupported architecture (' + parts[1] + ')';\n  }\n\n  if (!runtime) {\n    runtime = 'Unsupported runtime (' + parts[2] + ')';\n  }\n\n  return [\n    platform, arch, 'with', runtime,\n  ].join(' ');\n}", "language": "javascript"}
{"input": "Removes the mark for an extension to be updated on restart. Also deletes the\ndownloaded package file.\n@param {string} id The id of the extension for which the update is being removed", "output": "function removeUpdate(id) {\n        var installationResult = _idsToUpdate[id];\n        if (!installationResult) {\n            return;\n        }\n        if (installationResult.localPath && !installationResult.keepFile) {\n            FileSystem.getFileForPath(installationResult.localPath).unlink();\n        }\n        delete _idsToUpdate[id];\n        exports.trigger(\"statusChange\", id);\n    }", "language": "javascript"}
{"input": "trigger loading of libraries and component preloads and collect the given promises", "output": "function(oPromise) {\n\t\t\t\t\t// In order to make the error handling of the Promise.all() happen after all Promises finish, we catch all rejected Promises and make them resolve with an marked object.\n\t\t\t\t\toPromise = oPromise.then(\n\t\t\t\t\t\tfunction(v) {\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tresult: v,\n\t\t\t\t\t\t\t\trejected: false\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\t},\n\t\t\t\t\t\tfunction(v) {\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tresult: v,\n\t\t\t\t\t\t\t\trejected: true\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\t}\n\t\t\t\t\t);\n\t\t\t\t\treturn oPromise;\n\t\t\t\t}", "language": "javascript"}
{"input": "Called when the user specifies an intent for this bot.", "output": "def dispatch(intent_request):\n    \"\"\"\n    Called when the user specifies an intent for this bot.\n    \"\"\"\n\n    logger.debug('dispatch userId={}, intentName={}'.format(intent_request['userId'], intent_request['currentIntent']['name']))\n\n    intent_name = intent_request['currentIntent']['name']\n\n    # Dispatch to your bot's intent handlers\n    if intent_name == 'OrderFlowers':\n        return order_flowers(intent_request)\n\n    raise Exception('Intent with name ' + intent_name + ' not supported')", "language": "python"}
{"input": "Sends a message to axe running in frames to start analysis and collate results (via `mergeResults`)\n@private\n@param  {Context}  context   The resolved Context object\n@param  {Object}   options   Options object (as passed to `runRules`)\n@param  {string}   command   Command sent to all frames\n@param  {Array}    parameter Array of values to be passed along side the command\n@param  {Function} callback  Function to call when results from all frames have returned", "output": "function collectResultsFromFrames(\n\tcontext,\n\toptions,\n\tcommand,\n\tparameter,\n\tresolve,\n\treject\n) {\n\t'use strict';\n\n\tvar q = axe.utils.queue();\n\tvar frames = context.frames;\n\n\t// Tell each axe running in each frame to collect results\n\tframes.forEach(function(frame) {\n\t\tvar params = {\n\t\t\toptions: options,\n\t\t\tcommand: command,\n\t\t\tparameter: parameter,\n\t\t\tcontext: {\n\t\t\t\tinitiator: false,\n\t\t\t\tpage: context.page,\n\t\t\t\tinclude: frame.include || [],\n\t\t\t\texclude: frame.exclude || []\n\t\t\t}\n\t\t};\n\n\t\tq.defer(function(res, rej) {\n\t\t\tvar node = frame.node;\n\t\t\taxe.utils.sendCommandToFrame(\n\t\t\t\tnode,\n\t\t\t\tparams,\n\t\t\t\tfunction(data) {\n\t\t\t\t\tif (data) {\n\t\t\t\t\t\treturn res({\n\t\t\t\t\t\t\tresults: data,\n\t\t\t\t\t\t\tframeElement: node,\n\t\t\t\t\t\t\tframe: axe.utils.getSelector(node)\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\tres(null);\n\t\t\t\t},\n\t\t\t\trej\n\t\t\t);\n\t\t});\n\t});\n\n\t// Combine results from all frames and give it back\n\tq.then(function(data) {\n\t\tresolve(axe.utils.mergeResults(data, options));\n\t}).catch(reject);\n}", "language": "javascript"}
{"input": "Returns a list of information about ID's for a single document. This array is populated\nby createIDList()\n@type {?Array.<FileLocation>}", "output": "function createIDList() {\n        var doc = DocumentManager.getCurrentDocument();\n        if (!doc) {\n            return;\n        }\n\n        var idList = [];\n        var docText = doc.getText();\n        var lines = docText.split(\"\\n\");\n\n        var regex = new RegExp(/\\s+id\\s*?=\\s*?[\"'](.*?)[\"']/gi);\n        var id, chFrom, chTo, i, line;\n        for (i = 0; i < lines.length; i++) {\n            line = lines[i];\n            var info;\n            while ((info = regex.exec(line)) !== null) {\n                id = info[1];\n                // TODO: this doesn't handle id's that share the\n                // same portion of a name on the same line or when\n                // the id and value are on different lines\n                chFrom = line.indexOf(id);\n                chTo = chFrom + id.length;\n                idList.push(new FileLocation(null, i, chFrom, chTo, id));\n            }\n        }\n        return idList;\n    }", "language": "javascript"}
{"input": "Instantiate a `OneCycleScheduler` with `lr_max`.", "output": "def one_cycle_scheduler(lr_max:float, **kwargs:Any)->OneCycleScheduler:\n    \"Instantiate a `OneCycleScheduler` with `lr_max`.\"\n    return partial(OneCycleScheduler, lr_max=lr_max, **kwargs)", "language": "python"}
{"input": "Adds sinusoids of diff frequencies to a Tensor, with timing position given.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    position: a Tensor with shape [batch, length]\n    min_timescale: a float\n    max_timescale: a float\n\n  Returns:\n    a Tensor the same shape as x.", "output": "def add_timing_signal_1d_given_position(x,\n                                        position,\n                                        min_timescale=1.0,\n                                        max_timescale=1.0e4):\n  \"\"\"Adds sinusoids of diff frequencies to a Tensor, with timing position given.\n\n  Args:\n    x: a Tensor with shape [batch, length, channels]\n    position: a Tensor with shape [batch, length]\n    min_timescale: a float\n    max_timescale: a float\n\n  Returns:\n    a Tensor the same shape as x.\n  \"\"\"\n  channels = common_layers.shape_list(x)[2]\n  num_timescales = channels // 2\n  log_timescale_increment = (\n      math.log(float(max_timescale) / float(min_timescale)) /\n      (tf.to_float(num_timescales) - 1))\n  inv_timescales = min_timescale * tf.exp(\n      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  scaled_time = (\n      tf.expand_dims(tf.to_float(position), 2) * tf.expand_dims(\n          tf.expand_dims(inv_timescales, 0), 0))\n  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=2)\n  signal = tf.pad(signal, [[0, 0], [0, 0], [0, tf.mod(channels, 2)]])\n  signal = common_layers.cast_like(signal, x)\n  return x + signal", "language": "python"}
{"input": "Copyright (c) 2006-2015, JGraph Ltd\nCopyright (c) 2006-2015, Gaudenz Alder\n \nClass: mxDragSource\n\nWrapper to create a drag source from a DOM element so that the element can\nbe dragged over a graph and dropped into the graph as a new cell.\n\nProblem is that in the dropHandler the current preview location is not\navailable, so the preview and the dropHandler must match.\n\nConstructor: mxDragSource\n\nConstructs a new drag source for the given element.", "output": "function mxDragSource(element, dropHandler)\n{\n\tthis.element = element;\n\tthis.dropHandler = dropHandler;\n\t\n\t// Handles a drag gesture on the element\n\tmxEvent.addGestureListeners(element, mxUtils.bind(this, function(evt)\n\t{\n\t\tthis.mouseDown(evt);\n\t}));\n\t\n\t// Prevents native drag and drop\n\tmxEvent.addListener(element, 'dragstart', function(evt)\n\t{\n\t\tmxEvent.consume(evt);\n\t});\n\t\n\tthis.eventConsumer = function(sender, evt)\n\t{\n\t\tvar evtName = evt.getProperty('eventName');\n\t\tvar me = evt.getProperty('event');\n\t\t\n\t\tif (evtName != mxEvent.MOUSE_DOWN)\n\t\t{\n\t\t\tme.consume();\n\t\t}\n\t};\n}", "language": "javascript"}
{"input": "/*\nDetermines the type of a node.\n@param {object} oNode A node\n@returns {object} A pseudo property with path, $Type (and poss. $v2Type) or undefined if\nthe type cannot be determined", "output": "function getType(oNode) {\n\t\t\tvar oPropertyMetadata;\n\n\t\t\tif (oNode.type) {\n\t\t\t\treturn {\n\t\t\t\t\t$Type : oNode.type\n\t\t\t\t};\n\t\t\t}\n\t\t\tif (oNode.id === \"PATH\") {\n\t\t\t\toPropertyMetadata = that.oModelInterface\n\t\t\t\t\t.fetchMetadata(sMetaPath + \"/\" + oNode.value).getResult();\n\t\t\t\tif (!oPropertyMetadata) {\n\t\t\t\t\tthrow new Error(\"Invalid filter path: \" + oNode.value);\n\t\t\t\t}\n\t\t\t\treturn {\n\t\t\t\t\tpath : oNode.value,\n\t\t\t\t\t$Type : oPropertyMetadata.$Type,\n\t\t\t\t\t$v2Type : oPropertyMetadata.$v2Type\n\t\t\t\t};\n\t\t\t}\n\t\t\t// oNode must have id \"FUNCTION\" and type undefined here. So it must be either ceiling,\n\t\t\t// floor or round and the return type is determined from the first and only parameter.\n\t\t\treturn getType(oNode.parameters[0]);\n\t\t}", "language": "javascript"}
{"input": "Simplifies the fold ranges into an array of pairs of numbers.\n@param {!Object} folds the raw fold ranges indexed by line numbers\n@return {Object} an object whose keys are line numbers and the values are array\nof two 2-element arrays. First array contains [from.line, from.ch] and the second contains [to.line, to.ch]", "output": "function simplify(folds) {\n        if (!folds) {\n            return;\n        }\n        var res = {}, range;\n        Object.keys(folds).forEach(function (line) {\n            range = folds[line];\n            res[line] = Array.isArray(range) ? range : [[range.from.line, range.from.ch], [range.to.line, range.to.ch]];\n        });\n        return res;\n    }", "language": "javascript"}
{"input": "Transform an option object to a command line string\n\n@param {String|number} value\n@param {String}", "output": "function escapeShellArg(value) {\n    if (is.number(value)) {\n        return value;\n    }\n\n    value = String(value);\n    value = value.replace(/\"/g, '\\\\\"');\n\n    return '\"' + value + '\"';\n}", "language": "javascript"}
{"input": "create/cache the indexables if they don't exist", "output": "def indexables(self):\n        \"\"\" create/cache the indexables if they don't exist \"\"\"\n        if self._indexables is None:\n\n            self._indexables = []\n\n            # index columns\n            self._indexables.extend([\n                IndexCol(name=name, axis=axis, pos=i)\n                for i, (axis, name) in enumerate(self.attrs.index_cols)\n            ])\n\n            # values columns\n            dc = set(self.data_columns)\n            base_pos = len(self._indexables)\n\n            def f(i, c):\n                klass = DataCol\n                if c in dc:\n                    klass = DataIndexableCol\n                return klass.create_for_block(i=i, name=c, pos=base_pos + i,\n                                              version=self.version)\n\n            self._indexables.extend(\n                [f(i, c) for i, c in enumerate(self.attrs.values_cols)])\n\n        return self._indexables", "language": "python"}
{"input": "Prepare encoder.\n\n  Args:\n    image_feat: a Tensor.\n    question: a Tensor.\n    hparams: run hyperparameters\n\n  Returns:\n    encoder_input: a Tensor, bottom of encoder stack\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention", "output": "def prepare_image_question_encoder(image_feat, question, hparams):\n  \"\"\"Prepare encoder.\n\n  Args:\n    image_feat: a Tensor.\n    question: a Tensor.\n    hparams: run hyperparameters\n\n  Returns:\n    encoder_input: a Tensor, bottom of encoder stack\n    encoder_self_attention_bias: a bias tensor for use in encoder self-attention\n  \"\"\"\n\n  encoder_input = tf.concat([image_feat, question], axis=1)\n  encoder_padding = common_attention.embedding_to_padding(encoder_input)\n  ignore_padding = common_attention.attention_bias_ignore_padding(\n      encoder_padding)\n  encoder_self_attention_bias = ignore_padding\n  encoder_decoder_attention_bias = ignore_padding\n  # Usual case - not a packed dataset.\n  if hparams.pos == \"timing\":\n    question = common_attention.add_timing_signal_1d(question)\n  elif hparams.pos == \"emb\":\n    question = common_attention.add_positional_embedding(\n        question, hparams.max_length, \"inputs_positional_embedding\",\n        None)\n  encoder_input = tf.concat([image_feat, question], axis=1)\n\n  return (encoder_input, encoder_self_attention_bias,\n          encoder_decoder_attention_bias)", "language": "python"}
{"input": "Load the \"config.gypi\" file that was generated during \"configure\".", "output": "function loadConfigGypi () {\n    var configPath = path.resolve('build', 'config.gypi')\n    fs.readFile(configPath, 'utf8', function (err, data) {\n      if (err) {\n        if (err.code == 'ENOENT') {\n          callback(new Error('You must run `node-gyp configure` first!'))\n        } else {\n          callback(err)\n        }\n        return\n      }\n      config = JSON.parse(data.replace(/\\#.+\\n/, ''))\n\n      // get the 'arch', 'buildType', and 'nodeDir' vars from the config\n      buildType = config.target_defaults.default_configuration\n      arch = config.variables.target_arch\n      nodeDir = config.variables.nodedir\n\n      if ('debug' in gyp.opts) {\n        buildType = gyp.opts.debug ? 'Debug' : 'Release'\n      }\n      if (!buildType) {\n        buildType = 'Release'\n      }\n\n      log.verbose('build type', buildType)\n      log.verbose('architecture', arch)\n      log.verbose('node dev dir', nodeDir)\n\n      if (win) {\n        findSolutionFile()\n      } else {\n        doWhich()\n      }\n    })\n  }", "language": "javascript"}
{"input": "Create a copy of this extension bound to another environment.", "output": "def bind(self, environment):\n        \"\"\"Create a copy of this extension bound to another environment.\"\"\"\n        rv = object.__new__(self.__class__)\n        rv.__dict__.update(self.__dict__)\n        rv.environment = environment\n        return rv", "language": "python"}
{"input": "bias_variable generates a bias variable of a given shape.", "output": "def bias_variable(shape):\n    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)", "language": "python"}
{"input": "/////////////////////////////////////// Hidden Functions /////////////////////////////////////////", "output": "function checkCozyMode(oRef) {\n\t\tif (!oRef) {\n\t\t\treturn false;\n\t\t}\n\t\toRef = oRef.$ ? oRef.$() : jQuery(oRef);\n\t\treturn oRef.closest(\".sapUiSizeCompact,.sapUiSizeCondensed,.sapUiSizeCozy\").hasClass(\"sapUiSizeCozy\");\n\t}", "language": "javascript"}
{"input": "Mimics empty from PHP.", "output": "function isEmpty(obj) {\n  if (Array.isArray(obj)) {\n    return obj.length === 0;\n  } else if (typeof obj === 'object') {\n    for (var i in obj) {\n      return false;\n    }\n    return true;\n  } else {\n    return !obj;\n  }\n}", "language": "javascript"}
{"input": "Load mnist dataset", "output": "def load_mnist(training_num=50000):\n    \"\"\"Load mnist dataset\"\"\"\n    data_path = os.path.join(os.path.dirname(os.path.realpath('__file__')), 'mnist.npz')\n    if not os.path.isfile(data_path):\n        from six.moves import urllib\n        origin = (\n            'https://github.com/sxjscience/mxnet/raw/master/example/bayesian-methods/mnist.npz'\n        )\n        print('Downloading data from %s to %s' % (origin, data_path))\n        ctx = ssl._create_unverified_context()\n        with urllib.request.urlopen(origin, context=ctx) as u, open(data_path, 'wb') as f:\n            f.write(u.read())\n        print('Done!')\n    dat = numpy.load(data_path)\n    X = (dat['X'][:training_num] / 126.0).astype('float32')\n    Y = dat['Y'][:training_num]\n    X_test = (dat['X_test'] / 126.0).astype('float32')\n    Y_test = dat['Y_test']\n    Y = Y.reshape((Y.shape[0],))\n    Y_test = Y_test.reshape((Y_test.shape[0],))\n    return X, Y, X_test, Y_test", "language": "python"}
{"input": "Returns the specified table as a :class:`DataFrame`.\n\n        :return: :class:`DataFrame`\n\n        >>> df.createOrReplaceTempView(\"table1\")\n        >>> df2 = spark.table(\"table1\")\n        >>> sorted(df.collect()) == sorted(df2.collect())\n        True", "output": "def table(self, tableName):\n        \"\"\"Returns the specified table as a :class:`DataFrame`.\n\n        :return: :class:`DataFrame`\n\n        >>> df.createOrReplaceTempView(\"table1\")\n        >>> df2 = spark.table(\"table1\")\n        >>> sorted(df.collect()) == sorted(df2.collect())\n        True\n        \"\"\"\n        return DataFrame(self._jsparkSession.table(tableName), self._wrapped)", "language": "python"}
{"input": "\u8bd5\u56fe\u6539\u53d8 active \u72b6\u6001", "output": "function (e) {\n        const editor = this.editor\n        const $elem = this.$elem\n        if (editor.cmd.queryCommandState('italic')) {\n            this._active = true\n            $elem.addClass('w-e-active')\n        } else {\n            this._active = false\n            $elem.removeClass('w-e-active')\n        }\n    }", "language": "javascript"}
{"input": "Attaches the router to the hash changer @see sap.ui.core.routing.HashChanger\n\n@param {boolean} [bIgnoreInitialHash=false] @since 1.48.0 whether the current url hash shouldn't be parsed after the router is initialized\n@public\n@returns {sap.ui.core.routing.Router} this for chaining.", "output": "function (bIgnoreInitialHash) {\n\t\t\t\tvar that = this;\n\n\t\t\t\tif (!this.oHashChanger) {\n\t\t\t\t\tthis.oHashChanger = HashChanger.getInstance().createRouterHashChanger();\n\t\t\t\t}\n\n\t\t\t\tif (this._bIsInitialized) {\n\t\t\t\t\tLog.warning(\"Router is already initialized.\", this);\n\t\t\t\t\treturn this;\n\t\t\t\t}\n\n\t\t\t\tthis._bIsInitialized = true;\n\n\t\t\t\tthis._bLastHashReplaced = false;\n\t\t\t\tthis._bHashChangedAfterTitleChange = false;\n\n\t\t\t\tthis.fnHashChanged = function(oEvent) {\n\t\t\t\t\tthat.parse(oEvent.getParameter(\"newHash\"));\n\t\t\t\t\tthat._bHashChangedAfterTitleChange = true;\n\t\t\t\t};\n\n\t\t\t\tif (!this.oHashChanger) {\n\t\t\t\t\tLog.error(\"navTo of the router is called before the router is initialized. If you want to replace the current hash before you initialize the router you may use getUrl and use replaceHash of the Hashchanger.\", this);\n\t\t\t\t\treturn this;\n\t\t\t\t}\n\n\t\t\t\tif (this._oTargets) {\n\t\t\t\t\tvar oHomeRoute = this._oRoutes[this._oConfig.homeRoute];\n\n\t\t\t\t\tthis._oTargets.attachTitleChanged(function(oEvent) {\n\n\t\t\t\t\t\tvar oEventParameters = oEvent.getParameters();\n\n\t\t\t\t\t\tif (oHomeRoute && isHomeRouteTarget(oEventParameters.name, oHomeRoute._oConfig.name)) {\n\t\t\t\t\t\t\toEventParameters.isHome = true;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tthis.fireTitleChanged(oEventParameters);\n\n\t\t\t\t\t}, this);\n\n\t\t\t\t\tthis._aHistory = [];\n\n\t\t\t\t\t// Add the initial home route entry to history\n\t\t\t\t\tvar oHomeRouteEntry = oHomeRoute && getHomeEntry(this._oOwner, oHomeRoute);\n\t\t\t\t\tif (oHomeRouteEntry) {\n\t\t\t\t\t\tthis._aHistory.push(oHomeRouteEntry);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tthis.oHashChanger.init();\n\n\t\t\t\t// initialized because whether the current hash is parsed is\n\t\t\t\t// controlled by the 'bSuppressHashParsing' parameter and the\n\t\t\t\t// 'hashchanged' event which may be fired from hashChanger.init()\n\t\t\t\t// shouldn't be processed.\n\t\t\t\tthis.oHashChanger.attachEvent(\"hashChanged\", this.fnHashChanged);\n\n\t\t\t\tif (!bIgnoreInitialHash) {\n\t\t\t\t\tthis.parse(this.oHashChanger.getHash());\n\t\t\t\t}\n\n\t\t\t\treturn this;\n\t\t\t}", "language": "javascript"}
{"input": "parses the trained .caffemodel file\n\n    filepath: /path/to/trained-model.caffemodel\n\n    returns: layers", "output": "def parse_caffemodel(file_path):\n    \"\"\"\n    parses the trained .caffemodel file\n\n    filepath: /path/to/trained-model.caffemodel\n\n    returns: layers\n    \"\"\"\n    f = open(file_path, 'rb')\n    contents = f.read()\n\n    net_param = caffe_pb2.NetParameter()\n    net_param.ParseFromString(contents)\n\n    layers = find_layers(net_param)\n    return layers", "language": "python"}
{"input": "Destroy a driver", "output": "def destroy_webdriver(driver):\n    \"\"\"\n    Destroy a driver\n    \"\"\"\n\n    # This is some very flaky code in selenium. Hence the retries\n    # and catch-all exceptions\n    try:\n        retry_call(driver.close, tries=2)\n    except Exception:\n        pass\n    try:\n        driver.quit()\n    except Exception:\n        pass", "language": "python"}
{"input": "Extract key/value pairs from an object and encode them for\nuse in a query string", "output": "function urlencode(obj) {\n  var pairs = [];\n  for (var key in obj) {\n    if ({}.hasOwnProperty.call(obj, key))\n      pairs.push(encodeURIComponent(key) + '=' + encodeURIComponent(obj[key]));\n  }\n  return pairs.join('&');\n}", "language": "javascript"}
{"input": "NOTE: Before using this API, you need to do a few things.\n1. Create a new Pub/Sub topic.  You can use the command:\ngcloud pubsub topics create gmail\n2. Go to the Cloud Developer Console, and give the gmail\nservice account gmail-api-push@system.gserviceaccount.com\nPub/Sub Publisher rights to your newly created topic.\nhttps://console.cloud.google.com/cloudpubsub/topicList?project=${PROJECT_NAME}", "output": "async function runSample() {\n  const res = await gmail.users.watch({\n    userId: 'me',\n    requestBody: {\n      // Replace with `projects/${PROJECT_ID}/topics/${TOPIC_NAME}`\n      topicName: `projects/el-gato/topics/gmail`,\n    },\n  });\n  console.log(res.data);\n  return res.data;\n}", "language": "javascript"}
{"input": "onStart sets up a new state for the handler, which includes options from the nearest registered parent element of ev.target.", "output": "function (ev, pointer) {\n      if (this.state.isRunning) return;\n      var parentTarget = this.getNearestParent(ev.target);\n      // Get the options from the nearest registered parent\n      var parentTargetOptions = parentTarget && parentTarget.$mdGesture[this.name] || {};\n\n      this.state = {\n        isRunning: true,\n        // Override the default options with the nearest registered parent's options\n        options: angular.extend({}, this.options, parentTargetOptions),\n        // Pass in the registered parent node to the state so the onStart listener can use\n        registeredParent: parentTarget\n      };\n      this.onStart(ev, pointer);\n    }", "language": "javascript"}
{"input": "/* =========================================================== /* begin: internal methods\t\t\t\t\t\t\t\t\t   aa /* ===========================================================", "output": "function(sEntityType, sEntityId, bShouldStoreToHistory) {\n\t\t\t\tthis._oRouter.stop();\n\t\t\t\tthis._oRouter.navTo(\"apiId\", {\n\t\t\t\t\tid: encodeURIComponent(this._sTopicId),\n\t\t\t\t\tentityType: sEntityType,\n\t\t\t\t\tentityId: encodeURIComponent(sEntityId)\n\t\t\t\t}, !bShouldStoreToHistory);\n\t\t\t\tthis._oRouter.initialize(true);\n\t\t\t}", "language": "javascript"}
{"input": "Get the crop box position and size data.\n@returns {Object} The result crop box data.", "output": "function getCropBoxData() {\n    var cropBoxData = this.cropBoxData;\n\n    var data = void 0;\n\n    if (this.ready && this.cropped) {\n      data = {\n        left: cropBoxData.left,\n        top: cropBoxData.top,\n        width: cropBoxData.width,\n        height: cropBoxData.height\n      };\n    }\n\n    return data || {};\n  }", "language": "javascript"}
{"input": "Add column to after the current cell\n@param {jQuery} $cell - jQuery wrapped table cell\n@param {number} [numberOfCols=1] - number of cols\n@ignore", "output": "function addColToCellAfter($cell, numberOfCols = 1) {\n  const index = $cell.index();\n  let cellToAdd;\n\n  $cell.parents('table').find('tr').each((n, tr) => {\n    const isTBody = domUtils.getNodeName(tr.parentNode) === 'TBODY';\n    const isMSIE = util.browser.msie;\n    const cell = tr.children[index];\n    for (let i = 0; i < numberOfCols; i += 1) {\n      if (isTBody) {\n        cellToAdd = document.createElement('td');\n      } else {\n        cellToAdd = document.createElement('th');\n      }\n      if (!isMSIE) {\n        cellToAdd.appendChild(document.createElement('br'));\n      }\n      $(cellToAdd).insertAfter(cell);\n    }\n  });\n}", "language": "javascript"}
{"input": "Make table head align text.\nCopy from https://github.com/nhn/to-mark/blob/develop/src/renderer.gfm.js\n@param {HTMLElement} thElement - Table head cell element\n@returns {string}\n@private", "output": "function _makeTableHeadAlignText(thElement) {\n  const {align} = thElement;\n  const textContent = (thElement.textContent || thElement.innerText).replace(RX_COLS, '');\n  let textLength = textContent.length;\n  let leftAlignValue = '';\n  let rightAlignValue = '';\n\n  if (align) {\n    if (align === 'left') {\n      leftAlignValue = ':';\n      textLength -= 1;\n    } else if (align === 'right') {\n      rightAlignValue = ':';\n      textLength -= 1;\n    } else if (align === 'center') {\n      rightAlignValue = ':';\n      leftAlignValue = ':';\n      textLength -= 2;\n    }\n  }\n\n  textLength = Math.max(textLength, 3);\n\n  return leftAlignValue + _createRepeatString('-', textLength) + rightAlignValue;\n}", "language": "javascript"}
{"input": "Recent activity (actions) for a given user", "output": "def recent_activity(self, user_id):\n        \"\"\"Recent activity (actions) for a given user\"\"\"\n        M = models  # noqa\n\n        if request.args.get('limit'):\n            limit = int(request.args.get('limit'))\n        else:\n            limit = 1000\n\n        qry = (\n            db.session.query(M.Log, M.Dashboard, M.Slice)\n            .outerjoin(\n                M.Dashboard,\n                M.Dashboard.id == M.Log.dashboard_id,\n            )\n            .outerjoin(\n                M.Slice,\n                M.Slice.id == M.Log.slice_id,\n            )\n            .filter(\n                sqla.and_(\n                    ~M.Log.action.in_(('queries', 'shortner', 'sql_json')),\n                    M.Log.user_id == user_id,\n                ),\n            )\n            .order_by(M.Log.dttm.desc())\n            .limit(limit)\n        )\n        payload = []\n        for log in qry.all():\n            item_url = None\n            item_title = None\n            if log.Dashboard:\n                item_url = log.Dashboard.url\n                item_title = log.Dashboard.dashboard_title\n            elif log.Slice:\n                item_url = log.Slice.slice_url\n                item_title = log.Slice.slice_name\n\n            payload.append({\n                'action': log.Log.action,\n                'item_url': item_url,\n                'item_title': item_title,\n                'time': log.Log.dttm,\n            })\n        return json_success(\n            json.dumps(payload, default=utils.json_int_dttm_ser))", "language": "python"}
{"input": "Starts trial and restores last result if trial was paused.\n\n        Raises:\n            ValueError if restoring from checkpoint fails.", "output": "def _start_trial(self, trial, checkpoint=None):\n        \"\"\"Starts trial and restores last result if trial was paused.\n\n        Raises:\n            ValueError if restoring from checkpoint fails.\n        \"\"\"\n        prior_status = trial.status\n        self.set_status(trial, Trial.RUNNING)\n        trial.runner = self._setup_runner(\n            trial,\n            reuse_allowed=checkpoint is not None\n            or trial._checkpoint.value is not None)\n        if not self.restore(trial, checkpoint):\n            if trial.status == Trial.ERROR:\n                raise RuntimeError(\n                    \"Restore from checkpoint failed for Trial {}.\".format(\n                        str(trial)))\n\n        previous_run = self._find_item(self._paused, trial)\n        if (prior_status == Trial.PAUSED and previous_run):\n            # If Trial was in flight when paused, self._paused stores result.\n            self._paused.pop(previous_run[0])\n            self._running[previous_run[0]] = trial\n        else:\n            self._train(trial)", "language": "python"}
{"input": "Reports the given messageId for the given node. The location will be the start of the property or the callee.\n@param {ASTNode} node CallExpression or NewExpression node.\n@param {string} messageId The messageId to report.\n@returns {void}", "output": "function report(node, messageId) {\n            let callee = node.callee;\n\n            if (callee.type === \"MemberExpression\") {\n                callee = callee.property;\n            }\n\n            context.report({ node, loc: callee.loc.start, messageId });\n        }", "language": "javascript"}
{"input": "Shuffle and batch the given dataset.", "output": "def shuffle_and_batch_data(dataset, target_names, features_info, training):\n  \"\"\"Shuffle and batch the given dataset.\"\"\"\n  def append_targets(example):\n    \"\"\"Append targets to the example dictionary. Needed for Keras.\"\"\"\n    if len(target_names) == 1:\n      return (example, example[target_names[0]])\n    targets = {}\n    for name in target_names:\n      targets[name] = example[name]\n    return (example, targets)\n  dataset = dataset.map(append_targets)\n  if training:\n    dataset = dataset.repeat()\n  shapes = {k: features_info[k].shape for k in features_info}\n  shapes = (shapes, shapes[target_names[0]])\n  dataset = dataset.shuffle(128)\n  dataset = preprocess_fn(dataset, training)\n  dataset = batch_fn(dataset, training, shapes, target_names)\n  return dataset.prefetch(8)", "language": "python"}
{"input": "Update Time (x-axis) and Progression (y-axis) data for mouse position\n\n@param {Element} canvas <canvas> element\n@param {number} x Horizontal position\n@param {number} y Vertical position", "output": "function updateTimeProgression(curve, x, y) {\n        var percentX = Math.round(100 * x / WIDTH_MAIN),\n            percentY = Math.round(100 * ((HEIGHT_MAIN - y) / HEIGHT_MAIN));\n\n        // Constrain horizontal percentage to [0, 100] range\n        percentX = Math.min(Math.max(0, percentX), 100);\n\n        curve.parentNode.setAttribute(\"data-time\", percentX);\n        curve.parentNode.setAttribute(\"data-progression\", percentY);\n    }", "language": "javascript"}
{"input": "touchingIsIntersecting determines whether this method considers a node that borders a range intersects with it (as in WebKit) or not (as in Gecko pre-1.9, and the default)", "output": "function(node, touchingIsIntersecting) {\n                assertRangeValid(this);\n                assertNode(node, \"NOT_FOUND_ERR\");\n                if (getDocument(node) !== getRangeDocument(this)) {\n                    return false;\n                }\n\n                var parent = node.parentNode, offset = getNodeIndex(node);\n                assertNode(parent, \"NOT_FOUND_ERR\");\n\n                var startComparison = comparePoints(parent, offset, this.endContainer, this.endOffset),\n                    endComparison = comparePoints(parent, offset + 1, this.startContainer, this.startOffset);\n\n                return touchingIsIntersecting ? startComparison <= 0 && endComparison >= 0 : startComparison < 0 && endComparison > 0;\n            }", "language": "javascript"}
{"input": "Simple undiscretization from vector quantized representation.", "output": "def vq_discrete_unbottleneck(x, hparams):\n  \"\"\"Simple undiscretization from vector quantized representation.\"\"\"\n  x_shape = common_layers.shape_list(x)\n  bottleneck_size = 2**hparams.bottleneck_bits\n  means = hparams.means\n  x_flat = tf.reshape(x, [-1, bottleneck_size])\n  result = tf.matmul(x_flat, means)\n  result = tf.reshape(result, x_shape[:-1] + [hparams.hidden_size])\n  return result", "language": "python"}
{"input": "PrivateFunction: _onIdle\n_Private_ function called by Strophe.Connection._onIdle\n\nsends all queued stanzas", "output": "function () {\r\n        var data = this._conn._data;\r\n        if (data.length > 0 && !this._conn.paused) {\r\n            for (var i = 0; i < data.length; i++) {\r\n                if (data[i] !== null) {\r\n                    var stanza, rawStanza;\r\n                    if (data[i] === \"restart\") {\r\n                        stanza = this._buildStream().tree();\r\n                    } else {\r\n                        stanza = data[i];\r\n                    }\r\n                    rawStanza = Strophe.serialize(stanza);\r\n                    this._conn.xmlOutput(stanza);\r\n                    this._conn.rawOutput(rawStanza);\r\n                    this.socket.send(rawStanza);\r\n                }\r\n            }\r\n            this._conn._data = [];\r\n        }\r\n    }", "language": "javascript"}
{"input": "Writes batch images of specified DatasetType to Tensorboard.", "output": "def _write_for_dstype(self, learn:Learner, batch:Tuple, iteration:int, tbwriter:SummaryWriter, ds_type:DatasetType)->None:\n        \"Writes batch images of specified DatasetType to Tensorboard.\"\n        request = ImageTBRequest(learn=learn, batch=batch, iteration=iteration, tbwriter=tbwriter, ds_type=ds_type)\n        asyncTBWriter.request_write(request)", "language": "python"}
{"input": "Return the URL without the query string\n@param {string} URL", "output": "function _urlWithoutQueryString(url) {\n        var index = url.search(/[#\\?]/);\n        if (index >= 0) {\n            url = url.substr(0, index);\n        }\n        return url;\n    }", "language": "javascript"}
{"input": "Generate TypeScript.", "output": "async function run() {\n  console.log(`\\u{1f52c}  Searching for modules inside \"${chalk.dim(SRC_DIR)}\".`);\n  const files = glob.sync('!(index)*.js', { cwd: SRC_DIR });\n  const typings = files.map(file => createIconTyping(file));\n  await Promise.all([...typings, createIndexTyping(files)]);\n  console.log(`\\u{1F5C4}  Written typings to ${chalk.dim(TARGET_DIR)}.`);\n}", "language": "javascript"}
{"input": "Show `show_doc` info in preview window along with link to full docs.", "output": "def doc(elt):\n    \"Show `show_doc` info in preview window along with link to full docs.\"\n    global use_relative_links\n    use_relative_links = False\n    elt = getattr(elt, '__func__', elt)\n    md = show_doc(elt, markdown=False)\n    if is_fastai_class(elt):\n        md += f'\\n\\n<a href=\"{get_fn_link(elt)}\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a>'\n    output = HTMLExporter().markdown2html(md)\n    use_relative_links = True\n    if IS_IN_COLAB: get_ipython().run_cell_magic(u'html', u'', output)\n    else:\n        try: page.page({'text/html': output})\n        except: display(Markdown(md))", "language": "python"}
{"input": "Helper to determine the shape of reorder output.", "output": "def _reorder_shape(input_shape, output=None):  # pylint: disable=invalid-name\n  \"\"\"Helper to determine the shape of reorder output.\"\"\"\n  if output is None:\n    return input_shape\n  return base.nested_map(output, lambda i: input_shape[i])", "language": "python"}
{"input": "Create a pipeline component from a factory.\n\n        name (unicode): Factory name to look up in `Language.factories`.\n        config (dict): Configuration parameters to initialise component.\n        RETURNS (callable): Pipeline component.\n\n        DOCS: https://spacy.io/api/language#create_pipe", "output": "def create_pipe(self, name, config=dict()):\n        \"\"\"Create a pipeline component from a factory.\n\n        name (unicode): Factory name to look up in `Language.factories`.\n        config (dict): Configuration parameters to initialise component.\n        RETURNS (callable): Pipeline component.\n\n        DOCS: https://spacy.io/api/language#create_pipe\n        \"\"\"\n        if name not in self.factories:\n            if name == \"sbd\":\n                raise KeyError(Errors.E108.format(name=name))\n            else:\n                raise KeyError(Errors.E002.format(name=name))\n        factory = self.factories[name]\n        return factory(self, **config)", "language": "python"}
{"input": "Function: replacePlaceholders\n\nReplaces the given placeholders with the given parameters.\n\nParameters:\n\nvalue - String that contains the placeholders.\nparams - Array of the values for the placeholders of the form {1}...{n}\nto be replaced with in the resulting string.", "output": "function(value, params)\n\t{\n\t\tvar result = [];\n\t\tvar index = null;\n\t\t\n\t\tfor (var i = 0; i < value.length; i++)\n\t\t{\n\t\t\tvar c = value.charAt(i);\n\n\t\t\tif (c == '{')\n\t\t\t{\n\t\t\t\tindex = '';\n\t\t\t}\n\t\t\telse if (index != null && \tc == '}')\n\t\t\t{\n\t\t\t\tindex = parseInt(index)-1;\n\t\t\t\t\n\t\t\t\tif (index >= 0 && index < params.length)\n\t\t\t\t{\n\t\t\t\t\tresult.push(params[index]);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tindex = null;\n\t\t\t}\n\t\t\telse if (index != null)\n\t\t\t{\n\t\t\t\tindex += c;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tresult.push(c);\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn result.join('');\n\t}", "language": "javascript"}
{"input": "Convert Matrix attributes which are array-like or buffer to array.", "output": "def _convert_to_array(array_like, dtype):\n        \"\"\"\n        Convert Matrix attributes which are array-like or buffer to array.\n        \"\"\"\n        if isinstance(array_like, bytes):\n            return np.frombuffer(array_like, dtype=dtype)\n        return np.asarray(array_like, dtype=dtype)", "language": "python"}
{"input": "Parses an \"Edm.TimeOfDay\" value and returns the corresponding JavaScript\n<code>Date</code> value (UTC with a date value of \"1970-01-01\").\n\n@param {string} sTimeOfDay\nThe \"Edm.TimeOfDay\" value to parse\n@returns {Date}\nThe JavaScript <code>Date</code> value\n@throws {Error}\nIf the input cannot be parsed\n\n@public\n@since 1.43.0", "output": "function (sTimeOfDay) {\n\t\t\t\tvar oTimeOfDay;\n\n\t\t\t\tif (rTimeOfDay.test(sTimeOfDay)) {\n\t\t\t\t\tif (sTimeOfDay.length > 12) {\n\t\t\t\t\t\t// \"round\" to millis: \"HH:mm:ss.SSS\"\n\t\t\t\t\t\tsTimeOfDay = sTimeOfDay.slice(0, 12);\n\t\t\t\t\t}\n\t\t\t\t\toTimeOfDay =  DateFormat.getTimeInstance({\n\t\t\t\t\t\tpattern : \"HH:mm:ss.SSS\",\n\t\t\t\t\t\tstrictParsing : true,\n\t\t\t\t\t\tUTC : true\n\t\t\t\t\t}).parse(sTimeOfDay);\n\t\t\t\t}\n\t\t\t\tif (!oTimeOfDay) {\n\t\t\t\t\tthrow new Error(\"Not a valid Edm.TimeOfDay value: \" + sTimeOfDay);\n\t\t\t\t}\n\t\t\t\treturn oTimeOfDay;\n\t\t\t}", "language": "javascript"}
{"input": "Wrapper for data-dependent initialization.", "output": "def get_variable_ddi(name, shape, initial_value, dtype=tf.float32, init=False,\n                     trainable=True):\n  \"\"\"Wrapper for data-dependent initialization.\"\"\"\n  # If init is a tf bool: w is assigned dynamically at runtime.\n  # If init is a python bool: then w is determined during graph construction.\n  w = tf.get_variable(name, shape, dtype, None, trainable=trainable)\n  if isinstance(init, bool):\n    if init:\n      return assign(w, initial_value)\n    return w\n  else:\n    return tf.cond(init, lambda: assign(w, initial_value), lambda: w)", "language": "python"}
{"input": "Tied means fine-tune CNN/DM summarization as LM.", "output": "def transformer_tall_finetune_tied():\n  \"\"\"Tied means fine-tune CNN/DM summarization as LM.\"\"\"\n  hparams = transformer_tall()\n  hparams.multiproblem_max_input_length = 750\n  hparams.multiproblem_max_target_length = 100\n  hparams.multiproblem_schedule_max_examples = 0\n  hparams.learning_rate_schedule = (\"linear_warmup*constant*cosdecay\")\n  hparams.learning_rate_constant = 5e-5\n  hparams.learning_rate_warmup_steps = 100\n  # Set train steps to learning_rate_decay_steps or less\n  hparams.learning_rate_decay_steps = 80000\n  hparams.multiproblem_target_eval_only = True\n  hparams.multiproblem_reweight_label_loss = True\n  hparams.multiproblem_label_weight = 1.0\n  hparams.optimizer = \"true_adam\"\n  return hparams", "language": "python"}
{"input": "Save the tokenizer vocabulary to a directory or file.", "output": "def save_vocabulary(self, vocab_path):\n        \"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"\n        index = 0\n        if os.path.isdir(vocab_path):\n            vocab_file = os.path.join(vocab_path, VOCAB_NAME)\n        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n            for token, token_index in sorted(self.vocab.items(), key=lambda kv: kv[1]):\n                if index != token_index:\n                    logger.warning(\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n                                   \" Please check that the vocabulary is not corrupted!\".format(vocab_file))\n                    index = token_index\n                writer.write(token + u'\\n')\n                index += 1\n        return vocab_file", "language": "python"}
{"input": "Creates groups of properties.\n@param  {ASTNode} node ObjectExpression node being evaluated.\n@returns {Array.<ASTNode[]>} Groups of property AST node lists.", "output": "function createGroups(node) {\n            if (node.properties.length === 1) {\n                return [node.properties];\n            }\n\n            return node.properties.reduce((groups, property) => {\n                const currentGroup = last(groups),\n                    prev = last(currentGroup);\n\n                if (!prev || continuesPropertyGroup(prev, property)) {\n                    currentGroup.push(property);\n                } else {\n                    groups.push([property]);\n                }\n\n                return groups;\n            }, [\n                []\n            ]);\n        }", "language": "javascript"}
{"input": "Conform input DataFrame to align with chosen axis pair.\n\n        Parameters\n        ----------\n        frame : DataFrame\n        axis : {'items', 'major', 'minor'}\n\n            Axis the input corresponds to. E.g., if axis='major', then\n            the frame's columns would be items, and the index would be\n            values of the minor axis\n\n        Returns\n        -------\n        DataFrame", "output": "def conform(self, frame, axis='items'):\n        \"\"\"\n        Conform input DataFrame to align with chosen axis pair.\n\n        Parameters\n        ----------\n        frame : DataFrame\n        axis : {'items', 'major', 'minor'}\n\n            Axis the input corresponds to. E.g., if axis='major', then\n            the frame's columns would be items, and the index would be\n            values of the minor axis\n\n        Returns\n        -------\n        DataFrame\n        \"\"\"\n        axes = self._get_plane_axes(axis)\n        return frame.reindex(**self._extract_axes_for_slice(self, axes))", "language": "python"}
{"input": "Enable or disable all inspection.\n@param {?boolean} enabled Enabled state. If omitted, the state is toggled.\n@param {?boolean} doNotSave true if the preference should not be saved to user settings. This is generally for events triggered by project-level settings.", "output": "function toggleEnabled(enabled, doNotSave) {\n        if (enabled === undefined) {\n            enabled = !_enabled;\n        }\n\n        // Take no action when there is no change.\n        if (enabled === _enabled) {\n            return;\n        }\n\n        _enabled = enabled;\n\n        CommandManager.get(Commands.VIEW_TOGGLE_INSPECTION).setChecked(_enabled);\n        updateListeners();\n        if (!doNotSave) {\n            prefs.set(PREF_ENABLED, _enabled);\n            prefs.save();\n        }\n\n        // run immediately\n        run();\n    }", "language": "javascript"}
{"input": "for backwards compatibility", "output": "function batchData(map) {\n    var cy = this;\n    return this.batch(function () {\n      var ids = Object.keys(map);\n\n      for (var i = 0; i < ids.length; i++) {\n        var id = ids[i];\n        var data = map[id];\n        var ele = cy.getElementById(id);\n        ele.data(data);\n      }\n    });\n  }", "language": "javascript"}
{"input": "common agg/transform wrapping logic", "output": "def _wrap_output(self, output, index, names=None):\n        \"\"\" common agg/transform wrapping logic \"\"\"\n        output = output[self._selection_name]\n\n        if names is not None:\n            return DataFrame(output, index=index, columns=names)\n        else:\n            name = self._selection_name\n            if name is None:\n                name = self._selected_obj.name\n            return Series(output, index=index, name=name)", "language": "python"}
{"input": "When the user double clicks, we will select this file and add it to the working\nset (via the `selectInWorkingSet` action.)", "output": "function () {\n            if (!this.props.entry.get(\"rename\")) {\n                if (this.state.clickTimer !== null) {\n                    this.clearTimer();\n                }\n                this.props.actions.selectInWorkingSet(this.myPath());\n            }\n        }", "language": "javascript"}
{"input": "Apply layer preprocessing.\n\n  See layer_prepostprocess() for details.\n\n  A hyperparameters object is passed for convenience.  The hyperparameters\n  that may be used are:\n\n    layer_preprocess_sequence\n    layer_prepostprocess_dropout\n    norm_type\n    hidden_size\n    norm_epsilon\n\n  Args:\n    layer_input: a Tensor\n    hparams: a hyperparameters object.\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    a Tensor", "output": "def layer_preprocess(layer_input, hparams, layer_collection=None):\n  \"\"\"Apply layer preprocessing.\n\n  See layer_prepostprocess() for details.\n\n  A hyperparameters object is passed for convenience.  The hyperparameters\n  that may be used are:\n\n    layer_preprocess_sequence\n    layer_prepostprocess_dropout\n    norm_type\n    hidden_size\n    norm_epsilon\n\n  Args:\n    layer_input: a Tensor\n    hparams: a hyperparameters object.\n    layer_collection: A tensorflow_kfac.LayerCollection. Only used by the\n      KFAC optimizer. Default is None.\n\n  Returns:\n    a Tensor\n  \"\"\"\n  assert \"a\" not in hparams.layer_preprocess_sequence, (\n      \"No residual connections allowed in hparams.layer_preprocess_sequence\")\n  assert \"z\" not in hparams.layer_preprocess_sequence, (\n      \"No residual connections allowed in hparams.layer_preprocess_sequence\")\n  return layer_prepostprocess(\n      None,\n      layer_input,\n      sequence=hparams.layer_preprocess_sequence,\n      dropout_rate=hparams.layer_prepostprocess_dropout,\n      norm_type=hparams.norm_type,\n      depth=None,\n      epsilon=hparams.norm_epsilon,\n      dropout_broadcast_dims=comma_separated_string_to_integer_list(\n          getattr(hparams, \"layer_prepostprocess_dropout_broadcast_dims\", \"\")),\n      default_name=\"layer_prepostprocess\",\n      layer_collection=layer_collection)", "language": "python"}
{"input": "Max ROI Pooling.", "output": "def max_roi_pooling(attrs, inputs, proto_obj):\n    \"\"\"Max ROI Pooling.\"\"\"\n    new_attrs = translation_utils._fix_attribute_names(attrs,\n                                                       {'pooled_shape': 'pooled_size',\n                                                        'spatial_scale': 'spatial_scale'\n                                                       })\n    return 'ROIPooling', new_attrs, inputs", "language": "python"}
{"input": "Convert to dense DataFrame\n\n        Returns\n        -------\n        df : DataFrame", "output": "def to_dense(self):\n        \"\"\"\n        Convert to dense DataFrame\n\n        Returns\n        -------\n        df : DataFrame\n        \"\"\"\n        data = {k: v.to_dense() for k, v in self.items()}\n        return DataFrame(data, index=self.index, columns=self.columns)", "language": "python"}
{"input": "Gathers the snap and wrap elements", "output": "function gatherSnapWrap() {\n    var element;\n    var value;\n    for (element = $element; element.length; element = element.parent()) {\n      value = element.attr('md-autocomplete-snap');\n      if (angular.isDefined(value)) break;\n    }\n\n    if (element.length) {\n      return {\n        snap: element[0],\n        wrap: (value.toLowerCase() === 'width') ? element[0] : $element.find('md-autocomplete-wrap')[0]\n      };\n    }\n\n    var wrap = $element.find('md-autocomplete-wrap')[0];\n    return {\n      snap: wrap,\n      wrap: wrap\n    };\n  }", "language": "javascript"}
{"input": "------------------------------------------------------------------------------ Helpers ------------------------------------------------------------------------------ \nGets the containing loop node of a specified node.\n\nWe don't need to check nested functions, so this ignores those.\n`Scope.through` contains references of nested functions.\n\n@param {ASTNode} node - An AST node to get.\n@returns {ASTNode|null} The containing loop node of the specified node, or\n`null`.", "output": "function getContainingLoopNode(node) {\n    for (let currentNode = node; currentNode.parent; currentNode = currentNode.parent) {\n        const parent = currentNode.parent;\n\n        switch (parent.type) {\n            case \"WhileStatement\":\n            case \"DoWhileStatement\":\n                return parent;\n\n            case \"ForStatement\":\n\n                // `init` is outside of the loop.\n                if (parent.init !== currentNode) {\n                    return parent;\n                }\n                break;\n\n            case \"ForInStatement\":\n            case \"ForOfStatement\":\n\n                // `right` is outside of the loop.\n                if (parent.right !== currentNode) {\n                    return parent;\n                }\n                break;\n\n            case \"ArrowFunctionExpression\":\n            case \"FunctionExpression\":\n            case \"FunctionDeclaration\":\n\n                // We don't need to check nested functions.\n                return null;\n\n            default:\n                break;\n        }\n    }\n\n    return null;\n}", "language": "javascript"}
{"input": "Returns a distributed matrix whose columns are the left\n        singular vectors of the SingularValueDecomposition if computeU was set to be True.", "output": "def U(self):\n        \"\"\"\n        Returns a distributed matrix whose columns are the left\n        singular vectors of the SingularValueDecomposition if computeU was set to be True.\n        \"\"\"\n        u = self.call(\"U\")\n        if u is not None:\n            mat_name = u.getClass().getSimpleName()\n            if mat_name == \"RowMatrix\":\n                return RowMatrix(u)\n            elif mat_name == \"IndexedRowMatrix\":\n                return IndexedRowMatrix(u)\n            else:\n                raise TypeError(\"Expected RowMatrix/IndexedRowMatrix got %s\" % mat_name)", "language": "python"}
{"input": "/*\nCredits to Mike Samuel for the following method!\nSource: http://stackoverflow.com/questions/10454518/javascript-how-to-retrieve-the-number-of-decimals-of-a-string-number", "output": "function(ev) {\n\t\t\t\tif (this.touchCapable && (ev.type === 'touchstart' || ev.type === 'touchmove')) {\n\t\t\t\t\tev = ev.touches[0];\n\t\t\t\t}\n\n\t\t\t\tvar eventPosition = ev[this.mousePos];\n\t\t\t\tvar sliderOffset = this._state.offset[this.stylePos];\n\t\t\t\tvar distanceToSlide = eventPosition - sliderOffset;\n\t\t\t\t// Calculate what percent of the length the slider handle has slid\n\t\t\t\tvar percentage = (distanceToSlide / this._state.size) * 100;\n\t\t\t\tpercentage = Math.round(percentage / this._state.percentage[2]) * this._state.percentage[2];\n\t\t\t\tif (this.options.reversed) {\n\t\t\t\t\tpercentage = 100 - percentage;\n\t\t\t\t}\n\n\t\t\t\t// Make sure the percent is within the bounds of the slider.\n\t\t\t\t// 0% corresponds to the 'min' value of the slide\n\t\t\t\t// 100% corresponds to the 'max' value of the slide\n\t\t\t\treturn Math.max(0, Math.min(100, percentage));\n\t\t\t}", "language": "javascript"}
{"input": "Return the padded hexadecimal id of ``obj``.", "output": "def _raw_hex_id(obj):\n    \"\"\"Return the padded hexadecimal id of ``obj``.\"\"\"\n    # interpret as a pointer since that's what really what id returns\n    packed = struct.pack('@P', id(obj))\n    return ''.join(map(_replacer, packed))", "language": "python"}
{"input": "A string, which supports escaping \" and '  \"milky way\" 'he\\'s the one!'", "output": "function () {\n                    var str, j = i, e, index = i;\n\n                    if (input.charAt(j) === '~') { j++; e = true; } // Escaped strings\n                    if (input.charAt(j) !== '\"' && input.charAt(j) !== \"'\") { return; }\n\n                    if (e) { $char('~'); }\n\n                    str = $re(/^\"((?:[^\"\\\\\\r\\n]|\\\\.)*)\"|'((?:[^'\\\\\\r\\n]|\\\\.)*)'/);\n                    if (str) {\n                        return new(tree.Quoted)(str[0], str[1] || str[2], e, index, env.currentFileInfo);\n                    }\n                }", "language": "javascript"}
{"input": "Uncertainty reward based on logits.", "output": "def compute_uncertainty_reward(logits, predictions):\n  \"\"\"Uncertainty reward based on logits.\"\"\"\n  # TODO(rsepassi): Add support for L1/L2 loss models. Current code only\n  # works for softmax models.\n  vocab_size = logits.shape[-1]\n  assert vocab_size > 1\n  log_probs = common_layers.log_prob_from_logits(logits)\n  max_log_probs = common_layers.index_last_dim_with_indices(log_probs,\n                                                            predictions)\n  # Threshold\n  neg_log_prob = tf.nn.relu(-max_log_probs - 0.02)\n  # Sum across all but the batch dimension\n  reduce_dims = list(range(len(neg_log_prob.shape)))[1:]\n  summed = tf.reduce_sum(neg_log_prob, axis=reduce_dims)\n  return summed / 10", "language": "python"}
{"input": "Parse an entry point group", "output": "def parse_group(cls, group, lines, dist=None):\n        \"\"\"Parse an entry point group\"\"\"\n        if not MODULE(group):\n            raise ValueError(\"Invalid group name\", group)\n        this = {}\n        for line in yield_lines(lines):\n            ep = cls.parse(line, dist)\n            if ep.name in this:\n                raise ValueError(\"Duplicate entry point\", group, ep.name)\n            this[ep.name] = ep\n        return this", "language": "python"}
{"input": "Get an array of SAPUI5 Filter objects corresponding to this expression.\n\n@returns {sap.ui.model.Filter[]} List of filter objects representing this expression\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.FilterExpression#getExpressionAsUI5FilterArray", "output": "function() {\n\t\t\tvar aFilterObjects = this._aConditionUI5Filter.concat([]);\n\n\t\t\tfor ( var i = -1, aFilter; (aFilter = this._aUI5FilterArray[++i]) !== undefined;) {\n\t\t\t\tfor ( var j = -1, oFilter; (oFilter = aFilter[++j]) !== undefined;) {\n\t\t\t\t\taFilterObjects.push(oFilter);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn aFilterObjects;\n\t\t}", "language": "javascript"}
{"input": "Reports a given reference.\n\n@param {eslint-scope.Reference} reference - A reference to report.\n@returns {void}", "output": "function report(reference) {\n            context.report({\n                node: reference.identifier,\n                loc: reference.identifier.loc,\n                message: \"Use the rest parameters instead of 'arguments'.\"\n            });\n        }", "language": "javascript"}
{"input": "One sentence per line, formatted like\n\n        The###DET dog###NN ate###V the###DET apple###NN\n\n    Returns a list of pairs (tokenized_sentence, tags)", "output": "def load_data(file_path: str) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    One sentence per line, formatted like\n\n        The###DET dog###NN ate###V the###DET apple###NN\n\n    Returns a list of pairs (tokenized_sentence, tags)\n    \"\"\"\n    data = []\n\n    with open(file_path) as f:\n        for line in f:\n            pairs = line.strip().split()\n            sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n            data.append((sentence, tags))\n\n    return data", "language": "python"}
{"input": "Calls the method. Only calls the method if an arguments object is provided.\n\n@param {any} [vContext] The context of the call.\n@param {Object} [vArguments] The arguments object.\n@param {boolean} [bAsync=false] Whether the method should be called in a promise.\n@param {boolean} [bFinal=false] Whether this is the final invocation before cancellation.", "output": "function invoke(vContext, vArguments, bAsync, bFinal) {\n\t\t\t\tiLastInvocationTime = bFinal === true ? null : Date.now();\n\n\t\t\t\tif (vArguments == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (bAsync === true) {\n\t\t\t\t\tvar oPromise = Promise.resolve().then(function() {\n\t\t\t\t\t\tif (!oPromise.canceled) {\n\t\t\t\t\t\t\tfn.apply(vContext, vArguments);\n\t\t\t\t\t\t}\n\t\t\t\t\t\toCancelablePromise = null;\n\t\t\t\t\t});\n\t\t\t\t\toPromise.cancel = function() {\n\t\t\t\t\t\toPromise.canceled = true;\n\t\t\t\t\t};\n\t\t\t\t\toCancelablePromise = oPromise;\n\t\t\t\t} else {\n\t\t\t\t\tfn.apply(vContext, vArguments);\n\t\t\t\t}\n\t\t\t}", "language": "javascript"}
{"input": "Calls {@link sap.ui.core.util.reflection.BaseTreeModifier#setPropertyBinding} if the passed value is a\nbinding info object or binding string,\notherwise calls {@link sap.ui.core.util.reflection.BaseTreeModifier#setProperty}.\n\n@param {sap.ui.base.ManagedObject|Element} vControl - Control representation\n@param {string} sPropertyName - Property name\n@param {any} vBindingOrValue - Property binding or property value\n@public", "output": "function(vControl, sPropertyName, vBindingOrValue) {\n\t\t\tvar bIsBindingObject = vBindingOrValue && (vBindingOrValue.path || vBindingOrValue.parts);\n\t\t\tvar bIsBindingString = vBindingOrValue && typeof vBindingOrValue === \"string\" && vBindingOrValue.substring(0, 1) === \"{\" && vBindingOrValue.slice(-1) === \"}\";\n\n\t\t\tvar sOperation = bIsBindingObject || bIsBindingString ? \"setPropertyBinding\" : \"setProperty\";\n\t\t\tthis[sOperation](vControl, sPropertyName, vBindingOrValue);\n\t\t}", "language": "javascript"}
{"input": "Reports a given token if usage of spacing followed by the token is\ninvalid.\n\n@param {Token} token - A token to report.\n@param {RegExp|undefined} pattern - Optional. A pattern of the previous\ntoken to check.\n@returns {void}", "output": "function checkSpacingBefore(token, pattern) {\n            checkMethodMap[token.value].before(token, pattern || PREV_TOKEN);\n        }", "language": "javascript"}
{"input": "same as mx.model.load_checkpoint, but do not load symnet and will convert context", "output": "def load_param(params, ctx=None):\n    \"\"\"same as mx.model.load_checkpoint, but do not load symnet and will convert context\"\"\"\n    if ctx is None:\n        ctx = mx.cpu()\n    save_dict = mx.nd.load(params)\n    arg_params = {}\n    aux_params = {}\n    for k, v in save_dict.items():\n        tp, name = k.split(':', 1)\n        if tp == 'arg':\n            arg_params[name] = v.as_in_context(ctx)\n        if tp == 'aux':\n            aux_params[name] = v.as_in_context(ctx)\n    return arg_params, aux_params", "language": "python"}
{"input": "Lists all arguments and auxiliary states of this Symbol.\n\n        Returns\n        -------\n        inputs : list of str\n            List of all inputs.\n\n        Examples\n        --------\n        >>> bn = mx.sym.BatchNorm(name='bn')\n        >>> bn.list_arguments()\n        ['bn_data', 'bn_gamma', 'bn_beta']\n        >>> bn.list_auxiliary_states()\n        ['bn_moving_mean', 'bn_moving_var']\n        >>> bn.list_inputs()\n        ['bn_data', 'bn_gamma', 'bn_beta', 'bn_moving_mean', 'bn_moving_var']", "output": "def list_inputs(self):\n        \"\"\"Lists all arguments and auxiliary states of this Symbol.\n\n        Returns\n        -------\n        inputs : list of str\n            List of all inputs.\n\n        Examples\n        --------\n        >>> bn = mx.sym.BatchNorm(name='bn')\n        >>> bn.list_arguments()\n        ['bn_data', 'bn_gamma', 'bn_beta']\n        >>> bn.list_auxiliary_states()\n        ['bn_moving_mean', 'bn_moving_var']\n        >>> bn.list_inputs()\n        ['bn_data', 'bn_gamma', 'bn_beta', 'bn_moving_mean', 'bn_moving_var']\n        \"\"\"\n        size = ctypes.c_uint()\n        sarr = ctypes.POINTER(ctypes.c_char_p)()\n        check_call(_LIB.NNSymbolListInputNames(\n            self.handle, 0, ctypes.byref(size), ctypes.byref(sarr)))\n        return [py_str(sarr[i]) for i in range(size.value)]", "language": "python"}
{"input": "Checks if a given string is an url", "output": "def is_valid_url(url):\n    \"\"\"Checks if a given string is an url\"\"\"\n    from .misc import to_text\n\n    if not url:\n        return url\n    pieces = urllib_parse.urlparse(to_text(url))\n    return all([pieces.scheme, pieces.netloc])", "language": "python"}
{"input": "separate rgb embeddings.", "output": "def imagetransformer_sep_channels_8l_8h_local_and_global_att():\n  \"\"\"separate rgb embeddings.\"\"\"\n  hparams = imagetransformer_sep_channels_8l_8h()\n  hparams.num_heads = 8\n  hparams.batch_size = 1\n  hparams.attention_key_channels = hparams.attention_value_channels = 0\n  hparams.hidden_size = 256\n  hparams.filter_size = 256\n  hparams.num_hidden_layers = 4\n  hparams.sampling_method = \"random\"\n  hparams.local_and_global_att = True\n  return hparams", "language": "python"}
{"input": "Forward computation. Here we do nothing but to keep a reference to\n        the scores and the labels so that we can do backward computation.\n\n        Parameters\n        ----------\n        data_batch : DataBatch\n            Could be anything with similar API implemented.\n        is_train : bool\n            Default is ``None``, which means `is_train` takes the value of ``self.for_training``.", "output": "def forward(self, data_batch, is_train=None):\n        \"\"\"Forward computation. Here we do nothing but to keep a reference to\n        the scores and the labels so that we can do backward computation.\n\n        Parameters\n        ----------\n        data_batch : DataBatch\n            Could be anything with similar API implemented.\n        is_train : bool\n            Default is ``None``, which means `is_train` takes the value of ``self.for_training``.\n        \"\"\"\n        self._scores = data_batch.data[0]\n\n        if is_train is None:\n            is_train = self.for_training\n\n        if is_train:\n            self._labels = data_batch.label[0]", "language": "python"}
{"input": "/*!\nThe following code is taken from\njQuery UI 1.10.3 - 2013-11-18\njquery.ui.position.js\n\nhttp://jqueryui.com\nCopyright 2013 jQuery Foundation and other contributors; Licensed MIT\n TODO: Get rid of this coding when jQuery UI 1.8 is no longer supported and the framework was switched to jQuery UI 1.9 ff.", "output": "function _migrateDataTojQueryUI110(data){\n\t\tvar withinElement = jQuery(window);\n\t\tdata.within = {\n\t\t\telement: withinElement,\n\t\t\tisWindow: true,\n\t\t\toffset: withinElement.offset() || { left: 0, top: 0 },\n\t\t\tscrollLeft: withinElement.scrollLeft(),\n\t\t\tscrollTop: withinElement.scrollTop(),\n\t\t\twidth: withinElement.width(),\n\t\t\theight: withinElement.height()\n\t\t};\n\t\tdata.collisionPosition = {\n\t\t\tmarginLeft: 0,\n\t\t\tmarginTop: 0\n\t\t};\n\t\treturn data;\n\t}", "language": "javascript"}
{"input": "Generates data for each problem.", "output": "def generate_data(self, *args, **kwargs):\n    \"\"\"Generates data for each problem.\"\"\"\n    for p in self.problems:\n      p.generate_data(*args, **kwargs)", "language": "python"}
{"input": "Construction from a string, raise a TypeError if not\n        possible", "output": "def construct_from_string(cls, string):\n        \"\"\"\n        Construction from a string, raise a TypeError if not\n        possible\n        \"\"\"\n        if string == cls.name:\n            return cls()\n        raise TypeError(\"Cannot construct a '{}' from \"\n                        \"'{}'\".format(cls, string))", "language": "python"}
{"input": "Evaluate the CVPack for one iteration.", "output": "def eval(self, iteration, feval):\n        \"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\n        return self.bst.eval_set(self.watchlist, iteration, feval)", "language": "python"}
{"input": "helper function to add some resiliency to volatile GH api endpoints", "output": "async function runRetryable (fn, maxRetries) {\n  let lastError\n  for (let i = 0; i < maxRetries; i++) {\n    try {\n      return await fn()\n    } catch (error) {\n      await new Promise((resolve, reject) => setTimeout(resolve, CHECK_INTERVAL))\n      lastError = error\n    }\n  }\n  // Silently eat 404s.\n  if (lastError.status !== 404) throw lastError\n}", "language": "javascript"}
{"input": "/*\nCreates an array of all property paths for a given object\n@param {object} oObject\n@param {object} [sObjectName] The name of the complex property", "output": "function buildPropertyPaths(oObject, sObjectName) {\n\t\t\t\tObject.keys(oObject).forEach(function (sProperty) {\n\t\t\t\t\tvar sPropertyPath = _Helper.buildPath(sObjectName, sProperty),\n\t\t\t\t\t\tvPropertyValue = oObject[sProperty];\n\n\t\t\t\t\tif (sProperty === \"@$ui5._\") {\n\t\t\t\t\t\treturn; // ignore private namespace\n\t\t\t\t\t}\n\n\t\t\t\t\tif (vPropertyValue !== null && typeof vPropertyValue === \"object\") {\n\t\t\t\t\t\tbuildPropertyPaths(vPropertyValue, sPropertyPath);\n\t\t\t\t\t} else {\n\t\t\t\t\t\taSelect.push(sPropertyPath);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}", "language": "javascript"}
{"input": "Resize the image to `size`, size can be a single int.", "output": "def resize(self, size:Union[int,TensorImageSize]) -> 'ImagePoints':\n        \"Resize the image to `size`, size can be a single int.\"\n        if isinstance(size, int): size=(1, size, size)\n        self._flow.size = size[1:]\n        return self", "language": "python"}
{"input": "Open the file pointed by this path and return a file descriptor,\n        as os.open() does.", "output": "def _raw_open(self, flags, mode=0o777):\n        \"\"\"\n        Open the file pointed by this path and return a file descriptor,\n        as os.open() does.\n        \"\"\"\n        if self._closed:\n            self._raise_closed()\n        return self._accessor.open(self, flags, mode)", "language": "python"}
{"input": "Determine whether a button press has occured and emit events as appropriate.\n\n@param {string} id - ID of the button to check.\n@param {object} buttonState - State of the button to check.\n@returns {boolean} Whether button press state changed.", "output": "function (id, buttonState) {\n    var evtName;\n    var previousButtonState = this.buttonStates[id];\n\n    // Not changed.\n    if (buttonState.pressed === previousButtonState.pressed) { return false; }\n\n    evtName = buttonState.pressed ? EVENTS.BUTTONDOWN : EVENTS.BUTTONUP;\n    this.el.emit(evtName, this.buttonEventDetails[id], false);\n    previousButtonState.pressed = buttonState.pressed;\n    return true;\n  }", "language": "javascript"}
{"input": "Sum of non-NA/null values\n\n        Returns\n        -------\n        sum : float", "output": "def sum(self, axis=0, *args, **kwargs):\n        \"\"\"\n        Sum of non-NA/null values\n\n        Returns\n        -------\n        sum : float\n        \"\"\"\n        nv.validate_sum(args, kwargs)\n        valid_vals = self._valid_sp_values\n        sp_sum = valid_vals.sum()\n        if self._null_fill_value:\n            return sp_sum\n        else:\n            nsparse = self.sp_index.ngaps\n            return sp_sum + self.fill_value * nsparse", "language": "python"}
{"input": "itemgetter serializer (needed for namedtuple support)", "output": "def save_itemgetter(self, obj):\n        \"\"\"itemgetter serializer (needed for namedtuple support)\"\"\"\n        class Dummy:\n            def __getitem__(self, item):\n                return item\n        items = obj(Dummy())\n        if not isinstance(items, tuple):\n            items = (items,)\n        return self.save_reduce(operator.itemgetter, items)", "language": "python"}
{"input": "For files that don't support as-you-type live editing, but are loaded by live HTML documents\n(e.g. JS files), we want to show a dirty indicator on the live development icon when they\nhave unsaved changes, so the user knows s/he needs to save in order to have the page reload.\n@param {$.Event} event\n@param {Document} doc", "output": "function _onDirtyFlagChange(event, doc) {\n        if (!isActive() || !_server) {\n            return;\n        }\n\n        var absolutePath = doc.file.fullPath;\n\n        if (_liveDocument.isRelated(absolutePath)) {\n            // Set status to out of sync if dirty. Otherwise, set it to active status.\n            _setStatus(_docIsOutOfSync(doc) ? STATUS_OUT_OF_SYNC : STATUS_ACTIVE);\n        }\n    }", "language": "javascript"}
{"input": "\u5bfc\u5165 script \u5143\u7d20", "output": "function(url) {\n\t\tvar element = doc.createElement('script');\n\t\telement.src = url;\n\t\telement.async = true;\n\t\telement.defer = true;\n\t\tcontainer.appendChild(element);\n\t\treturn element;\n\t}", "language": "javascript"}
{"input": "Decode changes from a JS API to a page object.\nOnly the content can be edited by plugin's hooks.\n\n@param {Output} output\n@param {Page} page: page instance to edit\n@param {Object} result: result from API\n@return {Page}", "output": "function decodePage(output, page, result) {\n    var originalContent = page.getContent();\n\n    // No returned value\n    // Existing content will be used\n    if (!result) {\n        return page;\n    }\n\n    deprecate.disable('page.sections');\n\n    // GitBook 3\n    // Use returned page.content if different from original content\n    if (result.content != originalContent) {\n        page = page.set('content', result.content);\n    }\n\n    // GitBook 2 compatibility\n    // Finally, use page.sections\n    else if (result.sections) {\n        page = page.set('content',\n            result.sections.map(function(section) {\n                return section.content;\n            }).join('\\n')\n        );\n    }\n\n    deprecate.enable('page.sections');\n\n    return page;\n}", "language": "javascript"}
{"input": "Get the OS appropriate handle for the corresponding output stream.\n\n    :param str stream: The the stream to get the handle for\n    :return: A handle to the appropriate stream, either a ctypes buffer\n             or **sys.stdout** or **sys.stderr**.", "output": "def get_stream_handle(stream=sys.stdout):\n    \"\"\"\n    Get the OS appropriate handle for the corresponding output stream.\n\n    :param str stream: The the stream to get the handle for\n    :return: A handle to the appropriate stream, either a ctypes buffer\n             or **sys.stdout** or **sys.stderr**.\n    \"\"\"\n    handle = stream\n    if os.name == \"nt\":\n        from ctypes import windll\n\n        handle_id = WIN_STDOUT_HANDLE_ID\n        handle = windll.kernel32.GetStdHandle(handle_id)\n    return handle", "language": "python"}
{"input": "Save a code object", "output": "def save_codeobject(self, obj):\n        \"\"\"\n        Save a code object\n        \"\"\"\n        if PY3:  # pragma: no branch\n            args = (\n                obj.co_argcount, obj.co_kwonlyargcount, obj.co_nlocals, obj.co_stacksize,\n                obj.co_flags, obj.co_code, obj.co_consts, obj.co_names, obj.co_varnames,\n                obj.co_filename, obj.co_name, obj.co_firstlineno, obj.co_lnotab, obj.co_freevars,\n                obj.co_cellvars\n            )\n        else:\n            args = (\n                obj.co_argcount, obj.co_nlocals, obj.co_stacksize, obj.co_flags, obj.co_code,\n                obj.co_consts, obj.co_names, obj.co_varnames, obj.co_filename, obj.co_name,\n                obj.co_firstlineno, obj.co_lnotab, obj.co_freevars, obj.co_cellvars\n            )\n        self.save_reduce(types.CodeType, args, obj=obj)", "language": "python"}
{"input": "Checks whether or not there is a transition.\n\n@param styles The cached styles to use for the calculation. If null, getComputedStyle()\nwill be used.\n\n@returns {boolean} True if there is no transition/duration; false otherwise.", "output": "function noTransitionFound(styles) {\n          styles = styles || window.getComputedStyle(element[0]);\n\n          return styles.transitionDuration == '0s' || (!styles.transition && !styles.transitionProperty);\n        }", "language": "javascript"}
{"input": "Function: importNode\n\nCross browser implementation for document.importNode. Uses document.importNode\nin all browsers but IE, where the node is cloned by creating a new node and\ncopying all attributes and children into it using importNode, recursively.\n\nParameters:\n\ndoc - Document to import the node into.\nnode - Node to be imported.\nallChildren - If all children should be imported.", "output": "function(doc, node, allChildren)\n\t{\n\t\tif (mxClient.IS_IE && (document.documentMode == null || document.documentMode < 10))\n\t\t{\n\t\t\tswitch (node.nodeType)\n\t\t\t{\n\t\t\t\tcase 1: /* element */\n\t\t\t\t{\n\t\t\t\t\tvar newNode = doc.createElement(node.nodeName);\n\t\t\t\t\t\n\t\t\t\t\tif (node.attributes && node.attributes.length > 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tfor (var i = 0; i < node.attributes.length; i++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tnewNode.setAttribute(node.attributes[i].nodeName,\n\t\t\t\t\t\t\t\tnode.getAttribute(node.attributes[i].nodeName));\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (allChildren && node.childNodes && node.childNodes.length > 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor (var i = 0; i < node.childNodes.length; i++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tnewNode.appendChild(mxUtils.importNode(doc, node.childNodes[i], allChildren));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\treturn newNode;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase 3: /* text */\n\t\t\t    case 4: /* cdata-section */\n\t\t\t    case 8: /* comment */\n\t\t\t    {\n\t\t\t      return doc.createTextNode(node.value);\n\t\t\t      break;\n\t\t\t    }\n\t\t\t};\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn doc.importNode(node, allChildren);\n\t\t}\n\t}", "language": "javascript"}
{"input": "called when self.runtest() raises an exception.", "output": "def repr_failure(self, excinfo):\n        \"\"\" called when self.runtest() raises an exception. \"\"\"\n        exc = excinfo.value\n        cc = self.colors\n        if isinstance(exc, NbCellError):\n            msg_items = [\n                cc.FAIL + \"Notebook cell execution failed\" + cc.ENDC]\n            formatstring = (\n                cc.OKBLUE + \"Cell %d: %s\\n\\n\" +\n                \"Input:\\n\" + cc.ENDC + \"%s\\n\")\n            msg_items.append(formatstring % (\n                exc.cell_num,\n                str(exc),\n                exc.source\n            ))\n            if exc.inner_traceback:\n                msg_items.append((\n                    cc.OKBLUE + \"Traceback:\" + cc.ENDC + \"\\n%s\\n\") %\n                    exc.inner_traceback)\n            return \"\\n\".join(msg_items)\n        else:\n            return \"pytest plugin exception: %s\" % str(exc)", "language": "python"}
{"input": "Get the node which contains the selection\n\n@param {Boolean} [controlRange] (only IE) Whether it should return the selected ControlRange element when the selection type is a \"ControlRange\"\n@return {Object} The node that contains the caret\n@example\nvar nodeThatContainsCaret = selection.getSelectedNode();", "output": "function(controlRange) {\n      var selection,\n          range;\n\n      if (controlRange && this.doc.selection && this.doc.selection.type === \"Control\") {\n        range = this.doc.selection.createRange();\n        if (range && range.length) {\n          return range.item(0);\n        }\n      }\n\n      selection = this.getSelection(this.doc);\n      if (selection.focusNode === selection.anchorNode) {\n        return selection.focusNode;\n      } else {\n        range = this.getRange(this.doc);\n        return range ? range.commonAncestorContainer : this.doc.body;\n      }\n    }", "language": "javascript"}
{"input": "Creates a new metadata object from the given static infos.\n\nNote: throughout this class documentation, the described subclass of Object\nis referenced as <i>the described class</i>.\n\n@param {string} sClassName fully qualified name of the described class\n@param {object} oClassInfo info to construct the class and its metadata from\n\n@class Metadata for a class.\n@author Frank Weigel\n@version ${version}\n@since 0.8.6\n@public\n@alias sap.ui.base.Metadata", "output": "function(sClassName, oClassInfo) {\n\n\t\tassert(typeof sClassName === \"string\" && sClassName, \"Metadata: sClassName must be a non-empty string\");\n\t\tassert(typeof oClassInfo === \"object\", \"Metadata: oClassInfo must be empty or an object\");\n\n\t\t// support for old usage of Metadata\n\t\tif ( !oClassInfo || typeof oClassInfo.metadata !== \"object\" ) {\n\t\t\toClassInfo = {\n\t\t\t\tmetadata : oClassInfo || {},\n\t\t\t\t// retrieve class by its name. Using a lookup costs time but avoids the need for redundant arguments to this function\n\t\t\t\tconstructor : ObjectPath.get(sClassName)\n\t\t\t};\n\t\t\toClassInfo.metadata.__version = 1.0;\n\t\t}\n\t\toClassInfo.metadata.__version = oClassInfo.metadata.__version || 2.0;\n\t\tif ( typeof oClassInfo.constructor !== \"function\" ) {\n\t\t\tthrow Error(\"constructor for class \" + sClassName + \" must have been declared before creating metadata for it\");\n\t\t}\n\n\t\t// invariant: oClassInfo exists, oClassInfo.metadata exists, oClassInfo.constructor exists\n\t\tthis._sClassName = sClassName;\n\t\tthis._oClass = oClassInfo.constructor;\n\t\tthis.extend(oClassInfo);\n\t}", "language": "javascript"}
{"input": "Warm up cache.\n\n    This task periodically hits charts to warm up the cache.", "output": "def cache_warmup(strategy_name, *args, **kwargs):\n    \"\"\"\n    Warm up cache.\n\n    This task periodically hits charts to warm up the cache.\n\n    \"\"\"\n    logger.info('Loading strategy')\n    class_ = None\n    for class_ in strategies:\n        if class_.name == strategy_name:\n            break\n    else:\n        message = f'No strategy {strategy_name} found!'\n        logger.error(message)\n        return message\n\n    logger.info(f'Loading {class_.__name__}')\n    try:\n        strategy = class_(*args, **kwargs)\n        logger.info('Success!')\n    except TypeError:\n        message = 'Error loading strategy!'\n        logger.exception(message)\n        return message\n\n    results = {'success': [], 'errors': []}\n    for url in strategy.get_urls():\n        try:\n            logger.info(f'Fetching {url}')\n            requests.get(url)\n            results['success'].append(url)\n        except RequestException:\n            logger.exception('Error warming up cache!')\n            results['errors'].append(url)\n\n    return results", "language": "python"}
{"input": "Create request definitions based on openapi document.\n\n@param {Object} document - OpenAPI 3 valid object (https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md#oasObject)\n\n@returns {Object[]} array of insomnia endpoints definitions", "output": "function parseEndpoints(document) {\n  const defaultParent = WORKSPACE_ID;\n\n  const paths = Object.keys(document.paths);\n  const endpointsSchemas = paths\n    .map(path => {\n      const schemasPerMethod = document.paths[path];\n      const methods = Object.keys(schemasPerMethod);\n\n      return methods\n        .filter(method => method !== 'parameters')\n        .map(method => Object.assign({}, schemasPerMethod[method], { path, method }));\n    })\n    .reduce((flat, arr) => flat.concat(arr), []); //flat single array\n\n  const tags = document.tags || [];\n  const folders = tags.map(tag => {\n    return importFolderItem(tag, defaultParent);\n  });\n  const folderLookup = {};\n  folders.forEach(folder => (folderLookup[folder.name] = folder._id));\n\n  const requests = [];\n  endpointsSchemas.map(endpointSchema => {\n    let { tags } = endpointSchema;\n    if (!tags || tags.length == 0) tags = [''];\n    tags.forEach((tag, index) => {\n      let id = endpointSchema.operationId\n        ? `${endpointSchema.operationId}${index > 0 ? index : ''}`\n        : `__REQUEST_${requestCount++}__`;\n      let parentId = folderLookup[tag] || defaultParent;\n      requests.push(importRequest(endpointSchema, id, parentId));\n    });\n  });\n\n  return [...folders, ...requests];\n}", "language": "javascript"}
{"input": "Gets short help for the command or makes it by shortening the long help string.", "output": "def get_short_help_str(self, limit=45):\n        \"\"\"Gets short help for the command or makes it by shortening the long help string.\"\"\"\n        return self.short_help or self.help and make_default_short_help(self.help, limit) or ''", "language": "python"}
{"input": "Perspective effect", "output": "function scrollInterpolator2 (index, carouselProps) {\n    const range = [2, 1, 0, -1];\n    const inputRange = getInputRangeFromIndexes(range, index, carouselProps);\n    const outputRange = range;\n\n    return { inputRange, outputRange };\n}", "language": "javascript"}
{"input": "Dispatch messages to handlers according to msg.method value.\n@param {Object} msg Message to be dispatched.", "output": "function (msg) {\n            var msgHandlers;\n            if (!msg.method) {\n                // no message type, ignoring it\n                // TODO: should we trigger a generic event?\n                console.log(\"[Brackets LiveDev] Received message without method.\");\n                return;\n            }\n            // get handlers for msg.method\n            msgHandlers = this.handlers[msg.method];\n\n            if (msgHandlers && msgHandlers.length > 0) {\n                // invoke handlers with the received message\n                msgHandlers.forEach(function (handler) {\n                    try {\n                        // TODO: check which context should be used to call handlers here.\n                        handler(msg);\n                        return;\n                    } catch (e) {\n                        console.log(\"[Brackets LiveDev] Error executing a handler for \" + msg.method);\n                        console.log(e.stack);\n                        return;\n                    }\n                });\n            } else {\n                // no subscribers, ignore it.\n                // TODO: any other default handling? (eg. specific respond, trigger as a generic event, etc.);\n                console.log(\"[Brackets LiveDev] No subscribers for message \" + msg.method);\n                return;\n            }\n        }", "language": "javascript"}
{"input": "Walk through the dom nodes and insert the 'data-brackets-id' attribute at the end of the open tag", "output": "function walk(node) {\n            if (node.tag) {\n                var attrText = \" data-brackets-id='\" + node.tagID + \"'\";\n\n                // If the dom was fully rebuilt, use its offsets. Otherwise, use the marks in the\n                // associated editor, since they'll be more up to date.\n                var startOffset;\n                if (dom.fullBuild) {\n                    startOffset = node.start;\n                } else {\n                    var mark = markCache[node.tagID];\n                    if (mark) {\n                        startOffset = editor._codeMirror.indexFromPos(mark.range.from);\n                    } else {\n                        console.warn(\"generateInstrumentedHTML(): couldn't find existing mark for tagID \" + node.tagID);\n                        startOffset = node.start;\n                    }\n                }\n\n                // Insert the attribute as the first attribute in the tag.\n                var insertIndex = startOffset + node.tag.length + 1;\n                gen += orig.substr(lastIndex, insertIndex - lastIndex) + attrText;\n                lastIndex = insertIndex;\n\n                // If we have a script to inject and this is the head tag, inject it immediately\n                // after the open tag.\n                if (remoteScript && !remoteScriptInserted && node.tag === \"head\") {\n                    insertIndex = node.openEnd;\n                    gen += orig.substr(lastIndex, insertIndex - lastIndex) + remoteScript;\n                    lastIndex = insertIndex;\n                    remoteScriptInserted = true;\n                }\n            }\n\n            if (node.isElement()) {\n                node.children.forEach(walk);\n            }\n        }", "language": "javascript"}
{"input": ":return: ccache directory for the current platform", "output": "def default_ccache_dir() -> str:\n    \"\"\":return: ccache directory for the current platform\"\"\"\n    # Share ccache across containers\n    if 'CCACHE_DIR' in os.environ:\n        ccache_dir = os.path.realpath(os.environ['CCACHE_DIR'])\n        try:\n            os.makedirs(ccache_dir, exist_ok=True)\n            return ccache_dir\n        except PermissionError:\n            logging.info('Unable to make dirs at %s, falling back to local temp dir', ccache_dir)\n    # In osx tmpdir is not mountable by default\n    import platform\n    if platform.system() == 'Darwin':\n        ccache_dir = \"/tmp/_mxnet_ccache\"\n        os.makedirs(ccache_dir, exist_ok=True)\n        return ccache_dir\n    return os.path.join(os.path.expanduser(\"~\"), \".ccache\")", "language": "python"}
{"input": "Passes the result to SigOpt unless early terminated or errored.\n\n        If a trial fails, it will be reported as a failed Observation, telling\n        the optimizer that the Suggestion led to a metric failure, which\n        updates the feasible region and improves parameter recommendation.\n\n        Creates SigOpt Observation object for trial.", "output": "def on_trial_complete(self,\n                          trial_id,\n                          result=None,\n                          error=False,\n                          early_terminated=False):\n        \"\"\"Passes the result to SigOpt unless early terminated or errored.\n\n        If a trial fails, it will be reported as a failed Observation, telling\n        the optimizer that the Suggestion led to a metric failure, which\n        updates the feasible region and improves parameter recommendation.\n\n        Creates SigOpt Observation object for trial.\n        \"\"\"\n        if result:\n            self.conn.experiments(self.experiment.id).observations().create(\n                suggestion=self._live_trial_mapping[trial_id].id,\n                value=result[self._reward_attr],\n            )\n            # Update the experiment object\n            self.experiment = self.conn.experiments(self.experiment.id).fetch()\n        elif error or early_terminated:\n            # Reports a failed Observation\n            self.conn.experiments(self.experiment.id).observations().create(\n                failed=True, suggestion=self._live_trial_mapping[trial_id].id)\n        del self._live_trial_mapping[trial_id]", "language": "python"}
{"input": "Return either the currently active StreamingContext (i.e., if there is a context started\n        but not stopped) or None.", "output": "def getActive(cls):\n        \"\"\"\n        Return either the currently active StreamingContext (i.e., if there is a context started\n        but not stopped) or None.\n        \"\"\"\n        activePythonContext = cls._activeContext\n        if activePythonContext is not None:\n            # Verify that the current running Java StreamingContext is active and is the same one\n            # backing the supposedly active Python context\n            activePythonContextJavaId = activePythonContext._jssc.ssc().hashCode()\n            activeJvmContextOption = activePythonContext._jvm.StreamingContext.getActive()\n\n            if activeJvmContextOption.isEmpty():\n                cls._activeContext = None\n            elif activeJvmContextOption.get().hashCode() != activePythonContextJavaId:\n                cls._activeContext = None\n                raise Exception(\"JVM's active JavaStreamingContext is not the JavaStreamingContext \"\n                                \"backing the action Python StreamingContext. This is unexpected.\")\n        return cls._activeContext", "language": "python"}
{"input": "Async accessor to registered component instance\nIf not available then a promise is created to notify\nall listeners when the instance is registered.", "output": "function(handle) {\n        if (isValidID(handle)) {\n          var deferred = $q.defer();\n          var instance = self.get(handle);\n\n          if (instance)  {\n            deferred.resolve(instance);\n          } else {\n            if (pendings[handle] === undefined) {\n              pendings[handle] = [];\n            }\n            pendings[handle].push(deferred);\n          }\n\n          return deferred.promise;\n        }\n        return $q.reject(\"Invalid `md-component-id` value.\");\n      }", "language": "javascript"}
{"input": "Remove the source files from this requirement, if they are marked\n        for deletion", "output": "def remove_temporary_source(self):\n        # type: () -> None\n        \"\"\"Remove the source files from this requirement, if they are marked\n        for deletion\"\"\"\n        if self.source_dir and os.path.exists(\n                os.path.join(self.source_dir, PIP_DELETE_MARKER_FILENAME)):\n            logger.debug('Removing source in %s', self.source_dir)\n            rmtree(self.source_dir)\n        self.source_dir = None\n        self._temp_build_dir.cleanup()\n        self.build_env.cleanup()", "language": "python"}
{"input": "Get subset of current Dataset.\n\n        Parameters\n        ----------\n        used_indices : list of int\n            Indices used to create the subset.\n        params : dict or None, optional (default=None)\n            These parameters will be passed to Dataset constructor.\n\n        Returns\n        -------\n        subset : Dataset\n            Subset of the current Dataset.", "output": "def subset(self, used_indices, params=None):\n        \"\"\"Get subset of current Dataset.\n\n        Parameters\n        ----------\n        used_indices : list of int\n            Indices used to create the subset.\n        params : dict or None, optional (default=None)\n            These parameters will be passed to Dataset constructor.\n\n        Returns\n        -------\n        subset : Dataset\n            Subset of the current Dataset.\n        \"\"\"\n        if params is None:\n            params = self.params\n        ret = Dataset(None, reference=self, feature_name=self.feature_name,\n                      categorical_feature=self.categorical_feature, params=params,\n                      free_raw_data=self.free_raw_data)\n        ret._predictor = self._predictor\n        ret.pandas_categorical = self.pandas_categorical\n        ret.used_indices = used_indices\n        return ret", "language": "python"}
{"input": "Generate mnli examples.\n\n  Args:\n    filename: a string\n  Yields:\n    dictionaries containing \"premise\", \"hypothesis\" and \"label\" strings", "output": "def _example_generator(filename):\n  \"\"\"Generate mnli examples.\n\n  Args:\n    filename: a string\n  Yields:\n    dictionaries containing \"premise\", \"hypothesis\" and \"label\" strings\n  \"\"\"\n  for idx, line in enumerate(tf.gfile.Open(filename, \"rb\")):\n    if idx == 0: continue  # skip header\n    line = text_encoder.to_unicode_utf8(line.strip())\n    split_line = line.split(\"\\t\")\n    # Works for both splits even though dev has some extra human labels.\n    yield {\n        \"premise\": split_line[8],\n        \"hypothesis\": split_line[9],\n        \"label\": split_line[-1]\n    }", "language": "python"}
{"input": "return str }", "output": "function FileIcon () {\n  return <View style={styles.itemIconContainer}>\n    <Image\n      style={styles.itemIcon}\n      source={require('./assets/file-icon.png')}\n    />\n  </View>\n}", "language": "javascript"}
{"input": "The basic LSTM seq2seq model, main step used for training.", "output": "def lstm_seq2seq_internal(inputs, targets, hparams, train):\n  \"\"\"The basic LSTM seq2seq model, main step used for training.\"\"\"\n  with tf.variable_scope(\"lstm_seq2seq\"):\n    if inputs is not None:\n      inputs_length = common_layers.length_from_embedding(inputs)\n      # Flatten inputs.\n      inputs = common_layers.flatten4d3d(inputs)\n\n      # LSTM encoder.\n      inputs = tf.reverse_sequence(inputs, inputs_length, seq_axis=1)\n      _, final_encoder_state = lstm(inputs, inputs_length, hparams, train,\n                                    \"encoder\")\n    else:\n      final_encoder_state = None\n\n    # LSTM decoder.\n    shifted_targets = common_layers.shift_right(targets)\n    # Add 1 to account for the padding added to the left from shift_right\n    targets_length = common_layers.length_from_embedding(shifted_targets) + 1\n    decoder_outputs, _ = lstm(\n        common_layers.flatten4d3d(shifted_targets),\n        targets_length,\n        hparams,\n        train,\n        \"decoder\",\n        initial_state=final_encoder_state)\n    return tf.expand_dims(decoder_outputs, axis=2)", "language": "python"}
{"input": "Creates a function to wait for at least one interim element to be available.\n@param callbackFn Function to be used as callback\n@returns {Function}", "output": "function waitForInterim(callbackFn) {\n        return function() {\n          var fnArguments = arguments;\n\n          if (!showingInterims.length) {\n            // When there are still interim's opening, then wait for the first interim element to\n            // finish its open animation.\n            if (showPromises.length) {\n              return showPromises[0].finally(function () {\n                return callbackFn.apply(service, fnArguments);\n              });\n            }\n\n            return $q.when(\"No interim elements currently showing up.\");\n          }\n\n          return callbackFn.apply(service, fnArguments);\n        };\n      }", "language": "javascript"}
{"input": "Called when the network is done training.", "output": "function(obj) {\n    console.log(`trained in ${ obj.iterations } iterations with error: ${ obj.error }`);\n\n    const result01 = net.run([0, 1]);\n    const result00 = net.run([0, 0]);\n    const result11 = net.run([1, 1]);\n    const result10 = net.run([1, 0]);\n\n    assert(result01[0] > 0.9);\n    assert(result00[0] < 0.1);\n    assert(result11[0] < 0.1);\n    assert(result10[0] > 0.9);\n\n    console.log('0 XOR 1: ', result01);  // 0.987\n    console.log('0 XOR 0: ', result00);  // 0.058\n    console.log('1 XOR 1: ', result11);  // 0.087\n    console.log('1 XOR 0: ', result10);  // 0.934\n  }", "language": "javascript"}
{"input": "Creates a one-way binding manually rather than relying on AngularJS's isolated scope\n@param key\n@param handler", "output": "function defineOneWayBinding (key, handler) {\n    var attr = $attrs.$normalize('md-' + key);\n    if (handler) defineProperty(key, handler);\n    $attrs.$observe(attr, function (newValue) { ctrl[ key ] = newValue; });\n  }", "language": "javascript"}
{"input": "Manually add 'tags' attribute since it's not in the schema and call parent.\n\n@param {Object} data Has keys representing the model's attributes/fields in the database.\n@return {Object} The filtered results of the passed in data, containing only what's allowed in the schema.", "output": "function filterData(data) {\n        var filteredData = ghostBookshelf.Model.filterData.apply(this, arguments),\n            extraData = _.pick(data, this.prototype.relationships);\n\n        _.merge(filteredData, extraData);\n        return filteredData;\n    }", "language": "javascript"}
{"input": "Sort an array of django versions low to high.", "output": "function sortDjangoVersions(versions) {\n  return versions.sort((a, b) => {\n    if (\n      parseDjangoVersionString(a).major === parseDjangoVersionString(b).major\n    ) {\n      return (\n        parseDjangoVersionString(a).minor - parseDjangoVersionString(b).minor\n      )\n    } else {\n      return (\n        parseDjangoVersionString(a).major - parseDjangoVersionString(b).major\n      )\n    }\n  })\n}", "language": "javascript"}
{"input": "Processes an individual file using ESLint. Files used here are known to\nexist, so no need to check that here.\n@param {string} filename The filename of the file being checked.\n@param {Object} configHelper The configuration options for ESLint.\n@param {Object} options The CLIEngine options object.\n@param {Linter} linter Linter context\n@returns {{rules: LintResult, config: Object}} The results for linting on this text and the fully-resolved config for it.\n@private", "output": "function processFile(filename, configHelper, options, linter) {\n\n    const text = fs.readFileSync(path.resolve(filename), \"utf8\");\n\n    return processText(\n        text,\n        configHelper,\n        filename,\n        options.fix,\n        options.allowInlineConfig,\n        options.reportUnusedDisableDirectives,\n        linter\n    );\n}", "language": "javascript"}
{"input": "Better scroll events", "output": "function onScroll(cb) {\n  var isTicking = false;\n  var scrollY = 0;\n  var body = document.body;\n  var html = document.documentElement;\n  var scrollHeight = Math.max(body.scrollHeight, body.offsetHeight, html.clientHeight, html.scrollHeight, html.offsetHeight);\n  function scroll() {\n    scrollY = window.scrollY;\n    if (cb) cb(scrollY, scrollHeight);\n    requestTick();\n  }\n  function requestTick() {\n    if (!isTicking) requestAnimationFrame(updateScroll);\n    isTicking = true;\n  }\n  function updateScroll() {\n    isTicking = false;\n    var currentScrollY = scrollY;\n  }\n  scroll();\n  window.onscroll = scroll;\n}", "language": "javascript"}
{"input": "Convert an arbitrary string to a standard version string", "output": "def safe_version(version):\n    \"\"\"\n    Convert an arbitrary string to a standard version string\n    \"\"\"\n    try:\n        # normalize the version\n        return str(packaging.version.Version(version))\n    except packaging.version.InvalidVersion:\n        version = version.replace(' ', '.')\n        return re.sub('[^A-Za-z0-9.]+', '-', version)", "language": "python"}
{"input": "An @import directive  @import \"lib\";  Depending on our environemnt, importing is done differently: In the browser, it's an XHR request, in Node, it would be a file-system operation. The function used for importing is stored in `import`, which we pass to the Import constructor.", "output": "function () {\n                var path, features, index = i;\n\n                save();\n\n                var dir = $re(/^@import?\\s+/);\n\n                var options = (dir ? this.importOptions() : null) || {};\n\n                if (dir && (path = this.entities.quoted() || this.entities.url())) {\n                    features = this.mediaFeatures();\n                    if ($char(';')) {\n                        features = features && new(tree.Value)(features);\n                        return new(tree.Import)(path, features, options, index, env.currentFileInfo);\n                    }\n                }\n\n                restore();\n            }", "language": "javascript"}
{"input": "Extracts the milliseconds if the value is a date/time instance or formatted string.\n@param {any} vValue\nthe value (may be <code>undefined</code> or <code>null</code>)\n@returns {any}\nthe number of milliseconds or the value itself", "output": "function extractMilliseconds(vValue) {\n\t\tif (typeof vValue === \"string\" && rTime.test(vValue)) {\n\t\t\tvValue = parseInt(RegExp.$1) * 3600000 +\n\t\t\t\tparseInt(RegExp.$2) * 60000 +\n\t\t\t\tparseInt(RegExp.$3) * 1000;\n\t\t}\n\t\tif (vValue instanceof Date) {\n\t\t\treturn vValue.getTime();\n\t\t}\n\t\tif (vValue && vValue.__edmType === \"Edm.Time\") {\n\t\t\treturn vValue.ms;\n\t\t}\n\t\treturn vValue;\n\t}", "language": "javascript"}
{"input": "Triggers the BeforeRendering event on the given Control", "output": "function triggerBeforeRendering(oControl){\n\t\t\tbLocked = true;\n\t\t\ttry {\n\t\t\t\tvar oEvent = jQuery.Event(\"BeforeRendering\");\n\t\t\t\t// store the element on the event (aligned with jQuery syntax)\n\t\t\t\toEvent.srcControl = oControl;\n\t\t\t\toControl._handleEvent(oEvent);\n\t\t\t} finally {\n\t\t\t\tbLocked = false;\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Sends the current log directory to the remote node.\n\n        Syncing will not occur if the cluster is not started\n        with the Ray autoscaler.", "output": "def sync_results_to_new_location(self, worker_ip):\n        \"\"\"Sends the current log directory to the remote node.\n\n        Syncing will not occur if the cluster is not started\n        with the Ray autoscaler.\n        \"\"\"\n        if worker_ip != self._log_syncer.worker_ip:\n            self._log_syncer.set_worker_ip(worker_ip)\n            self._log_syncer.sync_to_worker_if_possible()", "language": "python"}
{"input": "Outputs the results of the linting.\n@param {CLIEngine} engine The CLIEngine to use.\n@param {LintResult[]} results The results to print.\n@param {string} format The name of the formatter to use or the path to the formatter.\n@param {string} outputFile The path for the output file.\n@returns {boolean} True if the printing succeeds, false if not.\n@private", "output": "function printResults(engine, results, format, outputFile) {\n    let formatter;\n    let rules;\n\n    try {\n        formatter = engine.getFormatter(format);\n        rules = engine.getRules();\n    } catch (e) {\n        log.error(e.message);\n        return false;\n    }\n\n    const rulesMeta = {};\n\n    rules.forEach((rule, ruleId) => {\n        rulesMeta[ruleId] = rule.meta;\n    });\n\n    const output = formatter(results, { rulesMeta });\n\n    if (output) {\n        if (outputFile) {\n            const filePath = path.resolve(process.cwd(), outputFile);\n\n            if (fs.existsSync(filePath) && fs.statSync(filePath).isDirectory()) {\n                log.error(\"Cannot write to output file path, it is a directory: %s\", outputFile);\n                return false;\n            }\n\n            try {\n                mkdirp.sync(path.dirname(filePath));\n                fs.writeFileSync(filePath, output);\n            } catch (ex) {\n                log.error(\"There was a problem writing the output file:\\n%s\", ex);\n                return false;\n            }\n        } else {\n            log.info(output);\n        }\n    }\n\n    return true;\n\n}", "language": "javascript"}
{"input": "Iterate over all resources within the SAM template, optionally filtering by type\n\n        :param string resource_type: Optional type to filter the resources by\n        :yields (string, SamResource): Tuple containing LogicalId and the resource", "output": "def iterate(self, resource_type=None):\n        \"\"\"\n        Iterate over all resources within the SAM template, optionally filtering by type\n\n        :param string resource_type: Optional type to filter the resources by\n        :yields (string, SamResource): Tuple containing LogicalId and the resource\n        \"\"\"\n\n        for logicalId, resource_dict in self.resources.items():\n\n            resource = SamResource(resource_dict)\n            needs_filter = resource.valid()\n            if resource_type:\n                needs_filter = needs_filter and resource.type == resource_type\n\n            if needs_filter:\n                yield logicalId, resource", "language": "python"}
{"input": "Build the align array", "output": "def build(self, align_path):\n        \"\"\"\n        Build the align array\n        \"\"\"\n        file = open(align_path, 'r')\n        lines = file.readlines()\n        file.close()\n        # words: list([op, ed, word])\n        words = []\n        for line in lines:\n            _op, _ed, word = line.strip().split(' ')\n            if word not in Align.skip_list:\n                words.append((int(_op), int(_ed), word))\n        self.words = words\n        self.n_words = len(words)\n        self.sentence_str = \" \".join([w[2] for w in self.words])\n        self.sentence_length = len(self.sentence_str)", "language": "python"}
{"input": "Convert the column into type ``dataType``.\n\n        >>> df.select(df.age.cast(\"string\").alias('ages')).collect()\n        [Row(ages=u'2'), Row(ages=u'5')]\n        >>> df.select(df.age.cast(StringType()).alias('ages')).collect()\n        [Row(ages=u'2'), Row(ages=u'5')]", "output": "def cast(self, dataType):\n        \"\"\" Convert the column into type ``dataType``.\n\n        >>> df.select(df.age.cast(\"string\").alias('ages')).collect()\n        [Row(ages=u'2'), Row(ages=u'5')]\n        >>> df.select(df.age.cast(StringType()).alias('ages')).collect()\n        [Row(ages=u'2'), Row(ages=u'5')]\n        \"\"\"\n        if isinstance(dataType, basestring):\n            jc = self._jc.cast(dataType)\n        elif isinstance(dataType, DataType):\n            from pyspark.sql import SparkSession\n            spark = SparkSession.builder.getOrCreate()\n            jdt = spark._jsparkSession.parseDataType(dataType.json())\n            jc = self._jc.cast(jdt)\n        else:\n            raise TypeError(\"unexpected type: %s\" % type(dataType))\n        return Column(jc)", "language": "python"}
{"input": "Group series by axis.", "output": "function groupSeriesByAxis(ecModel) {\n    var result = [];\n    var axisList = [];\n\n    ecModel.eachSeriesByType('boxplot', function (seriesModel) {\n        var baseAxis = seriesModel.getBaseAxis();\n        var idx = zrUtil.indexOf(axisList, baseAxis);\n\n        if (idx < 0) {\n            idx = axisList.length;\n            axisList[idx] = baseAxis;\n            result[idx] = {axis: baseAxis, seriesModels: []};\n        }\n\n        result[idx].seriesModels.push(seriesModel);\n    });\n\n    return result;\n}", "language": "javascript"}
{"input": "Return the first IP address for an ethernet interface on the system.", "output": "def determine_ip_address():\n    \"\"\"Return the first IP address for an ethernet interface on the system.\"\"\"\n    addrs = [\n        x.address for k, v in psutil.net_if_addrs().items() if k[0] == \"e\"\n        for x in v if x.family == AddressFamily.AF_INET\n    ]\n    return addrs[0]", "language": "python"}
{"input": "NB: Taken straight from: https://github.com/IvanVergiliev/2048-react/blob/master/src/board.js with no modification except to format it for CommonJS and fix lint/flow errors", "output": "function(matrix) {\n  const rows = matrix.length;\n  const columns = matrix[0].length;\n  const res = [];\n  for (let row = 0; row < rows; ++row) {\n    res.push([]);\n    for (let column = 0; column < columns; ++column) {\n      res[row][column] = matrix[column][columns - row - 1];\n    }\n  }\n  return res;\n}", "language": "javascript"}
{"input": "Get tokens of arrow(`=>`) and before/after arrow.\n@param {ASTNode} node The arrow function node.\n@returns {Object} Tokens of arrow and before/after arrow.", "output": "function getTokens(node) {\n            const arrow = sourceCode.getTokenBefore(node.body, astUtils.isArrowToken);\n\n            return {\n                before: sourceCode.getTokenBefore(arrow),\n                arrow,\n                after: sourceCode.getTokenAfter(arrow)\n            };\n        }", "language": "javascript"}
{"input": "Fired when the user starts dragging an appointment.", "output": "function (oEvent) {\n\t\t\t\t\tif (!oRow.getEnableAppointmentsResize() || oTimeline._isOneMonthIntervalOnSmallSizes() || !oTimeline._isResizingPerformed()) {\n\t\t\t\t\t\toEvent.preventDefault();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar oDragSession = oEvent.getParameter(\"dragSession\"),\n\t\t\t\t\t\t$CalendarRowAppsOverlay = oTimeline.$().find(\".sapUiCalendarRowAppsOverlay\"),\n\t\t\t\t\t\t$Indicator = jQuery(oDragSession.getIndicator()),\n\t\t\t\t\t\t$DraggedControl = oDragSession.getDragControl().$();\n\n\t\t\t\t\t$Indicator.addClass(\"sapUiDnDIndicatorHide\");\n\t\t\t\t\tsetTimeout(function () {\n\t\t\t\t\t\t$CalendarRowAppsOverlay.addClass(\"sapUiCalendarRowAppsOverlayDragging\");\n\t\t\t\t\t}, 0);\n\n\t\t\t\t\tjQuery(document).one(\"dragend\", function () {\n\t\t\t\t\t\t$CalendarRowAppsOverlay.removeClass(\"sapUiCalendarRowAppsOverlayDragging\");\n\t\t\t\t\t\t$Indicator.removeClass(\"sapUiDnDIndicatorHide\");\n\t\t\t\t\t\t$DraggedControl.css({\n\t\t\t\t\t\t\twidth: \"auto\",\n\t\t\t\t\t\t\t\"min-width\": \"auto\",\n\t\t\t\t\t\t\t\"z-index\": \"auto\",\n\t\t\t\t\t\t\topacity: 1\n\t\t\t\t\t\t});\n\t\t\t\t\t});\n\n\t\t\t\t\tif (!Device.browser.msie && !Device.browser.edge) {\n\t\t\t\t\t\toEvent.getParameter(\"browserEvent\").dataTransfer.setDragImage(getResizeGhost(), 0, 0);\n\t\t\t\t\t}\n\t\t\t\t}", "language": "javascript"}
{"input": "This function wraps a text in a span tag so that it can be represented in an HTML control.\n@param {string} sText\n@returns {string}\n@private", "output": "function (sText) {\n\t\t\treturn '<span class=\"fs0875\">' + JSDocUtil.formatTextBlock(sText, {\n\t\t\t\tlinkFormatter: function (target, text) {\n\n\t\t\t\t\tvar p;\n\n\t\t\t\t\ttarget = target.trim().replace(/\\.prototype\\./g, \"#\");\n\t\t\t\t\tp = target.indexOf(\"#\");\n\t\t\t\t\tif ( p === 0 ) {\n\t\t\t\t\t\t// a relative reference - we can't support that\n\t\t\t\t\t\treturn \"<code>\" + target.slice(1) + \"</code>\";\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( p > 0 ) {\n\t\t\t\t\t\ttext = text || target; // keep the full target in the fallback text\n\t\t\t\t\t\ttarget = target.slice(0, p);\n\t\t\t\t\t}\n\n\t\t\t\t\treturn \"<a class=\\\"jsdoclink\\\" href=\\\"#\\\" data-sap-ui-target=\\\"\" + target + \"\\\">\" + (text || target) + \"</a>\";\n\n\t\t\t\t}\n\t\t\t}) + '</span>';\n\t\t}", "language": "javascript"}
{"input": "Entries of the CoordinateMatrix stored as an RDD of\n        MatrixEntries.\n\n        >>> mat = CoordinateMatrix(sc.parallelize([MatrixEntry(0, 0, 1.2),\n        ...                                        MatrixEntry(6, 4, 2.1)]))\n        >>> entries = mat.entries\n        >>> entries.first()\n        MatrixEntry(0, 0, 1.2)", "output": "def entries(self):\n        \"\"\"\n        Entries of the CoordinateMatrix stored as an RDD of\n        MatrixEntries.\n\n        >>> mat = CoordinateMatrix(sc.parallelize([MatrixEntry(0, 0, 1.2),\n        ...                                        MatrixEntry(6, 4, 2.1)]))\n        >>> entries = mat.entries\n        >>> entries.first()\n        MatrixEntry(0, 0, 1.2)\n        \"\"\"\n        # We use DataFrames for serialization of MatrixEntry entries\n        # from Java, so we first convert the RDD of entries to a\n        # DataFrame on the Scala/Java side. Then we map each Row in\n        # the DataFrame back to a MatrixEntry on this side.\n        entries_df = callMLlibFunc(\"getMatrixEntries\", self._java_matrix_wrapper._java_model)\n        entries = entries_df.rdd.map(lambda row: MatrixEntry(row[0], row[1], row[2]))\n        return entries", "language": "python"}
{"input": "Remove a key binding from _keymap\n\n@param {!string} key - a key-description string that may or may not be normalized.\n@param {?string} platform - OS from which to remove the binding (all platforms if unspecified)", "output": "function removeBinding(key, platform) {\n        if (!key || ((platform !== null) && (platform !== undefined) && (platform !== brackets.platform))) {\n            return;\n        }\n\n        var normalizedKey = normalizeKeyDescriptorString(key);\n\n        if (!normalizedKey) {\n            console.log(\"Failed to normalize \" + key);\n        } else if (_isKeyAssigned(normalizedKey)) {\n            var binding = _keyMap[normalizedKey],\n                command = CommandManager.get(binding.commandID),\n                bindings = _commandMap[binding.commandID];\n\n            // delete key binding record\n            delete _keyMap[normalizedKey];\n\n            if (bindings) {\n                // delete mapping from command to key binding\n                _commandMap[binding.commandID] = bindings.filter(function (b) {\n                    return (b.key !== normalizedKey);\n                });\n\n                if (command) {\n                    command.trigger(\"keyBindingRemoved\", {key: normalizedKey, displayKey: binding.displayKey});\n                }\n            }\n        }\n    }", "language": "javascript"}
{"input": "Return an article by its path\n@param {String} filePath\n@return {Object|undefined}", "output": "function getArticleByPath(filePath) {\n        var article = summary.getByPath(filePath);\n        if (!article) return undefined;\n\n        return JSONUtils.encodeSummaryArticle(article);\n    }", "language": "javascript"}
{"input": "Determines whether a node should be preceded by an additional space when removing parens\n@param {ASTNode} node node to evaluate; must be surrounded by parentheses\n@returns {boolean} `true` if a space should be inserted before the node\n@private", "output": "function requiresLeadingSpace(node) {\n            const leftParenToken = sourceCode.getTokenBefore(node);\n            const tokenBeforeLeftParen = sourceCode.getTokenBefore(node, 1);\n            const firstToken = sourceCode.getFirstToken(node);\n\n            return tokenBeforeLeftParen &&\n                tokenBeforeLeftParen.range[1] === leftParenToken.range[0] &&\n                leftParenToken.range[1] === firstToken.range[0] &&\n                !astUtils.canTokensBeAdjacent(tokenBeforeLeftParen, firstToken);\n        }", "language": "javascript"}
{"input": "Sets the level of the list and its sublists", "output": "function(oList, iLevel){\n\t\toList._iLevel = iLevel;\n\t\tvar aLists = oList.getSubLists();\n\t\tfor (var i = 0; i < aLists.length; i++) {\n\t\t\tsetLevel(aLists[i], iLevel + 1);\n\t\t}\n\t}", "language": "javascript"}
{"input": "Parse integer with power-of-2 suffix eg. 32k.", "output": "def parse_general_int(s):\n    \"\"\"Parse integer with power-of-2 suffix eg. 32k.\"\"\"\n    mo = re.match(r\"(\\d+)([KkMGT]?)$\", s)\n    if mo:\n        i, suffix = mo.group(1, 2)\n        v = int(i)\n        if suffix:\n            if suffix == \"K\" or suffix == \"k\":\n                v *= 1024\n            elif suffix == \"M\":\n                v *= (1024 * 1024)\n            elif suffix == \"G\":\n                v *= (1024 * 1024 * 1024)\n            elif suffix == \"T\":\n                v *= (1024 * 1024 * 1024 * 1024)\n            else:\n                raise ValueError(\"invalid integer string %s\" % s)\n        return v\n    else:\n        v = int(s)\n    return v", "language": "python"}
{"input": "Yield ``Requirement`` objects for each specification in `strs`\n\n    `strs` must be a string, or a (possibly-nested) iterable thereof.", "output": "def parse_requirements(strs):\n    \"\"\"Yield ``Requirement`` objects for each specification in `strs`\n\n    `strs` must be a string, or a (possibly-nested) iterable thereof.\n    \"\"\"\n    # create a steppable iterator, so we can handle \\-continuations\n    lines = iter(yield_lines(strs))\n\n    for line in lines:\n        # Drop comments -- a hash without a space may be in a URL.\n        if ' #' in line:\n            line = line[:line.find(' #')]\n        # If there is a line continuation, drop it, and append the next line.\n        if line.endswith('\\\\'):\n            line = line[:-2].strip()\n            try:\n                line += next(lines)\n            except StopIteration:\n                return\n        yield Requirement(line)", "language": "python"}
{"input": "Get the filter expression for this request.\n\nExpressions are represented by separate objects. If none exists so far, a\nnew expression object gets created.\n\n@returns {sap.ui.model.analytics.odata4analytics.FilterExpression} The filter object\nassociated to this request.\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.QueryResultRequest#getFilterExpression", "output": "function() {\n\t\t\tif (this._oFilterExpression == null) {\n\t\t\t\tvar oEntityType = this._oQueryResult.getEntityType();\n\t\t\t\tthis._oFilterExpression = new odata4analytics.FilterExpression(this._oQueryResult.getModel(), oEntityType\n\t\t\t\t\t\t.getSchema(), oEntityType);\n\t\t\t}\n\t\t\treturn this._oFilterExpression;\n\t\t}", "language": "javascript"}
{"input": "Preprocessing used for Imagenet and similar problems.", "output": "def imagenet_preprocess_example(example, mode, resize_size=None,\n                                normalize=True):\n  \"\"\"Preprocessing used for Imagenet and similar problems.\"\"\"\n  resize_size = resize_size or [299, 299]\n  assert resize_size[0] == resize_size[1]\n\n  image = example[\"inputs\"]\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    image = preprocess_for_train(image, image_size=resize_size[0],\n                                 normalize=normalize)\n  else:\n    image = preprocess_for_eval(image, image_size=resize_size[0],\n                                normalize=normalize)\n\n  example[\"inputs\"] = image\n  return example", "language": "python"}
{"input": "Determine the URL corresponding to Python object", "output": "def linkcode_resolve(domain, info):\n    \"\"\"\n    Determine the URL corresponding to Python object\n    \"\"\"\n    if domain != 'py':\n        return None\n\n    modname = info['module']\n    fullname = info['fullname']\n\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split('.'):\n        try:\n            obj = getattr(obj, part)\n        except AttributeError:\n            return None\n\n    try:\n        # inspect.unwrap() was added in Python version 3.4\n        if sys.version_info >= (3, 5):\n            fn = inspect.getsourcefile(inspect.unwrap(obj))\n        else:\n            fn = inspect.getsourcefile(obj)\n    except TypeError:\n        fn = None\n    if not fn:\n        return None\n\n    try:\n        source, lineno = inspect.getsourcelines(obj)\n    except OSError:\n        lineno = None\n\n    if lineno:\n        linespec = \"#L{:d}-L{:d}\".format(lineno, lineno + len(source) - 1)\n    else:\n        linespec = \"\"\n\n    fn = os.path.relpath(fn, start=os.path.dirname(pandas.__file__))\n\n    if '+' in pandas.__version__:\n        return (\"http://github.com/pandas-dev/pandas/blob/master/pandas/\"\n                \"{}{}\".format(fn, linespec))\n    else:\n        return (\"http://github.com/pandas-dev/pandas/blob/\"\n                \"v{}/pandas/{}{}\".format(pandas.__version__, fn, linespec))", "language": "python"}
{"input": "Return a resource finder for a package.\n    :param package: The name of the package.\n    :return: A :class:`ResourceFinder` instance for the package.", "output": "def finder(package):\n    \"\"\"\n    Return a resource finder for a package.\n    :param package: The name of the package.\n    :return: A :class:`ResourceFinder` instance for the package.\n    \"\"\"\n    if package in _finder_cache:\n        result = _finder_cache[package]\n    else:\n        if package not in sys.modules:\n            __import__(package)\n        module = sys.modules[package]\n        path = getattr(module, '__path__', None)\n        if path is None:\n            raise DistlibException('You cannot get a finder for a module, '\n                                   'only for a package')\n        loader = getattr(module, '__loader__', None)\n        finder_maker = _finder_registry.get(type(loader))\n        if finder_maker is None:\n            raise DistlibException('Unable to locate finder for %r' % package)\n        result = finder_maker(module)\n        _finder_cache[package] = result\n    return result", "language": "python"}
{"input": "This is basically a rebuild of\nthe rails auto_link_urls text helper", "output": "function _convertUrlsToLinks(str) {\n    return str.replace(URL_REG_EXP, function(match, url) {\n      var punctuation = (url.match(TRAILING_CHAR_REG_EXP) || [])[1] || \"\",\n          opening     = BRACKETS[punctuation];\n      url = url.replace(TRAILING_CHAR_REG_EXP, \"\");\n\n      if (url.split(opening).length > url.split(punctuation).length) {\n        url = url + punctuation;\n        punctuation = \"\";\n      }\n      var realUrl    = url,\n          displayUrl = url;\n      if (url.length > MAX_DISPLAY_LENGTH) {\n        displayUrl = displayUrl.substr(0, MAX_DISPLAY_LENGTH) + \"...\";\n      }\n      // Add http prefix if necessary\n      if (realUrl.substr(0, 4) === \"www.\") {\n        realUrl = \"http://\" + realUrl;\n      }\n\n      return '<a href=\"' + realUrl + '\">' + displayUrl + '</a>' + punctuation;\n    });\n  }", "language": "javascript"}
{"input": "### Ensure Active Theme Ensure there's a properly set & mounted active theme before attempting to serve a blog request If there is no active theme, throw an error Else, ensure the active theme is mounted", "output": "function ensureActiveTheme(req, res, next) {\n    // CASE: this means that the theme hasn't been loaded yet i.e. there is no active theme\n    if (!activeTheme.get()) {\n        // This is the one place we ACTUALLY throw an error for a missing theme as it's a request we cannot serve\n        return next(new common.errors.InternalServerError({\n            // We use the settingsCache here, because the setting will be set,\n            // even if the theme itself is not usable because it is invalid or missing.\n            message: common.i18n.t('errors.middleware.themehandler.missingTheme', {theme: settingsCache.get('active_theme')})\n        }));\n    }\n\n    // CASE: bootstrap theme validation failed, we would like to show the errors on the blog [only production]\n    if (activeTheme.get().error && config.get('env') === 'production') {\n        return next(new common.errors.InternalServerError({\n            // We use the settingsCache here, because the setting will be set,\n            // even if the theme itself is not usable because it is invalid or missing.\n            message: common.i18n.t('errors.middleware.themehandler.invalidTheme', {theme: settingsCache.get('active_theme')}),\n            errorDetails: activeTheme.get().error.errorDetails\n        }));\n    }\n\n    // If the active theme has not yet been mounted, mount it into express\n    if (!activeTheme.get().mounted) {\n        activeTheme.get().mount(req.app);\n    }\n\n    next();\n}", "language": "javascript"}
{"input": "Split labels into `num_splits` and\n        generate candidates based on log-uniform distribution.", "output": "def generate_samples(label, num_splits, sampler):\n    \"\"\" Split labels into `num_splits` and\n        generate candidates based on log-uniform distribution.\n    \"\"\"\n    def listify(x):\n        return x if isinstance(x, list) else [x]\n    label_splits = listify(label.split(num_splits, axis=0))\n    prob_samples = []\n    prob_targets = []\n    samples = []\n    for label_split in label_splits:\n        label_split_2d = label_split.reshape((-1,1))\n        sampled_value = sampler.draw(label_split_2d)\n        sampled_classes, exp_cnt_true, exp_cnt_sampled = sampled_value\n        samples.append(sampled_classes.astype(np.float32))\n        prob_targets.append(exp_cnt_true.astype(np.float32).reshape((-1,1)))\n        prob_samples.append(exp_cnt_sampled.astype(np.float32))\n    return samples, prob_samples, prob_targets", "language": "python"}
{"input": ">>> package = yarg.get('yarg')\n            >>> package.downloads\n            Downloads(day=50100, week=367941, month=1601938)  # I wish", "output": "def downloads(self):\n        \"\"\"\n            >>> package = yarg.get('yarg')\n            >>> package.downloads\n            Downloads(day=50100, week=367941, month=1601938)  # I wish\n        \"\"\"\n        _downloads = self._package['downloads']\n        downloads = namedtuple('Downloads', 'day week month')\n        return downloads(day=_downloads['last_day'],\n                         week=_downloads['last_week'],\n                         month=_downloads['last_month'])", "language": "python"}
{"input": "Read the PyPI access configuration as supported by distutils, getting\n        PyPI to do the actual work. This populates ``username``, ``password``,\n        ``realm`` and ``url`` attributes from the configuration.", "output": "def read_configuration(self):\n        \"\"\"\n        Read the PyPI access configuration as supported by distutils, getting\n        PyPI to do the actual work. This populates ``username``, ``password``,\n        ``realm`` and ``url`` attributes from the configuration.\n        \"\"\"\n        # get distutils to do the work\n        c = self._get_pypirc_command()\n        c.repository = self.url\n        cfg = c._read_pypirc()\n        self.username = cfg.get('username')\n        self.password = cfg.get('password')\n        self.realm = cfg.get('realm', 'pypi')\n        self.url = cfg.get('repository', self.url)", "language": "python"}
{"input": "Returns the default locations of ticks.", "output": "def _get_default_locs(self, vmin, vmax):\n        \"Returns the default locations of ticks.\"\n\n        if self.plot_obj.date_axis_info is None:\n            self.plot_obj.date_axis_info = self.finder(vmin, vmax, self.freq)\n\n        locator = self.plot_obj.date_axis_info\n\n        if self.isminor:\n            return np.compress(locator['min'], locator['val'])\n        return np.compress(locator['maj'], locator['val'])", "language": "python"}
{"input": "Restore State.", "output": "def restore_state(output_dir):\n  \"\"\"Restore State.\"\"\"\n  params_file = os.path.join(output_dir, \"model.pkl\")\n  if not gfile.exists(params_file):\n    return State(step=None, params=None, history=trax_history.History())\n\n  with gfile.GFile(params_file, \"rb\") as f:\n    (params, step, history) = pickle.load(f)\n  log(\"Model loaded from %s at step %d\" % (params_file, step))\n  logging.debug(\"From loaded model : history = %s\", history)\n  return State(step=step, params=params, history=history)", "language": "python"}
{"input": "Collapses all foldable regions in the current document. Folding is done up to a level 'n'\nwhich is defined in the `maxFoldLevel` preference. Levels refer to fold heirarchies e.g., for the following\ncode fragment, the function is level 1, the if statement is level 2 and the forEach is level 3\n\nfunction sample() {\nif (debug) {\nlogMessages.forEach(function (m) {\nconsole.debug(m);\n});\n}\n}", "output": "function collapseAll() {\n        var editor = EditorManager.getFocusedEditor();\n        if (editor) {\n            var cm = editor._codeMirror;\n            CodeMirror.commands.foldToLevel(cm);\n        }\n    }", "language": "javascript"}
{"input": "Continue training a pre-trained model.\n\n        Create and return an optimizer, and initialize \"rehearsal\" for any pipeline\n        component that has a .rehearse() method. Rehearsal is used to prevent\n        models from \"forgetting\" their initialised \"knowledge\". To perform\n        rehearsal, collect samples of text you want the models to retain performance\n        on, and call nlp.rehearse() with a batch of Doc objects.", "output": "def resume_training(self, sgd=None, **cfg):\n        \"\"\"Continue training a pre-trained model.\n\n        Create and return an optimizer, and initialize \"rehearsal\" for any pipeline\n        component that has a .rehearse() method. Rehearsal is used to prevent\n        models from \"forgetting\" their initialised \"knowledge\". To perform\n        rehearsal, collect samples of text you want the models to retain performance\n        on, and call nlp.rehearse() with a batch of Doc objects.\n        \"\"\"\n        if cfg.get(\"device\", -1) >= 0:\n            util.use_gpu(cfg[\"device\"])\n            if self.vocab.vectors.data.shape[1] >= 1:\n                self.vocab.vectors.data = Model.ops.asarray(self.vocab.vectors.data)\n        link_vectors_to_models(self.vocab)\n        if self.vocab.vectors.data.shape[1]:\n            cfg[\"pretrained_vectors\"] = self.vocab.vectors.name\n        if sgd is None:\n            sgd = create_default_optimizer(Model.ops)\n        self._optimizer = sgd\n        for name, proc in self.pipeline:\n            if hasattr(proc, \"_rehearsal_model\"):\n                proc._rehearsal_model = deepcopy(proc.model)\n        return self._optimizer", "language": "python"}
{"input": "Returns the mode object and mode name string at a given position\n@param {!CodeMirror} cm CodeMirror instance\n@param {!{line:number, ch:number}} pos Position to query for mode\n@param {boolean} precise If given, results in more current results. Suppresses caching.\n@return {mode:{Object}, name:string}", "output": "function getModeAt(cm, pos, precise) {\n        precise = precise || true;\n        var modeData = cm.getMode(),\n            name;\n\n        if (modeData.innerMode) {\n            modeData = CodeMirror.innerMode(modeData, getTokenAt(cm, pos, precise).state).mode;\n        }\n\n        name = (modeData.name === \"xml\") ?\n                modeData.configuration : modeData.name;\n\n        return {mode: modeData, name: name};\n    }", "language": "javascript"}
{"input": "Passes the result to BayesOpt unless early terminated or errored", "output": "def on_trial_complete(self,\n                          trial_id,\n                          result=None,\n                          error=False,\n                          early_terminated=False):\n        \"\"\"Passes the result to BayesOpt unless early terminated or errored\"\"\"\n        if result:\n            self.optimizer.register(\n                params=self._live_trial_mapping[trial_id],\n                target=result[self._reward_attr])\n\n        del self._live_trial_mapping[trial_id]", "language": "python"}
{"input": "Downloading and preparing the dataset.\n\n  Args:\n    tmp_dir: tem directory\n    data_dir: data directory\n    vocab_size: size of vocabulary\n    vocab_filename: name of vocab file", "output": "def _prepare_lambada_data(tmp_dir, data_dir, vocab_size, vocab_filename):\n  \"\"\"Downloading and preparing the dataset.\n\n  Args:\n    tmp_dir: tem directory\n    data_dir: data directory\n    vocab_size: size of vocabulary\n    vocab_filename: name of vocab file\n\n  \"\"\"\n\n  if not tf.gfile.Exists(data_dir):\n    tf.gfile.MakeDirs(data_dir)\n\n  file_path = generator_utils.maybe_download(tmp_dir, _TAR, _URL)\n  tar_all = tarfile.open(file_path)\n  tar_all.extractall(tmp_dir)\n  tar_all.close()\n  tar_train = tarfile.open(os.path.join(tmp_dir, \"train-novels.tar\"))\n  tar_train.extractall(tmp_dir)\n  tar_train.close()\n\n  vocab_path = os.path.join(data_dir, vocab_filename)\n  if not tf.gfile.Exists(vocab_path):\n    with tf.gfile.GFile(os.path.join(tmp_dir, _VOCAB), \"r\") as infile:\n      reader = csv.reader(infile, delimiter=\"\\t\")\n      words = [row[0] for row in reader]\n      words = [_UNK] + words[:vocab_size]\n    with tf.gfile.GFile(vocab_path, \"w\") as outfile:\n      outfile.write(\"\\n\".join(words))", "language": "python"}
{"input": "Build a simple CNN text classifier, given a token-to-vector model as inputs.\n    If exclusive_classes=True, a softmax non-linearity is applied, so that the\n    outputs sum to 1. If exclusive_classes=False, a logistic non-linearity\n    is applied instead, so that outputs are in the range [0, 1].", "output": "def build_simple_cnn_text_classifier(tok2vec, nr_class, exclusive_classes=False, **cfg):\n    \"\"\"\n    Build a simple CNN text classifier, given a token-to-vector model as inputs.\n    If exclusive_classes=True, a softmax non-linearity is applied, so that the\n    outputs sum to 1. If exclusive_classes=False, a logistic non-linearity\n    is applied instead, so that outputs are in the range [0, 1].\n    \"\"\"\n    with Model.define_operators({\">>\": chain}):\n        if exclusive_classes:\n            output_layer = Softmax(nr_class, tok2vec.nO)\n        else:\n            output_layer = (\n                zero_init(Affine(nr_class, tok2vec.nO, drop_factor=0.0)) >> logistic\n            )\n        model = tok2vec >> flatten_add_lengths >> Pooling(mean_pool) >> output_layer\n    model.tok2vec = chain(tok2vec, flatten)\n    model.nO = nr_class\n    return model", "language": "python"}
{"input": "Finds an element by a partial match of its link text.\n\n        :Args:\n         - link_text: The text of the element to partially match on.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            ::\n\n                element = driver.find_element_by_partial_link_text('Sign')", "output": "def find_element_by_partial_link_text(self, link_text):\n        \"\"\"\n        Finds an element by a partial match of its link text.\n\n        :Args:\n         - link_text: The text of the element to partially match on.\n\n        :Returns:\n         - WebElement - the element if it was found\n\n        :Raises:\n         - NoSuchElementException - if the element wasn't found\n\n        :Usage:\n            ::\n\n                element = driver.find_element_by_partial_link_text('Sign')\n        \"\"\"\n        return self.find_element(by=By.PARTIAL_LINK_TEXT, value=link_text)", "language": "python"}
{"input": "Return the size of the dtype of the item of the underlying data.\n\n        .. deprecated:: 0.23.0", "output": "def itemsize(self):\n        \"\"\"\n        Return the size of the dtype of the item of the underlying data.\n\n        .. deprecated:: 0.23.0\n        \"\"\"\n        warnings.warn(\"{obj}.itemsize is deprecated and will be removed \"\n                      \"in a future version\".format(obj=type(self).__name__),\n                      FutureWarning, stacklevel=2)\n        return self._ndarray_values.itemsize", "language": "python"}
{"input": "We wrap the _evaluate method so we can track `seen` nodes, we push an item\nto the map before we actually evaluate it so we can deopt on self recursive\nnodes such as:\n\nvar g = a ? 1 : 2,\na = g * this.foo", "output": "function evaluateCached(path, state) {\n  const { node } = path;\n  const { seen } = state;\n\n  if (seen.has(node)) {\n    const existing = seen.get(node);\n    if (existing.resolved) {\n      return existing.value;\n    } else {\n      deopt(path, state);\n      return;\n    }\n  } else {\n    const item = { resolved: false };\n    seen.set(node, item);\n\n    const val = _evaluate(path, state);\n    if (state.confident) {\n      item.resolved = true;\n      item.value = val;\n    }\n    return val;\n  }\n}", "language": "javascript"}
{"input": "/*\nCalculates Gregorian and Julian calendar dates from the Julian Day number\n(jdn) for the period since jdn=-34839655 (i.e. the year -100100 of both\ncalendars) to some millions years ahead of the present.\n@param jdn Julian Day number\n@return\ngy: Calendar year (years BC numbered 0, -1, -2, ...)\ngm: Calendar month (1 to 12)\ngd: Calendar day of the month M (1 to 28/29/30/31)", "output": "function d2g(jdn) {\n\t\tvar j, i, gd, gm, gy;\n\t\tj = 4 * jdn + 139361631;\n\t\tj = j + div(div(4 * jdn + 183187720, 146097) * 3, 4) * 4 - 3908;\n\t\ti = div(mod(j, 1461), 4) * 5 + 308;\n\t\tgd = div(mod(i, 153), 5) + 1;\n\t\tgm = mod(div(i, 153), 12) + 1;\n\t\tgy = div(j, 1461) - 100100 + div(8 - gm, 6);\n\t\treturn\t{\n\t\t\tyear: gy,\n\t\t\tmonth: gm - 1,\n\t\t\tday: gd\n\t\t};\n\t}", "language": "javascript"}
{"input": "split lines into code and non-code blocks\n\n    Returns\n    -------\n    iterator of (bool, str, list of str)\n      - if it is a code block\n      - source language\n      - lines of source", "output": "def _get_blocks(lines):\n    \"\"\"split lines into code and non-code blocks\n\n    Returns\n    -------\n    iterator of (bool, str, list of str)\n      - if it is a code block\n      - source language\n      - lines of source\n    \"\"\"\n    cur_block = []\n    pre_lang = None\n    pre_in_code = None\n    for (l, in_code, cur_lang, _) in _parse_code_lines(lines):\n        if in_code != pre_in_code:\n            if pre_in_code and len(cur_block) >= 2:\n                cur_block = cur_block[1:-1] # remove ```\n            # remove empty lines at head\n            while len(cur_block) > 0:\n                if len(cur_block[0]) == 0:\n                    cur_block.pop(0)\n                else:\n                    break\n            # remove empty lines at tail\n            while len(cur_block) > 0:\n                if len(cur_block[-1]) == 0:\n                    cur_block.pop()\n                else:\n                    break\n            if len(cur_block):\n                yield (pre_in_code, pre_lang, cur_block)\n            cur_block = []\n        cur_block.append(l)\n        pre_lang = cur_lang\n        pre_in_code = in_code\n    if len(cur_block):\n        yield (pre_in_code, pre_lang, cur_block)", "language": "python"}
{"input": "Generate the implementation of HMC", "output": "def HMC(sym, data_inputs, X, Y, X_test, Y_test, sample_num,\n        initializer=None, noise_precision=1 / 9.0, prior_precision=0.1,\n        learning_rate=1E-6, L=10, dev=mx.gpu()):\n    \"\"\"Generate the implementation of HMC\"\"\"\n    label_key = list(set(data_inputs.keys()) - set(['data']))[0]\n    exe, exe_params, exe_grads, _ = get_executor(sym, dev, data_inputs, initializer)\n    exe.arg_dict['data'][:] = X\n    exe.arg_dict[label_key][:] = Y\n    sample_pool = []\n    accept_num = 0\n    start = time.time()\n    for i in range(sample_num):\n        sample_params, is_accept = step_HMC(exe, exe_params, exe_grads, label_key, noise_precision,\n                                            prior_precision, L, learning_rate)\n        accept_num += is_accept\n\n        if (i + 1) % 10 == 0:\n            sample_pool.append(sample_params)\n            if (i + 1) % 100000 == 0:\n                end = time.time()\n                print(\"Current Iter Num: %d\" % (i + 1), \"Time Spent: %f\" % (end - start), \"MSE:\",\n                      sample_test_regression(exe, X=X_test, Y=Y_test, sample_pool=sample_pool,\n                                             minibatch_size=Y.shape[0],\n                                             save_path='regression_HMC.txt'))\n                start = time.time()\n        exe.copy_params_from(sample_params)\n    print('accept ratio', accept_num / float(sample_num))\n    return sample_pool", "language": "python"}
{"input": "Docstring is inherited from the LGBMModel.", "output": "def predict(self, X, raw_score=False, num_iteration=None,\n                pred_leaf=False, pred_contrib=False, **kwargs):\n        \"\"\"Docstring is inherited from the LGBMModel.\"\"\"\n        result = self.predict_proba(X, raw_score, num_iteration,\n                                    pred_leaf, pred_contrib, **kwargs)\n        if raw_score or pred_leaf or pred_contrib:\n            return result\n        else:\n            class_index = np.argmax(result, axis=1)\n            return self._le.inverse_transform(class_index)", "language": "python"}
{"input": "Bottom transformation for target images.", "output": "def image_targets_bottom(x, model_hparams, vocab_size):\n  \"\"\"Bottom transformation for target images.\"\"\"\n  pixel_embedding_size = 64\n  inputs = x\n  with tf.variable_scope(\"image_modality\"):\n    if not tf.executing_eagerly():\n      tf.summary.image(\n          \"targets_bottom\",\n          common_layers.tpu_safe_image_summary(inputs),\n          max_outputs=1)\n    inputs_shape = common_layers.shape_list(inputs)\n    if len(inputs_shape) != 4:\n      raise ValueError(\"Assuming images given as int tensors in the format \"\n                       \"[batch, height, width, channels] (256 values).\")\n    # We embed each of 256=vocab_size possible pixel values.\n    embedding_var = tf.get_variable(\n        \"pixel_embedding\",\n        [vocab_size, pixel_embedding_size])\n    hot_inputs = tf.one_hot(tf.to_int32(inputs), vocab_size)\n    hot_inputs = tf.reshape(hot_inputs, [-1, vocab_size])\n    embedded = tf.matmul(hot_inputs, embedding_var)\n    # Let's now merge all channels that were embedded into a single vector.\n    merged_size = pixel_embedding_size * inputs_shape[3]\n    embedded = tf.reshape(embedded, inputs_shape[:3] + [merged_size])\n    merged = tf.layers.dense(\n        embedded,\n        model_hparams.hidden_size,\n        name=\"merge_pixel_embedded_channels\")\n    return merged", "language": "python"}
{"input": "Given a (possibly higher order) tensor of ids with shape\n    (d1, ..., dn, sequence_length)\n    Return a view that's (d1 * ... * dn, sequence_length).\n    If original tensor is 1-d or 2-d, return it as is.", "output": "def combine_initial_dims(tensor: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Given a (possibly higher order) tensor of ids with shape\n    (d1, ..., dn, sequence_length)\n    Return a view that's (d1 * ... * dn, sequence_length).\n    If original tensor is 1-d or 2-d, return it as is.\n    \"\"\"\n    if tensor.dim() <= 2:\n        return tensor\n    else:\n        return tensor.view(-1, tensor.size(-1))", "language": "python"}
{"input": "Generate an array of manifest entries using webpack's compilation data.\n\n@param {Object} compilation webpack compilation\n@param {Object} config\n@return {Array<workbox.build.ManifestEntry>}\n\n@private", "output": "function getManifestEntriesFromCompilation(compilation, config) {\n  const blacklistedChunkNames = config.excludeChunks;\n  const whitelistedChunkNames = config.chunks;\n  const {assets, chunks} = compilation;\n  const {publicPath} = compilation.options.output;\n\n  const assetMetadata = generateMetadataForAssets(assets, chunks);\n  const filteredAssetMetadata = filterAssets(assetMetadata,\n      whitelistedChunkNames, blacklistedChunkNames);\n\n  const knownHashes = [\n    compilation.hash,\n    compilation.fullHash,\n    ...getKnownHashesFromAssets(filteredAssetMetadata),\n  ].filter((hash) => !!hash);\n\n  const manifestEntries = [];\n  for (const [file, metadata] of Object.entries(filteredAssetMetadata)) {\n    // Filter based on test/include/exclude options set in the config,\n    // following webpack's conventions.\n    // This matches the behavior of, e.g., UglifyJS's webpack plugin.\n    if (!ModuleFilenameHelpers.matchObject(config, file)) {\n      continue;\n    }\n\n    const publicURL = resolveWebpackURL(publicPath, file);\n    const manifestEntry = getEntry(knownHashes, publicURL, metadata.hash);\n    manifestEntries.push(manifestEntry);\n  }\n  return manifestEntries;\n}", "language": "javascript"}
{"input": "Return the maximum value of the Index or maximum along\n        an axis.\n\n        See Also\n        --------\n        numpy.ndarray.max\n        Series.max : Return the maximum value in a Series.", "output": "def max(self, axis=None, skipna=True, *args, **kwargs):\n        \"\"\"\n        Return the maximum value of the Index or maximum along\n        an axis.\n\n        See Also\n        --------\n        numpy.ndarray.max\n        Series.max : Return the maximum value in a Series.\n        \"\"\"\n        nv.validate_max(args, kwargs)\n        nv.validate_minmax_axis(axis)\n\n        if not len(self):\n            return self._na_value\n\n        i8 = self.asi8\n        try:\n            # quick check\n            if len(i8) and self.is_monotonic:\n                if i8[-1] != iNaT:\n                    return self._box_func(i8[-1])\n\n            if self.hasnans:\n                if skipna:\n                    max_stamp = self[~self._isnan].asi8.max()\n                else:\n                    return self._na_value\n            else:\n                max_stamp = i8.max()\n            return self._box_func(max_stamp)\n        except ValueError:\n            return self._na_value", "language": "python"}
{"input": "The list from pypi is really a list of versions. We want a list of\n    packages with the list of versions stored inline. This converts the\n    list from pypi into one we can use.", "output": "def transform_hits(hits):\n    \"\"\"\n    The list from pypi is really a list of versions. We want a list of\n    packages with the list of versions stored inline. This converts the\n    list from pypi into one we can use.\n    \"\"\"\n    packages = OrderedDict()\n    for hit in hits:\n        name = hit['name']\n        summary = hit['summary']\n        version = hit['version']\n\n        if name not in packages.keys():\n            packages[name] = {\n                'name': name,\n                'summary': summary,\n                'versions': [version],\n            }\n        else:\n            packages[name]['versions'].append(version)\n\n            # if this is the highest version, replace summary and score\n            if version == highest_version(packages[name]['versions']):\n                packages[name]['summary'] = summary\n\n    return list(packages.values())", "language": "python"}
{"input": "Get the index of the current iteration.\n\n        Returns\n        -------\n        cur_iter : int\n            The index of the current iteration.", "output": "def current_iteration(self):\n        \"\"\"Get the index of the current iteration.\n\n        Returns\n        -------\n        cur_iter : int\n            The index of the current iteration.\n        \"\"\"\n        out_cur_iter = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(\n            self.handle,\n            ctypes.byref(out_cur_iter)))\n        return out_cur_iter.value", "language": "python"}
{"input": "Build convolutional GRU with diagonal gating as in ImprovedNGPU.", "output": "def ConvDiagonalGRU(units, kernel_size=(3, 3)):\n  \"\"\"Build convolutional GRU with diagonal gating as in ImprovedNGPU.\"\"\"\n\n  def BuildConv():\n    return layers.Conv(filters=units, kernel_size=kernel_size, padding='SAME')\n\n  return layers.GeneralGRUCell(\n      candidate_transform=BuildConv,\n      memory_transform=DiagonalGate,\n      gate_nonlinearity=layers.HardSigmoid,\n      candidate_nonlinearity=layers.HardTanh)", "language": "python"}
{"input": "Function: isPopupTrigger\n\nReturns true if the event is a popup trigger. This implementation\nreturns true if the right button or the left button and control was\npressed on a Mac.", "output": "function(evt)\n\t{\n\t\treturn mxEvent.isRightMouseButton(evt) || (mxClient.IS_MAC && mxEvent.isControlDown(evt) &&\n\t\t\t!mxEvent.isShiftDown(evt) && !mxEvent.isMetaDown(evt) && !mxEvent.isAltDown(evt));\n\t}", "language": "javascript"}
{"input": "User can get data raw indices on 'axisAreaSelected' event received.\n\n@public\n@param {string} activeState 'active' or 'inactive' or 'normal'\n@return {Array.<number>} Raw indices", "output": "function (activeState) {\n        var coordSys = this.coordinateSystem;\n        var data = this.getData();\n        var indices = [];\n\n        coordSys.eachActiveState(data, function (theActiveState, dataIndex) {\n            if (activeState === theActiveState) {\n                indices.push(data.getRawIndex(dataIndex));\n            }\n        });\n\n        return indices;\n    }", "language": "javascript"}
{"input": "Returns a stream that transforms between our icon font's codepoint file\nand an Iconjar ijmap.", "output": "function generateIjmap(ijmapPath) {\n  return through2.obj((codepointsFile, encoding, callback) => {\n    const ijmap = {\n      icons: codepointsToIjmap(codepointsFile.contents.toString())\n    };\n\n    callback(null, new File({\n      path: ijmapPath,\n      contents: new Buffer(JSON.stringify(ijmap), 'utf8')\n    }));\n\n    function codepointsToIjmap(codepoints) {\n      return _(codepoints)\n        .split('\\n')       // split into lines\n        .reject(_.isEmpty) // remove empty lines\n        .reduce((codepointMap, line) => {   // build up the codepoint map\n          let [ name, codepoint ] = line.split(' ');\n          codepointMap[codepoint] = { name: titleize(humanize(name)) };\n          return codepointMap;\n        }, {});\n    }\n  });\n}", "language": "javascript"}
{"input": "a very simple example of listing locations from the mirror API", "output": "async function runSample() {\n  const res = await mirror.locations.list({});\n  console.log(res.data);\n}", "language": "javascript"}
{"input": "Return stroke length for progress circle\n\n@param {number} diameter Diameter of the container.\n@param {number} strokeWidth Stroke width to be used when drawing circle\n@param {number} value Percentage of circle (between 0 and 100)\n@param {number} limit Max percentage for circle\n\n@returns {number} Stroke length for progres circle", "output": "function getDashLength(diameter, strokeWidth, value, limit) {\n    return (diameter - strokeWidth) * $window.Math.PI * ((3 * (limit || 100) / 100) - (value/100));\n  }", "language": "javascript"}
{"input": "Get the current GPU memory usage.\n    Based on https://discuss.pytorch.org/t/access-gpu-memory-usage-in-pytorch/3192/4\n\n    Returns\n    -------\n    ``Dict[int, int]``\n        Keys are device ids as integers.\n        Values are memory usage as integers in MB.\n        Returns an empty ``dict`` if GPUs are not available.", "output": "def gpu_memory_mb() -> Dict[int, int]:\n    \"\"\"\n    Get the current GPU memory usage.\n    Based on https://discuss.pytorch.org/t/access-gpu-memory-usage-in-pytorch/3192/4\n\n    Returns\n    -------\n    ``Dict[int, int]``\n        Keys are device ids as integers.\n        Values are memory usage as integers in MB.\n        Returns an empty ``dict`` if GPUs are not available.\n    \"\"\"\n    # pylint: disable=bare-except\n    try:\n        result = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used',\n                                          '--format=csv,nounits,noheader'],\n                                         encoding='utf-8')\n        gpu_memory = [int(x) for x in result.strip().split('\\n')]\n        return {gpu: memory for gpu, memory in enumerate(gpu_memory)}\n    except FileNotFoundError:\n        # `nvidia-smi` doesn't exist, assume that means no GPU.\n        return {}\n    except:\n        # Catch *all* exceptions, because this memory check is a nice-to-have\n        # and we'd never want a training run to fail because of it.\n        logger.exception(\"unable to check gpu_memory_mb(), continuing\")\n        return {}", "language": "python"}
{"input": "Automatically add attributes to media elements where convenient.\ncrossorigin, playsinline.", "output": "function fixUpMediaElement (mediaEl) {\n  // Cross-origin.\n  var newMediaEl = setCrossOrigin(mediaEl);\n\n  // Plays inline for mobile.\n  if (newMediaEl.tagName && newMediaEl.tagName.toLowerCase() === 'video') {\n    newMediaEl.setAttribute('playsinline', '');\n    newMediaEl.setAttribute('webkit-playsinline', '');\n  }\n\n  if (newMediaEl !== mediaEl) {\n    mediaEl.parentNode.appendChild(newMediaEl);\n    mediaEl.parentNode.removeChild(mediaEl);\n  }\n  return newMediaEl;\n}", "language": "javascript"}
{"input": "Formats the result to be an operand for a logical or comparison operator. Handles\nconstants accordingly.\n\n@param {object} oPathValue\npath and value information pointing to the parameters array (for a possible error\nmessage, see above)\n@param {number} iIndex\nthe parameter index (for a possible error message)\n@param {object} oResult\na result object with category\n@param {boolean} bWrapExpression\nif true, wrap an expression in <code>oResult</code> with \"()\"\n@returns {string}\nthe formatted result", "output": "function (oPathValue, iIndex, oResult, bWrapExpression) {\n\t\t\tvar oDate;\n\n\t\t\tif (oResult.result === \"constant\") {\n\t\t\t\tswitch (oResult.category) {\n\t\t\t\t\tcase \"boolean\":\n\t\t\t\t\tcase \"number\":\n\t\t\t\t\t\treturn oResult.value;\n\t\t\t\t\tcase \"date\":\n\t\t\t\t\t\toDate = Expression.parseDate(oResult.value);\n\t\t\t\t\t\tif (!oDate) {\n\t\t\t\t\t\t\tBasics.error(Basics.descend(oPathValue, iIndex),\n\t\t\t\t\t\t\t\t\t\"Invalid Date \" + oResult.value);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn String(oDate.getTime());\n\t\t\t\t\tcase \"datetime\":\n\t\t\t\t\t\toDate = Expression.parseDateTimeOffset(oResult.value);\n\t\t\t\t\t\tif (!oDate) {\n\t\t\t\t\t\t\tBasics.error(Basics.descend(oPathValue, iIndex),\n\t\t\t\t\t\t\t\t\t\"Invalid DateTime \" + oResult.value);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn String(oDate.getTime());\n\t\t\t\t\tcase \"time\":\n\t\t\t\t\t\treturn String(Expression.parseTimeOfDay(oResult.value).getTime());\n\t\t\t\t\t// no default\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (bWrapExpression) {\n\t\t\t\tExpression.wrapExpression(oResult);\n\t\t\t}\n\t\t\treturn Basics.resultToString(oResult, true);\n\t\t}", "language": "javascript"}
{"input": "Hparams for transformer on LM for pretraining/finetuning/mixing.", "output": "def transformer_tall():\n  \"\"\"Hparams for transformer on LM for pretraining/finetuning/mixing.\"\"\"\n  hparams = transformer_base()\n  hparams.batch_size = 2048\n  hparams.hidden_size = 768\n  hparams.filter_size = 3072\n  hparams.num_hidden_layers = 12\n  hparams.num_heads = 12\n  hparams.label_smoothing = 0.0\n  hparams.max_length = 1024\n  hparams.eval_drop_long_sequences = True\n  hparams.multiproblem_mixing_schedule = \"pretrain\"\n  hparams.multiproblem_vocab_size = 65536\n  hparams.clip_grad_norm = 1.0\n  return hparams", "language": "python"}
{"input": "Validate regular expression literals\n@param {ASTNode} node node to validate\n@returns {void}\n@private", "output": "function checkLiteral(node) {\n            const token = sourceCode.getFirstToken(node),\n                nodeType = token.type,\n                nodeValue = token.value;\n\n            if (nodeType === \"RegularExpression\") {\n                checkRegex(node, nodeValue, token.range[0]);\n            }\n        }", "language": "javascript"}
{"input": "Metadata for rollouts.", "output": "def _rollout_metadata(batch_env):\n  \"\"\"Metadata for rollouts.\"\"\"\n  batch_env_shape = batch_env.observ.get_shape().as_list()\n  batch_size = [batch_env_shape[0]]\n  shapes_types_names = [\n      # TODO(piotrmilos): possibly retrieve the observation type for batch_env\n      (batch_size + batch_env_shape[1:], batch_env.observ_dtype, \"observation\"),\n      (batch_size, tf.float32, \"reward\"),\n      (batch_size, tf.bool, \"done\"),\n      (batch_size + list(batch_env.action_shape), batch_env.action_dtype,\n       \"action\"),\n      (batch_size, tf.float32, \"pdf\"),\n      (batch_size, tf.float32, \"value_function\"),\n  ]\n  return shapes_types_names", "language": "python"}
{"input": "Makes this request field into a multipart request field.\n\n        This method overrides \"Content-Disposition\", \"Content-Type\" and\n        \"Content-Location\" headers to the request parameter.\n\n        :param content_type:\n            The 'Content-Type' of the request body.\n        :param content_location:\n            The 'Content-Location' of the request body.", "output": "def make_multipart(self, content_disposition=None, content_type=None,\n                       content_location=None):\n        \"\"\"\n        Makes this request field into a multipart request field.\n\n        This method overrides \"Content-Disposition\", \"Content-Type\" and\n        \"Content-Location\" headers to the request parameter.\n\n        :param content_type:\n            The 'Content-Type' of the request body.\n        :param content_location:\n            The 'Content-Location' of the request body.\n\n        \"\"\"\n        self.headers['Content-Disposition'] = content_disposition or 'form-data'\n        self.headers['Content-Disposition'] += '; '.join([\n            '', self._render_parts(\n                (('name', self._name), ('filename', self._filename))\n            )\n        ])\n        self.headers['Content-Type'] = content_type\n        self.headers['Content-Location'] = content_location", "language": "python"}
{"input": "Returns the component source in a flat array.", "output": "function findComponents(directory, components = []) {\n  const items = fs.readdirSync(directory);\n\n  items.forEach(item => {\n    const itemPath = path.resolve(directory, item);\n\n    if (fs.statSync(itemPath).isDirectory()) {\n      findComponents(itemPath, components);\n      return;\n    }\n\n    if (!componentRegex.test(item)) {\n      return;\n    }\n\n    components.push({\n      filename: itemPath,\n    });\n  });\n\n  return components;\n}", "language": "javascript"}
{"input": "Determines the managed object that is responsible resp. triggering the list binding.\nThere are two different cases: A binding of the form\n<ul>\n<li>{../table/items}, with the aggregation 'items' here the origin is the table</li>\n<li>{../field/conditions/0/value}, with the array property 'conditions' here the origin is the field</li>\n</ul>\n\nFor identifying this object we need to traverse through the complete binding using the record functionality\nof the _getObject method.\n\n@private", "output": "function() {\n\t\t\tif (!this._oOriginMO) {\n\t\t\t\tvar oMOM = this.oModel, aNodeStack = [];\n\t\t\t\toMOM._getObject(this.sPath, this.oContext, aNodeStack);\n\n\t\t\t\tvar aValueAndMO = _traverseToLastManagedObject(aNodeStack);\n\n\t\t\t\tthis._oOriginMO = aValueAndMO[0];\n\t\t\t\tthis._aPartsInJSON = aValueAndMO[2];\n\t\t\t\tthis._sMember = aValueAndMO[3];\n\t\t\t\tthis._oAggregation = this._oOriginMO.getMetadata().getAggregation(this._sMember);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Verifies AwaitExpressions satisfy spacing requirements\n@param {ASTNode} node AwaitExpression AST node\n@returns {void}", "output": "function checkForSpacesAfterAwait(node) {\n            const tokens = sourceCode.getFirstTokens(node, 3);\n\n            checkUnaryWordOperatorForSpaces(node, tokens[0], tokens[1], \"await\");\n        }", "language": "javascript"}
{"input": "Checks agent histories for processing condition, and processes them as necessary.\n        Processing involves calculating value and advantage targets for model updating step.\n        :param current_info: Current AllBrainInfo\n        :param next_info: Next AllBrainInfo", "output": "def process_experiences(self, current_info: AllBrainInfo, next_info: AllBrainInfo):\n        \"\"\"\n        Checks agent histories for processing condition, and processes them as necessary.\n        Processing involves calculating value and advantage targets for model updating step.\n        :param current_info: Current AllBrainInfo\n        :param next_info: Next AllBrainInfo\n        \"\"\"\n        info_student = next_info[self.brain_name]\n        for l in range(len(info_student.agents)):\n            if info_student.local_done[l]:\n                agent_id = info_student.agents[l]\n                self.stats['Environment/Cumulative Reward'].append(\n                    self.cumulative_rewards.get(agent_id, 0))\n                self.stats['Environment/Episode Length'].append(\n                    self.episode_steps.get(agent_id, 0))\n                self.cumulative_rewards[agent_id] = 0\n                self.episode_steps[agent_id] = 0", "language": "python"}
{"input": "Clears all entries in the cache.\n@returns {Promise} a promise that would be resolved in case of successful operation or rejected with\nvalue of the error message if the operation fails.\n@public", "output": "function () {\n\t\t\t\tvar pReset, oMsr = startMeasurements(\"reset\");\n\t\t\t\tLog.debug(\"Cache Manager: Reset called.\");\n\n\t\t\t\tpReset = this._callInstanceMethod(\"reset\", arguments).then(function callInstanceHandler() {\n\t\t\t\t\tLog.debug(\"Cache Manager: Reset completed successfully.\");\n\t\t\t\t\toMsr.endAsync();\n\t\t\t\t\t//nothing to return, just logging.\n\t\t\t\t}, function (e) {\n\t\t\t\t\tLog.debug(\"Cache Manager: Reset failed. Error: \" + e);\n\t\t\t\t\toMsr.endAsync();\n\t\t\t\t\tthrow e;\n\t\t\t\t});\n\t\t\t\toMsr.endSync();\n\t\t\t\treturn pReset;\n\t\t\t}", "language": "javascript"}
{"input": "Check good hashes against ones built from iterable of chunks of\n        data.\n\n        Raise HashMismatch if none match.", "output": "def check_against_chunks(self, chunks):\n        # type: (Iterator[bytes]) -> None\n        \"\"\"Check good hashes against ones built from iterable of chunks of\n        data.\n\n        Raise HashMismatch if none match.\n\n        \"\"\"\n        gots = {}\n        for hash_name in iterkeys(self._allowed):\n            try:\n                gots[hash_name] = hashlib.new(hash_name)\n            except (ValueError, TypeError):\n                raise InstallationError('Unknown hash name: %s' % hash_name)\n\n        for chunk in chunks:\n            for hash in itervalues(gots):\n                hash.update(chunk)\n\n        for hash_name, got in iteritems(gots):\n            if got.hexdigest() in self._allowed[hash_name]:\n                return\n        self._raise(gots)", "language": "python"}
{"input": "Filters potentially unsafe `options` in a model method's arguments, so you can pass them to Bookshelf / Knex.\n@param {Object} unfilteredOptions Represents options to filter in order to be passed to the Bookshelf query.\n@param {String} methodName The name of the method to check valid options for.\n@return {Object} The filtered results of `options`.", "output": "function filterOptions(unfilteredOptions, methodName, filterConfig) {\n        unfilteredOptions = unfilteredOptions || {};\n        filterConfig = filterConfig || {};\n\n        if (unfilteredOptions.hasOwnProperty('include')) {\n            throw new common.errors.IncorrectUsageError({\n                message: 'The model layer expects using `withRelated`.'\n            });\n        }\n\n        var options = _.cloneDeep(unfilteredOptions),\n            extraAllowedProperties = filterConfig.extraAllowedProperties || [],\n            permittedOptions;\n\n        permittedOptions = this.permittedOptions(methodName, options);\n        permittedOptions = _.union(permittedOptions, extraAllowedProperties);\n        options = _.pick(options, permittedOptions);\n\n        if (this.defaultRelations) {\n            options = this.defaultRelations(methodName, options);\n        }\n\n        return options;\n    }", "language": "javascript"}
{"input": "*\nChecks of passed node has parent control of type UI5.\n@param node HTML element that will be checked.\n@param oScope Scope in witch checking will be executed.\n@returns {boolean} If node has parent of type UI5 control it will return true, otherwise false.", "output": "function (node, oScope) {\n\t\t\t\t/**\n\t\t\t\t * Here we white list all controls that can contain DOM elements with style different than the framework style\n\t\t\t\t */\n\t\t\t\tvar skipParents = [\"sap.ui.core.HTML\"],\n\t\t\t\t\tparentNode = jQuery(node).control()[0];\n\n\t\t\t\tif (!parentNode) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\n\t\t\t\tvar parentName = parentNode.getMetadata().getName(),\n\t\t\t\t\tisParentOutOfSkipList = skipParents.indexOf(parentName) === -1,\n\t\t\t\t\tisParentInScope = oScope.getElements().indexOf(parentNode) > -1;\n\n\t\t\t\treturn isParentOutOfSkipList && isParentInScope;\n\n\t\t\t}", "language": "javascript"}
{"input": "/*\nmerging extra annotations with provided service metadata\n\n@private", "output": "function(sAnnotationJSONDoc) {\n\t\t\tvar oAnnotation = null;\n\t\t\ttry {\n\t\t\t\toAnnotation = JSON.parse(sAnnotationJSONDoc);\n\t\t\t} catch (exception) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tvar oMetadata;\n\t\t\ttry {\n\t\t\t\toMetadata = this._oModel.getServiceMetadata().dataServices;\n\t\t\t} catch (exception) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// find \"schema\" entry in annotation document\n\t\t\tfor ( var propName in oAnnotation) {\n\t\t\t\tif (!(this.oUI5ODataModelAnnotatableObject.objectName == propName)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (!(oAnnotation[propName] instanceof Array)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tthis.mergeV2AnnotationLevel(oMetadata[this.oUI5ODataModelAnnotatableObject.objectName],\n\t\t\t\t\t\toAnnotation[this.oUI5ODataModelAnnotatableObject.objectName], this.oUI5ODataModelAnnotatableObject);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\treturn;\n\t\t}", "language": "javascript"}
{"input": "Generate a Result instance for the given regex match object", "output": "def evaluate_result(self, m):\n        '''Generate a Result instance for the given regex match object'''\n        # ok, figure the fixed fields we've pulled out and type convert them\n        fixed_fields = list(m.groups())\n        for n in self._fixed_fields:\n            if n in self._type_conversions:\n                fixed_fields[n] = self._type_conversions[n](fixed_fields[n], m)\n        fixed_fields = tuple(fixed_fields[n] for n in self._fixed_fields)\n\n        # grab the named fields, converting where requested\n        groupdict = m.groupdict()\n        named_fields = {}\n        name_map = {}\n        for k in self._named_fields:\n            korig = self._group_to_name_map[k]\n            name_map[korig] = k\n            if k in self._type_conversions:\n                value = self._type_conversions[k](groupdict[k], m)\n            else:\n                value = groupdict[k]\n\n            named_fields[korig] = value\n\n        # now figure the match spans\n        spans = dict((n, m.span(name_map[n])) for n in named_fields)\n        spans.update((i, m.span(n + 1))\n            for i, n in enumerate(self._fixed_fields))\n\n        # and that's our result\n        return Result(fixed_fields, self._expand_named_fields(named_fields), spans)", "language": "python"}
{"input": "Close the preferences dialog\n\n@param {MozMillController} controller\nMozMillController of the window to operate on\n@param {boolean} saveChanges\n(Optional) If true the OK button is clicked on Windows which saves\nthe changes. On OS X and Linux changes are applied immediately", "output": "function preferencesDialog_close(saveChanges) {\n    saveChanges = (saveChanges == undefined) ? false : saveChanges;\n\n    if (mozmill.isWindows) {\n      var button = this.getElement({type: \"button\", subtype: (saveChanges ? \"accept\" : \"cancel\")});\n      this._controller.click(button);\n    } else {\n      this._controller.keypress(null, 'w', {accelKey: true});\n    }\n  }", "language": "javascript"}
{"input": "/*\nfunction isNonEmptyNamespace($) {\nreturn $.isNamespace && (\n($.properties && $.properties.length > 0) ||\n($.methods && $.methods.length > 0) ||\n($.augments && $.augments.length > 0) ||\n($.children && $.children.length > 0));\n}; /* Just the first sentence (up to a full stop). Should not break on dotted variable names.", "output": "function summarize(desc) {\n\tif ( desc != null ) {\n\t\tdesc = String(desc).replace(/\\s+/g, ' ').\n\t\t\t\t\treplace(/\"'/g, '&quot;').\n\t\t\t\t\treplace(/^(<\\/?p>|<br\\/?>|\\s)+/, '');\n\n\t\tvar match = /([\\w\\W]+?\\.)[^a-z0-9_$]/i.exec(desc);\n\t\treturn match ? match[1] : desc;\n\t}\n}", "language": "javascript"}
{"input": "Based on https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is", "output": "function _objectIs(a, b) {\n  // SameValue algorithm\n  if (a === b) { // Steps 1-5, 7-10\n    // Steps 6.b-6.e: +0 != -0\n    return a !== 0 || 1 / a === 1 / b;\n  } else {\n    // Step 6.a: NaN == NaN\n    return a !== a && b !== b;\n  }\n}", "language": "javascript"}
{"input": "Merge an Array of Objects into a single Object.", "output": "function toObject (arr) {\n  var res = {};\n  for (var i = 0; i < arr.length; i++) {\n    if (arr[i]) {\n      extend(res, arr[i]);\n    }\n  }\n  return res\n}", "language": "javascript"}
{"input": "Returns a `tapVersion`-appropriate TAP producer instance, if possible.\n\n@private\n@param {string} tapVersion - Version of TAP specification to produce.\n@returns {TAPProducer} specification-appropriate instance\n@throws {Error} if specification version has no associated producer.", "output": "function createProducer(tapVersion) {\n  var producers = {\n    '12': new TAP12Producer(),\n    '13': new TAP13Producer()\n  };\n  var producer = producers[tapVersion];\n\n  if (!producer) {\n    throw new Error(\n      'invalid or unsupported TAP version: ' + JSON.stringify(tapVersion)\n    );\n  }\n\n  return producer;\n}", "language": "javascript"}
{"input": "Helper that always returns a :class:`urllib3.util.Timeout`", "output": "def _get_timeout(self, timeout):\n        \"\"\" Helper that always returns a :class:`urllib3.util.Timeout` \"\"\"\n        if timeout is _Default:\n            return self.timeout.clone()\n\n        if isinstance(timeout, Timeout):\n            return timeout.clone()\n        else:\n            # User passed us an int/float. This is for backwards compatibility,\n            # can be removed later\n            return Timeout.from_float(timeout)", "language": "python"}
{"input": "Compares the given values using <code>===</code> and <code>></code>.\n\n@param {any} vValue1\nthe first value to compare\n@param {any} vValue2\nthe second value to compare\n@return {int}\nthe result of the compare: <code>0</code> if the values are equal, <code>-1</code> if the\nfirst value is smaller, <code>1</code> if the first value is larger, <code>NaN</code> if\nthey cannot be compared", "output": "function simpleCompare(vValue1, vValue2) {\n\t\tif (vValue1 === vValue2) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (vValue1 === null || vValue2 === null\n\t\t\t\t|| vValue1 === undefined || vValue2 === undefined) {\n\t\t\treturn NaN;\n\t\t}\n\t\treturn vValue1 > vValue2 ? 1 : -1;\n\t}", "language": "javascript"}
{"input": "Replace current attribute value with fallback value", "output": "function buildUpdateFn(element, className, attrs) {\n    return function updateAttrValue(fallback) {\n      if (!needsInterpolation(fallback)) {\n        // Do not modify the element's attribute value; so\n        // uses '<ui-layout layout=\"/api/sidebar.html\" />' will not\n        // be affected. Just update the attrs value.\n        attrs[attrs.$normalize(className)] = fallback;\n      }\n    };\n  }", "language": "javascript"}
{"input": "A list of names for the outputs of this module.", "output": "def output_names(self):\n        \"\"\"A list of names for the outputs of this module.\"\"\"\n        if self.binded:\n            return self._curr_module.output_names\n        else:\n            symbol, _, _ = self._call_sym_gen(self._default_bucket_key)\n            return symbol.list_outputs()", "language": "python"}
{"input": "Create layers for all sources.\n@param {Array<import(\"./Source.js\").default|import(\"../layer/Layer.js\").default>} sources The sources.\n@return {Array<import(\"../layer/Layer.js\").default>} Array of layers.", "output": "function createLayers(sources) {\n  const len = sources.length;\n  const layers = new Array(len);\n  for (let i = 0; i < len; ++i) {\n    layers[i] = createLayer(sources[i]);\n  }\n  return layers;\n}", "language": "javascript"}
{"input": "Handle modal onOpenEnd callback", "output": "function () {\n            if (typeof _this14.options.onOpenEnd === 'function') {\n              _this14.options.onOpenEnd.call(_this14, _this14.el, _this14._openingTrigger);\n            }\n          }", "language": "javascript"}
{"input": "/* [MS-OFFCRYPTO] 2.3.4.10 EncryptionInfo Stream (Agile Encryption)", "output": "function parse_EncInfoAgl(blob) {\n\tvar KeyData = [\"saltSize\",\"blockSize\",\"keyBits\",\"hashSize\",\"cipherAlgorithm\",\"cipherChaining\",\"hashAlgorithm\",\"saltValue\"];\n\tblob.l+=4;\n\tvar xml = blob.read_shift(blob.length - blob.l, 'utf8');\n\tvar o = {};\n\txml.replace(tagregex, function xml_agile(x) {\n\t\tvar y = parsexmltag(x);\n\t\tswitch(strip_ns(y[0])) {\n\t\t\tcase '<?xml': break;\n\t\t\tcase '<encryption': case '</encryption>': break;\n\t\t\tcase '<keyData': KeyData.forEach(function(k) { o[k] = y[k]; }); break;\n\t\t\tcase '<dataIntegrity': o.encryptedHmacKey = y.encryptedHmacKey; o.encryptedHmacValue = y.encryptedHmacValue; break;\n\t\t\tcase '<keyEncryptors>': case '<keyEncryptors': o.encs = []; break;\n\t\t\tcase '</keyEncryptors>': break;\n\n\t\t\tcase '<keyEncryptor': o.uri = y.uri; break;\n\t\t\tcase '</keyEncryptor>': break;\n\t\t\tcase '<encryptedKey': o.encs.push(y); break;\n\t\t\tdefault: throw y[0];\n\t\t}\n\t});\n\treturn o;\n}", "language": "javascript"}
{"input": "Translates any line ending types in the given text to the be the single form specified\n@param {!string} text\n@param {null|LINE_ENDINGS_CRLF|LINE_ENDINGS_LF} lineEndings\n@return {string}", "output": "function translateLineEndings(text, lineEndings) {\n        if (lineEndings !== LINE_ENDINGS_CRLF && lineEndings !== LINE_ENDINGS_LF) {\n            lineEndings = getPlatformLineEndings();\n        }\n\n        var eolStr = (lineEndings === LINE_ENDINGS_CRLF ? \"\\r\\n\" : \"\\n\");\n        var findAnyEol = /\\r\\n|\\r|\\n/g;\n\n        return text.replace(findAnyEol, eolStr);\n    }", "language": "javascript"}
{"input": "Trio of functions taken from Peter Michaux's article: http://peter.michaux.ca/articles/feature-detection-state-of-the-art-browser-scripting", "output": "function isHostMethod(o, p) {\n        var t = typeof o[p];\n        return t == FUNCTION || (!!(t == OBJECT && o[p])) || t == \"unknown\";\n    }", "language": "javascript"}
{"input": "`Promise.race` method https://tc39.github.io/ecma262/#sec-promise.race", "output": "function race(iterable) {\n    var C = this;\n    var capability = newPromiseCapability(C);\n    var reject = capability.reject;\n    var result = perform(function () {\n      var $promiseResolve = aFunction(C.resolve);\n      iterate(iterable, function (promise) {\n        $promiseResolve.call(C, promise).then(capability.resolve, reject);\n      });\n    });\n    if (result.error) reject(result.value);\n    return capability.promise;\n  }", "language": "javascript"}
{"input": "Convert from torch style `image` to numpy/matplotlib style.", "output": "def image2np(image:Tensor)->np.ndarray:\n    \"Convert from torch style `image` to numpy/matplotlib style.\"\n    res = image.cpu().permute(1,2,0).numpy()\n    return res[...,0] if res.shape[2]==1 else res", "language": "python"}
{"input": "Sets headers needed by proxies: specifically, the Accept and Host\n        headers. Only sets headers not provided by the user.", "output": "def _set_proxy_headers(self, url, headers=None):\n        \"\"\"\n        Sets headers needed by proxies: specifically, the Accept and Host\n        headers. Only sets headers not provided by the user.\n        \"\"\"\n        headers_ = {'Accept': '*/*'}\n\n        netloc = parse_url(url).netloc\n        if netloc:\n            headers_['Host'] = netloc\n\n        if headers:\n            headers_.update(headers)\n        return headers_", "language": "python"}
{"input": "Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`", "output": "def _ll_pre_transform(self, train_tfm:List[Callable], valid_tfm:List[Callable]):\n    \"Call `train_tfm` and `valid_tfm` after opening image, before converting from `PIL.Image`\"\n    self.train.x.after_open = compose(train_tfm)\n    self.valid.x.after_open = compose(valid_tfm)\n    return self", "language": "python"}
{"input": "called after new page loaded", "output": "function(sChangeReason) {\n\t\t\tthis._bLoading = false;\n\t\t\tthis._updateTriggerDelayed(false);\n\t\t\tthis._oControl.onAfterPageLoaded(this.getInfo(), sChangeReason);\n\n\t\t\t// After the data has been loaded, restore the busy indicator handling of the parent control.\n\t\t\tif (this._oControl.setEnableBusyIndicator) {\n\t\t\t\tthis._oControl.setEnableBusyIndicator(this._bParentEnableBusyIndicator);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Local 1d self attention.", "output": "def local_attention_1d(x,\n                       hparams,\n                       attention_type=\"local_unmasked\",\n                       q_padding=\"VALID\",\n                       kv_padding=\"VALID\"):\n  \"\"\"Local 1d self attention.\"\"\"\n  # self-attention\n  x, x_shape, is_4d = maybe_reshape_4d_to_3d(x)\n  with tf.variable_scope(\"local_1d_self_att\"):\n    y = common_attention.multihead_attention(\n        x,\n        None,\n        None,\n        hparams.attention_key_channels or hparams.hidden_size,\n        hparams.attention_value_channels or hparams.hidden_size,\n        hparams.hidden_size,\n        hparams.num_heads,\n        hparams.attention_dropout,\n        attention_type=attention_type,\n        shared_rel=hparams.shared_rel,\n        block_width=hparams.block_width,\n        block_length=hparams.block_length,\n        q_padding=q_padding,\n        kv_padding=kv_padding,\n        q_filter_width=hparams.q_filter_width,\n        kv_filter_width=hparams.kv_filter_width,\n        make_image_summary=False,\n        name=\"self_attention\")\n    if is_4d:\n      y = tf.reshape(y, x_shape)\n    return y", "language": "python"}
{"input": "Moves handle(s) by a percentage (bool, % to move, [% where handle started, ...], [index in scope_Handles, ...])", "output": "function moveHandles ( upward, proposal, locations, handleNumbers ) {\n\n            var proposals = locations.slice();\n\n            var b = [!upward, upward];\n            var f = [upward, !upward];\n\n            // Copy handleNumbers so we don't change the dataset\n            handleNumbers = handleNumbers.slice();\n\n            // Check to see which handle is 'leading'.\n            // If that one can't move the second can't either.\n            if ( upward ) {\n                handleNumbers.reverse();\n            }\n\n            // Step 1: get the maximum percentage that any of the handles can move\n            if ( handleNumbers.length > 1 ) {\n\n                handleNumbers.forEach(function(handleNumber, o) {\n\n                    var to = checkHandlePosition(proposals, handleNumber, proposals[handleNumber] + proposal, b[o], f[o]);\n\n                    // Stop if one of the handles can't move.\n                    if ( to === false ) {\n                        proposal = 0;\n                    } else {\n                        proposal = to - proposals[handleNumber];\n                        proposals[handleNumber] = to;\n                    }\n                });\n            }\n\n            // If using one handle, check backward AND forward\n            else {\n                b = f = [true];\n            }\n\n            var state = false;\n\n            // Step 2: Try to set the handles with the found percentage\n            handleNumbers.forEach(function(handleNumber, o) {\n                state = setHandle(handleNumber, locations[handleNumber] + proposal, b[o], f[o]) || state;\n            });\n\n            // Step 3: If a handle moved, fire events\n            if ( state ) {\n                handleNumbers.forEach(function(handleNumber){\n                    fireEvent('update', handleNumber);\n                    fireEvent('slide', handleNumber);\n                });\n            }\n        }", "language": "javascript"}
{"input": "Safely cast the values to the dtype if they\n    are equivalent, meaning floats must be equivalent to the\n    ints.", "output": "def safe_cast(values, dtype, copy):\n    \"\"\"\n    Safely cast the values to the dtype if they\n    are equivalent, meaning floats must be equivalent to the\n    ints.\n\n    \"\"\"\n\n    try:\n        return values.astype(dtype, casting='safe', copy=copy)\n    except TypeError:\n\n        casted = values.astype(dtype, copy=copy)\n        if (casted == values).all():\n            return casted\n\n        raise TypeError(\"cannot safely cast non-equivalent {} to {}\".format(\n            values.dtype, np.dtype(dtype)))", "language": "python"}
{"input": "COLLAPSE PUBLIC CLASS DEFINITION ================================", "output": "function (element, options) {\n    this.$element      = $(element)\n    this.options       = $.extend({}, Collapse.DEFAULTS, options)\n    this.$trigger      = $('[data-toggle=\"collapse\"][href=\"#' + element.id + '\"],' +\n                           '[data-toggle=\"collapse\"][data-target=\"#' + element.id + '\"]')\n    this.transitioning = null\n\n    if (this.options.parent) {\n      this.$parent = this.getParent()\n    } else {\n      this.addAriaAndCollapsedClass(this.$element, this.$trigger)\n    }\n\n    if (this.options.toggle) this.toggle()\n  }", "language": "javascript"}
{"input": "Computes an \"ideal\" category based on the absolute bar thickness or, if undefined or null,\nuses the smallest interval (see computeMinSampleSize) that prevents bar overlapping. This\nmode currently always generates bars equally sized (until we introduce scriptable options?).\n@private", "output": "function computeFitCategoryTraits(index, ruler, options) {\n\tvar thickness = options.barThickness;\n\tvar count = ruler.stackCount;\n\tvar curr = ruler.pixels[index];\n\tvar size, ratio;\n\n\tif (helpers.isNullOrUndef(thickness)) {\n\t\tsize = ruler.min * options.categoryPercentage;\n\t\tratio = options.barPercentage;\n\t} else {\n\t\t// When bar thickness is enforced, category and bar percentages are ignored.\n\t\t// Note(SB): we could add support for relative bar thickness (e.g. barThickness: '50%')\n\t\t// and deprecate barPercentage since this value is ignored when thickness is absolute.\n\t\tsize = thickness * count;\n\t\tratio = 1;\n\t}\n\n\treturn {\n\t\tchunk: size / count,\n\t\tratio: ratio,\n\t\tstart: curr - (size / 2)\n\t};\n}", "language": "javascript"}
{"input": "Removes a global keydown hook added by `addGlobalKeydownHook`.\nDoes not need to be the most recently added hook.\n\n@param {function(Event): boolean} hook The global hook to remove.", "output": "function removeGlobalKeydownHook(hook) {\n        var index = _globalKeydownHooks.indexOf(hook);\n        if (index !== -1) {\n            _globalKeydownHooks.splice(index, 1);\n        }\n    }", "language": "javascript"}
{"input": "\u5f00\u59cb\u6267\u884c\u52a8\u753b\n@param  {string|Function} [easing]\n\u52a8\u753b\u7f13\u52a8\u51fd\u6570\uff0c\u8be6\u89c1{@link module:zrender/animation/easing}\n@param  {boolean} forceAnimate\n@return {module:zrender/animation/Animator}", "output": "function (easing, forceAnimate) {\n\n        var self = this;\n        var clipCount = 0;\n\n        var oneTrackDone = function () {\n            clipCount--;\n            if (!clipCount) {\n                self._doneCallback();\n            }\n        };\n\n        var lastClip;\n        for (var propName in this._tracks) {\n            if (!this._tracks.hasOwnProperty(propName)) {\n                continue;\n            }\n            var clip = createTrackClip(\n                this, easing, oneTrackDone,\n                this._tracks[propName], propName, forceAnimate\n            );\n            if (clip) {\n                this._clipList.push(clip);\n                clipCount++;\n\n                // If start after added to animation\n                if (this.animation) {\n                    this.animation.addClip(clip);\n                }\n\n                lastClip = clip;\n            }\n        }\n\n        // Add during callback on the last clip\n        if (lastClip) {\n            var oldOnFrame = lastClip.onframe;\n            lastClip.onframe = function (target, percent) {\n                oldOnFrame(target, percent);\n\n                for (var i = 0; i < self._onframeList.length; i++) {\n                    self._onframeList[i](target, percent);\n                }\n            };\n        }\n\n        // This optimization will help the case that in the upper application\n        // the view may be refreshed frequently, where animation will be\n        // called repeatly but nothing changed.\n        if (!clipCount) {\n            this._doneCallback();\n        }\n        return this;\n    }", "language": "javascript"}
{"input": ":type nums: List[int]\n    :type target: int\n    :rtype: List[int]", "output": "def search_range(nums, target):\n    \"\"\"\n    :type nums: List[int]\n    :type target: int\n    :rtype: List[int]\n    \"\"\"\n    low = 0\n    high = len(nums) - 1\n    while low <= high:\n        mid = low + (high - low) // 2\n        if target < nums[mid]:\n            high = mid - 1\n        elif target > nums[mid]:\n            low = mid + 1\n        else:\n            break\n\n    for j in range(len(nums) - 1, -1, -1):\n        if nums[j] == target:\n            return [mid, j]\n\n    return [-1, -1]", "language": "python"}
{"input": "r\"\"\"Computes rewards to go.\n\n  Reward to go is defined as follows, the discounted reward that we have to\n  yet collect, going forward from this point, i.e.:\n\n  r2g_t = \\sum_{l=0}^{\\infty} (\\gamma^{l} * reward_{t+l})\n\n  Args:\n    rewards: np.ndarray of shape (B, T) of rewards.\n    mask: np.ndarray of shape (B, T) of mask for the rewards.\n    gamma: float, discount factor.\n\n  Returns:\n    rewards to go, np.ndarray of shape (B, T).", "output": "def rewards_to_go(rewards, mask, gamma=0.99):\n  r\"\"\"Computes rewards to go.\n\n  Reward to go is defined as follows, the discounted reward that we have to\n  yet collect, going forward from this point, i.e.:\n\n  r2g_t = \\sum_{l=0}^{\\infty} (\\gamma^{l} * reward_{t+l})\n\n  Args:\n    rewards: np.ndarray of shape (B, T) of rewards.\n    mask: np.ndarray of shape (B, T) of mask for the rewards.\n    gamma: float, discount factor.\n\n  Returns:\n    rewards to go, np.ndarray of shape (B, T).\n  \"\"\"\n  B, T = rewards.shape  # pylint: disable=invalid-name,unused-variable\n\n  masked_rewards = rewards * mask  # (B, T)\n\n  # We use the following recurrence relation, derived from the equation above:\n  #\n  # r2g[t+1] = (r2g[t] - r[t]) / gamma\n  #\n  # This means we'll need to calculate r2g[0] first and then r2g[1] and so on ..\n  #\n  # **However** this leads to overflows for long sequences: r2g[t] - r[t] > 0\n  # and gamma < 1.0, so the division keeps increasing.\n  #\n  # So we just run the recurrence in reverse, i.e.\n  #\n  # r2g[t] = r[t] + (gamma*r2g[t+1])\n  #\n  # This is much better, but might have lost updates since the (small) rewards\n  # at earlier time-steps may get added to a (very?) large sum.\n\n  # Compute r2g_{T-1} at the start and then compute backwards in time.\n  r2gs = [masked_rewards[:, -1]]\n\n  # Go from T-2 down to 0.\n  for t in reversed(range(T - 1)):\n    r2gs.append(masked_rewards[:, t] + (gamma * r2gs[-1]))\n\n  # The list should have length T.\n  assert T == len(r2gs)\n\n  # First we stack them in the correct way to make it (B, T), but these are\n  # still from newest (T-1) to oldest (0), so then we flip it on time axis.\n  return np.flip(np.stack(r2gs, axis=1), axis=1)", "language": "python"}
{"input": "Choose one of two URLs where both are candidates for distribution\n        archives for the same version of a distribution (for example,\n        .tar.gz vs. zip).\n\n        The current implementation favours https:// URLs over http://, archives\n        from PyPI over those from other locations, wheel compatibility (if a\n        wheel) and then the archive name.", "output": "def prefer_url(self, url1, url2):\n        \"\"\"\n        Choose one of two URLs where both are candidates for distribution\n        archives for the same version of a distribution (for example,\n        .tar.gz vs. zip).\n\n        The current implementation favours https:// URLs over http://, archives\n        from PyPI over those from other locations, wheel compatibility (if a\n        wheel) and then the archive name.\n        \"\"\"\n        result = url2\n        if url1:\n            s1 = self.score_url(url1)\n            s2 = self.score_url(url2)\n            if s1 > s2:\n                result = url1\n            if result != url2:\n                logger.debug('Not replacing %r with %r', url1, url2)\n            else:\n                logger.debug('Replacing %r with %r', url1, url2)\n        return result", "language": "python"}
{"input": "read the calculated css style of the element or override the style (via a bypass)", "output": "function( name, value ){\n    let cy = this.cy();\n\n    if( !cy.styleEnabled() ){ return this; }\n\n    let updateTransitions = false;\n    let style = cy.style();\n\n    if( is.plainObject( name ) ){ // then extend the bypass\n      let props = name;\n      style.applyBypass( this, props, updateTransitions );\n\n      this.emitAndNotify( 'style' ); // let the renderer know we've updated style\n\n    } else if( is.string( name ) ){\n\n      if( value === undefined ){ // then get the property from the style\n        let ele = this[0];\n\n        if( ele ){\n          return style.getStylePropertyValue( ele, name );\n        } else { // empty collection => can't get any value\n          return;\n        }\n\n      } else { // then set the bypass with the property value\n        style.applyBypass( this, name, value, updateTransitions );\n\n        this.emitAndNotify( 'style' ); // let the renderer know we've updated style\n      }\n\n    } else if( name === undefined ){\n      let ele = this[0];\n\n      if( ele ){\n        return style.getRawStyle( ele );\n      } else { // empty collection => can't get any value\n        return;\n      }\n    }\n\n    return this; // chaining\n  }", "language": "javascript"}
{"input": "Download `url` to `dest` unless it exists and not `overwrite`.", "output": "def download_url(url:str, dest:str, overwrite:bool=False, pbar:ProgressBar=None,\n                 show_progress=True, chunk_size=1024*1024, timeout=4, retries=5)->None:\n    \"Download `url` to `dest` unless it exists and not `overwrite`.\"\n    if os.path.exists(dest) and not overwrite: return\n\n    s = requests.Session()\n    s.mount('http://',requests.adapters.HTTPAdapter(max_retries=retries))\n    u = s.get(url, stream=True, timeout=timeout)\n    try: file_size = int(u.headers[\"Content-Length\"])\n    except: show_progress = False\n\n    with open(dest, 'wb') as f:\n        nbytes = 0\n        if show_progress: pbar = progress_bar(range(file_size), auto_update=False, leave=False, parent=pbar)\n        try:\n            for chunk in u.iter_content(chunk_size=chunk_size):\n                nbytes += len(chunk)\n                if show_progress: pbar.update(nbytes)\n                f.write(chunk)\n        except requests.exceptions.ConnectionError as e:\n            fname = url.split('/')[-1]\n            from fastai.datasets import Config\n            data_dir = Config().data_path()\n            timeout_txt =(f'\\n Download of {url} has failed after {retries} retries\\n'\n                          f' Fix the download manually:\\n'\n                          f'$ mkdir -p {data_dir}\\n'\n                          f'$ cd {data_dir}\\n'\n                          f'$ wget -c {url}\\n'\n                          f'$ tar -zxvf {fname}\\n\\n'\n                          f'And re-run your code once the download is successful\\n')\n            print(timeout_txt)\n            import sys;sys.exit(1)", "language": "python"}
{"input": "Close menu on menu item click, if said menu-item is not disabled", "output": "function captureClickListener(e) {\n          var target = e.target;\n          // Traverse up the event until we get to the menuContentEl to see if\n          // there is an ng-click and that the ng-click is not disabled\n          do {\n            if (target == opts.menuContentEl[0]) return;\n            if ((hasAnyAttribute(target, ['ng-click', 'ng-href', 'ui-sref']) ||\n                target.nodeName == 'BUTTON' || target.nodeName == 'MD-BUTTON') && !hasAnyAttribute(target, ['md-prevent-menu-close'])) {\n              var closestMenu = $mdUtil.getClosest(target, 'MD-MENU');\n              if (!target.hasAttribute('disabled') && (!closestMenu || closestMenu == opts.parent[0])) {\n                close();\n              }\n              break;\n            }\n          } while (target = target.parentNode);\n\n          function close() {\n            scope.$apply(function() {\n              opts.mdMenuCtrl.close(true, { closeAll: true });\n            });\n          }\n\n          function hasAnyAttribute(target, attrs) {\n            if (!target) return false;\n\n            for (var i = 0, attr; attr = attrs[i]; ++i) {\n              if (prefixer.hasAttribute(target, attr)) {\n                return true;\n              }\n            }\n\n            return false;\n          }\n        }", "language": "javascript"}
{"input": "Check if a member expression contains a call expression\n@param {ASTNode} node MemberExpression node to evaluate\n@returns {boolean} true if found, false if not", "output": "function doesMemberExpressionContainCallExpression(node) {\n            let currentNode = node.object;\n            let currentNodeType = node.object.type;\n\n            while (currentNodeType === \"MemberExpression\") {\n                currentNode = currentNode.object;\n                currentNodeType = currentNode.type;\n            }\n\n            return currentNodeType === \"CallExpression\";\n        }", "language": "javascript"}
{"input": "Initializes the current selection preset\n@param {Array} aSelectedRulesPlain The plain list of selected rules (same format as in the presets json file)", "output": "function (aSelectedRulesPlain) {\n\t\t\t// if we persist settings - load any selection presets, else use the default ones\n\t\t\tif (this.model.getProperty(\"/persistingSettings\")) {\n\t\t\t\tvar aPersistedPresets = Storage.getSelectionPresets();\n\t\t\t\tif (aPersistedPresets) {\n\t\t\t\t\tthis.model.setProperty(\"/selectionPresets\", aPersistedPresets);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tvar aPresets = this.model.getProperty(\"/selectionPresets\"),\n\t\t\t\tiLastSystemPresetPosition = 0;\n\n\t\t\t// add System Presets to Rule Presets Popover\n\t\t\tthis.getSystemPresets().forEach(function (oSystemPreset) {\n\t\t\t\tvar isFound = aPresets.some(function (oPreset) {\n\t\t\t\t\tif (oSystemPreset.id === oPreset.id) {\n\t\t\t\t\t\tif (!oPreset.isModified) {\n\t\t\t\t\t\t\tvar bIsSelected = oPreset.selected;\n\t\t\t\t\t\t\toPreset = jQuery.extend({}, oSystemPreset);\n\t\t\t\t\t\t\toPreset.selected = bIsSelected;\n\t\t\t\t\t\t\tif (bIsSelected) {\n\t\t\t\t\t\t\t\tSelectionUtils.setSelectedRules(oPreset.selections);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tif (!isFound) {\n\t\t\t\t\tvar mSystemPresetConfig = {\n\t\t\t\t\t\tdisableDelete: true,\n\t\t\t\t\t\tisSystemPreset: true\n\t\t\t\t\t};\n\t\t\t\t\taPresets.splice(iLastSystemPresetPosition + 1, 0, jQuery.extend(mSystemPresetConfig, oSystemPreset));\n\t\t\t\t}\n\n\t\t\t\tiLastSystemPresetPosition++;\n\t\t\t});\n\n\t\t\t// find the selected preset\n\t\t\tvar oSelectedPreset = null;\n\t\t\taPresets.some(function (oCurrent) {\n\t\t\t\tif (oCurrent.selected) {\n\t\t\t\t\toSelectedPreset = oCurrent;\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\t// sync 'My Selections' with current selections\n\t\t\tif (oSelectedPreset.isMySelection) {\n\t\t\t\toSelectedPreset.selections = aSelectedRulesPlain;\n\t\t\t}\n\n\t\t\t// need to init the current preset\n\t\t\tthis.model.setProperty(\"/selectionPresetsCurrent\", oSelectedPreset);\n\t\t}", "language": "javascript"}
{"input": "Check if node is followed by a blank newline.\n@param {ASTNode} node Node to check.\n@returns {boolean} Whether or not the passed in node is followed by a blank newline.", "output": "function hasNewlineAfter(node) {\n            const lastToken = getLastTokenOnLine(node);\n            const tokenAfter = sourceCode.getTokenAfter(lastToken, { includeComments: true });\n\n            return tokenAfter.loc.start.line - lastToken.loc.end.line >= 2;\n        }", "language": "javascript"}
{"input": "Helper function to scroll to following step (optionally with updating the focus (see focusStep)). Allowed directions are: next, prev, first, last.", "output": "function(oThis, sDir, bUpdateFocus){\n\t\tRoadMapRenderer.scrollToNextStep(oThis, sDir, function(sFirstVisibleNodeId){\n\t\t\tvar iIdx = sFirstVisibleNodeId.lastIndexOf(\"-expandend\");\n\t\t\tif (iIdx != -1) {\n\t\t\t\tsFirstVisibleNodeId = sFirstVisibleNodeId.substring(0, iIdx);\n\t\t\t}\n\t\t\toThis.setProperty(\"firstVisibleStep\", sFirstVisibleNodeId, true);\n\n\t\t\tif (bUpdateFocus) {\n\t\t\t\trefreshFocus(oThis, sDir);\n\t\t\t}\n\t\t});\n\t}", "language": "javascript"}
{"input": "Convert a list of Column (or names) into a JVM (Scala) List of Column.\n\n    An optional `converter` could be used to convert items in `cols`\n    into JVM Column objects.", "output": "def _to_list(sc, cols, converter=None):\n    \"\"\"\n    Convert a list of Column (or names) into a JVM (Scala) List of Column.\n\n    An optional `converter` could be used to convert items in `cols`\n    into JVM Column objects.\n    \"\"\"\n    if converter:\n        cols = [converter(c) for c in cols]\n    return sc._jvm.PythonUtils.toList(cols)", "language": "python"}
{"input": "Changes the layout scheme\n@param {!number} rows (may be 1 or 2)\n@param {!number} columns (may be 1 or 2)\n@summay Rows or Columns may be 1 or 2 but both cannot be 2. 1x2, 2x1 or 1x1 are the legal values", "output": "function setLayoutScheme(rows, columns) {\n        if ((rows < 1) || (rows > 2) || (columns < 1) || (columns > 2) || (columns === 2 && rows === 2)) {\n            console.error(\"setLayoutScheme unsupported layout \" + rows + \", \" + columns);\n            return false;\n        }\n\n        if (rows === columns) {\n            _mergePanes();\n        } else if (rows > columns) {\n            _doSplit(HORIZONTAL);\n        } else {\n            _doSplit(VERTICAL);\n        }\n        return true;\n    }", "language": "javascript"}
{"input": "Mark a given event name as deprecated, such that on() will emit warnings when called with it.\nMay be called before makeEventDispatcher(). May be called on a prototype where makeEventDispatcher()\nis called separately per instance (i.e. in the constructor). Should be called before clients have\na chance to start calling on().\n@param {!Object} obj Event dispatcher object\n@param {string} eventName Name of deprecated event\n@param {string=} insteadStr Suggested thing to use instead", "output": "function markDeprecated(obj, eventName, insteadStr) {\n        // Mark event as deprecated - on() will emit warnings when called with this event\n        if (!obj._deprecatedEvents) {\n            obj._deprecatedEvents = {};\n        }\n        obj._deprecatedEvents[eventName] = insteadStr || true;\n    }", "language": "javascript"}
{"input": "Get model meta.json from a directory path and validate its contents.\n\n    path (unicode or Path): Path to model directory.\n    RETURNS (dict): The model's meta data.", "output": "def get_model_meta(path):\n    \"\"\"Get model meta.json from a directory path and validate its contents.\n\n    path (unicode or Path): Path to model directory.\n    RETURNS (dict): The model's meta data.\n    \"\"\"\n    model_path = ensure_path(path)\n    if not model_path.exists():\n        raise IOError(Errors.E052.format(path=path2str(model_path)))\n    meta_path = model_path / \"meta.json\"\n    if not meta_path.is_file():\n        raise IOError(Errors.E053.format(path=meta_path))\n    meta = srsly.read_json(meta_path)\n    for setting in [\"lang\", \"name\", \"version\"]:\n        if setting not in meta or not meta[setting]:\n            raise ValueError(Errors.E054.format(setting=setting))\n    return meta", "language": "python"}
{"input": "Helper function for local 2d attention.\n\n  Args:\n    x: a [batch, height, width, depth] tensor\n    block_h: An integer. block height\n    block_w: An inteter. block width\n\n  returns:\n    a [batch, num_heads, height/block_h, width/block_w, depth] tensor", "output": "def _extract_blocks(x, block_h, block_w):\n  \"\"\"Helper function for local 2d attention.\n\n  Args:\n    x: a [batch, height, width, depth] tensor\n    block_h: An integer. block height\n    block_w: An inteter. block width\n\n  returns:\n    a [batch, num_heads, height/block_h, width/block_w, depth] tensor\n  \"\"\"\n  (_, height, width, depth) = common_layers.shape_list(x)\n  assert height % block_h == 0\n  assert width % block_w == 0\n  x = tf.reshape(x, [-1, height//block_h, block_h,\n                     width//block_w, block_w, depth])\n  return tf.transpose(x, [0, 1, 3, 2, 4, 5])", "language": "python"}
{"input": "Returns the URL that was the source of this response.\n        If the request that generated this response redirected, this method\n        will return the final redirect location.", "output": "def geturl(self):\n        \"\"\"\n        Returns the URL that was the source of this response.\n        If the request that generated this response redirected, this method\n        will return the final redirect location.\n        \"\"\"\n        if self.retries is not None and len(self.retries.history):\n            return self.retries.history[-1].redirect_location\n        else:\n            return self._request_url", "language": "python"}
{"input": "Opens the utils button menu and clicks the specified menu entry\n\n@param {object} aSpec\nInformation about the menu\nElements: item - menu item to click (updateNow, viewUpdates,\ninstallFromFile, autoUpdateDefault,\nresetAddonUpdatesToAutomatic,\nresetAddonUpdatesToManual)", "output": "function addonsManager_handleUtilsButton(aSpec) {\n    var spec = aSpec || { };\n    var item = spec.item;\n\n    if (!item)\n      throw new Error(arguments.callee.name + \": Menu item not specified.\");\n\n    var button = this.getElement({type: \"utilsButton\"});\n    var menu = this.getElement({type: \"utilsButton_menu\"});\n\n    try {\n      this._controller.click(button);\n\n      // Click the button and wait until menu has been opened\n      \n      // TODO: restore after 1.5.1 has landed\n      // mozmill.utils.waitFor(function() {\n      //   return menu.getNode() && menu.getNode().state == \"open\";\n      // }, TIMEOUT, 100, \"Menu of utils button has been opened.\");\n      \n      mozmill.utils.waitForEval(\"subject && subject.state == 'open'\",\n                                TIMEOUT, 100, menu.getNode());\n\n      // Click the given menu entry and make sure the \n      var menuItem = this.getElement({\n        type: \"utilsButton_menuItem\",\n        value: \"#utils-\" + item\n      });\n\n      this._controller.click(menuItem);\n    } finally {\n      // Make sure the menu has been closed\n      this._controller.keypress(menu, \"VK_ESCAPE\", {});\n      \n      // TODO: restore after 1.5.1 has landed\n      // mozmill.utils.waitFor(function() {\n      //   return menu.getNode() && menu.getNode().state == \"closed\";\n      // }, TIMEOUT, 100, \"Menu of utils button has been closed.\");\n      \n      mozmill.utils.waitForEval(\"subject && subject.state == 'closed'\",\n                                TIMEOUT, 100, menu.getNode());\n    }\n  }", "language": "javascript"}
{"input": "Notification when trial terminates.\n\n        Trial info is removed from bracket. Triggers halving if bracket is\n        not finished.", "output": "def on_trial_remove(self, trial_runner, trial):\n        \"\"\"Notification when trial terminates.\n\n        Trial info is removed from bracket. Triggers halving if bracket is\n        not finished.\"\"\"\n        bracket, _ = self._trial_info[trial]\n        bracket.cleanup_trial(trial)\n        if not bracket.finished():\n            self._process_bracket(trial_runner, bracket, trial)", "language": "python"}
{"input": "Determines whether an url() line contains a relative or absolute URL, and makes the URL absolute to the CSS file if it is relative", "output": "function makeUrlsRelativeToCss(match, quotationMark, url) {\n            if (PathUtils.isRelativeUrl(url)) {\n                var absUrl = PathUtils.makeUrlAbsolute(url, docUrl);\n                return \"url(\" + quotationMark + absUrl + quotationMark + \")\";\n            }\n            return match;\n        }", "language": "javascript"}
{"input": "@method walkPoint\n\n@param {BoundaryPoint} startPoint\n@param {BoundaryPoint} endPoint\n@param {Function} handler\n@param {Boolean} isSkipInnerOffset", "output": "function walkPoint(startPoint, endPoint, handler, isSkipInnerOffset) {\n  let point = startPoint;\n\n  while (point) {\n    handler(point);\n\n    if (isSamePoint(point, endPoint)) {\n      break;\n    }\n\n    const isSkipOffset = isSkipInnerOffset &&\n                       startPoint.node !== point.node &&\n                       endPoint.node !== point.node;\n    point = nextPoint(point, isSkipOffset);\n  }\n}", "language": "javascript"}
{"input": "Reset simulated and real environments.", "output": "def reset(self):\n    \"\"\"Reset simulated and real environments.\"\"\"\n    self._frame_counter = 0\n    ob_real = self.real_env.reset()\n    # Initialize simulated environment with frames from real one.\n    self.sim_env.add_to_initial_stack(ob_real)\n    for _ in range(3):\n      ob_real, _, _, _ = self.real_env.step(self.name_to_action_num[\"NOOP\"])\n      self.sim_env.add_to_initial_stack(ob_real)\n    ob_sim = self.sim_env.reset()\n    assert np.all(ob_real == ob_sim)\n    self._last_step_tuples = self._pack_step_tuples((ob_real, 0, False, {}),\n                                                    (ob_sim, 0, False, {}))\n    self.set_zero_cumulative_rewards()\n    ob, _, _, _ = self._player_step_tuple(self._last_step_tuples)\n    return ob", "language": "python"}
{"input": "Sets the value for multiple styles on a node.  If a value is specified as\n'' (empty string), the corresponding style property will be unset.\n\n@param {DOMElement} node\n@param {object} styles", "output": "function setValueForStyles(node, styles, getStack) {\n  const style = node.style;\n  for (let styleName in styles) {\n    if (!styles.hasOwnProperty(styleName)) {\n      continue;\n    }\n    const isCustomProperty = styleName.indexOf('--') === 0;\n    if (process.env.NODE_ENV !== 'production') {\n      if (!isCustomProperty) {\n        warnValidStyle(styleName, styles[styleName], getStack);\n      }\n    }\n    const styleValue = dangerousStyleValue(styleName, styles[styleName], isCustomProperty);\n    if (styleName === 'float') {\n      styleName = 'cssFloat';\n    }\n    if (isCustomProperty) {\n      const name = isCustomProperty ? styleName : hyphenateStyleName(styleName);\n      style.setProperty(name, styleValue);\n    } else {\n      style[styleName] = styleValue;\n    }\n  }\n}", "language": "javascript"}
{"input": "After each module, add the object to the '__mxOutput' namespace E.g. __mxOutput.mxLog, etc.", "output": "function (content, srcpath) {\n            var afterContent = \"\",\n                moduleName = path.basename(srcpath, \".js\");\n\n            afterContent += \"\\n__mxOutput.\" + path.basename(srcpath, \".js\") +\n              \" = typeof \" + moduleName + \" !== 'undefined' ? \" + moduleName + \" : undefined;\\n\";\n\n            return content + afterContent;\n          }", "language": "javascript"}
{"input": "Log each file before it is parsed\n@param {object} e Event info object", "output": "function (e) {\n\t\tcurrentProgram = undefined;\n\t\tcurrentModule = {\n\t\t\tname: null,\n\t\t\tresource: getResourceName(e.filename),\n\t\t\tmodule: getModuleName(getResourceName(e.filename)),\n\t\t\tlocalNames: Object.create(null)\n\t\t};\n\t}", "language": "javascript"}
{"input": "Return the path to the wheel in the temporary build directory.", "output": "def get_legacy_build_wheel_path(\n    names,  # type: List[str]\n    temp_dir,  # type: str\n    req,  # type: InstallRequirement\n    command_args,  # type: List[str]\n    command_output,  # type: str\n):\n    # type: (...) -> Optional[str]\n    \"\"\"\n    Return the path to the wheel in the temporary build directory.\n    \"\"\"\n    # Sort for determinism.\n    names = sorted(names)\n    if not names:\n        msg = (\n            'Legacy build of wheel for {!r} created no files.\\n'\n        ).format(req.name)\n        msg += format_command(command_args, command_output)\n        logger.warning(msg)\n        return None\n\n    if len(names) > 1:\n        msg = (\n            'Legacy build of wheel for {!r} created more than one file.\\n'\n            'Filenames (choosing first): {}\\n'\n        ).format(req.name, names)\n        msg += format_command(command_args, command_output)\n        logger.warning(msg)\n\n    return os.path.join(temp_dir, names[0])", "language": "python"}
{"input": "This calculates the Levenshtein distance between a and b.", "output": "def levenshtein_distance(self, a, b):\n        '''This calculates the Levenshtein distance between a and b.\n        '''\n\n        n, m = len(a), len(b)\n        if n > m:\n            a,b = b,a\n            n,m = m,n\n        current = range(n+1)\n        for i in range(1,m+1):\n            previous, current = current, [i]+[0]*n\n            for j in range(1,n+1):\n                add, delete = previous[j]+1, current[j-1]+1\n                change = previous[j-1]\n                if a[j-1] != b[i-1]:\n                    change = change + 1\n                current[j] = min(add, delete, change)\n        return current[n]", "language": "python"}
{"input": "Retrieve pandas object stored in file\n\n        Parameters\n        ----------\n        key : object\n\n        Returns\n        -------\n        obj : same type as object stored in file", "output": "def get(self, key):\n        \"\"\"\n        Retrieve pandas object stored in file\n\n        Parameters\n        ----------\n        key : object\n\n        Returns\n        -------\n        obj : same type as object stored in file\n        \"\"\"\n        group = self.get_node(key)\n        if group is None:\n            raise KeyError('No object named {key} in the file'.format(key=key))\n        return self._read_group(group)", "language": "python"}
{"input": "Validates the location of a single-line statement\n@param {ASTNode} node The single-line statement\n@param {string} keywordName The applicable keyword name for the single-line statement\n@returns {void}", "output": "function validateStatement(node, keywordName) {\n            const option = getOption(keywordName);\n\n            if (node.type === \"BlockStatement\" || option === \"any\") {\n                return;\n            }\n\n            const tokenBefore = sourceCode.getTokenBefore(node);\n\n            if (tokenBefore.loc.end.line === node.loc.start.line && option === \"below\") {\n                context.report({\n                    node,\n                    message: \"Expected a linebreak before this statement.\",\n                    fix: fixer => fixer.insertTextBefore(node, \"\\n\")\n                });\n            } else if (tokenBefore.loc.end.line !== node.loc.start.line && option === \"beside\") {\n                context.report({\n                    node,\n                    message: \"Expected no linebreak before this statement.\",\n                    fix(fixer) {\n                        if (sourceCode.getText().slice(tokenBefore.range[1], node.range[0]).trim()) {\n                            return null;\n                        }\n                        return fixer.replaceTextRange([tokenBefore.range[1], node.range[0]], \" \");\n                    }\n                });\n            }\n        }", "language": "javascript"}
{"input": "/*\nCalculate the name of TitleTarget based on the given parameters", "output": "function(vTargetNames, sProvidedTitleTargetName) {\n\t\t\t\tvar oTarget, sTitleTargetName;\n\n\t\t\t\tsTitleTargetName = sProvidedTitleTargetName || (typeof vTargetNames === \"string\" && vTargetNames);\n\n\t\t\t\tif (!sTitleTargetName) {\n\t\t\t\t\tvTargetNames.some(function(sTargetName) {\n\t\t\t\t\t\toTarget = this.getTarget(sTargetName);\n\n\t\t\t\t\t\t// search the TitleTarget depth first\n\t\t\t\t\t\twhile (oTarget && oTarget._oParent && oTarget._oParent._oOptions.title) {\n\t\t\t\t\t\t\toTarget = oTarget._oParent;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (oTarget && oTarget._oOptions.title) {\n\t\t\t\t\t\t\t// we found the TitleTarget\n\t\t\t\t\t\t\tsTitleTargetName = oTarget._oOptions._name;\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}.bind(this));\n\t\t\t\t}\n\n\t\t\t\treturn sTitleTargetName;\n\t\t\t}", "language": "javascript"}
{"input": "Verify a tag name is a valid Git reference.\n\n@param {String} tagName the tag name to verify.\n@param {Object} [execaOpts] Options to pass to `execa`.\n\n@return {Boolean} `true` if valid, falsy otherwise.", "output": "async function verifyTagName(tagName, execaOpts) {\n  try {\n    return (await execa('git', ['check-ref-format', `refs/tags/${tagName}`], execaOpts)).code === 0;\n  } catch (error) {\n    debug(error);\n  }\n}", "language": "javascript"}
{"input": "Listen for click events that occur somewhere in the document, outside of the element itself.\nFor instance, if you need to hide a menu when people click anywhere else on your page.", "output": "function ClickAwayListener(props) {\n  const { children, mouseEvent = 'onMouseUp', touchEvent = 'onTouchEnd', onClickAway } = props;\n  const mountedRef = useMountedRef();\n  const movedRef = React.useRef(false);\n\n  const nodeRef = React.useRef(null);\n  // can be removed once we drop support for non ref forwarding class components\n  const handleOwnRef = React.useCallback(instance => {\n    // #StrictMode ready\n    nodeRef.current = ReactDOM.findDOMNode(instance);\n  }, []);\n  const handleRef = useForkRef(children.ref, handleOwnRef);\n\n  const handleClickAway = React.useCallback(\n    event => {\n      // Ignore events that have been `event.preventDefault()` marked.\n      if (event.defaultPrevented) {\n        return;\n      }\n\n      // IE 11 support, which trigger the handleClickAway even after the unbind\n      if (!mountedRef.current) {\n        return;\n      }\n\n      // Do not act if user performed touchmove\n      if (movedRef.current) {\n        movedRef.current = false;\n        return;\n      }\n\n      const { current: node } = nodeRef;\n      // The child might render null.\n      if (!node) {\n        return;\n      }\n\n      const doc = ownerDocument(node);\n\n      if (\n        doc.documentElement &&\n        doc.documentElement.contains(event.target) &&\n        !node.contains(event.target)\n      ) {\n        onClickAway(event);\n      }\n    },\n    [mountedRef, onClickAway],\n  );\n\n  const handleTouchMove = React.useCallback(() => {\n    movedRef.current = true;\n  }, []);\n\n  const listenerProps = {};\n  if (mouseEvent !== false) {\n    listenerProps[mouseEvent] = handleClickAway;\n  }\n  if (touchEvent !== false) {\n    listenerProps[touchEvent] = handleClickAway;\n    listenerProps.onTouchMove = handleTouchMove;\n  }\n\n  return (\n    <React.Fragment>\n      {React.cloneElement(children, { ref: handleRef })}\n      <EventListener target=\"document\" {...listenerProps} />\n    </React.Fragment>\n  );\n}", "language": "javascript"}
{"input": "Increase the length and change the dimensionality.\n\n  Expand/project each positions of dim depth of the input into\n  factor*tokens of dim out_depth\n\n  Args:\n    x (tf.Tensor): shape [batch_size, length, depth]\n    factor (int): Multiplicative factor of each tokens.\n    out_depth (int): Output depth (if None, keep depth constant)\n\n  Returns:\n    tf.Tensor: shape [batch_size, length*factor, out_depth]", "output": "def deconv_elems_1d(x, factor, out_depth=None):\n  \"\"\"Increase the length and change the dimensionality.\n\n  Expand/project each positions of dim depth of the input into\n  factor*tokens of dim out_depth\n\n  Args:\n    x (tf.Tensor): shape [batch_size, length, depth]\n    factor (int): Multiplicative factor of each tokens.\n    out_depth (int): Output depth (if None, keep depth constant)\n\n  Returns:\n    tf.Tensor: shape [batch_size, length*factor, out_depth]\n  \"\"\"\n  out_depth = out_depth or x.get_shape().as_list()[-1]\n  x = tf.expand_dims(x, 1)  # [batch_size, 1, length, depth]\n  x = layers().Conv2DTranspose(\n      filters=out_depth,\n      kernel_size=(1, factor),\n      strides=(1, factor),\n      padding=\"valid\",\n      data_format=\"channels_last\",\n  )(x)  # [batch_size, 1, length*factor, out_depth]\n  x = tf.squeeze(x, 1)  # [batch_size, length*factor, depth]\n  return x", "language": "python"}
{"input": "Return values for selected item (ndarray or BlockManager).", "output": "def get(self, item, fastpath=True):\n        \"\"\"\n        Return values for selected item (ndarray or BlockManager).\n        \"\"\"\n        if self.items.is_unique:\n\n            if not isna(item):\n                loc = self.items.get_loc(item)\n            else:\n                indexer = np.arange(len(self.items))[isna(self.items)]\n\n                # allow a single nan location indexer\n                if not is_scalar(indexer):\n                    if len(indexer) == 1:\n                        loc = indexer.item()\n                    else:\n                        raise ValueError(\"cannot label index with a null key\")\n\n            return self.iget(loc, fastpath=fastpath)\n        else:\n\n            if isna(item):\n                raise TypeError(\"cannot label index with a null key\")\n\n            indexer = self.items.get_indexer_for([item])\n            return self.reindex_indexer(new_axis=self.items[indexer],\n                                        indexer=indexer, axis=0,\n                                        allow_dups=True)", "language": "python"}
{"input": "Add a .py or .zip dependency for all tasks to be executed on this\n        SparkContext in the future.  The C{path} passed can be either a local\n        file, a file in HDFS (or other Hadoop-supported filesystems), or an\n        HTTP, HTTPS or FTP URI.\n\n        .. note:: A path can be added only once. Subsequent additions of the same path are ignored.", "output": "def addPyFile(self, path):\n        \"\"\"\n        Add a .py or .zip dependency for all tasks to be executed on this\n        SparkContext in the future.  The C{path} passed can be either a local\n        file, a file in HDFS (or other Hadoop-supported filesystems), or an\n        HTTP, HTTPS or FTP URI.\n\n        .. note:: A path can be added only once. Subsequent additions of the same path are ignored.\n        \"\"\"\n        self.addFile(path)\n        (dirname, filename) = os.path.split(path)  # dirname may be directory or HDFS/S3 prefix\n        if filename[-4:].lower() in self.PACKAGE_EXTENSIONS:\n            self._python_includes.append(filename)\n            # for tests in local mode\n            sys.path.insert(1, os.path.join(SparkFiles.getRootDirectory(), filename))\n        if sys.version > '3':\n            import importlib\n            importlib.invalidate_caches()", "language": "python"}
{"input": "Load a model from an installed package.", "output": "def load_model_from_package(name, **overrides):\n    \"\"\"Load a model from an installed package.\"\"\"\n    cls = importlib.import_module(name)\n    return cls.load(**overrides)", "language": "python"}
{"input": "Linearly interpolate channel at \"rank\" between two tensors.\n\n  The channels are ranked according to their L2 norm between tensor1[channel]\n  and tensor2[channel].\n\n  Args:\n    tensor1: 4-D Tensor, NHWC\n    tensor2: 4-D Tensor, NHWC\n    coeffs: list of floats.\n    rank: integer.\n  Returns:\n    interp_latents: list of interpolated 4-D Tensors, shape=(NHWC)", "output": "def linear_interpolate_rank(tensor1, tensor2, coeffs, rank=1):\n  \"\"\"Linearly interpolate channel at \"rank\" between two tensors.\n\n  The channels are ranked according to their L2 norm between tensor1[channel]\n  and tensor2[channel].\n\n  Args:\n    tensor1: 4-D Tensor, NHWC\n    tensor2: 4-D Tensor, NHWC\n    coeffs: list of floats.\n    rank: integer.\n  Returns:\n    interp_latents: list of interpolated 4-D Tensors, shape=(NHWC)\n  \"\"\"\n  # sum across space, max across channels.\n  _, _, _, num_channels = common_layers.shape_list(tensor1)\n  diff_sq_sum = tf.reduce_sum((tensor1 - tensor2)**2, axis=(0, 1, 2))\n  _, feature_ranks = tf.math.top_k(diff_sq_sum, k=rank)\n  feature_rank = feature_ranks[-1]\n  channel_inds = tf.range(num_channels, dtype=tf.int32)\n  channel_mask = tf.equal(channel_inds, feature_rank)\n  ones_t = tf.ones(num_channels, dtype=tf.float32)\n  zeros_t = tf.zeros(num_channels, dtype=tf.float32)\n\n  interp_tensors = []\n  for coeff in coeffs:\n    curr_coeff = tf.where(channel_mask, coeff * ones_t, zeros_t)\n    interp_tensor = tensor1 + curr_coeff * (tensor2 - tensor1)\n    interp_tensors.append(interp_tensor)\n  return tf.concat(interp_tensors, axis=0)", "language": "python"}
{"input": "Get the outer sizes of the given element (offset size + margins)\n@method\n@memberof Popper.Utils\n@argument {Element} element\n@returns {Object} object containing width and height properties", "output": "function getOuterSizes(element) {\n  const window = element.ownerDocument.defaultView;\n  const styles = window.getComputedStyle(element);\n  const x = parseFloat(styles.marginTop || 0) + parseFloat(styles.marginBottom || 0);\n  const y = parseFloat(styles.marginLeft || 0) + parseFloat(styles.marginRight || 0);\n  const result = {\n    width: element.offsetWidth + y,\n    height: element.offsetHeight + x\n  };\n  return result;\n}", "language": "javascript"}
{"input": "Implements a downwards-striding conv block, like Xception exit flow.", "output": "def conv_block_downsample(x,\n                          kernel,\n                          strides,\n                          padding,\n                          separability=0,\n                          name=None,\n                          reuse=None):\n  \"\"\"Implements a downwards-striding conv block, like Xception exit flow.\"\"\"\n  with tf.variable_scope(\n      name, default_name=\"conv_block_downsample\", values=[x], reuse=reuse):\n    hidden_size = int(x.get_shape()[-1])\n    res = conv_block(\n        x,\n        int(1.25 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        strides=strides,\n        name=\"res_conv\")\n\n    x = subseparable_conv_block(\n        x,\n        hidden_size, [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv0\")\n    x = subseparable_conv_block(\n        x,\n        int(1.25 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv1\")\n    x = pool(x, kernel, \"MAX\", padding, strides=strides)\n\n    x += res\n\n    x = subseparable_conv_block(\n        x,\n        2 * hidden_size, [((1, 1), kernel)],\n        first_relu=False,\n        padding=padding,\n        separability=separability,\n        name=\"conv2\")\n    x = subseparable_conv_block(\n        x,\n        int(2.5 * hidden_size), [((1, 1), kernel)],\n        padding=padding,\n        separability=separability,\n        name=\"conv3\")\n    return x", "language": "python"}
{"input": "Build argument docs in python style.\n\n    arg_names : list of str\n        Argument names.\n\n    arg_types : list of str\n        Argument type information.\n\n    arg_descs : list of str\n        Argument description information.\n\n    remove_dup : boolean, optional\n        Whether remove duplication or not.\n\n    Returns\n    -------\n    docstr : str\n        Python docstring of parameter sections.", "output": "def build_param_doc(arg_names, arg_types, arg_descs, remove_dup=True):\n    \"\"\"Build argument docs in python style.\n\n    arg_names : list of str\n        Argument names.\n\n    arg_types : list of str\n        Argument type information.\n\n    arg_descs : list of str\n        Argument description information.\n\n    remove_dup : boolean, optional\n        Whether remove duplication or not.\n\n    Returns\n    -------\n    docstr : str\n        Python docstring of parameter sections.\n    \"\"\"\n    param_keys = set()\n    param_str = []\n    for key, type_info, desc in zip(arg_names, arg_types, arg_descs):\n        if key in param_keys and remove_dup:\n            continue\n        if key == 'num_args':\n            continue\n        param_keys.add(key)\n        ret = '%s : %s' % (key, type_info)\n        if len(desc) != 0:\n            ret += '\\n    ' + desc\n        param_str.append(ret)\n    doc_str = ('Parameters\\n' +\n               '----------\\n' +\n               '%s\\n')\n    doc_str = doc_str % ('\\n'.join(param_str))\n    return doc_str", "language": "python"}
{"input": "Enable an agent. Takes effect next time a connection is made. Does not affect\ncurrent live development sessions.\n\n@param {string} name of agent to enable", "output": "function enableAgent(name) {\n        if (agents.hasOwnProperty(name) && !_enabledAgentNames.hasOwnProperty(name)) {\n            _enabledAgentNames[name] = true;\n        }\n    }", "language": "javascript"}
{"input": "Convert prediction and target from rgb to real.", "output": "def convert_rgb_to_real(prediction, targets):\n  \"\"\"Convert prediction and target from rgb to real.\"\"\"\n  prediction = tf.squeeze(prediction, axis=-1)\n  prediction = common_layers.convert_rgb_to_real(prediction)\n  targets = common_layers.convert_rgb_to_real(targets)\n  return prediction, targets", "language": "python"}
{"input": "Check whether the given node is in loop.\n@param {ASTNode} node A node to check.\n@param {ASTNode} parent A parent node to check.\n@returns {boolean} `true` if the node is in loop.", "output": "function isLooped(node, parent) {\n    switch (parent.type) {\n        case \"ForStatement\":\n            return (\n                node === parent.test ||\n                node === parent.update ||\n                node === parent.body\n            );\n\n        case \"ForOfStatement\":\n        case \"ForInStatement\":\n            return node === parent.body;\n\n        case \"WhileStatement\":\n        case \"DoWhileStatement\":\n            return node === parent.test || node === parent.body;\n\n        default:\n            return false;\n    }\n}", "language": "javascript"}
{"input": "recursively search for possible transition defined inside the component root", "output": "function locateNode (vnode: VNode): VNodeWithData {\n  return vnode.componentInstance && (!vnode.data || !vnode.data.transition)\n    ? locateNode(vnode.componentInstance._vnode)\n    : vnode\n}", "language": "javascript"}
{"input": "Convert ``side_spec`` to an openpyxl v2 Side object\n        Parameters\n        ----------\n        side_spec : str, dict\n            A string specifying the border style, or a dict with zero or more\n            of the following keys (or their synonyms).\n                'style' ('border_style')\n                'color'\n        Returns\n        -------\n        side : openpyxl.styles.Side", "output": "def _convert_to_side(cls, side_spec):\n        \"\"\"\n        Convert ``side_spec`` to an openpyxl v2 Side object\n        Parameters\n        ----------\n        side_spec : str, dict\n            A string specifying the border style, or a dict with zero or more\n            of the following keys (or their synonyms).\n                'style' ('border_style')\n                'color'\n        Returns\n        -------\n        side : openpyxl.styles.Side\n        \"\"\"\n\n        from openpyxl.styles import Side\n\n        _side_key_map = {\n            'border_style': 'style',\n        }\n\n        if isinstance(side_spec, str):\n            return Side(style=side_spec)\n\n        side_kwargs = {}\n        for k, v in side_spec.items():\n            if k in _side_key_map:\n                k = _side_key_map[k]\n            if k == 'color':\n                v = cls._convert_to_color(v)\n            side_kwargs[k] = v\n\n        return Side(**side_kwargs)", "language": "python"}
{"input": "given index, find out sub-db and sub-index\n\n        Parameters\n        ----------\n        index : int\n            index of a specific image\n\n        Returns\n        ----------\n        a tuple (sub-db, sub-index)", "output": "def _locate_index(self, index):\n        \"\"\"\n        given index, find out sub-db and sub-index\n\n        Parameters\n        ----------\n        index : int\n            index of a specific image\n\n        Returns\n        ----------\n        a tuple (sub-db, sub-index)\n        \"\"\"\n        assert index >= 0 and index < self.num_images, \"index out of range\"\n        pos = self.image_set_index[index]\n        for k, v in enumerate(self.imdbs):\n            if pos >= v.num_images:\n                pos -= v.num_images\n            else:\n                return (k, pos)", "language": "python"}
{"input": "Skip to the next or previous track.\n@param  {String} direction 'next' or 'prev'.", "output": "function(direction) {\n    var self = this;\n\n    // Get the next track based on the direction of the track.\n    var index = 0;\n    if (direction === 'prev') {\n      index = self.index - 1;\n      if (index < 0) {\n        index = self.playlist.length - 1;\n      }\n    } else {\n      index = self.index + 1;\n      if (index >= self.playlist.length) {\n        index = 0;\n      }\n    }\n\n    self.skipTo(index);\n  }", "language": "javascript"}
{"input": "Used to request one of the available entities of the pool.", "output": "function () {\n    var el;\n    if (this.availableEls.length === 0) {\n      if (this.data.dynamic === false) {\n        warn('Requested entity from empty pool: ' + this.attrName);\n        return;\n      } else {\n        warn('Requested entity from empty pool. This pool is dynamic and will resize ' +\n             'automatically. You might want to increase its initial size: ' + this.attrName);\n      }\n      this.createEntity();\n    }\n    el = this.availableEls.shift();\n    this.usedEls.push(el);\n    el.object3D.visible = true;\n    return el;\n  }", "language": "javascript"}
{"input": "Search in the list of files given and populate the results\n@param {array} fileList           array of file paths\n@param {Object} queryExpr\n@param {number} startFileIndex    the start index of the array from which the search has to be done\n@param {number} maxResultsToReturn  the maximum number of results to return in this search", "output": "function doSearchInFiles(fileList, queryExpr, startFileIndex, maxResultsToReturn) {\n    var i;\n    if (fileList.length === 0) {\n        console.log('no files found');\n        return;\n\n    } else {\n        startFileIndex = startFileIndex || 0;\n        for (i = startFileIndex; i < fileList.length && !foundMaximum; i++) {\n            doSearchInOneFile(fileList[i], getFileContentsForFile(fileList[i]), queryExpr, maxResultsToReturn);\n        }\n        lastSearchedIndex = i;\n    }\n}", "language": "javascript"}
{"input": "---------------------------------------------------------------------------", "output": "function replaceInFile (filename, regex, replacement) {\n    let contents = fs.readFileSync (filename, 'utf8')\n    const parts = contents.split (regex)\n    const newContents = parts[0] + replacement + parts[1]\n    fs.truncateSync (filename)\n    fs.writeFileSync (filename, newContents)\n}", "language": "javascript"}
{"input": "Merge two predictions into one. Assumes the predicate in tags1 overlap with\n    the predicate of tags2.", "output": "def merge_overlapping_predictions(tags1: List[str], tags2: List[str]) -> List[str]:\n    \"\"\"\n    Merge two predictions into one. Assumes the predicate in tags1 overlap with\n    the predicate of tags2.\n    \"\"\"\n    ret_sequence = []\n    prev_label = \"O\"\n\n    # Build a coherent sequence out of two\n    # spans which predicates' overlap\n\n    for tag1, tag2 in zip(tags1, tags2):\n        label1 = tag1.split(\"-\")[-1]\n        label2 = tag2.split(\"-\")[-1]\n        if (label1 == \"V\") or (label2 == \"V\"):\n            # Construct maximal predicate length -\n            # add predicate tag if any of the sequence predict it\n            cur_label = \"V\"\n\n        # Else - prefer an argument over 'O' label\n        elif label1 != \"O\":\n            cur_label = label1\n        else:\n            cur_label = label2\n\n        # Append cur tag to the returned sequence\n        cur_tag = get_coherent_next_tag(prev_label, cur_label)\n        prev_label = cur_label\n        ret_sequence.append(cur_tag)\n    return ret_sequence", "language": "python"}
{"input": "Segregate Series based on type and coerce into matrices.\n\n    Needs to handle a lot of exceptional cases.", "output": "def arrays_to_mgr(arrays, arr_names, index, columns, dtype=None):\n    \"\"\"\n    Segregate Series based on type and coerce into matrices.\n\n    Needs to handle a lot of exceptional cases.\n    \"\"\"\n    # figure out the index, if necessary\n    if index is None:\n        index = extract_index(arrays)\n    else:\n        index = ensure_index(index)\n\n    # don't force copy because getting jammed in an ndarray anyway\n    arrays = _homogenize(arrays, index, dtype)\n\n    # from BlockManager perspective\n    axes = [ensure_index(columns), index]\n\n    return create_block_manager_from_arrays(arrays, arr_names, axes)", "language": "python"}
{"input": "Get the element node that encloses the given location\n@param {location}", "output": "function allNodesAtLocation(location) {\n        var nodes = [];\n        exports.root.each(function each(n) {\n            if (n.type === DOMNode.TYPE_ELEMENT && n.isAtLocation(location)) {\n                nodes.push(n);\n            }\n        });\n        return nodes;\n    }", "language": "javascript"}
{"input": "Returns all dashboards metadata as a json dump", "output": "def export_dashboards(session):\n    \"\"\"Returns all dashboards metadata as a json dump\"\"\"\n    logging.info('Starting export')\n    dashboards = session.query(Dashboard)\n    dashboard_ids = []\n    for dashboard in dashboards:\n        dashboard_ids.append(dashboard.id)\n    data = Dashboard.export_dashboards(dashboard_ids)\n    return data", "language": "python"}
{"input": "Analyze scope of the given AST.\n@param {ASTNode} ast The `Program` node to analyze.\n@param {Object} parserOptions The parser options.\n@param {Object} visitorKeys The visitor keys.\n@returns {ScopeManager} The analysis result.", "output": "function analyzeScope(ast, parserOptions, visitorKeys) {\n    const ecmaFeatures = parserOptions.ecmaFeatures || {};\n    const ecmaVersion = parserOptions.ecmaVersion || 5;\n\n    return eslintScope.analyze(ast, {\n        ignoreEval: true,\n        nodejsScope: ecmaFeatures.globalReturn,\n        impliedStrict: ecmaFeatures.impliedStrict,\n        ecmaVersion,\n        sourceType: parserOptions.sourceType || \"script\",\n        childVisitorKeys: visitorKeys || evk.KEYS,\n        fallback: Traverser.getKeys\n    });\n}", "language": "javascript"}
{"input": "This is the main function for handing the \\ce and \\pu commands. It takes the argument to \\ce or \\pu and returns the corresponding TeX string.", "output": "function (tokens, stateMachine) {\n    // Recreate the argument string from KaTeX's array of tokens.\n    var str = \"\";\n    var expectedLoc = tokens[tokens.length - 1].loc.start\n    for (var i = tokens.length - 1; i >= 0; i--) {\n      if(tokens[i].loc.start > expectedLoc) {\n        // context.consumeArgs has eaten a space.\n        str += \" \";\n        expectedLoc = tokens[i].loc.start;\n      }\n      str += tokens[i].text;\n      expectedLoc += tokens[i].text.length;\n    }\n    var tex = texify.go(mhchemParser.go(str, stateMachine));\n    return tex;\n  }", "language": "javascript"}
{"input": "Finds out if all rows are selected in a table.\n\n@param {sap.ui.table.Table} oTable Instance of the table.\n@returns {boolean} Returns <code>true</code> if all rows in the table are selected.", "output": "function(oTable) {\n\t\t\tif (!oTable) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tvar iSelectableRowCount = oTable._getSelectableRowCount();\n\t\t\treturn iSelectableRowCount > 0 && iSelectableRowCount === oTable._getSelectedIndicesCount();\n\t\t}", "language": "javascript"}
{"input": "Block for if-else.\n@this Blockly.Block", "output": "function() {\n    this.jsonInit({\n      \"type\": \"control_if_else\",\n      \"message0\": Blockly.Msg.CONTROL_IF,\n      \"message1\": \"%1\",\n      \"message2\": Blockly.Msg.CONTROL_ELSE,\n      \"message3\": \"%1\",\n      \"args0\": [\n        {\n          \"type\": \"input_value\",\n          \"name\": \"CONDITION\",\n          \"check\": \"Boolean\"\n        }\n      ],\n      \"args1\": [\n        {\n          \"type\": \"input_statement\",\n          \"name\": \"SUBSTACK\"\n        }\n      ],\n      \"args3\": [\n        {\n          \"type\": \"input_statement\",\n          \"name\": \"SUBSTACK2\"\n        }\n      ],\n      \"category\": Blockly.Categories.control,\n      \"extensions\": [\"colours_control\", \"shape_statement\"]\n    });\n  }", "language": "javascript"}
{"input": "props \u7c7b\u578b\u68c0\u6d4b\n\n@param {Object} props", "output": "function parseType (props) {\n  const {\n    current\n  } = props\n\n  // \u629b\u51fa\u9519\u8bef\u4fe1\u606f\n  const throwErrorMsg = type => {\n    throw new TypeError(type + ' must be number')\n  }\n\n  if (current) isNumber(current) ? '' : throwErrorMsg('current')\n}", "language": "javascript"}
{"input": "Deep flattens an array. Helper to `flatten`, see its parameters", "output": "function flattenArray(array, filter, map, result) {\n  let index = -1;\n  while (++index < array.length) {\n    const value = array[index];\n    if (Array.isArray(value)) {\n      flattenArray(value, filter, map, result);\n    } else if (filter(value)) {\n      result.push(map(value));\n    }\n  }\n  return result;\n}", "language": "javascript"}
{"input": "Mean of the inputs but counting only those where targets != mask_id.", "output": "def masked_mean(inputs, targets, mask_id=None):\n  \"\"\"Mean of the inputs but counting only those where targets != mask_id.\"\"\"\n  inputs = [x.astype(np.float32) for x in inputs]\n  # We assume all elements in the list contribute equally.\n  # TODO(lukaszkaiser): remove this assumption (e.g., when masks differ).\n  length = len(inputs)\n  if mask_id is None:\n    # TODO(lukaszkaiser): can we just divide the sum by length? XLA optimizes?\n    return sum([np.mean(x) / length for x in inputs])\n  unmask = [1.0 - np.equal(t, mask_id).astype(np.float32) for t in targets]\n  return sum([np.sum(x * m) / (length * np.sum(m))\n              for x, m in zip(inputs, unmask)])", "language": "python"}
{"input": "Replace old document with new one in open editor & workingset", "output": "function openNewFile() {\n                var fileOpenPromise;\n\n                if (FileViewController.getFileSelectionFocus() === FileViewController.PROJECT_MANAGER) {\n                    // If selection is in the tree, leave workingset unchanged - even if orig file is in the list\n                    fileOpenPromise = FileViewController\n                        .openAndSelectDocument(path, FileViewController.PROJECT_MANAGER);\n                } else {\n                    // If selection is in workingset, replace orig item in place with the new file\n                    var info = MainViewManager.findInAllWorkingSets(doc.file.fullPath).shift();\n\n                    // Remove old file from workingset; no redraw yet since there's a pause before the new file is opened\n                    MainViewManager._removeView(info.paneId, doc.file, true);\n\n                    // Add new file to workingset, and ensure we now redraw (even if index hasn't changed)\n                    fileOpenPromise = handleFileAddToWorkingSetAndOpen({fullPath: path, paneId: info.paneId, index: info.index, forceRedraw: true});\n                }\n\n                // always configure editor after file is opened\n                fileOpenPromise.always(function () {\n                    _configureEditorAndResolve();\n                });\n            }", "language": "javascript"}
{"input": "True if this Response one of the permanent versions of redirect.", "output": "def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))", "language": "python"}
{"input": "Properly register a hook.", "output": "def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, '__iter__'):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))", "language": "python"}
{"input": "The methods below are all non-standard. The following batch were introduced by Mozilla but have since been removed from Mozilla.", "output": "function(node) {\n                assertRangeValid(this);\n\n                var parent = node.parentNode;\n                var nodeIndex = getNodeIndex(node);\n\n                if (!parent) {\n                    throw new DOMException(\"NOT_FOUND_ERR\");\n                }\n\n                var startComparison = this.comparePoint(parent, nodeIndex),\n                    endComparison = this.comparePoint(parent, nodeIndex + 1);\n\n                if (startComparison < 0) { // Node starts before\n                    return (endComparison > 0) ? n_b_a : n_b;\n                } else {\n                    return (endComparison > 0) ? n_a : n_i;\n                }\n            }", "language": "javascript"}
{"input": "Creates prefix and params for new `Block`.", "output": "def create(prefix, params, hint):\n        \"\"\"Creates prefix and params for new `Block`.\"\"\"\n        current = getattr(_BlockScope._current, \"value\", None)\n        if current is None:\n            if prefix is None:\n                if not hasattr(_name.NameManager._current, \"value\"):\n                    _name.NameManager._current.value = _name.NameManager()\n                prefix = _name.NameManager._current.value.get(None, hint) + '_'\n            if params is None:\n                params = ParameterDict(prefix)\n            else:\n                params = ParameterDict(params.prefix, params)\n            return prefix, params\n\n        if prefix is None:\n            count = current._counter.get(hint, 0)\n            prefix = '%s%d_'%(hint, count)\n            current._counter[hint] = count + 1\n        if params is None:\n            parent = current._block.params\n            params = ParameterDict(parent.prefix+prefix, parent._shared)\n        else:\n            params = ParameterDict(params.prefix, params)\n        return current._block.prefix+prefix, params", "language": "python"}
{"input": "Takes 'extensionList' and returns a version filtered to only those that match 'keyword'", "output": "function filterForKeyword(extensionList, word) {\n            var filteredList = [];\n            extensionList.forEach(function (id) {\n                var entry = self._getEntry(id);\n                if (entry && self._entryMatchesQuery(entry, word)) {\n                    filteredList.push(id);\n                }\n            });\n            return filteredList;\n        }", "language": "javascript"}
{"input": "Return boolean value whether task checked or not\n@param {object} token Token object\n@returns {boolean}\n@ignore", "output": "function isChecked(token) {\n    var checked = false;\n\n    if (token.content.indexOf('[x]') === 0 || token.content.indexOf('[X]') === 0) {\n        checked = true;\n    }\n\n    return checked;\n}", "language": "javascript"}
{"input": "Escapes all potentially dangerous characters, so that the\nresulting string can be safely inserted into attribute or\nelement text.\n@param value\n@returns {string} escaped text", "output": "function encodeEntities(value) {\n  return value.\n    replace(/&/g, '&amp;').\n    replace(SURROGATE_PAIR_REGEXP, function (value) {\n      var hi = value.charCodeAt(0);\n      var low = value.charCodeAt(1);\n      return '&#' + (((hi - 0xD800) * 0x400) + (low - 0xDC00) + 0x10000) + ';';\n    }).\n    replace(NON_ALPHANUMERIC_REGEXP, function (value) {\n      return '&#' + value.charCodeAt(0) + ';';\n    }).\n    replace(/</g, '&lt;').\n    replace(/>/g, '&gt;');\n}", "language": "javascript"}
{"input": "Returns the appropriate getter function for this kind of prop.\nIf prop == null, returns the emptyStringGetter.", "output": "function getterForProp(prop) {\n    if (prop == null)\n        return emptyStringGetter;\n    if (typeof prop === 'number') {\n        return numericIndexGetter;\n    }\n    else {\n        // deep or simple\n        if (prop.indexOf('.') !== -1) {\n            return deepValueGetter;\n        }\n        else {\n            return shallowValueGetter;\n        }\n    }\n}", "language": "javascript"}
{"input": "Returns (line, col) of the current position in the stream.", "output": "def position(self):\n        \"\"\"Returns (line, col) of the current position in the stream.\"\"\"\n        line, col = self._position(self.chunkOffset)\n        return (line + 1, col)", "language": "python"}
{"input": "Xception exit flow.", "output": "def xception_exit(inputs):\n  \"\"\"Xception exit flow.\"\"\"\n  with tf.variable_scope(\"xception_exit\"):\n    x = inputs\n    x_shape = x.get_shape().as_list()\n    if x_shape[1] is None or x_shape[2] is None:\n      length_float = tf.to_float(tf.shape(x)[1])\n      length_float *= tf.to_float(tf.shape(x)[2])\n      spatial_dim_float = tf.sqrt(length_float)\n      spatial_dim = tf.to_int32(spatial_dim_float)\n      x_depth = x_shape[3]\n      x = tf.reshape(x, [-1, spatial_dim, spatial_dim, x_depth])\n    elif x_shape[1] != x_shape[2]:\n      spatial_dim = int(math.sqrt(float(x_shape[1] * x_shape[2])))\n      if spatial_dim * spatial_dim != x_shape[1] * x_shape[2]:\n        raise ValueError(\"Assumed inputs were square-able but they were \"\n                         \"not. Shape: %s\" % x_shape)\n      x = tf.reshape(x, [-1, spatial_dim, spatial_dim, x_depth])\n\n    x = common_layers.conv_block_downsample(x, (3, 3), (2, 2), \"SAME\")\n    return tf.nn.relu(x)", "language": "python"}
{"input": "Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``FileNotFoundError`` if `filename` or its stored metadata do not exist.", "output": "def filename_to_url(filename: str, cache_dir: str = None) -> Tuple[str, str]:\n    \"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``FileNotFoundError`` if `filename` or its stored metadata do not exist.\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = CACHE_DIRECTORY\n\n    cache_path = os.path.join(cache_dir, filename)\n    if not os.path.exists(cache_path):\n        raise FileNotFoundError(\"file {} not found\".format(cache_path))\n\n    meta_path = cache_path + '.json'\n    if not os.path.exists(meta_path):\n        raise FileNotFoundError(\"file {} not found\".format(meta_path))\n\n    with open(meta_path) as meta_file:\n        metadata = json.load(meta_file)\n    url = metadata['url']\n    etag = metadata['etag']\n\n    return url, etag", "language": "python"}
{"input": "Returns an array which identifies the memory layout. Each entry\n    of the array will contain a dictionary with the following keys:\n        addr        - Address of this memory segment\n        last_addr   - Last address contained within the memory segment.\n        size        - size of the segment, in bytes\n        num_pages   - number of pages in the segment\n        page_size   - size of each page, in bytes", "output": "def get_memory_layout(device):\n    \"\"\"Returns an array which identifies the memory layout. Each entry\n    of the array will contain a dictionary with the following keys:\n        addr        - Address of this memory segment\n        last_addr   - Last address contained within the memory segment.\n        size        - size of the segment, in bytes\n        num_pages   - number of pages in the segment\n        page_size   - size of each page, in bytes\n    \"\"\"\n    cfg = device[0]\n    intf = cfg[(0, 0)]\n    mem_layout_str = get_string(device, intf.iInterface)\n    mem_layout = mem_layout_str.split('/')\n    result = []\n    for mem_layout_index in range(1, len(mem_layout), 2):\n        addr = int(mem_layout[mem_layout_index], 0)\n        segments = mem_layout[mem_layout_index + 1].split(',')\n        seg_re = re.compile(r'(\\d+)\\*(\\d+)(.)(.)')\n        for segment in segments:\n            seg_match = seg_re.match(segment)\n            num_pages = int(seg_match.groups()[0], 10)\n            page_size = int(seg_match.groups()[1], 10)\n            multiplier = seg_match.groups()[2]\n            if multiplier == 'K':\n                page_size *= 1024\n            if multiplier == 'M':\n                page_size *= 1024 * 1024\n            size = num_pages * page_size\n            last_addr = addr + size - 1\n            result.append(named((addr, last_addr, size, num_pages, page_size),\n                          \"addr last_addr size num_pages page_size\"))\n            addr += size\n    return result", "language": "python"}
{"input": "Given an image, return the 128-dimension face encoding for each face in the image.\n\n    :param face_image: The image that contains one or more faces\n    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n    :return: A list of 128-dimensional face encodings (one for each face in the image)", "output": "def face_encodings(face_image, known_face_locations=None, num_jitters=1):\n    \"\"\"\n    Given an image, return the 128-dimension face encoding for each face in the image.\n\n    :param face_image: The image that contains one or more faces\n    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.\n    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)\n    :return: A list of 128-dimensional face encodings (one for each face in the image)\n    \"\"\"\n    raw_landmarks = _raw_face_landmarks(face_image, known_face_locations, model=\"small\")\n    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]", "language": "python"}
{"input": "Get the URI to locate the entity set for the dimension memebers.\n\n@param {String}\nsServiceRootURI (optional) Identifies the root of the OData\nservice\n@returns {String} The resource path of the URI pointing to the entity\nset. It is a relative URI unless a service root is given, which\nwould then prefixed in order to return a complete URL.\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.DimensionMemberSetRequest#getURIToDimensionMemberEntitySet", "output": "function(sServiceRootURI) {\n\t\t\tvar sResourcePath = null;\n\t\t\tif (!this._bUseMasterData && this._oParameterizationRequest) {\n\t\t\t\tsResourcePath = this._oParameterizationRequest.getURIToParameterizationEntry(sServiceRootURI) + \"/\"\n\t\t\t\t\t\t+ this._oDimension.getContainingQueryResult().getParameterization().getNavigationPropertyToQueryResult();\n\t\t\t} else {\n\t\t\t\tsResourcePath = (sServiceRootURI ? sServiceRootURI : \"\") + \"/\" + this._oEntitySet.getQName();\n\t\t\t}\n\t\t\treturn sResourcePath;\n\t\t}", "language": "javascript"}
{"input": "## Model Data Functions \n### Find All\nFetches all the data for a particular model\n@param {Object} unfilteredOptions (optional)\n@return {Promise(ghostBookshelf.Collection)} Collection of all Models", "output": "function findAll(unfilteredOptions) {\n        var options = this.filterOptions(unfilteredOptions, 'findAll'),\n            itemCollection = this.forge();\n\n        // @TODO: we can't use order raw when running migrations (see https://github.com/tgriesser/knex/issues/2763)\n        if (this.orderDefaultRaw && !options.migrating) {\n            itemCollection.query((qb) => {\n                qb.orderByRaw(this.orderDefaultRaw(options));\n            });\n        }\n\n        itemCollection.applyDefaultAndCustomFilters(options);\n        return itemCollection.fetchAll(options).then(function then(result) {\n            if (options.withRelated) {\n                _.each(result.models, function each(item) {\n                    item.withRelated = options.withRelated;\n                });\n            }\n\n            return result;\n        });\n    }", "language": "javascript"}
{"input": "Stop spinner, compose last frame and 'freeze' it.", "output": "def _freeze(self, final_text):\n        \"\"\"Stop spinner, compose last frame and 'freeze' it.\"\"\"\n        text = to_unicode(final_text)\n        self._last_frame = self._compose_out(text, mode=\"last\")\n\n        # Should be stopped here, otherwise prints after\n        # self._freeze call will mess up the spinner\n        self.stop()\n        sys.stdout.write(self._last_frame)", "language": "python"}
{"input": "Add Auth configuration to the Swagger file, if necessary", "output": "def _add_auth(self):\n        \"\"\"\n        Add Auth configuration to the Swagger file, if necessary\n        \"\"\"\n\n        if not self.auth:\n            return\n\n        if self.auth and not self.definition_body:\n            raise InvalidResourceException(self.logical_id,\n                                           \"Auth works only with inline Swagger specified in \"\n                                           \"'DefinitionBody' property\")\n\n        # Make sure keys in the dict are recognized\n        if not all(key in AuthProperties._fields for key in self.auth.keys()):\n            raise InvalidResourceException(\n                self.logical_id, \"Invalid value for 'Auth' property\")\n\n        if not SwaggerEditor.is_valid(self.definition_body):\n            raise InvalidResourceException(self.logical_id, \"Unable to add Auth configuration because \"\n                                                            \"'DefinitionBody' does not contain a valid Swagger\")\n        swagger_editor = SwaggerEditor(self.definition_body)\n        auth_properties = AuthProperties(**self.auth)\n        authorizers = self._get_authorizers(auth_properties.Authorizers, auth_properties.DefaultAuthorizer)\n\n        if authorizers:\n            swagger_editor.add_authorizers(authorizers)\n            self._set_default_authorizer(swagger_editor, authorizers, auth_properties.DefaultAuthorizer)\n\n        # Assign the Swagger back to template\n        self.definition_body = swagger_editor.swagger", "language": "python"}
{"input": "Parses font options and returns the font object.\n@param {object} options - A object that contains font options to be parsed.\n@return {object} The font object.\n@todo Support font.* options and renamed to toFont().\n@private", "output": "function(options) {\n\t\tvar globalDefaults = core_defaults.global;\n\t\tvar size = valueOrDefault(options.fontSize, globalDefaults.defaultFontSize);\n\t\tvar font = {\n\t\t\tfamily: valueOrDefault(options.fontFamily, globalDefaults.defaultFontFamily),\n\t\t\tlineHeight: helpers_core.options.toLineHeight(valueOrDefault(options.lineHeight, globalDefaults.defaultLineHeight), size),\n\t\t\tsize: size,\n\t\t\tstyle: valueOrDefault(options.fontStyle, globalDefaults.defaultFontStyle),\n\t\t\tweight: null,\n\t\t\tstring: ''\n\t\t};\n\n\t\tfont.string = toFontString(font);\n\t\treturn font;\n\t}", "language": "javascript"}
{"input": "Emit a ray to beginb uilding the scene.\n@param  {Number} sin    Sine of the cast angle.\n@param  {Number} cos    Cosine of the cast angle.\n@param  {Number} range  Max length of the ray.\n@param  {Object} origin x, y, height and sitance", "output": "function(sin, cos, range, origin) {\n    var stepX = this.step(sin, cos, origin.x, origin.y, false);\n    var stepY = this.step(cos, sin, origin.y, origin.x, true);\n    \n    var inspectX = [sin, cos, stepX, 1, 0, origin.dist, stepX.y];\n    var inspectY = [sin, cos, stepY, 0, 1, origin.dist, stepY.x];\n    var next = this.inspect.apply(this, (stepX.len2 < stepY.len2) ? inspectX : inspectY);\n\n    if (next.dist > range) {\n      return [origin];\n    }\n\n    return [origin].concat(this.ray(sin, cos, range, next));\n  }", "language": "javascript"}
{"input": "Push the item in the priority queue.\n        if priority is not given, priority is set to the value of item.", "output": "def push(self, item, priority=None):\n        \"\"\"Push the item in the priority queue.\n        if priority is not given, priority is set to the value of item.\n        \"\"\"\n        priority = item if priority is None else priority\n        node = PriorityQueueNode(item, priority)\n        for index, current in enumerate(self.priority_queue_list):\n            if current.priority < node.priority:\n                self.priority_queue_list.insert(index, node)\n                return\n        # when traversed complete queue\n        self.priority_queue_list.append(node)", "language": "python"}
{"input": "Add Support for multiple select return 1...n", "output": "function(data, select, currentPath) {\n\t\t\t\t\t\tvar result = {};\n\t\t\t\t\t\t// traversed path to get to data:\n\t\t\t\t\t\tcurrentPath = currentPath || '';\n\t\t\t\t\t\tif (typeof data !== 'object') {\n\t\t\t\t\t\t\treturn data;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (typeof data.slice === 'function') {\n\t\t\t\t\t\t\treturn data.map(function(el, index) {\n\t\t\t\t\t\t\t\treturn fnMultiSelect(el, select, currentPath); // on same path\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// If Object:\n\t\t\t\t\t\t// Handle \"__metadata\" property\n\t\t\t\t\t\tif (data.__metadata !== undefined && currentPath.length === 0) {\n\t\t\t\t\t\t\tresult.__metadata = data.__metadata;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Take the relevant paths only.\n\t\t\t\t\t\tselect.filter(function(path) {\n\t\t\t\t\t\t\treturn (path + '/').indexOf(currentPath) === 0;\n\t\t\t\t\t\t}).forEach(function(path, _, innerSelect) {\n\t\t\t\t\t\t\t// then get the next property in given path\n\t\t\t\t\t\t\tvar propertyKey = path.substr(currentPath.length).split('/')[0];\n\t\t\t\t\t\t\t// Check if we have that propertyKey on the current object\n\t\t\t\t\t\t\tif (data[propertyKey] !== undefined) {\n\t\t\t\t\t\t\t\t// in this case recurse again while adding this to the current path\n\t\t\t\t\t\t\t\tresult[propertyKey] = fnMultiSelect(data[propertyKey], innerSelect, currentPath + propertyKey + '/');\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t\t// Add specific results case handling\n\t\t\t\t\t\tif (data.results !== undefined) { // recurse with same path\n\t\t\t\t\t\t\tresult.results = fnMultiSelect(data.results, select, currentPath);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t}", "language": "javascript"}
{"input": "Checks whether given 2 nodes are identifiers which have the same name or not.\n\n@param {ASTNode} ctorParam - A node to check.\n@param {ASTNode} superArg - A node to check.\n@returns {boolean} `true` if the nodes are identifiers which have the same\nname.", "output": "function isValidIdentifierPair(ctorParam, superArg) {\n    return (\n        ctorParam.type === \"Identifier\" &&\n        superArg.type === \"Identifier\" &&\n        ctorParam.name === superArg.name\n    );\n}", "language": "javascript"}
{"input": "Redispatch these CodeMirror key events as Editor events", "output": "function _onKeyEvent(instance, event) {\n            self.trigger(\"keyEvent\", self, event);  // deprecated\n            self.trigger(event.type, self, event);\n            return event.defaultPrevented;   // false tells CodeMirror we didn't eat the event\n        }", "language": "javascript"}
{"input": "Run the main event loop for collector thread.\n\n        In each round the collector traverse the results log directory\n        and reload trial information from the status files.", "output": "def run(self):\n        \"\"\"Run the main event loop for collector thread.\n\n        In each round the collector traverse the results log directory\n        and reload trial information from the status files.\n        \"\"\"\n        self._initialize()\n\n        self._do_collect()\n        while not self._is_finished:\n            time.sleep(self._reload_interval)\n            self._do_collect()\n\n        self.logger.info(\"Collector stopped.\")", "language": "python"}
{"input": "Converts 0x-prefixed color to hex\n@param {string} color - Color to convert\n@param {boolean} convertToString - true if color should\nbe returned as string\n@returns {tinycolor|string} - Hex color as a Tinycolor object\nor a hex string", "output": "function _0xColorToHex(color, convertToStr) {\n        var hexColor = tinycolor(color.replace(\"0x\", \"#\"));\n        hexColor._format = \"0x\";\n\n        if (convertToStr) {\n            return hexColor.toString();\n        }\n        return hexColor;\n    }", "language": "javascript"}
{"input": "Prepare the master working set.", "output": "def _build_master(cls):\n        \"\"\"\n        Prepare the master working set.\n        \"\"\"\n        ws = cls()\n        try:\n            from __main__ import __requires__\n        except ImportError:\n            # The main program does not list any requirements\n            return ws\n\n        # ensure the requirements are met\n        try:\n            ws.require(__requires__)\n        except VersionConflict:\n            return cls._build_from_requirements(__requires__)\n\n        return ws", "language": "python"}
{"input": "List of ints to list of str.", "output": "def decode_list(self, integers):\n    \"\"\"List of ints to list of str.\"\"\"\n    integers = list(np.squeeze(integers))\n    return self.encoders[\"inputs\"].decode_list(integers)", "language": "python"}
{"input": "Intent each line with indent", "output": "def _indent(s, indent='  '):\n    \"\"\"Intent each line with indent\"\"\"\n    if isinstance(s, six.string_types):\n        return '\\n'.join(('%s%s' % (indent, line) for line in s.splitlines()))\n    return s", "language": "python"}
{"input": "A <Link> wrapper that knows if it's \"active\" or not.", "output": "function NavLink({\n  \"aria-current\": ariaCurrent = \"page\",\n  activeClassName = \"active\",\n  activeStyle,\n  className: classNameProp,\n  exact,\n  isActive: isActiveProp,\n  location,\n  strict,\n  style: styleProp,\n  to,\n  ...rest\n}) {\n  const path = typeof to === \"object\" ? to.pathname : to;\n\n  // Regex taken from: https://github.com/pillarjs/path-to-regexp/blob/master/index.js#L202\n  const escapedPath = path && path.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n\n  return (\n    <Route\n      path={escapedPath}\n      exact={exact}\n      strict={strict}\n      location={location}\n      children={({ location, match }) => {\n        const isActive = !!(isActiveProp\n          ? isActiveProp(match, location)\n          : match);\n\n        const className = isActive\n          ? joinClassnames(classNameProp, activeClassName)\n          : classNameProp;\n        const style = isActive ? { ...styleProp, ...activeStyle } : styleProp;\n\n        return (\n          <Link\n            aria-current={(isActive && ariaCurrent) || null}\n            className={className}\n            style={style}\n            to={to}\n            {...rest}\n          />\n        );\n      }}\n    />\n  );\n}", "language": "javascript"}
{"input": "Checks if an API Gateway integration is already present at the given path/method\n\n        :param string path: Path name\n        :param string method: HTTP method\n        :return: True, if an API Gateway integration is already present", "output": "def has_integration(self, path, method):\n        \"\"\"\n        Checks if an API Gateway integration is already present at the given path/method\n\n        :param string path: Path name\n        :param string method: HTTP method\n        :return: True, if an API Gateway integration is already present\n        \"\"\"\n        method = self._normalize_method_name(method)\n\n        path_dict = self.get_path(path)\n        return self.has_path(path, method) and \\\n            isinstance(path_dict[method], dict) and \\\n            self.method_has_integration(path_dict[method])", "language": "python"}
{"input": "Get the style sheets for a url\n@param {string} url\n@return {Object.<string, CSSStyleSheetHeader>}", "output": "function styleForURL(url) {\n        var styleSheetId, styles = {};\n        url = _canonicalize(url);\n        for (styleSheetId in _styleSheetDetails) {\n            if (_styleSheetDetails[styleSheetId].canonicalizedURL === url) {\n                styles[styleSheetId] = _styleSheetDetails[styleSheetId];\n            }\n        }\n        return styles;\n    }", "language": "javascript"}
{"input": "Given the (reconstructed) library name, find appropriate destination", "output": "def license_destination(vendor_dir, libname, filename):\n    \"\"\"Given the (reconstructed) library name, find appropriate destination\"\"\"\n    normal = vendor_dir / libname\n    if normal.is_dir():\n        return normal / filename\n    lowercase = vendor_dir / libname.lower().replace('-', '_')\n    if lowercase.is_dir():\n        return lowercase / filename\n    rename_dict = LIBRARY_RENAMES if vendor_dir.name != 'patched' else PATCHED_RENAMES\n    # Short circuit all logic if we are renaming the whole library\n    if libname in rename_dict:\n        return vendor_dir / rename_dict[libname] / filename\n    if libname in LIBRARY_DIRNAMES:\n        override = vendor_dir / LIBRARY_DIRNAMES[libname]\n        if not override.exists() and override.parent.exists():\n            # for flattened subdeps, specifically backports/weakref.py\n            return (\n                vendor_dir / override.parent\n            ) / '{0}.{1}'.format(override.name, filename)\n        return vendor_dir / LIBRARY_DIRNAMES[libname] / filename\n    # fallback to libname.LICENSE (used for nondirs)\n    return vendor_dir / '{}.{}'.format(libname, filename)", "language": "python"}
{"input": "View the internal symbols using the forward function.\n\n        :param sym_name:\n        :param bucket_kwargs:\n        :param input_dict:\n        :return:", "output": "def compute_internal(self, sym_name, bucket_kwargs=None, **arg_dict):\n        \"\"\"\n        View the internal symbols using the forward function.\n\n        :param sym_name:\n        :param bucket_kwargs:\n        :param input_dict:\n        :return:\n        \"\"\"\n        data_shapes = {k: v.shape for k, v in arg_dict.items()}\n        self.switch_bucket(bucket_kwargs=bucket_kwargs,\n                           data_shapes=data_shapes)\n        internal_sym = self.sym.get_internals()[sym_name]\n        data_inputs = {k: mx.nd.empty(v, ctx=self.ctx)\n                       for k, v in self.data_shapes.items()\n                       if k in internal_sym.list_arguments()}\n        params = {k: v for k, v in self.params.items() if\n                  k in internal_sym.list_arguments()}\n        aux_states = {k: v for k, v in self.aux_states.items()\n                      if k in internal_sym.list_auxiliary_states()}\n        exe = internal_sym.bind(ctx=self.ctx,\n                                args=dict(params, **data_inputs),\n                                args_grad=None,\n                                grad_req='null',\n                                aux_states=aux_states,\n                                shared_exec=self.exe)\n        for k, v in arg_dict.items():\n            exe.arg_dict[k][:] = v\n        exe.forward(is_train=False)\n        assert 1 == len(exe.outputs)\n        for output in exe.outputs:\n            output.wait_to_read()\n        return exe.outputs[0]", "language": "python"}
{"input": "Yield directories starting from the given directory up to the root", "output": "def _walk_to_root(path):\n    \"\"\"\n    Yield directories starting from the given directory up to the root\n    \"\"\"\n    if not os.path.exists(path):\n        raise IOError('Starting path not found')\n\n    if os.path.isfile(path):\n        path = os.path.dirname(path)\n\n    last_dir = None\n    current_dir = os.path.abspath(path)\n    while last_dir != current_dir:\n        yield current_dir\n        parent_dir = os.path.abspath(os.path.join(current_dir, os.path.pardir))\n        last_dir, current_dir = current_dir, parent_dir", "language": "python"}
{"input": "Explicitly start a new session. If we have an existing session,\nthen close the current one and restart a new one.\n@param {Editor} editor", "output": "function _startNewSession(editor) {\n        if (isOpen()) {\n            return;\n        }\n\n        if (!editor) {\n            editor = EditorManager.getFocusedEditor();\n        }\n        if (editor) {\n            lastChar = null;\n            if (_inSession(editor)) {\n                _endSession();\n            }\n\n            // Begin a new explicit session\n            _beginSession(editor);\n        }\n    }", "language": "javascript"}
{"input": "Saves the optimizer (updater) state to a file. This is often used when checkpointing\n        the model during training.\n\n        Parameters\n        ----------\n        fname : str\n            Path to the output states file.\n        dump_optimizer : bool, default False\n            Whether to also save the optimizer itself. This would also save optimizer\n            information such as learning rate and weight decay schedules.", "output": "def save_optimizer_states(self, fname, dump_optimizer=False):\n        \"\"\"Saves the optimizer (updater) state to a file. This is often used when checkpointing\n        the model during training.\n\n        Parameters\n        ----------\n        fname : str\n            Path to the output states file.\n        dump_optimizer : bool, default False\n            Whether to also save the optimizer itself. This would also save optimizer\n            information such as learning rate and weight decay schedules.\n        \"\"\"\n        assert self._updater is not None, \"Cannot save states for distributed training\"\n        with open(fname, 'wb') as fout:\n            fout.write(self._updater.get_states(dump_optimizer))", "language": "python"}
{"input": "Unwraps a node which is wrapped into a XPCNativeWrapper or XrayWrapper\n\n@param {DOMnode} Wrapped DOM node\n@returns {DOMNode} Unwrapped DOM node", "output": "function unwrapNode(aNode) {\n  var node = aNode;\n\n  if (node) {\n    // unwrap is not available on older branches (3.5 and 3.6) - Bug 533596\n    if (\"unwrap\" in XPCNativeWrapper) {\n      node = XPCNativeWrapper.unwrap(node);\n    }\n    else if (\"wrappedJSObject\" in node) {\n      node = node.wrappedJSObject;\n    }\n  }\n\n  return node;\n}", "language": "javascript"}
{"input": "Handles resolving replacements in the Sub action based on the handler that is passed as an input.\n\n        :param input_dict: Dictionary to be resolved\n        :param supported_values: One of several different objects that contain the supported values that\n            need to be changed. See each method above for specifics on these objects.\n        :param handler: handler that is specific to each implementation.\n        :return: Resolved value of the Sub dictionary", "output": "def _handle_sub_action(self, input_dict, handler):\n        \"\"\"\n        Handles resolving replacements in the Sub action based on the handler that is passed as an input.\n\n        :param input_dict: Dictionary to be resolved\n        :param supported_values: One of several different objects that contain the supported values that\n            need to be changed. See each method above for specifics on these objects.\n        :param handler: handler that is specific to each implementation.\n        :return: Resolved value of the Sub dictionary\n        \"\"\"\n        if not self.can_handle(input_dict):\n            return input_dict\n\n        key = self.intrinsic_name\n        sub_value = input_dict[key]\n\n        input_dict[key] = self._handle_sub_value(sub_value, handler)\n\n        return input_dict", "language": "python"}
{"input": "================================================================================ Helper methods ================================================================================ \nChecks if an sap.ui.core.URI parameter is an icon src or not.\n\n@protected\n@param {string} source The source to be checked.\n@returns {boolean} The result of the check.", "output": "function isIcon(source) {\n            if (!source) {\n                return false;\n            }\n\n            var result = window.URI.parse(source);\n            return (result.protocol && result.protocol == 'sap-icon');\n        }", "language": "javascript"}
{"input": "URL Template (RFC 6570) Transform.", "output": "function template (options) {\n\n    var variables = [], url = expand(options.url, options.params, variables);\n\n    variables.forEach(function (key) {\n        delete options.params[key];\n    });\n\n    return url;\n}", "language": "javascript"}
{"input": "Continuously poll the kernel 'shell' stream for messages until:\n         - It receives an 'execute_reply' status for the given message id\n         - The timeout is reached awaiting a message, in which case\n           a `Queue.Empty` exception will be raised.", "output": "def await_reply(self, msg_id, timeout=None):\n        \"\"\"\n        Continuously poll the kernel 'shell' stream for messages until:\n         - It receives an 'execute_reply' status for the given message id\n         - The timeout is reached awaiting a message, in which case\n           a `Queue.Empty` exception will be raised.\n        \"\"\"\n        while True:\n            msg = self.get_message(stream='shell', timeout=timeout)\n\n            # Is this the message we are waiting for?\n            if msg['parent_header'].get('msg_id') == msg_id:\n                if msg['content']['status'] == 'aborted':\n                    # This should not occur!\n                    raise RuntimeError('Kernel aborted execution request')\n                return", "language": "python"}
{"input": "sorter: [ new sap.ui.model.Sorter(\"/text\", false) ],", "output": "function(sId, oBindingContext) {\n\t\t\t\t\t\t\t\t\tvar oAvailableRoleType = oBindingContext.getObject();\n\t\t\t\t\t\t\t\t\treturn new Item({\n\t\t\t\t\t\t\t\t\t\tkey: oAvailableRoleType.key,\n\t\t\t\t\t\t\t\t\t\ttext: oAvailableRoleType.text\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}", "language": "javascript"}
{"input": "Sanitize hooks. If the hook is a string, convert it to Service method calling.\n\n@param {Function|String|Array<any>} hooks\n@param {Service?} service\n@returns", "output": "function sanitizeHooks(hooks, service) {\n\tif (_.isString(hooks))\n\t\treturn service && _.isFunction(service[hooks]) ? service[hooks] : null;\n\n\tif (Array.isArray(hooks)) {\n\t\treturn _.compact(hooks.map(h => {\n\t\t\tif (_.isString(h))\n\t\t\t\treturn service && _.isFunction(service[h]) ? service[h] : null;\n\n\t\t\treturn h;\n\t\t}));\n\t}\n\n\treturn hooks;\n}", "language": "javascript"}
{"input": "Enumerate a set of anchors for each aspect ratio wrt an anchor.", "output": "def _ratio_enum(anchor, ratios):\n        \"\"\"\n        Enumerate a set of anchors for each aspect ratio wrt an anchor.\n        \"\"\"\n        w, h, x_ctr, y_ctr = AnchorGenerator._whctrs(anchor)\n        size = w * h\n        size_ratios = size / ratios\n        ws = np.round(np.sqrt(size_ratios))\n        hs = np.round(ws * ratios)\n        anchors = AnchorGenerator._mkanchors(ws, hs, x_ctr, y_ctr)\n        return anchors", "language": "python"}
{"input": "Function: link\n\nAdds a hyperlink to the specified parent and invokes the given function\nwhen the link is clicked.\n\nParameters:\n\nparent - DOM node to contain the new link.\ntext - String that is used as the link label.\nfunct - Function to execute when the link is clicked.\npad - Optional left-padding for the link. Default is 0.", "output": "function(parent, text, funct, pad)\n\t{\n\t\tvar a = document.createElement('span');\n\t\t\n\t\ta.style.color = 'blue';\n\t\ta.style.textDecoration = 'underline';\n\t\ta.style.cursor = 'pointer';\n\t\t\n\t\tif (pad != null)\n\t\t{\n\t\t\ta.style.paddingLeft = pad+'px';\n\t\t}\n\t\t\n\t\tmxEvent.addListener(a, 'click', funct);\n\t\tmxUtils.write(a, text);\n\t\t\n\t\tif (parent != null)\n\t\t{\n\t\t\tparent.appendChild(a);\n\t\t}\n\t\t\n\t\treturn a;\n\t}", "language": "javascript"}
{"input": "Parameters\n    ----------\n    num_classes : int, default 1000\n        Number of classification classes.\n    num_layers : int\n        Number of layers for the variant of densenet. Options are 11, 13, 16, 19.\n    batch_norm : bool, default False\n        Use batch normalization.\n    dtype: str, float32 or float16\n        Data precision.", "output": "def get_symbol(num_classes, num_layers=11, batch_norm=False, dtype='float32', **kwargs):\n    \"\"\"\n    Parameters\n    ----------\n    num_classes : int, default 1000\n        Number of classification classes.\n    num_layers : int\n        Number of layers for the variant of densenet. Options are 11, 13, 16, 19.\n    batch_norm : bool, default False\n        Use batch normalization.\n    dtype: str, float32 or float16\n        Data precision.\n    \"\"\"\n    vgg_spec = {11: ([1, 1, 2, 2, 2], [64, 128, 256, 512, 512]),\n                13: ([2, 2, 2, 2, 2], [64, 128, 256, 512, 512]),\n                16: ([2, 2, 3, 3, 3], [64, 128, 256, 512, 512]),\n                19: ([2, 2, 4, 4, 4], [64, 128, 256, 512, 512])}\n    if num_layers not in vgg_spec:\n        raise ValueError(\"Invalide num_layers {}. Possible choices are 11,13,16,19.\".format(num_layers))\n    layers, filters = vgg_spec[num_layers]\n    data = mx.sym.Variable(name=\"data\")\n    if dtype == 'float16':\n        data = mx.sym.Cast(data=data, dtype=np.float16)\n    feature = get_feature(data, layers, filters, batch_norm)\n    classifier = get_classifier(feature, num_classes)\n    if dtype == 'float16':\n        classifier = mx.sym.Cast(data=classifier, dtype=np.float32)\n    symbol = mx.sym.SoftmaxOutput(data=classifier, name='softmax')\n    return symbol", "language": "python"}
{"input": "Adds the list of given files to the project cache. However the files will not be\nread at this time. We just delete the project cache entry which will trigger a fetch on search.\n@param   {Object}   updateObject", "output": "function addFilesToCache(updateObject) {\n    var fileList = updateObject.fileList || [],\n        filesInSearchScope = updateObject.filesInSearchScope || [],\n        i = 0,\n        changedFilesAlreadyInList = [],\n        newFiles = [];\n    for (i = 0; i < fileList.length; i++) {\n        // We just add a null entry indicating the precense of the file in the project list.\n        // The file will be later read when required.\n        projectCache[fileList[i]] = null;\n    }\n\n    //Now update the search scope\n    function isInChangedFileList(path) {\n        return (filesInSearchScope.indexOf(path) !== -1) ? true : false;\n    }\n    changedFilesAlreadyInList = files ? files.filter(isInChangedFileList) : [];\n    function isNotAlreadyInList(path) {\n        return (changedFilesAlreadyInList.indexOf(path) === -1) ? true : false;\n    }\n    newFiles = changedFilesAlreadyInList.filter(isNotAlreadyInList);\n    files.push.apply(files, newFiles);\n}", "language": "javascript"}
{"input": "Parameters\n    ----------\n    values : ndarray\n    axis: int, optional\n    skipna : bool, default True\n    mask : ndarray[bool], optional\n        nan-mask if known\n\n    Returns\n    --------\n    result : int\n        The index of max value in specified axis or -1 in the NA case\n\n    Examples\n    --------\n    >>> import pandas.core.nanops as nanops\n    >>> s = pd.Series([1, 2, 3, np.nan, 4])\n    >>> nanops.nanargmax(s)\n    4", "output": "def nanargmax(values, axis=None, skipna=True, mask=None):\n    \"\"\"\n    Parameters\n    ----------\n    values : ndarray\n    axis: int, optional\n    skipna : bool, default True\n    mask : ndarray[bool], optional\n        nan-mask if known\n\n    Returns\n    --------\n    result : int\n        The index of max value in specified axis or -1 in the NA case\n\n    Examples\n    --------\n    >>> import pandas.core.nanops as nanops\n    >>> s = pd.Series([1, 2, 3, np.nan, 4])\n    >>> nanops.nanargmax(s)\n    4\n    \"\"\"\n    values, mask, dtype, _, _ = _get_values(\n        values, skipna, fill_value_typ='-inf', mask=mask)\n    result = values.argmax(axis)\n    result = _maybe_arg_null_out(result, axis, mask, skipna)\n    return result", "language": "python"}
{"input": "This closes the connection with the child application. Note that\n        calling close() more than once is valid. This emulates standard Python\n        behavior with files. Set force to True if you want to make sure that\n        the child is terminated (SIGKILL is sent if the child ignores SIGHUP\n        and SIGINT).", "output": "def close(self, force=True):\n        '''This closes the connection with the child application. Note that\n        calling close() more than once is valid. This emulates standard Python\n        behavior with files. Set force to True if you want to make sure that\n        the child is terminated (SIGKILL is sent if the child ignores SIGHUP\n        and SIGINT). '''\n\n        self.flush()\n        with _wrap_ptyprocess_err():\n            # PtyProcessError may be raised if it is not possible to terminate\n            # the child.\n            self.ptyproc.close(force=force)\n        self.isalive()  # Update exit status from ptyproc\n        self.child_fd = -1\n        self.closed = True", "language": "python"}
{"input": "Batch Keep Absolute (retrain)\n    xlabel = \"Fraction of features kept\"\n    ylabel = \"R^2\"\n    transform = \"identity\"\n    sort_order = 13", "output": "def batch_keep_absolute_retrain__r2(X, y, model_generator, method_name, num_fcounts=11):\n    \"\"\" Batch Keep Absolute (retrain)\n    xlabel = \"Fraction of features kept\"\n    ylabel = \"R^2\"\n    transform = \"identity\"\n    sort_order = 13\n    \"\"\"\n    return __run_batch_abs_metric(measures.batch_keep_retrain, X, y, model_generator, method_name, sklearn.metrics.r2_score, num_fcounts)", "language": "python"}
{"input": "Map the function f to the nested structure x (dicts, tuples, lists).", "output": "def nested_map(x, f):\n  \"\"\"Map the function f to the nested structure x (dicts, tuples, lists).\"\"\"\n  if isinstance(x, list):\n    return [nested_map(y, f) for y in x]\n  if isinstance(x, tuple):\n    return tuple([nested_map(y, f) for y in x])\n  if isinstance(x, dict):\n    return {k: nested_map(x[k], f) for k in x}\n  return f(x)", "language": "python"}
{"input": "A simple HTML tokenizer. See the description of nextToken() for usage details.\n@constructor\n@param {string} text The HTML document to tokenize.", "output": "function Tokenizer(text) {\n        this._state = TEXT;\n        this._buffer = text;\n        this._sectionStart = 0;\n        this._sectionStartPos = {line: 0, ch: 0};\n        this._index = 0;\n        this._indexPos = {line: 0, ch: 0};\n        this._special = 0; // 1 for script, 2 for style\n        this._token = null;\n        this._nextToken = null;\n    }", "language": "javascript"}
{"input": "Checks whether the operator of a given node is mixed with parent\nnode's operator or not.\n\n@param {ASTNode} node - A node to check. This is a BinaryExpression\nnode or a LogicalExpression node. This parent node is one of\nthem, too.\n@returns {boolean} `true` if the node was mixed.", "output": "function isMixedWithParent(node) {\n            return (\n                node.operator !== node.parent.operator &&\n                !astUtils.isParenthesised(sourceCode, node)\n            );\n        }", "language": "javascript"}
{"input": "Updates the changelog, bumps the version number in package.json, creates a local git commit and tag,\nand generates the site in an adjacent `eslint.github.io` folder.\n@param {string} prereleaseId The prerelease identifier (alpha, beta, etc.)\n@returns {void}", "output": "function generatePrerelease(prereleaseId) {\n    ReleaseOps.generateRelease(prereleaseId);\n    const releaseInfo = JSON.parse(cat(\".eslint-release-info.json\"));\n    const nextMajor = semver.inc(releaseInfo.version, \"major\");\n\n    echo(\"Generating site\");\n\n    // always write docs into the next major directory (so 2.0.0-alpha.0 writes to 2.0.0)\n    target.gensite(nextMajor);\n\n    /*\n     * Premajor release should have identical \"next major version\".\n     * Preminor and prepatch release will not.\n     * 5.0.0-alpha.0 --> next major = 5, current major = 5\n     * 4.4.0-alpha.0 --> next major = 5, current major = 4\n     * 4.0.1-alpha.0 --> next major = 5, current major = 4\n     */\n    if (semver.major(releaseInfo.version) === semver.major(nextMajor)) {\n\n        /*\n         * This prerelease is for a major release (not preminor/prepatch).\n         * Blog post generation logic needs to be aware of this (as well as\n         * know what the next major version is actually supposed to be).\n         */\n        generateBlogPost(releaseInfo, nextMajor);\n    } else {\n        generateBlogPost(releaseInfo);\n    }\n\n    commitSiteToGit(`v${releaseInfo.version}`);\n}", "language": "javascript"}
{"input": "SVG elements do not inherit from HTMLElement", "output": "function getOffsetElement(el) {\n    return el\n        ? 'offsetTop' in el\n            ? el\n            : getOffsetElement(el.parentNode)\n        : document.body;\n}", "language": "javascript"}
{"input": "Sets up the initial layout so panes are evenly distributed\nThis also sets css properties that aid in the layout when _updateLayout is called\n@param {boolean} forceRefresh - true to force a resize and refresh of the entire view\n@private", "output": "function _initialLayout(forceRefresh) {\n        var panes = Object.keys(_panes),\n            size = 100 / panes.length;\n\n        _.forEach(_panes, function (pane) {\n            if (pane.id === FIRST_PANE) {\n                if (_orientation === VERTICAL) {\n                    pane.$el.css({height: \"100%\",\n                                  width: size + \"%\",\n                                  float: \"left\"\n                                 });\n                } else {\n                    pane.$el.css({ height: size + \"%\",\n                                   width: \"100%\"\n                                 });\n                }\n            } else {\n                if (_orientation === VERTICAL) {\n                    pane.$el.css({  height: \"100%\",\n                                    width: \"auto\",\n                                    float: \"none\"\n                                 });\n                } else {\n                    pane.$el.css({ width: \"100%\",\n                                   height: \"50%\"\n                                 });\n                }\n            }\n\n            _synchronizePaneSize(pane, forceRefresh);\n        });\n    }", "language": "javascript"}
{"input": "Spring solver inspired by Webkit Copyright \u00a9 2016 Apple Inc. All rights reserved. https://webkit.org/demos/spring/spring.js", "output": "function spring(string, duration) {\n\n  var params = parseEasingParameters(string);\n  var mass = minMax(is.und(params[0]) ? 1 : params[0], .1, 100);\n  var stiffness = minMax(is.und(params[1]) ? 100 : params[1], .1, 100);\n  var damping = minMax(is.und(params[2]) ? 10 : params[2], .1, 100);\n  var velocity =  minMax(is.und(params[3]) ? 0 : params[3], .1, 100);\n  var w0 = Math.sqrt(stiffness / mass);\n  var zeta = damping / (2 * Math.sqrt(stiffness * mass));\n  var wd = zeta < 1 ? w0 * Math.sqrt(1 - zeta * zeta) : 0;\n  var a = 1;\n  var b = zeta < 1 ? (zeta * w0 + -velocity) / wd : -velocity + w0;\n\n  function solver(t) {\n    var progress = duration ? (duration * t) / 1000 : t;\n    if (zeta < 1) {\n      progress = Math.exp(-progress * zeta * w0) * (a * Math.cos(wd * progress) + b * Math.sin(wd * progress));\n    } else {\n      progress = (a + b * progress) * Math.exp(-progress * w0);\n    }\n    if (t === 0 || t === 1) { return t; }\n    return 1 - progress;\n  }\n\n  function getDuration() {\n    var cached = cache.springs[string];\n    if (cached) { return cached; }\n    var frame = 1/6;\n    var elapsed = 0;\n    var rest = 0;\n    while(true) {\n      elapsed += frame;\n      if (solver(elapsed) === 1) {\n        rest++;\n        if (rest >= 16) { break; }\n      } else {\n        rest = 0;\n      }\n    }\n    var duration = elapsed * frame * 1000;\n    cache.springs[string] = duration;\n    return duration;\n  }\n\n  return duration ? solver : getDuration;\n\n}", "language": "javascript"}
{"input": "Get offsets to the reference element\n@method\n@memberof Popper.Utils\n@param {Object} state\n@param {Element} popper - the popper element\n@param {Element} reference - the reference element (the popper will be relative to this)\n@param {Element} fixedPosition - is in fixed position mode\n@returns {Object} An object containing the offsets which will be applied to the popper", "output": "function getReferenceOffsets(state, popper, reference, fixedPosition = null) {\n  const commonOffsetParent = fixedPosition ? getFixedPositionOffsetParent(popper) : findCommonOffsetParent(popper, reference);\n  return getOffsetRectRelativeToArbitraryNode(reference, commonOffsetParent, fixedPosition);\n}", "language": "javascript"}
{"input": "Crude approximation of what the label width might be\n@private", "output": "function(label) {\n\t\tvar me = this;\n\t\tvar ticksOpts = me.options.ticks;\n\t\tvar tickLabelWidth = me.ctx.measureText(label).width;\n\t\tvar angle = helpers.toRadians(ticksOpts.maxRotation);\n\t\tvar cosRotation = Math.cos(angle);\n\t\tvar sinRotation = Math.sin(angle);\n\t\tvar tickFontSize = valueOrDefault(ticksOpts.fontSize, defaults.global.defaultFontSize);\n\n\t\treturn (tickLabelWidth * cosRotation) + (tickFontSize * sinRotation);\n\t}", "language": "javascript"}
{"input": "Combine the items by creator and combiner", "output": "def mergeValues(self, iterator):\n        \"\"\" Combine the items by creator and combiner \"\"\"\n        # speedup attribute lookup\n        creator, comb = self.agg.createCombiner, self.agg.mergeValue\n        c, data, pdata, hfun, batch = 0, self.data, self.pdata, self._partition, self.batch\n        limit = self.memory_limit\n\n        for k, v in iterator:\n            d = pdata[hfun(k)] if pdata else data\n            d[k] = comb(d[k], v) if k in d else creator(v)\n\n            c += 1\n            if c >= batch:\n                if get_used_memory() >= limit:\n                    self._spill()\n                    limit = self._next_limit()\n                    batch /= 2\n                    c = 0\n                else:\n                    batch *= 1.5\n\n        if get_used_memory() >= limit:\n            self._spill()", "language": "python"}
{"input": "Return a pkg_resources.Distribution for this requirement", "output": "def get_dist(self):\n        # type: () -> Distribution\n        \"\"\"Return a pkg_resources.Distribution for this requirement\"\"\"\n        if self.metadata_directory:\n            base_dir, distinfo = os.path.split(self.metadata_directory)\n            metadata = pkg_resources.PathMetadata(\n                base_dir, self.metadata_directory\n            )\n            dist_name = os.path.splitext(distinfo)[0]\n            typ = pkg_resources.DistInfoDistribution\n        else:\n            egg_info = self.egg_info_path.rstrip(os.path.sep)\n            base_dir = os.path.dirname(egg_info)\n            metadata = pkg_resources.PathMetadata(base_dir, egg_info)\n            dist_name = os.path.splitext(os.path.basename(egg_info))[0]\n            # https://github.com/python/mypy/issues/1174\n            typ = pkg_resources.Distribution  # type: ignore\n\n        return typ(\n            base_dir,\n            project_name=dist_name,\n            metadata=metadata,\n        )", "language": "python"}
{"input": "Determines the variables that are in scope for a fragment given the variables\nin scope at the root query as well as any arguments applied at the fragment\nspread via `@arguments`.\n\nNote that this is analagous to determining function arguments given a function call.", "output": "function getFragmentVariables(\n  fragment: ReaderFragment,\n  rootVariables: Variables,\n  argumentVariables: Variables,\n): Variables {\n  let variables;\n  fragment.argumentDefinitions.forEach(definition => {\n    if (argumentVariables.hasOwnProperty(definition.name)) {\n      return;\n    }\n    variables = variables || {...argumentVariables};\n    switch (definition.kind) {\n      case 'LocalArgument':\n        variables[definition.name] = definition.defaultValue;\n        break;\n      case 'RootArgument':\n        if (!rootVariables.hasOwnProperty(definition.name)) {\n          /*\n           * Global variables passed as values of @arguments are not required to\n           * be declared unless they are used by the callee fragment or a\n           * descendant. In this case, the root variable may not be defined when\n           * resolving the callee's variables. The value is explicitly set to\n           * undefined to conform to the check in\n           * RelayStoreUtils.getStableVariableValue() that variable keys are all\n           * present.\n           */\n          variables[definition.name] = undefined;\n          break;\n        }\n        variables[definition.name] = rootVariables[definition.name];\n        break;\n      default:\n        (definition: empty);\n        invariant(\n          false,\n          'RelayConcreteVariables: Unexpected node kind `%s` in fragment `%s`.',\n          definition.kind,\n          fragment.name,\n        );\n    }", "language": "javascript"}
{"input": "helper which recursively generate an xlwt easy style string\n        for example:\n\n            hstyle = {\"font\": {\"bold\": True},\n            \"border\": {\"top\": \"thin\",\n                    \"right\": \"thin\",\n                    \"bottom\": \"thin\",\n                    \"left\": \"thin\"},\n            \"align\": {\"horiz\": \"center\"}}\n            will be converted to\n            font: bold on; \\\n                    border: top thin, right thin, bottom thin, left thin; \\\n                    align: horiz center;", "output": "def _style_to_xlwt(cls, item, firstlevel=True, field_sep=',',\n                       line_sep=';'):\n        \"\"\"helper which recursively generate an xlwt easy style string\n        for example:\n\n            hstyle = {\"font\": {\"bold\": True},\n            \"border\": {\"top\": \"thin\",\n                    \"right\": \"thin\",\n                    \"bottom\": \"thin\",\n                    \"left\": \"thin\"},\n            \"align\": {\"horiz\": \"center\"}}\n            will be converted to\n            font: bold on; \\\n                    border: top thin, right thin, bottom thin, left thin; \\\n                    align: horiz center;\n        \"\"\"\n        if hasattr(item, 'items'):\n            if firstlevel:\n                it = [\"{key}: {val}\"\n                      .format(key=key, val=cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"{sep} \".format(sep=(line_sep).join(it))\n                return out\n            else:\n                it = [\"{key} {val}\"\n                      .format(key=key, val=cls._style_to_xlwt(value, False))\n                      for key, value in item.items()]\n                out = \"{sep} \".format(sep=(field_sep).join(it))\n                return out\n        else:\n            item = \"{item}\".format(item=item)\n            item = item.replace(\"True\", \"on\")\n            item = item.replace(\"False\", \"off\")\n            return item", "language": "python"}
{"input": "Cheap model.\n\n  on lm1b_32k:\n     45M params\n     2 steps/sec on  [GeForce GTX TITAN X]\n\n  Returns:\n    an hparams object.", "output": "def attention_lm_small():\n  \"\"\"Cheap model.\n\n  on lm1b_32k:\n     45M params\n     2 steps/sec on  [GeForce GTX TITAN X]\n\n  Returns:\n    an hparams object.\n  \"\"\"\n  hparams = attention_lm_base()\n  hparams.num_hidden_layers = 4\n  hparams.hidden_size = 512\n  hparams.filter_size = 2048\n  hparams.layer_prepostprocess_dropout = 0.5\n  return hparams", "language": "python"}
{"input": "Series of architectures for language modeling.", "output": "def mqp_lm1b_base():\n  \"\"\"Series of architectures for language modeling.\"\"\"\n  hparams = mtf_transformer2.mtf_unitransformer_base()\n  hparams.d_model = 1024\n  hparams.max_length = 256\n  hparams.batch_size = 256\n  # Parameters for my_layer_stack()\n  hparams.num_hidden_layers = 6\n  hparams.d_ff = 8192\n  hparams.d_kv = 128\n  hparams.num_heads = 8\n  hparams.learning_rate_decay_steps = 13600\n  hparams.layout = \"batch:batch;vocab:model;d_ff:model;heads:model\"\n  hparams.mesh_shape = \"batch:32\"\n  return hparams", "language": "python"}
{"input": "Only picks certain app args to pass to nativefier.json\n@param options", "output": "function selectAppArgs(options) {\n  return {\n    name: options.name,\n    targetUrl: options.targetUrl,\n    counter: options.counter,\n    bounce: options.bounce,\n    width: options.width,\n    height: options.height,\n    minWidth: options.minWidth,\n    minHeight: options.minHeight,\n    maxWidth: options.maxWidth,\n    maxHeight: options.maxHeight,\n    x: options.x,\n    y: options.y,\n    showMenuBar: options.showMenuBar,\n    fastQuit: options.fastQuit,\n    userAgent: options.userAgent,\n    nativefierVersion: options.nativefierVersion,\n    ignoreCertificate: options.ignoreCertificate,\n    disableGpu: options.disableGpu,\n    ignoreGpuBlacklist: options.ignoreGpuBlacklist,\n    enableEs3Apis: options.enableEs3Apis,\n    insecure: options.insecure,\n    flashPluginDir: options.flashPluginDir,\n    diskCacheSize: options.diskCacheSize,\n    fullScreen: options.fullScreen,\n    hideWindowFrame: options.hideWindowFrame,\n    maximize: options.maximize,\n    disableContextMenu: options.disableContextMenu,\n    disableDevTools: options.disableDevTools,\n    zoom: options.zoom,\n    internalUrls: options.internalUrls,\n    crashReporter: options.crashReporter,\n    singleInstance: options.singleInstance,\n    clearCache: options.clearCache,\n    appCopyright: options.appCopyright,\n    appVersion: options.appVersion,\n    buildVersion: options.buildVersion,\n    win32metadata: options.win32metadata,\n    versionString: options.versionString,\n    processEnvs: options.processEnvs,\n    fileDownloadOptions: options.fileDownloadOptions,\n    tray: options.tray,\n    basicAuthUsername: options.basicAuthUsername,\n    basicAuthPassword: options.basicAuthPassword,\n    alwaysOnTop: options.alwaysOnTop,\n    titleBarStyle: options.titleBarStyle,\n    globalShortcuts: options.globalShortcuts,\n  };\n}", "language": "javascript"}
{"input": "Header specific", "output": "function _setHeaderActionEnabledState(mItem) {\n\t\t\tvar oAction = mItem.actions[0],\n\t\t\t\toBindingContext = this.getBindingContext(),\n\t\t\t\tmParameters = oAction.parameters,\n\t\t\t\toModel = this.getModel(),\n\t\t\t\tsPath;\n\n\t\t\tif (oBindingContext) {\n\t\t\t\tsPath = oBindingContext.getPath();\n\t\t\t}\n\n\t\t\tmParameters = BindingResolver.resolveValue(oAction.parameters, oModel, sPath);\n\n\t\t\treturn new Promise(function (resolve) {\n\t\t\t\tthis._oServiceManager.getService(_getServiceName(oAction.service))\n\t\t\t\t\t.then(function (oNavigationService) {\n\t\t\t\t\t\tif (oNavigationService) {\n\t\t\t\t\t\t\toNavigationService\n\t\t\t\t\t\t\t\t.enabled({\n\t\t\t\t\t\t\t\t\tparameters: mParameters\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t.then(function (bEnabled) {\n\t\t\t\t\t\t\t\t\tresolve(bEnabled);\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t.catch(function () {\n\t\t\t\t\t\t\t\t\tresolve(false);\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresolve(false);\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t\t.catch(function () {\n\t\t\t\t\t\tresolve(false);\n\t\t\t\t\t});\n\t\t\t}.bind(this));\n\t\t}", "language": "javascript"}
{"input": "Returns a dictionary containing the weights of the network.\n\n        Returns:\n            Dictionary mapping variable names to their weights.", "output": "def get_weights(self):\n        \"\"\"Returns a dictionary containing the weights of the network.\n\n        Returns:\n            Dictionary mapping variable names to their weights.\n        \"\"\"\n        self._check_sess()\n        return {\n            k: v.eval(session=self.sess)\n            for k, v in self.variables.items()\n        }", "language": "python"}
{"input": "Plots the lr rate/momentum schedule", "output": "def plot_lr(self, show_text=True, show_moms=True):\n        \"\"\"Plots the lr rate/momentum schedule\"\"\"\n        phase_limits = [0]\n        for nb_batch, phase in zip(self.nb_batches, self.phases):\n            phase_limits.append(phase_limits[-1] + nb_batch * phase.epochs)\n        if not in_ipynb():\n            plt.switch_backend('agg')\n        np_plts = 2 if show_moms else 1\n        fig, axs = plt.subplots(1,np_plts,figsize=(6*np_plts,4))\n        if not show_moms: axs = [axs]\n        for i in range(np_plts): axs[i].set_xlabel('iterations')\n        axs[0].set_ylabel('learning rate')\n        axs[0].plot(self.iterations,self.lrs)\n        if show_moms:\n            axs[1].set_ylabel('momentum')\n            axs[1].plot(self.iterations,self.momentums)\n        if show_text:   \n            for i, phase in enumerate(self.phases):\n                text = phase.opt_fn.__name__\n                if phase.wds is not None: text+='\\nwds='+str(phase.wds)\n                if phase.beta is not None: text+='\\nbeta='+str(phase.beta)\n                for k in range(np_plts):\n                    if i < len(self.phases)-1:\n                        draw_line(axs[k], phase_limits[i+1])\n                    draw_text(axs[k], (phase_limits[i]+phase_limits[i+1])/2, text) \n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, 'lr_plot.png'))", "language": "python"}
{"input": "Calculate the distance between two points using the \"haversine\" formula.\nThe formula is based on http://mathforum.org/library/drmath/view/51879.html.\n@param start The starting point\n@param end The end point\n@return The distance between the points in meters", "output": "function getDistance(start, end) {\n  function toRadians(num) {\n    return num * Math.PI / 180;\n  }\n  var R = 6371000;  // earth radius in metres\n  var lat1 = toRadians(start.latitude / COORD_FACTOR);\n  var lat2 = toRadians(end.latitude / COORD_FACTOR);\n  var lon1 = toRadians(start.longitude / COORD_FACTOR);\n  var lon2 = toRadians(end.longitude / COORD_FACTOR);\n\n  var deltalat = lat2-lat1;\n  var deltalon = lon2-lon1;\n  var a = Math.sin(deltalat/2) * Math.sin(deltalat/2) +\n      Math.cos(lat1) * Math.cos(lat2) *\n      Math.sin(deltalon/2) * Math.sin(deltalon/2);\n  var c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1-a));\n  return R * c;\n}", "language": "javascript"}
{"input": "Focus to cell.\n@param {squireext} sq - squire instance\n@param {range} range - range object\n@param {HTMLElement} targetCell - cell element for focus\n@ignore", "output": "function focusToCell(sq, range, targetCell) {\n  range.selectNodeContents(targetCell);\n  range.collapse(true);\n  sq.setSelection(range);\n}", "language": "javascript"}
{"input": "Return the hash digest of a file.", "output": "def _hash_of_file(path, algorithm):\n    \"\"\"Return the hash digest of a file.\"\"\"\n    with open(path, 'rb') as archive:\n        hash = hashlib.new(algorithm)\n        for chunk in read_chunks(archive):\n            hash.update(chunk)\n    return hash.hexdigest()", "language": "python"}
{"input": "Checks if the new label shape is valid", "output": "def check_label_shape(self, label_shape):\n        \"\"\"Checks if the new label shape is valid\"\"\"\n        if not len(label_shape) == 2:\n            raise ValueError('label_shape should have length 2')\n        if label_shape[0] < self.label_shape[0]:\n            msg = 'Attempts to reduce label count from %d to %d, not allowed.' \\\n                % (self.label_shape[0], label_shape[0])\n            raise ValueError(msg)\n        if label_shape[1] != self.provide_label[0][1][2]:\n            msg = 'label_shape object width inconsistent: %d vs %d.' \\\n                % (self.provide_label[0][1][2], label_shape[1])\n            raise ValueError(msg)", "language": "python"}
{"input": "Creates and returns a buffer of given size", "output": "function(size) {\n    var match;\n    var buffer;\n    if (match = size.match(/(\\d+)KB/)) {\n      buffer = new Buffer(parseInt(match[1]) * 1024);\n    } else if (match = size.match(/(\\d+)MB/)) {\n      buffer = new Buffer(parseInt(match[1]) * 1024 * 1024);\n    } else {\n      switch (size) {\n        case 'empty': buffer = new Buffer(0); break;\n        case 'small': buffer = new Buffer(1024 * 1024); break;\n        case 'large': buffer = new Buffer(1024 * 1024 * 20); break;\n        default: return new Buffer(1024 * 1024);\n      }\n    }\n    buffer.fill('x');\n    return buffer;\n  }", "language": "javascript"}
{"input": "change selectors for rules with duplicate grid-areas.\n@param  {Array<Rule>} rules\n@param  {Array<String>} templateSelectors\n@return {Array<Rule>} rules with changed selectors", "output": "function changeDuplicateAreaSelectors (ruleSelectors, templateSelectors) {\n  ruleSelectors = ruleSelectors.map(selector => {\n    let selectorBySpace = list.space(selector)\n    let selectorByComma = list.comma(selector)\n\n    if (selectorBySpace.length > selectorByComma.length) {\n      selector = selectorBySpace.slice(-1).join('')\n    }\n    return selector\n  })\n\n  return ruleSelectors.map(ruleSelector => {\n    let newSelector = templateSelectors.map((tplSelector, index) => {\n      let space = index === 0 ? '' : ' '\n      return `${ space }${ tplSelector } > ${ ruleSelector }`\n    })\n\n    return newSelector\n  })\n}", "language": "javascript"}
{"input": "sample 10 times of a size of 1000 for estimating the density of the sparse dataset", "output": "def estimate_density(DATA_PATH, feature_size):\n    \"\"\"sample 10 times of a size of 1000 for estimating the density of the sparse dataset\"\"\"\n    if not os.path.exists(DATA_PATH):\n        raise Exception(\"Data is not there!\")\n    density = []\n    P = 0.01\n    for _ in range(10):\n        num_non_zero = 0\n        num_sample = 0\n        with open(DATA_PATH) as f:\n            for line in f:\n                if (random.random() < P):\n                    num_non_zero += len(line.split(\" \")) - 1\n                    num_sample += 1\n        density.append(num_non_zero * 1.0 / (feature_size * num_sample))\n    return sum(density) / len(density)", "language": "python"}
{"input": "Build a wheel from a source directory using PEP 517 hooks.\n\n    :param str source_dir: Source directory containing pyproject.toml\n    :param str wheel_dir: Target directory to create wheel in\n    :param dict config_settings: Options to pass to build backend\n\n    This is a blocking function which will run pip in a subprocess to install\n    build requirements.", "output": "def build_wheel(source_dir, wheel_dir, config_settings=None):\n    \"\"\"Build a wheel from a source directory using PEP 517 hooks.\n\n    :param str source_dir: Source directory containing pyproject.toml\n    :param str wheel_dir: Target directory to create wheel in\n    :param dict config_settings: Options to pass to build backend\n\n    This is a blocking function which will run pip in a subprocess to install\n    build requirements.\n    \"\"\"\n    if config_settings is None:\n        config_settings = {}\n    requires, backend = _load_pyproject(source_dir)\n    hooks = Pep517HookCaller(source_dir, backend)\n\n    with BuildEnvironment() as env:\n        env.pip_install(requires)\n        reqs = hooks.get_requires_for_build_wheel(config_settings)\n        env.pip_install(reqs)\n        return hooks.build_wheel(wheel_dir, config_settings)", "language": "python"}
{"input": "Parse the JSDoc output.\n@param {string} output JSDoc output\n@return {Object} Symbol and define info.", "output": "function parseOutput(output) {\n  if (!output) {\n    throw new Error('Expected JSON output');\n  }\n\n  let info;\n  try {\n    info = JSON.parse(String(output));\n  } catch (err) {\n    throw new Error('Failed to parse output as JSON: ' + output);\n  }\n  if (!Array.isArray(info.symbols)) {\n    throw new Error('Expected symbols array: ' + output);\n  }\n  if (!Array.isArray(info.defines)) {\n    throw new Error('Expected defines array: ' + output);\n  }\n\n  return info;\n}", "language": "javascript"}
{"input": "Execute notebook `fname` with `metadata` for preprocessing.", "output": "def execute_nb(fname, metadata=None, save=True, show_doc_only=False):\n    \"Execute notebook `fname` with `metadata` for preprocessing.\"\n    # Any module used in the notebook that isn't inside must be in the same directory as this script\n    with open(fname) as f: nb = nbformat.read(f, as_version=4)\n    ep_class = ExecuteShowDocPreprocessor if show_doc_only else ExecutePreprocessor\n    ep = ep_class(timeout=600, kernel_name='python3')\n    metadata = metadata or {}\n    ep.preprocess(nb, metadata)\n    if save:\n        with open(fname, 'wt') as f: nbformat.write(nb, f)\n        NotebookNotary().sign(nb)", "language": "python"}
{"input": "Merge holiday calendars together.  The caller's class\n        rules take precedence.  The merge will be done\n        based on each holiday's name.\n\n        Parameters\n        ----------\n        other : holiday calendar\n        inplace : bool (default=False)\n            If True set rule_table to holidays, else return array of Holidays", "output": "def merge(self, other, inplace=False):\n        \"\"\"\n        Merge holiday calendars together.  The caller's class\n        rules take precedence.  The merge will be done\n        based on each holiday's name.\n\n        Parameters\n        ----------\n        other : holiday calendar\n        inplace : bool (default=False)\n            If True set rule_table to holidays, else return array of Holidays\n        \"\"\"\n        holidays = self.merge_class(self, other)\n        if inplace:\n            self.rules = holidays\n        else:\n            return holidays", "language": "python"}
{"input": "Shows an image using matplotlib and saves it.", "output": "def show_and_save_image(img, save_path):\n  \"\"\"Shows an image using matplotlib and saves it.\"\"\"\n  try:\n    import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top\n  except ImportError as e:\n    tf.logging.warning(\n        \"Showing and saving an image requires matplotlib to be \"\n        \"installed: %s\", e)\n    raise NotImplementedError(\"Image display and save not implemented.\")\n  plt.imshow(img)\n  with tf.gfile.Open(save_path, \"wb\") as sp:\n    plt.savefig(sp)", "language": "python"}
{"input": "Render a helpful description of the location of the error in the GraphQL\nSource document.", "output": "function highlightSourceAtLocation(\n  source: Source,\n  location: SourceLocation,\n): string {\n  const firstLineColumnOffset = source.locationOffset.column - 1;\n  const body = whitespace(firstLineColumnOffset) + source.body;\n\n  const lineIndex = location.line - 1;\n  const lineOffset = source.locationOffset.line - 1;\n  const lineNum = location.line + lineOffset;\n\n  const columnOffset = location.line === 1 ? firstLineColumnOffset : 0;\n  const columnNum = location.column + columnOffset;\n\n  const lines = body.split(/\\r\\n|[\\n\\r]/g);\n  return (\n    `${source.name} (${lineNum}:${columnNum})\\n` +\n    printPrefixedLines([\n      // Lines specified like this: [\"prefix\", \"string\"],\n      [`${lineNum - 1}: `, lines[lineIndex - 1]],\n      [`${lineNum}: `, lines[lineIndex]],\n      ['', whitespace(columnNum - 1) + '^'],\n      [`${lineNum + 1}: `, lines[lineIndex + 1]],\n    ])\n  );\n}", "language": "javascript"}
{"input": ":type A: List[List[int]]\n    :type B: List[List[int]]\n    :rtype: List[List[int]]", "output": "def multiply(self, a, b):\n    \"\"\"\n    :type A: List[List[int]]\n    :type B: List[List[int]]\n    :rtype: List[List[int]]\n    \"\"\"\n    if a is None or b is None: return None\n    m, n, l = len(a), len(b[0]), len(b[0])\n    if len(b) != n:\n        raise Exception(\"A's column number must be equal to B's row number.\")\n    c = [[0 for _ in range(l)] for _ in range(m)]\n    for i, row in enumerate(a):\n        for k, eleA in enumerate(row):\n            if eleA:\n                for j, eleB in enumerate(b[k]):\n                    if eleB: c[i][j] += eleA * eleB\n    return c", "language": "python"}
{"input": "Residual block over inputs.\n\n  Runs a residual block consisting of\n    conv: kernel_size x kernel_size\n    conv: 1x1\n    dropout, add and normalize according to hparams.layer_postprocess_sequence.\n\n  Args:\n    inputs: Tensor of shape [batch, height, width, hparams.hidden_size].\n    hparams: HParams.\n\n  Returns:\n    Tensor of shape [batch, height, width, hparams.hidden_size].", "output": "def residual_block_layer(inputs, hparams):\n  \"\"\"Residual block over inputs.\n\n  Runs a residual block consisting of\n    conv: kernel_size x kernel_size\n    conv: 1x1\n    dropout, add and normalize according to hparams.layer_postprocess_sequence.\n\n  Args:\n    inputs: Tensor of shape [batch, height, width, hparams.hidden_size].\n    hparams: HParams.\n\n  Returns:\n    Tensor of shape [batch, height, width, hparams.hidden_size].\n  \"\"\"\n  kernel = (hparams.res_kernel_size, hparams.res_kernel_size)\n  x = inputs\n  for i in range(hparams.num_res_layers):\n    with tf.variable_scope(\"res_conv_%d\" % i):\n      # kernel_size x kernel_size conv block\n      y = common_layers.conv_block(\n          common_layers.layer_norm(x, hparams.hidden_size, name=\"lnorm\"),\n          hparams.hidden_size, [((1, 1), kernel)],\n          strides=(1, 1),\n          padding=\"SAME\",\n          name=\"residual_conv\")\n      # 1x1 conv block\n      y = common_layers.conv_block(\n          y,\n          hparams.hidden_size, [((1, 1), (1, 1))],\n          strides=(1, 1),\n          padding=\"SAME\",\n          name=\"residual_dense\")\n      x = common_layers.layer_postprocess(x, y, hparams)\n  return x", "language": "python"}
{"input": "Checks if a control has API Reference\n@param {string} sControlName\n@return {Promise} A promise that resolves to {boolean}", "output": "function (sControlName) {\n\t\t\t\treturn APIInfo.getIndexJsonPromise().then(function (aData) {\n\t\t\t\t\tfunction findSymbol (a) {\n\t\t\t\t\t\treturn a.some(function (o) {\n\t\t\t\t\t\t\tvar bFound = o.name === sControlName;\n\t\t\t\t\t\t\tif (!bFound && o.nodes) {\n\t\t\t\t\t\t\t\treturn findSymbol(o.nodes);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn bFound;\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\treturn findSymbol(aData);\n\t\t\t\t});\n\t\t\t}", "language": "javascript"}
{"input": "Create a vocabulary from a set of `tokens`.", "output": "def create(cls, tokens:Tokens, max_vocab:int, min_freq:int) -> 'Vocab':\n        \"Create a vocabulary from a set of `tokens`.\"\n        freq = Counter(p for o in tokens for p in o)\n        itos = [o for o,c in freq.most_common(max_vocab) if c >= min_freq]\n        for o in reversed(defaults.text_spec_tok):\n            if o in itos: itos.remove(o)\n            itos.insert(0, o)\n        return cls(itos)", "language": "python"}
{"input": "Convert a value to a string, if possible.", "output": "def toString(value):\n        \"\"\"\n        Convert a value to a string, if possible.\n        \"\"\"\n        if isinstance(value, basestring):\n            return value\n        elif type(value) in [np.string_, np.str_]:\n            return str(value)\n        elif type(value) == np.unicode_:\n            return unicode(value)\n        else:\n            raise TypeError(\"Could not convert %s to string type\" % type(value))", "language": "python"}
{"input": "check s1 == s2 if both are not None", "output": "def _check_shape(s1, s2):\n    \"\"\"check s1 == s2 if both are not None\"\"\"\n    if s1 and s2 and s1 != s2:\n        raise ValueError(\"Shape mismatch detected. \" + str(s1) + \" v.s. \" + str(s2))", "language": "python"}
{"input": "Show method for dialogs", "output": "function onShow(scope, element, options, controller) {\n      angular.element($document[0].body).addClass('md-dialog-is-showing');\n\n      var dialogElement = element.find('md-dialog');\n\n      // Once a dialog has `ng-cloak` applied on his template the dialog animation will not work properly.\n      // This is a very common problem, so we have to notify the developer about this.\n      if (dialogElement.hasClass('ng-cloak')) {\n        var message = '$mdDialog: using `<md-dialog ng-cloak>` will affect the dialog opening animations.';\n        $log.warn(message, element[0]);\n      }\n\n      captureParentAndFromToElements(options);\n      configureAria(dialogElement, options);\n      showBackdrop(scope, element, options);\n      activateListeners(element, options);\n\n      return dialogPopIn(element, options)\n        .then(function() {\n          lockScreenReader(element, options);\n          warnDeprecatedActions();\n          focusOnOpen();\n        });\n\n      /**\n       * Check to see if they used the deprecated .md-actions class and log a warning\n       */\n      function warnDeprecatedActions() {\n        if (element[0].querySelector('.md-actions')) {\n          $log.warn('Using a class of md-actions is deprecated, please use <md-dialog-actions>.');\n        }\n      }\n\n      /**\n       * For alerts, focus on content... otherwise focus on\n       * the close button (or equivalent)\n       */\n      function focusOnOpen() {\n        if (options.focusOnOpen) {\n          var target = $mdUtil.findFocusTarget(element) || findCloseButton() || dialogElement;\n          target.focus();\n        }\n\n        /**\n         * If no element with class dialog-close, try to find the last\n         * button child in md-actions and assume it is a close button.\n         *\n         * If we find no actions at all, log a warning to the console.\n         */\n        function findCloseButton() {\n          return element[0].querySelector('.dialog-close, md-dialog-actions button:last-child');\n        }\n      }\n    }", "language": "javascript"}
{"input": "Read the end of the Zip 64 central directory.\nNot merged with the method readEndOfCentral :\nThe end of central can coexist with its Zip64 brother,\nI don't want to read the wrong number of bytes !", "output": "function() {\n        this.zip64EndOfCentralSize = this.reader.readInt(8);\n        this.versionMadeBy = this.reader.readString(2);\n        this.versionNeeded = this.reader.readInt(2);\n        this.diskNumber = this.reader.readInt(4);\n        this.diskWithCentralDirStart = this.reader.readInt(4);\n        this.centralDirRecordsOnThisDisk = this.reader.readInt(8);\n        this.centralDirRecords = this.reader.readInt(8);\n        this.centralDirSize = this.reader.readInt(8);\n        this.centralDirOffset = this.reader.readInt(8);\n\n        this.zip64ExtensibleData = {};\n        var extraDataSize = this.zip64EndOfCentralSize - 44,\n            index = 0,\n            extraFieldId,\n            extraFieldLength,\n            extraFieldValue;\n        while (index < extraDataSize) {\n            extraFieldId = this.reader.readInt(2);\n            extraFieldLength = this.reader.readInt(4);\n            extraFieldValue = this.reader.readString(extraFieldLength);\n            this.zip64ExtensibleData[extraFieldId] = {\n                id: extraFieldId,\n                length: extraFieldLength,\n                value: extraFieldValue\n            };\n        }\n    }", "language": "javascript"}
{"input": "Handles a message from the transport. Parses it as JSON and delegates\nto MessageBroker who is in charge of routing them to handlers.\n@param {string} msgStr The protocol message as stringified JSON.", "output": "function (msgStr) {\n            var msg;\n            try {\n                msg = JSON.parse(msgStr);\n            } catch (e) {\n                console.log(\"[Brackets LiveDev] Malformed message received: \", msgStr);\n                return;\n            }\n            // delegates handling/routing to MessageBroker.\n            MessageBroker.trigger(msg);\n        }", "language": "javascript"}
{"input": "Set Ok (success) finalizer to a spinner.", "output": "def ok(self, text=u\"OK\", err=False):\n        \"\"\"Set Ok (success) finalizer to a spinner.\"\"\"\n        # Do not display spin text for ok state\n        self._text = None\n\n        _text = to_text(text) if text else u\"OK\"\n        err = err or not self.write_to_stdout\n        self._freeze(_text, err=err)", "language": "python"}
{"input": "helper for textMatrixToTexture", "output": "function setTextStyle(ctx, fontSize) {\n  ctx.font = `${fontSize}px Helvetica,Arial,sans-serif`;\n  ctx.fillStyle = '#000';\n  ctx.textBaseline = 'top';\n  ctx.textAlign = 'center';\n}", "language": "javascript"}
{"input": "Save pose.", "output": "function () {\n    if (!this.el.sceneEl.checkHeadsetConnected()) { return; }\n    this.saveCameraPose();\n    this.el.object3D.position.set(0, 0, 0);\n    this.el.object3D.updateMatrix();\n  }", "language": "javascript"}
{"input": "Given value and vshape, create an `NDArray` from value with the same\n        context and dtype as the current one and broadcast it to vshape.", "output": "def _prepare_value_nd(self, value, vshape):\n        \"\"\"Given value and vshape, create an `NDArray` from value with the same\n        context and dtype as the current one and broadcast it to vshape.\"\"\"\n        if isinstance(value, numeric_types):\n            value_nd = full(shape=vshape, val=value, ctx=self.context, dtype=self.dtype)\n        elif isinstance(value, NDArray):\n            value_nd = value.as_in_context(self.context)\n            if value_nd.dtype != self.dtype:\n                value_nd = value_nd.astype(self.dtype)\n        else:\n            try:\n                value_nd = array(value, ctx=self.context, dtype=self.dtype)\n            except:\n                raise TypeError('NDArray does not support assignment with non-array-like'\n                                ' object %s of type %s' % (str(value), str(type(value))))\n        if value_nd.shape != vshape:\n            value_nd = value_nd.broadcast_to(vshape)\n        return value_nd", "language": "python"}
{"input": "Select function takes a row as a list and a column name and returns the date in that column.", "output": "def select_date(self, rows: List[Row], column: DateColumn) -> Date:\n        \"\"\"\n        Select function takes a row as a list and a column name and returns the date in that column.\n        \"\"\"\n        dates: List[Date] = []\n        for row in rows:\n            cell_value = row.values[column.name]\n            if isinstance(cell_value, Date):\n                dates.append(cell_value)\n\n        return dates[0] if dates else Date(-1, -1, -1)", "language": "python"}
{"input": "Normalize the optional params of axe.run()\n@param  {object}   context\n@param  {object}   options\n@param  {Function} callback\n@return {object}            With 3 keys: context, options, callback", "output": "function normalizeRunParams(context, options, callback) {\n\t'use strict';\n\tlet typeErr = new TypeError('axe.run arguments are invalid');\n\n\t// Determine the context\n\tif (!isContext(context)) {\n\t\tif (callback !== undefined) {\n\t\t\t// Either context is invalid or there are too many params\n\t\t\tthrow typeErr;\n\t\t}\n\t\t// Set default and shift one over\n\t\tcallback = options;\n\t\toptions = context;\n\t\tcontext = document;\n\t}\n\n\t// Determine the options\n\tif (typeof options !== 'object') {\n\t\tif (callback !== undefined) {\n\t\t\t// Either options is invalid or there are too many params\n\t\t\tthrow typeErr;\n\t\t}\n\t\t// Set default and shift one over\n\t\tcallback = options;\n\t\toptions = {};\n\t}\n\n\t// Set the callback or noop;\n\tif (typeof callback !== 'function' && callback !== undefined) {\n\t\tthrow typeErr;\n\t}\n\n\treturn {\n\t\tcontext: context,\n\t\toptions: options,\n\t\tcallback: callback || noop\n\t};\n}", "language": "javascript"}
{"input": "Evaluate possibly callable input using obj and kwargs if it is callable,\n    otherwise return as it is.\n\n    Parameters\n    ----------\n    maybe_callable : possibly a callable\n    obj : NDFrame\n    **kwargs", "output": "def apply_if_callable(maybe_callable, obj, **kwargs):\n    \"\"\"\n    Evaluate possibly callable input using obj and kwargs if it is callable,\n    otherwise return as it is.\n\n    Parameters\n    ----------\n    maybe_callable : possibly a callable\n    obj : NDFrame\n    **kwargs\n    \"\"\"\n\n    if callable(maybe_callable):\n        return maybe_callable(obj, **kwargs)\n\n    return maybe_callable", "language": "python"}
{"input": "Converts ASCII coding into a string. Required for restoring stored code extensions\n\n@param {String} ascii string containing ascii code valid numbers separated by ','\n@returns {String} parsedString parsed string", "output": "function (ascii) {\n\t\t\tvar asciiArray = ascii.split(\",\");\n\t\t\tvar parsedString = \"\";\n\n\t\t\tjQuery.each(asciiArray, function (index, asciiChar) {\n\t\t\t\tparsedString += String.fromCharCode(asciiChar);\n\t\t\t});\n\n\t\t\treturn parsedString;\n\n\t\t}", "language": "javascript"}
{"input": "Returns whether or not there are padding and OOV tokens added to the given namespace.", "output": "def is_padded(self, namespace: str) -> bool:\n        \"\"\"\n        Returns whether or not there are padding and OOV tokens added to the given namespace.\n        \"\"\"\n        return self._index_to_token[namespace][0] == self._padding_token", "language": "python"}
{"input": "Implementation of Breadth-first search (BFS) on caffe network DAG\n    :param root_node: root node of caffe network DAG\n    :param process_node: function to run on each node", "output": "def _bfs(root_node, process_node):\n    \"\"\"\n    Implementation of Breadth-first search (BFS) on caffe network DAG\n    :param root_node: root node of caffe network DAG\n    :param process_node: function to run on each node\n    \"\"\"\n\n    from collections import deque\n\n    seen_nodes = set()\n    next_nodes = deque()\n\n    seen_nodes.add(root_node)\n    next_nodes.append(root_node)\n\n    while next_nodes:\n        current_node = next_nodes.popleft()\n\n        # process current node\n        process_node(current_node)\n\n        for child_node in current_node.children:\n            if child_node not in seen_nodes:\n                seen_nodes.add(child_node)\n                next_nodes.append(child_node)", "language": "python"}
{"input": "Returns the unique hash key for this template name.", "output": "def get_cache_key(self, name, filename=None):\n        \"\"\"Returns the unique hash key for this template name.\"\"\"\n        hash = sha1(name.encode('utf-8'))\n        if filename is not None:\n            filename = '|' + filename\n            if isinstance(filename, text_type):\n                filename = filename.encode('utf-8')\n            hash.update(filename)\n        return hash.hexdigest()", "language": "python"}
{"input": "Base setting with a stochastic next-frame model.", "output": "def rlmb_base_stochastic():\n  \"\"\"Base setting with a stochastic next-frame model.\"\"\"\n  hparams = rlmb_base()\n  hparams.initial_epoch_train_steps_multiplier = 5\n  hparams.generative_model = \"next_frame_basic_stochastic\"\n  hparams.generative_model_params = \"next_frame_basic_stochastic\"\n  return hparams", "language": "python"}
{"input": "Add Esc key handling for a popup DOM element.\n\n@param {!jQuery} $popUp jQuery object for the DOM element pop-up\n@param {function} removeHandler Pop-up specific remove (e.g. display:none or DOM removal)\n@param {?Boolean} autoRemove - Specify true to indicate the PopUpManager should\nremove the popup from the _popUps array when the popup is closed. Specify false\nwhen the popup is always persistant in the _popUps array.", "output": "function addPopUp($popUp, removeHandler, autoRemove) {\n        autoRemove = autoRemove || false;\n\n        _popUps.push($popUp[0]);\n        $popUp.data(\"PopUpManager-autoRemove\", autoRemove);\n        $popUp.data(\"PopUpManager-removeHandler\", removeHandler);\n    }", "language": "javascript"}
{"input": "Transfer this instance to a Java OneVsRestModel. Used for ML persistence.\n\n        :return: Java object equivalent to this instance.", "output": "def _to_java(self):\n        \"\"\"\n        Transfer this instance to a Java OneVsRestModel. Used for ML persistence.\n\n        :return: Java object equivalent to this instance.\n        \"\"\"\n        sc = SparkContext._active_spark_context\n        java_models = [model._to_java() for model in self.models]\n        java_models_array = JavaWrapper._new_java_array(\n            java_models, sc._gateway.jvm.org.apache.spark.ml.classification.ClassificationModel)\n        metadata = JavaParams._new_java_obj(\"org.apache.spark.sql.types.Metadata\")\n        _java_obj = JavaParams._new_java_obj(\"org.apache.spark.ml.classification.OneVsRestModel\",\n                                             self.uid, metadata.empty(), java_models_array)\n        _java_obj.set(\"classifier\", self.getClassifier()._to_java())\n        _java_obj.set(\"featuresCol\", self.getFeaturesCol())\n        _java_obj.set(\"labelCol\", self.getLabelCol())\n        _java_obj.set(\"predictionCol\", self.getPredictionCol())\n        return _java_obj", "language": "python"}
{"input": "Image standardization on batches and videos.", "output": "def standardize_images(x):\n  \"\"\"Image standardization on batches and videos.\"\"\"\n  with tf.name_scope(\"standardize_images\", values=[x]):\n    x_shape = shape_list(x)\n    x = to_float(tf.reshape(x, [-1] + x_shape[-3:]))\n    x_mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n    x_variance = tf.reduce_mean(\n        tf.squared_difference(x, x_mean), axis=[1, 2], keepdims=True)\n    num_pixels = to_float(x_shape[-2] * x_shape[-3])\n    x = (x - x_mean) / tf.maximum(tf.sqrt(x_variance), tf.rsqrt(num_pixels))\n    return tf.reshape(x, x_shape)", "language": "python"}
{"input": "Reshapes a to match the shape of b in all but the last dimension.", "output": "def reshape_like(a, b):\n  \"\"\"Reshapes a to match the shape of b in all but the last dimension.\"\"\"\n  ret = tf.reshape(a, tf.concat([tf.shape(b)[:-1], tf.shape(a)[-1:]], 0))\n  if not tf.executing_eagerly():\n    ret.set_shape(b.get_shape().as_list()[:-1] + a.get_shape().as_list()[-1:])\n  return ret", "language": "python"}
{"input": "Appointments Node", "output": "function AppointmentNode(oData) {\n\t\tthis.data = oData;\n\t\tthis.level = 0;\n\t\tthis.width = 1;\n\t\tthis.prev = null;\n\t\tthis.next = null;\n\t}", "language": "javascript"}
{"input": "find the right offset a given local time. The o input is our guess, which determines which offset we'll pick in ambiguous cases (e.g. there are two 3 AMs b/c Fallback DST)", "output": "function fixOffset(localTS, o, tz) {\n  // Our UTC time is just a guess because our offset is just a guess\n  let utcGuess = localTS - o * 60 * 1000;\n\n  // Test whether the zone matches the offset for this ts\n  const o2 = tz.offset(utcGuess);\n\n  // If so, offset didn't change and we're done\n  if (o === o2) {\n    return [utcGuess, o];\n  }\n\n  // If not, change the ts by the difference in the offset\n  utcGuess -= (o2 - o) * 60 * 1000;\n\n  // If that gives us the local time we want, we're done\n  const o3 = tz.offset(utcGuess);\n  if (o2 === o3) {\n    return [utcGuess, o2];\n  }\n\n  // If it's different, we're in a hole time. The offset has changed, but the we don't adjust the time\n  return [localTS - Math.min(o2, o3) * 60 * 1000, Math.max(o2, o3)];\n}", "language": "javascript"}
{"input": "------------------------------------------------------------------------------", "output": "function clearDatabase(tx, resultSet) {\n    var sql = \"delete from clicks\"\n    tx.executeSql(sql, null, null, sqlError);\n}", "language": "javascript"}
{"input": "Makes a ValueInfoProto based on the data type and shape.", "output": "def make_tensor_value_info(\n        name,  # type: Text\n        elem_type,  # type: int\n        shape,  # type: Optional[Sequence[Union[Text, int]]]\n        doc_string=\"\",  # type: Text\n        shape_denotation=None,  # type: Optional[List[Text]]\n):  # type: (...) -> ValueInfoProto\n    \"\"\"Makes a ValueInfoProto based on the data type and shape.\"\"\"\n    value_info_proto = ValueInfoProto()\n    value_info_proto.name = name\n    if doc_string:\n        value_info_proto.doc_string = doc_string\n\n    tensor_type_proto = value_info_proto.type.tensor_type\n    tensor_type_proto.elem_type = elem_type\n\n    tensor_shape_proto = tensor_type_proto.shape\n\n    if shape is not None:\n        # You might think this is a no-op (extending a normal Python\n        # list by [] certainly is), but protobuf lists work a little\n        # differently; if a field is never set, it is omitted from the\n        # resulting protobuf; a list that is explicitly set to be\n        # empty will get an (empty) entry in the protobuf. This\n        # difference is visible to our consumers, so make sure we emit\n        # an empty shape!\n        tensor_shape_proto.dim.extend([])\n\n        if shape_denotation:\n            if len(shape_denotation) != len(shape):\n                raise ValueError(\n                    'Invalid shape_denotation. '\n                    'Must be of the same length as shape.')\n\n        for i, d in enumerate(shape):\n            dim = tensor_shape_proto.dim.add()\n            if d is None:\n                pass\n            elif isinstance(d, integer_types):\n                dim.dim_value = d\n            elif isinstance(d, text_type):\n                dim.dim_param = d\n            else:\n                raise ValueError(\n                    'Invalid item in shape: {}. '\n                    'Needs to of integer_types or text_type.'.format(d))\n\n            if shape_denotation:\n                dim.denotation = shape_denotation[i]\n\n    return value_info_proto", "language": "python"}
{"input": "Reduce the array along a given axis by sum square value", "output": "def reduce_sum_square(attrs, inputs, proto_obj):\n    \"\"\"Reduce the array along a given axis by sum square value\"\"\"\n    square_op = symbol.square(inputs[0])\n    sum_op = symbol.sum(square_op, axis=attrs.get('axes'),\n                        keepdims=attrs.get('keepdims'))\n    return sum_op, attrs, inputs", "language": "python"}
{"input": "Helper function to warn when a user specified value is being overwritten", "output": "function setConf(conf, name, value, msg) {\n  if (conf[name] && conf[name] !== value) {\n    console.warn(\n        `Your protractor configuration specifies an option which is overwritten by Bazel: '${name}' ${msg}`);\n  }\n  conf[name] = value;\n}", "language": "javascript"}
{"input": "Gets the log entry listener instance, if not present creates a new one\n@returns {Object} the singleton log entry listener", "output": "function getLogEntryListenerInstance(){\n\t\tif (!oListener) {\n\t\t\toListener = {\n\t\t\t\tlisteners: [],\n\t\t\t\tonLogEntry: function(oLogEntry){\n\t\t\t\t\tfor (var i = 0; i < oListener.listeners.length; i++) {\n\t\t\t\t\t\tif (oListener.listeners[i].onLogEntry) {\n\t\t\t\t\t\t\toListener.listeners[i].onLogEntry(oLogEntry);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tattach: function(oLog, oLstnr){\n\t\t\t\t\tif (oLstnr) {\n\t\t\t\t\t\toListener.listeners.push(oLstnr);\n\t\t\t\t\t\tif (oLstnr.onAttachToLog) {\n\t\t\t\t\t\t\toLstnr.onAttachToLog(oLog);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\tdetach: function(oLog, oLstnr){\n\t\t\t\t\tfor (var i = 0; i < oListener.listeners.length; i++) {\n\t\t\t\t\t\tif (oListener.listeners[i] === oLstnr) {\n\t\t\t\t\t\t\tif (oLstnr.onDetachFromLog) {\n\t\t\t\t\t\t\t\toLstnr.onDetachFromLog(oLog);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\toListener.listeners.splice(i,1);\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t\treturn oListener;\n\t}", "language": "javascript"}
{"input": "Runtime helper for v-once.\nEffectively it means marking the node as static with a unique key.\n /*", "output": "function initRender (vm) {\n  vm._vnode = null; // the root of the child tree\n  vm._staticTrees = null;\n  var parentVnode = vm.$vnode = vm.$options._parentVnode; // the placeholder node in parent tree\n  var renderContext = parentVnode && parentVnode.context;\n  /**\n   * react-vue change\n   */\n  // vm.$slots = resolveSlots(vm.$options._renderChildren, renderContext)\n  vm.$scopedSlots = emptyObject;\n  // bind the createElement fn to this instance\n  // so that we get proper render context inside it.\n  // args order: tag, data, children, normalizationType, alwaysNormalize\n  // internal version is used by render functions compiled from templates\n  vm._c = function (a, b, c, d) { return createElement(vm, a, b, c, d, false); };\n  // normalization is always applied for the public version, used in\n  // user-written render functions.\n  vm.$createElement = function (a, b, c, d) { return createElement(vm, a, b, c, d, true); };\n}", "language": "javascript"}
{"input": "Add a bias to x.\n\n  Initialize such that the output of the first minibatch is zero centered\n  per channel.\n\n  Args:\n    name: scope\n    x: 2-D or 4-D Tensor.\n    reverse: Forward or backward operation.\n    init: data-dependent initialization.\n\n  Returns:\n    x_center: (x + b), if reverse is True and (x - b) otherwise.", "output": "def actnorm_center(name, x, reverse=False, init=False):\n  \"\"\"Add a bias to x.\n\n  Initialize such that the output of the first minibatch is zero centered\n  per channel.\n\n  Args:\n    name: scope\n    x: 2-D or 4-D Tensor.\n    reverse: Forward or backward operation.\n    init: data-dependent initialization.\n\n  Returns:\n    x_center: (x + b), if reverse is True and (x - b) otherwise.\n  \"\"\"\n  shape = common_layers.shape_list(x)\n  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n    assert len(shape) == 2 or len(shape) == 4\n    if len(shape) == 2:\n      x_mean = tf.reduce_mean(x, [0], keepdims=True)\n      b = get_variable_ddi(\"b\", (1, shape[1]), initial_value=-x_mean,\n                           init=init)\n    elif len(shape) == 4:\n      x_mean = tf.reduce_mean(x, [0, 1, 2], keepdims=True)\n      b = get_variable_ddi(\n          \"b\", (1, 1, 1, shape[3]), initial_value=-x_mean, init=init)\n\n    if not reverse:\n      x += b\n    else:\n      x -= b\n    return x", "language": "python"}
{"input": "The shake-shake sum of 2 tensors, python version.", "output": "def shakeshake2_py(x, y, equal=False, individual=False):\n  \"\"\"The shake-shake sum of 2 tensors, python version.\"\"\"\n  if equal:\n    alpha = 0.5\n  elif individual:\n    alpha = tf.random_uniform(tf.get_shape(x)[:1])\n  else:\n    alpha = tf.random_uniform([])\n\n  return alpha * x + (1.0 - alpha) * y", "language": "python"}
{"input": "Mousedown or touchstart\nonly for handlers\n\n@param target {String|null}\n@param e {Object} event object", "output": "function (target, e) {\n            e.preventDefault();\n            var x = e.pageX || e.originalEvent.touches && e.originalEvent.touches[0].pageX;\n            if (e.button === 2) {\n                return;\n            }\n\n            if (target === \"both\") {\n                this.setTempMinInterval();\n            }\n\n            if (!target) {\n                target = this.target || \"from\";\n            }\n\n            this.current_plugin = this.plugin_count;\n            this.target = target;\n\n            this.is_active = true;\n            this.dragging = true;\n\n            this.coords.x_gap = this.$cache.rs.offset().left;\n            this.coords.x_pointer = x - this.coords.x_gap;\n\n            this.calcPointerPercent();\n            this.changeLevel(target);\n\n            if (is_old_ie) {\n                $(\"*\").prop(\"unselectable\", true);\n            }\n\n            this.$cache.line.trigger(\"focus\");\n\n            this.updateScene();\n        }", "language": "javascript"}
{"input": "Visits all child nodes of the given node.\n\n@param {Node} oNode the XML DOM node\n@param {sap.ui.core.util._with} oWithControl the \"with\" control\n@returns {sap.ui.base.SyncPromise}\nA sync promise which resolves with <code>undefined</code> as soon as visiting is\ndone, or is rejected with a corresponding error if visiting fails.", "output": "function visitChildNodes(oNode, oWithControl) {\n\t\t\t\treturn stopAndGo(\n\t\t\t\t\t// cache live collection so that removing a template node does not hurt\n\t\t\t\t\tArray.prototype.slice.apply(oNode.childNodes),\n\t\t\t\t\tfunction (oChild) {\n\t\t\t\t\t\treturn visitNode(oChild, oWithControl);\n\t\t\t\t\t});\n\t\t\t}", "language": "javascript"}
{"input": "This is called upon unpickling, rather than the default which doesn't\n    have arguments and breaks __new__", "output": "def _new_DatetimeIndex(cls, d):\n    \"\"\" This is called upon unpickling, rather than the default which doesn't\n    have arguments and breaks __new__ \"\"\"\n\n    if \"data\" in d and not isinstance(d[\"data\"], DatetimeIndex):\n        # Avoid need to verify integrity by calling simple_new directly\n        data = d.pop(\"data\")\n        result = cls._simple_new(data, **d)\n    else:\n        with warnings.catch_warnings():\n            # we ignore warnings from passing verify_integrity=False\n            # TODO: If we knew what was going in to **d, we might be able to\n            #  go through _simple_new instead\n            warnings.simplefilter(\"ignore\")\n            result = cls.__new__(cls, verify_integrity=False, **d)\n\n    return result", "language": "python"}
{"input": "Delegates to <code>BindingParser.mergeParts</code>, but stifles any errors.\n\n@param {object} oBindingInfo\na binding info object\n@param {string} [sBinding]\nthe original binding string as a detail for error logs", "output": "function mergeParts(oBindingInfo, sBinding) {\n\t\ttry {\n\t\t\tBindingParser.mergeParts(oBindingInfo);\n\t\t} catch (e) {\n\t\t\tLog.error(\"Cannot merge parts: \" + e.message, sBinding,\n\t\t\t\t\"sap.ui.base.BindingParser\");\n\t\t\t// rely on error in ManagedObject\n\t\t}\n\t}", "language": "javascript"}
{"input": "Whether this trial is due for checkpointing.", "output": "def should_checkpoint(self):\n        \"\"\"Whether this trial is due for checkpointing.\"\"\"\n        result = self.last_result or {}\n\n        if result.get(DONE) and self.checkpoint_at_end:\n            return True\n\n        if self.checkpoint_freq:\n            return result.get(TRAINING_ITERATION,\n                              0) % self.checkpoint_freq == 0\n        else:\n            return False", "language": "python"}
{"input": "Bias for item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)", "output": "def weight(self, arr:Collection, is_item:bool=True):\n        \"Bias for item or user (based on `is_item`) for all in `arr`. (Set model to `cpu` and no grad.)\"\n        idx = self.get_idx(arr, is_item)\n        m = self.model\n        layer = m.i_weight if is_item else m.u_weight\n        return layer(idx)", "language": "python"}
{"input": "Function to check existence of a file entry, validity of markers\n@private", "output": "function _validateFrame(entry) {\n        var deferred = new $.Deferred(),\n            fileEntry = FileSystem.getFileForPath(entry.filePath);\n\n        if (entry.inMem) {\n            var indexInWS = MainViewManager.findInWorkingSet(entry.paneId, entry.filePath);\n            // Remove entry if InMemoryFile is not found in Working set\n            if (indexInWS === -1) {\n                deferred.reject();\n            } else {\n                deferred.resolve();\n            }\n        } else {\n            fileEntry.exists(function (err, exists) {\n                if (!err && exists) {\n                    // Additional check to handle external modification and mutation of the doc text affecting markers\n                    if (fileEntry._hash !== entry._hash) {\n                        deferred.reject();\n                    } else if (!entry._validateMarkers()) {\n                        deferred.reject();\n                    } else {\n                        deferred.resolve();\n                    }\n                } else {\n                    deferred.reject();\n                }\n            });\n        }\n\n        return deferred.promise();\n    }", "language": "javascript"}
{"input": "Provides a specialized parser for getBucketLocation -- all other\noperations are parsed by the super class.\n\n@api private", "output": "function extractData(resp) {\n    var req = resp.request;\n    if (req.operation === 'getBucketLocation') {\n      var match = resp.httpResponse.body.toString().match(/>(.+)<\\/Location/);\n      delete resp.data['_'];\n      if (match) {\n        resp.data.LocationConstraint = match[1];\n      } else {\n        resp.data.LocationConstraint = '';\n      }\n    }\n    var bucket = req.params.Bucket || null;\n    if (req.operation === 'deleteBucket' && typeof bucket === 'string' && !resp.error) {\n      req.service.clearBucketRegionCache(bucket);\n    } else {\n      var headers = resp.httpResponse.headers || {};\n      var region = headers['x-amz-bucket-region'] || null;\n      if (!region && req.operation === 'createBucket' && !resp.error) {\n        var createBucketConfiguration = req.params.CreateBucketConfiguration;\n        if (!createBucketConfiguration) {\n          region = 'us-east-1';\n        } else if (createBucketConfiguration.LocationConstraint === 'EU') {\n          region = 'eu-west-1';\n        } else {\n          region = createBucketConfiguration.LocationConstraint;\n        }\n      }\n      if (region) {\n          if (bucket && region !== req.service.bucketRegionCache[bucket]) {\n            req.service.bucketRegionCache[bucket] = region;\n          }\n      }\n    }\n    req.service.extractRequestIds(resp);\n  }", "language": "javascript"}
{"input": "A signal that the Episode has ended. The buffer must be reset.\n        Get only called when the academy resets.", "output": "def end_episode(self):\n        \"\"\"\n        A signal that the Episode has ended. The buffer must be reset.\n        Get only called when the academy resets.\n        \"\"\"\n        self.evaluation_buffer.reset_local_buffers()\n        for agent_id in self.cumulative_rewards:\n            self.cumulative_rewards[agent_id] = 0\n        for agent_id in self.episode_steps:\n            self.episode_steps[agent_id] = 0", "language": "python"}
{"input": "************************************ Closure Functions ************************************", "output": "function onBackdropClick(e) {\n          e.preventDefault();\n          e.stopPropagation();\n          opts.restoreFocus = false;\n          $mdUtil.nextTick($mdSelect.hide, true);\n        }", "language": "javascript"}
{"input": "Change hparams to be compatible with TPU training.", "output": "def update_hparams_for_tpu(hparams):\n  \"\"\"Change hparams to be compatible with TPU training.\"\"\"\n\n  # Adafactor uses less memory than Adam.\n  # switch to Adafactor with its recommended learning rate scheme.\n  hparams.optimizer = \"Adafactor\"\n  hparams.learning_rate_schedule = \"rsqrt_decay\"\n  hparams.learning_rate_warmup_steps = 10000\n\n  # Avoid an expensive concat on TPU.\n  # >1 shards helps with faster parameter distribution on multi-GPU machines\n  hparams.symbol_modality_num_shards = 1\n\n  # Adaptive batch sizes and sequence lengths are not supported on TPU.\n  # Instead, every batch has the same sequence length and the same batch size.\n  # Longer sequences are dropped and shorter ones are padded.\n  #\n  # It is therefore suggested to use a problem where examples have been combined\n  # to a longer length, e.g. the \"_packed\" problems.\n  #\n  # For problems with variable sequence lengths, this parameter controls the\n  # maximum sequence length.  Shorter sequences are dropped and longer ones\n  # are padded.\n  #\n  # For problems with fixed sequence lengths - e.g. the \"_packed\" problems,\n  # this hyperparameter is ignored.\n  hparams.max_length = 64\n\n  # TPUs have less memory than GPUs, so decrease the batch size\n  hparams.batch_size = 2048\n\n  # Using noise broadcast in the dropout layers saves memory during training.\n  hparams.attention_dropout_broadcast_dims = \"0,1\"  # batch, heads\n  hparams.relu_dropout_broadcast_dims = \"1\"  # length\n  hparams.layer_prepostprocess_dropout_broadcast_dims = \"1\"  # length\n  return hparams", "language": "python"}
{"input": "Returns a map with library infos for the requested libraries\n\n@param {Array} aLibrariesToTest list of libraries to load\n@returns a map of library infos", "output": "function getRequestedLibraries(aLibrariesToTest) {\n\t\tvar mLibraries = sap.ui.getCore().getLoadedLibraries(),\n\t\t\tbNewLibrary,\n\t\t\ti;\n\n\t\t// make sure the explicitly requested libraries are there\n\t\tfor (i = 0; i < aLibrariesToTest.length; i++) {\n\t\t\tif (!mLibraries[aLibrariesToTest[i]]) {\n\t\t\t\tsap.ui.getCore().loadLibrary(aLibrariesToTest[i]); // no try-catch, as this library was explicitly requested\n\t\t\t\tbNewLibrary = true;\n\t\t\t}\n\t\t}\n\n\t\tif (bNewLibrary) {\n\t\t\tmLibraries = sap.ui.getCore().getLoadedLibraries();\n\t\t}\n\n\t\tfor (var sLibraryName in mLibraries) {\n\t\t\tif (aLibrariesToTest.indexOf(sLibraryName) === -1) {\n\t\t\t\tmLibraries[sLibraryName] = undefined;\n\t\t\t}\n\t\t}\n\n\t\treturn mLibraries;\n\t}", "language": "javascript"}
{"input": "Often in Gatsby context gets piped through GraphQL, but GraphQL adds unnecessary complexity here, so this uses the programmatic API. https://www.gatsbyjs.org/docs/using-gatsby-without-graphql/#the-approach-fetch-data-and-use-gatsbys-createpages-api", "output": "async function createPages({ actions: { createPage } }) {\n  if (includeDevPages) {\n    createPage({\n      path: '/dev/logos',\n      component: require.resolve('./frontend/components/development/logo-page'),\n    })\n  }\n\n  categories.forEach(category => {\n    const { id } = category\n    createPage({\n      path: `/category/${id}`,\n      component: require.resolve('./frontend/components/main'),\n      // `context` provided here becomes `props.pageContext` on the page.\n      context: { category },\n    })\n  })\n}", "language": "javascript"}
{"input": "Returns ComponentId of the control. If the control has no component, it walks up the control tree in order to find a control having one\n\n@param {sap.ui.core.Control} oControl - SAPUI5 control\n@returns {String} The component id or empty string if component id couldn't be found\n@see sap.ui.core.Component.getOwnerIdFor\n@private", "output": "function (oControl) {\n\t\t\tvar sComponentId = Utils._getOwnerIdForControl(oControl);\n\t\t\tif (!sComponentId) {\n\t\t\t\tif (oControl && typeof oControl.getParent === \"function\") {\n\t\t\t\t\tvar oParent = oControl.getParent();\n\t\t\t\t\tif (oParent) {\n\t\t\t\t\t\treturn Utils._getComponentIdForControl(oParent);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn sComponentId || \"\";\n\t\t}", "language": "javascript"}
{"input": "Go to the given source node", "output": "function _onRemoteGoto(event, res) {\n        // res = {nodeId, name, value}\n        var location, url = res.value;\n        var matches = /^(.*):([^:]+)$/.exec(url);\n        if (matches) {\n            url = matches[1];\n            location = matches[2].split(\",\");\n            if (location.length === 1) {\n                location = parseInt(location[0], 10);\n            } else {\n                location = { line: parseInt(location[0], 10), ch: parseInt(location[1], 10) };\n            }\n        }\n        open(url, location);\n    }", "language": "javascript"}
{"input": "`URLSearchParams.prototype.forEach` method", "output": "function forEach(callback /* , thisArg */) {\n    var entries = getInternalParamsState(this).entries;\n    var boundFunction = bind(callback, arguments.length > 1 ? arguments[1] : undefined, 3);\n    var i = 0;\n    var entry;\n    while (i < entries.length) {\n      entry = entries[i++];\n      boundFunction(entry.value, entry.key, this);\n    }\n  }", "language": "javascript"}
{"input": "Return a comparison of actual and expected hash values.\n\n        Example::\n\n               Expected sha256 abcdeabcdeabcdeabcdeabcdeabcdeabcdeabcdeabcde\n                            or 123451234512345123451234512345123451234512345\n                    Got        bcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdef", "output": "def _hash_comparison(self):\n        \"\"\"\n        Return a comparison of actual and expected hash values.\n\n        Example::\n\n               Expected sha256 abcdeabcdeabcdeabcdeabcdeabcdeabcdeabcdeabcde\n                            or 123451234512345123451234512345123451234512345\n                    Got        bcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdefbcdef\n\n        \"\"\"\n        def hash_then_or(hash_name):\n            # For now, all the decent hashes have 6-char names, so we can get\n            # away with hard-coding space literals.\n            return chain([hash_name], repeat('    or'))\n\n        lines = []\n        for hash_name, expecteds in iteritems(self.allowed):\n            prefix = hash_then_or(hash_name)\n            lines.extend(('        Expected %s %s' % (next(prefix), e))\n                         for e in expecteds)\n            lines.append('             Got        %s\\n' %\n                         self.gots[hash_name].hexdigest())\n            prefix = '    or'\n        return '\\n'.join(lines)", "language": "python"}
{"input": "/*\nFastest md5 implementation around (JKM md5)\nCredits: Joseph Myers\n\n@see http://www.myersdaily.org/joseph/javascript/md5-text.html\n@see http://jsperf.com/md5-shootout/7\n /* this function is much faster,\nso if possible we use it. Some IEs\nare the only ones I know of that\nneed the idiotic second function,\ngenerated by an if clause.", "output": "function (a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }", "language": "javascript"}
{"input": "Draw a heatmap on top of the original image using intensities from activation_map", "output": "def get_img_heatmap(orig_img, activation_map):\n    \"\"\"Draw a heatmap on top of the original image using intensities from activation_map\"\"\"\n    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_COOL)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    img_heatmap = np.float32(heatmap) + np.float32(orig_img)\n    img_heatmap = img_heatmap / np.max(img_heatmap)\n    img_heatmap *= 255\n    return img_heatmap.astype(int)", "language": "python"}
{"input": "Check whether a given token can connect the previous statement.\n@param {Token} token A token to check.\n@returns {boolean} `true` if the token is one of `[`, `(`, `/`, `+`, `-`, ```, `++`, and `--`.", "output": "function maybeAsiHazardBefore(token) {\n            return (\n                Boolean(token) &&\n                OPT_OUT_PATTERN.test(token.value) &&\n                token.value !== \"++\" &&\n                token.value !== \"--\"\n            );\n        }", "language": "javascript"}
{"input": "Dynamic Programming Algorithm for\n    counting the length of longest increasing subsequence\n    type sequence: List[int]", "output": "def longest_increasing_subsequence(sequence):\n    \"\"\"\n    Dynamic Programming Algorithm for\n    counting the length of longest increasing subsequence\n    type sequence: List[int]\n    \"\"\"\n    length = len(sequence)\n    counts = [1 for _ in range(length)]\n    for i in range(1, length):\n        for j in range(0, i):\n            if sequence[i] > sequence[j]:\n                counts[i] = max(counts[i], counts[j] + 1)\n                print(counts)\n    return max(counts)", "language": "python"}
{"input": "Estimate the probability density at points", "output": "def estimate(self, points):\n        \"\"\"Estimate the probability density at points\"\"\"\n        points = list(points)\n        densities = callMLlibFunc(\n            \"estimateKernelDensity\", self._sample, self._bandwidth, points)\n        return np.asarray(densities)", "language": "python"}
{"input": "Wraps a function so that it swallows exceptions.", "output": "def safecall(func):\n    \"\"\"Wraps a function so that it swallows exceptions.\"\"\"\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except Exception:\n            pass\n    return wrapper", "language": "python"}
{"input": "Function called when custom field button was pressed\n\n@param {sap.ui.base.Event}\noEvent event object", "output": "function (oEvent) {\n\t\t\t// open field ext ui\n\t\t\tvar oUshellContainer = FlUtils.getUshellContainer();\n\t\t\tvar oCrossAppNav = oUshellContainer.getService(\"CrossApplicationNavigation\");\n\t\t\tvar sHrefForFieldExtensionUi = (oCrossAppNav && oCrossAppNav.hrefForExternal({\n\t\t\t\ttarget : {\n\t\t\t\t\tsemanticObject : \"CustomField\",\n\t\t\t\t\taction : \"develop\"\n\t\t\t\t},\n\t\t\t\tparams : {\n\t\t\t\t\tbusinessContexts : this._oCurrentFieldExtInfo.BusinessContexts.map( function( oBusinessContext){\n\t\t\t\t\t\treturn oBusinessContext.BusinessContext;\n\t\t\t\t\t}),\n\t\t\t\t\tserviceName : this._oCurrentFieldExtInfo.ServiceName,\n\t\t\t\t\tserviceVersion : this._oCurrentFieldExtInfo.ServiceVersion,\n\t\t\t\t\tentityType : this._oCurrentFieldExtInfo.EntityType\n\t\t\t\t}\n\t\t\t}));\n\t\t\tUtils.openNewWindow(sHrefForFieldExtensionUi);\n\t\t}", "language": "javascript"}
{"input": "Calculate tree balance factor", "output": "def update_balances(self, recursive=True):\n        \"\"\"\n        Calculate tree balance factor\n\n        \"\"\"\n        if self.node:\n            if recursive:\n                if self.node.left:\n                    self.node.left.update_balances()\n                if self.node.right:\n                    self.node.right.update_balances()\n\n            self.balance = self.node.left.height - self.node.right.height\n        else:\n            self.balance = 0", "language": "python"}
{"input": "Sets an element's attributes without falling prey to things like\n<form><input name=\"setAttribute\"></form>. Equivalent to {@code\nelement.setAttribute(\"foo\", \"bar\")}.\n@param {!Element} element\n@param {string} name\n@param {string} value", "output": "function setElementAttribute(element, name, value) {\n  try {\n    genericMethodCall(\n        Methods.SET_ATTRIBUTE, element, 'setAttribute', [name, value]);\n  } catch (e) {\n    // IE throws an exception if the src attribute contains HTTP credentials.\n    // However the attribute gets set anyway.\n    if (e.message.indexOf('A security problem occurred') != -1) {\n      return;\n    }\n    throw e;\n  }\n}", "language": "javascript"}
{"input": "Process SVG string.\n@param {string} svg - An SVG string.\n@param {Promise<string>}", "output": "function processSvg(svg) {\n  return (\n    optimize(svg)\n      .then(setAttrs)\n      .then(format)\n      // remove semicolon inserted by prettier\n      // because prettier thinks it's formatting JSX not HTML\n      .then(svg => svg.replace(/;/g, ''))\n  );\n}", "language": "javascript"}
{"input": "Data representation of the datasource sent to the frontend", "output": "def data(self):\n        \"\"\"Data representation of the datasource sent to the frontend\"\"\"\n        order_by_choices = []\n        # self.column_names return sorted column_names\n        for s in self.column_names:\n            s = str(s or '')\n            order_by_choices.append((json.dumps([s, True]), s + ' [asc]'))\n            order_by_choices.append((json.dumps([s, False]), s + ' [desc]'))\n\n        verbose_map = {'__timestamp': 'Time'}\n        verbose_map.update({\n            o.metric_name: o.verbose_name or o.metric_name\n            for o in self.metrics\n        })\n        verbose_map.update({\n            o.column_name: o.verbose_name or o.column_name\n            for o in self.columns\n        })\n        return {\n            # simple fields\n            'id': self.id,\n            'column_formats': self.column_formats,\n            'description': self.description,\n            'database': self.database.data,  # pylint: disable=no-member\n            'default_endpoint': self.default_endpoint,\n            'filter_select': self.filter_select_enabled,  # TODO deprecate\n            'filter_select_enabled': self.filter_select_enabled,\n            'name': self.name,\n            'datasource_name': self.datasource_name,\n            'type': self.type,\n            'schema': self.schema,\n            'offset': self.offset,\n            'cache_timeout': self.cache_timeout,\n            'params': self.params,\n            'perm': self.perm,\n            'edit_url': self.url,\n\n            # sqla-specific\n            'sql': self.sql,\n\n            # one to many\n            'columns': [o.data for o in self.columns],\n            'metrics': [o.data for o in self.metrics],\n\n            # TODO deprecate, move logic to JS\n            'order_by_choices': order_by_choices,\n            'owners': [owner.id for owner in self.owners],\n            'verbose_map': verbose_map,\n            'select_star': self.select_star,\n        }", "language": "python"}
{"input": "Checks the SAPUI5 debug settings to determine whether all or at least the <code>sap.ui.fl</code> library is debugged.\n\n@returns {boolean} Returns a flag if the flexibility library is debugged\n@public", "output": "function () {\n\t\t\tvar oUriParams = this._getUriParameters();\n\t\t\tvar sDebugParameters = oUriParams.get(\"sap-ui-debug\") || \"\";\n\n\t\t\t// true if SAPUI5 is in complete debug mode\n\t\t\tif (sap.ui.getCore().getConfiguration().getDebug() || sDebugParameters === \"true\") {\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tvar aDebugParameters = sDebugParameters.split(\",\");\n\t\t\treturn aDebugParameters.indexOf(\"sap/ui/fl\") !== -1 || aDebugParameters.indexOf(\"sap/ui/fl/\") !== -1;\n\t\t}", "language": "javascript"}
{"input": "Set of hyperparameters.", "output": "def img2img_transformer2d_n31():\n  \"\"\"Set of hyperparameters.\"\"\"\n  hparams = img2img_transformer2d_base()\n  hparams.batch_size = 1\n  hparams.num_encoder_layers = 6\n  hparams.num_decoder_layers = 12\n  hparams.num_heads = 8\n  hparams.query_shape = (16, 32)\n  hparams.memory_flange = (16, 32)\n  return hparams", "language": "python"}
{"input": "It's too dangerous to use `-y` and `-r` together.", "output": "def _add_conflicting_arguments(self):\n        \"\"\"It's too dangerous to use `-y` and `-r` together.\"\"\"\n        group = self._parser.add_mutually_exclusive_group()\n        group.add_argument(\n            '-y', '--yes', '--yeah',\n            action='store_true',\n            help='execute fixed command without confirmation')\n        group.add_argument(\n            '-r', '--repeat',\n            action='store_true',\n            help='repeat on failure')", "language": "python"}
{"input": "Checks whether or not a node is `null` or `undefined`.\n@param {ASTNode} node - A node to check.\n@returns {boolean} Whether or not the node is a `null` or `undefined`.\n@public", "output": "function isNullOrUndefined(node) {\n    return (\n        module.exports.isNullLiteral(node) ||\n        (node.type === \"Identifier\" && node.name === \"undefined\") ||\n        (node.type === \"UnaryExpression\" && node.operator === \"void\")\n    );\n}", "language": "javascript"}
{"input": "Function: link\n\nAdds a link node to the head of the document. Use this\nto add a stylesheet to the page as follows:\n\n(code)\nmxClient.link('stylesheet', filename);\n(end)\n\nwhere filename is the (relative) URL of the stylesheet. The charset\nis hardcoded to ISO-8859-1 and the type is text/css.\n\nParameters:\n\nrel - String that represents the rel attribute of the link node.\nhref - String that represents the href attribute of the link node.\ndoc - Optional parent document of the link node.", "output": "function(rel, href, doc)\n\t{\n\t\tdoc = doc || document;\n\n\t\t// Workaround for Operation Aborted in IE6 if base tag is used in head\n\t\tif (mxClient.IS_IE6)\n\t\t{\n\t\t\tdoc.write('<link rel=\"' + rel + '\" href=\"' + href + '\" charset=\"UTF-8\" type=\"text/css\"/>');\n\t\t}\n\t\telse\n\t\t{\t\n\t\t\tvar link = doc.createElement('link');\n\t\t\t\n\t\t\tlink.setAttribute('rel', rel);\n\t\t\tlink.setAttribute('href', href);\n\t\t\tlink.setAttribute('charset', 'UTF-8');\n\t\t\tlink.setAttribute('type', 'text/css');\n\t\t\t\n\t\t\tvar head = doc.getElementsByTagName('head')[0];\n\t   \t\thead.appendChild(link);\n\t\t}\n\t}", "language": "javascript"}
{"input": "Search for vegetables.", "output": "function querySearch (query) {\n      var results = query ? self.vegetables.filter(createFilterFor(query)) : [];\n      return results;\n    }", "language": "javascript"}
{"input": "callback function to update draft specific properties post creation", "output": "function(oEvent) {\n\t\t\t\tvar oNewEntity = oEvent.getParameter(\"oEntity\");\n\t\t\t\toNewEntity.IsActiveEntity = false;\n\t\t\t\toNewEntity.HasActiveEntity = false;\n\t\t\t\toNewEntity.HasDraftEntity = false;\n\t\t\t}", "language": "javascript"}
{"input": "Checks and adapts the given index if needed.\n\n@param {sap.ui.table.Column} oColumn Column of the table.\n@param {int} iNewIndex The desired new index of the column in the current table setup.\n@returns {int} The corrected index.\n@private", "output": "function(oColumn, iNewIndex) {\n\t\t\tvar oTable = oColumn.getParent(),\n\t\t\t\tiCurrentIndex = oTable.indexOfColumn(oColumn),\n\t\t\t\taColumns = oTable.getColumns();\n\n\t\t\tif (iNewIndex > iCurrentIndex) {\n\t\t\t\t// The index is always given for the current table setup\n\t\t\t\t// -> A move consists of a remove and an insert, so if a column is moved to a higher index the index must be shifted\n\t\t\t\tiNewIndex--;\n\t\t\t}\n\t\t\tif (iNewIndex < 0) {\n\t\t\t\tiNewIndex = 0;\n\t\t\t} else if (iNewIndex > aColumns.length) {\n\t\t\t\tiNewIndex = aColumns.length;\n\t\t\t}\n\n\t\t\treturn iNewIndex;\n\t\t}", "language": "javascript"}
{"input": "Construct Chips instance and set up overlay\n@constructor\n@param {Element} el\n@param {Object} options", "output": "function Chips(el, options) {\n      _classCallCheck(this, Chips);\n\n      var _this45 = _possibleConstructorReturn(this, (Chips.__proto__ || Object.getPrototypeOf(Chips)).call(this, Chips, el, options));\n\n      _this45.el.M_Chips = _this45;\n\n      /**\n       * Options for the modal\n       * @member Chips#options\n       * @prop {Array} data\n       * @prop {String} placeholder\n       * @prop {String} secondaryPlaceholder\n       * @prop {Object} autocompleteOptions\n       */\n      _this45.options = $.extend({}, Chips.defaults, options);\n\n      _this45.$el.addClass('chips input-field');\n      _this45.chipsData = [];\n      _this45.$chips = $();\n      _this45._setupInput();\n      _this45.hasAutocomplete = Object.keys(_this45.options.autocompleteOptions).length > 0;\n\n      // Set input id\n      if (!_this45.$input.attr('id')) {\n        _this45.$input.attr('id', M.guid());\n      }\n\n      // Render initial chips\n      if (_this45.options.data.length) {\n        _this45.chipsData = _this45.options.data;\n        _this45._renderChips(_this45.chipsData);\n      }\n\n      // Setup autocomplete if needed\n      if (_this45.hasAutocomplete) {\n        _this45._setupAutocomplete();\n      }\n\n      _this45._setPlaceholder();\n      _this45._setupLabel();\n      _this45._setupEventHandlers();\n      return _this45;\n    }", "language": "javascript"}
{"input": "get/set the rendered (i.e. on screen) positon of the element", "output": "function renderedPosition(dim, val) {\n    var ele = this[0];\n    var cy = this.cy();\n    var zoom = cy.zoom();\n    var pan = cy.pan();\n    var rpos = plainObject(dim) ? dim : undefined;\n    var setting = rpos !== undefined || val !== undefined && string(dim);\n\n    if (ele && ele.isNode()) {\n      // must have an element and must be a node to return position\n      if (setting) {\n        for (var i = 0; i < this.length; i++) {\n          var _ele = this[i];\n\n          if (val !== undefined) {\n            // set one dimension\n            _ele.position(dim, (val - pan[dim]) / zoom);\n          } else if (rpos !== undefined) {\n            // set whole position\n            _ele.position(renderedToModelPosition(rpos, zoom, pan));\n          }\n        }\n      } else {\n        // getting\n        var pos = ele.position();\n        rpos = modelToRenderedPosition(pos, zoom, pan);\n\n        if (dim === undefined) {\n          // then return the whole rendered position\n          return rpos;\n        } else {\n          // then return the specified dimension\n          return rpos[dim];\n        }\n      }\n    } else if (!setting) {\n      return undefined; // for empty collection case\n    }\n\n    return this; // chaining\n  }", "language": "javascript"}
{"input": "Returns copies of this parameter on all contexts, in the same order\n        as creation. For sparse parameters, use :py:meth:`Parameter.list_row_sparse_data`\n        instead.\n\n        Returns\n        -------\n        list of NDArrays", "output": "def list_data(self):\n        \"\"\"Returns copies of this parameter on all contexts, in the same order\n        as creation. For sparse parameters, use :py:meth:`Parameter.list_row_sparse_data`\n        instead.\n\n        Returns\n        -------\n        list of NDArrays\n        \"\"\"\n        if self._stype != 'default':\n            raise RuntimeError(\"Cannot return copies of Parameter '%s' on all contexts via \" \\\n                               \"list_data() because its storage type is %s. Please use \" \\\n                               \"row_sparse_data() instead.\" % (self.name, self._stype))\n        return self._check_and_get(self._data, list)", "language": "python"}
{"input": "Confusion matrix as an `np.ndarray`.", "output": "def confusion_matrix(self, slice_size:int=1):\n        \"Confusion matrix as an `np.ndarray`.\"\n        x=torch.arange(0,self.data.c)\n        if slice_size is None: cm = ((self.pred_class==x[:,None]) & (self.y_true==x[:,None,None])).sum(2)\n        else:\n            cm = torch.zeros(self.data.c, self.data.c, dtype=x.dtype)\n            for i in range(0, self.y_true.shape[0], slice_size):\n                cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n                            & (self.y_true[i:i+slice_size]==x[:,None,None])).sum(2)\n                torch.add(cm, cm_slice, out=cm)\n        return to_np(cm)", "language": "python"}
{"input": "Asynchronously asks providers to handle jump-to-definition.\n@return {!Promise} Resolved when the provider signals that it's done; rejected if no\nprovider responded or the provider that responded failed.", "output": "function _doJumpToDef() {\n        var request = null,\n            result = new $.Deferred(),\n            jumpToDefProvider = null,\n            editor = EditorManager.getActiveEditor();\n\n        if (editor) {\n            // Find a suitable provider, if any\n            var language = editor.getLanguageForSelection(),\n                enabledProviders = _providerRegistrationHandler.getProvidersForLanguageId(language.getId());\n\n\n            enabledProviders.some(function (item, index) {\n                if (item.provider.canJumpToDef(editor)) {\n                    jumpToDefProvider = item.provider;\n                    return true;\n                }\n            });\n\n            if (jumpToDefProvider) {\n                request = jumpToDefProvider.doJumpToDef(editor);\n\n                if (request) {\n                    request.done(function () {\n                        result.resolve();\n                    }).fail(function () {\n                        result.reject();\n                    });\n                } else {\n                    result.reject();\n                }\n            } else {\n                result.reject();\n            }\n        } else {\n            result.reject();\n        }\n\n        return result.promise();\n    }", "language": "javascript"}
{"input": "Multi layer transformer encoder.", "output": "def transformer_encoder_layers(inputs,\n                               num_layers,\n                               hparams,\n                               attention_type=AttentionType.GLOBAL,\n                               self_attention_bias=None,\n                               q_padding=\"VALID\",\n                               kv_padding=\"VALID\",\n                               name=\"transformer\"):\n  \"\"\"Multi layer transformer encoder.\"\"\"\n  x = inputs\n  x = tf.nn.dropout(x, 1.0 - hparams.layer_prepostprocess_dropout)\n\n  for layer in range(num_layers):\n    # attention layers + skip connections\n    with tf.variable_scope(\"%s_layer_%d\" % (name, layer)):\n      if attention_type == AttentionType.LOCAL_2D:\n        y = local_attention_2d(common_layers.layer_preprocess(x, hparams),\n                               hparams,\n                               attention_type=\"local_attention_2d\")\n      elif attention_type == AttentionType.LOCAL_1D:\n        y = local_attention_1d(common_layers.layer_preprocess(x, hparams),\n                               hparams,\n                               attention_type=\"local_unmasked\",\n                               q_padding=q_padding, kv_padding=kv_padding)\n      elif attention_type == AttentionType.GLOBAL:\n        y = full_self_attention(common_layers.layer_preprocess(x, hparams),\n                                self_attention_bias, hparams,\n                                q_padding=q_padding, kv_padding=kv_padding)\n      x = common_layers.layer_postprocess(x, y, hparams)\n      # feed-fwd layer + skip connections\n      y = ffn_layer(common_layers.layer_preprocess(x, hparams), hparams)\n      x = common_layers.layer_postprocess(x, y, hparams)\n  return common_layers.layer_preprocess(x, hparams)", "language": "python"}
{"input": "Helper function to find any files in the project that end with the\nname we are looking for.  This is so we can find requirejs modules\nwhen the baseUrl is unknown, or when the project root is not the same\nas the script root (e.g. if you open the 'brackets' dir instead of 'brackets/src' dir).", "output": "function findNameInProject() {\n                // check for any files in project that end with the right path.\n                var fileName = name.substring(name.lastIndexOf(\"/\") + 1);\n\n                function _fileFilter(entry) {\n                    return entry.name === fileName;\n                }\n\n                ProjectManager.getAllFiles(_fileFilter).done(function (files) {\n                    var file;\n                    files = files.filter(function (file) {\n                        var pos = file.fullPath.length - name.length;\n                        return pos === file.fullPath.lastIndexOf(name);\n                    });\n\n                    if (files.length === 1) {\n                        file = files[0];\n                    }\n                    if (file) {\n                        getDocText(file.fullPath).fail(function () {\n                            replyWith(name, \"\");\n                        });\n                    } else {\n                        replyWith(name, \"\");\n                    }\n                });\n            }", "language": "javascript"}
{"input": "Xception body.", "output": "def xception_internal(inputs, hparams):\n  \"\"\"Xception body.\"\"\"\n  with tf.variable_scope(\"xception\"):\n    cur = inputs\n\n    if cur.get_shape().as_list()[1] > 200:\n      # Large image, Xception entry flow\n      cur = xception_entry(cur, hparams.hidden_size)\n    else:\n      # Small image, conv\n      cur = common_layers.conv_block(\n          cur,\n          hparams.hidden_size, [((1, 1), (3, 3))],\n          first_relu=False,\n          padding=\"SAME\",\n          force2d=True,\n          name=\"small_image_conv\")\n\n    for i in range(hparams.num_hidden_layers):\n      with tf.variable_scope(\"layer_%d\" % i):\n        cur = residual_block(cur, hparams)\n\n    return xception_exit(cur)", "language": "python"}
{"input": "Trains the model.", "output": "def train(net, X_train, y_train, epochs, verbose_epoch, learning_rate,\n          weight_decay, batch_size):\n    \"\"\"Trains the model.\"\"\"\n    dataset_train = gluon.data.ArrayDataset(X_train, y_train)\n    data_iter_train = gluon.data.DataLoader(dataset_train, batch_size,\n                                            shuffle=True)\n    trainer = gluon.Trainer(net.collect_params(), 'adam',\n                            {'learning_rate': learning_rate,\n                             'wd': weight_decay})\n    net.initialize(force_reinit=True)\n    for epoch in range(epochs):\n        for data, label in data_iter_train:\n            with autograd.record():\n                output = net(data)\n                loss = square_loss(output, label)\n            loss.backward()\n            trainer.step(batch_size)\n            avg_loss = get_rmse_log(net, X_train, y_train)\n        if epoch > verbose_epoch:\n            print(\"Epoch %d, train loss: %f\" % (epoch, avg_loss))\n    return avg_loss", "language": "python"}
{"input": "Adds the infix operator with the given id, binding power and formatter function to the\nsymbol table.\n@param {string} sId - the id of the infix operator\n@param {int} iBindingPower - the binding power = precedence of the infix operator\n@param {function} fnOperator - the function to evaluate the operator\n@param {boolean} [bLazy=false] - whether the right operand is lazily evaluated\n@return {object} the newly created symbol for the infix operator", "output": "function addInfix(sId, iBindingPower, fnOperator, bLazy) {\n\t\t// Note: this function is executed at load time only!\n\t\tmSymbols[sId] = {\n\t\t\tlbp: iBindingPower,\n\t\t\tled: function (oToken, oParser, fnLeft) {\n\t\t\t\t//lazy evaluation is right associative: performance optimization for guard and\n\t\t\t\t//default operator, e.g. true || A || B || C does not execute the || for B and C\n\t\t\t\tvar rbp = bLazy ? this.lbp - 1 : this.lbp;\n\n\t\t\t\treturn INFIX.bind(null, fnLeft, oParser.expression(rbp),\n\t\t\t\t\tfnOperator, bLazy);\n\t\t\t},\n\t\t\tnud: unexpected\n\t\t};\n\t\treturn mSymbols[sId];\n\t}", "language": "javascript"}
{"input": "Makes sure that time and panels are conformable.", "output": "def _ensure_like_indices(time, panels):\n    \"\"\"\n    Makes sure that time and panels are conformable.\n    \"\"\"\n    n_time = len(time)\n    n_panel = len(panels)\n    u_panels = np.unique(panels)  # this sorts!\n    u_time = np.unique(time)\n    if len(u_time) == n_time:\n        time = np.tile(u_time, len(u_panels))\n    if len(u_panels) == n_panel:\n        panels = np.repeat(u_panels, len(u_time))\n    return time, panels", "language": "python"}
{"input": "/*\nInternal class that can help to synchronize a set of asynchronous tasks.\nEach task must be registered in the sync point by calling startTask with\nan (purely informative) title. The returned value must be used in a later\ncall to finishTask.\nWhen finishTask has been called for all tasks that have been started,\nthe fnCallback will be fired.\nWhen a timeout is given and reached, the callback is called at that\ntime, no matter whether all tasks have been finished or not.", "output": "function (sName, fnCallback) {\n\t\tvar aTasks = [],\n\t\t\tiOpenTasks = 0,\n\t\t\tiFailures = 0;\n\n\t\tthis.startTask = function(sTitle) {\n\t\t\tvar iId = aTasks.length;\n\t\t\taTasks[iId] = { name : sTitle, finished : false };\n\t\t\tiOpenTasks++;\n\t\t\treturn iId;\n\t\t};\n\n\t\tthis.finishTask = function(iId, bSuccess) {\n\t\t\tif ( !aTasks[iId] || aTasks[iId].finished ) {\n\t\t\t\tthrow new Error(\"trying to finish non existing or already finished task\");\n\t\t\t}\n\t\t\taTasks[iId].finished = true;\n\t\t\tiOpenTasks--;\n\t\t\tif ( bSuccess === false ) {\n\t\t\t\tiFailures++;\n\t\t\t}\n\t\t\tif ( iOpenTasks === 0 ) {\n\t\t\t\tLog.info(\"Sync point '\" + sName + \"' finished (tasks:\" + aTasks.length + \", open:\" + iOpenTasks + \", failures:\" + iFailures + \")\");\n\t\t\t\tfinish();\n\t\t\t}\n\t\t};\n\n\t\tfunction finish() {\n\t\t\tif ( fnCallback ) {\n\t\t\t\tfnCallback(iOpenTasks, iFailures);\n\t\t\t}\n\t\t\tfnCallback = null;\n\t\t}\n\n\t\tLog.info(\"Sync point '\" + sName + \"' created\");\n\t}", "language": "javascript"}
{"input": "Matching function e.g. match(\"a\", input) will look for the regexp called \"a\" and see if it matches returns null or {match_:\"a\", remainder:\"bc\"}", "output": "function (m, input) {\n        var pattern = mhchemParser.patterns.patterns[m];\n        if (pattern === undefined) {\n          throw [\"MhchemBugP\", \"mhchem bug P. Please report. (\" + m + \")\"];  // Trying to use non-existing pattern\n        } else if (typeof pattern === \"function\") {\n          return mhchemParser.patterns.patterns[m](input);  // cannot use cached var pattern here, because some pattern functions need this===mhchemParser\n        } else {  // RegExp\n          var match = input.match(pattern);\n          if (match) {\n            var mm;\n            if (match[2]) {\n              mm = [ match[1], match[2] ];\n            } else if (match[1]) {\n              mm = match[1];\n            } else {\n              mm = match[0];\n            }\n            return { match_: mm, remainder: input.substr(match[0].length) };\n          }\n          return null;\n        }\n      }", "language": "javascript"}
{"input": "Saves the binding as a part. Reuses an existing part if the binding is identical.\n@param {object} oBinding\nthe binding to save\n@param {int} iStart\nthe binding's start index in the input string\n@param {boolean} [bTargetTypeAny=false]\nwhether the binding's \"targetType\" should default to \"any\" (recursively, for all parts)\n@returns {int}\nthe index at which it has been saved/found in aParts", "output": "function saveBindingAsPart(oBinding, iStart, bTargetTypeAny) {\n\t\t\tvar bHasNonPrimitiveValue = false,\n\t\t\t\tsKey,\n\t\t\t\toPrimitiveValueBinding,\n\t\t\t\ti;\n\n\t\t\t/*\n\t\t\t * Sets the target type of the given binding to the default \"any\", if applicable.\n\t\t\t *\n\t\t\t * @param {object} oBinding\n\t\t\t *   A binding\n\t\t\t */\n\t\t\tfunction setTargetType(oBinding) {\n\t\t\t\tif (bTargetTypeAny) {\n\t\t\t\t\tif (oBinding.parts) {\n\t\t\t\t\t\toBinding.parts.forEach(setTargetType);\n\t\t\t\t\t\t// Note: targetType not allowed here, see BindingParser.mergeParts\n\t\t\t\t\t} else {\n\t\t\t\t\t\toBinding.targetType = oBinding.targetType || \"any\";\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (sKey in oBinding) {\n\t\t\t\tswitch (typeof oBinding[sKey]) {\n\t\t\t\t\tcase \"boolean\":\n\t\t\t\t\tcase \"number\":\n\t\t\t\t\tcase \"string\":\n\t\t\t\t\tcase \"undefined\":\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\t// binding has at least one property of non-primitive value\n\t\t\t\t\t\tbHasNonPrimitiveValue = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsetTargetType(oBinding);\n\t\t\tif (bHasNonPrimitiveValue) {\n\t\t\t\t// the binding must be a complex binding; property \"type\" (and poss. others) are\n\t\t\t\t// newly created objects and thus incomparable -> parse again to have the names\n\t\t\t\toPrimitiveValueBinding = JSTokenizer.parseJS(sInput, iStart).result;\n\t\t\t\tsetTargetType(oPrimitiveValueBinding);\n\t\t\t} else {\n\t\t\t\t// only primitive values; easily comparable\n\t\t\t\toPrimitiveValueBinding = oBinding;\n\t\t\t}\n\t\t\tfor (i = 0; i < aParts.length; i += 1) {\n\t\t\t\t// Note: order of top-level properties must not matter for equality!\n\t\t\t\tif (deepEqual(aPrimitiveValueBindings[i], oPrimitiveValueBinding)) {\n\t\t\t\t\treturn i;\n\t\t\t\t}\n\t\t\t}\n\t\t\taPrimitiveValueBindings[i] = oPrimitiveValueBinding;\n\t\t\taParts[i] = oBinding;\n\t\t\treturn i;\n\t\t}", "language": "javascript"}
{"input": "OR (false/true)\n\n    This tests how well a feature attribution method agrees with human intuition\n    for an OR operation combined with linear effects. This metric deals\n    specifically with the question of credit allocation for the following function\n    when all three inputs are true:\n    if fever: +2 points\n    if cough: +2 points\n    if fever or cough: +6 points\n\n    transform = \"identity\"\n    sort_order = 1", "output": "def human_or_01(X, y, model_generator, method_name):\n    \"\"\" OR (false/true)\n\n    This tests how well a feature attribution method agrees with human intuition\n    for an OR operation combined with linear effects. This metric deals\n    specifically with the question of credit allocation for the following function\n    when all three inputs are true:\n    if fever: +2 points\n    if cough: +2 points\n    if fever or cough: +6 points\n\n    transform = \"identity\"\n    sort_order = 1\n    \"\"\"\n    return _human_or(X, model_generator, method_name, False, True)", "language": "python"}
{"input": "Construct highway net\n    Parameters\n    ----------\n    data:\n    Returns\n    ----------\n    Highway Networks", "output": "def highway(data):\n    \"\"\"Construct highway net\n    Parameters\n    ----------\n    data:\n    Returns\n    ----------\n    Highway Networks\n    \"\"\"\n    _data = data\n    high_weight = mx.sym.Variable('high_weight')\n    high_bias = mx.sym.Variable('high_bias')\n    high_fc = mx.sym.FullyConnected(data=data, weight=high_weight, bias=high_bias, num_hidden=300, name='high_fc')\n    high_relu = mx.sym.Activation(high_fc, act_type='relu')\n\n    high_trans_weight = mx.sym.Variable('high_trans_weight')\n    high_trans_bias = mx.sym.Variable('high_trans_bias')\n    high_trans_fc = mx.sym.FullyConnected(data=_data, weight=high_trans_weight, bias=high_trans_bias, num_hidden=300,\n                                          name='high_trans_sigmoid')\n    high_trans_sigmoid = mx.sym.Activation(high_trans_fc, act_type='sigmoid')\n\n    return high_relu * high_trans_sigmoid + _data * (1 - high_trans_sigmoid)", "language": "python"}
{"input": "apply the function to my values; return a block if we are not\n        one", "output": "def apply(self, func, **kwargs):\n        \"\"\" apply the function to my values; return a block if we are not\n        one\n        \"\"\"\n        with np.errstate(all='ignore'):\n            result = func(self.values, **kwargs)\n        if not isinstance(result, Block):\n            result = self.make_block(values=_block_shape(result,\n                                                         ndim=self.ndim))\n\n        return result", "language": "python"}
{"input": "Return list of all sanitize files provided by the user on the command line.\n\n        N.B.: We only support one sanitize file at the moment, but\n              this is likely to change in the future", "output": "def get_sanitize_files(self):\n        \"\"\"\n        Return list of all sanitize files provided by the user on the command line.\n\n        N.B.: We only support one sanitize file at the moment, but\n              this is likely to change in the future\n\n        \"\"\"\n        if self.parent.config.option.sanitize_with is not None:\n            return [self.parent.config.option.sanitize_with]\n        else:\n            return []", "language": "python"}
{"input": "Return the python codec name corresponding to an encoding or None if the\n    string doesn't correspond to a valid encoding.", "output": "def lookupEncoding(encoding):\n    \"\"\"Return the python codec name corresponding to an encoding or None if the\n    string doesn't correspond to a valid encoding.\"\"\"\n    if isinstance(encoding, binary_type):\n        try:\n            encoding = encoding.decode(\"ascii\")\n        except UnicodeDecodeError:\n            return None\n\n    if encoding is not None:\n        try:\n            return webencodings.lookup(encoding)\n        except AttributeError:\n            return None\n    else:\n        return None", "language": "python"}
{"input": "Iterate over batches of items. `size` may be an iterator,\n    so that batch-size can vary on each step.", "output": "def minibatch(items, size=8):\n    \"\"\"Iterate over batches of items. `size` may be an iterator,\n    so that batch-size can vary on each step.\n    \"\"\"\n    if isinstance(size, int):\n        size_ = itertools.repeat(size)\n    else:\n        size_ = size\n    items = iter(items)\n    while True:\n        batch_size = next(size_)\n        batch = list(itertools.islice(items, int(batch_size)))\n        if len(batch) == 0:\n            break\n        yield list(batch)", "language": "python"}
{"input": "Get media type from file extension", "output": "function getTypeFromFileExtension(url) {\n\turl = url.toLowerCase().split('?')[0];\n\tvar _ext = url.substring(url.lastIndexOf('.') + 1);\n\tvar _av = /mp4|m4v|ogg|ogv|m3u8|webm|webmv|wmv|mpeg|mov/gi.test(_ext) ? 'video/' : 'audio/';\n\n\tswitch (_ext) {\n\t\tcase 'mp4':\n\t\tcase 'm4v':\n\t\tcase 'm4a':\n\t\t\treturn _av + 'mp4';\n\t\tcase 'webm':\n\t\tcase 'webma':\n\t\tcase 'webmv':\n\t\t\treturn _av + 'webm';\n\t\tcase 'ogg':\n\t\tcase 'oga':\n\t\tcase 'ogv':\n\t\t\treturn _av + 'ogg';\n\t\tcase 'm3u8':\n\t\t\treturn 'application/x-mpegurl';\n\t\tcase 'ts':\n\t\t\treturn _av + 'mp2t';\n\t\tdefault:\n\t\t\treturn _av + _ext;\n\t}\n}", "language": "javascript"}
{"input": "Walk over summary and execute \"fn\" on each article\n\n@param {Summary} summary\n@param {Function(article)}\n@return {Promise}", "output": "function walkSummary(summary, fn) {\n    var parts = summary.getParts();\n\n    return Promise.forEach(parts, function(part) {\n        return walkArticles(part.getArticles(), fn);\n    });\n}", "language": "javascript"}
{"input": "Fetches one result of the running trials.\n\n        Returns:\n            Result of the most recent trial training run.", "output": "def fetch_result(self, trial):\n        \"\"\"Fetches one result of the running trials.\n\n        Returns:\n            Result of the most recent trial training run.\"\"\"\n        trial_future = self._find_item(self._running, trial)\n        if not trial_future:\n            raise ValueError(\"Trial was not running.\")\n        self._running.pop(trial_future[0])\n        with warn_if_slow(\"fetch_result\"):\n            result = ray.get(trial_future[0])\n\n        # For local mode\n        if isinstance(result, _LocalWrapper):\n            result = result.unwrap()\n        return result", "language": "python"}
{"input": "Parse from a token, regexp or string, and move forward if match", "output": "function $(tok) {\n        var tokType = typeof tok,\n            match, length;\n\n        // Either match a single character in the input,\n        // or match a regexp in the current chunk (`current`).\n        //\n        if (tokType === \"string\") {\n            if (input.charAt(i) !== tok) {\n                return null;\n            }\n            skipWhitespace(1);\n            return tok;\n        }\n\n        // regexp\n        sync ();\n        if (! (match = tok.exec(current))) {\n            return null;\n        }\n\n        length = match[0].length;\n\n        // The match is confirmed, add the match length to `i`,\n        // and consume any extra white-space characters (' ' || '\\n')\n        // which come after that. The reason for this is that LeSS's\n        // grammar is mostly white-space insensitive.\n        //\n        skipWhitespace(length);\n\n        if(typeof(match) === 'string') {\n            return match;\n        } else {\n            return match.length === 1 ? match[0] : match;\n        }\n    }", "language": "javascript"}
{"input": "Compute group sizes", "output": "def size(self):\n        \"\"\"\n        Compute group sizes\n\n        \"\"\"\n        ids, _, ngroup = self.group_info\n        ids = ensure_platform_int(ids)\n        if ngroup:\n            out = np.bincount(ids[ids != -1], minlength=ngroup)\n        else:\n            out = []\n        return Series(out,\n                      index=self.result_index,\n                      dtype='int64')", "language": "python"}
{"input": "### Handle Permissions\nWe need to be an authorised user to perform this action\n@param {Object} options\n@returns {Object} options", "output": "function handlePermissions(options) {\n            return models.Role.findOne({name: 'Owner'}).then((ownerRole) => {\n                return canThis(options.context).assign.role(ownerRole);\n            }).then(() => {\n                return options;\n            });\n        }", "language": "javascript"}
{"input": "Concatenate multiple serialized binders into one byte string.", "output": "def merge_bytes(binder_strings):\n    \"\"\"Concatenate multiple serialized binders into one byte string.\"\"\"\n    output = None\n    for byte_string in binder_strings:\n        binder = Binder().from_bytes(byte_string)\n        if output is None:\n            output = binder\n        else:\n            output.merge(binder)\n    return output.to_bytes()", "language": "python"}
{"input": "Returns the local ID of the encompassing variant management control.\n\n@param {sap.ui.core.Element} oControl - The control for which a variant management control has to be evaluated\n@returns {object} Returns a map with needed parameters\n@private", "output": "function(oControl, mParams) {\n\t\t\tmParams = mParams || this._determineParameters(oControl);\n\t\t\tvar fnCheckForControl = function (oControl) {\n\t\t\t\tif (!mParams.variantManagement[oControl.getId()] && oControl.getParent() && oControl.getId() !== mParams.rootControl.getId()) {\n\t\t\t\t\treturn fnCheckForControl(oControl.getParent());\n\t\t\t\t} else if (!oControl.getParent() || oControl.getId() === mParams.rootControl.getId()) {\n\t\t\t\t\treturn mParams.variantManagement[oControl.getId()] || \"\";\n\t\t\t\t} else {\n\t\t\t\t\treturn mParams.variantManagement[oControl.getId()];\n\t\t\t\t}\n\t\t\t};\n\n\t\t\treturn fnCheckForControl(oControl);\n\t\t}", "language": "javascript"}
{"input": "Validate cubic-bezier function parameters that are not already validated by regex:\n\n@param {RegExp.match} match  RegExp Match object with cubic-bezier function parameters\nin array positions 1-4.\n@return {boolean} true if all parameters are valid, otherwise, false", "output": "function _validateCubicBezierParams(match) {\n        var x1 = _convertToNumber(match[1]),\n            y1 = _convertToNumber(match[2]),\n            x2 = _convertToNumber(match[3]),\n            y2 = _convertToNumber(match[4]);\n\n        // Verify all params are numbers\n        if (!x1.isNumber || !y1.isNumber || !x2.isNumber || !y2.isNumber) {\n            return false;\n        }\n\n        // Verify x params are in 0-1 range\n        if (x1.value < 0 || x1.value > 1 || x2.value < 0 || x2.value > 1) {\n            return false;\n        }\n\n        return true;\n    }", "language": "javascript"}
{"input": "/*\nAdds the given mapping to oValueListInfo.\n\n@param {object} mValueListMapping The mapping\n@param {string} sQualifier The mapping qualifier\n@param {string} sMappingUrl The mapping URL (for error messages)\n@param {sap.ui.model.odata.v4.ODataModel} oModel The value list model\n@throws {Error} If there is already a mapping for the given qualifier", "output": "function addMapping(mValueListMapping, sQualifier, sMappingUrl, oModel) {\n\t\t\t\tif (bFixedValues !== undefined && \"SearchSupported\" in mValueListMapping) {\n\t\t\t\t\tthrow new Error(\"Must not set 'SearchSupported' in annotation \"\n\t\t\t\t\t\t+ \"'com.sap.vocabularies.Common.v1.ValueList' and annotation \"\n\t\t\t\t\t\t+ \"'com.sap.vocabularies.Common.v1.ValueListWithFixedValues'\");\n\t\t\t\t}\n\t\t\t\tif (\"CollectionRoot\" in mValueListMapping) {\n\t\t\t\t\toModel = that.getOrCreateSharedModel(mValueListMapping.CollectionRoot);\n\t\t\t\t\tif (oValueListInfo[sQualifier]\n\t\t\t\t\t\t\t&& oValueListInfo[sQualifier].$model === oModel) {\n\t\t\t\t\t\t// same model -> allow overriding the qualifier\n\t\t\t\t\t\tmMappingUrlByQualifier[sQualifier] = undefined;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (mMappingUrlByQualifier[sQualifier]) {\n\t\t\t\t\tthrow new Error(\"Annotations '\" + sValueList.slice(1)\n\t\t\t\t\t\t+ \"' with identical qualifier '\" + sQualifier\n\t\t\t\t\t\t+ \"' for property \" + sPropertyPath + \" in \"\n\t\t\t\t\t\t+ mMappingUrlByQualifier[sQualifier] + \" and \" + sMappingUrl);\n\t\t\t\t}\n\t\t\t\tmMappingUrlByQualifier[sQualifier] = sMappingUrl;\n\t\t\t\tmValueListMapping = jQuery.extend(true, {\n\t\t\t\t\t$model : oModel\n\t\t\t\t}, mValueListMapping);\n\t\t\t\tdelete mValueListMapping.CollectionRoot;\n\t\t\t\tdelete mValueListMapping.SearchSupported;\n\t\t\t\toValueListInfo[sQualifier] = mValueListMapping;\n\t\t\t}", "language": "javascript"}
{"input": "validate against an existing table", "output": "def validate(self, other):\n        \"\"\" validate against an existing table \"\"\"\n        if other is None:\n            return\n\n        if other.table_type != self.table_type:\n            raise TypeError(\n                \"incompatible table_type with existing \"\n                \"[{other} - {self}]\".format(\n                    other=other.table_type, self=self.table_type))\n\n        for c in ['index_axes', 'non_index_axes', 'values_axes']:\n            sv = getattr(self, c, None)\n            ov = getattr(other, c, None)\n            if sv != ov:\n\n                # show the error for the specific axes\n                for i, sax in enumerate(sv):\n                    oax = ov[i]\n                    if sax != oax:\n                        raise ValueError(\n                            \"invalid combinate of [{c}] on appending data \"\n                            \"[{sax}] vs current table [{oax}]\".format(\n                                c=c, sax=sax, oax=oax))\n\n                # should never get here\n                raise Exception(\n                    \"invalid combinate of [{c}] on appending data [{sv}] vs \"\n                    \"current table [{ov}]\".format(c=c, sv=sv, ov=ov))", "language": "python"}
{"input": "return a read-only clone of the current theme configuration", "output": "function() {\n      return angular.extend({ }, themeConfig, {\n        defaultTheme : defaultTheme,\n        alwaysWatchTheme : alwaysWatchTheme,\n        registeredStyles : [].concat(themeConfig.registeredStyles)\n      });\n    }", "language": "javascript"}
{"input": "Return a new DStream in which each RDD contains the counts of each\n        distinct value in each RDD of this DStream.", "output": "def countByValue(self):\n        \"\"\"\n        Return a new DStream in which each RDD contains the counts of each\n        distinct value in each RDD of this DStream.\n        \"\"\"\n        return self.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y)", "language": "python"}
{"input": "PrivateFunction: _makeGenerator\n_Private_ function that creates a dummy XML DOM document to serve as\nan element and text node generator.", "output": "function () {\r\n        var doc;\r\n\r\n        // IE9 does implement createDocument(); however, using it will cause the browser to leak memory on page unload.\r\n        // Here, we test for presence of createDocument() plus IE's proprietary documentMode attribute, which would be\r\n                // less than 10 in the case of IE9 and below.\r\n        if (document.implementation.createDocument === undefined ||\r\n                        document.implementation.createDocument && document.documentMode && document.documentMode < 10) {\r\n            doc = this._getIEXmlDom();\r\n            doc.appendChild(doc.createElement('strophe'));\r\n        } else {\r\n            doc = document.implementation\r\n                .createDocument('jabber:client', 'strophe', null);\r\n        }\r\n\r\n        return doc;\r\n    }", "language": "javascript"}
{"input": "Computes the version of packages after installing to_install.", "output": "def _simulate_installation_of(to_install, package_set):\n    # type: (List[InstallRequirement], PackageSet) -> Set[str]\n    \"\"\"Computes the version of packages after installing to_install.\n    \"\"\"\n\n    # Keep track of packages that were installed\n    installed = set()\n\n    # Modify it as installing requirement_set would (assuming no errors)\n    for inst_req in to_install:\n        dist = make_abstract_dist(inst_req).dist()\n        name = canonicalize_name(dist.key)\n        package_set[name] = PackageDetails(dist.version, dist.requires())\n\n        installed.add(name)\n\n    return installed", "language": "python"}
{"input": "@private\nDispatches a message to the remote protocol handler via the transport.\n\n@param {Object} msg The message to send.\n@param {number|Array.<number>} idOrArray ID or IDs of the client(s) that should\nreceive the message.\n@return {$.Promise} A promise that's fulfilled when the response to the message is received.", "output": "function _send(msg, clients) {\n        var id = _nextMsgId++,\n            result = new $.Deferred();\n\n        // broadcast if there are no specific clients\n        clients = clients || getConnectionIds();\n        msg.id = id;\n        _responseDeferreds[id] = result;\n        _transport.send(clients, JSON.stringify(msg));\n        return result.promise();\n    }", "language": "javascript"}
{"input": "Check Images", "output": "function checkImages() {\n    this.log('\\nChecking Docker images in applications directories...');\n\n    let imagePath = '';\n    let runCommand = '';\n    this.warning = false;\n    this.warningMessage = 'To generate the missing Docker image(s), please run:\\n';\n    this.appsFolders.forEach((appsFolder, index) => {\n        const appConfig = this.appConfigs[index];\n        if (appConfig.buildTool === 'maven') {\n            imagePath = this.destinationPath(`${this.directoryPath + appsFolder}/target/jib-cache`);\n            runCommand = './mvnw -Pprod verify jib:dockerBuild';\n        } else {\n            imagePath = this.destinationPath(`${this.directoryPath + appsFolder}/build/jib-cache`);\n            runCommand = './gradlew bootJar -Pprod jibDockerBuild';\n        }\n        if (shelljs.ls(imagePath).length === 0) {\n            this.warning = true;\n            this.warningMessage += `  ${chalk.cyan(runCommand)} in ${this.destinationPath(this.directoryPath + appsFolder)}\\n`;\n        }\n    });\n}", "language": "javascript"}
{"input": "Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.", "output": "def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False", "language": "python"}
{"input": "/* istanbul ignore next \ndisplay the data\n@param {Object} data Data object to be displayed\n@returns {string} modified string\n@private", "output": "function display(data) {\n    let total = 0;\n    const rows = Object.keys(data)\n        .map(key => {\n            const time = data[key];\n\n            total += time;\n            return [key, time];\n        })\n        .sort((a, b) => b[1] - a[1])\n        .slice(0, 10);\n\n    rows.forEach(row => {\n        row.push(`${(row[1] * 100 / total).toFixed(1)}%`);\n        row[1] = row[1].toFixed(3);\n    });\n\n    rows.unshift(HEADERS);\n\n    const widths = [];\n\n    rows.forEach(row => {\n        const len = row.length;\n\n        for (let i = 0; i < len; i++) {\n            const n = row[i].length;\n\n            if (!widths[i] || n > widths[i]) {\n                widths[i] = n;\n            }\n        }\n    });\n\n    const table = rows.map(row => (\n        row\n            .map((cell, index) => ALIGN[index](cell, widths[index]))\n            .join(\" | \")\n    ));\n\n    table.splice(1, 0, widths.map((width, index) => {\n        const extraAlignment = index !== 0 && index !== widths.length - 1 ? 2 : 1;\n\n        return ALIGN[index](\":\", width + extraAlignment, \"-\");\n    }).join(\"|\"));\n\n    console.log(table.join(\"\\n\")); // eslint-disable-line no-console\n}", "language": "javascript"}
{"input": "Converts byte array observation image into numpy array, re-sizes it,\n        and optionally converts it to grey scale\n        :param gray_scale: Whether to convert the image to grayscale.\n        :param image_bytes: input byte array corresponding to image\n        :return: processed numpy array of observation from environment", "output": "def process_pixels(image_bytes, gray_scale):\n        \"\"\"\n        Converts byte array observation image into numpy array, re-sizes it,\n        and optionally converts it to grey scale\n        :param gray_scale: Whether to convert the image to grayscale.\n        :param image_bytes: input byte array corresponding to image\n        :return: processed numpy array of observation from environment\n        \"\"\"\n        s = bytearray(image_bytes)\n        image = Image.open(io.BytesIO(s))\n        s = np.array(image) / 255.0\n        if gray_scale:\n            s = np.mean(s, axis=2)\n            s = np.reshape(s, [s.shape[0], s.shape[1], 1])\n        return s", "language": "python"}
{"input": "Apply weight noise to vars in var_list.", "output": "def weight_noise(noise_rate, learning_rate, var_list):\n  \"\"\"Apply weight noise to vars in var_list.\"\"\"\n  if not noise_rate:\n    return [tf.no_op()]\n\n  tf.logging.info(\"Applying weight noise scaled by learning rate, \"\n                  \"noise_rate: %0.5f\", noise_rate)\n\n  noise_ops = []\n\n  for v in var_list:\n    with tf.device(v.device):  # pylint: disable=protected-access\n      scale = noise_rate * learning_rate * 0.001\n      if common_layers.should_generate_summaries():\n        tf.summary.scalar(\"weight_noise_scale\", scale)\n      noise = tf.truncated_normal(v.shape) * scale\n      noise_op = v.assign_add(noise)\n      noise_ops.append(noise_op)\n\n  return noise_ops", "language": "python"}
{"input": "Update list of objects to test for intersection.", "output": "function () {\n    var data = this.data;\n    var els;\n\n    // If objects not defined, intersect with everything.\n    els = data.objects\n      ? this.el.sceneEl.querySelectorAll(data.objects)\n      : this.el.sceneEl.querySelectorAll('*');\n    this.objects = this.flattenObject3DMaps(els);\n    this.dirty = false;\n  }", "language": "javascript"}
{"input": "Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.", "output": "def get_transforms(do_flip:bool=True, flip_vert:bool=False, max_rotate:float=10., max_zoom:float=1.1,\n                   max_lighting:float=0.2, max_warp:float=0.2, p_affine:float=0.75,\n                   p_lighting:float=0.75, xtra_tfms:Optional[Collection[Transform]]=None)->Collection[Transform]:\n    \"Utility func to easily create a list of flip, rotate, `zoom`, warp, lighting transforms.\"\n    res = [rand_crop()]\n    if do_flip:    res.append(dihedral_affine() if flip_vert else flip_lr(p=0.5))\n    if max_warp:   res.append(symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine))\n    if max_rotate: res.append(rotate(degrees=(-max_rotate,max_rotate), p=p_affine))\n    if max_zoom>1: res.append(rand_zoom(scale=(1.,max_zoom), p=p_affine))\n    if max_lighting:\n        res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))\n        res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))\n    #       train                   , valid\n    return (res + listify(xtra_tfms), [crop_pad()])", "language": "python"}
{"input": "Runs multipass autofix one pass at a time to find the last good source text before a fatal error occurs\n@param {string} originalText Syntactically valid source code that results in a syntax error or crash when autofixing with `config`\n@param {Object} config The config to lint with\n@returns {string} A possibly-modified version of originalText that results in the same syntax error or crash after only one pass", "output": "function isolateBadAutofixPass(originalText, config) {\n        let lastGoodText = originalText;\n        let currentText = originalText;\n\n        do {\n            let messages;\n\n            try {\n                messages = linter.verify(currentText, config);\n            } catch (err) {\n                return lastGoodText;\n            }\n\n            if (messages.length === 1 && messages[0].fatal) {\n                return lastGoodText;\n            }\n\n            lastGoodText = currentText;\n            currentText = SourceCodeFixer.applyFixes(currentText, messages).output;\n        } while (lastGoodText !== currentText);\n\n        return lastGoodText;\n    }", "language": "javascript"}
{"input": "Resume paused profiling.\n\n    Parameters\n    ----------\n    profile_process : string\n        whether to profile kvstore `server` or `worker`.\n        server can only be profiled when kvstore is of type dist.\n        if this is not passed, defaults to `worker`", "output": "def resume(profile_process='worker'):\n    \"\"\"\n    Resume paused profiling.\n\n    Parameters\n    ----------\n    profile_process : string\n        whether to profile kvstore `server` or `worker`.\n        server can only be profiled when kvstore is of type dist.\n        if this is not passed, defaults to `worker`\n    \"\"\"\n    profile_process2int = {'worker': 0, 'server': 1}\n    check_call(_LIB.MXProcessProfilePause(int(0),\n                                          profile_process2int[profile_process],\n                                          profiler_kvstore_handle))", "language": "python"}
{"input": "Return an RDD created by piping elements to a forked external process.\n\n        >>> sc.parallelize(['1', '2', '', '3']).pipe('cat').collect()\n        [u'1', u'2', u'', u'3']\n\n        :param checkCode: whether or not to check the return value of the shell command.", "output": "def pipe(self, command, env=None, checkCode=False):\n        \"\"\"\n        Return an RDD created by piping elements to a forked external process.\n\n        >>> sc.parallelize(['1', '2', '', '3']).pipe('cat').collect()\n        [u'1', u'2', u'', u'3']\n\n        :param checkCode: whether or not to check the return value of the shell command.\n        \"\"\"\n        if env is None:\n            env = dict()\n\n        def func(iterator):\n            pipe = Popen(\n                shlex.split(command), env=env, stdin=PIPE, stdout=PIPE)\n\n            def pipe_objs(out):\n                for obj in iterator:\n                    s = unicode(obj).rstrip('\\n') + '\\n'\n                    out.write(s.encode('utf-8'))\n                out.close()\n            Thread(target=pipe_objs, args=[pipe.stdin]).start()\n\n            def check_return_code():\n                pipe.wait()\n                if checkCode and pipe.returncode:\n                    raise Exception(\"Pipe function `%s' exited \"\n                                    \"with error code %d\" % (command, pipe.returncode))\n                else:\n                    for i in range(0):\n                        yield i\n            return (x.rstrip(b'\\n').decode('utf-8') for x in\n                    chain(iter(pipe.stdout.readline, b''), check_return_code()))\n        return self.mapPartitions(func)", "language": "python"}
{"input": "attempt to coerce any object types to better types return a copy of\n        the block (if copy = True) by definition we ARE an ObjectBlock!!!!!\n\n        can return multiple blocks!", "output": "def convert(self, *args, **kwargs):\n        \"\"\" attempt to coerce any object types to better types return a copy of\n        the block (if copy = True) by definition we ARE an ObjectBlock!!!!!\n\n        can return multiple blocks!\n        \"\"\"\n\n        if args:\n            raise NotImplementedError\n        by_item = kwargs.get('by_item', True)\n\n        new_inputs = ['coerce', 'datetime', 'numeric', 'timedelta']\n        new_style = False\n        for kw in new_inputs:\n            new_style |= kw in kwargs\n\n        if new_style:\n            fn = soft_convert_objects\n            fn_inputs = new_inputs\n        else:\n            fn = maybe_convert_objects\n            fn_inputs = ['convert_dates', 'convert_numeric',\n                         'convert_timedeltas']\n        fn_inputs += ['copy']\n\n        fn_kwargs = {key: kwargs[key] for key in fn_inputs if key in kwargs}\n\n        # operate column-by-column\n        def f(m, v, i):\n            shape = v.shape\n            values = fn(v.ravel(), **fn_kwargs)\n            try:\n                values = values.reshape(shape)\n                values = _block_shape(values, ndim=self.ndim)\n            except (AttributeError, NotImplementedError):\n                pass\n\n            return values\n\n        if by_item and not self._is_single_block:\n            blocks = self.split_and_operate(None, f, False)\n        else:\n            values = f(None, self.values.ravel(), None)\n            blocks = [make_block(values, ndim=self.ndim,\n                                 placement=self.mgr_locs)]\n\n        return blocks", "language": "python"}
{"input": "List default first if it exists", "output": "def list_available(cls) -> List[str]:\n        \"\"\"List default first if it exists\"\"\"\n        keys = list(Registrable._registry[cls].keys())\n        default = cls.default_implementation\n\n        if default is None:\n            return keys\n        elif default not in keys:\n            message = \"Default implementation %s is not registered\" % default\n            raise ConfigurationError(message)\n        else:\n            return [default] + [k for k in keys if k != default]", "language": "python"}
{"input": "Clamps the repositioning of the menu within the confines of\nbounding element (often the screen/body)", "output": "function clamp(pos) {\n        pos.top = Math.max(Math.min(pos.top, bounds.bottom - containerNode.offsetHeight), bounds.top);\n        pos.left = Math.max(Math.min(pos.left, bounds.right - containerNode.offsetWidth), bounds.left);\n      }", "language": "javascript"}
{"input": "Copies attributes from a source element to the destination element\nBy default the function will copy the most necessary attributes, supported\nby the button executor for clickable list items.\n@param source Element with the specified attributes\n@param destination Element which will retrieve the attributes\n@param extraAttrs Additional attributes, which will be copied over.", "output": "function copyAttributes(source, destination, extraAttrs) {\n        var copiedAttrs = $mdUtil.prefixer([\n          'ng-if', 'ng-click', 'ng-dblclick', 'aria-label', 'ng-disabled', 'ui-sref',\n          'href', 'ng-href', 'rel', 'target', 'ng-attr-ui-sref', 'ui-sref-opts', 'download'\n        ]);\n\n        if (extraAttrs) {\n          copiedAttrs = copiedAttrs.concat($mdUtil.prefixer(extraAttrs));\n        }\n\n        angular.forEach(copiedAttrs, function(attr) {\n          if (source.hasAttribute(attr)) {\n            destination.setAttribute(attr, source.getAttribute(attr));\n            source.removeAttribute(attr);\n          }\n        });\n      }", "language": "javascript"}
{"input": "Increase count of entity using a geometry.", "output": "function incrementCacheCount (cacheCount, hash) {\n  cacheCount[hash] = cacheCount[hash] === undefined ? 1 : cacheCount[hash] + 1;\n}", "language": "javascript"}
{"input": "Auxiliary function for :meth:`str.cat`\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep", "output": "def cat_core(list_of_columns, sep):\n    \"\"\"\n    Auxiliary function for :meth:`str.cat`\n\n    Parameters\n    ----------\n    list_of_columns : list of numpy arrays\n        List of arrays to be concatenated with sep;\n        these arrays may not contain NaNs!\n    sep : string\n        The separator string for concatenating the columns\n\n    Returns\n    -------\n    nd.array\n        The concatenation of list_of_columns with sep\n    \"\"\"\n    list_with_sep = [sep] * (2 * len(list_of_columns) - 1)\n    list_with_sep[::2] = list_of_columns\n    return np.sum(list_with_sep, axis=0)", "language": "python"}
{"input": "We likely want to take the cross-product", "output": "def maybe_convert_ix(*args):\n    \"\"\"\n    We likely want to take the cross-product\n    \"\"\"\n\n    ixify = True\n    for arg in args:\n        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n            ixify = False\n\n    if ixify:\n        return np.ix_(*args)\n    else:\n        return args", "language": "python"}
{"input": "Returns control variant technical parameter for the passed component.\n\n@param  {object} oComponent - Component instance used to get the technical parameters\n@returns {string|undefined} Returns the control variant technical parameter", "output": "function(oComponent) {\n\t\t\tvar aTechnicalParameters = flUtils.getTechnicalParametersForComponent(oComponent);\n\t\t\treturn aTechnicalParameters\n\t\t\t\t&& aTechnicalParameters[VariantUtil.variantTechnicalParameterName]\n\t\t\t\t&& Array.isArray(aTechnicalParameters[VariantUtil.variantTechnicalParameterName])\n\t\t\t\t&& aTechnicalParameters[VariantUtil.variantTechnicalParameterName][0];\n\t\t}", "language": "javascript"}
{"input": "Checks whether the position settings fits to the set height/width attribute of a control.\n\n@private", "output": "function(oPositionContainer, oControl, sProp, sPos1, sVal1, sPos2, sVal2) {\n\t\tif (sVal1 && sVal2) {\n\t\t\tvar oLayout = oPositionContainer.getParent();\n\t\t\tvar oProp = getPropertyInfo(oControl, sProp);\n\t\t\tif (oProp) {\n\t\t\t\tvar val = oControl[oProp._sGetter]();\n\t\t\t\tif (!(!val || val == \"\" || val == \"auto\" || val == \"inherit\")) {\n\t\t\t\t\tLog.warning(\"Position \" + sPos2 + \"=\" + sVal2 + \" ignored, because child control \" + oControl.getId() + \" has fixed \" + sProp + \" (\" + val + \").\",\n\t\t\t\t\t\t\t\"\", \"AbsoluteLayout '\" + (oLayout ? oLayout.getId() : \"_undefined\") + \"'\");\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif ((sProp === \"width\" && !oPositionContainer._disableWidthCheck) || (sProp === \"height\" && !oPositionContainer._disableHeightCheck)) {\n\t\t\t\t\tLog.warning(\"Position \" + sPos2 + \"=\" + sVal2 + \" ignored, because child control \" + oControl.getId() + \" not resizable.\",\n\t\t\t\t\t\t\t\"\", \"AbsoluteLayout '\" + (oLayout ? oLayout.getId() : \"_undefined\") + \"'\");\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "language": "javascript"}
{"input": "Expect the next token to match the specified punctuator. If not, an exception will be thrown.", "output": "function expect(value) {\n        var token = lex();\n        if (token.type !== Token.Punctuator || token.value !== value) {\n            throwUnexpected(token);\n        }\n    }", "language": "javascript"}
{"input": "Loss telling to be more similar to your own targets than to others.", "output": "def similarity_cost(inputs_encoded, targets_encoded):\n  \"\"\"Loss telling to be more similar to your own targets than to others.\"\"\"\n  # This is a first very simple version: handle variable-length by padding\n  # to same length and putting everything into batch. In need of a better way.\n  x, y = common_layers.pad_to_same_length(inputs_encoded, targets_encoded)\n  depth = tf.shape(inputs_encoded)[3]\n  x, y = tf.reshape(x, [-1, depth]), tf.reshape(y, [-1, depth])\n  return rank_loss(x, y)", "language": "python"}
{"input": "Recursive function, calls the original callback() when the directory is entirely parsed. @param {function} callback - called with ([ all files and directories in that directoryReader ])", "output": "function readEntries (directoryReader, oldEntries, callback) {\n  directoryReader.readEntries(\n    (entries) => {\n      const newEntries = [...oldEntries, ...entries]\n      // According to the FileSystem API spec, readEntries() must be called until it calls the callback with an empty array.\n      if (entries.length) {\n        setTimeout(() => {\n          readEntries(directoryReader, newEntries, callback)\n        }, 0)\n      // Done iterating this particular directory\n      } else {\n        callback(newEntries)\n      }\n    },\n    // Make sure we resolve on error anyway\n    () =>\n      callback(oldEntries)\n  )\n}", "language": "javascript"}
{"input": "ext-if() evaluates and returns its second argument, if the boolean value of its first argument is true, otherwise it evaluates and returns its third argument.", "output": "function(ctx) {\n    assert(this.args.length == 3);\n    if (this.args[0].evaluate(ctx).booleanValue()) {\n      return this.args[1].evaluate(ctx);\n    } else {\n      return this.args[2].evaluate(ctx);\n    }\n  }", "language": "javascript"}
{"input": "Utility function for processing arguments that are singletons or lists.\n\n    Args:\n      x: either a list of self.n elements, or not a list.\n\n    Returns:\n      a list of self.n elements.", "output": "def _maybe_repeat(self, x):\n    \"\"\"Utility function for processing arguments that are singletons or lists.\n\n    Args:\n      x: either a list of self.n elements, or not a list.\n\n    Returns:\n      a list of self.n elements.\n    \"\"\"\n    if isinstance(x, list):\n      assert len(x) == self.n\n      return x\n    else:\n      return [x] * self.n", "language": "python"}
{"input": "tries to fill all control properties with string values (hoping this might trigger more leaks)", "output": "function(oControl) {\n\t\tvar mProperties = oControl.getMetadata().getAllProperties();\n\n\t\tfor (var sPropertyName in mProperties) {\n\t\t\tif (oControl.isPropertyInitial(sPropertyName)) { // if no value has been set yet by the control factory\n\t\t\t\tvar oProperty = mProperties[sPropertyName];\n\t\t\t\ttry {\n\t\t\t\t\toControl[oProperty._sMutator](\"dummyValueForMemLeakTest\"); // just try a string for everything now, TODO: check type\n\t\t\t\t} catch (e) {\n\t\t\t\t\t// type check error, ignore (we stupidly always try with a string, even if the property has a different type)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (!oControl.getTooltip()) {\n\t\t\toControl.setTooltip(\"test\"); // seems not to be a property...\n\t\t}\n\t}", "language": "javascript"}
{"input": "Create geometry using component data.\n\n@param {object} data - Component data.\n@returns {object} Geometry.", "output": "function createGeometry (data) {\n  var geometryType = data.primitive;\n  var GeometryClass = geometries[geometryType] && geometries[geometryType].Geometry;\n  var geometryInstance = new GeometryClass();\n\n  if (!GeometryClass) { throw new Error('Unknown geometry `' + geometryType + '`'); }\n\n  geometryInstance.init(data);\n  return toBufferGeometry(geometryInstance.geometry, data.buffer);\n}", "language": "javascript"}
{"input": "Destroys an editor object if a document is no longer referenced\n@param {!Document} doc - document to destroy", "output": "function _destroyEditorIfNotNeeded(document) {\n        if (!(document instanceof DocumentManager.Document)) {\n            throw new Error(\"_destroyEditorIfUnneeded() should be passed a Document\");\n        }\n        if (document._masterEditor) {\n            // findPaneForDocument tries to locate the pane in which the document\n            //  is either opened or will be opened (in the event that the document is\n            //  in a working set but has yet to be opened) and then asks the pane\n            //  to destroy the view if it doesn't need it anymore\n            var pane = _findPaneForDocument(document);\n\n            if (pane) {\n                // let the pane deceide if it wants to destroy the view if it's no needed\n                pane.destroyViewIfNotNeeded(document._masterEditor);\n            } else {\n                // in this case, the document isn't referenced at all so just destroy it\n                document._masterEditor.destroy();\n            }\n        }\n    }", "language": "javascript"}
{"input": "Returns a function creating a simulated env, in or out of graph.\n\n  Args:\n    **env_kwargs: kwargs to pass to the simulated env constructor.\n\n  Returns:\n    Function in_graph -> env.", "output": "def make_simulated_env_fn(**env_kwargs):\n  \"\"\"Returns a function creating a simulated env, in or out of graph.\n\n  Args:\n    **env_kwargs: kwargs to pass to the simulated env constructor.\n\n  Returns:\n    Function in_graph -> env.\n  \"\"\"\n  def env_fn(in_graph):\n    class_ = SimulatedBatchEnv if in_graph else SimulatedBatchGymEnv\n    return class_(**env_kwargs)\n  return env_fn", "language": "python"}
{"input": "Compute the gradients of outputs w.r.t variables.\n\n    Parameters\n    ----------\n    outputs: list of NDArray\n    out_grads: list of NDArray or None", "output": "def backward(outputs, out_grads=None, retain_graph=False):\n    \"\"\"Compute the gradients of outputs w.r.t variables.\n\n    Parameters\n    ----------\n    outputs: list of NDArray\n    out_grads: list of NDArray or None\n    \"\"\"\n    assert isinstance(outputs, (list, tuple)), \\\n        \"outputs must be a list or tuple of NDArrays\"\n\n    if out_grads is None:\n        check_call(_LIB.MXAutogradBackward(\n            len(outputs),\n            c_handle_array(outputs),\n            ctypes.c_void_p(0),\n            ctypes.c_int(retain_graph)))\n        return\n\n    ograd_handles = []\n    for arr in out_grads:\n        if arr is not None:\n            ograd_handles.append(arr.handle)\n        else:\n            ograd_handles.append(NDArrayHandle(0))\n    assert len(ograd_handles) == len(outputs), \\\n        \"outputs and out_grads must have the same length\"\n\n    check_call(_LIB.MXAutogradBackward(\n        len(outputs),\n        c_handle_array(outputs),\n        c_array(NDArrayHandle, ograd_handles),\n        ctypes.c_int(retain_graph)))", "language": "python"}
{"input": "Summernote API\n\n@param {Object|String}\n@return {this}", "output": "function() {\n    const type = $.type(lists.head(arguments));\n    const isExternalAPICalled = type === 'string';\n    const hasInitOptions = type === 'object';\n\n    const options = $.extend({}, $.summernote.options, hasInitOptions ? lists.head(arguments) : {});\n\n    // Update options\n    options.langInfo = $.extend(true, {}, $.summernote.lang['en-US'], $.summernote.lang[options.lang]);\n    options.icons = $.extend(true, {}, $.summernote.options.icons, options.icons);\n    options.tooltip = options.tooltip === 'auto' ? !env.isSupportTouch : options.tooltip;\n\n    this.each((idx, note) => {\n      const $note = $(note);\n      if (!$note.data('summernote')) {\n        const context = new Context($note, options);\n        $note.data('summernote', context);\n        $note.data('summernote').triggerEvent('init', context.layoutInfo);\n      }\n    });\n\n    const $note = this.first();\n    if ($note.length) {\n      const context = $note.data('summernote');\n      if (isExternalAPICalled) {\n        return context.invoke.apply(context, lists.from(arguments));\n      } else if (options.focus) {\n        context.invoke('editor.focus');\n      }\n    }\n\n    return this;\n  }", "language": "javascript"}
{"input": "separate rgb embeddings.", "output": "def imagetransformer_sep_channels():\n  \"\"\"separate rgb embeddings.\"\"\"\n  hparams = imagetransformer_base()\n  hparams.num_heads = 4\n  hparams.attention_key_channels = hparams.attention_value_channels = 0\n  hparams.hidden_size = 256\n  hparams.filter_size = 512\n  hparams.num_hidden_layers = 6\n  return hparams", "language": "python"}
{"input": "Change wysiwyg component managers.\n@param {object} wwComponentManager - componentMananger instance\n@private", "output": "function _changeWysiwygManagers(wwComponentManager) {\n  wwComponentManager.removeManager('table');\n  wwComponentManager.removeManager('tableSelection');\n\n  wwComponentManager.addManager(WwMergedTableManager);\n  wwComponentManager.addManager(WwMergedTableSelectionManager);\n}", "language": "javascript"}
{"input": "Performs the functionality associated with dict.pop(key), along with checking for\n        returned dictionaries, replacing them with Param objects with an updated history.\n\n        If ``key`` is not present in the dictionary, and no default was specified, we raise a\n        ``ConfigurationError``, instead of the typical ``KeyError``.", "output": "def pop(self, key: str, default: Any = DEFAULT) -> Any:\n        \"\"\"\n        Performs the functionality associated with dict.pop(key), along with checking for\n        returned dictionaries, replacing them with Param objects with an updated history.\n\n        If ``key`` is not present in the dictionary, and no default was specified, we raise a\n        ``ConfigurationError``, instead of the typical ``KeyError``.\n        \"\"\"\n        if default is self.DEFAULT:\n            try:\n                value = self.params.pop(key)\n            except KeyError:\n                raise ConfigurationError(\"key \\\"{}\\\" is required at location \\\"{}\\\"\".format(key, self.history))\n        else:\n            value = self.params.pop(key, default)\n        if not isinstance(value, dict):\n            logger.info(self.history + key + \" = \" + str(value))  # type: ignore\n        return self._check_is_dict(key, value)", "language": "python"}
{"input": "Fix the memory of multi-dimensional sliced object.", "output": "def convert_from_sliced_object(data):\n    \"\"\"Fix the memory of multi-dimensional sliced object.\"\"\"\n    if data.base is not None and isinstance(data, np.ndarray) and isinstance(data.base, np.ndarray):\n        if not data.flags.c_contiguous:\n            warnings.warn(\"Usage of np.ndarray subset (sliced data) is not recommended \"\n                          \"due to it will double the peak memory cost in LightGBM.\")\n            return np.copy(data)\n    return data", "language": "python"}
{"input": "Tries to kill the process otherwise just logs a debug message, the\n    process will be killed when thefuck terminates.\n\n    :type proc: Process", "output": "def _kill_process(proc):\n    \"\"\"Tries to kill the process otherwise just logs a debug message, the\n    process will be killed when thefuck terminates.\n\n    :type proc: Process\n\n    \"\"\"\n    try:\n        proc.kill()\n    except AccessDenied:\n        logs.debug(u'Rerun: process PID {} ({}) could not be terminated'.format(\n            proc.pid, proc.exe()))", "language": "python"}
{"input": "/*\ngestureStart vets if a start event is legitimate (and not part of a 'ghost click' from iOS/Android)\nIf it is legitimate, we initiate the pointer state and mark the current pointer's type\nFor example, for a touchstart event, mark the current pointer as a 'touch' pointer, so mouse events\nwon't effect it.", "output": "function gestureStart(ev) {\n    // If we're already touched down, abort\n    if (pointer) return;\n\n    var now = +Date.now();\n\n    // iOS & old android bug: after a touch event, a click event is sent 350 ms later.\n    // If <400ms have passed, don't allow an event of a different type than the previous event\n    if (lastPointer && !typesMatch(ev, lastPointer) && (now - lastPointer.endTime < 1500)) {\n      return;\n    }\n\n    pointer = makeStartPointer(ev);\n\n    runHandlers('start', ev);\n  }", "language": "javascript"}
{"input": "Check if a dependency is eligible to be used by us\n@param {Object} dependency dependency to check\n@returns {boolean} true if we have permission\n@private", "output": "function isPermissible(dependency) {\n        const licenses = dependency.licenses;\n\n        if (Array.isArray(licenses)) {\n            return licenses.some(license => isPermissible({\n                name: dependency.name,\n                licenses: license\n            }));\n        }\n\n        return OPEN_SOURCE_LICENSES.some(license => license.test(licenses));\n    }", "language": "javascript"}
{"input": "Return the slice of `a` corresponding to `idxs`.", "output": "def index_row(a:Union[Collection,pd.DataFrame,pd.Series], idxs:Collection[int])->Any:\n    \"Return the slice of `a` corresponding to `idxs`.\"\n    if a is None: return a\n    if isinstance(a,(pd.DataFrame,pd.Series)):\n        res = a.iloc[idxs]\n        if isinstance(res,(pd.DataFrame,pd.Series)): return res.copy()\n        return res\n    return a[idxs]", "language": "python"}
{"input": "Helper to create a new renderer by extending an existing one.\n\n@this {sap.ui.core.Renderer} The base renderer to extend\n@param {string} sName Global name of the new renderer\n@param {object} oRendererInfo Methods and static properties of the new renderer\n@returns {object} New static renderer class\n@private", "output": "function createExtendedRenderer(sName, oRendererInfo) {\n\n\t\tassert(this != null, 'BaseRenderer must be a non-null object');\n\t\tassert(typeof sName === 'string' && sName, 'Renderer.extend must be called with a non-empty name for the new renderer');\n\t\tassert(oRendererInfo == null ||\n\t\t\t(isPlainObject(oRendererInfo)\n\t\t\t && Object.keys(oRendererInfo).every(function(key) { return oRendererInfo[key] !== undefined; })),\n\t\t\t'oRendererInfo can be omitted or must be a plain object without any undefined property values');\n\n\t\tvar oChildRenderer = Object.create(this);\n\t\t// subclasses should expose the modern signature variant only\n\t\toChildRenderer.extend = createExtendedRenderer;\n\t\tjQuery.extend(oChildRenderer, oRendererInfo);\n\n\t\t// expose the renderer globally\n\t\tObjectPath.set(sName, oChildRenderer);\n\n\t\treturn oChildRenderer;\n\t}", "language": "javascript"}
{"input": "plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path.", "output": "def plot_loss(self, n_skip=10, n_skip_end=5):\n        '''\n        plots loss function as function of iterations. \n        When used in Jupyternotebook, plot will be displayed in notebook. Else, plot will be displayed in console and both plot and loss are saved in save_path. \n        '''\n        if not in_ipynb(): plt.switch_backend('agg')\n        plt.plot(self.iterations[n_skip:-n_skip_end], self.losses[n_skip:-n_skip_end])\n        if not in_ipynb():\n            plt.savefig(os.path.join(self.save_path, 'loss_plot.png'))\n            np.save(os.path.join(self.save_path, 'losses.npy'), self.losses[10:])", "language": "python"}
{"input": "If the specifier is a simple string selector, then query for\nthe DOM element.", "output": "function getDomElement(element, defaultElement) {\n            if (angular.isString(element)) {\n              element = $document[0].querySelector(element);\n            }\n\n            // If we have a reference to a raw dom element, always wrap it in jqLite\n            return angular.element(element || defaultElement);\n          }", "language": "javascript"}
{"input": "Calc crop shape of `target_px` to nearest multiple of `mult`.", "output": "def _get_crop_target(target_px:Union[int,TensorImageSize], mult:int=None)->Tuple[int,int]:\n    \"Calc crop shape of `target_px` to nearest multiple of `mult`.\"\n    target_r,target_c = tis2hw(target_px)\n    return _round_multiple(target_r,mult),_round_multiple(target_c,mult)", "language": "python"}
{"input": "Copies the inherited properties of a UI5 control from the metadata.\n@param {Object} control - UI5 Control.\n@param {Object} inheritedMetadata - UI5 control metadata.\n@returns {Object}\n@private", "output": "function (control, inheritedMetadata) {\n\t\t\t\tvar inheritedMetadataProperties = inheritedMetadata.getProperties();\n\t\t\t\tvar result = Object.create(null);\n\n\t\t\t\tresult.meta = Object.create(null);\n\t\t\t\tresult.meta.controlName = inheritedMetadata.getName();\n\n\t\t\t\tresult.properties = Object.create(null);\n\t\t\t\tObject.keys(inheritedMetadataProperties).forEach(function (key) {\n\t\t\t\t\tresult.properties[key] = Object.create(null);\n\t\t\t\t\tresult.properties[key].value = inheritedMetadataProperties[key].get(control);\n\t\t\t\t\tresult.properties[key].type = inheritedMetadataProperties[key].getType().getName ? inheritedMetadataProperties[key].getType().getName() : '';\n\t\t\t\t});\n\n\t\t\t\treturn result;\n\t\t\t}", "language": "javascript"}
{"input": "Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.", "output": "def _cl_int_plot_top_losses(self, k, largest=True, figsize=(12,12), heatmap:bool=True, heatmap_thresh:int=16,\n                            return_fig:bool=None)->Optional[plt.Figure]:\n    \"Show images in `top_losses` along with their prediction, actual, loss, and probability of actual class.\"\n    tl_val,tl_idx = self.top_losses(k, largest)\n    classes = self.data.classes\n    cols = math.ceil(math.sqrt(k))\n    rows = math.ceil(k/cols)\n    fig,axes = plt.subplots(rows, cols, figsize=figsize)\n    fig.suptitle('prediction/actual/loss/probability', weight='bold', size=14)\n    for i,idx in enumerate(tl_idx):\n        im,cl = self.data.dl(self.ds_type).dataset[idx]\n        cl = int(cl)\n        im.show(ax=axes.flat[i], title=\n            f'{classes[self.pred_class[idx]]}/{classes[cl]} / {self.losses[idx]:.2f} / {self.probs[idx][cl]:.2f}')\n        if heatmap:\n            xb,_ = self.data.one_item(im, detach=False, denorm=False)\n            m = self.learn.model.eval()\n            with hook_output(m[0]) as hook_a:\n                with hook_output(m[0], grad= True) as hook_g:\n                    preds = m(xb)\n                    preds[0,cl].backward()\n            acts = hook_a.stored[0].cpu()\n            if (acts.shape[-1]*acts.shape[-2]) >= heatmap_thresh:\n                grad = hook_g.stored[0][0].cpu()\n                grad_chan = grad.mean(1).mean(1)\n                mult = F.relu(((acts*grad_chan[...,None,None])).sum(0))\n                sz = list(im.shape[-2:])\n                axes.flat[i].imshow(mult, alpha=0.6, extent=(0,*sz[::-1],0), interpolation='bilinear', cmap='magma')                \n    if ifnone(return_fig, defaults.return_fig): return fig", "language": "python"}
{"input": "Sends a command to node to cause a restart.", "output": "function restartNode() {\n        try {\n            _nodeConnection.domains.base.restartNode();\n        } catch (e) {\n            window.alert(\"Failed trying to restart Node: \" + e.message);\n        }\n    }", "language": "javascript"}
{"input": "Returns a random integer between min (included) and max (excluded)", "output": "def get_random_int(minimum, maximum):\n    \"\"\"\n    Returns a random integer between min (included) and max (excluded)\n    \"\"\"\n    min_int = math.ceil(minimum)\n    max_int = math.floor(maximum)\n\n    return random.randint(min_int, max_int - 1)", "language": "python"}
{"input": "Public API for generating a URL pathname from a path and parameters.", "output": "function generatePath(path = \"/\", params = {}) {\n  return path === \"/\" ? path : compilePath(path)(params, { pretty: true });\n}", "language": "javascript"}
{"input": "Mix properties into target object.", "output": "function extend$1 (to, _from) {\n  for (var key in _from) {\n    to[key] = _from[key];\n  }\n  return to\n}", "language": "javascript"}
{"input": "Given the module object passed to JS module define function,\nconvert the path to a native absolute path.\nReturns a native absolute path to the module folder.\n\nWARNING: unlike most paths in Brackets, this path EXCLUDES the trailing \"/\".\n@return {string}", "output": "function getNativeModuleDirectoryPath(module) {\n        var path;\n\n        if (module && module.uri) {\n            path = decodeURI(module.uri);\n\n            // Remove module name and trailing slash from path.\n            path = path.substr(0, path.lastIndexOf(\"/\"));\n        }\n        return path;\n    }", "language": "javascript"}
{"input": "Generates Python code for a shared param class.\n\n    :param name: param name\n    :param doc: param doc\n    :param defaultValueStr: string representation of the default value\n    :return: code string", "output": "def _gen_param_code(name, doc, defaultValueStr):\n    \"\"\"\n    Generates Python code for a shared param class.\n\n    :param name: param name\n    :param doc: param doc\n    :param defaultValueStr: string representation of the default value\n    :return: code string\n    \"\"\"\n    # TODO: How to correctly inherit instance attributes?\n    template = '''\n    def set$Name(self, value):\n        \"\"\"\n        Sets the value of :py:attr:`$name`.\n        \"\"\"\n        return self._set($name=value)\n\n    def get$Name(self):\n        \"\"\"\n        Gets the value of $name or its default value.\n        \"\"\"\n        return self.getOrDefault(self.$name)'''\n\n    Name = name[0].upper() + name[1:]\n    return template \\\n        .replace(\"$name\", name) \\\n        .replace(\"$Name\", Name) \\\n        .replace(\"$doc\", doc) \\\n        .replace(\"$defaultValueStr\", str(defaultValueStr))", "language": "python"}
{"input": "/* [MS-XLS] 2.4.122 TODO", "output": "function parse_Font(blob, length, opts) {\n\tvar o = {\n\t\tdyHeight: blob.read_shift(2),\n\t\tfl: blob.read_shift(2)\n\t};\n\tswitch((opts && opts.biff) || 8) {\n\t\tcase 2: break;\n\t\tcase 3: case 4: blob.l += 2; break;\n\t\tdefault: blob.l += 10; break;\n\t}\n\to.name = parse_ShortXLUnicodeString(blob, 0, opts);\n\treturn o;\n}", "language": "javascript"}
{"input": "Get the function type for the given offset\n\n@param {{type: string, name: string, offsetLines: number, text: string}} fileInfo\n- type of update, name of file, and the text of the update.\nFor \"full\" updates, the whole text of the file is present. For \"part\" updates,\nthe changed portion of the text. For \"empty\" updates, the file has not been modified\nand the text is empty.\n@param {{line: number, ch: number}} offset -\nthe offset into the file where we want completions for", "output": "function handleFunctionType(fileInfo, offset) {\n    var request = buildRequest(fileInfo, \"type\", offset),\n        error;\n\n    request.query.preferFunction = true;\n\n    var fnType = \"\";\n    try {\n        ternServer.request(request, function (ternError, data) {\n\n            if (ternError) {\n                _log(\"Error for Tern request: \\n\" + JSON.stringify(request) + \"\\n\" + ternError);\n                error = ternError.toString();\n            } else {\n                var file = ternServer.findFile(fileInfo.name);\n\n                // convert query from partial to full offsets\n                var newOffset = offset;\n                if (fileInfo.type === MessageIds.TERN_FILE_INFO_TYPE_PART) {\n                    newOffset = {line: offset.line + fileInfo.offsetLines, ch: offset.ch};\n                }\n\n                request = buildRequest(createEmptyUpdate(fileInfo.name), \"type\", newOffset);\n\n                var expr = Tern.findQueryExpr(file, request.query);\n                Infer.resetGuessing();\n                var type = Infer.expressionType(expr);\n                type = type.getFunctionType() || type.getType();\n\n                if (type) {\n                    fnType = getParameters(type);\n                } else {\n                    ternError = \"No parameter type found\";\n                    _log(ternError);\n                }\n            }\n        });\n    } catch (e) {\n        _reportError(e, fileInfo.name);\n    }\n\n    // Post a message back to the main thread with the completions\n    self.postMessage({type: MessageIds.TERN_CALLED_FUNC_TYPE_MSG,\n        file: _getNormalizedFilename(fileInfo.name),\n        offset: offset,\n        fnType: fnType,\n        error: error\n        });\n}", "language": "javascript"}
{"input": "Identify the bounding RECT for the target element", "output": "function getBoundingClientRect (element, orig) {\n            var source = angular.element((element || {}));\n            if (source && source.length) {\n              // Compute and save the target element's bounding rect, so that if the\n              // element is hidden when the dialog closes, we can shrink the dialog\n              // back to the same position it expanded from.\n              //\n              // Checking if the source is a rect object or a DOM element\n              var bounds = {top:0,left:0,height:0,width:0};\n              var hasFn = angular.isFunction(source[0].getBoundingClientRect);\n\n              return angular.extend(orig || {}, {\n                  element : hasFn ? source : undefined,\n                  bounds  : hasFn ? source[0].getBoundingClientRect() : angular.extend({}, bounds, source[0]),\n                  focus   : angular.bind(source, source.focus),\n              });\n            }\n          }", "language": "javascript"}
{"input": "Checks if browser notification is permitted by user.\n\n@private\n@see {@link https://developer.mozilla.org/en-US/docs/Web/API/Notification/permission|Notification.permission}\n@see {@link Mocha#growl}\n@see {@link Mocha#isGrowlPermitted}\n@returns {Promise<boolean>} promise determining if browser notification\npermissible when fulfilled.", "output": "function isPermitted() {\n  var permitted = {\n    granted: function allow() {\n      return Promise.resolve(true);\n    },\n    denied: function deny() {\n      return Promise.resolve(false);\n    },\n    default: function ask() {\n      return Notification.requestPermission().then(function(permission) {\n        return permission === 'granted';\n      });\n    }\n  };\n\n  return permitted[Notification.permission]();\n}", "language": "javascript"}
{"input": "\u95f4\u9694\u6298\u53e0\u8282\u70b9\uff0c\u5f53\u8282\u70b9\u8fc7\u591a\u65f6\u53ef\u4ee5\u89e3\u51b3\u8282\u70b9\u663e\u793a\u8fc7\u6742\u95f4\u9694\u3002\r\n\r\n        :param data: \u8282\u70b9\u6570\u636e\r\n        :param interval: \u6307\u5b9a\u95f4\u9694", "output": "def _set_collapse_interval(data, interval):\r\n        \"\"\"\r\n        \u95f4\u9694\u6298\u53e0\u8282\u70b9\uff0c\u5f53\u8282\u70b9\u8fc7\u591a\u65f6\u53ef\u4ee5\u89e3\u51b3\u8282\u70b9\u663e\u793a\u8fc7\u6742\u95f4\u9694\u3002\r\n\r\n        :param data: \u8282\u70b9\u6570\u636e\r\n        :param interval: \u6307\u5b9a\u95f4\u9694\r\n        \"\"\"\r\n        if interval <= 0:\r\n            return data\r\n        if data and isinstance(data, list):\r\n            for d in data:\r\n                children = d.get(\"children\", None)\r\n                if children and interval > 0:\r\n                    for index, value in enumerate(children):\r\n                        if index % interval == 0:\r\n                            value.update(collapsed=\"false\")\r\n            return data", "language": "python"}
{"input": "Disconnect from the remote debugger WebSocket\n@return {jQuery.Promise} Promise that is resolved immediately if not\ncurrently connected or asynchronously when the socket is closed.", "output": "function disconnect() {\n        var deferred = new $.Deferred(),\n            promise = deferred.promise();\n\n        if (_socket && (_socket.readyState === WebSocket.OPEN)) {\n            _socket.onclose = function () {\n                // trigger disconnect event\n                _onDisconnect();\n\n                deferred.resolve();\n            };\n\n            promise = Async.withTimeout(promise, 5000);\n\n            _socket.close();\n        } else {\n            if (_socket) {\n                delete _socket.onmessage;\n                delete _socket.onopen;\n                delete _socket.onclose;\n                delete _socket.onerror;\n\n                _socket = undefined;\n            }\n\n            deferred.resolve();\n        }\n\n        return promise;\n    }", "language": "javascript"}
{"input": "### Format Response\nTakes the no. items returned and original options and calculates all of the pagination meta data\n@param {Number} totalItems\n@param {options} options\n@returns {pagination} pagination metadata", "output": "function formatResponse(totalItems, options) {\n        var calcPages = Math.ceil(totalItems / options.limit) || 0,\n            pagination = {\n                page: options.page || defaults.page,\n                limit: options.limit,\n                pages: calcPages === 0 ? 1 : calcPages,\n                total: totalItems,\n                next: null,\n                prev: null\n            };\n\n        if (pagination.pages > 1) {\n            if (pagination.page === 1) {\n                pagination.next = pagination.page + 1;\n            } else if (pagination.page === pagination.pages) {\n                pagination.prev = pagination.page - 1;\n            } else {\n                pagination.next = pagination.page + 1;\n                pagination.prev = pagination.page - 1;\n            }\n        }\n\n        return pagination;\n    }", "language": "javascript"}
{"input": "Get the unescaped URI to fetch the dimension members, optionally\naugmented by text and attributes.\n\n@param {String}\nsServiceRootURI (optional) Identifies the root of the OData\nservice\n@returns {String} The unescaped URI that contains the OData resource path\nand OData system query options to express the request for the\nparameter value set..\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.DimensionMemberSetRequest#getURIToDimensionMemberEntries", "output": "function(sServiceRootURI) {\n\n\t\t\t// construct resource path\n\t\t\tvar sResourcePath = this.getURIToDimensionMemberEntitySet(sServiceRootURI);\n\n\t\t\t// check if request is compliant with filter constraints expressed in\n\t\t\t// metadata\n\t\t\tthis.getFilterExpression().checkValidity();\n\n\t\t\t// construct query options\n\t\t\tvar sSelectOption = this.getURIQueryOptionValue(\"$select\");\n\t\t\tvar sFilterOption = this.getURIQueryOptionValue(\"$filter\");\n\t\t\tvar sSortOption = this.getURIQueryOptionValue(\"$orderby\");\n\t\t\tvar sTopOption = this.getURIQueryOptionValue(\"$top\");\n\t\t\tvar sSkipOption = this.getURIQueryOptionValue(\"$skip\");\n\t\t\tvar sInlineCountOption = this.getURIQueryOptionValue(\"$inlinecount\");\n\n\t\t\tvar sURI = sResourcePath;\n\t\t\tvar bQuestionmark = false;\n\n\t\t\tif (sSelectOption) {\n\t\t\t\tsURI += \"?$select=\" + sSelectOption;\n\t\t\t\tbQuestionmark = true;\n\t\t\t}\n\t\t\tif (this._oFilterExpression && sFilterOption) {\n\t\t\t\tif (!bQuestionmark) {\n\t\t\t\t\tsURI += \"?\";\n\t\t\t\t\tbQuestionmark = true;\n\t\t\t\t} else {\n\t\t\t\t\tsURI += \"&\";\n\t\t\t\t}\n\t\t\t\tsURI += \"$filter=\" + sFilterOption;\n\t\t\t}\n\t\t\tif (this._oSortExpression && sSortOption) {\n\t\t\t\tif (!bQuestionmark) {\n\t\t\t\t\tsURI += \"?\";\n\t\t\t\t\tbQuestionmark = true;\n\t\t\t\t} else {\n\t\t\t\t\tsURI += \"&\";\n\t\t\t\t}\n\t\t\t\tsURI += \"$orderby=\" + sSortOption;\n\t\t\t}\n\t\t\tif (this._iTopRequestOption && sTopOption) {\n\t\t\t\tif (!bQuestionmark) {\n\t\t\t\t\tsURI += \"?\";\n\t\t\t\t\tbQuestionmark = true;\n\t\t\t\t} else {\n\t\t\t\t\tsURI += \"&\";\n\t\t\t\t}\n\t\t\t\tsURI += \"$top=\" + sTopOption;\n\t\t\t}\n\t\t\tif (this._iSkipRequestOption && sSkipOption) {\n\t\t\t\tif (!bQuestionmark) {\n\t\t\t\t\tsURI += \"?\";\n\t\t\t\t\tbQuestionmark = true;\n\t\t\t\t} else {\n\t\t\t\t\tsURI += \"&\";\n\t\t\t\t}\n\t\t\t\tsURI += \"$skip=\" + sSkipOption;\n\t\t\t}\n\t\t\tif (this._bIncludeCount && sInlineCountOption) {\n\t\t\t\tif (!bQuestionmark) {\n\t\t\t\t\tsURI += \"?\";\n\t\t\t\t\tbQuestionmark = true;\n\t\t\t\t} else {\n\t\t\t\t\tsURI += \"&\";\n\t\t\t\t}\n\t\t\t\tsURI += \"$inlinecount=\" + sInlineCountOption;\n\t\t\t}\n\t\t\treturn sURI;\n\t\t}", "language": "javascript"}
{"input": "Create a new :class:`Context` for this template.  The vars\n        provided will be passed to the template.  Per default the globals\n        are added to the context.  If shared is set to `True` the data\n        is passed as it to the context without adding the globals.\n\n        `locals` can be a dict of local variables for internal usage.", "output": "def new_context(self, vars=None, shared=False, locals=None):\n        \"\"\"Create a new :class:`Context` for this template.  The vars\n        provided will be passed to the template.  Per default the globals\n        are added to the context.  If shared is set to `True` the data\n        is passed as it to the context without adding the globals.\n\n        `locals` can be a dict of local variables for internal usage.\n        \"\"\"\n        return new_context(self.environment, self.name, self.blocks,\n                           vars, shared, self.globals, locals)", "language": "python"}
{"input": "Appends the buffer of an agent to the update buffer.\n        :param agent_id: The id of the agent which data will be appended\n        :param key_list: The fields that must be added. If None: all fields will be appended.\n        :param batch_size: The number of elements that must be appended. If None: All of them will be.\n        :param training_length: The length of the samples that must be appended. If None: only takes one element.", "output": "def append_update_buffer(self, agent_id, key_list=None, batch_size=None, training_length=None):\n        \"\"\"\n        Appends the buffer of an agent to the update buffer.\n        :param agent_id: The id of the agent which data will be appended\n        :param key_list: The fields that must be added. If None: all fields will be appended.\n        :param batch_size: The number of elements that must be appended. If None: All of them will be.\n        :param training_length: The length of the samples that must be appended. If None: only takes one element.\n        \"\"\"\n        if key_list is None:\n            key_list = self[agent_id].keys()\n        if not self[agent_id].check_length(key_list):\n            raise BufferException(\"The length of the fields {0} for agent {1} where not of same length\"\n                                  .format(key_list, agent_id))\n        for field_key in key_list:\n            self.update_buffer[field_key].extend(\n                self[agent_id][field_key].get_batch(batch_size=batch_size, training_length=training_length)\n            )", "language": "python"}
{"input": "Returns the set of objects in the same boxes that are below the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        below the first object in the first box, and those below the second object in the second box.", "output": "def below(self, objects: Set[Object]) -> Set[Object]:\n        \"\"\"\n        Returns the set of objects in the same boxes that are below the given objects. That is, if\n        the input is a set of two objects, one in each box, we will return a union of the objects\n        below the first object in the first box, and those below the second object in the second box.\n        \"\"\"\n        objects_per_box = self._separate_objects_by_boxes(objects)\n        return_set = set()\n        for box in objects_per_box:\n            # max_y_loc corresponds to the bottom-most object.\n            max_y_loc = max([obj.y_loc for obj in objects_per_box[box]])\n            for candidate_obj in box.objects:\n                if candidate_obj.y_loc > max_y_loc:\n                    return_set.add(candidate_obj)\n        return return_set", "language": "python"}
{"input": "Checkpoints the model and erases old checkpoints\n            if needed.\n        Parameters\n        ----------\n            trial : trial to save", "output": "def _checkpoint_and_erase(self, trial):\n        \"\"\"Checkpoints the model and erases old checkpoints\n            if needed.\n        Parameters\n        ----------\n            trial : trial to save\n        \"\"\"\n\n        with warn_if_slow(\"save_to_disk\"):\n            trial._checkpoint.value = ray.get(trial.runner.save.remote())\n\n        if len(trial.history) >= trial.keep_checkpoints_num:\n            ray.get(trial.runner.delete_checkpoint.remote(trial.history[-1]))\n            trial.history.pop()\n\n        trial.history.insert(0, trial._checkpoint.value)", "language": "python"}
{"input": "Making sure x is a multiple of shape.\n\n  Args:\n    x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor\n    block_shape: a 2-d list of integer shapes\n\n  Returns:\n    padded_x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor", "output": "def pad_to_multiple_2d(x, block_shape):\n  \"\"\"Making sure x is a multiple of shape.\n\n  Args:\n    x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor\n    block_shape: a 2-d list of integer shapes\n\n  Returns:\n    padded_x: a [batch, heads, h, w, depth] or [batch, h, w, depth] tensor\n  \"\"\"\n  old_shape = x.get_shape().dims\n  last = old_shape[-1]\n  if len(old_shape) == 4:\n    height_padding = -common_layers.shape_list(x)[1] % block_shape[0]\n    width_padding = -common_layers.shape_list(x)[2] % block_shape[1]\n    paddings = [[0, 0], [0, height_padding], [0, width_padding], [0, 0]]\n  elif len(old_shape) == 5:\n    height_padding = -common_layers.shape_list(x)[2] % block_shape[0]\n    width_padding = -common_layers.shape_list(x)[3] % block_shape[1]\n    paddings = [[0, 0], [0, 0], [0, height_padding], [0, width_padding], [0, 0]]\n\n  padded_x = tf.pad(x, paddings)\n  padded_shape = padded_x.get_shape().as_list()\n  padded_shape = padded_shape[:-1] + [last]\n  padded_x.set_shape(padded_shape)\n  return padded_x", "language": "python"}
{"input": "Checks if the control id is generated or maintained by the application.\n\n@param {sap.ui.core.Control|string} vControl - Control instance or ID\n@param {sap.ui.core.Component} oAppComponent - oAppComponent application component, needed only if vControl is a string (ID)\n@param {boolean} [bSuppressLogging] bSuppressLogging - Flag to suppress the warning in the console\n@returns {boolean} <code>true</code> if the ID is maintained by the application\n@protected", "output": "function (vControl, oAppComponent, bSuppressLogging) {\n\n\t\t\tvar sControlId = vControl instanceof ManagedObject ? vControl.getId() : vControl;\n\t\t\tvar bIsGenerated = ManagedObjectMetadata.isGeneratedId(sControlId);\n\n\t\t\tif (!bIsGenerated || this.hasLocalIdSuffix(vControl, oAppComponent)) {\n\t\t\t\treturn true;\n\t\t\t} else {\n\n\t\t\t\tvar sHasConcatenatedId = sControlId.indexOf(\"--\") !== -1;\n\t\t\t\tif (!bSuppressLogging && !sHasConcatenatedId) {\n\t\t\t\t\tLog.warning(\"Control ID was generated dynamically by SAPUI5. To support SAPUI5 flexibility, a stable control ID is needed to assign the changes to.\", sControlId);\n\t\t\t\t}\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Compute count of group, excluding missing values", "output": "def count(self):\n        \"\"\" Compute count of group, excluding missing values \"\"\"\n        ids, _, ngroups = self.grouper.group_info\n        val = self.obj.get_values()\n\n        mask = (ids != -1) & ~isna(val)\n        ids = ensure_platform_int(ids)\n        minlength = ngroups or 0\n        out = np.bincount(ids[mask], minlength=minlength)\n\n        return Series(out,\n                      index=self.grouper.result_index,\n                      name=self._selection_name,\n                      dtype='int64')", "language": "python"}
{"input": "Handler if a route was matched;\nChecks if the matched route is current route and then requests content from Layered Repository.\n@param {Object} oRouteMatch - route object specified in the router which was matched via regexp\n@private", "output": "function (oRouteMatch) {\n\t\t\tvar that = this;\n\t\t\tvar mRouteArguments = oRouteMatch.getParameter(\"arguments\");\n\t\t\tthis.sLayer = mRouteArguments.layer;\n\t\t\tthis.sNamespace = mRouteArguments.namespace || \"\";\n\t\t\tvar oPage = this.getView().getContent()[0];\n\t\t\toPage.setBusy(true);\n\t\t\tthat.sNamespace = decodeURIComponent(that.sNamespace);\n\t\t\toPage.setTitle(this._shortenNamespace());\n\n\t\t\tLRepConnector.getContent(that.sLayer, that.sNamespace).then(\n\t\t\t\tthat._onContentReceived.bind(that, oPage),\n\t\t\t\tfunction(){\n\t\t\t\t\toPage.setBusy(false);\n\t\t\t\t}).then(function () {\n\t\t\t\t\tLRepConnector.requestPending = false;\n\t\t\t\t});\n\t\t}", "language": "javascript"}
{"input": "Flattens the input array into a 2-D array by collapsing the higher dimensions.", "output": "def flatten(attrs, inputs, proto_obj):\n    \"\"\"Flattens the input array into a 2-D array by collapsing the higher dimensions.\"\"\"\n    #Mxnet does not have axis support. By default uses axis=1\n    if 'axis' in attrs and attrs['axis'] != 1:\n        raise RuntimeError(\"Flatten operator only supports axis=1\")\n    new_attrs = translation_utils._remove_attributes(attrs, ['axis'])\n    return 'Flatten', new_attrs, inputs", "language": "python"}
{"input": "Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.", "output": "def res_block(nf, dense:bool=False, norm_type:Optional[NormType]=NormType.Batch, bottle:bool=False, **conv_kwargs):\n    \"Resnet block of `nf` features. `conv_kwargs` are passed to `conv_layer`.\"\n    norm2 = norm_type\n    if not dense and (norm_type==NormType.Batch): norm2 = NormType.BatchZero\n    nf_inner = nf//2 if bottle else nf\n    return SequentialEx(conv_layer(nf, nf_inner, norm_type=norm_type, **conv_kwargs),\n                      conv_layer(nf_inner, nf, norm_type=norm2, **conv_kwargs),\n                      MergeLayer(dense))", "language": "python"}
{"input": "MDContactChips Directive Definition\n\n@param $mdTheming\n@param $mdUtil\n@returns {*}\n@ngInject", "output": "function MdContactChips($mdTheming, $mdUtil) {\n  return {\n    template: function(element, attrs) {\n      return MD_CONTACT_CHIPS_TEMPLATE;\n    },\n    restrict: 'E',\n    controller: 'MdContactChipsCtrl',\n    controllerAs: '$mdContactChipsCtrl',\n    bindToController: true,\n    compile: compile,\n    scope: {\n      contactQuery: '&mdContacts',\n      placeholder: '@?',\n      secondaryPlaceholder: '@?',\n      contactName: '@mdContactName',\n      contactImage: '@mdContactImage',\n      contactEmail: '@mdContactEmail',\n      contacts: '=ngModel',\n      ngChange: '&?',\n      requireMatch: '=?mdRequireMatch',\n      minLength: '=?mdMinLength',\n      highlightFlags: '@?mdHighlightFlags',\n      chipAppendDelay: '@?mdChipAppendDelay',\n      separatorKeys: '=?mdSeparatorKeys',\n      removedMessage: '@?mdRemovedMessage',\n      inputAriaDescribedBy: '@?inputAriaDescribedby',\n      inputAriaLabelledBy: '@?inputAriaLabelledby',\n      inputAriaLabel: '@?',\n      containerHint: '@?',\n      containerEmptyHint: '@?',\n      deleteHint: '@?'\n    }\n  };\n\n  function compile(element, attr) {\n    return function postLink(scope, element, attrs, controllers) {\n      var contactChipsController = controllers;\n\n      $mdUtil.initOptionalProperties(scope, attr);\n      $mdTheming(element);\n\n      element.attr('tabindex', '-1');\n\n      attrs.$observe('mdChipAppendDelay', function(newValue) {\n        contactChipsController.chipAppendDelay = newValue;\n      });\n    };\n  }\n}", "language": "javascript"}
{"input": "Waits until the transistion into or out of the Private Browsing mode happened\n\n@param {boolean} state\nExpected target state of the Private Browsing mode", "output": "function privateBrowsing_waitForTransitionComplete(state) {\n    // We have to wait until the transition has been finished\n    this._controller.waitForEval(\"subject.hasAttribute('disabled') == false\", gTimeout, 100,\n                                 this._pbTransitionItem.getNode());\n    this._controller.waitForEval(\"subject.privateBrowsing.enabled == subject.state\", gTimeout, 100,\n                                 {privateBrowsing: this, state: state});\n  }", "language": "javascript"}
{"input": "Make a tf.train.Example for the problem.\n\n  features[input_feature_name] = input_ids\n\n  Also fills in any other required features with dummy values.\n\n  Args:\n    input_ids: list<int>.\n    problem: Problem.\n    input_feature_name: name of feature for input_ids.\n\n  Returns:\n    tf.train.Example", "output": "def _make_example(input_ids, problem, input_feature_name=\"inputs\"):\n  \"\"\"Make a tf.train.Example for the problem.\n\n  features[input_feature_name] = input_ids\n\n  Also fills in any other required features with dummy values.\n\n  Args:\n    input_ids: list<int>.\n    problem: Problem.\n    input_feature_name: name of feature for input_ids.\n\n  Returns:\n    tf.train.Example\n  \"\"\"\n  features = {\n      input_feature_name:\n          tf.train.Feature(int64_list=tf.train.Int64List(value=input_ids))\n  }\n\n  # Fill in dummy values for any other required features that presumably\n  # will not actually be used for prediction.\n  data_fields, _ = problem.example_reading_spec()\n  for fname, ftype in data_fields.items():\n    if fname == input_feature_name:\n      continue\n    if not isinstance(ftype, tf.FixedLenFeature):\n      # Only FixedLenFeatures are required\n      continue\n    if ftype.default_value is not None:\n      # If there's a default value, no need to fill it in\n      continue\n    num_elements = functools.reduce(lambda acc, el: acc * el, ftype.shape, 1)\n    if ftype.dtype in [tf.int32, tf.int64]:\n      value = tf.train.Feature(\n          int64_list=tf.train.Int64List(value=[0] * num_elements))\n    if ftype.dtype in [tf.float32, tf.float64]:\n      value = tf.train.Feature(\n          float_list=tf.train.FloatList(value=[0.] * num_elements))\n    if ftype.dtype == tf.bytes:\n      value = tf.train.Feature(\n          bytes_list=tf.train.BytesList(value=[\"\"] * num_elements))\n    tf.logging.info(\"Adding dummy value for feature %s as it is required by \"\n                    \"the Problem.\", fname)\n    features[fname] = value\n  return tf.train.Example(features=tf.train.Features(feature=features))", "language": "python"}
{"input": "Register a command to match all unmatched commands\n@param {CAC} cli", "output": "function registerUnknownCommands (cli, options) {\n  cli.on('command:*', async () => {\n    const { args, options: commandoptions } = cli\n\n    logger.debug('global_options', options)\n    logger.debug('cli_options', commandoptions)\n    logger.debug('cli_args', args)\n\n    const [commandName] = args\n    const sourceDir = args[1] ? path.resolve(args[1]) : pwd\n    const inferredUserDocsDirectory = await inferUserDocsDirectory(pwd)\n    logger.developer('inferredUserDocsDirectory', inferredUserDocsDirectory)\n    logger.developer('sourceDir', sourceDir)\n\n    if (inferredUserDocsDirectory && sourceDir !== inferredUserDocsDirectory) {\n      logUnknownCommand(cli)\n      console.log()\n      logger.tip(`Did you miss to specify the target docs dir? e.g. ${chalk.cyan(`vuepress ${commandName} [targetDir]`)}.`)\n      logger.tip(`A custom command registered by a plugin requires VuePress to locate your site configuration like ${chalk.cyan('vuepress dev')} or ${chalk.cyan('vuepress build')}.`)\n      console.log()\n      process.exit(1)\n    }\n\n    if (!inferredUserDocsDirectory) {\n      logUnknownCommand(cli)\n      process.exit(1)\n    }\n\n    logger.debug('Custom command', chalk.cyan(commandName))\n    CLI({\n      async beforeParse (subCli) {\n        const app = createApp({\n          sourceDir: sourceDir,\n          ...options,\n          ...commandoptions\n        })\n        await app.process()\n        app.pluginAPI.applySyncOption('extendCli', subCli, app)\n        console.log()\n      },\n      async afterParse (subCli) {\n        if (!subCli.matchedCommand) {\n          logUnknownCommand(subCli)\n          console.log()\n        }\n      }\n    })\n  })\n}", "language": "javascript"}
{"input": "Print detailed information on the store.\n\n        .. versionadded:: 0.21.0", "output": "def info(self):\n        \"\"\"\n        Print detailed information on the store.\n\n        .. versionadded:: 0.21.0\n        \"\"\"\n        output = '{type}\\nFile path: {path}\\n'.format(\n            type=type(self), path=pprint_thing(self._path))\n        if self.is_open:\n            lkeys = sorted(list(self.keys()))\n            if len(lkeys):\n                keys = []\n                values = []\n\n                for k in lkeys:\n                    try:\n                        s = self.get_storer(k)\n                        if s is not None:\n                            keys.append(pprint_thing(s.pathname or k))\n                            values.append(\n                                pprint_thing(s or 'invalid_HDFStore node'))\n                    except Exception as detail:\n                        keys.append(k)\n                        values.append(\n                            \"[invalid_HDFStore node: {detail}]\".format(\n                                detail=pprint_thing(detail)))\n\n                output += adjoin(12, keys, values)\n            else:\n                output += 'Empty'\n        else:\n            output += \"File is CLOSED\"\n\n        return output", "language": "python"}
{"input": "Multiply the current lr if necessary.", "output": "def on_batch_begin(self, train, **kwargs):\n        \"Multiply the current lr if necessary.\"\n        if not self.learn.gan_trainer.gen_mode and train: self.learn.opt.lr *= self.mult_lr", "language": "python"}
{"input": "PrivateFunction: _abortAllRequests\n_Private_ helper function that makes sure all pending requests are aborted.", "output": "function _abortAllRequests() {\r\n        var req;\r\n        while (this._requests.length > 0) {\r\n            req = this._requests.pop();\r\n            req.abort = true;\r\n            req.xhr.abort();\r\n            // jslint complains, but this is fine. setting to empty func\r\n            // is necessary for IE6\r\n            req.xhr.onreadystatechange = function () {}; // jshint ignore:line\r\n        }\r\n    }", "language": "javascript"}
{"input": "Function: getDefaultBundle\n\nHook for subclassers to return the URL for the special bundle. This\nimplementation returns basename + <extension> or null if\n<loadDefaultBundle> is false.\n\nParameters:\n\nbasename - The basename for which the file should be loaded.\nlan - The current language.", "output": "function(basename, lan)\n\t{\n\t\tif (mxResources.loadDefaultBundle || !mxResources.isLanguageSupported(lan))\n\t\t{\n\t\t\treturn basename + mxResources.extension;\n\t\t}\n\t\telse\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t}", "language": "javascript"}
{"input": "Language tags are case insensitive however an amd loader is case sensitive To make this work on case preserving & insensitive FS we do the following: the language bundles have lower case language tags and we always lower case the locale we receive from the user or OS. \n@returns {Promise<string>}", "output": "function getUserDefinedLocale() {\n\tconst locale = args['locale'];\n\tif (locale) {\n\t\treturn Promise.resolve(locale.toLowerCase());\n\t}\n\n\tconst localeConfig = path.join(userDataPath, 'User', 'locale.json');\n\treturn bootstrap.readFile(localeConfig).then(content => {\n\t\tcontent = stripComments(content);\n\t\ttry {\n\t\t\tconst value = JSON.parse(content).locale;\n\t\t\treturn value && typeof value === 'string' ? value.toLowerCase() : undefined;\n\t\t} catch (e) {\n\t\t\treturn undefined;\n\t\t}\n\t}, () => {\n\t\treturn undefined;\n\t});\n}", "language": "javascript"}
{"input": "Return a copy of the DStream in which each RDD are partitioned\n        using the specified partitioner.", "output": "def partitionBy(self, numPartitions, partitionFunc=portable_hash):\n        \"\"\"\n        Return a copy of the DStream in which each RDD are partitioned\n        using the specified partitioner.\n        \"\"\"\n        return self.transform(lambda rdd: rdd.partitionBy(numPartitions, partitionFunc))", "language": "python"}
{"input": "for a tz-aware type, return an encoded zone", "output": "def _get_tz(tz):\n    \"\"\" for a tz-aware type, return an encoded zone \"\"\"\n    zone = timezones.get_timezone(tz)\n    if zone is None:\n        zone = tz.utcoffset().total_seconds()\n    return zone", "language": "python"}
{"input": "Validate strings passed to the RegExp constructor\n@param {ASTNode} node node to validate\n@returns {void}\n@private", "output": "function checkFunction(node) {\n            const scope = context.getScope();\n            const regExpVar = astUtils.getVariableByName(scope, \"RegExp\");\n            const shadowed = regExpVar && regExpVar.defs.length > 0;\n\n            if (node.callee.type === \"Identifier\" && node.callee.name === \"RegExp\" && isString(node.arguments[0]) && !shadowed) {\n                checkRegex(node, node.arguments[0].value, node.arguments[0].range[0] + 1);\n            }\n        }", "language": "javascript"}
{"input": "Proof-of-Concept middleware to convert context params\n@param {Function} handler\n@param {Action} action", "output": "function paramConverterMiddleware(handler, action) {\n\n\tfunction convertProperties(obj, schema) {\n\t\tObject.keys(schema).forEach(key => {\n\t\t\tconst s = schema[key];\n\t\t\tconst val = obj[key];\n\t\t\tif (val == null)\n\t\t\t\treturn;\n\n\t\t\tif (s.type == \"string\" && typeof val !== \"string\") {\n\t\t\t\tobj[key] = \"\" + val;\n\t\t\t} else if (s.type == \"number\" && typeof val !== \"number\") {\n\t\t\t\tobj[key] = Number(val);\n\t\t\t} else if (s.type == \"boolean\" && typeof val !== \"boolean\") {\n\t\t\t\tobj[key] = String(val).toLowerCase() === \"true\";\n\t\t\t} else if (s.type == \"date\" && !(val instanceof Date)) {\n\t\t\t\tobj[key] = new Date(val);\n\t\t\t} else if (s.type == \"object\")\n\t\t\t\tconvertProperties(val, s.props);\n\t\t});\n\t}\n\n\t// Wrap a param validator\n\tif (action.params && typeof action.params === \"object\") {\n\t\treturn function convertContextParams(ctx) {\n\t\t\tconvertProperties(ctx.params, action.params);\n\n\t\t\treturn handler(ctx);\n\t\t};\n\t}\n\treturn handler;\n}", "language": "javascript"}
{"input": "Get creator function\n\n    Parameters\n    ----------\n    base_class : type\n        base class for classes that will be reigstered\n    nickname : str\n        nickname of base_class for logging\n\n    Returns\n    -------\n    a creator function", "output": "def get_create_func(base_class, nickname):\n    \"\"\"Get creator function\n\n    Parameters\n    ----------\n    base_class : type\n        base class for classes that will be reigstered\n    nickname : str\n        nickname of base_class for logging\n\n    Returns\n    -------\n    a creator function\n    \"\"\"\n    if base_class not in _REGISTRY:\n        _REGISTRY[base_class] = {}\n    registry = _REGISTRY[base_class]\n\n    def create(*args, **kwargs):\n        \"\"\"Create instance from config\"\"\"\n        if len(args):\n            name = args[0]\n            args = args[1:]\n        else:\n            name = kwargs.pop(nickname)\n\n        if isinstance(name, base_class):\n            assert len(args) == 0 and len(kwargs) == 0, \\\n                \"%s is already an instance. Additional arguments are invalid\"%(nickname)\n            return name\n\n        if isinstance(name, dict):\n            return create(**name)\n\n        assert isinstance(name, string_types), \"%s must be of string type\"%nickname\n\n        if name.startswith('['):\n            assert not args and not kwargs\n            name, kwargs = json.loads(name)\n            return create(name, **kwargs)\n        elif name.startswith('{'):\n            assert not args and not kwargs\n            kwargs = json.loads(name)\n            return create(**kwargs)\n\n        name = name.lower()\n        assert name in registry, \\\n            \"%s is not registered. Please register with %s.register first\"%(\n                str(name), nickname)\n        return registry[name](*args, **kwargs)\n\n    create.__doc__ = \"\"\"Create a %s instance from config.\n\nParameters\n----------\n%s : str or %s instance\n    class name of desired instance. If is a instance,\n    it will be returned directly.\n**kwargs : dict\n    arguments to be passed to constructor\"\"\"%(nickname, nickname, base_class.__name__)\n\n    return create", "language": "python"}
{"input": "We're doing way too much stuff at once, with webpack et al. So much stuff\nthat while downloading extensions from the marketplace, node js doesn't get enough\nstack frames to complete the download in under 2 minutes, at which point the\nmarketplace server cuts off the http request. So, we sequentialize the extensino tasks.", "output": "function sequence(streamProviders) {\n    const result = es.through();\n    function pop() {\n        if (streamProviders.length === 0) {\n            result.emit('end');\n        }\n        else {\n            const fn = streamProviders.shift();\n            fn()\n                .on('end', function () { setTimeout(pop, 0); })\n                .pipe(result, { end: false });\n        }\n    }\n    pop();\n    return result;\n}", "language": "javascript"}
{"input": "Validates that the input dictionary contains only one key and is of the given intrinsic_name\n\n        :param input_dict: Input dictionary representing the intrinsic function\n        :return: True if it matches expected structure, False otherwise", "output": "def can_handle(self, input_dict):\n        \"\"\"\n        Validates that the input dictionary contains only one key and is of the given intrinsic_name\n\n        :param input_dict: Input dictionary representing the intrinsic function\n        :return: True if it matches expected structure, False otherwise\n        \"\"\"\n\n        return input_dict is not None \\\n            and isinstance(input_dict, dict) \\\n            and len(input_dict) == 1 \\\n            and self.intrinsic_name in input_dict", "language": "python"}
{"input": "Adds a Layer to this Scope. The Layer object should define a `key`, which\nrepresents the subset of the preference data that the Layer works with.\nLayers should also define `get` and `getKeys` operations that are like their\ncounterparts in Scope but take \"data\" as the first argument.\n\nListeners are notified of potential changes in preferences with the addition of\nthis layer.\n\n@param {Layer} layer Layer object to add to this Scope", "output": "function (layer) {\n            this._layers.push(layer);\n            this._layerMap[layer.key] = layer;\n            this._exclusions.push(layer.key);\n            this.trigger(PREFERENCE_CHANGE, {\n                ids: layer.getKeys(this.data[layer.key], {})\n            });\n        }", "language": "javascript"}
{"input": "Converts snake_case to camelCase.\nAlso there is special case for Moz prefix starting with upper case letter.\n@param name Name to normalize", "output": "function directiveNormalize(name) {\n      return name\n        .replace(PREFIX_REGEXP, '')\n        .replace(SPECIAL_CHARS_REGEXP, function(_, separator, letter, offset) {\n          return offset ? letter.toUpperCase() : letter;\n        });\n    }", "language": "javascript"}
{"input": "Utility routine to compute zoom/squish matrix.", "output": "def _compute_zs_mat(sz:TensorImageSize, scale:float, squish:float,\n                   invert:bool, row_pct:float, col_pct:float)->AffineMatrix:\n    \"Utility routine to compute zoom/squish matrix.\"\n    orig_ratio = math.sqrt(sz[1]/sz[0])\n    for s,r,i in zip(scale,squish, invert):\n        s,r = 1/math.sqrt(s),math.sqrt(r)\n        if s * r <= 1 and s / r <= 1: #Test if we are completely inside the picture\n            w,h = (s/r, s*r) if i else (s*r,s/r)\n            col_c = (1-w) * (2*col_pct - 1)\n            row_c = (1-h) * (2*row_pct - 1)\n            return _get_zoom_mat(w, h, col_c, row_c)\n\n    #Fallback, hack to emulate a center crop without cropping anything yet.\n    if orig_ratio > 1: return _get_zoom_mat(1/orig_ratio**2, 1, 0, 0.)\n    else:              return _get_zoom_mat(1, orig_ratio**2, 0, 0.)", "language": "python"}
{"input": "Return the path of the Makefile.", "output": "def get_makefile_filename():\n    \"\"\"Return the path of the Makefile.\"\"\"\n    if _PYTHON_BUILD:\n        return os.path.join(_PROJECT_BASE, \"Makefile\")\n    if hasattr(sys, 'abiflags'):\n        config_dir_name = 'config-%s%s' % (_PY_VERSION_SHORT, sys.abiflags)\n    else:\n        config_dir_name = 'config'\n    return os.path.join(get_path('stdlib'), config_dir_name, 'Makefile')", "language": "python"}
{"input": "Returning inputs sorted according to decreasing length.\n\n  This causes inputs of similar lengths to be processed in the same batch,\n  facilitating early stopping for short sequences.\n\n  Longer sequences are sorted first so that if you're going to get OOMs,\n  you'll see it in the first batch.\n\n  Args:\n    filename: path to file with inputs, 1 per line.\n    delimiter: str, delimits records in the file.\n\n  Returns:\n    a sorted list of inputs", "output": "def _get_sorted_inputs(filename, delimiter=\"\\n\"):\n  \"\"\"Returning inputs sorted according to decreasing length.\n\n  This causes inputs of similar lengths to be processed in the same batch,\n  facilitating early stopping for short sequences.\n\n  Longer sequences are sorted first so that if you're going to get OOMs,\n  you'll see it in the first batch.\n\n  Args:\n    filename: path to file with inputs, 1 per line.\n    delimiter: str, delimits records in the file.\n\n  Returns:\n    a sorted list of inputs\n\n  \"\"\"\n  tf.logging.info(\"Getting sorted inputs\")\n  with tf.gfile.Open(filename) as f:\n    text = f.read()\n    records = text.split(delimiter)\n    inputs = [record.strip() for record in records]\n    # Strip the last empty line.\n    if not inputs[-1]:\n      inputs.pop()\n  input_lens = [(i, -len(line.split())) for i, line in enumerate(inputs)]\n  sorted_input_lens = sorted(input_lens, key=operator.itemgetter(1))\n  # We'll need the keys to rearrange the inputs back into their original order\n  sorted_keys = {}\n  sorted_inputs = []\n  for i, (index, _) in enumerate(sorted_input_lens):\n    sorted_inputs.append(inputs[index])\n    sorted_keys[index] = i\n  return sorted_inputs, sorted_keys", "language": "python"}
{"input": "Implements a gating function on a (memory, gate, candidate) tuple.\n\n  Final update is memory * gate + (1-gate) * candidate\n\n  This gating equation may also be referred to as Highway Network.\n  Highway Networks: https://arxiv.org/abs/1505.00387\n\n  Args:\n    x: A tuple of (memory, gate, candidate)\n\n  Returns:\n    The result of applying gating.", "output": "def GateBranches(x, **unused_kwargs):\n  \"\"\"Implements a gating function on a (memory, gate, candidate) tuple.\n\n  Final update is memory * gate + (1-gate) * candidate\n\n  This gating equation may also be referred to as Highway Network.\n  Highway Networks: https://arxiv.org/abs/1505.00387\n\n  Args:\n    x: A tuple of (memory, gate, candidate)\n\n  Returns:\n    The result of applying gating.\n  \"\"\"\n  assert len(x) == 3, x\n  state, gate, candidate = x\n  return gate * state + (1.0 - gate) * candidate", "language": "python"}
{"input": "Check the difference between predictions from MXNet and CoreML.", "output": "def check_error(model, path, shapes, output = 'softmax_output', verbose = True):\n    \"\"\"\n    Check the difference between predictions from MXNet and CoreML.\n    \"\"\"\n    coreml_model = _coremltools.models.MLModel(path)\n    input_data = {}\n    input_data_copy = {}\n    for ip in shapes:\n        input_data[ip] = _np.random.rand(*shapes[ip]).astype('f')\n        input_data_copy[ip] = _np.copy(input_data[ip])\n\n    dataIter = _mxnet.io.NDArrayIter(input_data_copy)\n    mx_out = model.predict(dataIter).flatten()\n\n    e_out_dict = coreml_model.predict(_mxnet_remove_batch(input_data))\n    e_out = e_out_dict[output].flatten()\n    error = _np.linalg.norm(e_out - mx_out)\n\n    if verbose:\n        print(\"First few predictions from CoreML : %s\" % e_out[0:10])\n        print(\"First few predictions from MXNet  : %s\" % e_out[0:10])\n        print(\"L2 Error on random data %s\" % error)\n    return error", "language": "python"}
{"input": "The listener of the `Receiver` `'conclude'` event.\n\n@param {Number} code The status code\n@param {String} reason The reason for closing\n@private", "output": "function receiverOnConclude(code, reason) {\n  const websocket = this[kWebSocket];\n\n  websocket._socket.removeListener('data', socketOnData);\n  websocket._socket.resume();\n\n  websocket._closeFrameReceived = true;\n  websocket._closeMessage = reason;\n  websocket._closeCode = code;\n\n  if (code === 1005) websocket.close();\n  else websocket.close(code, reason);\n}", "language": "javascript"}
{"input": "Gather options where to go to from the given source node", "output": "function _onRemoteShowGoto(event, res) {\n        // res = {nodeId, name, value}\n        var node = DOMAgent.nodeWithId(res.nodeId);\n\n        // get all css rules that apply to the given node\n        Inspector.CSS.getMatchedStylesForNode(node.nodeId, function onMatchedStyles(res) {\n            var i, targets = [];\n            _makeHTMLTarget(targets, node);\n            for (i in node.trace) {\n                _makeJSTarget(targets, node.trace[i]);\n            }\n            for (i in node.events) {\n                var trace = node.events[i];\n                _makeJSTarget(targets, trace.callFrames[0]);\n            }\n            for (i in res.matchedCSSRules.reverse()) {\n                _makeCSSTarget(targets, res.matchedCSSRules[i].rule);\n            }\n            RemoteAgent.call(\"showGoto\", targets);\n        });\n    }", "language": "javascript"}
{"input": "Prepare Variables for YellowFin.\n\n    Returns:\n      Grad**2, Norm, Norm**2, Mean(Norm**2) ops", "output": "def _prepare_variables(self):\n    \"\"\"Prepare Variables for YellowFin.\n\n    Returns:\n      Grad**2, Norm, Norm**2, Mean(Norm**2) ops\n    \"\"\"\n    self._moving_averager = tf.train.ExponentialMovingAverage(\n        decay=self._beta, zero_debias=self._zero_debias)\n    # assert self._grad is not None and len(self._grad) > 0\n    # List for the returned Operations\n    prepare_variables_op = []\n\n    # Get per var g**2 and norm**2\n    self._grad_squared = []\n    self._grad_norm_squared = []\n\n    # Gradient squared\n    for v, g in zip(self._vars, self._grad):\n      if g is None: continue\n      with tf.colocate_with(v):\n        self._grad_squared.append(tf.square(g))\n\n    # Norm squared.\n    self._grad_norm_squared = [tf.reduce_sum(g_sq)\n                               for g_sq in self._grad_squared]\n\n    if self._sparsity_debias:\n      avg_op_sparsity = self._grad_sparsity()\n      prepare_variables_op.append(avg_op_sparsity)\n\n    # The following running average on squared norm of gradient\n    # is shared by grad_var and dist_to_opt\n    avg_op = self._moving_averager.apply(self._grad_norm_squared)\n\n    with tf.control_dependencies([avg_op]):\n      self._grad_norm_squared_avg = [self._moving_averager.average(val)\n                                     for val in self._grad_norm_squared]\n      self._grad_norm_squared = tf.add_n(self._grad_norm_squared)\n      self._grad_norm_squared_avg = tf.add_n(self._grad_norm_squared_avg)\n\n    prepare_variables_op.append(avg_op)\n    return tf.group(*prepare_variables_op)", "language": "python"}
{"input": "Train the world model on problem_name.", "output": "def train_world_model(\n    env, data_dir, output_dir, hparams, world_model_steps_num, epoch\n):\n  \"\"\"Train the world model on problem_name.\"\"\"\n  world_model_steps_num += world_model_step_increment(\n      hparams, is_initial_epoch=(epoch == 0)\n  )\n  model_hparams = trainer_lib.create_hparams(hparams.generative_model_params)\n  model_hparams.learning_rate = model_hparams.learning_rate_constant\n  if epoch > 0:\n    model_hparams.learning_rate *= hparams.learning_rate_bump\n  if hparams.wm_policy_param_sharing:\n    model_hparams.optimizer_zero_grads = True\n\n  restarter = Restarter(\"world_model\", output_dir, world_model_steps_num)\n  if restarter.should_skip:\n    return world_model_steps_num\n  with restarter.training_loop():\n    train_supervised(\n        problem=env,\n        model_name=hparams.generative_model,\n        hparams=model_hparams,\n        data_dir=data_dir,\n        output_dir=output_dir,\n        train_steps=restarter.target_global_step,\n        eval_steps=100,\n        local_eval_frequency=2000\n    )\n\n  return world_model_steps_num", "language": "python"}
{"input": "Loads MR polarity data from files, splits the data into words and generates labels.\n    Returns split sentences and labels.", "output": "def load_data_and_labels():\n    \"\"\"Loads MR polarity data from files, splits the data into words and generates labels.\n    Returns split sentences and labels.\n    \"\"\"\n    # Load data from files\n    pos_path = \"./data/rt-polaritydata/rt-polarity.pos\"\n    neg_path = \"./data/rt-polaritydata/rt-polarity.neg\"\n    if not os.path.exists(pos_path):\n        os.system(\"git clone https://github.com/dennybritz/cnn-text-classification-tf.git\")\n        os.system('mv cnn-text-classification-tf/data .')\n        os.system('rm -rf cnn-text-classification-tf')\n    positive_examples = list(open(pos_path).readlines())\n    positive_examples = [s.strip() for s in positive_examples]\n    negative_examples = list(open(neg_path).readlines())\n    negative_examples = [s.strip() for s in negative_examples]\n    # Split by words\n    x_text = positive_examples + negative_examples\n    x_text = [clean_str(sent) for sent in x_text]\n    x_text = [s.split(\" \") for s in x_text]\n    # Generate labels\n    positive_labels = [1 for _ in positive_examples]\n    negative_labels = [0 for _ in negative_examples]\n    y = np.concatenate([positive_labels, negative_labels], 0)\n    return [x_text, y]", "language": "python"}
{"input": "Called on every Vue.js batcher flush cycle.\nCapture current component tree structure and the state\nof the current inspected instance (if present) and\nsend it to the devtools.", "output": "function flush () {\n  let start\n  functionalIds.clear()\n  captureIds.clear()\n  if (process.env.NODE_ENV !== 'production') {\n    captureCount = 0\n    start = isBrowser ? window.performance.now() : 0\n  }\n  const payload = stringify({\n    inspectedInstance: getInstanceDetails(currentInspectedId),\n    instances: findQualifiedChildrenFromList(rootInstances)\n  })\n  if (process.env.NODE_ENV !== 'production') {\n    console.log(`[flush] serialized ${captureCount} instances${isBrowser ? `, took ${window.performance.now() - start}ms.` : ''}.`)\n  }\n  bridge.send('flush', payload)\n}", "language": "javascript"}
{"input": "\u521b\u5efa\u5e76\u663e\u793a\u8fdb\u5ea6\u6761\n@param {Object} container  \u53ef\u9009\uff0c\u9ed8\u8ba4body\uff0c\u652f\u6301selector,DOM Node,mui wrapper\n@param {Object} progress \u53ef\u9009\uff0cundefined\u8868\u793a\u5faa\u73af\uff0c\u6570\u5b57\u8868\u793a\u5177\u4f53\u8fdb\u5ea6\n@param {Object} color \u53ef\u9009\uff0c\u6307\u5b9a\u989c\u8272\u6837\u5f0f(\u76ee\u524d\u6682\u672a\u63d0\u4f9b\u5b9e\u9645\u6837\u5f0f\uff0c\u53ef\u6682\u65f6\u4e0d\u66b4\u9732\u6b64\u53c2\u6570)", "output": "function(container, progress, color) {\n\t\tif (typeof container === 'number') {\n\t\t\tcolor = progress;\n\t\t\tprogress = container;\n\t\t\tcontainer = 'body';\n\t\t}\n\t\tcontainer = $(container || 'body');\n\t\tif (container.length === 0) return;\n\t\tcontainer = container[0];\n\t\tvar progressbar;\n\t\tif (container.classList.contains(CLASS_PROGRESSBAR)) {\n\t\t\tprogressbar = container;\n\t\t} else {\n\t\t\tvar progressbars = container.querySelectorAll(SELECTOR_PROGRESSBAR + ':not(.' + CLASS_PROGRESSBAR_OUT + ')');\n\t\t\tif (progressbars) {\n\t\t\t\tfor (var i = 0, len = progressbars.length; i < len; i++) {\n\t\t\t\t\tvar _progressbar = progressbars[i];\n\t\t\t\t\tif (_progressbar.parentNode === container) {\n\t\t\t\t\t\tprogressbar = _progressbar;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!progressbar) {\n\t\t\t\tprogressbar = document.createElement('span');\n\t\t\t\tprogressbar.className = CLASS_PROGRESSBAR + ' ' + CLASS_PROGRESSBAR_IN + (typeof progress !== 'undefined' ? '' : (' ' + CLASS_PROGRESSBAR_INFINITE)) + (color ? (' ' + CLASS_PROGRESSBAR + '-' + color) : '');\n\t\t\t\tif (typeof progress !== 'undefined') {\n\t\t\t\t\tprogressbar.innerHTML = '<span></span>';\n\t\t\t\t}\n\t\t\t\tcontainer.appendChild(progressbar);\n\t\t\t} else {\n\t\t\t\tprogressbar.classList.add(CLASS_PROGRESSBAR_IN);\n\t\t\t}\n\t\t}\n\t\tif (progress) setProgressbar(container, progress);\n\t\treturn progressbar;\n\t}", "language": "javascript"}
{"input": "Parse a whole book from a filesystem\n\n@param {Book} book\n@return {Promise<Book>}", "output": "function parseBook(book) {\n    return timing.measure(\n        'parse.book',\n        Promise(book)\n        .then(parseIgnore)\n        .then(parseConfig)\n        .then(parseLanguages)\n        .then(function(resultBook) {\n            if (resultBook.isMultilingual()) {\n                return parseMultilingualBook(resultBook);\n            } else {\n                return parseBookContent(resultBook);\n            }\n        })\n    );\n}", "language": "javascript"}
{"input": "Increments health log count for a particular kind of search done\n@param {string} searchType The kind of search type that needs to be logged- should be a js var compatible string", "output": "function searchDone(searchType) {\n        var searchDetails = getHealthDataLog(\"searchDetails\");\n        if (!searchDetails) {\n            searchDetails = {};\n        }\n        if (!searchDetails[searchType]) {\n            searchDetails[searchType] = 0;\n        }\n        searchDetails[searchType]++;\n        setHealthDataLog(\"searchDetails\", searchDetails);\n    }", "language": "javascript"}
{"input": "Yield distributions accessible via `path_item`", "output": "def find_distributions(path_item, only=False):\n    \"\"\"Yield distributions accessible via `path_item`\"\"\"\n    importer = get_importer(path_item)\n    finder = _find_adapter(_distribution_finders, importer)\n    return finder(importer, path_item, only)", "language": "python"}
{"input": "Resolve a variable name in a possibly local context\n\n        Parameters\n        ----------\n        key : str\n            A variable name\n        is_local : bool\n            Flag indicating whether the variable is local or not (prefixed with\n            the '@' symbol)\n\n        Returns\n        -------\n        value : object\n            The value of a particular variable", "output": "def resolve(self, key, is_local):\n        \"\"\"Resolve a variable name in a possibly local context\n\n        Parameters\n        ----------\n        key : str\n            A variable name\n        is_local : bool\n            Flag indicating whether the variable is local or not (prefixed with\n            the '@' symbol)\n\n        Returns\n        -------\n        value : object\n            The value of a particular variable\n        \"\"\"\n        try:\n            # only look for locals in outer scope\n            if is_local:\n                return self.scope[key]\n\n            # not a local variable so check in resolvers if we have them\n            if self.has_resolvers:\n                return self.resolvers[key]\n\n            # if we're here that means that we have no locals and we also have\n            # no resolvers\n            assert not is_local and not self.has_resolvers\n            return self.scope[key]\n        except KeyError:\n            try:\n                # last ditch effort we look in temporaries\n                # these are created when parsing indexing expressions\n                # e.g., df[df > 0]\n                return self.temps[key]\n            except KeyError:\n                raise compu.ops.UndefinedVariableError(key, is_local)", "language": "python"}
{"input": "Set the volume and update the volume slider display.\n@param  {Number} val Volume between 0 and 1.", "output": "function(val) {\n    var self = this;\n\n    // Update the global volume (affecting all Howls).\n    Howler.volume(val);\n\n    // Update the display on the slider.\n    var barWidth = (val * 90) / 100;\n    barFull.style.width = (barWidth * 100) + '%';\n    sliderBtn.style.left = (window.innerWidth * barWidth + window.innerWidth * 0.05 - 25) + 'px';\n  }", "language": "javascript"}
{"input": "Exponential weighted sample covariance.", "output": "def cov(self, other=None, pairwise=None, bias=False, **kwargs):\n        \"\"\"\n        Exponential weighted sample covariance.\n        \"\"\"\n        if other is None:\n            other = self._selected_obj\n            # only default unset\n            pairwise = True if pairwise is None else pairwise\n        other = self._shallow_copy(other)\n\n        def _get_cov(X, Y):\n            X = self._shallow_copy(X)\n            Y = self._shallow_copy(Y)\n            cov = libwindow.ewmcov(X._prep_values(), Y._prep_values(),\n                                   self.com, int(self.adjust),\n                                   int(self.ignore_na), int(self.min_periods),\n                                   int(bias))\n            return X._wrap_result(cov)\n\n        return _flex_binary_moment(self._selected_obj, other._selected_obj,\n                                   _get_cov, pairwise=bool(pairwise))", "language": "python"}
{"input": "Creates a new measure tooltip", "output": "function createMeasureTooltip() {\n  if (measureTooltipElement) {\n    measureTooltipElement.parentNode.removeChild(measureTooltipElement);\n  }\n  measureTooltipElement = document.createElement('div');\n  measureTooltipElement.className = 'ol-tooltip ol-tooltip-measure';\n  measureTooltip = new Overlay({\n    element: measureTooltipElement,\n    offset: [0, -15],\n    positioning: 'bottom-center'\n  });\n  map.addOverlay(measureTooltip);\n}", "language": "javascript"}
{"input": "this will not avoid warnings that react-dom 16.8.0 logs for triggering state updates asynchronously, but at least we can tell people they need to upgrade to avoid the warnings.", "output": "async function asyncActPolyfill(cb) {\n  // istanbul-ignore-next\n  if (\n    !youHaveBeenWarned &&\n    actSupported &&\n    reactDomSixteenPointNineIsReleased\n  ) {\n    // if act is supported and async act isn't and they're trying to use async\n    // act, then they need to upgrade from 16.8 to 16.9.\n    // This is a seemless upgrade, so we'll add a warning\n    console.error(\n      `It looks like you're using a version of react-dom that supports the \"act\" function, but not an awaitable version of \"act\" which you will need. Please upgrade to at least react-dom@16.9.0 to remove this warning.`,\n    )\n    youHaveBeenWarned = true\n  }\n  await cb()\n  // make all effects resolve after\n  act(() => {})\n}", "language": "javascript"}
{"input": "Launch job on ML Engine.", "output": "def launch_job(job_spec):\n  \"\"\"Launch job on ML Engine.\"\"\"\n  project_id = \"projects/{}\".format(\n      text_encoder.native_to_unicode(default_project()))\n  credentials = GoogleCredentials.get_application_default()\n  cloudml = discovery.build(\"ml\", \"v1\", credentials=credentials,\n                            cache_discovery=False)\n  request = cloudml.projects().jobs().create(body=job_spec, parent=project_id)\n  request.execute()", "language": "python"}
{"input": "Draws tooltip unless a plugin returns `false` to the `beforeTooltipDraw`\nhook, in which case, plugins will not be called on `afterTooltipDraw`.\n@private", "output": "function(easingValue) {\n\t\tvar me = this;\n\t\tvar tooltip = me.tooltip;\n\t\tvar args = {\n\t\t\ttooltip: tooltip,\n\t\t\teasingValue: easingValue\n\t\t};\n\n\t\tif (core_plugins.notify(me, 'beforeTooltipDraw', [args]) === false) {\n\t\t\treturn;\n\t\t}\n\n\t\ttooltip.draw();\n\n\t\tcore_plugins.notify(me, 'afterTooltipDraw', [args]);\n\t}", "language": "javascript"}
{"input": "Retrieving sibling elements from its parent container which are bound to the same Model (important!)\n\n@param {sap.ui.core.Control} oElement - element for which we're looking for siblings\n@param {sap.ui.core.Control} oRelevantContainer - \"parent\" container of the oElement\n@param {string} sAggregationName - name of the aggregation of the action\n\n@return {Array.<sap.ui.core.Control>} - returns an array with found siblings elements\n\n@private", "output": "function _getRelevantElements(oElement, oRelevantContainer, sAggregationName) {\n\t\tif (oRelevantContainer && oRelevantContainer !== oElement) {\n\t\t\tvar sEntityName = RtaUtils.getEntityTypeByPath(\n\t\t\t\toElement.getModel(),\n\t\t\t\t_getBindingPath(oElement, sAggregationName)\n\t\t\t);\n\n\t\t\treturn ElementUtil\n\t\t\t\t.findAllSiblingsInContainer(oElement, oRelevantContainer)\n\t\t\t\t// We accept only siblings that are bound on the same model\n\t\t\t\t.filter(function (oSiblingElement) {\n\t\t\t\t\tvar sPath = _getBindingPath(oSiblingElement, sAggregationName);\n\t\t\t\t\tif (sPath) {\n\t\t\t\t\t\treturn RtaUtils.getEntityTypeByPath(oSiblingElement.getModel(), sPath) === sEntityName;\n\t\t\t\t\t}\n\t\t\t\t\treturn false;\n\t\t\t\t});\n\t\t} else {\n\t\t\treturn [oElement];\n\t\t}\n\t}", "language": "javascript"}
{"input": "Perform any of 8 permutations of 90-degrees rotations or flips for image x.", "output": "def dihedral(x, dih):\n    \"\"\" Perform any of 8 permutations of 90-degrees rotations or flips for image x. \"\"\"\n    x = np.rot90(x, dih%4)\n    return x if dih<4 else np.fliplr(x)", "language": "python"}
{"input": "Like :meth:`find_object` but sets the innermost object to a\n        new instance of `object_type` if it does not exist.", "output": "def ensure_object(self, object_type):\n        \"\"\"Like :meth:`find_object` but sets the innermost object to a\n        new instance of `object_type` if it does not exist.\n        \"\"\"\n        rv = self.find_object(object_type)\n        if rv is None:\n            self.obj = rv = object_type()\n        return rv", "language": "python"}
{"input": "Poisson loss for real.", "output": "def real_log_poisson_loss(top_out,\n                          targets,\n                          model_hparams,\n                          vocab_size,\n                          weights_fn):\n  \"\"\"Poisson loss for real.\"\"\"\n  del model_hparams, vocab_size  # unused arg\n  predictions = top_out\n  if (len(common_layers.shape_list(top_out)) != len(\n      common_layers.shape_list(targets))):\n    predictions = tf.squeeze(top_out, axis=[-1])\n  with tf.name_scope(\"log_possion\"):\n    weights = weights_fn(targets)\n    lp_loss = tf.nn.log_poisson_loss(targets, predictions)\n    return tf.reduce_sum(lp_loss * weights), tf.reduce_sum(weights)", "language": "python"}
{"input": "Fired when a dragged appointment enters a drop target.", "output": "function(oEvent) {\n\t\t\t\t\tvar oDragSession = oEvent.getParameter(\"dragSession\"),\n\t\t\t\t\t\toAppointmentRef = oDragSession.getDragControl().$().get(0),\n\t\t\t\t\t\toDropTarget = oDragSession.getDropControl().getDomRef(),\n\t\t\t\t\t\toAppointmentStartingBoundaries = oDragSession.getComplexData(\"appointmentStartingBoundaries\"),\n\t\t\t\t\t\tfnHideIndicator = function() {\n\t\t\t\t\t\t\tvar $Indicator = jQuery(oDragSession.getIndicator());\n\t\t\t\t\t\t\t$Indicator.addClass(\"sapUiDnDIndicatorHide\");\n\t\t\t\t\t\t},\n\t\t\t\t\t\tiTop,\n\t\t\t\t\t\tiBottom,\n\t\t\t\t\t\tiHeight,\n\t\t\t\t\t\tiVariableBoundaryY,\n\t\t\t\t\t\tmDraggedControlConfig;\n\n\t\t\t\t\tif (!oAppointmentStartingBoundaries) {\n\t\t\t\t\t\toAppointmentStartingBoundaries = {\n\t\t\t\t\t\t\ttop: oAppointmentRef.offsetTop,\n\t\t\t\t\t\t\tbottom: oAppointmentRef.offsetTop + oAppointmentRef.getBoundingClientRect().height,\n\t\t\t\t\t\t\theight: oAppointmentRef.getBoundingClientRect().height\n\t\t\t\t\t\t};\n\t\t\t\t\t\toDragSession.setComplexData(\"appointmentStartingBoundaries\", oAppointmentStartingBoundaries);\n\t\t\t\t\t}\n\n\t\t\t\t\tiVariableBoundaryY = oDragSession.getData(\"bottomHandle\") ? oAppointmentStartingBoundaries.top : oAppointmentStartingBoundaries.bottom;\n\n\t\t\t\t\tiTop = Math.min(iVariableBoundaryY, oDropTarget.offsetTop);\n\t\t\t\t\tiBottom = Math.max(iVariableBoundaryY, oDropTarget.offsetTop + oDropTarget.getBoundingClientRect().height);\n\t\t\t\t\tiHeight = iBottom - iTop;\n\n\t\t\t\t\tmDraggedControlConfig = {\n\t\t\t\t\t\ttop: iTop,\n\t\t\t\t\t\theight: iHeight,\n\t\t\t\t\t\t\"z-index\": 1,\n\t\t\t\t\t\topacity: 0.8\n\t\t\t\t\t};\n\n\t\t\t\t\toDragSession.getDragControl().$().css(mDraggedControlConfig);\n\n\t\t\t\t\tif (!oDragSession.getIndicator()) {\n\t\t\t\t\t\tsetTimeout(fnHideIndicator, 0);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfnHideIndicator();\n\t\t\t\t\t}\n\t\t\t\t}", "language": "javascript"}
{"input": "Opens the given file, makes it the current file, does NOT add it to the workingset\n@param {FileCommandData} commandData\nfullPath: File to open;\nsilent: optional flag to suppress error messages;\npaneId: optional PaneId (defaults to active pane)\n@return {$.Promise} a jQuery promise that will be resolved with @type {Document}", "output": "function handleDocumentOpen(commandData) {\n        var result = new $.Deferred();\n        handleFileOpen(commandData)\n            .done(function (file) {\n                // if we succeeded with an open file\n                //  then we need to resolve that to a document.\n                //  getOpenDocumentForPath will return null if there isn't a\n                //  supporting document for that file (e.g. an image)\n                var doc = DocumentManager.getOpenDocumentForPath(file.fullPath);\n                result.resolve(doc);\n            })\n            .fail(function (err) {\n                result.reject(err);\n            });\n\n        return result.promise();\n\n    }", "language": "javascript"}
{"input": "Parameters\n        ----------\n        other : TimedeltaArray or ndarray[timedelta64]\n\n        Returns\n        -------\n        result : ndarray[int64]", "output": "def _add_delta_tdi(self, other):\n        \"\"\"\n        Parameters\n        ----------\n        other : TimedeltaArray or ndarray[timedelta64]\n\n        Returns\n        -------\n        result : ndarray[int64]\n        \"\"\"\n        assert isinstance(self.freq, Tick)  # checked by calling function\n\n        delta = self._check_timedeltalike_freq_compat(other)\n        return self._addsub_int_array(delta, operator.add).asi8", "language": "python"}
{"input": "Convert CH y/x to WGS long", "output": "function CHtoWGSlng(y, x) {\n\n  // Converts militar to civil and  to unit = 1000km\n  // Axiliary values (% Bern)\n  const y_aux = (y - 600000) / 1000000;\n  const x_aux = (x - 200000) / 1000000;\n\n  // Process long\n  let lng = 2.6779094 +\n      4.728982 * y_aux +\n      0.791484 * y_aux * x_aux +\n      0.1306 * y_aux * Math.pow(x_aux, 2) -\n      0.0436 * Math.pow(y_aux, 3);\n\n  // Unit 10000\" to 1 \" and converts seconds to degrees (dec)\n  lng = lng * 100 / 36;\n\n  return lng;\n\n}", "language": "javascript"}
{"input": "Render tempita templates before calling cythonize", "output": "def maybe_cythonize(extensions, *args, **kwargs):\n    \"\"\"\n    Render tempita templates before calling cythonize\n    \"\"\"\n    if len(sys.argv) > 1 and 'clean' in sys.argv:\n        # Avoid running cythonize on `python setup.py clean`\n        # See https://github.com/cython/cython/issues/1495\n        return extensions\n    if not cython:\n        # Avoid trying to look up numpy when installing from sdist\n        # https://github.com/pandas-dev/pandas/issues/25193\n        # TODO: See if this can be removed after pyproject.toml added.\n        return extensions\n\n    numpy_incl = pkg_resources.resource_filename('numpy', 'core/include')\n    # TODO: Is this really necessary here?\n    for ext in extensions:\n        if (hasattr(ext, 'include_dirs') and\n                numpy_incl not in ext.include_dirs):\n            ext.include_dirs.append(numpy_incl)\n\n    build_ext.render_templates(_pxifiles)\n    return cythonize(extensions, *args, **kwargs)", "language": "python"}
{"input": "r'''\n    Expects something like /tmp/tmpAjry4Gdsbench/test.weights.e5.XXX.YYY.pb\n    Where XXX is a variation on the model size for example\n    And where YYY is a const related to the training dataset", "output": "def reduce_filename(f):\n    r'''\n    Expects something like /tmp/tmpAjry4Gdsbench/test.weights.e5.XXX.YYY.pb\n    Where XXX is a variation on the model size for example\n    And where YYY is a const related to the training dataset\n    '''\n\n    f = os.path.basename(f).split('.')\n    return keep_only_digits(f[-3])", "language": "python"}
{"input": "/*\nReturns whether the given cell is hidden", "output": "function($Cell, oCell) {\n\t\t\tvar bGroup = TableUtils.Grouping.isInGroupingRow($Cell);\n\t\t\tvar bSum = TableUtils.Grouping.isInSumRow($Cell);\n\t\t\tvar bSupportStyleClass = !!oCell && !!oCell.hasStyleClass;\n\n\t\t\tvar bIsRowHidden = $Cell.parent().hasClass(\"sapUiTableRowHidden\");\n\t\t\tvar bIsCellHidden = $Cell.hasClass(\"sapUiTableCellHidden\");\n\t\t\tvar bNoMeasureInFirstCellInGroup = bGroup && $Cell.hasClass(\"sapUiTableCellFirst\") && !$Cell.hasClass(\"sapUiTableMeasureCell\");\n\t\t\tvar bGroupCellHiddenByApp = bGroup && bSupportStyleClass && oCell.hasStyleClass(\"sapUiAnalyticalTableGroupCellHidden\");\n\t\t\tvar bSumCellHiddenByApp = bSum && bSupportStyleClass && oCell.hasStyleClass(\"sapUiAnalyticalTableSumCellHidden\");\n\n\t\t\treturn bIsRowHidden || bIsCellHidden || bNoMeasureInFirstCellInGroup || bGroupCellHiddenByApp || bSumCellHiddenByApp;\n\t\t}", "language": "javascript"}
{"input": "Return a dict of dtype -> Constructor Types that\n        each is a homogeneous dtype.\n\n        Internal ONLY", "output": "def _to_dict_of_blocks(self, copy=True):\n        \"\"\"\n        Return a dict of dtype -> Constructor Types that\n        each is a homogeneous dtype.\n\n        Internal ONLY\n        \"\"\"\n        return {k: self._constructor(v).__finalize__(self)\n                for k, v, in self._data.to_dict(copy=copy).items()}", "language": "python"}
{"input": "A helper function to compute the control point of a quadratic bezier curve\n@param  {number[]} source  - the coordinates of source point, ex: [x, y, z]\n@param  {number[]} target  - the coordinates of target point, ex: [x, y, z]\n@param  {number} direction - the direction of the curve, 1 or -1\n@param  {number} offset    - offset from the midpoint\n@return {number[]}         - the coordinates of the control point", "output": "function computeControlPoint(source, target, direction, offset) {\n  const midPoint = [(source[0] + target[0]) / 2, (source[1] + target[1]) / 2];\n  const dx = target[0] - source[0];\n  const dy = target[1] - source[1];\n  const normal = [dy, -dx];\n  const length = Math.sqrt(Math.pow(normal[0], 2.0) + Math.pow(normal[1], 2.0));\n  const normalized = [normal[0] / length, normal[1] / length];\n  return [\n    midPoint[0] + normalized[0] * offset * direction,\n    midPoint[1] + normalized[1] * offset * direction\n  ];\n}", "language": "javascript"}
{"input": "If n is positive, return tomorrow's business day opening time.\n        Otherwise yesterday's business day's opening time.\n\n        Opening time always locates on BusinessDay.\n        Otherwise, closing time may not if business hour extends over midnight.", "output": "def _next_opening_time(self, other):\n        \"\"\"\n        If n is positive, return tomorrow's business day opening time.\n        Otherwise yesterday's business day's opening time.\n\n        Opening time always locates on BusinessDay.\n        Otherwise, closing time may not if business hour extends over midnight.\n        \"\"\"\n        if not self.next_bday.onOffset(other):\n            other = other + self.next_bday\n        else:\n            if self.n >= 0 and self.start < other.time():\n                other = other + self.next_bday\n            elif self.n < 0 and other.time() < self.start:\n                other = other + self.next_bday\n        return datetime(other.year, other.month, other.day,\n                        self.start.hour, self.start.minute)", "language": "python"}
{"input": "Gets current model step.\n        :return: current model step.", "output": "def get_current_step(self):\n        \"\"\"\n        Gets current model step.\n        :return: current model step.\n        \"\"\"\n        step = self.sess.run(self.model.global_step)\n        return step", "language": "python"}
{"input": "/* [MS-OFFCRYPTO] 2.3.4.5  EncryptionInfo Stream (Standard Encryption)", "output": "function parse_EncInfoStd(blob) {\n\tvar flags = blob.read_shift(4);\n\tif((flags & 0x3F) != 0x24) throw new Error(\"EncryptionInfo mismatch\");\n\tvar sz = blob.read_shift(4);\n\t//var tgt = blob.l + sz;\n\tvar hdr = parse_EncryptionHeader(blob, sz);\n\tvar verifier = parse_EncryptionVerifier(blob, blob.length - blob.l);\n\treturn { t:\"Std\", h:hdr, v:verifier };\n}", "language": "javascript"}
{"input": "Opens the context menu of a column.\nIf context menus of other columns are open, they will be closed.\n\n@param {sap.ui.table.Table} oTable Instance of the table.\n@param {int} iColumnIndex The index of the column to open the context menu on.\n@param {boolean} [bHoverFirstMenuItem] If <code>true</code>, the first item in the opened menu will be hovered.\n@param {jQuery} oCell The column header cell to which the menu should be attached.\n@see openContextMenu\n@see closeColumnContextMenu\n@private", "output": "function(oTable, iColumnIndex, bHoverFirstMenuItem, oCell) {\n\t\t\tif (!oTable ||\n\t\t\t\tiColumnIndex == null || iColumnIndex < 0) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (bHoverFirstMenuItem == null) {\n\t\t\t\tbHoverFirstMenuItem = false;\n\t\t\t}\n\n\t\t\tvar oColumns = oTable.getColumns();\n\t\t\tif (iColumnIndex >= oColumns.length) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tvar oColumn = oColumns[iColumnIndex];\n\t\t\tif (!oColumn.getVisible()) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Close all menus.\n\t\t\tfor (var i = 0; i < oColumns.length; i++) {\n\t\t\t\t// If column menus of other columns are open, close them.\n\t\t\t\tif (oColumns[i] !== oColumn) {\n\t\t\t\t\tMenuUtils.closeColumnContextMenu(oTable, i);\n\t\t\t\t}\n\t\t\t}\n\t\t\tMenuUtils.closeDataCellContextMenu(oTable);\n\n\t\t\tvar colspan = oCell && oCell.attr(\"colspan\");\n\t\t\tif (colspan && colspan !== \"1\") {\n\t\t\t\treturn; // headers with span do not have connection to a column, do not open the context menu\n\t\t\t}\n\n\t\t\toColumn._openMenu(oCell && oCell[0] || oColumn.getDomRef(), bHoverFirstMenuItem);\n\t\t}", "language": "javascript"}
{"input": "Triggers the processing of the i18n texts to replace them\nwith the values from \"sap.app/i18n\"\n\n@param {boolean} bAsync true, if the ResourceBundle will be loaded async\n@return {Promise|undefined} when using the API async it will return a Promise which resolves when the texts have been replaced", "output": "function(bAsync) {\n\n\t\t\t// find i18n property paths in the manifest if i18n texts in\n\t\t\t// the manifest which should be processed\n\t\t\tvar aI18nProperties = [];\n\t\t\tprocessObject(this._oManifest, function(oObject, sKey, vValue) {\n\t\t\t\tvar match = vValue.match(rManifestTemplate);\n\t\t\t\tif (match) {\n\t\t\t\t\taI18nProperties.push({\n\t\t\t\t\t\tobject: oObject,\n\t\t\t\t\t\tkey: sKey\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tif (aI18nProperties.length > 0) {\n\n\t\t\t\tvar fnReplaceI18n = function(oResourceBundle) {\n\t\t\t\t\tvar fnReplaceI18nText = function(sMatch, sI18nKey) {\n\t\t\t\t\t\treturn oResourceBundle.getText(sI18nKey);\n\t\t\t\t\t};\n\t\t\t\t\tfor (var i = 0, l = aI18nProperties.length; i < l; i++) {\n\t\t\t\t\t\tvar oProperty = aI18nProperties[i];\n\t\t\t\t\t\toProperty.object[oProperty.key] = oProperty.object[oProperty.key].replace(rManifestTemplate, fnReplaceI18nText);\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\t\tif (bAsync) {\n\t\t\t\t\treturn this._loadI18n(bAsync).then(fnReplaceI18n);\n\t\t\t\t} else {\n\t\t\t\t\tfnReplaceI18n(this._loadI18n(bAsync));\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\treturn bAsync ? Promise.resolve() : undefined;\n\t\t\t}\n\n\t\t}", "language": "javascript"}
{"input": "Dispatches an XPath evaluation method on the relevant engine for the\ngiven document, and returns the result", "output": "function dispatch(methodName, inDocument, xpath, contextNode, namespaceResolver) {\n        xpath = preprocess(xpath);\n\n        if (! contextNode) {\n            contextNode = inDocument;\n        }\n\n        var result = getEngineFor(inDocument)\n            .setIgnoreAttributesWithoutValue(ignoreAttributesWithoutValue)\n            [methodName](xpath, contextNode, namespaceResolver);\n\n        return result;\n    }", "language": "javascript"}
{"input": "Update item available by list,\nwhen list has been performed options like 'filterSelf' or 'map'.", "output": "function () {\n        var data = this.data;\n        var nodes = this._nodes;\n\n        for (var i = 0, len = nodes.length; i < len; i++) {\n            nodes[i].dataIndex = -1;\n        }\n\n        for (var i = 0, len = data.count(); i < len; i++) {\n            nodes[data.getRawIndex(i)].dataIndex = i;\n        }\n    }", "language": "javascript"}
{"input": "Index levels in a part\n\n@param {Part}\n@param {Number} index\n@return {Part}", "output": "function indexPartLevels(part, index) {\n    var baseLevel = String(index + 1);\n    var articles = part.getArticles();\n\n    articles = articles.map(function(inner, i) {\n        return indexArticleLevels(inner, baseLevel + '.' + (i + 1));\n    });\n\n    return part.merge({\n        level: baseLevel,\n        articles: articles\n    });\n}", "language": "javascript"}
{"input": "Infer and return an integer array of the values.\n\n    Parameters\n    ----------\n    values : 1D list-like\n    dtype : dtype, optional\n        dtype to coerce\n    copy : boolean, default False\n\n    Returns\n    -------\n    IntegerArray\n\n    Raises\n    ------\n    TypeError if incompatible types", "output": "def integer_array(values, dtype=None, copy=False):\n    \"\"\"\n    Infer and return an integer array of the values.\n\n    Parameters\n    ----------\n    values : 1D list-like\n    dtype : dtype, optional\n        dtype to coerce\n    copy : boolean, default False\n\n    Returns\n    -------\n    IntegerArray\n\n    Raises\n    ------\n    TypeError if incompatible types\n    \"\"\"\n    values, mask = coerce_to_array(values, dtype=dtype, copy=copy)\n    return IntegerArray(values, mask)", "language": "python"}
{"input": "Define default roll function to be called in apply method.", "output": "def cbday_roll(self):\n        \"\"\"\n        Define default roll function to be called in apply method.\n        \"\"\"\n        cbday = CustomBusinessDay(n=self.n, normalize=False, **self.kwds)\n\n        if self._prefix.endswith('S'):\n            # MonthBegin\n            roll_func = cbday.rollforward\n        else:\n            # MonthEnd\n            roll_func = cbday.rollback\n        return roll_func", "language": "python"}
{"input": "Override Transforms input data with specified augmentations.", "output": "def augmentation_transform(self, data, label):  # pylint: disable=arguments-differ\n        \"\"\"Override Transforms input data with specified augmentations.\"\"\"\n        for aug in self.auglist:\n            data, label = aug(data, label)\n        return (data, label)", "language": "python"}
{"input": "Count the lines in the function\n@param {ASTNode} funcNode Function AST node\n@returns {void}\n@private", "output": "function processFunction(funcNode) {\n            const node = isEmbedded(funcNode) ? funcNode.parent : funcNode;\n\n            if (!IIFEs && isIIFE(node)) {\n                return;\n            }\n            let lineCount = 0;\n\n            for (let i = node.loc.start.line - 1; i < node.loc.end.line; ++i) {\n                const line = lines[i];\n\n                if (skipComments) {\n                    if (commentLineNumbers.has(i + 1) && isFullLineComment(line, i + 1, commentLineNumbers.get(i + 1))) {\n                        continue;\n                    }\n                }\n\n                if (skipBlankLines) {\n                    if (line.match(/^\\s*$/u)) {\n                        continue;\n                    }\n                }\n\n                lineCount++;\n            }\n\n            if (lineCount > maxLines) {\n                const name = astUtils.getFunctionNameWithKind(funcNode);\n\n                context.report({\n                    node,\n                    messageId: \"exceed\",\n                    data: { name, lineCount, maxLines }\n                });\n            }\n        }", "language": "javascript"}
{"input": "Create in the build directory an html file with a redirect,\n        for every row in REDIRECTS_FILE.", "output": "def _add_redirects(self):\n        \"\"\"\n        Create in the build directory an html file with a redirect,\n        for every row in REDIRECTS_FILE.\n        \"\"\"\n        html = '''\n        <html>\n            <head>\n                <meta http-equiv=\"refresh\" content=\"0;URL={url}\"/>\n            </head>\n            <body>\n                <p>\n                    The page has been moved to <a href=\"{url}\">{title}</a>\n                </p>\n            </body>\n        <html>\n        '''\n        with open(REDIRECTS_FILE) as mapping_fd:\n            reader = csv.reader(mapping_fd)\n            for row in reader:\n                if not row or row[0].strip().startswith('#'):\n                    continue\n\n                path = os.path.join(BUILD_PATH,\n                                    'html',\n                                    *row[0].split('/')) + '.html'\n\n                try:\n                    title = self._get_page_title(row[1])\n                except Exception:\n                    # the file can be an ipynb and not an rst, or docutils\n                    # may not be able to read the rst because it has some\n                    # sphinx specific stuff\n                    title = 'this page'\n\n                if os.path.exists(path):\n                    raise RuntimeError((\n                        'Redirection would overwrite an existing file: '\n                        '{}').format(path))\n\n                with open(path, 'w') as moved_page_fd:\n                    moved_page_fd.write(\n                        html.format(url='{}.html'.format(row[1]),\n                                    title=title))", "language": "python"}
{"input": "Get the name of the single base directory if there is one, else return an empty string\n@param {String} directory\n@returns {Promise (String)}", "output": "function (directory) {\n        // Globs match root level only\n        var extMatches = glob.sync(this.getExtensionGlob(this.getExtensions(), ROOT_ONLY), {cwd: directory}),\n            dirMatches = glob.sync(this.getDirectoryGlob(this.getDirectories(), ROOT_ONLY), {cwd: directory}),\n            extMatchesAll;\n\n        // There is no base directory\n        if (extMatches.length > 0 || dirMatches.length > 0) {\n            return;\n        }\n        // There is a base directory, grab it from any ext match\n        extMatchesAll = glob.sync(\n            this.getExtensionGlob(this.getExtensions(), ALL_DIRS), {cwd: directory}\n        );\n        if (extMatchesAll.length < 1 || extMatchesAll[0].split('/') < 1) {\n            throw new common.errors.ValidationError({message: common.i18n.t('errors.data.importer.index.invalidZipFileBaseDirectory')});\n        }\n\n        return extMatchesAll[0].split('/')[0];\n    }", "language": "javascript"}
{"input": "Normalizes the possible options for `linter.verify` and `linter.verifyAndFix` to a\nconsistent shape.\n@param {(string|{reportUnusedDisableDirectives: boolean, filename: string, allowInlineConfig: boolean})} providedOptions Options\n@returns {{reportUnusedDisableDirectives: boolean, filename: string, allowInlineConfig: boolean}} Normalized options", "output": "function normalizeVerifyOptions(providedOptions) {\n    const isObjectOptions = typeof providedOptions === \"object\";\n    const providedFilename = isObjectOptions ? providedOptions.filename : providedOptions;\n\n    return {\n        filename: typeof providedFilename === \"string\" ? providedFilename : \"<input>\",\n        allowInlineConfig: !isObjectOptions || providedOptions.allowInlineConfig !== false,\n        reportUnusedDisableDirectives: isObjectOptions && !!providedOptions.reportUnusedDisableDirectives\n    };\n}", "language": "javascript"}
{"input": "Read package version.\n@param {string} root\n@returns {string}", "output": "function readPackageVersion(root) {\n  let pkg = JSON.parse(fs.readFileSync(path.join(root, 'package.json'), 'utf8'));\n  // use _originalVersion if present if we've already mutated it\n  return pkg._originalVersion || pkg.version;\n}", "language": "javascript"}
{"input": "Round the fractional part of the given number", "output": "def _round_frac(x, precision):\n    \"\"\"\n    Round the fractional part of the given number\n    \"\"\"\n    if not np.isfinite(x) or x == 0:\n        return x\n    else:\n        frac, whole = np.modf(x)\n        if whole == 0:\n            digits = -int(np.floor(np.log10(abs(frac)))) - 1 + precision\n        else:\n            digits = precision\n        return np.around(x, digits)", "language": "python"}
{"input": "Takes a step in all environments.\n\n    Subclasses should override _step to do the actual reset if something other\n    than the default implementation is desired.\n\n    Args:\n      actions: Batch of actions.\n\n    Returns:\n      (preprocessed_observations, processed_rewards, dones, infos).", "output": "def step(self, actions):\n    \"\"\"Takes a step in all environments.\n\n    Subclasses should override _step to do the actual reset if something other\n    than the default implementation is desired.\n\n    Args:\n      actions: Batch of actions.\n\n    Returns:\n      (preprocessed_observations, processed_rewards, dones, infos).\n    \"\"\"\n\n    observations, raw_rewards, dones, infos = self._step(actions)\n\n    # Process rewards.\n    raw_rewards = raw_rewards.astype(np.float32)\n    processed_rewards = self.process_rewards(raw_rewards)\n\n    # Process observations.\n    processed_observations = self.process_observations(observations)\n\n    # Record history.\n    self.trajectories.step(processed_observations, raw_rewards,\n                           processed_rewards, dones, actions)\n\n    return processed_observations, processed_rewards, dones, infos", "language": "python"}
{"input": "Parses the input and returns an instance of this class.\n\n        :param string template_name: Name of the template\n        :param dict template_values_dict: Dictionary containing the value of the template. This dict must have passed\n            the JSON Schema validation.\n        :return Template: Instance of this class containing the values provided in this dictionary", "output": "def from_dict(template_name, template_values_dict):\n        \"\"\"\n        Parses the input and returns an instance of this class.\n\n        :param string template_name: Name of the template\n        :param dict template_values_dict: Dictionary containing the value of the template. This dict must have passed\n            the JSON Schema validation.\n        :return Template: Instance of this class containing the values provided in this dictionary\n        \"\"\"\n\n        parameters = template_values_dict.get(\"Parameters\", {})\n        definition = template_values_dict.get(\"Definition\", {})\n\n        return Template(template_name, parameters, definition)", "language": "python"}
{"input": "Basic conv model with L2 modality.", "output": "def next_frame_l2():\n  \"\"\"Basic conv model with L2 modality.\"\"\"\n  hparams = next_frame_basic_deterministic()\n  hparams.loss[\"targets\"] = modalities.video_l2_loss\n  hparams.top[\"targets\"] = modalities.video_l1_top\n  hparams.video_modality_loss_cutoff = 2.4\n  return hparams", "language": "python"}
{"input": "Returns Path object representing the user config resource", "output": "def _get_user_dir_path(self):\n        \"\"\"Returns Path object representing the user config resource\"\"\"\n        xdg_config_home = os.environ.get('XDG_CONFIG_HOME', '~/.config')\n        user_dir = Path(xdg_config_home, 'thefuck').expanduser()\n        legacy_user_dir = Path('~', '.thefuck').expanduser()\n\n        # For backward compatibility use legacy '~/.thefuck' if it exists:\n        if legacy_user_dir.is_dir():\n            warn(u'Config path {} is deprecated. Please move to {}'.format(\n                legacy_user_dir, user_dir))\n            return legacy_user_dir\n        else:\n            return user_dir", "language": "python"}
{"input": "For example:\n{\naxisPointer: {\nlinks: [{\nxAxisIndex: [2, 4],\nyAxisIndex: 'all'\n}, {\nxAxisId: ['a5', 'a7'],\nxAxisName: 'xxx'\n}]\n}\n}", "output": "function getLinkGroupIndex(linksOption, axis) {\n    var axisModel = axis.model;\n    var dim = axis.dim;\n    for (var i = 0; i < linksOption.length; i++) {\n        var linkOption = linksOption[i] || {};\n        if (checkPropInLink(linkOption[dim + 'AxisId'], axisModel.id)\n            || checkPropInLink(linkOption[dim + 'AxisIndex'], axisModel.componentIndex)\n            || checkPropInLink(linkOption[dim + 'AxisName'], axisModel.name)\n        ) {\n            return i;\n        }\n    }\n}", "language": "javascript"}
{"input": "@method makeOffsetPath\n\nreturn offsetPath(array of offset) from ancestor\n\n@param {Node} ancestor - ancestor node\n@param {Node} node", "output": "function makeOffsetPath(ancestor, node) {\n  const ancestors = listAncestor(node, func.eq(ancestor));\n  return ancestors.map(position).reverse();\n}", "language": "javascript"}
{"input": "Attempts a download of the latest installer, while cleaning up any existing downloaded installers", "output": "function attemptToDownload() {\n        if (checkIfOnline()) {\n            postMessageToNode(MessageIds.PERFORM_CLEANUP, ['.json'], true);\n        } else {\n            enableCheckForUpdateEntry(true);\n            UpdateStatus.cleanUpdateStatus();\n            HealthLogger.sendAnalyticsData(\n                autoUpdateEventNames.AUTOUPDATE_DOWNLOAD_FAILED,\n                \"autoUpdate\",\n                \"download\",\n                \"fail\",\n                \"No Internet connection available.\"\n            );\n            UpdateInfoBar.showUpdateBar({\n                type: \"warning\",\n                title: Strings.DOWNLOAD_FAILED,\n                description: Strings.INTERNET_UNAVAILABLE\n            });\n\n            setUpdateStateInJSON(\"autoUpdateInProgress\", false);\n        }\n    }", "language": "javascript"}
{"input": "Requests a URL, returning a promise.\n\n@param  {string} url       The URL we want to request\n@param  {object} [options] The options we want to pass to \"fetch\"\n@return {object}           An object containing either \"data\" or \"err\"", "output": "async function request(url, options) {\n  const response = await fetch(url, options);\n\n  checkStatus(response);\n\n  const data = await response.json();\n\n  const ret = {\n    data,\n    headers: {},\n  };\n\n  if (response.headers.get('x-total-count')) {\n    ret.headers['x-total-count'] = response.headers.get('x-total-count');\n  }\n\n  return ret;\n}", "language": "javascript"}
{"input": "@property {Boolean} [auto=false]\n@namespace options\n@for Uploader\n@description \u8bbe\u7f6e\u4e3a true \u540e\uff0c\u4e0d\u9700\u8981\u624b\u52a8\u8c03\u7528\u4e0a\u4f20\uff0c\u6709\u6587\u4ef6\u9009\u62e9\u5373\u5f00\u59cb\u4e0a\u4f20\u3002\n\n \n@method addFiles\n@grammar addFiles( file ) => undefined\n@grammar addFiles( [file1, file2 ...] ) => undefined\n@param {Array of File or File} [files] Files \u5bf9\u8c61 \u6570\u7ec4\n@description \u6dfb\u52a0\u6587\u4ef6\u5230\u961f\u5217\n@for  Uploader", "output": "function( files ) {\n                var me = this;\n    \n                if ( !files.length ) {\n                    files = [ files ];\n                }\n    \n                files = $.map( files, function( file ) {\n                    return me._addFile( file );\n                });\n    \n                me.owner.trigger( 'filesQueued', files );\n    \n                if ( me.options.auto ) {\n                    setTimeout(function() {\n                        me.request('start-upload');\n                    }, 20 );\n                }\n            }", "language": "javascript"}
{"input": "Saves the new language code provided in the language code input field.", "output": "function onSetLanguageCode() {\n  var languageCode = $('#language-code').val() || null;\n  try {\n    auth.languageCode = languageCode;\n    alertSuccess('Language code changed to \"' + languageCode + '\".');\n  } catch (error) {\n    alertError('Error: ' + error.code);\n  }\n}", "language": "javascript"}
{"input": "@private\nA unique key to log performance data\n\n@param {(string|undefined)} id Unique ID for this measurement name\n@param {!string} name A short name for this measurement\n@param {?number} reent Sequence identifier for parallel tests of the same name", "output": "function PerfMeasurement(id, name, reent) {\n        this.name = name;\n        this.reent = reent;\n        if (id) {\n            this.id = id;\n        } else {\n            this.id = (reent) ? \"[reent \" + this.reent + \"] \" + name : name;\n        }\n    }", "language": "javascript"}
{"input": "This is the common loop used inside expect. The 'searcher' should be\n        an instance of searcher_re or searcher_string, which describes how and\n        what to search for in the input.\n\n        See expect() for other arguments, return value and exceptions.", "output": "def expect_loop(self, searcher, timeout=-1, searchwindowsize=-1):\n        '''This is the common loop used inside expect. The 'searcher' should be\n        an instance of searcher_re or searcher_string, which describes how and\n        what to search for in the input.\n\n        See expect() for other arguments, return value and exceptions. '''\n\n        exp = Expecter(self, searcher, searchwindowsize)\n        return exp.expect_loop(timeout)", "language": "python"}
{"input": "Given a possibly complex data structure,\n    check if it has any torch.Tensors in it.", "output": "def has_tensor(obj) -> bool:\n    \"\"\"\n    Given a possibly complex data structure,\n    check if it has any torch.Tensors in it.\n    \"\"\"\n    if isinstance(obj, torch.Tensor):\n        return True\n    elif isinstance(obj, dict):\n        return any(has_tensor(value) for value in obj.values())\n    elif isinstance(obj, (list, tuple)):\n        return any(has_tensor(item) for item in obj)\n    else:\n        return False", "language": "python"}
{"input": "Create a tracked temporary directory.\n\n    This uses `TemporaryDirectory`, but does not remove the directory when\n    the return value goes out of scope, instead registers a handler to cleanup\n    on program exit.\n\n    The return value is the path to the created directory.", "output": "def create_tracked_tempdir(*args, **kwargs):\n    \"\"\"Create a tracked temporary directory.\n\n    This uses `TemporaryDirectory`, but does not remove the directory when\n    the return value goes out of scope, instead registers a handler to cleanup\n    on program exit.\n\n    The return value is the path to the created directory.\n    \"\"\"\n\n    tempdir = TemporaryDirectory(*args, **kwargs)\n    TRACKED_TEMPORARY_DIRECTORIES.append(tempdir)\n    atexit.register(tempdir.cleanup)\n    warnings.simplefilter(\"ignore\", ResourceWarning)\n    return tempdir.name", "language": "python"}
{"input": "Calculates the Total Flex Grow", "output": "function getTotalFlexGrow(columns) {\n    var totalFlexGrow = 0;\n    for (var _i = 0, columns_1 = columns; _i < columns_1.length; _i++) {\n        var c = columns_1[_i];\n        totalFlexGrow += c.flexGrow || 0;\n    }\n    return totalFlexGrow;\n}", "language": "javascript"}
{"input": "\u6587\u4ef6\u961f\u5217, \u7528\u6765\u5b58\u50a8\u5404\u4e2a\u72b6\u6001\u4e2d\u7684\u6587\u4ef6\u3002\n@class Queue\n@extends Mediator", "output": "function Queue() {\n    \n            /**\n             * \u7edf\u8ba1\u6587\u4ef6\u6570\u3002\n             * * `numOfQueue` \u961f\u5217\u4e2d\u7684\u6587\u4ef6\u6570\u3002\n             * * `numOfSuccess` \u4e0a\u4f20\u6210\u529f\u7684\u6587\u4ef6\u6570\n             * * `numOfCancel` \u88ab\u79fb\u9664\u7684\u6587\u4ef6\u6570\n             * * `numOfProgress` \u6b63\u5728\u4e0a\u4f20\u4e2d\u7684\u6587\u4ef6\u6570\n             * * `numOfUploadFailed` \u4e0a\u4f20\u9519\u8bef\u7684\u6587\u4ef6\u6570\u3002\n             * * `numOfInvalid` \u65e0\u6548\u7684\u6587\u4ef6\u6570\u3002\n             * @property {Object} stats\n             */\n            this.stats = {\n                numOfQueue: 0,\n                numOfSuccess: 0,\n                numOfCancel: 0,\n                numOfProgress: 0,\n                numOfUploadFailed: 0,\n                numOfInvalid: 0\n            };\n    \n            // \u4e0a\u4f20\u961f\u5217\uff0c\u4ec5\u5305\u62ec\u7b49\u5f85\u4e0a\u4f20\u7684\u6587\u4ef6\n            this._queue = [];\n    \n            // \u5b58\u50a8\u6240\u6709\u6587\u4ef6\n            this._map = {};\n        }", "language": "javascript"}
{"input": "Writes the step HTML into the rendermanger", "output": "function(rm, oRoadMap, oStep, aAdditionalClasses, fAddAdditionalBoxContent, sId){\n\t\trm.write(\"<li\");\n\t\tif (sId) { //Write the given Id if available, otherwise use writeControlData\n\t\t\trm.writeAttribute(\"id\", sId);\n\t\t} else {\n\t\t\trm.writeElementData(oStep);\n\t\t}\n\t\tvar sStepName = getStepName(oRoadMap, oStep);\n\t\toStep.__stepName = sStepName;\n\t\tvar sTooltip = getStepTooltip(oStep);\n\n\t\trm.addClass(\"sapUiRoadMapContent\");\n\t\trm.addClass(\"sapUiRoadMapStep\");\n\t\tif (!oStep.getVisible()) {\n\t\t\trm.addClass(\"sapUiRoadMapHidden\");\n\t\t}\n\t\tif (oStep.getEnabled()) {\n\t\t\tif (oRoadMap.getSelectedStep() == oStep.getId()) {\n\t\t\t\trm.addClass(\"sapUiRoadMapSelected\");\n\t\t\t}\n\t\t} else {\n\t\t\trm.addClass(\"sapUiRoadMapDisabled\");\n\t\t}\n\t\tif (aAdditionalClasses) { //Write additional CSS classes if available\n\t\t\tfor (var i = 0; i < aAdditionalClasses.length; i++) {\n\t\t\t\trm.addClass(aAdditionalClasses[i]);\n\t\t\t}\n\t\t}\n\t\trm.writeClasses();\n\n\t\trm.write(\">\");\n\n\t\trenderAdditionalStyleElem(rm, sId ? sId : oStep.getId(), 1);\n\n\t\trm.write(\"<div\");\n\t\trm.writeAttribute(\"id\", (sId ? sId : oStep.getId()) + \"-box\");\n\t\trm.writeAttribute(\"tabindex\", \"-1\");\n\t\trm.addClass(\"sapUiRoadMapStepBox\");\n\t\trm.writeClasses();\n\t\trm.writeAttributeEscaped(\"title\", sTooltip);\n\n\t\twriteStepAria(rm, oRoadMap, oStep, fAddAdditionalBoxContent ? true : false);\n\n\t\trm.write(\"><span>\");\n\t\trm.write(sStepName);\n\t\trm.write(\"</span>\");\n\n\t\t//Call callback function to render additional content\n\t\tif (fAddAdditionalBoxContent) {\n\t\t\tfAddAdditionalBoxContent(rm, oRoadMap, oStep);\n\t\t}\n\n\t\trm.write(\"</div>\");\n\n\t\trm.write(\"<label\");\n\t\trm.writeAttribute(\"id\", (sId ? sId : oStep.getId()) + \"-label\");\n\t\trm.addClass(\"sapUiRoadMapTitle\");\n\t\trm.writeAttributeEscaped(\"title\", sTooltip);\n\t\trm.writeClasses();\n\t\trm.write(\">\");\n\t\tvar sLabel = oStep.getLabel();\n\t\tif (sLabel) {\n\t\t\trm.writeEscaped(sLabel);\n\t\t}\n\t\trm.write(\"</label>\");\n\n\t\trenderAdditionalStyleElem(rm, sId ? sId : oStep.getId(), 2);\n\n\t\trm.write(\"</li>\");\n\t}", "language": "javascript"}
{"input": "Use py_func to yield elements from the given generator.", "output": "def make_input_fn_from_generator(gen):\n  \"\"\"Use py_func to yield elements from the given generator.\"\"\"\n  first_ex = six.next(gen)\n  flattened = tf.contrib.framework.nest.flatten(first_ex)\n  types = [t.dtype for t in flattened]\n  shapes = [[None] * len(t.shape) for t in flattened]\n  first_ex_list = [first_ex]\n\n  def py_func():\n    if first_ex_list:\n      example = first_ex_list.pop()\n    else:\n      example = six.next(gen)\n    return tf.contrib.framework.nest.flatten(example)\n\n  def input_fn():\n    flat_example = tf.py_func(py_func, [], types)\n    _ = [t.set_shape(shape) for t, shape in zip(flat_example, shapes)]\n    example = tf.contrib.framework.nest.pack_sequence_as(first_ex, flat_example)\n    return example\n\n  return input_fn", "language": "python"}
{"input": "Export cached remote functions\n\n        Note: this should be called only once when worker is connected.", "output": "def export_cached(self):\n        \"\"\"Export cached remote functions\n\n        Note: this should be called only once when worker is connected.\n        \"\"\"\n        for remote_function in self._functions_to_export:\n            self._do_export(remote_function)\n        self._functions_to_export = None\n        for info in self._actors_to_export:\n            (key, actor_class_info) = info\n            self._publish_actor_class_to_key(key, actor_class_info)", "language": "python"}
{"input": "dump the values into disk", "output": "def _spill(self):\n        \"\"\" dump the values into disk \"\"\"\n        global MemoryBytesSpilled, DiskBytesSpilled\n        if self._file is None:\n            self._open_file()\n\n        used_memory = get_used_memory()\n        pos = self._file.tell()\n        self._ser.dump_stream(self.values, self._file)\n        self.values = []\n        gc.collect()\n        DiskBytesSpilled += self._file.tell() - pos\n        MemoryBytesSpilled += max(used_memory - get_used_memory(), 0) << 20", "language": "python"}
{"input": "Start the collector worker thread.\n\n        If running in standalone mode, the current thread will wait\n        until the collector thread ends.", "output": "def run(self):\n        \"\"\"Start the collector worker thread.\n\n        If running in standalone mode, the current thread will wait\n        until the collector thread ends.\n        \"\"\"\n        self.collector.start()\n        if self.standalone:\n            self.collector.join()", "language": "python"}
{"input": "Gets column info from the source system", "output": "def external_metadata(self, datasource_type=None, datasource_id=None):\n        \"\"\"Gets column info from the source system\"\"\"\n        if datasource_type == 'druid':\n            datasource = ConnectorRegistry.get_datasource(\n                datasource_type, datasource_id, db.session)\n        elif datasource_type == 'table':\n            database = (\n                db.session\n                .query(Database)\n                .filter_by(id=request.args.get('db_id'))\n                .one()\n            )\n            Table = ConnectorRegistry.sources['table']\n            datasource = Table(\n                database=database,\n                table_name=request.args.get('table_name'),\n                schema=request.args.get('schema') or None,\n            )\n        external_metadata = datasource.external_metadata()\n        return self.json_response(external_metadata)", "language": "python"}
{"input": "Try to find the most capable encoding supported by the console.\n    slightly modified from the way IPython handles the same issue.", "output": "def detect_console_encoding():\n    \"\"\"\n    Try to find the most capable encoding supported by the console.\n    slightly modified from the way IPython handles the same issue.\n    \"\"\"\n    global _initial_defencoding\n\n    encoding = None\n    try:\n        encoding = sys.stdout.encoding or sys.stdin.encoding\n    except (AttributeError, IOError):\n        pass\n\n    # try again for something better\n    if not encoding or 'ascii' in encoding.lower():\n        try:\n            encoding = locale.getpreferredencoding()\n        except Exception:\n            pass\n\n    # when all else fails. this will usually be \"ascii\"\n    if not encoding or 'ascii' in encoding.lower():\n        encoding = sys.getdefaultencoding()\n\n    # GH#3360, save the reported defencoding at import time\n    # MPL backends may change it. Make available for debugging.\n    if not _initial_defencoding:\n        _initial_defencoding = sys.getdefaultencoding()\n\n    return encoding", "language": "python"}
{"input": "Valid timings are all timings which are completed, not empty and not responded from browser cache.\n\nNote: Currently only Chrome and FF support size related properties (body size and transfer size),\nhence the requests of others not supporting them are counted as complete (in dubio pro reo), as\nbefore.\n\n@param {object} oRequestTiming\n@private", "output": "function isValidRoundtrip(oRequestTiming) {\n\t\tvar bComplete, bEmpty, bCached;\n\n\t\t// if the request has been completed it has complete timing figures)\n\t\tbComplete = oRequestTiming.startTime > 0 &&\n\t\t\toRequestTiming.startTime <= oRequestTiming.requestStart &&\n\t\t\toRequestTiming.requestStart <= oRequestTiming.responseEnd;\n\n\t\t// encodedBodySize and transferSize info are not available in all browsers\n\t\tif (oRequestTiming.encodedBodySize !== undefined && oRequestTiming.transferSize !== undefined) {\n\t\t\t// if the body is empty a script tag responded from cache is assumed\n\t\t\tbEmpty = oRequestTiming.encodedBodySize ===  0;\n\t\t\t// if transfer size is smaller than body an xhr responded from cache is assumed\n\t\t\tbCached = oRequestTiming.transferSize < oRequestTiming.encodedBodySize;\n\t\t}\n\n\t\treturn bComplete && !bEmpty && !bCached;\n\t}", "language": "javascript"}
{"input": "Return a new free identifier as :class:`~jinja2.nodes.InternalName`.", "output": "def free_identifier(self, lineno=None):\n        \"\"\"Return a new free identifier as :class:`~jinja2.nodes.InternalName`.\"\"\"\n        self._last_identifier += 1\n        rv = object.__new__(nodes.InternalName)\n        nodes.Node.__init__(rv, 'fi%d' % self._last_identifier, lineno=lineno)\n        return rv", "language": "python"}
{"input": "builds the root namespace with a given base ID and project ID for the following scenarios:\nApp Variants, adaptation project, adapting new fiori elements app and UI adaptation\n\n@param {string} sBaseId base ID\n@param {string} sScenario current scenario\n@param {string} sProjectId project ID\n@returns {string} Returns the root LRep namespace", "output": "function(sBaseId, sScenario, sProjectId) {\n\t\t\tvar sRootNamespace = \"apps/\";\n\t\t\tvar oError = new Error(\"Error in sap.ui.fl.Utils#buildLrepRootNamespace: \");\n\t\t\tif (!sBaseId) {\n\t\t\t\toError.message += \"for every scenario you need a base ID\";\n\t\t\t\tthrow oError;\n\t\t\t}\n\n\t\t\tswitch (sScenario) {\n\t\t\t\tcase sap.ui.fl.Scenario.VersionedAppVariant:\n\t\t\t\t\tif (!sProjectId) {\n\t\t\t\t\t\toError.message += \"in a versioned app variant scenario you additionally need a project ID\";\n\t\t\t\t\t\tthrow oError;\n\t\t\t\t\t}\n\t\t\t\t\tsRootNamespace += sBaseId + \"/appVariants/\" + sProjectId + \"/\";\n\t\t\t\t\tbreak;\n\t\t\t\tcase sap.ui.fl.Scenario.AppVariant:\n\t\t\t\t\tif (!sProjectId) {\n\t\t\t\t\t\toError.message += \"in an app variant scenario you additionally need a project ID\";\n\t\t\t\t\t\tthrow oError;\n\t\t\t\t\t}\n\t\t\t\t\tsRootNamespace += sBaseId + \"/appVariants/\" + sProjectId + \"/\";\n\t\t\t\t\tbreak;\n\t\t\t\tcase sap.ui.fl.Scenario.AdaptationProject:\n\t\t\t\t\tif (!sProjectId) {\n\t\t\t\t\t\toError.message += \"in a adaptation project scenario you additionally need a project ID\";\n\t\t\t\t\t\tthrow oError;\n\t\t\t\t\t}\n\t\t\t\t\tsRootNamespace += sBaseId + \"/adapt/\" + sProjectId + \"/\";\n\t\t\t\t\tbreak;\n\t\t\t\tcase sap.ui.fl.Scenario.FioriElementsFromScratch:\n\t\t\t\tcase sap.ui.fl.Scenario.UiAdaptation:\n\t\t\t\tdefault:\n\t\t\t\t\tsRootNamespace += sBaseId + \"/\";\n\t\t\t}\n\n\t\t\treturn sRootNamespace;\n\t\t}", "language": "javascript"}
{"input": "Calculate accuracy.", "output": "def accuracy(batch, model_predictions):\n  \"\"\"Calculate accuracy.\"\"\"\n  _, targets = batch\n  model_predictions, targets = _make_list(model_predictions, targets)\n  correct = []\n  for (prediction, target) in zip(model_predictions, targets):\n    predicted_class = np.argmax(prediction, axis=-1)\n    correct.append(np.equal(predicted_class, target))\n  return masked_mean(correct, targets)", "language": "python"}
{"input": "bar length can be negative.", "output": "function prepareBarLength(itemModel, symbolRepeat, layout, opt, output) {\n    var valueDim = opt.valueDim;\n    var symbolBoundingData = itemModel.get('symbolBoundingData');\n    var valueAxis = opt.coordSys.getOtherAxis(opt.coordSys.getBaseAxis());\n    var zeroPx = valueAxis.toGlobalCoord(valueAxis.dataToCoord(0));\n    var pxSignIdx = 1 - +(layout[valueDim.wh] <= 0);\n    var boundingLength;\n\n    if (zrUtil.isArray(symbolBoundingData)) {\n        var symbolBoundingExtent = [\n            convertToCoordOnAxis(valueAxis, symbolBoundingData[0]) - zeroPx,\n            convertToCoordOnAxis(valueAxis, symbolBoundingData[1]) - zeroPx\n        ];\n        symbolBoundingExtent[1] < symbolBoundingExtent[0] && (symbolBoundingExtent.reverse());\n        boundingLength = symbolBoundingExtent[pxSignIdx];\n    }\n    else if (symbolBoundingData != null) {\n        boundingLength = convertToCoordOnAxis(valueAxis, symbolBoundingData) - zeroPx;\n    }\n    else if (symbolRepeat) {\n        boundingLength = opt.coordSysExtent[valueDim.index][pxSignIdx] - zeroPx;\n    }\n    else {\n        boundingLength = layout[valueDim.wh];\n    }\n\n    output.boundingLength = boundingLength;\n\n    if (symbolRepeat) {\n        output.repeatCutLength = layout[valueDim.wh];\n    }\n\n    output.pxSign = boundingLength > 0 ? 1 : boundingLength < 0 ? -1 : 0;\n}", "language": "javascript"}
{"input": "Init the chart\n@override\n@param  {module:echarts/model/Global} ecModel\n@param  {module:echarts/ExtensionAPI} api", "output": "function (ecModel, api) {\n\n        /**\n         * @private\n         * @type {module:echarts/data/Tree}\n         */\n        this._oldTree;\n\n        /**\n         * @private\n         * @type {module:zrender/container/Group}\n         */\n        this._mainGroup = new graphic.Group();\n\n        /**\n         * @private\n         * @type {module:echarts/componet/helper/RoamController}\n         */\n        this._controller = new RoamController(api.getZr());\n\n        this._controllerHost = {target: this.group};\n\n        this.group.add(this._mainGroup);\n    }", "language": "javascript"}
{"input": "Parse the repository URL to use, and return the URL, revision,\n        and auth info to use.\n\n        Returns: (url, rev, (username, password)).", "output": "def get_url_rev_and_auth(self, url):\n        # type: (str) -> Tuple[str, Optional[str], AuthInfo]\n        \"\"\"\n        Parse the repository URL to use, and return the URL, revision,\n        and auth info to use.\n\n        Returns: (url, rev, (username, password)).\n        \"\"\"\n        scheme, netloc, path, query, frag = urllib_parse.urlsplit(url)\n        if '+' not in scheme:\n            raise ValueError(\n                \"Sorry, {!r} is a malformed VCS url. \"\n                \"The format is <vcs>+<protocol>://<url>, \"\n                \"e.g. svn+http://myrepo/svn/MyApp#egg=MyApp\".format(url)\n            )\n        # Remove the vcs prefix.\n        scheme = scheme.split('+', 1)[1]\n        netloc, user_pass = self.get_netloc_and_auth(netloc, scheme)\n        rev = None\n        if '@' in path:\n            path, rev = path.rsplit('@', 1)\n        url = urllib_parse.urlunsplit((scheme, netloc, path, query, ''))\n        return url, rev, user_pass", "language": "python"}
{"input": "FAB leaves faulty permissions that need to be cleaned up", "output": "def clean_perms(self):\n        \"\"\"FAB leaves faulty permissions that need to be cleaned up\"\"\"\n        logging.info('Cleaning faulty perms')\n        sesh = self.get_session\n        pvms = (\n            sesh.query(ab_models.PermissionView)\n            .filter(or_(\n                ab_models.PermissionView.permission == None,  # NOQA\n                ab_models.PermissionView.view_menu == None,  # NOQA\n            ))\n        )\n        deleted_count = pvms.delete()\n        sesh.commit()\n        if deleted_count:\n            logging.info('Deleted {} faulty permissions'.format(deleted_count))", "language": "python"}
{"input": "Base params for img2img 2d attention.", "output": "def img2img_transformer2d_base():\n  \"\"\"Base params for img2img 2d attention.\"\"\"\n  hparams = image_transformer2d_base()\n  # learning related flags\n  hparams.layer_preprocess_sequence = \"n\"\n  hparams.layer_postprocess_sequence = \"da\"\n  # This version seems to benefit from a higher learning rate.\n  hparams.learning_rate = 0.2\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.learning_rate_warmup_steps = 12000\n  hparams.filter_size = 2048\n  hparams.num_encoder_layers = 4\n  hparams.num_decoder_layers = 8\n  hparams.bottom[\"inputs\"] = modalities.image_channel_embeddings_bottom\n  hparams.dec_attention_type = cia.AttentionType.LOCAL_2D\n  hparams.block_raster_scan = True\n  return hparams", "language": "python"}
{"input": "render all the collected items in the chunk and flush them into the DOM vInsert whether to append (true) or replace (falsy) or to insert at a certain position (int)", "output": "function(vInsert, oDomRef) {\n\t\t\tthis.applyPendingGroupItem();\n\n\t\t\tvar iLength = this._aChunk.length;\n\t\t\tif (!iLength) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (this._oControl.getGrowingDirection() == ListGrowingDirection.Upwards) {\n\t\t\t\tthis._aChunk.reverse();\n\t\t\t\tif (vInsert === true) {\n\t\t\t\t\tvInsert = 0;\n\t\t\t\t} else if (typeof vInsert == \"number\") {\n\t\t\t\t\tvInsert = this._iRenderedDataItems - iLength - vInsert;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\toDomRef = oDomRef || this._oContainerDomRef;\n\t\t\tthis._oRM = this._oRM || sap.ui.getCore().createRenderManager();\n\n\t\t\tfor (var i = 0; i < iLength; i++) {\n\t\t\t\tthis._oRM.renderControl(this._aChunk[i]);\n\t\t\t}\n\n\t\t\tthis._oRM.flush(oDomRef, false, this._getDomIndex(vInsert));\n\t\t\tthis._aChunk = [];\n\t\t}", "language": "javascript"}
{"input": "Check whether a node returns in every codepath.\n@param {Node} node The node to be checked\n@returns {boolean} `true` if it returns on every codepath.", "output": "function alwaysReturns(node) {\n            if (node.type === \"BlockStatement\") {\n\n                // If we have a BlockStatement, check each consequent body node.\n                return node.body.some(checkForReturnOrIf);\n            }\n\n            /*\n             * If not a block statement, make sure the consequent isn't a\n             * ReturnStatement or an IfStatement with returns on both paths.\n             */\n            return checkForReturnOrIf(node);\n        }", "language": "javascript"}
{"input": "Get the real native browser event from a jQuery event object", "output": "function(oEvent) {\n\t\t\twhile (oEvent && oEvent.originalEvent && oEvent !== oEvent.originalEvent) {\n\t\t\t\toEvent = oEvent.originalEvent;\n\t\t\t}\n\t\t\treturn oEvent;\n\t\t}", "language": "javascript"}
{"input": "converts a style_dict to an openpyxl style object\n        Parameters\n        ----------\n        style_dict : style dictionary to convert", "output": "def _convert_to_style(cls, style_dict):\n        \"\"\"\n        converts a style_dict to an openpyxl style object\n        Parameters\n        ----------\n        style_dict : style dictionary to convert\n        \"\"\"\n\n        from openpyxl.style import Style\n        xls_style = Style()\n        for key, value in style_dict.items():\n            for nk, nv in value.items():\n                if key == \"borders\":\n                    (xls_style.borders.__getattribute__(nk)\n                     .__setattr__('border_style', nv))\n                else:\n                    xls_style.__getattribute__(key).__setattr__(nk, nv)\n\n        return xls_style", "language": "python"}
{"input": "Creates a copy of this instance with a randomly generated uid\n        and some extra params. This copies creates a deep copy of\n        the embedded paramMap, and copies the embedded and extra parameters over.\n\n        :param extra: Extra parameters to copy to the new instance\n        :return: Copy of this instance", "output": "def copy(self, extra=None):\n        \"\"\"\n        Creates a copy of this instance with a randomly generated uid\n        and some extra params. This copies creates a deep copy of\n        the embedded paramMap, and copies the embedded and extra parameters over.\n\n        :param extra: Extra parameters to copy to the new instance\n        :return: Copy of this instance\n        \"\"\"\n        if extra is None:\n            extra = dict()\n        newTVS = Params.copy(self, extra)\n        if self.isSet(self.estimator):\n            newTVS.setEstimator(self.getEstimator().copy(extra))\n        # estimatorParamMaps remain the same\n        if self.isSet(self.evaluator):\n            newTVS.setEvaluator(self.getEvaluator().copy(extra))\n        return newTVS", "language": "python"}
{"input": "When evaluating a function call, we either find the function in `tree.functions` [1], in which case we call it, passing the  evaluated arguments, if this returns null or we cannot find the function, we simply print it out as it appeared originally [2].  The *functions.js* file contains the built-in functions.  The reason why we evaluate the arguments, is in the case where we try to pass a variable to a function, like: `saturate(@color)`. The function should receive the value, not the variable.", "output": "function (env) {\n        var args = this.args.map(function (a) { return a.eval(env); }),\n            nameLC = this.name.toLowerCase(),\n            result, func;\n\n        if (nameLC in tree.functions) { // 1.\n            try {\n                func = new tree.functionCall(env, this.currentFileInfo);\n                result = func[nameLC].apply(func, args);\n                if (result != null) {\n                    return result;\n                }\n            } catch (e) {\n                throw { type: e.type || \"Runtime\",\n                        message: \"error evaluating function `\" + this.name + \"`\" +\n                                 (e.message ? ': ' + e.message : ''),\n                        index: this.index, filename: this.currentFileInfo.filename };\n            }\n        }\n\n        return new tree.Call(this.name, args, this.index, this.currentFileInfo);\n    }", "language": "javascript"}
{"input": "Loads the given name (or [name, options] pair) from the given table object\nholding the available presets or plugins.\n\nReturns undefined if the preset or plugin is not available; passes through\nname unmodified if it (or the first element of the pair) is not a string.", "output": "function loadBuiltin(builtinTable, name) {\n  if (isArray(name) && typeof name[0] === \"string\") {\n    if (builtinTable.hasOwnProperty(name[0])) {\n      return [builtinTable[name[0]]].concat(name.slice(1));\n    }\n    return;\n  } else if (typeof name === \"string\") {\n    return builtinTable[name];\n  }\n  // Could be an actual preset/plugin module\n  return name;\n}", "language": "javascript"}
{"input": "Deletes the current line if there is no selection or the lines for the selection\n(removing the end of line too)", "output": "function deleteCurrentLines(editor) {\n        editor = editor || EditorManager.getFocusedEditor();\n        if (!editor) {\n            return;\n        }\n\n        // Walk the selections, calculating the deletion edits we need to do as we go;\n        // document.doMultipleEdits() will take care of adjusting the edit locations when\n        // it actually performs the edits.\n        var doc = editor.document,\n            from,\n            to,\n            lineSelections = editor.convertToLineSelections(editor.getSelections()),\n            edits = [];\n\n        _.each(lineSelections, function (lineSel, index) {\n            var sel = lineSel.selectionForEdit;\n\n            from = sel.start;\n            to = sel.end; // this is already at the beginning of the line after the last selected line\n            if (to.line === editor.getLastVisibleLine() + 1) {\n                // Instead of deleting the newline after the last line, delete the newline\n                // before the beginning of the line--unless this is the entire visible content\n                // of the editor, in which case just delete the line content.\n                if (from.line > editor.getFirstVisibleLine()) {\n                    from.line -= 1;\n                    from.ch = doc.getLine(from.line).length;\n                }\n                to.line -= 1;\n                to.ch = doc.getLine(to.line).length;\n            }\n\n            // We don't need to track the original selections, since they'll get collapsed as\n            // part of the various deletions that occur.\n            edits.push({edit: {text: \"\", start: from, end: to}});\n        });\n        doc.doMultipleEdits(edits);\n    }", "language": "javascript"}
{"input": "return the length of a single non-tuple indexer which could be a slice", "output": "def length_of_indexer(indexer, target=None):\n    \"\"\"\n    return the length of a single non-tuple indexer which could be a slice\n    \"\"\"\n    if target is not None and isinstance(indexer, slice):\n        target_len = len(target)\n        start = indexer.start\n        stop = indexer.stop\n        step = indexer.step\n        if start is None:\n            start = 0\n        elif start < 0:\n            start += target_len\n        if stop is None or stop > target_len:\n            stop = target_len\n        elif stop < 0:\n            stop += target_len\n        if step is None:\n            step = 1\n        elif step < 0:\n            step = -step\n        return (stop - start + step - 1) // step\n    elif isinstance(indexer, (ABCSeries, Index, np.ndarray, list)):\n        return len(indexer)\n    elif not is_list_like_indexer(indexer):\n        return 1\n    raise AssertionError(\"cannot find the length of the indexer\")", "language": "python"}
{"input": "Create a new `OptimWrapper` from `self` with another `layer_groups` but the same hyper-parameters.", "output": "def new_with_params(self, param_groups:Collection[Collection[nn.Parameter]]):\n        \"Create a new `OptimWrapper` from `self` with another `layer_groups` but the same hyper-parameters.\"\n        opt_func = getattr(self, 'opt_func', self.opt.__class__)\n        opt = opt_func([{'params': p, 'lr':0} for p in param_groups])\n        opt = self.__class__(opt, wd=self.wd, true_wd=self.true_wd, bn_wd=self.bn_wd)\n        opt.lr,opt.opt_func,opt.mom,opt.beta = self.lr,opt_func,self.mom,self.beta\n        return opt", "language": "python"}
{"input": "Build an enum object\n@param {any} field : entity field\n@param {string} angularAppName\n@param {string} packageName", "output": "function buildEnumInfo(field, angularAppName, packageName, clientRootFolder) {\n    const fieldType = field.fieldType;\n    field.enumInstance = _.lowerFirst(fieldType);\n    const enumInfo = {\n        enumName: fieldType,\n        enumValues: field.fieldValues.split(',').join(', '),\n        enumInstance: field.enumInstance,\n        enums: field.fieldValues.replace(/\\s/g, '').split(','),\n        angularAppName,\n        packageName,\n        clientRootFolder: clientRootFolder ? `${clientRootFolder}-` : ''\n    };\n    return enumInfo;\n}", "language": "javascript"}
{"input": "Lift all extensions from the <a href=\"http://www.sap.com/Protocols/SAPData\"> SAP\nAnnotations for OData Version 2.0</a> namespace up as attributes with \"sap:\" prefix.\n\n@param {object} o\nany object\n@param {string} sTypeClass\nthe type class of the given object; supported type classes are \"Property\" and\n\"EntitySet\"", "output": "function (o, sTypeClass) {\n\t\t\tif (!o.extensions) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\to.extensions.forEach(function (oExtension) {\n\t\t\t\tif (oExtension.namespace === \"http://www.sap.com/Protocols/SAPData\") {\n\t\t\t\t\to[\"sap:\" + oExtension.name] = oExtension.value;\n\t\t\t\t\tUtils.addV4Annotation(o, oExtension, sTypeClass);\n\t\t\t\t}\n\t\t\t});\n\t\t\t// after all SAP V2 annotations are lifted up add V4 annotations that are calculated\n\t\t\t// by multiple V2 annotations or that have a different default value\n\t\t\tswitch (sTypeClass) {\n\t\t\t\tcase \"Property\":\n\t\t\t\t\tif (o[\"sap:updatable\"] === \"false\") {\n\t\t\t\t\t\tif (o[\"sap:creatable\"] === \"false\") {\n\t\t\t\t\t\t\to[\"Org.OData.Core.V1.Computed\"] = oBoolTrue;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\to[\"Org.OData.Core.V1.Immutable\"] = oBoolTrue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase \"EntitySet\":\n\t\t\t\t\tif (o[\"sap:searchable\"] !== \"true\") {\n\t\t\t\t\t\to[\"Org.OData.Capabilities.V1.SearchRestrictions\"] =\n\t\t\t\t\t\t\t{ \"Searchable\" : oBoolFalse };\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t// nothing to do\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Use the id of the ManagedObject instance as the unique key to identify\nthe entry in the extended change detection. The default implementation\nin the parent class which uses JSON.stringify to serialize the instance\ndoesn't fit here because none of the ManagedObject instance can be\nSerialized.\n\n@param {sap.ui.model.Context} oContext the binding context object\n@return {string} The identifier used for diff comparison\n@see sap.ui.model.ListBinding.prototype.getEntryData", "output": "function(oContext) {\n\t\t\t// use the id of the ManagedObject instance as the identifier\n\t\t\t// for the extended change detection\n\t\t\tvar oObject = oContext.getObject();\n\t\t\tif (oObject instanceof  ManagedObject) {\n\t\t\t\treturn oObject.getId();\n\t\t\t}\n\n\t\t\treturn JSONListBinding.prototype.getEntryKey.apply(this, arguments);\n\t\t}", "language": "javascript"}
{"input": "Register a language handler for the given file extensions.\n@param {function (JobT)} handler a function from source code to a list\nof decorations.  Takes a single argument job which describes the\nstate of the computation and attaches the decorations to it.\n@param {Array.<string>} fileExtensions", "output": "function registerLangHandler(handler, fileExtensions) {\n    for (var i = fileExtensions.length; --i >= 0;) {\n      var ext = fileExtensions[i];\n      if (!langHandlerRegistry.hasOwnProperty(ext)) {\n        langHandlerRegistry[ext] = handler;\n      } else if (win['console']) {\n        console['warn']('cannot override language handler %s', ext);\n      }\n    }\n  }", "language": "javascript"}
{"input": "Returns the type for creating enum members, and the first inherited\n        enum class.\n\n        bases: the tuple of bases that was given to __new__", "output": "def _get_mixins_(bases):\n        \"\"\"Returns the type for creating enum members, and the first inherited\n        enum class.\n\n        bases: the tuple of bases that was given to __new__\n\n        \"\"\"\n        if not bases or Enum is None:\n            return object, Enum\n\n\n        # double check that we are not subclassing a class with existing\n        # enumeration members; while we're at it, see if any other data\n        # type has been mixed in so we can use the correct __new__\n        member_type = first_enum = None\n        for base in bases:\n            if  (base is not Enum and\n                    issubclass(base, Enum) and\n                    base._member_names_):\n                raise TypeError(\"Cannot extend enumerations\")\n        # base is now the last base in bases\n        if not issubclass(base, Enum):\n            raise TypeError(\"new enumerations must be created as \"\n                    \"`ClassName([mixin_type,] enum_type)`\")\n\n        # get correct mix-in type (either mix-in type of Enum subclass, or\n        # first base if last base is Enum)\n        if not issubclass(bases[0], Enum):\n            member_type = bases[0]     # first data type\n            first_enum = bases[-1]  # enum type\n        else:\n            for base in bases[0].__mro__:\n                # most common: (IntEnum, int, Enum, object)\n                # possible:    (<Enum 'AutoIntEnum'>, <Enum 'IntEnum'>,\n                #               <class 'int'>, <Enum 'Enum'>,\n                #               <class 'object'>)\n                if issubclass(base, Enum):\n                    if first_enum is None:\n                        first_enum = base\n                else:\n                    if member_type is None:\n                        member_type = base\n\n        return member_type, first_enum", "language": "python"}
{"input": "based on our axes, compute the expected nrows", "output": "def nrows_expected(self):\n        \"\"\" based on our axes, compute the expected nrows \"\"\"\n        return np.prod([i.cvalues.shape[0] for i in self.index_axes])", "language": "python"}
{"input": "Returns a map of libraries - either exactly those requested in aLibrariesToTest, if defined, or all discoverable libraries\nunder the given conditions.", "output": "function(aLibrariesToTest, aExcludedLibraries, bIncludeDistLayer, QUnit) {\n\t\tvar mLibraries = aLibrariesToTest ?\n\t\t\t\tgetRequestedLibraries(aLibrariesToTest)\n\t\t\t\t:\n\t\t\t\tgetAllLibraries(aExcludedLibraries, bIncludeDistLayer);\n\n\t\tQUnit.test(\"Should load at least one library and some controls\", function(assert) {\n\t\t\tassert.expect(2);\n\n\t\t\tvar bLibFound = false;\n\n\t\t\tfor (var sLibName in mLibraries) {\n\t\t\t\tif (mLibraries[sLibName]) {\n\t\t\t\t\tif (!bLibFound) {\n\t\t\t\t\t\tassert.ok(mLibraries[sLibName], \"Should have loaded at least one library\");\n\t\t\t\t\t\tbLibFound = true;\n\t\t\t\t\t}\n\t\t\t\t\tvar iControls = mLibraries[sLibName].controls ? mLibraries[sLibName].controls.length : 0;\n\t\t\t\t\tif (iControls > 0) {\n\t\t\t\t\t\tassert.ok(iControls > 0, \"Should find at least 10 controls in a library\");\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t\treturn mLibraries;\n\t}", "language": "javascript"}
{"input": "/*\nclear content before delete panel", "output": "function _deletePanel( oPanel, bDestroyLayout ) {\n\n\t\toPanel.setLayout(null);\n\t\toPanel.setContainer(null);\n\n\t\tif (!bDestroyLayout || !oPanel.getParent()) {\n\t\t\t// if in real control tree let the ManagedObject logic destroy the children\n\t\t\toPanel.setContent(null);\n\t\t\toPanel.destroy();\n\t\t}\n\n\t}", "language": "javascript"}
{"input": "Get separate embedding for each of the channels.", "output": "def get_channel_embeddings(io_depth, targets, hidden_size, name=\"channel\"):\n  \"\"\"Get separate embedding for each of the channels.\"\"\"\n  targets_split = tf.split(targets, io_depth, axis=3)\n  rgb_embedding_var = tf.get_variable(\"rgb_target_emb_%s\" % name,\n                                      [256 * io_depth, hidden_size])\n  rgb_embedding_var = tf.identity(rgb_embedding_var)\n  rgb_embedding_var *= float(hidden_size)**0.5\n  channel_target_embs = []\n  for i in range(io_depth):\n    # Adding the channel offsets to get the right embedding since the\n    # embedding tensor has shape 256 * io_depth, hidden_size\n    target_ids = tf.squeeze(targets_split[i], axis=3) + i * 256\n    target_embs = common_layers.gather(rgb_embedding_var, target_ids)\n    channel_target_embs.append(target_embs)\n\n  return tf.concat(channel_target_embs, axis=-1)", "language": "python"}
{"input": "Spawn a command and invoke the callback when it completes with an error and the output from standard out.", "output": "function (args, detached, callback) {\n  let error, errorEmitted, stderr, stdout\n\n  try {\n    // Ensure we don't spawn multiple squirrel processes\n    // Process spawned, same args:        Attach events to alread running process\n    // Process spawned, different args:   Return with error\n    // No process spawned:                Spawn new process\n    if (spawnedProcess && !isSameArgs(args)) {\n      // Disabled for backwards compatibility:\n      // eslint-disable-next-line standard/no-callback-literal\n      return callback(`AutoUpdater process with arguments ${args} is already running`)\n    } else if (!spawnedProcess) {\n      spawnedProcess = spawn(updateExe, args, {\n        detached: detached,\n        windowsHide: true\n      })\n      spawnedArgs = args || []\n    }\n  } catch (error1) {\n    error = error1\n\n    // Shouldn't happen, but still guard it.\n    process.nextTick(function () {\n      return callback(error)\n    })\n    return\n  }\n  stdout = ''\n  stderr = ''\n\n  spawnedProcess.stdout.on('data', (data) => { stdout += data })\n  spawnedProcess.stderr.on('data', (data) => { stderr += data })\n\n  errorEmitted = false\n  spawnedProcess.on('error', (error) => {\n    errorEmitted = true\n    callback(error)\n  })\n\n  return spawnedProcess.on('exit', function (code, signal) {\n    spawnedProcess = undefined\n    spawnedArgs = []\n\n    // We may have already emitted an error.\n    if (errorEmitted) {\n      return\n    }\n\n    // Process terminated with error.\n    if (code !== 0) {\n      // Disabled for backwards compatibility:\n      // eslint-disable-next-line standard/no-callback-literal\n      return callback(`Command failed: ${signal != null ? signal : code}\\n${stderr}`)\n    }\n\n    // Success.\n    callback(null, stdout)\n  })\n}", "language": "javascript"}
{"input": "Extends an already generated vocabulary using a collection of instances.", "output": "def extend_from_instances(self,\n                              params: Params,\n                              instances: Iterable['adi.Instance'] = ()) -> None:\n        \"\"\"\n        Extends an already generated vocabulary using a collection of instances.\n        \"\"\"\n        min_count = params.pop(\"min_count\", None)\n        max_vocab_size = pop_max_vocab_size(params)\n        non_padded_namespaces = params.pop(\"non_padded_namespaces\", DEFAULT_NON_PADDED_NAMESPACES)\n        pretrained_files = params.pop(\"pretrained_files\", {})\n        min_pretrained_embeddings = params.pop(\"min_pretrained_embeddings\", None)\n        only_include_pretrained_words = params.pop_bool(\"only_include_pretrained_words\", False)\n        tokens_to_add = params.pop(\"tokens_to_add\", None)\n        params.assert_empty(\"Vocabulary - from dataset\")\n\n        logger.info(\"Fitting token dictionary from dataset.\")\n        namespace_token_counts: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))\n        for instance in Tqdm.tqdm(instances):\n            instance.count_vocab_items(namespace_token_counts)\n        self._extend(counter=namespace_token_counts,\n                     min_count=min_count,\n                     max_vocab_size=max_vocab_size,\n                     non_padded_namespaces=non_padded_namespaces,\n                     pretrained_files=pretrained_files,\n                     only_include_pretrained_words=only_include_pretrained_words,\n                     tokens_to_add=tokens_to_add,\n                     min_pretrained_embeddings=min_pretrained_embeddings)", "language": "python"}
{"input": "Set group size of DMatrix (used for ranking).\n\n        Parameters\n        ----------\n        group : array like\n            Group size of each group", "output": "def set_group(self, group):\n        \"\"\"Set group size of DMatrix (used for ranking).\n\n        Parameters\n        ----------\n        group : array like\n            Group size of each group\n        \"\"\"\n        _check_call(_LIB.XGDMatrixSetGroup(self.handle,\n                                           c_array(ctypes.c_uint, group),\n                                           c_bst_ulong(len(group))))", "language": "python"}
{"input": "automate the event listeners for the native events\n\n@private\n@param {!HTMLElement} node Node on which to add the event.\n@param {string} evType Event type to add.\n@param {function(!Event)} handler Event handler function.\n@return {void}\n@this {Gestures}", "output": "function _add(node, evType, handler) {\n  let recognizer = gestures[evType];\n  let deps = recognizer.deps;\n  let name = recognizer.name;\n  let gobj = node[GESTURE_KEY];\n  if (!gobj) {\n    node[GESTURE_KEY] = gobj = {};\n  }\n  for (let i = 0, dep, gd; i < deps.length; i++) {\n    dep = deps[i];\n    // don't add mouse handlers on iOS because they cause gray selection overlays\n    if (IS_TOUCH_ONLY && isMouseEvent(dep) && dep !== 'click') {\n      continue;\n    }\n    gd = gobj[dep];\n    if (!gd) {\n      gobj[dep] = gd = {_count: 0};\n    }\n    if (gd._count === 0) {\n      node.addEventListener(dep, _handleNative, PASSIVE_TOUCH(dep));\n    }\n    gd[name] = (gd[name] || 0) + 1;\n    gd._count = (gd._count || 0) + 1;\n  }\n  node.addEventListener(evType, handler);\n  if (recognizer.touchAction) {\n    setTouchAction(node, recognizer.touchAction);\n  }\n}", "language": "javascript"}
{"input": "Sets the current orientation of the device\n\n        :Args:\n         - value: orientation to set it to.\n\n        :Usage:\n            ::\n\n                driver.orientation = 'landscape'", "output": "def orientation(self, value):\n        \"\"\"\n        Sets the current orientation of the device\n\n        :Args:\n         - value: orientation to set it to.\n\n        :Usage:\n            ::\n\n                driver.orientation = 'landscape'\n        \"\"\"\n        allowed_values = ['LANDSCAPE', 'PORTRAIT']\n        if value.upper() in allowed_values:\n            self.execute(Command.SET_SCREEN_ORIENTATION, {'orientation': value})\n        else:\n            raise WebDriverException(\"You can only set the orientation to 'LANDSCAPE' and 'PORTRAIT'\")", "language": "python"}
{"input": "Strip SGML/XML tags and replace adjacent whitespace by one space.", "output": "def do_striptags(value):\n    \"\"\"Strip SGML/XML tags and replace adjacent whitespace by one space.\n    \"\"\"\n    if hasattr(value, '__html__'):\n        value = value.__html__()\n    return Markup(text_type(value)).striptags()", "language": "python"}
{"input": "/* [MS-XLSB] 2.4.331 BrtCsProp", "output": "function parse_BrtCsProp(data, length/*:number*/) {\n\tdata.l += 10;\n\tvar name = parse_XLWideString(data, length - 10);\n\treturn { name: name };\n}", "language": "javascript"}
{"input": "Learning rate schedule based on hparams.", "output": "def learning_rate_schedule(hparams):\n  \"\"\"Learning rate schedule based on hparams.\"\"\"\n  mlperf_log.transformer_print(key=mlperf_log.OPT_LR, deferred=True)\n  mlperf_log.transformer_print(\n      key=mlperf_log.OPT_LR_WARMUP_STEPS,\n      value=hparams.learning_rate_warmup_steps)\n  step_num = _global_step(hparams)\n  schedule_string = hparams.learning_rate_schedule\n  names = schedule_string.split(\"*\")\n  names = [name.strip() for name in names if name.strip()]\n  ret = tf.constant(1.0)\n  for name in names:\n    ret *= learning_rate_factor(name, step_num, hparams)\n  return ret", "language": "python"}
{"input": "Get hyper-parameters file path.", "output": "def _get_hparams_path():\n  \"\"\"Get hyper-parameters file path.\"\"\"\n  hparams_path = None\n  if FLAGS.output_dir:\n    hparams_path = os.path.join(FLAGS.output_dir, \"hparams.json\")\n  else:\n    tf.logging.warning(\n        \"--output_dir not specified. Hyper-parameters will be infered from\"\n        \"--hparams_set and --hparams only. These may not match training time\"\n        \"hyper-parameters.\")\n  return hparams_path", "language": "python"}
{"input": "Hparams for machine translation with ~1.1B parameters.", "output": "def transformer_tpu_1b():\n  \"\"\"Hparams for machine translation with ~1.1B parameters.\"\"\"\n  hparams = transformer_tpu()\n  hparams.hidden_size = 2048\n  hparams.filter_size = 8192\n  hparams.num_hidden_layers = 8\n  # smaller batch size to avoid OOM\n  hparams.batch_size = 1024\n  hparams.activation_dtype = \"bfloat16\"\n  hparams.weight_dtype = \"bfloat16\"\n  # maximize number of parameters relative to computation by not sharing.\n  hparams.shared_embedding_and_softmax_weights = False\n  return hparams", "language": "python"}
{"input": "Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.", "output": "def value2rgba(x:float, cmap:Callable=cm.RdYlGn, alpha_mult:float=1.0)->Tuple:\n    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n    c = cmap(x)\n    rgb = (np.array(c[:-1]) * 255).astype(int)\n    a = c[-1] * alpha_mult\n    return tuple(rgb.tolist() + [a])", "language": "python"}
{"input": "Extracts value of the parameter with the specified <code>sParameterName</code>\nfrom the specified <code>sHeaderValue</code>.\n\n@param {string} sHeaderValue\nHTTP header value e.g. \"application/json;charset=utf-8\"\n@param {string} sParameterName\nName of HTTP header parameter e.g. \"charset\"\n@returns {string} The HTTP header parameter value", "output": "function getHeaderParameterValue(sHeaderValue, sParameterName) {\n\t\tvar iParamIndex,\n\t\t\taHeaderParts = sHeaderValue.split(\";\"),\n\t\t\taMatches;\n\n\t\tsParameterName = sParameterName.toLowerCase();\n\t\tfor (iParamIndex = 1; iParamIndex < aHeaderParts.length; iParamIndex += 1) {\n\t\t\t// remove possible quotes via reg exp\n\t\t\t// RFC7231: parameter = token \"=\" ( token / quoted-string )\n\t\t\taMatches = rHeaderParameter.exec(aHeaderParts[iParamIndex]);\n\t\t\tif (aMatches[1].toLowerCase() === sParameterName) {\n\t\t\t\treturn aMatches[2] || aMatches[3];\n\t\t\t}\n\t\t}\n\t}", "language": "javascript"}
{"input": "eslint-disable-next-line no-unused-vars", "output": "function toJSON(key) {\n    var O = toObject(this);\n    var pv = toPrimitive(O);\n    return typeof pv == 'number' && !isFinite(pv) ? null : O.toISOString();\n  }", "language": "javascript"}
{"input": "Find MXNet included header files.\n\n    Returns\n    -------\n    incl_path : string\n        Path to the header files.", "output": "def find_include_path():\n    \"\"\"Find MXNet included header files.\n\n    Returns\n    -------\n    incl_path : string\n        Path to the header files.\n    \"\"\"\n    incl_from_env = os.environ.get('MXNET_INCLUDE_PATH')\n    if incl_from_env:\n        if os.path.isdir(incl_from_env):\n            if not os.path.isabs(incl_from_env):\n                logging.warning(\"MXNET_INCLUDE_PATH should be an absolute path, instead of: %s\",\n                                incl_from_env)\n            else:\n                return incl_from_env\n        else:\n            logging.warning(\"MXNET_INCLUDE_PATH '%s' doesn't exist\", incl_from_env)\n\n    curr_path = os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))\n    # include path in pip package\n    pip_incl_path = os.path.join(curr_path, 'include/')\n    if os.path.isdir(pip_incl_path):\n        return pip_incl_path\n    else:\n        # include path if build from source\n        src_incl_path = os.path.join(curr_path, '../../include/')\n        if os.path.isdir(src_incl_path):\n            return src_incl_path\n        else:\n            raise RuntimeError('Cannot find the MXNet include path in either ' + pip_incl_path +\n                               ' or ' + src_incl_path + '\\n')", "language": "python"}
{"input": "Access a property without creating an Immer draft.", "output": "function peek(draft, prop) {\n    const state = draft[DRAFT_STATE]\n    const desc = Reflect.getOwnPropertyDescriptor(\n        state ? source(state) : draft,\n        prop\n    )\n    return desc && desc.value\n}", "language": "javascript"}
{"input": "Encodes a string into the proper filesystem encoding\n\n    Borrowed from pip-tools", "output": "def fs_str(string):\n    \"\"\"Encodes a string into the proper filesystem encoding\n\n    Borrowed from pip-tools\n    \"\"\"\n\n    if isinstance(string, str):\n        return string\n    assert not isinstance(string, bytes)\n    return string.encode(_fs_encoding)", "language": "python"}
{"input": "Make sure the provided value for --single is a path to an existing\n        .rst/.ipynb file, or a pandas object that can be imported.\n\n        For example, categorial.rst or pandas.DataFrame.head. For the latter,\n        return the corresponding file path\n        (e.g. reference/api/pandas.DataFrame.head.rst).", "output": "def _process_single_doc(self, single_doc):\n        \"\"\"\n        Make sure the provided value for --single is a path to an existing\n        .rst/.ipynb file, or a pandas object that can be imported.\n\n        For example, categorial.rst or pandas.DataFrame.head. For the latter,\n        return the corresponding file path\n        (e.g. reference/api/pandas.DataFrame.head.rst).\n        \"\"\"\n        base_name, extension = os.path.splitext(single_doc)\n        if extension in ('.rst', '.ipynb'):\n            if os.path.exists(os.path.join(SOURCE_PATH, single_doc)):\n                return single_doc\n            else:\n                raise FileNotFoundError('File {} not found'.format(single_doc))\n\n        elif single_doc.startswith('pandas.'):\n            try:\n                obj = pandas  # noqa: F821\n                for name in single_doc.split('.'):\n                    obj = getattr(obj, name)\n            except AttributeError:\n                raise ImportError('Could not import {}'.format(single_doc))\n            else:\n                return single_doc[len('pandas.'):]\n        else:\n            raise ValueError(('--single={} not understood. Value should be a '\n                              'valid path to a .rst or .ipynb file, or a '\n                              'valid pandas object (e.g. categorical.rst or '\n                              'pandas.DataFrame.head)').format(single_doc))", "language": "python"}
{"input": "Return the inner state of the `Callback`, `minimal` or not.", "output": "def get_state(self, minimal:bool=True):\n        \"Return the inner state of the `Callback`, `minimal` or not.\"\n        to_remove = ['exclude', 'not_min'] + getattr(self, 'exclude', []).copy()\n        if minimal: to_remove += getattr(self, 'not_min', []).copy()\n        return {k:v for k,v in self.__dict__.items() if k not in to_remove}", "language": "python"}
{"input": "Utility for PreferencesSystem & PrefixedPreferencesSystem -- attach EventDispatcher's on()/off()\nimplementation as private _on_internal()/_off_internal() methods, so the custom on()/off() APIs\nthese classes use can leverage EventDispatcher code internally. Also attach the regular public trigger().", "output": "function _addEventDispatcherImpl(proto) {\n        var temp = {};\n        EventDispatcher.makeEventDispatcher(temp);\n        proto._on_internal  = temp.on;\n        proto._off_internal = temp.off;\n        proto.trigger       = temp.trigger;\n    }", "language": "javascript"}
{"input": "Report exception\n@private\n@param {Error} e - the error object", "output": "function _reportError(e, file) {\n    if (e instanceof Infer.TimedOut) {\n        // Post a message back to the main thread with timedout info\n        self.postMessage({\n            type: MessageIds.TERN_INFERENCE_TIMEDOUT,\n            file: file\n        });\n    } else {\n        _log(\"Error thrown in tern_node domain:\" + e.message + \"\\n\" + e.stack);\n    }\n}", "language": "javascript"}
{"input": "helper function that actually does the launch once we are sure we have a doc and the server for that doc is up and running.", "output": "function _doLaunchAfterServerReady(initialDoc) {\n        // update status\n        _setStatus(STATUS_CONNECTING);\n        _createLiveDocumentForFrame(initialDoc);\n\n        // start listening for requests\n        _server.start();\n\n        // Install a one-time event handler when connected to the launcher page\n        Inspector.one(\"connect\", _onConnect);\n\n        // open browser to the interstitial page to prepare for loading agents\n        _openInterstitialPage();\n\n        // Once all agents loaded (see _onInterstitialPageLoad()), begin Live Highlighting for preprocessor documents\n        _openDeferred.done(function () {\n            // Setup activeEditorChange event listener so that we can track cursor positions in\n            // CSS preprocessor files and perform live preview highlighting on all elements with\n            // the current selector in the preprocessor file.\n            EditorManager.on(\"activeEditorChange\", onActiveEditorChange);\n\n            // Explicitly trigger onActiveEditorChange so that live preview highlighting\n            // can be set up for the preprocessor files.\n            onActiveEditorChange(null, EditorManager.getActiveEditor(), null);\n        });\n    }", "language": "javascript"}
{"input": "Convert SQL and params args to DBAPI2.0 compliant format.", "output": "def _convert_params(sql, params):\n    \"\"\"Convert SQL and params args to DBAPI2.0 compliant format.\"\"\"\n    args = [sql]\n    if params is not None:\n        if hasattr(params, 'keys'):  # test if params is a mapping\n            args += [params]\n        else:\n            args += [list(params)]\n    return args", "language": "python"}
{"input": "Autoplace grid items\n@param {Declaration} decl\n@param {Result} result\n@param {Object} gap gap values\n@param {String} autoflowValue grid-auto-flow value\n@return {void}\n@see https://github.com/postcss/autoprefixer/issues/1148", "output": "function autoplaceGridItems (decl, result, gap, autoflowValue = 'row') {\n  let { parent } = decl\n\n  let rowDecl = parent.nodes.find(i => i.prop === 'grid-template-rows')\n  let rows = normalizeRowColumn(rowDecl.value)\n  let columns = normalizeRowColumn(decl.value)\n\n  // Build array of area names with dummy values. If we have 3 columns and\n  // 2 rows, filledRows will be equal to ['1 2 3', '4 5 6']\n  let filledRows = rows.map((_, rowIndex) => {\n    return Array.from({ length: columns.length }, (v, k) =>\n      k + (rowIndex * columns.length) + 1).join(' ')\n  })\n\n  let areas = parseGridAreas({ rows: filledRows, gap })\n  let keys = Object.keys(areas)\n  let items = keys.map(i => areas[i])\n\n  // Change the order of cells if grid-auto-flow value is 'column'\n  if (autoflowValue.includes('column')) {\n    items = items.sort((a, b) => a.column.start - b.column.start)\n  }\n\n  // Insert new rules\n  items.reverse().forEach((item, index) => {\n    let { column, row } = item\n    let nodeSelector = parent.selectors.map(sel =>\n      sel + ` > *:nth-child(${ keys.length - index })`).join(', ')\n\n    // create new rule\n    let node = parent.clone().removeAll()\n\n    // change rule selector\n    node.selector = nodeSelector\n\n    // insert prefixed row/column values\n    node.append({ prop: '-ms-grid-row', value: row.start })\n    node.append({ prop: '-ms-grid-column', value: column.start })\n\n    // insert rule\n    parent.after(node)\n  })\n\n  return undefined\n}", "language": "javascript"}
{"input": "Compares current layer with a provided layer\n-1: Lower layer, 0: Same layer, 1: Layer above\n\n@param {String} sLayer - Layer name to be evaluated\n@param {String} [sCurrentLayer] - Current layer name to be evaluated, if not provided the layer is taken from URL parameter\n@returns {int} -1: Lower layer, 0: Same layer, 1: Layer above\n@public\n@function\n@name sap.ui.fl.Utils.isLayerOverCurrentLayer", "output": "function(sLayer, sCurrentLayer) {\n\t\t\tvar sCurrent = sCurrentLayer || Utils.getCurrentLayer(false);\n\t\t\t// If sLayer is undefined, it is assumed it be on the lowest layer\n\t\t\tif ((this.getLayerIndex(sCurrent) > this.getLayerIndex(sLayer)) || !sLayer) {\n\t\t\t\treturn -1;\n\t\t\t} else if (this.getLayerIndex(sCurrent) === this.getLayerIndex(sLayer)) {\n\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "remove all selection classes", "output": "function removeCellSelections () {\n        if (editable) {\n            var selectedCells = editable.querySelectorAll('.' + selection_class);\n            if (selectedCells.length > 0) {\n              for (var i = 0; i < selectedCells.length; i++) {\n                  dom.removeClass(selectedCells[i], selection_class);\n              }\n            }\n        }\n    }", "language": "javascript"}
{"input": "Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager", "output": "def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager\n        \"\"\"\n        if proxy in self.proxy_manager:\n            manager = self.proxy_manager[proxy]\n        elif proxy.lower().startswith('socks'):\n            username, password = get_auth_from_url(proxy)\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                proxy,\n                username=username,\n                password=password,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs\n            )\n        else:\n            proxy_headers = self.proxy_headers(proxy)\n            manager = self.proxy_manager[proxy] = proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs)\n\n        return manager", "language": "python"}
{"input": "Parse version string to a VersionInfo instance.\n\n    :param version: version string\n    :return: a :class:`VersionInfo` instance\n    :rtype: :class:`VersionInfo`\n\n    >>> import semver\n    >>> version_info = semver.parse_version_info(\"3.4.5-pre.2+build.4\")\n    >>> version_info.major\n    3\n    >>> version_info.minor\n    4\n    >>> version_info.patch\n    5\n    >>> version_info.prerelease\n    'pre.2'\n    >>> version_info.build\n    'build.4'", "output": "def parse_version_info(version):\n    \"\"\"Parse version string to a VersionInfo instance.\n\n    :param version: version string\n    :return: a :class:`VersionInfo` instance\n    :rtype: :class:`VersionInfo`\n\n    >>> import semver\n    >>> version_info = semver.parse_version_info(\"3.4.5-pre.2+build.4\")\n    >>> version_info.major\n    3\n    >>> version_info.minor\n    4\n    >>> version_info.patch\n    5\n    >>> version_info.prerelease\n    'pre.2'\n    >>> version_info.build\n    'build.4'\n    \"\"\"\n    parts = parse(version)\n    version_info = VersionInfo(\n            parts['major'], parts['minor'], parts['patch'],\n            parts['prerelease'], parts['build'])\n\n    return version_info", "language": "python"}
{"input": "r\"\"\"Inception v3 model from\n    `\"Rethinking the Inception Architecture for Computer Vision\"\n    <http://arxiv.org/abs/1512.00567>`_ paper.\n\n    Parameters\n    ----------\n    pretrained : bool, default False\n        Whether to load the pretrained weights for model.\n    ctx : Context, default CPU\n        The context in which to load the pretrained weights.\n    root : str, default $MXNET_HOME/models\n        Location for keeping the model parameters.", "output": "def inception_v3(pretrained=False, ctx=cpu(),\n                 root=os.path.join(base.data_dir(), 'models'), **kwargs):\n    r\"\"\"Inception v3 model from\n    `\"Rethinking the Inception Architecture for Computer Vision\"\n    <http://arxiv.org/abs/1512.00567>`_ paper.\n\n    Parameters\n    ----------\n    pretrained : bool, default False\n        Whether to load the pretrained weights for model.\n    ctx : Context, default CPU\n        The context in which to load the pretrained weights.\n    root : str, default $MXNET_HOME/models\n        Location for keeping the model parameters.\n    \"\"\"\n    net = Inception3(**kwargs)\n    if pretrained:\n        from ..model_store import get_model_file\n        net.load_parameters(get_model_file('inceptionv3', root=root), ctx=ctx)\n    return net", "language": "python"}
{"input": "Try to look up the process tree via the output of `ps`.", "output": "def get_process_mapping():\n    \"\"\"Try to look up the process tree via the output of `ps`.\n    \"\"\"\n    try:\n        output = subprocess.check_output([\n            'ps', '-ww', '-o', 'pid=', '-o', 'ppid=', '-o', 'args=',\n        ])\n    except OSError as e:    # Python 2-compatible FileNotFoundError.\n        if e.errno != errno.ENOENT:\n            raise\n        raise PsNotAvailable('ps not found')\n    except subprocess.CalledProcessError as e:\n        # `ps` can return 1 if the process list is completely empty.\n        # (sarugaku/shellingham#15)\n        if not e.output.strip():\n            return {}\n        raise\n    if not isinstance(output, str):\n        encoding = sys.getfilesystemencoding() or sys.getdefaultencoding()\n        output = output.decode(encoding)\n    processes = {}\n    for line in output.split('\\n'):\n        try:\n            pid, ppid, args = line.strip().split(None, 2)\n            # XXX: This is not right, but we are really out of options.\n            # ps does not offer a sane way to decode the argument display,\n            # and this is \"Good Enough\" for obtaining shell names. Hopefully\n            # people don't name their shell with a space, or have something\n            # like \"/usr/bin/xonsh is uber\". (sarugaku/shellingham#14)\n            args = tuple(a.strip() for a in args.split(' '))\n        except ValueError:\n            continue\n        processes[pid] = Process(args=args, pid=pid, ppid=ppid)\n    return processes", "language": "python"}
{"input": "Eliminate the query string from a URL\n@param {string} URL", "output": "function _cleanURL(url) {\n        var index = url.search(/[#\\?]/);\n        if (index >= 0) {\n            url = url.substr(0, index);\n        }\n        return url;\n    }", "language": "javascript"}
{"input": "Export the minimal state and save it in `fn` to load an empty version for inference.", "output": "def export(self, fn:PathOrStr, **kwargs):\n        \"Export the minimal state and save it in `fn` to load an empty version for inference.\"\n        pickle.dump(self.get_state(**kwargs), open(fn, 'wb'))", "language": "python"}
{"input": "Apply `processor` or `self.processor` to `item`.", "output": "def process_one(self, item:ItemBase, processor:PreProcessors=None):\n        \"Apply `processor` or `self.processor` to `item`.\"\n        if processor is not None: self.processor = processor\n        self.processor = listify(self.processor)\n        for p in self.processor: item = p.process_one(item)\n        return item", "language": "python"}
{"input": "Scale learning rate according to the given schedule.\n\n  Multipliers are not cumulative.\n\n  Args:\n    step: global step\n    boundaries: List of steps to transition on.\n    values: Multiplier to apply at each boundary transition.\n\n  Returns:\n    Scaled value for the learning rate.", "output": "def _piecewise_learning_rate(step, boundaries, values):\n  \"\"\"Scale learning rate according to the given schedule.\n\n  Multipliers are not cumulative.\n\n  Args:\n    step: global step\n    boundaries: List of steps to transition on.\n    values: Multiplier to apply at each boundary transition.\n\n  Returns:\n    Scaled value for the learning rate.\n  \"\"\"\n  values = [1.0] + values\n  boundaries = [float(x) for x in boundaries]\n  return tf.train.piecewise_constant(\n      step, boundaries, values, name=\"piecewise_lr\")", "language": "python"}
{"input": "Stashes the directory or file and returns its new location.", "output": "def stash(self, path):\n        \"\"\"Stashes the directory or file and returns its new location.\n        \"\"\"\n        if os.path.isdir(path):\n            new_path = self._get_directory_stash(path)\n        else:\n            new_path = self._get_file_stash(path)\n\n        self._moves.append((path, new_path))\n        if os.path.isdir(path) and os.path.isdir(new_path):\n            # If we're moving a directory, we need to\n            # remove the destination first or else it will be\n            # moved to inside the existing directory.\n            # We just created new_path ourselves, so it will\n            # be removable.\n            os.rmdir(new_path)\n        renames(path, new_path)\n        return new_path", "language": "python"}
{"input": "$, upperCase, lowerCase, _", "output": "function sortObjName(a, b) {\n  let lenA = a.length\n  let lenB = b.length\n  let len = lenA > lenB ? lenB : lenA\n\n  for (let i = 0; i < len; i++) {\n    let codeA = a.charCodeAt(i)\n    let codeB = b.charCodeAt(i)\n    let cmpResult = cmpCode(codeA, codeB)\n\n    if (cmpResult !== 0) return cmpResult\n  }\n\n  if (lenA > lenB) return 1\n  if (lenA < lenB) return -1\n\n  return 0\n}", "language": "javascript"}
{"input": "The base implementation of `_.toString` which doesn't convert nullish\nvalues to empty strings.\n\n@private\n@param {*} value The value to process.\n@returns {string} Returns the string.", "output": "function baseToString(value) {\n  // Exit early for strings to avoid a performance hit in some environments.\n  if (typeof value === 'string') {\n    return value\n  }\n  if (isSymbol(value)) {\n    return symbolToString ? symbolToString.call(value) : ''\n  }\n  var result = value + ''\n  return result == '0' && 1 / value == -INFINITY ? '-0' : result\n}", "language": "javascript"}
{"input": "\u83b7\u53d6\u6587\u4ef6\u7edf\u8ba1\u4fe1\u606f\u3002\u8fd4\u56de\u4e00\u4e2a\u5305\u542b\u4e00\u4e0b\u4fe1\u606f\u7684\u5bf9\u8c61\u3002\n* `successNum` \u4e0a\u4f20\u6210\u529f\u7684\u6587\u4ef6\u6570\n* `progressNum` \u4e0a\u4f20\u4e2d\u7684\u6587\u4ef6\u6570\n* `cancelNum` \u88ab\u5220\u9664\u7684\u6587\u4ef6\u6570\n* `invalidNum` \u65e0\u6548\u7684\u6587\u4ef6\u6570\n* `uploadFailNum` \u4e0a\u4f20\u5931\u8d25\u7684\u6587\u4ef6\u6570\n* `queueNum` \u8fd8\u5728\u961f\u5217\u4e2d\u7684\u6587\u4ef6\u6570\n* `interruptNum` \u88ab\u6682\u505c\u7684\u6587\u4ef6\u6570\n@method getStats\n@grammar getStats() => Object", "output": "function() {\n            // return this._mgr.getStats.apply( this._mgr, arguments );\n            var stats = this.request('get-stats');\n\n            return stats ? {\n                successNum: stats.numOfSuccess,\n                progressNum: stats.numOfProgress,\n\n                // who care?\n                // queueFailNum: 0,\n                cancelNum: stats.numOfCancel,\n                invalidNum: stats.numOfInvalid,\n                uploadFailNum: stats.numOfUploadFailed,\n                queueNum: stats.numOfQueue,\n                interruptNum: stats.numOfInterrupt\n            } : {};\n        }", "language": "javascript"}
{"input": "Gets edge vectors for the edge types in the adjacency matrix.\n\n  Args:\n    adjacency_matrix: A [batch, num_nodes, num_nodes] tensor of ints.\n    num_edge_types: Number of different edge types\n    depth: Number of channels\n    name: a string\n  Returns:\n    A [batch, num_nodes, num_nodes, depth] vector of tensors", "output": "def make_edge_vectors(adjacency_matrix, num_edge_types, depth, name=None):\n  \"\"\"Gets edge vectors for the edge types in the adjacency matrix.\n\n  Args:\n    adjacency_matrix: A [batch, num_nodes, num_nodes] tensor of ints.\n    num_edge_types: Number of different edge types\n    depth: Number of channels\n    name: a string\n  Returns:\n    A [batch, num_nodes, num_nodes, depth] vector of tensors\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"edge_vectors\"):\n    att_adj_vectors_shape = [num_edge_types, depth]\n    adjacency_matrix_shape = common_layers.shape_list(adjacency_matrix)\n    adj_vectors = (\n        tf.get_variable(\n            \"adj_vectors\",\n            att_adj_vectors_shape,\n            initializer=tf.random_normal_initializer(0, depth**-0.5)) *\n        (depth**0.5))\n    # Avoiding gathers so that it works on TPUs\n    # adjacency_matrix_one_hot has shape\n    # [batch, num_nodes, num_nodes, num_edge_types]\n\n    adjacency_matrix_one_hot = tf.one_hot(adjacency_matrix, num_edge_types)\n\n    att_adj_vectors = tf.matmul(\n        tf.reshape(tf.to_float(adjacency_matrix_one_hot), [-1, num_edge_types]),\n        adj_vectors)\n    return tf.reshape(att_adj_vectors,\n                      [adjacency_matrix_shape[0], adjacency_matrix_shape[1],\n                       adjacency_matrix_shape[2], depth])", "language": "python"}
{"input": "Extracts vars from a path Useful for removing blocks or paths that can contain variable declarations inside them Note: drops are inits extractVars({ var x = 5, y = x }) => var x, y;", "output": "function extractVars(path) {\n    const declarators = [];\n\n    if (path.isVariableDeclaration({ kind: \"var\" })) {\n      for (const decl of path.node.declarations) {\n        const bindingIds = Object.keys(t.getBindingIdentifiers(decl.id));\n\n        declarators.push(\n          ...bindingIds.map(name => t.variableDeclarator(t.identifier(name)))\n        );\n      }\n    } else {\n      path.traverse({\n        VariableDeclaration(varPath) {\n          if (!varPath.isVariableDeclaration({ kind: \"var\" })) return;\n\n          if (!isSameFunctionScope(varPath, path)) return;\n\n          for (const decl of varPath.node.declarations) {\n            const bindingIds = Object.keys(t.getBindingIdentifiers(decl.id));\n            declarators.push(\n              ...bindingIds.map(name =>\n                t.variableDeclarator(t.identifier(name))\n              )\n            );\n          }\n        }\n      });\n    }\n\n    if (declarators.length <= 0) return [];\n\n    return [t.variableDeclaration(\"var\", declarators)];\n  }", "language": "javascript"}
{"input": "Synchronously find a file or directory\n@param {RegExp} pattern regex\n@param {string} base path\n@param {boolean} [findDir] if true, search results will be limited to only directories\n@returns {Array}", "output": "function findSync(pattern, basePath, findDir) {\n  const matches = [];\n\n  (function findSyncRecurse(base) {\n    let children;\n    try {\n      children = fs.readdirSync(base);\n    } catch (exception) {\n      if (exception.code === 'ENOENT') {\n        return;\n      }\n      throw exception;\n    }\n\n    children.forEach((child) => {\n      const childPath = path.join(base, child);\n      const childIsDirectory = fs.lstatSync(childPath).isDirectory();\n      const patternMatches = pattern.test(childPath);\n\n      if (!patternMatches) {\n        if (!childIsDirectory) {\n          return;\n        }\n        findSyncRecurse(childPath);\n        return;\n      }\n\n      if (!findDir) {\n        matches.push(childPath);\n        return;\n      }\n\n      if (childIsDirectory) {\n        matches.push(childPath);\n      }\n    });\n  })(basePath);\n  return matches;\n}", "language": "javascript"}
{"input": "Check if a binding is safe to remove and returns it if it is.", "output": "function getUnusedBinding(path, name) {\n  let binding = path.scope.getBinding(name);\n  if (!binding) {\n    return null;\n  }\n\n  let pure = isPure(binding);\n  if (!binding.referenced && pure) {\n    return binding;\n  }\n\n  // Is there any references which aren't simple assignments?\n  let bailout = binding.referencePaths.some(\n    path => !isExportAssignment(path) && !isUnusedWildcard(path)\n  );\n\n  if (!bailout && pure) {\n    return binding;\n  }\n\n  return null;\n}", "language": "javascript"}
{"input": "/*\nCalls a computed annotation according to the given segment which was found at the\ngiven path; changes <code>vResult</code> accordingly.\n\n@param {string} sSegment\nContains the name of the computed annotation as \"@@...\"\n@param {string} sPath\nPath where the segment was found\n@returns {boolean}\n<code>true</code>", "output": "function computedAnnotation(sSegment, sPath) {\n\t\t\t\tvar fnAnnotation,\n\t\t\t\t\tiThirdAt = sSegment.indexOf(\"@\", 2);\n\n\t\t\t\tif (iThirdAt > -1) {\n\t\t\t\t\treturn log(WARNING, \"Unsupported path after \", sSegment.slice(0, iThirdAt));\n\t\t\t\t}\n\n\t\t\t\tsSegment = sSegment.slice(2);\n\t\t\t\tfnAnnotation = sSegment[0] === \".\"\n\t\t\t\t\t? ObjectPath.get(sSegment.slice(1), mParameters.scope)\n\t\t\t\t\t: mParameters && ObjectPath.get(sSegment, mParameters.scope)\n\t\t\t\t\t\t|| (sSegment === \"requestCurrencyCodes\"\n\t\t\t\t\t\t\t|| sSegment === \"requestUnitsOfMeasure\"\n\t\t\t\t\t\t\t? that[sSegment].bind(that)\n\t\t\t\t\t\t\t: ObjectPath.get(sSegment));\n\t\t\t\tif (typeof fnAnnotation !== \"function\") {\n\t\t\t\t\t// Note: \"varargs\" syntax does not help because Array#join ignores undefined\n\t\t\t\t\treturn log(WARNING, sSegment, \" is not a function but: \" + fnAnnotation);\n\t\t\t\t}\n\n\t\t\t\ttry {\n\t\t\t\t\tvResult = fnAnnotation(vResult, {\n\t\t\t\t\t\t$$valueAsPromise : mParameters && mParameters.$$valueAsPromise,\n\t\t\t\t\t\tcontext : new BaseContext(that, sPath),\n\t\t\t\t\t\tschemaChildName : sSchemaChildName\n\t\t\t\t\t});\n\t\t\t\t} catch (e) {\n\t\t\t\t\tlog(WARNING, \"Error calling \", sSegment, \": \", e);\n\t\t\t\t}\n\n\t\t\t\treturn true;\n\t\t\t}", "language": "javascript"}
{"input": "Callback to be called when a READ event is received. Pushes the data onto\nthe read queue and starts reading again if applicable\n@param {grpc.Event} event READ event object", "output": "function readCallback(err, event) {\n    if (err) {\n      self.terminate();\n      return;\n    }\n    if (self.finished) {\n      self.push(null);\n      return;\n    }\n    var data = event.read;\n    var deserialized;\n    try {\n      deserialized = self.deserialize(data);\n    } catch (e) {\n      e.code = constants.status.INTERNAL;\n      self.emit('error', e);\n      return;\n    }\n    if (self.push(deserialized) && data !== null) {\n      var read_batch = {};\n      read_batch[grpc.opType.RECV_MESSAGE] = true;\n      self.call.startBatch(read_batch, readCallback);\n    } else {\n      self.reading = false;\n    }\n  }", "language": "javascript"}
{"input": "amount of pixels to drag to determine direction of swipe", "output": "function(e, isDown) {\n\t    _preventObj.prevent = !_closestElement(e.target, _options.isClickableElement);\n\n\t\t_shout('preventDragEvent', e, isDown, _preventObj);\n\t\treturn _preventObj.prevent;\n\n\t}", "language": "javascript"}
{"input": "Create `nn.ConvTranspose2d` layer.", "output": "def conv2d_trans(ni:int, nf:int, ks:int=2, stride:int=2, padding:int=0, bias=False) -> nn.ConvTranspose2d:\n    \"Create `nn.ConvTranspose2d` layer.\"\n    return nn.ConvTranspose2d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias)", "language": "python"}
{"input": "returns an array of all keys of an object, and a status flag indicating if all extracted keys were converted to stringLiterals or not e.g. extracts {keys: [\"a\", \"b\", \"3\", ++x], allLiteral: false } from ast of {a: \"foo\", b, 3: \"bar\", [++x]: \"baz\"}", "output": "function extractNormalizedKeys(path) {\n    const props = path.node.properties;\n    const keys = [];\n    let allLiteral = true;\n\n    for (const prop of props) {\n      if (t.isIdentifier(prop.key) && !prop.computed) {\n        // since a key {a: 3} is equivalent to {\"a\": 3}, use the latter\n        keys.push(t.stringLiteral(prop.key.name));\n      } else if (t.isTemplateLiteral(prop.key)) {\n        keys.push(t.cloneNode(prop.key));\n      } else if (t.isLiteral(prop.key)) {\n        keys.push(t.stringLiteral(String(prop.key.value)));\n      } else {\n        keys.push(t.cloneNode(prop.key));\n        allLiteral = false;\n      }\n    }\n\n    return { keys, allLiteral };\n  }", "language": "javascript"}
{"input": "Get a JAX random number generator and set random seed everywhere.", "output": "def get_random_number_generator_and_set_seed(seed=None):\n  \"\"\"Get a JAX random number generator and set random seed everywhere.\"\"\"\n  random.seed(seed)\n  # While python random accepts None as seed and uses time/os seed then,\n  # some other functions expect integers so we create one here.\n  if seed is None:\n    seed = random.randint(0, 2**31 - 1)\n  tf.set_random_seed(seed)\n  numpy.random.seed(seed)\n  return jax_random.get_prng(seed)", "language": "python"}
{"input": "Update chart progressive and blend.\n@param {module:echarts/model/Series|module:echarts/model/Component} model\n@param {module:echarts/view/Component|module:echarts/view/Chart} view", "output": "function updateBlend(seriesModel, chartView) {\n    var blendMode = seriesModel.get('blendMode') || null;\n    if (__DEV__) {\n        if (!env.canvasSupported && blendMode && blendMode !== 'source-over') {\n            console.warn('Only canvas support blendMode');\n        }\n    }\n    chartView.group.traverse(function (el) {\n        // FIXME marker and other components\n        if (!el.isGroup) {\n            // Only set if blendMode is changed. In case element is incremental and don't wan't to rerender.\n            if (el.style.blend !== blendMode) {\n                el.setStyle('blend', blendMode);\n            }\n        }\n        if (el.eachPendingDisplayable) {\n            el.eachPendingDisplayable(function (displayable) {\n                displayable.setStyle('blend', blendMode);\n            });\n        }\n    });\n}", "language": "javascript"}
{"input": "Sets the configuration, generally for testing/debugging use.\nConfiguration keys are merged into the current configuration.\nThe Tern worker is automatically updated to the new config as well.\n\n* debug: Set to true if you want verbose logging\n* noReset: Set to true if you don't want the worker to restart periodically\n\n@param {Object} configUpdate keys/values to merge into the config", "output": "function setConfig(configUpdate) {\n        var config = setConfig.config;\n        Object.keys(configUpdate).forEach(function (key) {\n            config[key] = configUpdate[key];\n        });\n\n        ScopeManager._setConfig(configUpdate);\n    }", "language": "javascript"}
{"input": "Constructs a vocabulary given a collection of `Instances` and some parameters.\n        We count all of the vocabulary items in the instances, then pass those counts\n        and the other parameters, to :func:`__init__`.  See that method for a description\n        of what the other parameters do.", "output": "def from_instances(cls,\n                       instances: Iterable['adi.Instance'],\n                       min_count: Dict[str, int] = None,\n                       max_vocab_size: Union[int, Dict[str, int]] = None,\n                       non_padded_namespaces: Iterable[str] = DEFAULT_NON_PADDED_NAMESPACES,\n                       pretrained_files: Optional[Dict[str, str]] = None,\n                       only_include_pretrained_words: bool = False,\n                       tokens_to_add: Dict[str, List[str]] = None,\n                       min_pretrained_embeddings: Dict[str, int] = None) -> 'Vocabulary':\n        \"\"\"\n        Constructs a vocabulary given a collection of `Instances` and some parameters.\n        We count all of the vocabulary items in the instances, then pass those counts\n        and the other parameters, to :func:`__init__`.  See that method for a description\n        of what the other parameters do.\n        \"\"\"\n        logger.info(\"Fitting token dictionary from dataset.\")\n        namespace_token_counts: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))\n        for instance in Tqdm.tqdm(instances):\n            instance.count_vocab_items(namespace_token_counts)\n\n        return cls(counter=namespace_token_counts,\n                   min_count=min_count,\n                   max_vocab_size=max_vocab_size,\n                   non_padded_namespaces=non_padded_namespaces,\n                   pretrained_files=pretrained_files,\n                   only_include_pretrained_words=only_include_pretrained_words,\n                   tokens_to_add=tokens_to_add,\n                   min_pretrained_embeddings=min_pretrained_embeddings)", "language": "python"}
{"input": "Generate a vocabulary from txt files with example-per-line.", "output": "def get_or_generate_txt_vocab(data_dir, vocab_filename, vocab_size,\n                              filepatterns):\n  \"\"\"Generate a vocabulary from txt files with example-per-line.\"\"\"\n  if isinstance(filepatterns, str):\n    filepatterns = [filepatterns]\n\n  def generate():\n    tf.logging.info(\"Generating vocab from %s\", filepatterns)\n    for filepattern in filepatterns:\n      for filename in tf.gfile.Glob(filepattern):\n        with tf.gfile.GFile(filename, mode=\"r\") as source_file:\n          for line in source_file:\n            yield line.strip()\n\n  return get_or_generate_vocab_inner(data_dir, vocab_filename, vocab_size,\n                                     generate())", "language": "python"}
{"input": "get type for error message", "output": "function gettype(obj) {\n  var type = typeof obj;\n\n  if (type !== 'object') {\n    return type;\n  }\n\n  // inspect [[Class]] for objects\n  return toString.call(obj)\n    .replace(objectRegExp, '$1');\n}", "language": "javascript"}
{"input": "return appropriate class of Series concat\n    input is either dict or array-like", "output": "def _get_series_result_type(result, objs=None):\n    \"\"\"\n    return appropriate class of Series concat\n    input is either dict or array-like\n    \"\"\"\n    from pandas import SparseSeries, SparseDataFrame, DataFrame\n\n    # concat Series with axis 1\n    if isinstance(result, dict):\n        # concat Series with axis 1\n        if all(isinstance(c, (SparseSeries, SparseDataFrame))\n               for c in result.values()):\n            return SparseDataFrame\n        else:\n            return DataFrame\n\n    # otherwise it is a SingleBlockManager (axis = 0)\n    if result._block.is_sparse:\n        return SparseSeries\n    else:\n        return objs[0]._constructor", "language": "python"}
{"input": "visualize detections in one image\n\n        Parameters:\n        ----------\n        img : numpy.array\n            image, in bgr format\n        dets : numpy.array\n            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n            each row is one object\n        classes : tuple or list of str\n            class names\n        thresh : float\n            score threshold", "output": "def visualize_detection(self, img, dets, classes=[], thresh=0.6):\n        \"\"\"\n        visualize detections in one image\n\n        Parameters:\n        ----------\n        img : numpy.array\n            image, in bgr format\n        dets : numpy.array\n            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n            each row is one object\n        classes : tuple or list of str\n            class names\n        thresh : float\n            score threshold\n        \"\"\"\n        import matplotlib.pyplot as plt\n        import random\n        plt.imshow(img)\n        height = img.shape[0]\n        width = img.shape[1]\n        colors = dict()\n        for det in dets:\n            (klass, score, x0, y0, x1, y1) = det\n            if score < thresh:\n                continue\n            cls_id = int(klass)\n            if cls_id not in colors:\n                colors[cls_id] = (random.random(), random.random(), random.random())\n            xmin = int(x0 * width)\n            ymin = int(y0 * height)\n            xmax = int(x1 * width)\n            ymax = int(y1 * height)\n            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n                                 ymax - ymin, fill=False,\n                                 edgecolor=colors[cls_id],\n                                 linewidth=3.5)\n            plt.gca().add_patch(rect)\n            class_name = str(cls_id)\n            if classes and len(classes) > cls_id:\n                class_name = classes[cls_id]\n            plt.gca().text(xmin, ymin - 2,\n                            '{:s} {:.3f}'.format(class_name, score),\n                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n                                    fontsize=12, color='white')\n        plt.show()", "language": "python"}
{"input": "Sanitizes attributes on an HTML tag.\n\n@param {string} tagName An HTML tag name in lowercase\n@param {array} attribs An array of alternating names and values\n@return {array} The sanitized attributes as a list of alternating names and values. Null value means to omit the attribute\n@private", "output": "function (tagName, attribs) {\n\n\t\t\tvar intPattern = /^[0-9]*$/;\n\t\t\tfor (var i = 0; i < attribs.length; i += 2) {\n\t\t\t\t// attribs[i] is the name of the tag's attribute.\n\t\t\t\t// attribs[i+1] is its corresponding value.\n\t\t\t\t// (i.e. <span class=\"foo\"> -> attribs[i] = \"class\" | attribs[i+1] =\n\t\t\t\t// \"foo\")\n\n\t\t\t\tvar sAttribKey = tagName + \"::\" + attribs[i];\n\n\t\t\t\tif (this._renderingRules.ATTRIBS[sAttribKey]) {\n\t\t\t\t\t// keep the value of this class\n\t\t\t\t\tif (tagName === \"embed\" && !(attribs[i + 1].match(intPattern))) {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tvar sWarning = '<' + tagName + '> with attribute [' + attribs[i] + '=\"' + attribs[i + 1] + '\"] is not allowed and cut';\n\t\t\t\t\tLog.warning(sWarning, this);\n\n\t\t\t\t\t// to remove this attribute by the sanitizer the value has to be\n\t\t\t\t\t// set to null\n\t\t\t\t\tattribs[i + 1] = null;\n\t\t\t\t}\n\n\t\t\t}\n\t\t\treturn attribs;\n\t\t}", "language": "javascript"}
{"input": "Output a list of tuples(story, 1st continuation, 2nd continuation, label)", "output": "def load_rocstories_dataset(dataset_path):\n    \"\"\" Output a list of tuples(story, 1st continuation, 2nd continuation, label) \"\"\"\n    with open(dataset_path, encoding='utf_8') as f:\n        f = csv.reader(f)\n        output = []\n        next(f) # skip the first line\n        for line in tqdm(f):\n            output.append((' '.join(line[1:5]), line[5], line[6], int(line[-1])-1))\n    return output", "language": "python"}
{"input": "11.1.4 Array Initialiser", "output": "function parseArrayInitialiser() {\n        var elements = [], startToken;\n\n        startToken = lookahead;\n        expect('[');\n\n        while (!match(']')) {\n            if (match(',')) {\n                lex();\n                elements.push(null);\n            } else {\n                elements.push(parseAssignmentExpression());\n\n                if (!match(']')) {\n                    expect(',');\n                }\n            }\n        }\n\n        lex();\n\n        return delegate.markEnd(delegate.createArrayExpression(elements), startToken);\n    }", "language": "javascript"}
{"input": "Wrap comparison operations to convert Period-like to PeriodDtype", "output": "def _period_array_cmp(cls, op):\n    \"\"\"\n    Wrap comparison operations to convert Period-like to PeriodDtype\n    \"\"\"\n    opname = '__{name}__'.format(name=op.__name__)\n    nat_result = opname == '__ne__'\n\n    def wrapper(self, other):\n        op = getattr(self.asi8, opname)\n\n        if isinstance(other, (ABCDataFrame, ABCSeries, ABCIndexClass)):\n            return NotImplemented\n\n        if is_list_like(other) and len(other) != len(self):\n            raise ValueError(\"Lengths must match\")\n\n        if isinstance(other, Period):\n            self._check_compatible_with(other)\n\n            result = op(other.ordinal)\n        elif isinstance(other, cls):\n            self._check_compatible_with(other)\n\n            result = op(other.asi8)\n\n            mask = self._isnan | other._isnan\n            if mask.any():\n                result[mask] = nat_result\n\n            return result\n        elif other is NaT:\n            result = np.empty(len(self.asi8), dtype=bool)\n            result.fill(nat_result)\n        else:\n            other = Period(other, freq=self.freq)\n            result = op(other.ordinal)\n\n        if self._hasnans:\n            result[self._isnan] = nat_result\n\n        return result\n\n    return compat.set_function_name(wrapper, opname, cls)", "language": "python"}
{"input": "Calculate mean rewards from given epoch.", "output": "def compute_mean_reward(rollouts, clipped):\n  \"\"\"Calculate mean rewards from given epoch.\"\"\"\n  reward_name = \"reward\" if clipped else \"unclipped_reward\"\n  rewards = []\n  for rollout in rollouts:\n    if rollout[-1].done:\n      rollout_reward = sum(getattr(frame, reward_name) for frame in rollout)\n      rewards.append(rollout_reward)\n  if rewards:\n    mean_rewards = np.mean(rewards)\n  else:\n    mean_rewards = 0\n  return mean_rewards", "language": "python"}
{"input": "Ensures that argument passed in arg_name is of type bool.", "output": "def validate_bool_kwarg(value, arg_name):\n    \"\"\" Ensures that argument passed in arg_name is of type bool. \"\"\"\n    if not (is_bool(value) or value is None):\n        raise ValueError('For argument \"{arg}\" expected type bool, received '\n                         'type {typ}.'.format(arg=arg_name,\n                                              typ=type(value).__name__))\n    return value", "language": "python"}
{"input": "Updates the options of Popper\n@method\n@memberof Popper", "output": "function updateModifiers() {\n  if (this.state.isDestroyed) {\n    return;\n  }\n  // Deep merge modifiers options\n  let options = this.defaultOptions;\n  this.options.modifiers = {};\n  const _this = this;\n  Object.keys(_extends({}, Popper.Defaults.modifiers, options.modifiers)).forEach(function (name) {\n    _this.options.modifiers[name] = _extends({}, Popper.Defaults.modifiers[name] || {}, options.modifiers ? options.modifiers[name] : {});\n  });\n\n  // Refactoring modifiers' list (Object => Array)\n  this.modifiers = Object.keys(this.options.modifiers).map(function (name) {\n    return _extends({\n      name: name\n    }, _this.options.modifiers[name]);\n  })\n  // sort the modifiers by order\n    .sort(function (a, b) {\n      return a.order - b.order;\n    });\n\n  // modifiers have the ability to execute arbitrary code when Popper.js get inited\n  // such code is executed in the same order of its modifier\n  // they could add new properties to their options configuration\n  // BE AWARE: don't add options to `options.modifiers.name` but to `modifierOptions`!\n  this.modifiers.forEach(function (modifierOptions) {\n    if (modifierOptions.enabled && isFunction(modifierOptions.onLoad)) {\n      modifierOptions.onLoad(_this.reference, _this.popper, _this.options, modifierOptions, _this.state);\n    }\n  });\n}", "language": "javascript"}
{"input": "Version for IR", "output": "function getSourceDefinitionName(\n  node: Fragment | Request | Root | SplitOperation,\n): string {\n  const derivedFrom =\n    node.kind === 'Request' ||\n    node.kind === 'Root' ||\n    node.kind === 'SplitOperation'\n      ? node.metadata?.derivedFrom\n      : null;\n  return typeof derivedFrom === 'string' ? derivedFrom : node.name;\n}", "language": "javascript"}
{"input": "provide concatenation of an datetimelike array of arrays each of which is a\n    single M8[ns], datetimet64[ns, tz] or m8[ns] dtype\n\n    Parameters\n    ----------\n    to_concat : array of arrays\n    axis : axis to provide concatenation\n    typs : set of to_concat dtypes\n\n    Returns\n    -------\n    a single array, preserving the combined dtypes", "output": "def _concat_datetime(to_concat, axis=0, typs=None):\n    \"\"\"\n    provide concatenation of an datetimelike array of arrays each of which is a\n    single M8[ns], datetimet64[ns, tz] or m8[ns] dtype\n\n    Parameters\n    ----------\n    to_concat : array of arrays\n    axis : axis to provide concatenation\n    typs : set of to_concat dtypes\n\n    Returns\n    -------\n    a single array, preserving the combined dtypes\n    \"\"\"\n\n    if typs is None:\n        typs = get_dtype_kinds(to_concat)\n\n    # multiple types, need to coerce to object\n    if len(typs) != 1:\n        return _concatenate_2d([_convert_datetimelike_to_object(x)\n                                for x in to_concat],\n                               axis=axis)\n\n    # must be single dtype\n    if any(typ.startswith('datetime') for typ in typs):\n\n        if 'datetime' in typs:\n            to_concat = [x.astype(np.int64, copy=False) for x in to_concat]\n            return _concatenate_2d(to_concat, axis=axis).view(_NS_DTYPE)\n        else:\n            # when to_concat has different tz, len(typs) > 1.\n            # thus no need to care\n            return _concat_datetimetz(to_concat)\n\n    elif 'timedelta' in typs:\n        return _concatenate_2d([x.view(np.int64) for x in to_concat],\n                               axis=axis).view(_TD_DTYPE)\n\n    elif any(typ.startswith('period') for typ in typs):\n        assert len(typs) == 1\n        cls = to_concat[0]\n        new_values = cls._concat_same_type(to_concat)\n        return new_values", "language": "python"}
{"input": "Returns a list of tables/views in the specified database.\n\n        If no database is specified, the current database is used.\n        This includes all temporary views.", "output": "def listTables(self, dbName=None):\n        \"\"\"Returns a list of tables/views in the specified database.\n\n        If no database is specified, the current database is used.\n        This includes all temporary views.\n        \"\"\"\n        if dbName is None:\n            dbName = self.currentDatabase()\n        iter = self._jcatalog.listTables(dbName).toLocalIterator()\n        tables = []\n        while iter.hasNext():\n            jtable = iter.next()\n            tables.append(Table(\n                name=jtable.name(),\n                database=jtable.database(),\n                description=jtable.description(),\n                tableType=jtable.tableType(),\n                isTemporary=jtable.isTemporary()))\n        return tables", "language": "python"}
{"input": "Create a custom variable getter for diet variables according to params.", "output": "def make_diet_var_getter(params):\n  \"\"\"Create a custom variable getter for diet variables according to params.\"\"\"\n\n  def diet_var_initializer(shape, dtype, partition_info=None):\n    \"\"\"Initializer for a diet variable.\"\"\"\n    del dtype\n    del partition_info\n\n    with common_layers.fn_device_dependency(\"diet_init\") as out_deps:\n      float_range = math.sqrt(3)\n      ret = tf.random_uniform(shape, -float_range, float_range)\n      if params.quantize:\n        ret = _quantize(ret, params, randomize=False)\n      out_deps.append(ret)\n      return ret\n\n  def diet_var_getter(getter, **kwargs):\n    \"\"\"Get diet variable and return it dequantized.\"\"\"\n    if params.quantize:\n      kwargs[\"dtype\"] = tf.float16\n    kwargs[\"initializer\"] = diet_var_initializer\n    kwargs[\"trainable\"] = False\n\n    base_var = getter(**kwargs)\n\n    dequantized = _dequantize(base_var, params)\n\n    if not hasattr(params, \"dequantized\"):\n      params.dequantized = defaultdict(list)\n    params.dequantized[base_var.name].append(dequantized)\n\n    return dequantized\n\n  return diet_var_getter", "language": "python"}
{"input": "Mesure an operation\n\n@parqm {String} type\n@param {Promise} p\n@return {Promise}", "output": "function measure(type, p) {\n    timers[type] = timers[type] || {\n        type: type,\n        count: 0,\n        total: 0,\n        min: undefined,\n        max: 0\n    };\n\n    var start = Date.now();\n\n    return p\n    .fin(function() {\n        var end = Date.now();\n        var duration = (end - start);\n\n        timers[type].count ++;\n        timers[type].total += duration;\n\n        if (is.undefined(timers[type].min)) {\n            timers[type].min = duration;\n        } else {\n            timers[type].min = Math.min(timers[type].min, duration);\n        }\n\n        timers[type].max = Math.max(timers[type].max, duration);\n    });\n}", "language": "javascript"}
{"input": "Adds new frame to (initial) frame stack, removes last one.", "output": "def add_to_initial_stack(self, frame):\n    \"\"\"Adds new frame to (initial) frame stack, removes last one.\"\"\"\n    if not self._setable_initial_frames:\n      raise ValueError(\n          \"This instance does not allow to manually set initial frame stack.\")\n    assert_msg = \"{}, {}\".format(frame.shape, self._initial_frames.shape[:1])\n    assert frame.shape == self._initial_frames.shape[2:], assert_msg\n    initial_frames = np.roll(self._initial_frames, shift=-1, axis=1)\n    initial_frames[0, -1, ...] = frame\n    self._initial_frames = initial_frames", "language": "python"}
{"input": "\u521d\u59cb\u5316\n@method init\n@public", "output": "function (cfg) {\n    this._cfg = merge({\n      delay: 400\n    }, cfg)\n\n    // \u4e8b\u4ef6\u8ba2\u9605\u6570\u7ec4\n    this._subs = {\n      on: [],\n      after: []\n    }\n\n    // \u5f53\u524d\u4fe1\u606f\n    this.info = this.getInfo()\n\n    // \u7ed1\u5b9a\u4e8b\u4ef6\u56de\u8c03\u4e0a\u4e0b\u6587\n    this._onWinOrientationChange = bind(this._onWinOrientationChange, this)\n\n    // \u7ed1\u5b9a\u7a97\u53e3\u5207\u6362\u4e8b\u4ef6\n    window.addEventListener(EVT_ORIENTATION_CHANGE, this._onWinOrientationChange, false)\n  }", "language": "javascript"}
{"input": "Replace position markers of blocks by body after processing\nThis is done to avoid that markdown/asciidoc processer parse the block content\n\n@param {String} content\n@return {Object} {blocks: Set, content: String}", "output": "function replaceBlocks(content, blocks) {\n    var newContent = content.replace(/\\{\\{\\-\\%([\\s\\S]+?)\\%\\-\\}\\}/g, function(match, key) {\n        var replacedWith = match;\n\n        var block = blocks.get(key);\n        if (block) {\n            replacedWith = replaceBlocks(block.get('body'), blocks);\n        }\n\n        return replacedWith;\n    });\n\n    return newContent;\n}", "language": "javascript"}
{"input": "Loads the default stop words for the given language.\n        Supported languages: danish, dutch, english, finnish, french, german, hungarian,\n        italian, norwegian, portuguese, russian, spanish, swedish, turkish", "output": "def loadDefaultStopWords(language):\n        \"\"\"\n        Loads the default stop words for the given language.\n        Supported languages: danish, dutch, english, finnish, french, german, hungarian,\n        italian, norwegian, portuguese, russian, spanish, swedish, turkish\n        \"\"\"\n        stopWordsObj = _jvm().org.apache.spark.ml.feature.StopWordsRemover\n        return list(stopWordsObj.loadDefaultStopWords(language))", "language": "python"}
{"input": "compute bounding box regression targets from ex_rois to gt_rois\n    :param ex_rois: [N, 4]\n    :param gt_rois: [N, 4]\n    :return: [N, 4]", "output": "def bbox_transform(ex_rois, gt_rois, box_stds):\n    \"\"\"\n    compute bounding box regression targets from ex_rois to gt_rois\n    :param ex_rois: [N, 4]\n    :param gt_rois: [N, 4]\n    :return: [N, 4]\n    \"\"\"\n    assert ex_rois.shape[0] == gt_rois.shape[0], 'inconsistent rois number'\n\n    ex_widths = ex_rois[:, 2] - ex_rois[:, 0] + 1.0\n    ex_heights = ex_rois[:, 3] - ex_rois[:, 1] + 1.0\n    ex_ctr_x = ex_rois[:, 0] + 0.5 * (ex_widths - 1.0)\n    ex_ctr_y = ex_rois[:, 1] + 0.5 * (ex_heights - 1.0)\n\n    gt_widths = gt_rois[:, 2] - gt_rois[:, 0] + 1.0\n    gt_heights = gt_rois[:, 3] - gt_rois[:, 1] + 1.0\n    gt_ctr_x = gt_rois[:, 0] + 0.5 * (gt_widths - 1.0)\n    gt_ctr_y = gt_rois[:, 1] + 0.5 * (gt_heights - 1.0)\n\n    targets_dx = (gt_ctr_x - ex_ctr_x) / (ex_widths + 1e-14) / box_stds[0]\n    targets_dy = (gt_ctr_y - ex_ctr_y) / (ex_heights + 1e-14) / box_stds[1]\n    targets_dw = np.log(gt_widths / ex_widths) / box_stds[2]\n    targets_dh = np.log(gt_heights / ex_heights) / box_stds[3]\n\n    targets = np.vstack((targets_dx, targets_dy, targets_dw, targets_dh)).transpose()\n    return targets", "language": "python"}
{"input": "Return the :class:`~matplotlib.units.AxisInfo` for *unit*.\n\n        *unit* is a tzinfo instance or None.\n        The *axis* argument is required but not used.", "output": "def axisinfo(unit, axis):\n        \"\"\"\n        Return the :class:`~matplotlib.units.AxisInfo` for *unit*.\n\n        *unit* is a tzinfo instance or None.\n        The *axis* argument is required but not used.\n        \"\"\"\n        tz = unit\n\n        majloc = PandasAutoDateLocator(tz=tz)\n        majfmt = PandasAutoDateFormatter(majloc, tz=tz)\n        datemin = pydt.date(2000, 1, 1)\n        datemax = pydt.date(2010, 1, 1)\n\n        return units.AxisInfo(majloc=majloc, majfmt=majfmt, label='',\n                              default_limits=(datemin, datemax))", "language": "python"}
{"input": "Create Tensor of sinusoids of different frequencies.\n\n  Args:\n    length: Length of the Tensor to create, i.e. Number of steps.\n    min_timescale: a float\n    max_timescale: a float\n    num_timescales: an int\n\n  Returns:\n    Tensor of shape (length, 2*num_timescales)", "output": "def get_timing_signal(length,\n                      min_timescale=1,\n                      max_timescale=1e4,\n                      num_timescales=16):\n  \"\"\"Create Tensor of sinusoids of different frequencies.\n\n  Args:\n    length: Length of the Tensor to create, i.e. Number of steps.\n    min_timescale: a float\n    max_timescale: a float\n    num_timescales: an int\n\n  Returns:\n    Tensor of shape (length, 2*num_timescales)\n  \"\"\"\n  positions = to_float(tf.range(length))\n  log_timescale_increment = (\n      math.log(max_timescale / min_timescale) / (num_timescales - 1))\n  inv_timescales = min_timescale * tf.exp(\n      to_float(tf.range(num_timescales)) * -log_timescale_increment)\n  scaled_time = tf.expand_dims(positions, 1) * tf.expand_dims(inv_timescales, 0)\n  return tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)", "language": "python"}
{"input": "HParams for parsing on WSJ semi-supervised.", "output": "def transformer_parsing_big():\n  \"\"\"HParams for parsing on WSJ semi-supervised.\"\"\"\n  hparams = transformer_big()\n  hparams.max_length = 512\n  hparams.shared_source_target_embedding = False\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.layer_prepostprocess_dropout = 0.1\n  hparams.batch_size = 2048\n  hparams.learning_rate = 0.05\n  return hparams", "language": "python"}
{"input": "`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.", "output": "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:\n    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n    x,y = b\n    mean,std = mean.to(x.device),std.to(x.device)\n    if do_x: x = normalize(x,mean,std)\n    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n    return x,y", "language": "python"}
{"input": "Resolves a variable like :meth:`resolve` but returns the\n        special `missing` value if it cannot be found.", "output": "def resolve_or_missing(self, key):\n        \"\"\"Resolves a variable like :meth:`resolve` but returns the\n        special `missing` value if it cannot be found.\n        \"\"\"\n        if self._legacy_resolve_mode:\n            rv = self.resolve(key)\n            if isinstance(rv, Undefined):\n                rv = missing\n            return rv\n        return resolve_or_missing(self, key)", "language": "python"}
{"input": "/* Dark mode", "output": "function loadDarkMode () {\n  let enabled, forcedTheme\n  if ((forcedTheme = getForcedTheme())) {\n    enabled = forcedTheme === 'dark'\n  } else {\n    const raw = localStorage.getItem('vue-ui-dark-mode')\n    enabled = raw === 'true'\n  }\n  apolloClient.mutate({\n    mutation: DARK_MODE_SET,\n    variables: {\n      enabled\n    }\n  })\n}", "language": "javascript"}
{"input": "Handling old Demo Kit API routes which should be navigated to new routes\n@param {object} oEvent event object\n@private", "output": "function(oEvent) {\n\t\t\tvar sEntityType,\n\t\t\t\tsEntityId,\n\t\t\t\taSplit,\n\t\t\t\tsId = oEvent.getParameter(\"arguments\").id;\n\n\t\t\tif (sId) {\n\t\t\t\taSplit = sId.split(\"#\");\n\t\t\t\tif (aSplit.length === 2) {\n\t\t\t\t\tsId = aSplit[0];\n\t\t\t\t\tsEntityType = aSplit[1];\n\n\t\t\t\t\taSplit = sEntityType.split(\":\");\n\t\t\t\t\tif (aSplit.length === 2) {\n\t\t\t\t\t\tsEntityType = aSplit[0];\n\t\t\t\t\t\tsEntityId = aSplit[1];\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tsId = sId.replace(/.html$/, \"\");\n\n\t\t\t\tif (sEntityType === 'event') { // legacy keyword is singular\n\t\t\t\t\tsEntityType = \"events\";\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tthis.navTo(\"apiId\", {id: sId, entityType: sEntityType, entityId: sEntityId});\n\t\t}", "language": "javascript"}
{"input": "Return a dict for the globals.", "output": "def make_globals(self, d):\n        \"\"\"Return a dict for the globals.\"\"\"\n        if not d:\n            return self.globals\n        return dict(self.globals, **d)", "language": "python"}
{"input": "Provides Trial objects to be queued into the TrialRunner.\n\n        Returns:\n            trials (list): Returns a list of trials.", "output": "def next_trials(self):\n        \"\"\"Provides Trial objects to be queued into the TrialRunner.\n\n        Returns:\n            trials (list): Returns a list of trials.\n        \"\"\"\n        trials = list(self._trial_generator)\n        if self._shuffle:\n            random.shuffle(trials)\n        self._finished = True\n        return trials", "language": "python"}
{"input": "Query an element that's known to exist by a selector. We use this instead of\njust calling querySelector and not checking the result because this lets us\nsatisfy the JSCompiler type system.\n@param {string} selectors CSS selectors to query the element.\n@param {(!Document|!DocumentFragment|!Element)=} opt_context An optional\ncontext object for querySelector.\n@return {!HTMLElement} the Element.", "output": "function queryRequiredElement(selectors, opt_context) {\n  var element = (opt_context || document).querySelector(selectors);\n  return assertInstanceof(element, HTMLElement,\n                          'Missing required element: ' + selectors);\n}", "language": "javascript"}
{"input": "@private\n\nSee `FileTreeViewModel.isFilePathVisible`", "output": "function _isFilePathVisible(treeData, path) {\n        if (path === null) {\n            return null;\n        } else if (path === \"\") {\n            return true;\n        }\n\n        var parts = path.split(\"/\"),\n            part = parts.shift(),\n            result = [],\n            node;\n\n        while (part) {\n            if (treeData === null) {\n                return false;\n            }\n            node = treeData.get(part);\n            if (node === undefined) {\n                return null;\n            }\n            result.push(part);\n            part = parts.shift();\n            if (part) {\n                if (!node.get(\"open\")) {\n                    return false;\n                }\n                treeData = node.get(\"children\");\n                if (treeData) {\n                    result.push(\"children\");\n                }\n            }\n        }\n\n        return true;\n    }", "language": "javascript"}
{"input": "Decode one chunk of the input.\n\n        :param input: A byte string.\n        :param final:\n            Indicate that no more input is available.\n            Must be :obj:`True` if this is the last call.\n        :returns: An Unicode string.", "output": "def decode(self, input, final=False):\n        \"\"\"Decode one chunk of the input.\n\n        :param input: A byte string.\n        :param final:\n            Indicate that no more input is available.\n            Must be :obj:`True` if this is the last call.\n        :returns: An Unicode string.\n\n        \"\"\"\n        decoder = self._decoder\n        if decoder is not None:\n            return decoder(input, final)\n\n        input = self._buffer + input\n        encoding, input = _detect_bom(input)\n        if encoding is None:\n            if len(input) < 3 and not final:  # Not enough data yet.\n                self._buffer = input\n                return ''\n            else:  # No BOM\n                encoding = self._fallback_encoding\n        decoder = encoding.codec_info.incrementaldecoder(self._errors).decode\n        self._decoder = decoder\n        self.encoding = encoding\n        return decoder(input, final)", "language": "python"}
{"input": "Return training and testing iterator for the CUB200-2011 dataset.", "output": "def cub200_iterator(data_path, batch_k, batch_size, data_shape):\n    \"\"\"Return training and testing iterator for the CUB200-2011 dataset.\"\"\"\n    return (CUB200Iter(data_path, batch_k, batch_size, data_shape, is_train=True),\n            CUB200Iter(data_path, batch_k, batch_size, data_shape, is_train=False))", "language": "python"}
{"input": "Deep-renders the `wrappingComponent` and returns the context that should\nbe accessible to the primary wrapper.\n\n@param {WrappingComponentWrapper} wrapper The `WrappingComponentWrapper` for a\n`wrappingComponent`\n@param {Adapter} adapter An Enzyme adapter\n@returns {object} An object containing an object of legacy context values and a Map of\n`createContext()` Provider values.", "output": "function getContextFromWrappingComponent(wrapper, adapter) {\n  const rootFinder = deepRender(wrapper, wrapper[ROOT_FINDER], adapter);\n  if (!rootFinder) {\n    throw new Error('`wrappingComponent` must render its children!');\n  }\n  return {\n    legacyContext: rootFinder[OPTIONS].context,\n    providerValues: rootFinder[PROVIDER_VALUES],\n  };\n}", "language": "javascript"}
{"input": "Computes metrics from predictions.\n\n  Args:\n    predictions: list of list of dicts.\n                 outer length: num_decodes, inner_length: num_samples\n    decode_hparams: Decode hparams. instance of HParams.\n  Returns:\n    statistics: dict of Tensors, key being the metric with each Tensor\n                having the shape (num_samples, num_frames).", "output": "def compute_video_metrics_from_predictions(predictions, decode_hparams):\n  \"\"\"Computes metrics from predictions.\n\n  Args:\n    predictions: list of list of dicts.\n                 outer length: num_decodes, inner_length: num_samples\n    decode_hparams: Decode hparams. instance of HParams.\n  Returns:\n    statistics: dict of Tensors, key being the metric with each Tensor\n                having the shape (num_samples, num_frames).\n  \"\"\"\n  all_results = {}\n\n\n  ssim_all_decodes, psnr_all_decodes = [], []\n  for single_decode in predictions:\n    args = get_zipped_dataset_from_predictions(single_decode)\n    psnr_single, ssim_single = compute_one_decoding_video_metrics(*args)\n    psnr_all_decodes.append(psnr_single)\n    ssim_all_decodes.append(ssim_single)\n  psnr_all_decodes = np.array(psnr_all_decodes)\n  ssim_all_decodes = np.array(ssim_all_decodes)\n  all_results.update({\"PSNR\": psnr_all_decodes, \"SSIM\": ssim_all_decodes})\n  return compute_all_metrics_statistics(all_results)", "language": "python"}
{"input": "Find the index of a filter set in the list of saved filter sets.\n@param {Array.<{name: string, patterns: Array.<string>}>} filterSets\n@return {{name: string, patterns: Array.<string>}} filter", "output": "function _getFilterIndex(filterSets, filter) {\n        var index = -1;\n\n        if (!filter || !filterSets.length) {\n            return index;\n        }\n\n        return _.findIndex(filterSets, _.partial(_.isEqual, filter));\n    }", "language": "javascript"}
{"input": "Fix all links in generated files to other generated files to point to top\nlevel of generated docs dir.\n\n@param {Array} htmlFiles List of html files found in generated dir.", "output": "function fixAllLinks(htmlFiles) {\n  const writePromises = [];\n  htmlFiles.forEach(file => {\n    // Update links in each html file to match flattened file structure.\n    writePromises.push(fixLinks(`${docPath}/${file}.html`));\n  });\n  return Promise.all(writePromises);\n}", "language": "javascript"}
{"input": "Counts the number of initialized and uninitialized declarations in a list of declarations\n@param {ASTNode[]} declarations List of declarations\n@returns {Object} Counts of 'uninitialized' and 'initialized' declarations\n@private", "output": "function countDeclarations(declarations) {\n            const counts = { uninitialized: 0, initialized: 0 };\n\n            for (let i = 0; i < declarations.length; i++) {\n                if (declarations[i].init === null) {\n                    counts.uninitialized++;\n                } else {\n                    counts.initialized++;\n                }\n            }\n            return counts;\n        }", "language": "javascript"}
{"input": "replaces impure computed keys with new identifiers and returns variable declarators of these new identifiers", "output": "function replaceImpureComputedKeys(path) {\n    const impureComputedPropertyDeclarators = [];\n    for (const propPath of path.get(\"properties\")) {\n      const key = propPath.get(\"key\");\n      if (propPath.node.computed && !key.isPure()) {\n        const name = path.scope.generateUidBasedOnNode(key.node);\n        const declarator = t.variableDeclarator(t.identifier(name), key.node);\n        impureComputedPropertyDeclarators.push(declarator);\n        key.replaceWith(t.identifier(name));\n      }\n    }\n    return impureComputedPropertyDeclarators;\n  }", "language": "javascript"}
{"input": "Recreate an error from a transferred payload `err`\n\n@param {Error} err\n@returns {MoleculerError}", "output": "function recreateError(err) {\n\tconst Class = module.exports[err.name];\n\tif (Class) {\n\t\tswitch(err.name) {\n\t\t\tcase \"MoleculerError\": return new Class(err.message, err.code, err.type, err.data);\n\t\t\tcase \"MoleculerRetryableError\": return new Class(err.message, err.code, err.type, err.data);\n\t\t\tcase \"MoleculerServerError\": return new Class(err.message, err.code, err.type, err.data);\n\t\t\tcase \"MoleculerClientError\": return new Class(err.message, err.code, err.type, err.data);\n\n\t\t\tcase \"ValidationError\": return new Class(err.message, err.type, err.data);\n\n\t\t\tcase \"ServiceNotFoundError\": return new Class(err.data);\n\t\t\tcase \"ServiceNotAvailableError\": return new Class(err.data);\n\t\t\tcase \"RequestTimeoutError\": return new Class(err.data);\n\t\t\tcase \"RequestSkippedError\": return new Class(err.data);\n\t\t\tcase \"RequestRejectedError\": return new Class(err.data);\n\t\t\tcase \"QueueIsFullError\": return new Class(err.data);\n\t\t\tcase \"MaxCallLevelError\": return new Class(err.data);\n\t\t\tcase \"GracefulStopTimeoutError\": return new Class(err.data);\n\t\t\tcase \"ProtocolVersionMismatchError\": return new Class(err.data);\n\t\t\tcase \"InvalidPacketDataError\": return new Class(err.data);\n\n\t\t\tcase \"ServiceSchemaError\":\n\t\t\tcase \"BrokerOptionsError\": return new Class(err.message, err.data);\n\t\t}\n\t}\n}", "language": "javascript"}
{"input": "Set of hyperparameters for a very small imagetransformer with MoE.", "output": "def imagetransformer_moe_tiny():\n  \"\"\"Set of hyperparameters for a very small imagetransformer with MoE.\"\"\"\n  hparams = imagetransformer_tiny()\n  hparams.hidden_size = 64\n  hparams.batch_size = 1\n  hparams.num_hidden_layers = 3\n  hparams.dec_attention_type = cia.AttentionType.MOE_LOCAL_1D\n  hparams.add_hparam(\"moe_layers_decoder\", \"1\")  # Which layer is MoE.\n  hparams.moe_hidden_sizes = \"1024\"  # Hidden layer sizes (comma-separated).\n  hparams.moe_num_experts = 16  # Number of experts in each MoE layer.\n  hparams.moe_k = 2  # How many experts to use per batch element (try 2 or 4).\n  hparams.moe_loss_coef = 1e-2  # MoE loss coefficient (1e-2 is usually ok).\n  return hparams", "language": "python"}
{"input": "This reads until EOF using readline() and returns a list containing\n        the lines thus read. The optional 'sizehint' argument is ignored.\n        Remember, because this reads until EOF that means the child\n        process should have closed its stdout. If you run this method on\n        a child that is still running with its stdout open then this\n        method will block until it timesout.", "output": "def readlines(self, sizehint=-1):\n        '''This reads until EOF using readline() and returns a list containing\n        the lines thus read. The optional 'sizehint' argument is ignored.\n        Remember, because this reads until EOF that means the child\n        process should have closed its stdout. If you run this method on\n        a child that is still running with its stdout open then this\n        method will block until it timesout.'''\n\n        lines = []\n        while True:\n            line = self.readline()\n            if not line:\n                break\n            lines.append(line)\n        return lines", "language": "python"}
{"input": "Remove task format text for rendering\n@param {object} token Token object\n@ignore", "output": "function removeMarkdownTaskFormatText(token) {\n    // '[X] ' length is 4\n    // FIXED: we don't need first space\n    token.content = token.content.slice(4);\n    token.children[0].content = token.children[0].content.slice(4);\n}", "language": "javascript"}
{"input": "/*\nConverts sorter definitions to sap.ui.model.Sorter instances.\n\nThe value of the given property can either be a single sorter definition object\nwhich then will be fed into the constructor of sap.ui.model.Sorter, or it can\nbe an array of such objects.\n\nProperties 'group' and 'comparator' in any of the sorter definitions\nwill be resolved as functions in the given context (oEnv).", "output": "function resolveSorters(o, sProp) {\n\t\t\tvar v = o[sProp];\n\n\t\t\tif ( Array.isArray(v) ) {\n\t\t\t\tv.forEach(function(oObject, iIndex) {\n\t\t\t\t\tresolveSorters(v, iIndex);\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif ( v && typeof v === 'object' ) {\n\t\t\t\tresolveRef(v, \"group\");\n\t\t\t\tresolveRef(v, \"comparator\");\n\t\t\t\to[sProp] = new Sorter(v);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "/* [MS-DTYP] 2.3.3 FILETIME /* [MS-OLEDS] 2.1.3 FILETIME (Packet Version) /* [MS-OLEPS] 2.8 FILETIME (Packet Version)", "output": "function parse_FILETIME(blob) {\n\tvar dwLowDateTime = blob.read_shift(4), dwHighDateTime = blob.read_shift(4);\n\treturn new Date(((dwHighDateTime/1e7*Math.pow(2,32) + dwLowDateTime/1e7) - 11644473600)*1000).toISOString().replace(/\\.000/,\"\");\n}", "language": "javascript"}
{"input": "Given a representation of the board, returns a list of open spaces.", "output": "def get_open_spaces(board):\n  \"\"\"Given a representation of the board, returns a list of open spaces.\"\"\"\n  open_spaces = []\n  for i in range(3):\n    for j in range(3):\n      if board[i][j] == 0:\n        open_spaces.append(encode_pos(i, j))\n  return open_spaces", "language": "python"}
{"input": "Mocked. Retrieve the logs produced by the execution of the query.\n    Can be called multiple times to fetch the logs produced after\n    the previous call.\n    :returns: list<str>\n    :raises: ``ProgrammingError`` when no query has been started\n    .. note::\n        This is not a part of DB-API.", "output": "def fetch_logs(self, max_rows=1024,\n               orientation=None):\n    \"\"\"Mocked. Retrieve the logs produced by the execution of the query.\n    Can be called multiple times to fetch the logs produced after\n    the previous call.\n    :returns: list<str>\n    :raises: ``ProgrammingError`` when no query has been started\n    .. note::\n        This is not a part of DB-API.\n    \"\"\"\n    from pyhive import hive\n    from TCLIService import ttypes\n    from thrift import Thrift\n    orientation = orientation or ttypes.TFetchOrientation.FETCH_NEXT\n    try:\n        req = ttypes.TGetLogReq(operationHandle=self._operationHandle)\n        logs = self._connection.client.GetLog(req).log\n        return logs\n    # raised if Hive is used\n    except (ttypes.TApplicationException,\n            Thrift.TApplicationException):\n        if self._state == self._STATE_NONE:\n            raise hive.ProgrammingError('No query yet')\n        logs = []\n        while True:\n            req = ttypes.TFetchResultsReq(\n                operationHandle=self._operationHandle,\n                orientation=ttypes.TFetchOrientation.FETCH_NEXT,\n                maxRows=self.arraysize,\n                fetchType=1,  # 0: results, 1: logs\n            )\n            response = self._connection.client.FetchResults(req)\n            hive._check_status(response)\n            assert not response.results.rows, \\\n                'expected data in columnar format'\n            assert len(response.results.columns) == 1, response.results.columns\n            new_logs = hive._unwrap_column(response.results.columns[0])\n            logs += new_logs\n            if not new_logs:\n                break\n        return '\\n'.join(logs)", "language": "python"}
{"input": "Imports the Applications and Entities defined in JDL\nThe app .yo-rc.json files and entity json files are written to disk", "output": "function importJDL() {\n    logger.info('The JDL is being parsed.');\n    const jdlImporter = new jhiCore.JDLImporter(this.jdlFiles, {\n        databaseType: this.prodDatabaseType,\n        applicationType: this.applicationType,\n        applicationName: this.baseName,\n        generatorVersion: packagejs.version,\n        forceNoFiltering: this.options.force\n    });\n    let importState = {\n        exportedEntities: [],\n        exportedApplications: [],\n        exportedDeployments: []\n    };\n    try {\n        importState = jdlImporter.import();\n        logger.debug(`importState exportedEntities: ${importState.exportedEntities.length}`);\n        logger.debug(`importState exportedApplications: ${importState.exportedApplications.length}`);\n        logger.debug(`importState exportedDeployments: ${importState.exportedDeployments.length}`);\n        updateDeploymentState(importState);\n        if (importState.exportedEntities.length > 0) {\n            const entityNames = _.uniq(importState.exportedEntities.map(exportedEntity => exportedEntity.name)).join(', ');\n            logger.info(`Found entities: ${chalk.yellow(entityNames)}.`);\n        } else {\n            logger.info(chalk.yellow('No change in entity configurations, no entities were updated.'));\n        }\n        logger.info('The JDL has been successfully parsed');\n    } catch (error) {\n        logger.debug('Error:', error);\n        if (error) {\n            const errorName = `${error.name}:` || '';\n            const errorMessage = error.message || '';\n            logger.log(chalk.red(`${errorName} ${errorMessage}`));\n        }\n        logger.error(`Error while parsing applications and entities from the JDL ${error}`, error);\n    }\n    return importState;\n}", "language": "javascript"}
{"input": "A styled version of the Next.js Link component: https://nextjs.org/docs/#with-link", "output": "function Link(props) {\n  const { activeClassName, router, className: classNameProps, naked, ...other } = props;\n\n  const className = clsx(classNameProps, {\n    [activeClassName]: router.pathname === props.href && activeClassName,\n  });\n\n  if (naked) {\n    return <NextComposed className={className} {...other} />;\n  }\n\n  return <MuiLink component={NextComposed} className={className} {...other} />;\n}", "language": "javascript"}
{"input": "Resolves a CodeMirror mode to a Language object.\n@param {!string} mode CodeMirror mode\n@return {Language} The language for the provided mode or the fallback language", "output": "function _getLanguageForMode(mode) {\n        var language = _modeToLanguageMap[mode];\n        if (language) {\n            return language;\n        }\n\n        // In case of unsupported languages\n        console.log(\"Called LanguageManager._getLanguageForMode with a mode for which no language has been registered:\", mode);\n        return _fallbackLanguage;\n    }", "language": "javascript"}
{"input": "Mean squared error between `pred` and `targ`.", "output": "def mean_squared_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    \"Mean squared error between `pred` and `targ`.\"\n    pred,targ = flatten_check(pred,targ)\n    return F.mse_loss(pred, targ)", "language": "python"}
{"input": "Computes the loss on the next minibatch of the validation set.", "output": "def validate_next(stepper, metrics, val_iter):\n    \"\"\"Computes the loss on the next minibatch of the validation set.\"\"\"\n    stepper.reset(False)\n    with no_grad_context():\n        (*x,y) = val_iter.next()\n        preds,l = stepper.evaluate(VV(x), VV(y))\n        res = [delistify(to_np(l))]\n        res += [f(datafy(preds), datafy(y)) for f in metrics]\n    stepper.reset(True)\n    return res", "language": "python"}
{"input": "Checks whether the given variable has any references from a more specific\nfunction expression (i.e. a closure).\n\n@param {eslint-scope.Variable} variable - A variable to check.\n@returns {boolean} `true` if the variable is used from a closure.", "output": "function isReferencedInClosure(variable) {\n    const enclosingFunctionScope = getEnclosingFunctionScope(variable.scope);\n\n    return variable.references.some(reference =>\n        getEnclosingFunctionScope(reference.from) !== enclosingFunctionScope);\n}", "language": "javascript"}
{"input": "/* [MS-XLS] 2.5.198.30 ; [MS-XLSB] 2.5.97.21", "output": "function parse_PtgAreaErr3d(blob, length, opts) {\n\tvar type = (blob[blob.l++] & 0x60) >> 5;\n\tvar ixti = blob.read_shift(2);\n\tvar w = 8;\n\tif(opts) switch(opts.biff) {\n\t\tcase 5: blob.l += 12; w = 6; break;\n\t\tcase 12: w = 12; break;\n\t}\n\tblob.l += w;\n\treturn [type, ixti];\n}", "language": "javascript"}
{"input": "process user's style guide of choice and return an appropriate config object.\n@param {string} guide name of the chosen style guide\n@returns {Object} config object", "output": "function getConfigForStyleGuide(guide) {\n    const guides = {\n        google: { extends: \"google\" },\n        airbnb: { extends: \"airbnb\" },\n        \"airbnb-base\": { extends: \"airbnb-base\" },\n        standard: { extends: \"standard\" }\n    };\n\n    if (!guides[guide]) {\n        throw new Error(\"You referenced an unsupported guide.\");\n    }\n\n    return guides[guide];\n}", "language": "javascript"}
{"input": "To avoid numpy DeprecationWarnings, cast float to integer where valid.\n\n    Parameters\n    ----------\n    val : scalar\n\n    Returns\n    -------\n    outval : scalar", "output": "def cast_scalar_indexer(val):\n    \"\"\"\n    To avoid numpy DeprecationWarnings, cast float to integer where valid.\n\n    Parameters\n    ----------\n    val : scalar\n\n    Returns\n    -------\n    outval : scalar\n    \"\"\"\n    # assumes lib.is_scalar(val)\n    if lib.is_float(val) and val == int(val):\n        return int(val)\n    return val", "language": "python"}
{"input": "set scope id attribute for scoped CSS. this is implemented as a special case to avoid the overhead of going through the normal attribute patching process.", "output": "function setScope (vnode) {\n    var i;\n    var ancestor = vnode;\n    while (ancestor) {\n      if (isDef(i = ancestor.context) && isDef(i = i.$options._scopeId)) {\n        nodeOps.setAttribute(vnode.elm, i, '');\n      }\n      ancestor = ancestor.parent;\n    }\n    // for slot content they should also get the scopeId from the host instance.\n    if (isDef(i = activeInstance) &&\n        i !== vnode.context &&\n        isDef(i = i.$options._scopeId)) {\n      nodeOps.setAttribute(vnode.elm, i, '');\n    }\n  }", "language": "javascript"}
{"input": "Get node color\n\n@param {TreeNode} node the node to get color\n@param {module:echarts/model/Series} seriesModel series\n@param {module:echarts/model/Global} ecModel echarts defaults", "output": "function getNodeColor(node, seriesModel, ecModel) {\n    // Color from visualMap\n    var visualColor = node.getVisual('color');\n    var visualMetaList = node.getVisual('visualMeta');\n    if (!visualMetaList || visualMetaList.length === 0) {\n        // Use first-generation color if has no visualMap\n        visualColor = null;\n    }\n\n    // Self color or level color\n    var color = node.getModel('itemStyle').get('color');\n    if (color) {\n        return color;\n    }\n    else if (visualColor) {\n        // Color mapping\n        return visualColor;\n    }\n    else if (node.depth === 0) {\n        // Virtual root node\n        return ecModel.option.color[0];\n    }\n    else {\n        // First-generation color\n        var length = ecModel.option.color.length;\n        color = ecModel.option.color[getRootId(node) % length];\n    }\n    return color;\n}", "language": "javascript"}
{"input": "Links a signed in user with an email and password account.", "output": "function onLinkWithEmailAndPassword() {\n  var email = $('#link-email').val();\n  var password = $('#link-password').val();\n  activeUser().linkWithCredential(\n      firebase.auth.EmailAuthProvider.credential(email, password))\n      .then(onAuthUserCredentialSuccess, onAuthError);\n}", "language": "javascript"}
{"input": "Internal method to handle NA filling of take", "output": "def _assert_take_fillable(self, values, indices, allow_fill=True,\n                              fill_value=None, na_value=None):\n        \"\"\" Internal method to handle NA filling of take \"\"\"\n        # only fill if we are passing a non-None fill_value\n        if allow_fill and fill_value is not None:\n            if (indices < -1).any():\n                msg = ('When allow_fill=True and fill_value is not None, '\n                       'all indices must be >= -1')\n                raise ValueError(msg)\n            taken = [lab.take(indices) for lab in self.codes]\n            mask = indices == -1\n            if mask.any():\n                masked = []\n                for new_label in taken:\n                    label_values = new_label.values()\n                    label_values[mask] = na_value\n                    masked.append(np.asarray(label_values))\n                taken = masked\n        else:\n            taken = [lab.take(indices) for lab in self.codes]\n        return taken", "language": "python"}
{"input": "Return the bool of a single element PandasObject.\n\n        This must be a boolean scalar value, either True or False.  Raise a\n        ValueError if the PandasObject does not have exactly 1 element, or that\n        element is not boolean", "output": "def bool(self):\n        \"\"\"\n        Return the bool of a single element PandasObject.\n\n        This must be a boolean scalar value, either True or False.  Raise a\n        ValueError if the PandasObject does not have exactly 1 element, or that\n        element is not boolean\n        \"\"\"\n        v = self.squeeze()\n        if isinstance(v, (bool, np.bool_)):\n            return bool(v)\n        elif is_scalar(v):\n            raise ValueError(\"bool cannot act on a non-boolean single element \"\n                             \"{0}\".format(self.__class__.__name__))\n\n        self.__nonzero__()", "language": "python"}
{"input": "Prepare the HTML document for readability to scrape it.\nThis includes things like stripping javascript, CSS, and handling terrible markup.\n\n@return void", "output": "function() {\n    var doc = this._doc;\n\n    // Remove all style tags in head\n    this._removeNodes(doc.getElementsByTagName(\"style\"));\n\n    if (doc.body) {\n      this._replaceBrs(doc.body);\n    }\n\n    this._replaceNodeTags(doc.getElementsByTagName(\"font\"), \"SPAN\");\n  }", "language": "javascript"}
{"input": "Creates data model of the rendered controls as a tree.\n@param {Element} nodeElement - HTML DOM element from which the function will star searching.\n@param {Array} resultArray - Array that will contains all the information.\n@private", "output": "function (nodeElement, resultArray) {\n\t\t\t\tvar node = nodeElement;\n\t\t\t\tvar childNode = node.firstElementChild;\n\t\t\t\tvar results = resultArray;\n\t\t\t\tvar subResult = results;\n\t\t\t\tvar control = sap.ui.getCore().byId(node.id);\n\n\t\t\t\tif (node.getAttribute('data-sap-ui') && control) {\n\t\t\t\t\tresults.push({\n\t\t\t\t\t\tid: control.getId(),\n\t\t\t\t\t\tname: control.getMetadata().getName(),\n\t\t\t\t\t\ttype: 'sap-ui-control',\n\t\t\t\t\t\tcontent: []\n\t\t\t\t\t});\n\n\t\t\t\t\tsubResult = results[results.length - 1].content;\n\t\t\t\t} else if (node.getAttribute('data-sap-ui-area')) {\n\t\t\t\t\tresults.push({\n\t\t\t\t\t\tid: node.id,\n\t\t\t\t\t\tname: 'sap-ui-area',\n\t\t\t\t\t\ttype: 'data-sap-ui',\n\t\t\t\t\t\tcontent: []\n\t\t\t\t\t});\n\n\t\t\t\t\tsubResult = results[results.length - 1].content;\n\t\t\t\t}\n\n\t\t\t\twhile (childNode) {\n\t\t\t\t\tthis._createRenderedTreeModel(childNode, subResult);\n\t\t\t\t\tchildNode = childNode.nextElementSibling;\n\t\t\t\t}\n\t\t\t}", "language": "javascript"}
{"input": "Saves scalar value.\n\n    Args:\n      tag: str: label for this data\n      value: int/float: number to log\n      step: int: training step", "output": "def scalar(self, tag, value, step=None):\n    \"\"\"Saves scalar value.\n\n    Args:\n      tag: str: label for this data\n      value: int/float: number to log\n      step: int: training step\n    \"\"\"\n    value = float(onp.array(value))\n    if step is None:\n      step = self._step\n    else:\n      self._step = step\n    summary = Summary(value=[Summary.Value(tag=tag, simple_value=value)])\n    self.add_summary(summary, step)", "language": "python"}
{"input": "Calculate table chape considering index levels.", "output": "def _shape(self, df):\n        \"\"\"\n        Calculate table chape considering index levels.\n        \"\"\"\n\n        row, col = df.shape\n        return row + df.columns.nlevels, col + df.index.nlevels", "language": "python"}
{"input": "Transform a sequence of int ids into a human-readable string.\n\n    EOS is not expected in ids.\n\n    Args:\n      ids: list of integers to be converted.\n      strip_extraneous: bool, whether to strip off extraneous tokens\n        (EOS and PAD).\n\n    Returns:\n      s: human-readable string.", "output": "def decode(self, ids, strip_extraneous=False):\n    \"\"\"Transform a sequence of int ids into a human-readable string.\n\n    EOS is not expected in ids.\n\n    Args:\n      ids: list of integers to be converted.\n      strip_extraneous: bool, whether to strip off extraneous tokens\n        (EOS and PAD).\n\n    Returns:\n      s: human-readable string.\n    \"\"\"\n    if strip_extraneous:\n      ids = strip_ids(ids, list(range(self._num_reserved_ids or 0)))\n    return \" \".join(self.decode_list(ids))", "language": "python"}
{"input": "Calculate the log of linear spectrogram from FFT energy\n    Params:\n        filename (str): Path to the audio file\n        step (int): Step size in milliseconds between windows\n        window (int): FFT window size in milliseconds\n        max_freq (int): Only FFT bins corresponding to frequencies between\n            [0, max_freq] are returned\n        eps (float): Small value to ensure numerical stability (for ln(x))", "output": "def spectrogram_from_file(filename, step=10, window=20, max_freq=None,\n                          eps=1e-14, overwrite=False, save_feature_as_csvfile=False):\n    \"\"\" Calculate the log of linear spectrogram from FFT energy\n    Params:\n        filename (str): Path to the audio file\n        step (int): Step size in milliseconds between windows\n        window (int): FFT window size in milliseconds\n        max_freq (int): Only FFT bins corresponding to frequencies between\n            [0, max_freq] are returned\n        eps (float): Small value to ensure numerical stability (for ln(x))\n    \"\"\"\n\n    csvfilename = filename.replace(\".wav\", \".csv\")\n    if (os.path.isfile(csvfilename) is False) or overwrite:\n        with soundfile.SoundFile(filename) as sound_file:\n            audio = sound_file.read(dtype='float32')\n            sample_rate = sound_file.samplerate\n            if audio.ndim >= 2:\n                audio = np.mean(audio, 1)\n            if max_freq is None:\n                max_freq = sample_rate / 2\n            if max_freq > sample_rate / 2:\n                raise ValueError(\"max_freq must not be greater than half of \"\n                                 \" sample rate\")\n            if step > window:\n                raise ValueError(\"step size must not be greater than window size\")\n            hop_length = int(0.001 * step * sample_rate)\n            fft_length = int(0.001 * window * sample_rate)\n\n            pxx, freqs = spectrogram(\n                audio, fft_length=fft_length, sample_rate=sample_rate,\n                hop_length=hop_length)\n\n            ind = np.where(freqs <= max_freq)[0][-1] + 1\n            res = np.transpose(np.log(pxx[:ind, :] + eps))\n            if save_feature_as_csvfile:\n                np.savetxt(csvfilename, res)\n            return res\n    else:\n        return np.loadtxt(csvfilename)", "language": "python"}
{"input": "Get the prefixed supported property name\n@method\n@memberof Popper.Utils\n@argument {String} property (camelCase)\n@returns {String} prefixed property (camelCase or PascalCase, depending on the vendor prefix)", "output": "function getSupportedPropertyName(property) {\n  const prefixes = [false, 'ms', 'Webkit', 'Moz', 'O'];\n  const upperProp = property.charAt(0).toUpperCase() + property.slice(1);\n\n  for (let i = 0; i < prefixes.length; i++) {\n    const prefix = prefixes[i];\n    const toCheck = prefix ? `${prefix}${upperProp}` : property;\n    if (typeof document.body.style[toCheck] !== 'undefined') {\n      return toCheck;\n    }\n  }\n  return null;\n}", "language": "javascript"}
{"input": "Get label of the property with specified name (identified by property\nmetadata annotation sap:label)\n\n@param {string}\nsPropertyName Property name\n@returns {string} The label string\n@public\n@function\n@name sap.ui.model.analytics.odata4analytics.EntityType#getLabelOfProperty", "output": "function(sPropertyName) {\n\t\t\tvar oProperty = this._oPropertySet[sPropertyName];\n\t\t\tif (oProperty == null) {\n\t\t\t\tthrow \"no such property with name \" + sPropertyName;\n\t\t\t}\n\n\t\t\tif (oProperty.extensions != undefined) {\n\t\t\t\tfor (var i = -1, oExtension; (oExtension = oProperty.extensions[++i]) !== undefined;) {\n\t\t\t\t\tif (!oExtension.namespace == odata4analytics.constants.SAP_NAMESPACE) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (oExtension.name == \"label\") {\n\t\t\t\t\t\treturn oExtension.value;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t}", "language": "javascript"}
{"input": "Determines the new element which will gain the focus.\n\n@param {sap.ui.ux3.ToolPopup} context to get/set instance values\n@private", "output": "function (context) {\n                var oElement;\n                var oFocusControl;\n                var that = context;\n                var defaultFocusableElements = [that._mParameters.firstFocusable, that._mParameters.lastFocusable];\n                // jQuery custom selectors \":sapTabbable\"\n                var aTabbables = jQuery(\":sapTabbable\", that.$()).get();\n\n                // search the first tabbable element\n                for (var i = 0; i < aTabbables.length; i++) {\n                    if (defaultFocusableElements.indexOf(aTabbables[i].id) === -1) {\n                        oElement = aTabbables[i];\n                        break;\n                    }\n                }\n\n                // If a tabbable element is part of a control, focus the control instead\n                // jQuery Plugin \"control\"\n                oFocusControl = jQuery(oElement).control();\n                if (oFocusControl[0]) {\n                    var oFocusDomRef = oFocusControl[0].getFocusDomRef();\n                    oElement = oFocusDomRef || oElement;\n                } else {\n                    // if there is no tabbable element in the content use the first fake\n                    // element to set the focus to the toolpopup\n                    oElement = defaultFocusableElements[0] ? window.document.getElementById(defaultFocusableElements[0]) : null;\n                }\n\n                // oElement might not be available if this function is called during destroy\n                if (oElement) {\n                    if (oElement) {\n                        oElement.focus();\n                    }\n                    that._sInitialFocusId = oElement.id;\n                }\n            }", "language": "javascript"}
{"input": "Local Accuracy\n    transform = \"identity\"\n    sort_order = 2", "output": "def local_accuracy(X, y, model_generator, method_name):\n    \"\"\" Local Accuracy\n    transform = \"identity\"\n    sort_order = 2\n    \"\"\"\n\n    def score_map(true, pred):\n        \"\"\" Converts local accuracy from % of standard deviation to numerical scores for coloring.\n        \"\"\"\n\n        v = min(1.0, np.std(pred - true) / (np.std(true) + 1e-8))\n        if v < 1e-6:\n            return 1.0\n        elif v < 0.01:\n            return 0.9\n        elif v < 0.05:\n            return 0.75\n        elif v < 0.1:\n            return 0.6\n        elif v < 0.2:\n            return 0.4\n        elif v < 0.3:\n            return 0.3\n        elif v < 0.5:\n            return 0.2\n        elif v < 0.7:\n            return 0.1\n        else:\n            return 0.0\n    def score_function(X_train, X_test, y_train, y_test, attr_function, trained_model, random_state):\n        return measures.local_accuracy(\n            X_train, y_train, X_test, y_test, attr_function(X_test),\n            model_generator, score_map, trained_model\n        )\n    return None, __score_method(X, y, None, model_generator, score_function, method_name)", "language": "python"}
{"input": ", \"150\", \"1k\", \"10k\", \"50k\", \"100k\", \"1M\"];", "output": "function createBrokers(transporter) {\n\tlet b1 = new ServiceBroker({\n\t\ttransporter,\n\t\t//requestTimeout: 0,\n\t\tlogger: false,\n\t\t//logLevel: \"debug\",\n\t\tnodeID: \"node-1\"\n\t});\n\n\tlet b2 = new ServiceBroker({\n\t\ttransporter,\n\t\t//requestTimeout: 0,\n\t\tlogger: false,\n\t\t//logLevel: \"debug\",\n\t\tnodeID: \"node-2\"\n\t});\n\n\tb2.createService({\n\t\tname: \"echo\",\n\t\tactions: {\n\t\t\treply(ctx) {\n\t\t\t\treturn ctx.params;\n\t\t\t}\n\t\t}\n\t});\n\n\treturn Promise.all([\n\t\tb1.start(),\n\t\tb2.start()\n\t]).then(() => [b1, b2]);\n}", "language": "javascript"}
{"input": "Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707", "output": "def map(self, fn, *iterables, timeout=None, chunksize=1, prefetch=None):\n        \"\"\"\n        Collects iterables lazily, rather than immediately.\n        Docstring same as parent: https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor\n        Implmentation taken from this PR: https://github.com/python/cpython/pull/707\n        \"\"\"\n        if timeout is not None: end_time = timeout + time.time()\n        if prefetch is None: prefetch = self._max_workers\n        if prefetch < 0: raise ValueError(\"prefetch count may not be negative\")\n        argsiter = zip(*iterables)\n        fs = collections.deque(self.submit(fn, *args) for args in itertools.islice(argsiter, self._max_workers+prefetch))\n        # Yield must be hidden in closure so that the futures are submitted before the first iterator value is required.\n        def result_iterator():\n            nonlocal argsiter\n            try:\n                while fs:\n                    res = fs[0].result() if timeout is None else fs[0].result(end_time-time.time())\n                    # Got a result, future needn't be cancelled\n                    del fs[0]\n                    # Dispatch next task before yielding to keep pipeline full\n                    if argsiter:\n                        try:\n                            args = next(argsiter)\n                        except StopIteration:\n                            argsiter = None\n                        else:\n                            fs.append(self.submit(fn, *args))\n                    yield res\n            finally:\n                for future in fs: future.cancel()\n        return result_iterator()", "language": "python"}
{"input": "Multiply this matrix by a local dense matrix on the right.\n\n        :param matrix: a local dense matrix whose number of rows must match the number of columns\n                       of this matrix\n        :returns: :py:class:`IndexedRowMatrix`\n\n        >>> mat = IndexedRowMatrix(sc.parallelize([(0, (0, 1)), (1, (2, 3))]))\n        >>> mat.multiply(DenseMatrix(2, 2, [0, 2, 1, 3])).rows.collect()\n        [IndexedRow(0, [2.0,3.0]), IndexedRow(1, [6.0,11.0])]", "output": "def multiply(self, matrix):\n        \"\"\"\n        Multiply this matrix by a local dense matrix on the right.\n\n        :param matrix: a local dense matrix whose number of rows must match the number of columns\n                       of this matrix\n        :returns: :py:class:`IndexedRowMatrix`\n\n        >>> mat = IndexedRowMatrix(sc.parallelize([(0, (0, 1)), (1, (2, 3))]))\n        >>> mat.multiply(DenseMatrix(2, 2, [0, 2, 1, 3])).rows.collect()\n        [IndexedRow(0, [2.0,3.0]), IndexedRow(1, [6.0,11.0])]\n        \"\"\"\n        if not isinstance(matrix, DenseMatrix):\n            raise ValueError(\"Only multiplication with DenseMatrix \"\n                             \"is supported.\")\n        return IndexedRowMatrix(self._java_matrix_wrapper.call(\"multiply\", matrix))", "language": "python"}
{"input": "Ensure that a user-provided `secret` is 32 bytes long (the length required\nfor an AES256 key) by hashing it with SHA256.\n\n@param {string|Buffer} secret", "output": "function createSecret (secret) {\n  const hash = crypto.createHash('sha256')\n  hash.update(secret)\n  return hash.digest()\n}", "language": "javascript"}
{"input": "Map MXNet's pad operator attributes to onnx's Pad operator\n    and return the created node.", "output": "def convert_pad(node, **kwargs):\n    \"\"\"Map MXNet's pad operator attributes to onnx's Pad operator\n    and return the created node.\n    \"\"\"\n    name, input_nodes, attrs = get_inputs(node, kwargs)\n\n    mxnet_pad_width = convert_string_to_list(attrs.get(\"pad_width\"))\n    onnx_pad_width = transform_padding(mxnet_pad_width)\n\n    pad_mode = attrs.get(\"mode\")\n\n    if pad_mode == \"constant\":\n        pad_value = float(attrs.get(\"constant_value\")) \\\n            if \"constant_value\" in attrs else 0.0\n        node = onnx.helper.make_node(\n            'Pad',\n            inputs=input_nodes,\n            outputs=[name],\n            mode='constant',\n            value=pad_value,\n            pads=onnx_pad_width,\n            name=name\n        )\n    else:\n        node = onnx.helper.make_node(\n            'Pad',\n            inputs=input_nodes,\n            outputs=[name],\n            mode=pad_mode,\n            pads=onnx_pad_width,\n            name=name\n        )\n\n    return [node]", "language": "python"}
{"input": "Process a directory by looking at all of its entries and recursing\nthrough child directories as is appropriate.", "output": "function processDirectory(directory: string) {\n      // If we were rejected then we should not continue.\n      if (rejected === true) {\n        return;\n      }\n      // We are now waiting on this asynchronous task.\n      waiting++;\n      // Read the directory...\n      fs.readdir(directory, (error, fileNames) => {\n        if (error) {\n          return reject(error);\n        }\n        // Process every file name that we got from reading the directory.\n        for (let i = 0; i < fileNames.length; i++) {\n          processFilePath(directory, fileNames[i]);\n        }\n        // We are done with this async task.\n        done();\n      });\n    }", "language": "javascript"}
{"input": "Infer the schema from dict/namedtuple/object", "output": "def _infer_schema(row, names=None):\n    \"\"\"Infer the schema from dict/namedtuple/object\"\"\"\n    if isinstance(row, dict):\n        items = sorted(row.items())\n\n    elif isinstance(row, (tuple, list)):\n        if hasattr(row, \"__fields__\"):  # Row\n            items = zip(row.__fields__, tuple(row))\n        elif hasattr(row, \"_fields\"):  # namedtuple\n            items = zip(row._fields, tuple(row))\n        else:\n            if names is None:\n                names = ['_%d' % i for i in range(1, len(row) + 1)]\n            elif len(names) < len(row):\n                names.extend('_%d' % i for i in range(len(names) + 1, len(row) + 1))\n            items = zip(names, row)\n\n    elif hasattr(row, \"__dict__\"):  # object\n        items = sorted(row.__dict__.items())\n\n    else:\n        raise TypeError(\"Can not infer schema for type: %s\" % type(row))\n\n    fields = [StructField(k, _infer_type(v), True) for k, v in items]\n    return StructType(fields)", "language": "python"}
{"input": "filters the given map according to the given filter function for keys", "output": "function filter(mMap, fnFilter) {\n\t\t\treturn Object.keys(mMap).filter(fnFilter).reduce(copyTo.bind(mMap), {});\n\t\t}", "language": "javascript"}
{"input": "/* [MS-XLS] 2.4.261", "output": "function parse_ShtProps(blob, length, opts) {\n\tvar def = {area:false};\n\tif(opts.biff != 5) { blob.l += length; return def; }\n\tvar d = blob.read_shift(1); blob.l += 3;\n\tif((d & 0x10)) def.area = true;\n\treturn def;\n}", "language": "javascript"}
{"input": "Control, Internal, Application", "output": "function _fnFindBestMatch(aValues, sBindingPath) {\n\t\tvar iJsonModelMin = -1;\n\t\tvar sJsonModelBestMatch = false;\n\t\taValues.forEach(function(sKey) {\n\t\t\tvar iCurrDest = StringAnalyzer.calculateLevenshteinDistance(sBindingPath, sKey);\n\t\t\tif (iJsonModelMin === -1 || iCurrDest < iJsonModelMin) {\n\t\t\t\tiJsonModelMin = iCurrDest;\n\t\t\t\tsJsonModelBestMatch = sKey;\n\t\t\t}\n\t\t});\n\t\treturn sJsonModelBestMatch;\n\t}", "language": "javascript"}
{"input": "kruskal's algorithm (finds min spanning tree, assuming undirected graph) implemented from pseudocode from wikipedia", "output": "function kruskal(weightFn) {\n    weightFn = weightFn || function (edge) {\n      return 1;\n    };\n\n    var _this$byGroup = this.byGroup(),\n        nodes = _this$byGroup.nodes,\n        edges = _this$byGroup.edges;\n\n    var numNodes = nodes.length;\n    var forest = new Array(numNodes);\n    var A = nodes; // assumes byGroup() creates new collections that can be safely mutated\n\n    var findSetIndex = function findSetIndex(ele) {\n      for (var i = 0; i < forest.length; i++) {\n        var eles = forest[i];\n\n        if (eles.has(ele)) {\n          return i;\n        }\n      }\n    }; // start with one forest per node\n\n\n    for (var i = 0; i < numNodes; i++) {\n      forest[i] = this.spawn(nodes[i]);\n    }\n\n    var S = edges.sort(function (a, b) {\n      return weightFn(a) - weightFn(b);\n    });\n\n    for (var _i = 0; _i < S.length; _i++) {\n      var edge = S[_i];\n      var u = edge.source()[0];\n      var v = edge.target()[0];\n      var setUIndex = findSetIndex(u);\n      var setVIndex = findSetIndex(v);\n      var setU = forest[setUIndex];\n      var setV = forest[setVIndex];\n\n      if (setUIndex !== setVIndex) {\n        A.merge(edge); // combine forests for u and v\n\n        setU.merge(setV);\n        forest.splice(setVIndex, 1);\n      }\n    }\n\n    return A;\n  }", "language": "javascript"}
{"input": "Build an \"__esModule\" header statement setting the property on a given object.", "output": "function buildESModuleHeader(\n  metadata: ModuleMetadata,\n  enumerable: boolean = false,\n) {\n  return (enumerable\n    ? template.statement`\n        EXPORTS.__esModule = true;\n      `\n    : template.statement`\n        Object.defineProperty(EXPORTS, \"__esModule\", {\n          value: true,\n        });\n      `)({ EXPORTS: metadata.exportName });\n}", "language": "javascript"}
{"input": "Sends a shutdown signal to the unity environment, and closes the grpc connection.", "output": "def close(self):\n        \"\"\"\n        Sends a shutdown signal to the unity environment, and closes the grpc connection.\n        \"\"\"\n        if self.is_open:\n            message_input = UnityMessage()\n            message_input.header.status = 400\n            self.unity_to_external.parent_conn.send(message_input)\n            self.unity_to_external.parent_conn.close()\n            self.server.stop(False)\n            self.is_open = False", "language": "python"}
{"input": "Get the parenthesis tokens of a given ObjectExpression node.\nThis incldues the braces of the object literal and enclosing parentheses.\n@param {ASTNode} node The node to get.\n@param {Token} leftArgumentListParen The opening paren token of the argument list.\n@param {SourceCode} sourceCode The source code object to get tokens.\n@returns {Token[]} The parenthesis tokens of the node. This is sorted by the location.", "output": "function getParenTokens(node, leftArgumentListParen, sourceCode) {\n    const parens = [sourceCode.getFirstToken(node), sourceCode.getLastToken(node)];\n    let leftNext = sourceCode.getTokenBefore(node);\n    let rightNext = sourceCode.getTokenAfter(node);\n\n    // Note: don't include the parens of the argument list.\n    while (\n        leftNext &&\n        rightNext &&\n        leftNext.range[0] > leftArgumentListParen.range[0] &&\n        isOpeningParenToken(leftNext) &&\n        isClosingParenToken(rightNext)\n    ) {\n        parens.push(leftNext, rightNext);\n        leftNext = sourceCode.getTokenBefore(leftNext);\n        rightNext = sourceCode.getTokenAfter(rightNext);\n    }\n\n    return parens.sort((a, b) => a.range[0] - b.range[0]);\n}", "language": "javascript"}
{"input": "Restores the state of the batched queue for writing.", "output": "def enable_writes(self):\n        \"\"\"Restores the state of the batched queue for writing.\"\"\"\n        self.write_buffer = []\n        self.flush_lock = threading.RLock()\n        self.flush_thread = FlushThread(self.max_batch_time,\n                                        self._flush_writes)", "language": "python"}
{"input": "Prevent parent scrolling (when the SideNav is open)", "output": "function disableParentScroll(disabled) {\n      if (disabled && !lastParentOverFlow) {\n        lastParentOverFlow = disableScrollTarget.css('overflow');\n        disableScrollTarget.css('overflow', 'hidden');\n      } else if (angular.isDefined(lastParentOverFlow)) {\n        disableScrollTarget.css('overflow', lastParentOverFlow);\n        lastParentOverFlow = undefined;\n      }\n    }", "language": "javascript"}
{"input": "Generate start and end indices per outfile.", "output": "def generate_shard_args(outfiles, num_examples):\n  \"\"\"Generate start and end indices per outfile.\"\"\"\n  num_shards = len(outfiles)\n  num_examples_per_shard = num_examples // num_shards\n  start_idxs = [i * num_examples_per_shard for i in range(num_shards)]\n  end_idxs = list(start_idxs)\n  end_idxs.pop(0)\n  end_idxs.append(num_examples)\n  return zip(start_idxs, end_idxs, outfiles)", "language": "python"}
{"input": "determine the event is from codeblock in markdown/codeblock editor\n@param {CodeMirror} cm - markdown codemirror editor\n@param {string} source - event source\n@param {Object} eventData - event data\n@returns {boolean} - true for the event from codeblock in markdown/codeblock editor\n@ignore", "output": "function _isFromCodeBlockInCodeMirror(cm, source, eventData) {\n  // cursor in codeblock in markdown editor\n  let fromCodeBlockInCodeMirror = source === 'markdown' && cm.getTokenAt(eventData.from).state.overlay.codeBlock;\n  // or codeblock editor\n  fromCodeBlockInCodeMirror = fromCodeBlockInCodeMirror || (source === 'codeblock');\n  // but not from wysiwyg\n  fromCodeBlockInCodeMirror = fromCodeBlockInCodeMirror && (source !== 'wysiwyg');\n\n  return fromCodeBlockInCodeMirror;\n}", "language": "javascript"}
{"input": "Starts the query to gather the results for the current searchText.  Attempts to return cached\nresults first, then forwards the process to `fetchResults` if necessary.", "output": "function handleQuery () {\n    var searchText = $scope.searchText || '';\n    var term = searchText.toLowerCase();\n\n    // If caching is enabled and the current searchText is stored in the cache\n    if (!$scope.noCache && cache[term]) {\n      // The results should be handled as same as a normal un-cached request does.\n      handleResults(cache[term]);\n    } else {\n      fetchResults(searchText);\n    }\n\n    ctrl.hidden = shouldHide();\n  }", "language": "javascript"}
{"input": "Query and validate a query selector,\n\n@param  {string} selector - DOM selector.\n@return {object|null|undefined} Selected DOM element if exists.\nnull if query yields no results.\nundefined if `selector` is not a valid selector.", "output": "function validateAndGetQuerySelector (selector) {\n  try {\n    var el = document.querySelector(selector);\n    if (!el) {\n      warn('No element was found matching the selector: \"%s\"', selector);\n    }\n    return el;\n  } catch (e) {  // Capture exception if it's not a valid selector.\n    warn('\"%s\" is not a valid selector', selector);\n    return undefined;\n  }\n}", "language": "javascript"}
{"input": "Adds width style to 100% in case of the given content container is the only container with content amongst the three (left, middle, right)\n@param {string} sArea The content container - one of the left, middle or right\n@param {sap.ui.core.RenderManager} oRm The RenderManager that can be used for writing to the Render-Output-Buffer.\n@param {sap.ui.core.Control} oControl the Bar instance\n@private", "output": "function writeWidthIfContentOccupiesWholeArea(sArea, oRm, oControl) {\n\t\tvar bContentLeft = !!oControl.getContentLeft().length,\n\t\t\tbContentMiddle = !!oControl.getContentMiddle().length,\n\t\t\tbContentRight = !!oControl.getContentRight().length;\n\n\t\tfunction writeAndUpdate() {\n\t\t\toRm.addStyle(\"width\", \"100%\");\n\t\t\toRm.writeStyles();\n\t\t}\n\t\tswitch (sArea.toLowerCase()) {\n\t\t\tcase \"left\":\n\t\t\t\tif (bContentLeft && !bContentMiddle && !bContentRight) {\n\t\t\t\t\twriteAndUpdate();\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase \"middle\":\n\t\t\t\tif (bContentMiddle && !bContentLeft && !bContentRight) {\n\t\t\t\t\twriteAndUpdate();\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase \"right\" :\n\t\t\t\tif (bContentRight && !bContentLeft && !bContentMiddle) {\n\t\t\t\t\twriteAndUpdate();\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tLog.error(\"Cannot determine which of the three content aggregations is alone\");\n\t\t}\n\t}", "language": "javascript"}
{"input": "Handles the response from the SAR service call\n\n        :param dict response: the response dictionary from the app repo\n        :param string application_id: the ApplicationId\n        :param string template_id: the unique TemplateId for this application", "output": "def _handle_get_cfn_template_response(self, response, application_id, template_id):\n        \"\"\"\n        Handles the response from the SAR service call\n\n        :param dict response: the response dictionary from the app repo\n        :param string application_id: the ApplicationId\n        :param string template_id: the unique TemplateId for this application\n        \"\"\"\n        status = response['Status']\n        if status != \"ACTIVE\":\n            # Other options are PREPARING and EXPIRED.\n            if status == 'EXPIRED':\n                message = (\"Template for {} with id {} returned status: {}. Cannot access an expired \"\n                           \"template.\".format(application_id, template_id, status))\n                raise InvalidResourceException(application_id, message)\n            self._in_progress_templates.append((application_id, template_id))", "language": "python"}
{"input": "Function: sortCells\n\nSorts the given cells according to the order in the cell hierarchy.\nAscending is optional and defaults to true.", "output": "function(cells, ascending)\n\t{\n\t\tascending = (ascending != null) ? ascending : true;\n\t\tvar lookup = new mxDictionary();\n\t\tcells.sort(function(o1, o2)\n\t\t{\n\t\t\tvar p1 = lookup.get(o1);\n\t\t\t\n\t\t\tif (p1 == null)\n\t\t\t{\n\t\t\t\tp1 = mxCellPath.create(o1).split(mxCellPath.PATH_SEPARATOR);\n\t\t\t\tlookup.put(o1, p1);\n\t\t\t}\n\t\t\t\n\t\t\tvar p2 = lookup.get(o2);\n\t\t\t\n\t\t\tif (p2 == null)\n\t\t\t{\n\t\t\t\tp2 = mxCellPath.create(o2).split(mxCellPath.PATH_SEPARATOR);\n\t\t\t\tlookup.put(o2, p2);\n\t\t\t}\n\t\t\t\n\t\t\tvar comp = mxCellPath.compare(p1, p2);\n\t\t\t\n\t\t\treturn (comp == 0) ? 0 : (((comp > 0) == ascending) ? 1 : -1);\n\t\t});\n\t\t\n\t\treturn cells;\n\t}", "language": "javascript"}
{"input": "This function removes the leading # sign if there's any. If the bRemoveId is set to true, it will also remove the unique\nid inside the hash.\n\n@private", "output": "function formatHash(hash, bRemoveId){\n\t\t\tvar sRes = hash, iSharpIndex = hash ? hash.indexOf(\"#\") : -1;\n\n\t\t\tif (iSharpIndex === 0) {\n\t\t\t\tsRes = sRes.slice(iSharpIndex + 1);\n\t\t\t}\n\n\t\t\tif (bRemoveId) {\n\t\t\t\tsRes = sRes.replace(rIdRegex, \"\");\n\t\t\t}\n\n\t\t\treturn sRes;\n\t\t}", "language": "javascript"}
{"input": "Split iterables `a` in equal parts of size `sz`", "output": "def partition(a:Collection, sz:int)->List[Collection]:\n    \"Split iterables `a` in equal parts of size `sz`\"\n    return [a[i:i+sz] for i in range(0, len(a), sz)]", "language": "python"}
{"input": "Removes the object from the aggregation of the given control\nAdds insertAggregation as the undo operation\nThe aggregationElements can be an array or a single object (e.g. ToolTip)\n@override", "output": "function (oParent, sName, oObject) {\n\t\t\tvar iOldIndex;\n\t\t\tvar oAggregationElements;\n\t\t\tif (oParent && oObject){\n\t\t\t\toAggregationElements = JsControlTreeModifier.getAggregation.call(this, oParent, sName);\n\t\t\t\tif (oAggregationElements){\n\t\t\t\t\toAggregationElements.some(function(oElement, iIndex) {\n\t\t\t\t\t\tif (oElement === oObject){\n\t\t\t\t\t\t\tiOldIndex = iIndex;\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tJsControlTreeModifier.removeAggregation.apply(this, arguments);\n\n\t\t\tif (iOldIndex || iOldIndex === 0) {\n\t\t\t\tthis._saveUndoOperation(\"insertAggregation\", [oParent, sName, oObject, iOldIndex]);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Compiles CSS file and writes it to stdout.\n\n@param {CompileOptions} compileOptions\n@return {Promise}", "output": "function buildToStdout(compileOptions) {\n  return compile(compileOptions).then(result => process.stdout.write(result.css))\n}", "language": "javascript"}
{"input": "bitonic sort is sorting algorithm to use multiple process, but this code not containing parallel process\n    It can sort only array that sizes power of 2\n    It can sort array in both increasing order and decreasing order by giving argument true(increasing) and false(decreasing)\n    \n    Worst-case in parallel: O(log(n)^2)\n    Worst-case in non-parallel: O(nlog(n)^2)\n    \n    reference: https://en.wikipedia.org/wiki/Bitonic_sorter", "output": "def bitonic_sort(arr, reverse=False):\n    \"\"\"\n    bitonic sort is sorting algorithm to use multiple process, but this code not containing parallel process\n    It can sort only array that sizes power of 2\n    It can sort array in both increasing order and decreasing order by giving argument true(increasing) and false(decreasing)\n    \n    Worst-case in parallel: O(log(n)^2)\n    Worst-case in non-parallel: O(nlog(n)^2)\n    \n    reference: https://en.wikipedia.org/wiki/Bitonic_sorter\n    \"\"\"\n    def compare(arr, reverse):\n        n = len(arr)//2\n        for i in range(n):\n            if reverse != (arr[i] > arr[i+n]):\n                arr[i], arr[i+n] = arr[i+n], arr[i]\n        return arr\n\n    def bitonic_merge(arr, reverse):\n        n = len(arr)\n        \n        if n <= 1:\n            return arr\n        \n        arr = compare(arr, reverse)\n        left = bitonic_merge(arr[:n // 2], reverse)\n        right = bitonic_merge(arr[n // 2:], reverse)\n        return left + right\n    \n    #end of function(compare and bitionic_merge) definition\n    n = len(arr)\n    if n <= 1:\n        return arr\n    # checks if n is power of two\n    if not (n and (not(n & (n - 1))) ):\n        raise ValueError(\"the size of input should be power of two\")\n    \n    left = bitonic_sort(arr[:n // 2], True)\n    right = bitonic_sort(arr[n // 2:], False)\n\n    arr = bitonic_merge(left + right, reverse)\n        \n    return arr", "language": "python"}
{"input": "Gets the flag which shows `super()` is called in all paths.\n@param {CodePathSegment} segment - A code path segment to get.\n@returns {boolean} The flag which shows `super()` is called in all paths.", "output": "function isCalledInEveryPath(segment) {\n\n            /*\n             * If specific segment is the looped segment of the current segment,\n             * skip the segment.\n             * If not skipped, this never becomes true after a loop.\n             */\n            if (segment.nextSegments.length === 1 &&\n                segment.nextSegments[0].isLoopedPrevSegment(segment)\n            ) {\n                return true;\n            }\n            return segment.reachable && segInfoMap[segment.id].calledInEveryPaths;\n        }", "language": "javascript"}
{"input": "Synchronous wrapper around browserHistory.removeAllPages()\nRemoves history and blocks until done", "output": "function removeAllHistory() {\n  const TOPIC_EXPIRATION_FINISHED = \"places-expiration-finished\";\n\n  // Create flag visible to both the eval and the observer object\n  var finishedFlag = {\n    state: false\n  }\n\n  // Set up an observer so we get notified when remove completes\n  let observer = {\n    observe: function(aSubject, aTopic, aData) {\n      observerService.removeObserver(this, TOPIC_EXPIRATION_FINISHED);    \n      finishedFlag.state = true;\n    }\n  }\n  observerService.addObserver(observer, TOPIC_EXPIRATION_FINISHED, false);\n\n  // Remove the pages, then block until we're done or until timeout is reached\n  browserHistory.removeAllPages();\n  mozmill.controller.waitForEval(\"subject.state == true\", gTimeout, 100, finishedFlag);\n}", "language": "javascript"}
{"input": "For serving/predict, assume that only video frames are provided.", "output": "def serving_input_fn(self, hparams):\n    \"\"\"For serving/predict, assume that only video frames are provided.\"\"\"\n    video_input_frames = tf.placeholder(\n        dtype=tf.float32,\n        shape=[\n            None, hparams.video_num_input_frames, self.frame_width,\n            self.frame_height, self.num_channels\n        ])\n\n    # TODO(michalski): add support for passing input_action and input_reward.\n    return tf.estimator.export.ServingInputReceiver(\n        features={\"inputs\": video_input_frames},\n        receiver_tensors=video_input_frames)", "language": "python"}
{"input": "URL Template v2.0.6 (https://github.com/bramstein/url-template)", "output": "function expand(url, params, variables) {\n\n    var tmpl = parse(url), expanded = tmpl.expand(params);\n\n    if (variables) {\n        variables.push.apply(variables, tmpl.vars);\n    }\n\n    return expanded;\n}", "language": "javascript"}
{"input": "Currently only used for module level hooks, can be used to add global level ones", "output": "function( handler ) {\n\t\tvar hooks = [];\n\n\t\t// Hooks are ignored on skipped tests\n\t\tif ( this.skip ) {\n\t\t\treturn hooks;\n\t\t}\n\n\t\tif ( this.module.testEnvironment &&\n\t\t\t\tQUnit.objectType( this.module.testEnvironment[ handler ] ) === \"function\" ) {\n\t\t\thooks.push( this.queueHook( this.module.testEnvironment[ handler ], handler ) );\n\t\t}\n\n\t\treturn hooks;\n\t}", "language": "javascript"}
{"input": "In your project, replace by the following line and install IPFS as a dep const IPFS = require('ipfs')", "output": "function createNode (options, callback) {\n  if (typeof options === 'function') {\n    callback = options\n    options = {}\n  }\n\n  options.path = options.path || '/tmp/ipfs' + Math.random()\n\n  const node = new IPFS({\n    repo: options.path\n  })\n\n  node.on('start', () => callback(null, node))\n}", "language": "javascript"}
{"input": "Return the intersection of this RDD and another one. The output will\n        not contain any duplicate elements, even if the input RDDs did.\n\n        .. note:: This method performs a shuffle internally.\n\n        >>> rdd1 = sc.parallelize([1, 10, 2, 3, 4, 5])\n        >>> rdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\n        >>> rdd1.intersection(rdd2).collect()\n        [1, 2, 3]", "output": "def intersection(self, other):\n        \"\"\"\n        Return the intersection of this RDD and another one. The output will\n        not contain any duplicate elements, even if the input RDDs did.\n\n        .. note:: This method performs a shuffle internally.\n\n        >>> rdd1 = sc.parallelize([1, 10, 2, 3, 4, 5])\n        >>> rdd2 = sc.parallelize([1, 6, 2, 3, 7, 8])\n        >>> rdd1.intersection(rdd2).collect()\n        [1, 2, 3]\n        \"\"\"\n        return self.map(lambda v: (v, None)) \\\n            .cogroup(other.map(lambda v: (v, None))) \\\n            .filter(lambda k_vs: all(k_vs[1])) \\\n            .keys()", "language": "python"}
{"input": "Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.\n        That's required because although they use SSH they sometimes don't\n        work with a ssh:// scheme (e.g. GitHub). But we need a scheme for\n        parsing. Hence we remove it again afterwards and return it as a stub.", "output": "def get_url_rev_and_auth(self, url):\n        \"\"\"\n        Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.\n        That's required because although they use SSH they sometimes don't\n        work with a ssh:// scheme (e.g. GitHub). But we need a scheme for\n        parsing. Hence we remove it again afterwards and return it as a stub.\n        \"\"\"\n        if '://' not in url:\n            assert 'file:' not in url\n            url = url.replace('git+', 'git+ssh://')\n            url, rev, user_pass = super(Git, self).get_url_rev_and_auth(url)\n            url = url.replace('ssh://', '')\n        else:\n            url, rev, user_pass = super(Git, self).get_url_rev_and_auth(url)\n\n        return url, rev, user_pass", "language": "python"}
{"input": "Sends a signal to reset the unity environment.\n        :return: AllBrainInfo  : A data structure corresponding to the initial reset state of the environment.", "output": "def reset(self, config=None, train_mode=True, custom_reset_parameters=None) -> AllBrainInfo:\n        \"\"\"\n        Sends a signal to reset the unity environment.\n        :return: AllBrainInfo  : A data structure corresponding to the initial reset state of the environment.\n        \"\"\"\n        if config is None:\n            config = self._resetParameters\n        elif config:\n            logger.info(\"Academy reset with parameters: {0}\"\n                        .format(', '.join([str(x) + ' -> ' + str(config[x]) for x in config])))\n        for k in config:\n            if (k in self._resetParameters) and (isinstance(config[k], (int, float))):\n                self._resetParameters[k] = config[k]\n            elif not isinstance(config[k], (int, float)):\n                raise UnityEnvironmentException(\n                    \"The value for parameter '{0}'' must be an Integer or a Float.\".format(k))\n            else:\n                raise UnityEnvironmentException(\n                    \"The parameter '{0}' is not a valid parameter.\".format(k))\n\n        if self._loaded:\n            outputs = self.communicator.exchange(\n                self._generate_reset_input(train_mode, config, custom_reset_parameters)\n            )\n            if outputs is None:\n                raise KeyboardInterrupt\n            rl_output = outputs.rl_output\n            s = self._get_state(rl_output)\n            self._global_done = s[1]\n            for _b in self._external_brain_names:\n                self._n_agents[_b] = len(s[0][_b].agents)\n            return s[0]\n        else:\n            raise UnityEnvironmentException(\"No Unity environment is loaded.\")", "language": "python"}
{"input": "Check if an element exists between the end of the active\n        formatting elements and the last marker. If it does, return it, else\n        return false", "output": "def elementInActiveFormattingElements(self, name):\n        \"\"\"Check if an element exists between the end of the active\n        formatting elements and the last marker. If it does, return it, else\n        return false\"\"\"\n\n        for item in self.activeFormattingElements[::-1]:\n            # Check for Marker first because if it's a Marker it doesn't have a\n            # name attribute.\n            if item == Marker:\n                break\n            elif item.name == name:\n                return item\n        return False", "language": "python"}
{"input": "Parses a S3 Uri into a dictionary of the Bucket, Key, and VersionId\n\n    :return: a BodyS3Location dict or None if not an S3 Uri\n    :rtype: dict", "output": "def parse_s3_uri(uri):\n    \"\"\"Parses a S3 Uri into a dictionary of the Bucket, Key, and VersionId\n\n    :return: a BodyS3Location dict or None if not an S3 Uri\n    :rtype: dict\n    \"\"\"\n    if not isinstance(uri, string_types):\n        return None\n\n    url = urlparse(uri)\n    query = parse_qs(url.query)\n\n    if url.scheme == 's3' and url.netloc and url.path:\n        s3_pointer = {\n            'Bucket': url.netloc,\n            'Key': url.path.lstrip('/')\n        }\n        if 'versionId' in query and len(query['versionId']) == 1:\n            s3_pointer['Version'] = query['versionId'][0]\n        return s3_pointer\n    else:\n        return None", "language": "python"}
{"input": "Try to convert `o` to int, default to `o` if not possible.", "output": "def try_int(o:Any)->Any:\n    \"Try to convert `o` to int, default to `o` if not possible.\"\n    # NB: single-item rank-1 array/tensor can be converted to int, but we don't want to do this\n    if isinstance(o, (np.ndarray,Tensor)): return o if o.ndim else int(o)\n    if isinstance(o, collections.Sized) or getattr(o,'__array_interface__',False): return o\n    try: return int(o)\n    except: return o", "language": "python"}
{"input": "Read from videos", "output": "def from_video(self, path):\n        \"\"\"\n        Read from videos\n        \"\"\"\n        frames = self.get_video_frames(path)\n        self.handle_type(frames)\n        return self", "language": "python"}
{"input": "Set spectator camera to render the scene on a 2D display.\n\n@param {Element} newCameraEl - Entity with camera component.", "output": "function (newCameraEl) {\n    var newCamera;\n    var previousCamera = this.spectatorCameraEl;\n    var sceneEl = this.sceneEl;\n    var spectatorCameraEl;\n\n    // Same camera.\n    newCamera = newCameraEl.getObject3D('camera');\n    if (!newCamera || newCameraEl === this.spectatorCameraEl) { return; }\n\n    // Disable current camera\n    if (previousCamera) {\n      previousCamera.setAttribute('camera', 'spectator', false);\n    }\n\n    spectatorCameraEl = this.spectatorCameraEl = newCameraEl;\n\n    sceneEl.addEventListener('enter-vr', this.wrapRender);\n    sceneEl.addEventListener('exit-vr', this.unwrapRender);\n\n    spectatorCameraEl.setAttribute('camera', 'active', false);\n    spectatorCameraEl.play();\n\n    sceneEl.emit('camera-set-spectator', {cameraEl: newCameraEl});\n  }", "language": "javascript"}
{"input": "Try to use the 'fix' from a problem.\n@param   {Message} problem The message object to apply fixes from\n@returns {boolean}         Whether fix was successfully applied", "output": "function attemptFix(problem) {\n        const fix = problem.fix;\n        const start = fix.range[0];\n        const end = fix.range[1];\n\n        // Remain it as a problem if it's overlapped or it's a negative range\n        if (lastPos >= start || start > end) {\n            remainingMessages.push(problem);\n            return false;\n        }\n\n        // Remove BOM.\n        if ((start < 0 && end >= 0) || (start === 0 && fix.text.startsWith(BOM))) {\n            output = \"\";\n        }\n\n        // Make output to this fix.\n        output += text.slice(Math.max(0, lastPos), Math.max(0, start));\n        output += fix.text;\n        lastPos = end;\n        return true;\n    }", "language": "javascript"}
{"input": "Model parallel ImageNet parameters.", "output": "def mtf_image_transformer_base_imagenet_mp_sp():\n  \"\"\"Model parallel ImageNet parameters.\"\"\"\n  hparams = mtf_image_transformer_base_imagenet_mp128()\n  hparams.mesh_shape = \"model:8;batch:4\"\n  hparams.layout = \"batch:batch;d_ff:model;num_wblocks:model\"\n  hparams.batch_size = 8\n  hparams.img_len = 128\n  hparams.block_length = 128\n  hparams.attention_type = \"local1d_spatial\"\n  return hparams", "language": "python"}
{"input": "Gets the last token of a node that is on the same line as the rest of the node.\nThis will usually be the last token of the node, but it will be the second-to-last token if the node has a trailing\nsemicolon on a different line.\n@param {ASTNode} node A directive node\n@returns {Token} The last token of the node on the line", "output": "function getLastTokenOnLine(node) {\n            const lastToken = sourceCode.getLastToken(node);\n            const secondToLastToken = sourceCode.getTokenBefore(lastToken);\n\n            return astUtils.isSemicolonToken(lastToken) && lastToken.loc.start.line > secondToLastToken.loc.end.line\n                ? secondToLastToken\n                : lastToken;\n        }", "language": "javascript"}
{"input": "Render head tag\n\n@param {Object} tag\n@returns {string}", "output": "function renderHeadTag (tag) {\n  const { tagName, attributes, innerHTML, closeTag } = normalizeHeadTag(tag)\n  return `<${tagName}${renderAttrs(attributes)}>${innerHTML}${closeTag ? `</${tagName}>` : ``}`\n}", "language": "javascript"}
{"input": "Prepares the data from an XMLHttpRequest for saving into an har file. All needed data to replay the request\nis collected (e.g. time, headers, response, status).\n\n@param {Object} oXhr The finished XMLHttpRequest, from which the data for the har file is extracted.\n@param {number} fStartTimestamp The request start timestamp.\n@returns {Object} The prepared entry for the har file.", "output": "function(oXhr, fStartTimestamp) {\n\t\t\tvar oEntry = {\n\t\t\t\tstartedDateTime: new Date(fStartTimestamp).toISOString(),\n\t\t\t\ttime: this.preciseDateNow() - fStartTimestamp,\n\t\t\t\trequest: {\n\t\t\t\t\theaders: oXhr._requestParams.headers,\n\t\t\t\t\turl: resolveURL(oXhr._requestParams.url),\n\t\t\t\t\tmethod: oXhr._requestParams.method\n\t\t\t\t},\n\t\t\t\tresponse: {\n\t\t\t\t\tstatus: oXhr.status,\n\t\t\t\t\tcontent: {\n\t\t\t\t\t\ttext: oXhr.responseText\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tif (oXhr._requestParams.customGroupName) {\n\t\t\t\toEntry._customGroupName = oXhr._requestParams.customGroupName;\n\t\t\t}\n\t\t\toEntry.response.headers = this.transformHeadersFromArrayToObject(oXhr);\n\t\t\treturn oEntry;\n\t\t}", "language": "javascript"}
{"input": "Handle timed out inference\n\n@param {{path: string, type: string}} response - the response from node domain", "output": "function handleTimedOut(response) {\n\n        var detectedExclusions  = PreferencesManager.get(\"jscodehints.detectedExclusions\") || [],\n            filePath            = response.file;\n\n        // Don't exclude the file currently being edited\n        if (isFileBeingEdited(filePath)) {\n            return;\n        }\n\n        // Handle file that is already excluded\n        if (detectedExclusions.indexOf(filePath) !== -1) {\n            console.log(\"JavaScriptCodeHints.handleTimedOut: file already in detectedExclusions array timed out: \" + filePath);\n            return;\n        }\n\n        // Save detected exclusion in project prefs so no further time is wasted on it\n        detectedExclusions.push(filePath);\n        PreferencesManager.set(\"jscodehints.detectedExclusions\", detectedExclusions, { location: { scope: \"project\" } });\n\n        // Show informational dialog\n        Dialogs.showModalDialog(\n            DefaultDialogs.DIALOG_ID_INFO,\n            Strings.DETECTED_EXCLUSION_TITLE,\n            StringUtils.format(\n                Strings.DETECTED_EXCLUSION_INFO,\n                StringUtils.breakableUrl(filePath)\n            ),\n            [\n                {\n                    className : Dialogs.DIALOG_BTN_CLASS_PRIMARY,\n                    id        : Dialogs.DIALOG_BTN_OK,\n                    text      : Strings.OK\n                }\n            ]\n        );\n    }", "language": "javascript"}
{"input": "Writes model graph to Tensorboard.", "output": "def write(self, model:nn.Module, tbwriter:SummaryWriter, input_to_model:torch.Tensor)->None:\n        \"Writes model graph to Tensorboard.\"\n        request = GraphTBRequest(model=model, tbwriter=tbwriter, input_to_model=input_to_model)\n        asyncTBWriter.request_write(request)", "language": "python"}
{"input": "Copies static files such as robots.txt, favicon.ico to the\noutput (build) folder.", "output": "async function copy() {\n  await makeDir('build');\n  await Promise.all([\n    writeFile(\n      'build/package.json',\n      JSON.stringify(\n        {\n          private: true,\n          engines: pkg.engines,\n          dependencies: pkg.dependencies,\n          scripts: {\n            start: 'node server.js',\n          },\n        },\n        null,\n        2,\n      ),\n    ),\n    copyFile('LICENSE.txt', 'build/LICENSE.txt'),\n    copyFile('yarn.lock', 'build/yarn.lock'),\n    copyDir('public', 'build/public'),\n  ]);\n\n  if (process.argv.includes('--watch')) {\n    const watcher = chokidar.watch(['public/**/*'], { ignoreInitial: true });\n\n    watcher.on('all', async (event, filePath) => {\n      const start = new Date();\n      const src = path.relative('./', filePath);\n      const dist = path.join(\n        'build/',\n        src.startsWith('src') ? path.relative('src', src) : src,\n      );\n      switch (event) {\n        case 'add':\n        case 'change':\n          await makeDir(path.dirname(dist));\n          await copyFile(filePath, dist);\n          break;\n        case 'unlink':\n        case 'unlinkDir':\n          cleanDir(dist, { nosort: true, dot: true });\n          break;\n        default:\n          return;\n      }\n      const end = new Date();\n      const time = end.getTime() - start.getTime();\n      console.info(`[${format(end)}] ${event} '${dist}' after ${time} ms`);\n    });\n  }\n}", "language": "javascript"}
{"input": "Adds an entry to MROF list\n@private\n@param {Editor} editor - editor to extract file information", "output": "function _addToMROFList(file, paneId, cursorPos) {\n\n        var filePath = file.fullPath;\n        \n        if (!paneId) { // Don't handle this if not a full view/editor\n            return;\n        }\n\n\n        // Check existing list for this doc path and pane entry\n        var index = _.findIndex(_mrofList, function (record) {\n            return (record && record.file === filePath && record.paneId === paneId);\n        });\n\n        var entry;\n        if (index !== -1) {\n            entry = _mrofList[index];\n            if (entry.cursor && !cursorPos) {\n                cursorPos = entry.cursor;\n            }\n        }\n\n        entry = _makeMROFListEntry(filePath, paneId, cursorPos);\n\n        // Check if the file is an InMemoryFile\n        if (file.constructor.name === \"InMemoryFile\") {\n            // Mark the entry as inMem, so that we can knock it off from the list when removed from working set\n            entry.inMem = true;\n        }\n\n\n        if (index !== -1) {\n            _mrofList.splice(index, 1);\n        }\n\n        // add it to the front of the list\n        _mrofList.unshift(entry);\n\n        PreferencesManager.setViewState(OPEN_FILES_VIEW_STATE, _mrofList, _getPrefsContext(), true);\n    }", "language": "javascript"}
{"input": "Sets the storage level to persist the contents of the :class:`DataFrame` across\n        operations after the first time it is computed. This can only be used to assign\n        a new storage level if the :class:`DataFrame` does not have a storage level set yet.\n        If no storage level is specified defaults to (C{MEMORY_AND_DISK}).\n\n        .. note:: The default storage level has changed to C{MEMORY_AND_DISK} to match Scala in 2.0.", "output": "def persist(self, storageLevel=StorageLevel.MEMORY_AND_DISK):\n        \"\"\"Sets the storage level to persist the contents of the :class:`DataFrame` across\n        operations after the first time it is computed. This can only be used to assign\n        a new storage level if the :class:`DataFrame` does not have a storage level set yet.\n        If no storage level is specified defaults to (C{MEMORY_AND_DISK}).\n\n        .. note:: The default storage level has changed to C{MEMORY_AND_DISK} to match Scala in 2.0.\n        \"\"\"\n        self.is_cached = True\n        javaStorageLevel = self._sc._getJavaStorageLevel(storageLevel)\n        self._jdf.persist(javaStorageLevel)\n        return self", "language": "python"}
{"input": "Creates watchers on scope and newScope that ensure that for any\n$digest of scope, newScope is also $digested.", "output": "function connectScopes() {\n        var scopeDigesting = false;\n        var newScopeDigesting = false;\n\n        scope.$watch(function() {\n          if (newScopeDigesting || scopeDigesting) {\n            return;\n          }\n\n          scopeDigesting = true;\n          scope.$$postDigest(function() {\n            if (!newScopeDigesting) {\n              newScope.$digest();\n            }\n\n            scopeDigesting = newScopeDigesting = false;\n          });\n        });\n\n        newScope.$watch(function() {\n          newScopeDigesting = true;\n        });\n      }", "language": "javascript"}
{"input": "Preprocessed given dependencies\n\n@param {object} oDependencies - Dependencies to preprocess\n@returns {object} oDependencies - Proprocessed dependencies", "output": "function preprocessDependencies(dependencies) {\n\t\tif (Array.isArray(dependencies)) {\n\t\t\t// remove .library-preload suffix from dependencies\n\t\t\treturn dependencies.map(function (dep) {\n\t\t\t\treturn dep.replace(/\\.library-preload$/, '');\n\t\t\t});\n\t\t}\n\t\treturn dependencies;\n\t}", "language": "javascript"}
{"input": "Time string formatter", "output": "function strftime (offsetObject) {\n  return function (format) {\n    var directives = format.match(/%(-|!)?[A-Z]{1}(:[^]+)?/gi)\n    var d2h = false\n    if (directives.indexOf('%D') < 0 && directives.indexOf('%H') >= 0) {\n      d2h = true\n    }\n    if (directives) {\n      for (var i = 0, len = directives.length; i < len; ++i) {\n        var directive = directives[i].match(/%(-|!)?([a-zA-Z]{1})(:[^]+)?/)\n        var regexp = escapedRegExp(directive[0])\n        var modifier = directive[1] || ''\n        var plural = directive[3] || ''\n        var value = null\n        var key = null\n        // Get the key\n        directive = directive[2]\n        // Swap shot-versions directives\n        if (DIRECTIVE_KEY_MAP.hasOwnProperty(directive)) {\n          key = DIRECTIVE_KEY_MAP[directive]\n          value = Number(offsetObject[key])\n          if (key === 'hours' && d2h) {\n            value += Number(offsetObject['days']) * 24\n          }\n        }\n        if (value !== null) {\n          // Pluralize\n          if (modifier === '!') {\n            value = pluralize(plural, value)\n          }\n          // Add zero-padding\n          if (modifier === '') {\n            if (value < 10) {\n              value = '0' + value.toString()\n            }\n          }\n          // Replace the directive\n          format = format.replace(regexp, value.toString())\n        }\n      }\n    }\n    format = format.replace('%_M1', offsetObject.minutes_1)\n      .replace('%_M2', offsetObject.minutes_2)\n      .replace('%_S1', offsetObject.seconds_1)\n      .replace('%_S2', offsetObject.seconds_2)\n      .replace('%_S3', offsetObject.seconds_3)\n      .replace('%_H1', offsetObject.hours_1)\n      .replace('%_H2', offsetObject.hours_2)\n      .replace('%_H3', offsetObject.hours_3)\n      .replace('%_D1', offsetObject.days_1)\n      .replace('%_D2', offsetObject.days_2)\n      .replace('%_D3', offsetObject.days_3)\n    format = format.replace(/%%/, '%')\n    return format\n  }\n}", "language": "javascript"}
{"input": "Version with Noam's decay scheme.", "output": "def slicenet_params1_noam():\n  \"\"\"Version with Noam's decay scheme.\"\"\"\n  hparams = slicenet_params1()\n  hparams.learning_rate_decay_scheme = \"noam\"\n  hparams.learning_rate = 1.0\n  hparams.learning_rate_warmup_steps = 4000\n  hparams.initializer = \"uniform_unit_scaling\"\n  hparams.optimizer_adam_epsilon = 1e-9\n  hparams.optimizer_adam_beta1 = 0.9\n  hparams.optimizer_adam_beta2 = 0.98\n  return hparams", "language": "python"}
{"input": "/* [MS-XLS] 2.4.126 Number Formats", "output": "function parse_Format(blob, length, opts) {\n\tvar numFmtId = blob.read_shift(2);\n\tvar fmtstr = parse_XLUnicodeString2(blob, 0, opts);\n\treturn [numFmtId, fmtstr];\n}", "language": "javascript"}
{"input": "/*\nIf selection is a link, it removes the link and wraps it with a <code> element\nThe <code> element is needed to avoid auto linking\n\n@example\nwysihtml5.commands.createLink.exec(composer, \"removeLink\");", "output": "function(composer, command) {\n      var anchors = this.state(composer, command);\n      if (anchors) {\n        composer.selection.executeAndRestore(function() {\n          _removeFormat(composer, anchors);\n        });\n      }\n    }", "language": "javascript"}
{"input": "Create a multi-polygon from a TopoJSON geometry object.\n\n@param {TopoJSONMultiPolygon} object TopoJSON object.\n@param {Array<Array<import(\"../coordinate.js\").Coordinate>>} arcs Array of arcs.\n@return {MultiPolygon} Geometry.", "output": "function readMultiPolygonGeometry(object, arcs) {\n  const coordinates = [];\n  for (let i = 0, ii = object['arcs'].length; i < ii; ++i) {\n    // for each polygon\n    const polyArray = object['arcs'][i];\n    const ringCoords = [];\n    for (let j = 0, jj = polyArray.length; j < jj; ++j) {\n      // for each ring\n      ringCoords[j] = concatenateArcs(polyArray[j], arcs);\n    }\n    coordinates[i] = ringCoords;\n  }\n  return new MultiPolygon(coordinates);\n}", "language": "javascript"}
{"input": "Passes the result to skopt unless early terminated or errored.\n\n        The result is internally negated when interacting with Skopt\n        so that Skopt Optimizers can \"maximize\" this value,\n        as it minimizes on default.", "output": "def on_trial_complete(self,\n                          trial_id,\n                          result=None,\n                          error=False,\n                          early_terminated=False):\n        \"\"\"Passes the result to skopt unless early terminated or errored.\n\n        The result is internally negated when interacting with Skopt\n        so that Skopt Optimizers can \"maximize\" this value,\n        as it minimizes on default.\n        \"\"\"\n        skopt_trial_info = self._live_trial_mapping.pop(trial_id)\n        if result:\n            self._skopt_opt.tell(skopt_trial_info, -result[self._reward_attr])", "language": "python"}
{"input": "Get the current total cluster resources.\n\n        Note that this information can grow stale as nodes are added to or\n        removed from the cluster.\n\n        Returns:\n            A dictionary mapping resource name to the total quantity of that\n                resource in the cluster.", "output": "def cluster_resources(self):\n        \"\"\"Get the current total cluster resources.\n\n        Note that this information can grow stale as nodes are added to or\n        removed from the cluster.\n\n        Returns:\n            A dictionary mapping resource name to the total quantity of that\n                resource in the cluster.\n        \"\"\"\n        resources = defaultdict(int)\n        clients = self.client_table()\n        for client in clients:\n            # Only count resources from live clients.\n            if client[\"IsInsertion\"]:\n                for key, value in client[\"Resources\"].items():\n                    resources[key] += value\n\n        return dict(resources)", "language": "python"}
{"input": "Called twice during file write. The first populates the values in\n        the map with 0s.  The second call writes the final map locations when\n        all blocks have been written.", "output": "def _write_map(self):\n        \"\"\"Called twice during file write. The first populates the values in\n        the map with 0s.  The second call writes the final map locations when\n        all blocks have been written.\"\"\"\n        if self._map is None:\n            self._map = OrderedDict((('stata_data', 0),\n                                     ('map', self._file.tell()),\n                                     ('variable_types', 0),\n                                     ('varnames', 0),\n                                     ('sortlist', 0),\n                                     ('formats', 0),\n                                     ('value_label_names', 0),\n                                     ('variable_labels', 0),\n                                     ('characteristics', 0),\n                                     ('data', 0),\n                                     ('strls', 0),\n                                     ('value_labels', 0),\n                                     ('stata_data_close', 0),\n                                     ('end-of-file', 0)))\n        # Move to start of map\n        self._file.seek(self._map['map'])\n        bio = BytesIO()\n        for val in self._map.values():\n            bio.write(struct.pack(self._byteorder + 'Q', val))\n        bio.seek(0)\n        self._file.write(self._tag(bio.read(), 'map'))", "language": "python"}
{"input": "Adds `options.*` params for options that match the longname of one of the\ncollected typedefs.\n@param {Object} e Event object.", "output": "function(e) {\n    const doclets = e.doclets;\n    for (let i = 0, ii = doclets.length; i < ii; ++i) {\n      const doclet = doclets[i];\n      if (doclet.params) {\n        const params = doclet.params;\n        for (let j = 0, jj = params.length; j < jj; ++j) {\n          const param = params[j];\n          if (param.type && param.type.names) {\n            const type = param.type.names[0];\n            if (type in properties) {\n              param.type.names[0] = type;\n              params.push.apply(params, properties[type].map(p => {\n                const property = Object.assign({}, p);\n                property.name = `${param.name}.${property.name}`;\n                return property;\n              }));\n            }\n          }\n        }\n      }\n    }\n  }", "language": "javascript"}
{"input": "Copy this distribution, substituting in any changed keyword args", "output": "def clone(self, **kw):\n        \"\"\"Copy this distribution, substituting in any changed keyword args\"\"\"\n        names = 'project_name version py_version platform location precedence'\n        for attr in names.split():\n            kw.setdefault(attr, getattr(self, attr, None))\n        kw.setdefault('metadata', self._provider)\n        return self.__class__(**kw)", "language": "python"}
{"input": "Handle Active Editor change to update mrof information", "output": "function _handleActiveEditorChange(event, current, previous) {\n        if (current) { // Handle only full editors\n            if (_mrofList.length === 0) {\n                _initRecentFilesList();\n            }\n\n            var file = current.document.file;\n            var paneId = current._paneId;\n            _addToMROFList(file, paneId, current.getCursorPos(true, \"first\"));\n        }\n\n        if (previous) { // Capture the last know cursor position\n            _updateCursorPosition(previous.document.file.fullPath, previous._paneId, previous.getCursorPos(true, \"first\"));\n        }\n    }", "language": "javascript"}
{"input": "========================================================================= Fills", "output": "function(fill) {\n    var xml = this.map.fill.toXml(fill);\n    var index = this.index.fill[xml];\n    if (index === undefined) {\n      index = this.index.fill[xml] = this.model.fills.length;\n      this.model.fills.push(xml);\n    }\n    return index;\n  }", "language": "javascript"}
{"input": "Convert from NHWC|NCHW => HW", "output": "def pool_to_HW(shape, data_frmt):\n    \"\"\" Convert from NHWC|NCHW => HW\n    \"\"\"\n    if len(shape) != 4:\n        return shape # Not NHWC|NCHW, return as is\n    if data_frmt == 'NCHW':\n        return [shape[2], shape[3]]\n    return [shape[1], shape[2]]", "language": "python"}
{"input": "Function: createMarker\n\nReturns a function to paint the given marker.", "output": "function(canvas, shape, type, pe, unitX, unitY, size, source, sw, filled)\n\t{\n\t\tvar funct = mxMarker.markers[type];\n\t\t\n\t\treturn (funct != null) ? funct(canvas, shape, type, pe, unitX, unitY, size, source, sw, filled) : null;\n\t}", "language": "javascript"}
{"input": "Replace weights of models in the pipeline with those provided in the\n        params dictionary. Can be used as a contextmanager, in which case,\n        models go back to their original weights after the block.\n\n        params (dict): A dictionary of parameters keyed by model ID.\n        **cfg: Config parameters.\n\n        EXAMPLE:\n            >>> with nlp.use_params(optimizer.averages):\n            >>>     nlp.to_disk('/tmp/checkpoint')", "output": "def use_params(self, params, **cfg):\n        \"\"\"Replace weights of models in the pipeline with those provided in the\n        params dictionary. Can be used as a contextmanager, in which case,\n        models go back to their original weights after the block.\n\n        params (dict): A dictionary of parameters keyed by model ID.\n        **cfg: Config parameters.\n\n        EXAMPLE:\n            >>> with nlp.use_params(optimizer.averages):\n            >>>     nlp.to_disk('/tmp/checkpoint')\n        \"\"\"\n        contexts = [\n            pipe.use_params(params)\n            for name, pipe in self.pipeline\n            if hasattr(pipe, \"use_params\")\n        ]\n        # TODO: Having trouble with contextlib\n        # Workaround: these aren't actually context managers atm.\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass\n        yield\n        for context in contexts:\n            try:\n                next(context)\n            except StopIteration:\n                pass", "language": "python"}
{"input": "Initialize the schedulers for training.", "output": "def on_train_begin(self, epoch:int, **kwargs:Any)->None:\n        \"Initialize the schedulers for training.\"\n        res = {'epoch':self.start_epoch} if self.start_epoch is not None else None\n        self.start_epoch = ifnone(self.start_epoch, epoch)\n        self.scheds = [p.scheds for p in self.phases]\n        self.opt = self.learn.opt\n        for k,v in self.scheds[0].items(): \n            v.restart()\n            self.opt.set_stat(k, v.start)\n        self.idx_s = 0\n        return res", "language": "python"}
{"input": "Execute a list of Promises", "output": "function processArray(aPromises) {\n\t\t\t\t\t\treturn aPromises.reduce(function(pacc, fn) {\n\t\t\t\t\t\t\treturn pacc.then(fn);\n\t\t\t\t\t\t}, Promise.resolve())\n\t\t\t\t\t\t.catch(function() {\n\t\t\t\t\t\t\treturn Promise.resolve(false);\n\t\t\t\t\t\t});\n\t\t\t\t\t}", "language": "javascript"}
{"input": "Return an object with absolute value taken. Only applicable to objects\n        that are all numeric\n\n        Returns\n        -------\n        abs: same type as caller", "output": "def abs(self):\n        \"\"\"\n        Return an object with absolute value taken. Only applicable to objects\n        that are all numeric\n\n        Returns\n        -------\n        abs: same type as caller\n        \"\"\"\n        return self._constructor(np.abs(self.values),\n                                 index=self.index).__finalize__(self)", "language": "python"}
{"input": "Reports an AssignmentExpression node that has a non-atomic update\n@param {ASTNode} assignmentExpression The assignment that is potentially unsafe\n@returns {void}", "output": "function reportAssignment(assignmentExpression) {\n            context.report({\n                node: assignmentExpression,\n                messageId: \"nonAtomicUpdate\",\n                data: {\n                    value: sourceCode.getText(assignmentExpression.left)\n                }\n            });\n        }", "language": "javascript"}
{"input": "Add additional __dir__ for this object.", "output": "def _dir_additions(self):\n        \"\"\"\n        Add additional __dir__ for this object.\n        \"\"\"\n        rv = set()\n        for accessor in self._accessors:\n            try:\n                getattr(self, accessor)\n                rv.add(accessor)\n            except AttributeError:\n                pass\n        return rv", "language": "python"}
{"input": "Reverses the given array in place.", "output": "function reverseInplace(array) {\n  for (var i = 0; i < array.length / 2; ++i) {\n    var h = array[i];\n    var ii = array.length - i - 1;\n    array[i] = array[ii];\n    array[ii] = h;\n  }\n}", "language": "javascript"}
{"input": "/*\nConvert image data into texture\n@returns {Texture2D} texture", "output": "function getTextureFromData(gl, data, opts) {\n  if (data instanceof Texture2D) {\n    return data;\n  }\n  return new Texture2D(gl, Object.assign({data}, opts));\n}", "language": "javascript"}
{"input": "Finds elements by link text.\n\n        :Args:\n         - link_text: The text of the elements to be found.\n\n        :Returns:\n         - list of webelement - a list with elements if any was found.  an\n           empty list if not\n\n        :Usage:\n            ::\n\n                elements = driver.find_elements_by_link_text('Sign In')", "output": "def find_elements_by_link_text(self, text):\n        \"\"\"\n        Finds elements by link text.\n\n        :Args:\n         - link_text: The text of the elements to be found.\n\n        :Returns:\n         - list of webelement - a list with elements if any was found.  an\n           empty list if not\n\n        :Usage:\n            ::\n\n                elements = driver.find_elements_by_link_text('Sign In')\n        \"\"\"\n        return self.find_elements(by=By.LINK_TEXT, value=text)", "language": "python"}
{"input": "Policy and Value optimizer step.", "output": "def policy_and_value_opt_step(i,\n                              opt_state,\n                              opt_update,\n                              policy_and_value_net_apply,\n                              old_params,\n                              padded_observations,\n                              padded_actions,\n                              padded_rewards,\n                              reward_mask,\n                              c1=1.0,\n                              c2=0.01,\n                              gamma=0.99,\n                              lambda_=0.95,\n                              epsilon=0.1):\n  \"\"\"Policy and Value optimizer step.\"\"\"\n  # Combined loss function given the new params.\n  def policy_and_value_loss(params):\n    \"\"\"Returns the combined loss given just parameters.\"\"\"\n    (loss, _, _, _) = combined_loss(\n        params,\n        old_params,\n        policy_and_value_net_apply,\n        padded_observations,\n        padded_actions,\n        padded_rewards,\n        reward_mask,\n        c1=c1,\n        c2=c2,\n        gamma=gamma,\n        lambda_=lambda_,\n        epsilon=epsilon)\n    return loss\n\n  new_params = trax_opt.get_params(opt_state)\n  g = grad(policy_and_value_loss)(new_params)\n  return opt_update(i, g, opt_state)", "language": "python"}
{"input": "Fails gracefully when various install steps don't work.", "output": "def try_run_setup(**kwargs):\n    \"\"\" Fails gracefully when various install steps don't work.\n    \"\"\"\n\n    try:\n        run_setup(**kwargs)\n    except Exception as e:\n        print(str(e))\n        if \"xgboost\" in str(e).lower():\n            kwargs[\"test_xgboost\"] = False\n            print(\"Couldn't install XGBoost for testing!\")\n            try_run_setup(**kwargs)\n        elif \"lightgbm\" in str(e).lower():\n            kwargs[\"test_lightgbm\"] = False\n            print(\"Couldn't install LightGBM for testing!\")\n            try_run_setup(**kwargs)\n        elif kwargs[\"with_binary\"]:\n            kwargs[\"with_binary\"] = False\n            print(\"WARNING: The C extension could not be compiled, sklearn tree models not supported.\")\n            try_run_setup(**kwargs)\n        else:\n            print(\"ERROR: Failed to build!\")", "language": "python"}
{"input": "Should we redirect and where to?\n\n        :returns: Truthy redirect location string if we got a redirect status\n            code and valid location. ``None`` if redirect status and no\n            location. ``False`` if not a redirect status code.", "output": "def get_redirect_location(self):\n        \"\"\"\n        Should we redirect and where to?\n\n        :returns: Truthy redirect location string if we got a redirect status\n            code and valid location. ``None`` if redirect status and no\n            location. ``False`` if not a redirect status code.\n        \"\"\"\n        if self.status in self.REDIRECT_STATUSES:\n            return self.headers.get('location')\n\n        return False", "language": "python"}
{"input": "Parse content of a book\n\n@param {Book} book\n@return {Promise<Book>}", "output": "function parseBookContent(book) {\n    return Promise(book)\n        .then(parseReadme)\n        .then(parseSummary)\n        .then(parseGlossary);\n}", "language": "javascript"}
{"input": "Modify all deprecated and experimental links\n@private", "output": "function (oEvent) {\n\t\t\t\tvar aItems = oEvent.getSource().getItems(),\n\t\t\t\t\tiLen = aItems.length,\n\t\t\t\t\toItem;\n\n\t\t\t\twhile (iLen--) {\n\t\t\t\t\toItem = aItems[iLen];\n\t\t\t\t\t// Access control lazy loading method if available\n\t\t\t\t\tif (oItem._getLinkSender) {\n\t\t\t\t\t\tvar oCustomData = oItem.getCustomData(),\n\t\t\t\t\t\t\tsClassName = oCustomData[0].getValue(),\n\t\t\t\t\t\t\tsEntityId = oCustomData[1].getValue(),\n\t\t\t\t\t\t\tsEntityType = oCustomData[2].getValue(),\n\t\t\t\t\t\t\tsHref;\n\n\t\t\t\t\t\t// oCustomData[3].getValue() is true if method is static, else it is false\n\t\t\t\t\t\tif (oCustomData[3].getValue()) {\n\t\t\t\t\t\t\tsEntityId = sClassName + \".\" + sEntityId;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tsHref = \"#/api/\" + sClassName;\n\t\t\t\t\t\tif (sEntityType !== \"class\") {\n\t\t\t\t\t\t\tsHref += \"/\" + sEntityType + \"/\" + sEntityId;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Set link href to allow open in new window functionality\n\t\t\t\t\t\toItem._getLinkSender().setHref(sHref);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}", "language": "javascript"}
{"input": "The logical parent of the path.", "output": "def parent(self):\n        \"\"\"The logical parent of the path.\"\"\"\n        drv = self._drv\n        root = self._root\n        parts = self._parts\n        if len(parts) == 1 and (drv or root):\n            return self\n        return self._from_parsed_parts(drv, root, parts[:-1])", "language": "python"}
{"input": "Convert a svg file to a pmg", "output": "function convertSVGToPNG(source, dest, options) {\n    if (!fs.existsSync(source)) return Promise.reject(new error.FileNotFoundError({ filename: source }));\n\n    return command.spawn('svgexport', [source, dest])\n    .fail(function(err) {\n        if (err.code == 'ENOENT') {\n            err = error.RequireInstallError({\n                cmd: 'svgexport',\n                install: 'Install it using: \"npm install svgexport -g\"'\n            });\n        }\n        throw err;\n    })\n    .then(function() {\n        if (fs.existsSync(dest)) return;\n\n        throw new Error('Error converting '+source+' into '+dest);\n    });\n}", "language": "javascript"}
{"input": "Determines whether or not the callback is part of a callback expression.\n@param {ASTNode} node The callback node\n@param {ASTNode} parentNode The expression node\n@returns {boolean} Whether or not this is part of a callback expression", "output": "function isCallbackExpression(node, parentNode) {\n\n            // ensure the parent node exists and is an expression\n            if (!parentNode || parentNode.type !== \"ExpressionStatement\") {\n                return false;\n            }\n\n            // cb()\n            if (parentNode.expression === node) {\n                return true;\n            }\n\n            // special case for cb && cb() and similar\n            if (parentNode.expression.type === \"BinaryExpression\" || parentNode.expression.type === \"LogicalExpression\") {\n                if (parentNode.expression.right === node) {\n                    return true;\n                }\n            }\n\n            return false;\n        }", "language": "javascript"}
{"input": "Reshapes first two dimensions in to single dimension.\n\n  Args:\n    tensor: Tensor to reshape of shape [A, B, ...]\n\n  Returns:\n    Reshaped tensor of shape [A*B, ...]", "output": "def _merge_beam_dim(tensor):\n  \"\"\"Reshapes first two dimensions in to single dimension.\n\n  Args:\n    tensor: Tensor to reshape of shape [A, B, ...]\n\n  Returns:\n    Reshaped tensor of shape [A*B, ...]\n  \"\"\"\n  shape = common_layers.shape_list(tensor)\n  shape[0] *= shape[1]  # batch -> batch * beam_size\n  shape.pop(1)  # Remove beam dim\n  return tf.reshape(tensor, shape)", "language": "python"}
{"input": "Create a binding for a function that will call \"super.foo()\" or \"super[foo]()\".", "output": "function getSuperPropCallBinding(thisEnvFn, propName) {\n  return getBinding(thisEnvFn, `superprop_call:${propName || \"\"}`, () => {\n    const argsBinding = thisEnvFn.scope.generateUidIdentifier(\"args\");\n    const argsList = [t.restElement(argsBinding)];\n\n    let fnBody;\n    if (propName) {\n      // (...args) => super.foo(...args)\n      fnBody = t.callExpression(\n        t.memberExpression(t.super(), t.identifier(propName)),\n        [t.spreadElement(t.identifier(argsBinding.name))],\n      );\n    } else {\n      const method = thisEnvFn.scope.generateUidIdentifier(\"prop\");\n      // (method, ...args) => super[method](...args)\n      argsList.unshift(method);\n      fnBody = t.callExpression(\n        t.memberExpression(\n          t.super(),\n          t.identifier(method.name),\n          true /* computed */,\n        ),\n        [t.spreadElement(t.identifier(argsBinding.name))],\n      );\n    }\n\n    return t.arrowFunctionExpression(argsList, fnBody);\n  });\n}", "language": "javascript"}
{"input": "Function: serialize\nRender a DOM element and all descendants to a String.\n\nParameters:\n(XMLElement) elem - A DOM element.\n\nReturns:\nThe serialized element tree as a String.", "output": "function (elem)\r\n    {\r\n        var result;\r\n\r\n        if (!elem) { return null; }\r\n\r\n        if (typeof(elem.tree) === \"function\") {\r\n            elem = elem.tree();\r\n        }\r\n\r\n        var nodeName = elem.nodeName;\r\n        var i, child;\r\n\r\n        if (elem.getAttribute(\"_realname\")) {\r\n            nodeName = elem.getAttribute(\"_realname\");\r\n        }\r\n\r\n        result = \"<\" + nodeName;\r\n        for (i = 0; i < elem.attributes.length; i++) {\r\n               if(elem.attributes[i].nodeName != \"_realname\") {\r\n                 result += \" \" + elem.attributes[i].nodeName +\r\n                \"='\" + elem.attributes[i].value\r\n                    .replace(/&/g, \"&amp;\")\r\n                       .replace(/\\'/g, \"&apos;\")\r\n                       .replace(/>/g, \"&gt;\")\r\n                       .replace(/</g, \"&lt;\") + \"'\";\r\n               }\r\n        }\r\n\r\n        if (elem.childNodes.length > 0) {\r\n            result += \">\";\r\n            for (i = 0; i < elem.childNodes.length; i++) {\r\n                child = elem.childNodes[i];\r\n                switch( child.nodeType ){\r\n                  case Strophe.ElementType.NORMAL:\r\n                    // normal element, so recurse\r\n                    result += Strophe.serialize(child);\r\n                    break;\r\n                  case Strophe.ElementType.TEXT:\r\n                    // text element to escape values\r\n                    result += Strophe.xmlescape(child.nodeValue);\r\n                    break;\r\n                  case Strophe.ElementType.CDATA:\r\n                    // cdata section so don't escape values\r\n                    result += \"<![CDATA[\"+child.nodeValue+\"]]>\";\r\n                }\r\n            }\r\n            result += \"</\" + nodeName + \">\";\r\n        } else {\r\n            result += \"/>\";\r\n        }\r\n\r\n        return result;\r\n    }", "language": "javascript"}
{"input": "Checks wether a return statement is wrapped in ()\n@param {ASTNode} node node to examine\n@returns {boolean} the result", "output": "function isWrappedInParenthesis(node) {\n            const regex = /^return\\s*?\\(\\s*?\\);*?/u;\n\n            const statementWithoutArgument = sourceCode.getText(node).replace(\n                sourceCode.getText(node.argument), \"\"\n            );\n\n            return regex.test(statementWithoutArgument);\n        }", "language": "javascript"}
{"input": "Get KL loss for all the predicted Gaussians.", "output": "def get_kl_loss(self, means, log_vars, means_p=None, log_vars_p=None):\n    \"\"\"Get KL loss for all the predicted Gaussians.\"\"\"\n    kl_loss = 0.0\n    if means_p is None:\n      means_p = tf.unstack(tf.zeros_like(means))\n    if log_vars_p is None:\n      log_vars_p = tf.unstack(tf.zeros_like(log_vars))\n    enumerated_inputs = enumerate(zip(means, log_vars, means_p, log_vars_p))\n    if self.is_training and self.hparams.stochastic_model:\n      for i, (mean, log_var, mean_p, log_var_p) in enumerated_inputs:\n        kl_loss += common_layers.kl_divergence(mean, log_var, mean_p, log_var_p)\n        tf.summary.histogram(\"posterior_mean_%d\" % i, mean)\n        tf.summary.histogram(\"posterior_log_var_%d\" % i, log_var)\n        tf.summary.histogram(\"prior_mean_%d\" % i, mean_p)\n        tf.summary.histogram(\"prior_log_var_%d\" % i, log_var_p)\n      tf.summary.scalar(\"kl_raw\", tf.reduce_mean(kl_loss))\n\n    beta = self.get_beta(kl_loss)\n    # information capacity from \"Understanding disentangling in beta-VAE\"\n    if self.hparams.information_capacity > 0.0:\n      kl_loss = tf.abs(kl_loss - self.hparams.information_capacity)\n    return beta * kl_loss", "language": "python"}
{"input": "Find an element given a By strategy and locator. Prefer the find_element_by_* methods when\n        possible.\n\n        :Usage:\n            ::\n\n                element = driver.find_element(By.ID, 'foo')\n\n        :rtype: WebElement", "output": "def find_element(self, by=By.ID, value=None):\n        \"\"\"\n        Find an element given a By strategy and locator. Prefer the find_element_by_* methods when\n        possible.\n\n        :Usage:\n            ::\n\n                element = driver.find_element(By.ID, 'foo')\n\n        :rtype: WebElement\n        \"\"\"\n        if self.w3c:\n            if by == By.ID:\n                by = By.CSS_SELECTOR\n                value = '[id=\"%s\"]' % value\n            elif by == By.TAG_NAME:\n                by = By.CSS_SELECTOR\n            elif by == By.CLASS_NAME:\n                by = By.CSS_SELECTOR\n                value = \".%s\" % value\n            elif by == By.NAME:\n                by = By.CSS_SELECTOR\n                value = '[name=\"%s\"]' % value\n        return self.execute(Command.FIND_ELEMENT, {\n            'using': by,\n            'value': value})['value']", "language": "python"}
{"input": "Creates an Agent from hparams.", "output": "def make_agent_from_hparams(\n    agent_type, base_env, stacked_env, loop_hparams, policy_hparams,\n    planner_hparams, model_dir, policy_dir, sampling_temp, video_writers=()\n):\n  \"\"\"Creates an Agent from hparams.\"\"\"\n  def sim_env_kwargs_fn():\n    return rl.make_simulated_env_kwargs(\n        base_env, loop_hparams, batch_size=planner_hparams.batch_size,\n        model_dir=model_dir\n    )\n  planner_kwargs = planner_hparams.values()\n  planner_kwargs.pop(\"batch_size\")\n  planner_kwargs.pop(\"rollout_agent_type\")\n  planner_kwargs.pop(\"env_type\")\n  return make_agent(\n      agent_type, stacked_env, policy_hparams, policy_dir, sampling_temp,\n      sim_env_kwargs_fn, loop_hparams.frame_stack_size,\n      planner_hparams.rollout_agent_type,\n      inner_batch_size=planner_hparams.batch_size,\n      env_type=planner_hparams.env_type,\n      video_writers=video_writers, **planner_kwargs\n  )", "language": "python"}
{"input": "Sets the options File Upload Dialog Timeout value\n\n        :Args:\n         - value: Timeout in milliseconds", "output": "def file_upload_dialog_timeout(self, value):\n        \"\"\"\n        Sets the options File Upload Dialog Timeout value\n\n        :Args:\n         - value: Timeout in milliseconds\n\n        \"\"\"\n        if not isinstance(value, int):\n            raise ValueError('File Upload Dialog Timeout must be an integer.')\n        self._options[self.FILE_UPLOAD_DIALOG_TIMEOUT] = value", "language": "python"}
{"input": "Functions - Definitions", "output": "function _main() {\n  const {guides: acGuidePaths, images: acGuideImagesPaths, examples: acExamplePaths} = getPathsFromAioContent();\n  const {guides: coGuidePaths, images: coGuideImagesPaths, examples: coExamplePaths} = getPathsFromCodeowners();\n\n  const guidesDiff = arrayDiff(acGuidePaths, coGuidePaths);\n  const imagesDiff = arrayDiff(acGuideImagesPaths, coGuideImagesPaths);\n  const examplesDiff = arrayDiff(acExamplePaths, coExamplePaths);\n  const hasDiff = !!(guidesDiff.diffCount || imagesDiff.diffCount || examplesDiff.diffCount);\n\n  if (hasDiff) {\n    const expectedGuidesSrc = path.relative(PROJECT_ROOT_DIR, AIO_GUIDES_DIR);\n    const expectedImagesSrc = path.relative(PROJECT_ROOT_DIR, AIO_GUIDE_IMAGES_DIR);\n    const expectedExamplesSrc = path.relative(PROJECT_ROOT_DIR, AIO_GUIDE_EXAMPLES_DIR);\n    const actualSrc = path.relative(PROJECT_ROOT_DIR, CODEOWNERS_PATH);\n\n    reportDiff(guidesDiff, expectedGuidesSrc, actualSrc);\n    reportDiff(imagesDiff, expectedImagesSrc, actualSrc);\n    reportDiff(examplesDiff, expectedExamplesSrc, actualSrc);\n  }\n\n  process.exit(hasDiff ? 1 : 0);\n}", "language": "javascript"}
{"input": "<ctrl> + <alt> + s = Regular screenshot.\n<ctrl> + <alt> + <shift> + s = Equirectangular screenshot.", "output": "function (evt) {\n    var shortcutPressed = evt.keyCode === 83 && evt.ctrlKey && evt.altKey;\n    if (!this.data || !shortcutPressed) { return; }\n    var projection = evt.shiftKey ? 'equirectangular' : 'perspective';\n    this.capture(projection);\n  }", "language": "javascript"}
{"input": "returns the configuration of the replacement View or undefined\n@private", "output": "function(sViewName, vObject) {\n\t\t\t\tvar oResultConfig;\n\t\t\t\t// TODO: checking order of components?\n\t\t\t\tfindConfig(CONFIG_VIEW_REPLACEMENTS, vObject, function(oConfig) {\n\t\t\t\t\toResultConfig = oConfig[sViewName];\n\t\t\t\t\treturn !!oResultConfig;\n\t\t\t\t});\n\t\t\t\treturn oResultConfig;\n\t\t\t}", "language": "javascript"}
{"input": "Creates the URL group for to map the requested XMLHttpRequests to it's response.\n\n@param {string} sMethod The http method (e.g. GET, POST...)\n@param {string} sUrl The full requested URL.\n@returns {string} The created URL group for the mapping.", "output": "function(sMethod, sUrl) {\n\t\t\tvar sUrlResourcePart = new URI(sUrl).resource();\n\t\t\tsUrlResourcePart = this.replaceEntriesUrlByRegex(sUrlResourcePart);\n\t\t\treturn sMethod + sUrlResourcePart;\n\t\t}", "language": "javascript"}
{"input": "Returns a new requirement object with extras removed.", "output": "def strip_extras(requirement):\n    \"\"\"Returns a new requirement object with extras removed.\n    \"\"\"\n    line = requirement.as_line()\n    new = type(requirement).from_line(line)\n    new.extras = None\n    return new", "language": "python"}
{"input": "Special case for terminal comma. \nPush a single token into the push-back variable.\n@param {goog.labs.format.csv.Token} t Single token.", "output": "function pushBack(t) {\n    goog.labs.format.csv.assertToken_(t);\n    goog.asserts.assert(goog.isNull(pushBackToken));\n    pushBackToken = t;\n  }", "language": "javascript"}
{"input": "Returns a 'context' object for getting/setting project-specific preferences", "output": "function _getPrefsContext() {\n        var projectRoot = ProjectManager.getProjectRoot();  // note: null during unit tests!\n        return { location : { scope: \"user\", layer: \"project\", layerID: projectRoot && projectRoot.fullPath } };\n    }", "language": "javascript"}
{"input": "Context manager wrapping the training loop, updates step counters.", "output": "def training_loop(self):\n    \"\"\"Context manager wrapping the training loop, updates step counters.\"\"\"\n    if not self.restarting:\n      self._write_counters(self._local_step_at_start, self._global_step)\n\n    tf.logging.info(\n        \"Training %s up to %d, %d to go\", self.model_mode,\n        self.target_local_step, self.steps_to_go\n    )\n\n    yield\n\n    self._write_counters(self.target_local_step, -1)", "language": "python"}
{"input": "Description : training for LipNet", "output": "def train_batch(self, dataloader):\n        \"\"\"\n        Description : training for LipNet\n        \"\"\"\n        sum_losses = 0\n        len_losses = 0\n        for input_data, input_label in tqdm(dataloader):\n            data = gluon.utils.split_and_load(input_data, self.ctx, even_split=False)\n            label = gluon.utils.split_and_load(input_label, self.ctx, even_split=False)\n            batch_size = input_data.shape[0]\n            sum_losses, len_losses = self.train(data, label, batch_size)\n            sum_losses += sum_losses\n            len_losses += len_losses\n\n        return sum_losses, len_losses", "language": "python"}
{"input": "listing all previous siblings (until predicate hit).\n\n@param {Node} node\n@param {Function} [optional] pred - predicate function", "output": "function listPrev(node, pred) {\n  pred = pred || func.fail;\n\n  const nodes = [];\n  while (node) {\n    if (pred(node)) { break; }\n    nodes.push(node);\n    node = node.previousSibling;\n  }\n  return nodes;\n}", "language": "javascript"}
{"input": "Create view corresponding to the chosen config\n@returns {sap.ui.view} Created view", "output": "function () {\n\t\t\tvar oController;\n\n\t\t\t//step3: create view\n\t\t\tthis._oView = sap.ui.view(this._oViewConfig);\n\n\t\t\t//step4: bind the view with the model\n\t\t\tif (this._oModel) {\n\t\t\t\toController = this._oView.getController();\n\n\t\t\t\t//some factory requires pre-processing once the view and model are created\n\t\t\t\tif (oController && oController.connectToComponent) {\n\t\t\t\t\toController.connectToComponent(this._oModel);\n\t\t\t\t}\n\n\t\t\t\t//can now apply the model and rely on the underlying factory logic\n\t\t\t\tthis._oView.setModel(this._oModel, \"objectPageLayoutMetadata\");\n\t\t\t}\n\n\t\t\treturn this._oView;\n\t\t}", "language": "javascript"}
{"input": "Concat all nodelists passed as arguments.\n\n@return ...NodeList\n@return Array", "output": "function() {\n    var slice = Array.prototype.slice;\n    var args = slice.call(arguments);\n    var nodeLists = args.map(function(list) {\n      return slice.call(list);\n    });\n    return Array.prototype.concat.apply([], nodeLists);\n  }", "language": "javascript"}
{"input": "For the Layout attribute value, validate or replace with default\nfallback value", "output": "function validateAttributeValue(className, value, updateFn) {\n    var origValue;\n\n    if (!needsInterpolation(value)) {\n      switch (className.replace(SUFFIXES,\"\")) {\n        case 'layout'        :\n          if (!findIn(value, LAYOUT_OPTIONS)) {\n            value = LAYOUT_OPTIONS[0];    // 'row';\n          }\n          break;\n\n        case 'flex'          :\n          if (!findIn(value, FLEX_OPTIONS)) {\n            if (isNaN(value)) {\n              value = '';\n            }\n          }\n          break;\n\n        case 'flex-offset' :\n        case 'flex-order'    :\n          if (!value || isNaN(+value)) {\n            value = '0';\n          }\n          break;\n\n        case 'layout-align'  :\n          var axis = extractAlignAxis(value);\n          value = $mdUtil.supplant(\"{main}-{cross}\",axis);\n          break;\n\n        case 'layout-padding' :\n        case 'layout-margin'  :\n        case 'layout-fill'    :\n        case 'layout-wrap'    :\n        case 'layout-nowrap' :\n          value = '';\n          break;\n      }\n\n      if (value != origValue) {\n        (updateFn || angular.noop)(value);\n      }\n    }\n\n    return value ? value.trim() : \"\";\n  }", "language": "javascript"}
{"input": "If there are promise handlers waiting for execution at the time the timeout fires, start another timeout to postpone timer execution after promise execution.", "output": "function wrapTimerHandler(vHandler) {\n\t\t\t\tvar fnWrappedHandler = function() {\n\t\t\t\t\tvar aArgs, fnHandler;\n\t\t\t\t\tif (bPromisesQueued) {\n\t\t\t\t\t\taArgs = [fnWrappedHandler, 0].concat(arguments);\n\t\t\t\t\t\t_timeout.apply(window, aArgs);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfnHandler = typeof vHandler !== \"function\" ? new Function(vHandler) : vHandler; // eslint-disable-line no-new-func\n\t\t\t\t\t\tfnHandler.apply(window, arguments);\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\treturn fnWrappedHandler;\n\t\t\t}", "language": "javascript"}
{"input": "Gets to 2.92 in just under 4 days on 8 p100s.", "output": "def imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p():\n  \"\"\"Gets to 2.92 in just under 4 days on 8 p100s.\"\"\"\n  hparams = imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_l()\n  hparams.num_decoder_layers = 14\n  hparams.batch_size = 8\n  hparams.layer_prepostprocess_dropout = 0.2\n  return hparams", "language": "python"}
{"input": "Comparing a DateOffset to the string \"infer\" raises, so we need to\n    be careful about comparisons.  Make a dummy variable `freq_infer` to\n    signify the case where the given freq is \"infer\" and set freq to None\n    to avoid comparison trouble later on.\n\n    Parameters\n    ----------\n    freq : {DateOffset, None, str}\n\n    Returns\n    -------\n    freq : {DateOffset, None}\n    freq_infer : bool", "output": "def maybe_infer_freq(freq):\n    \"\"\"\n    Comparing a DateOffset to the string \"infer\" raises, so we need to\n    be careful about comparisons.  Make a dummy variable `freq_infer` to\n    signify the case where the given freq is \"infer\" and set freq to None\n    to avoid comparison trouble later on.\n\n    Parameters\n    ----------\n    freq : {DateOffset, None, str}\n\n    Returns\n    -------\n    freq : {DateOffset, None}\n    freq_infer : bool\n    \"\"\"\n    freq_infer = False\n    if not isinstance(freq, DateOffset):\n        # if a passed freq is None, don't infer automatically\n        if freq != 'infer':\n            freq = frequencies.to_offset(freq)\n        else:\n            freq_infer = True\n            freq = None\n    return freq, freq_infer", "language": "python"}
{"input": "Return a mix of env and video data fields and decoders.", "output": "def example_reading_spec(self):\n    \"\"\"Return a mix of env and video data fields and decoders.\"\"\"\n    video_fields, video_decoders = (\n        video_utils.VideoProblem.example_reading_spec(self))\n    env_fields, env_decoders = env_problem.EnvProblem.example_reading_spec(self)\n\n    # Remove raw observations field since we want to capture them as videos.\n    env_fields.pop(env_problem.OBSERVATION_FIELD)\n    env_decoders.pop(env_problem.OBSERVATION_FIELD)\n\n    # Add frame number spec and decoder.\n    env_fields[_FRAME_NUMBER_FIELD] = tf.FixedLenFeature((1,), tf.int64)\n    env_decoders[\n        _FRAME_NUMBER_FIELD] = tf.contrib.slim.tfexample_decoder.Tensor(\n            _FRAME_NUMBER_FIELD)\n\n    # Add video fields and decoders\n    env_fields.update(video_fields)\n    env_decoders.update(video_decoders)\n    return env_fields, env_decoders", "language": "python"}
{"input": "Parse an assign statement.", "output": "def parse_set(self):\n        \"\"\"Parse an assign statement.\"\"\"\n        lineno = next(self.stream).lineno\n        target = self.parse_assign_target(with_namespace=True)\n        if self.stream.skip_if('assign'):\n            expr = self.parse_tuple()\n            return nodes.Assign(target, expr, lineno=lineno)\n        filter_node = self.parse_filter(None)\n        body = self.parse_statements(('name:endset',),\n                                     drop_needle=True)\n        return nodes.AssignBlock(target, filter_node, body, lineno=lineno)", "language": "python"}
{"input": "Reshapes both modules for new input shapes.\n\n        Parameters\n        ----------\n        data_shapes : list of (str, tuple)\n            Typically is ``data_iter.provide_data``.\n        label_shapes : list of (str, tuple)\n            Typically is ``data_iter.provide_label``.", "output": "def reshape(self, data_shapes, label_shapes=None):\n        \"\"\"Reshapes both modules for new input shapes.\n\n        Parameters\n        ----------\n        data_shapes : list of (str, tuple)\n            Typically is ``data_iter.provide_data``.\n        label_shapes : list of (str, tuple)\n            Typically is ``data_iter.provide_label``.\n        \"\"\"\n        super(SVRGModule, self).reshape(data_shapes, label_shapes=label_shapes)\n        self._mod_aux.reshape(data_shapes, label_shapes=label_shapes)", "language": "python"}
{"input": "\u586b\u5145 Path \u6570\u636e\u3002\n\u5c3d\u91cf\u590d\u7528\u800c\u4e0d\u7533\u660e\u65b0\u7684\u6570\u7ec4\u3002\u5927\u90e8\u5206\u56fe\u5f62\u91cd\u7ed8\u7684\u6307\u4ee4\u6570\u636e\u957f\u5ea6\u90fd\u662f\u4e0d\u53d8\u7684\u3002", "output": "function (cmd) {\n        if (!this._saveData) {\n            return;\n        }\n\n        var data = this.data;\n        if (this._len + arguments.length > data.length) {\n            // \u56e0\u4e3a\u4e4b\u524d\u7684\u6570\u7ec4\u5df2\u7ecf\u8f6c\u6362\u6210\u9759\u6001\u7684 Float32Array\n            // \u6240\u4ee5\u4e0d\u591f\u7528\u65f6\u9700\u8981\u6269\u5c55\u4e00\u4e2a\u65b0\u7684\u52a8\u6001\u6570\u7ec4\n            this._expandData();\n            data = this.data;\n        }\n        for (var i = 0; i < arguments.length; i++) {\n            data[this._len++] = arguments[i];\n        }\n\n        this._prevCmd = cmd;\n    }", "language": "javascript"}
{"input": "Run this to be sure output and input (adaptive) softmax weights are tied", "output": "def tie_weights(self):\n        \"\"\" Run this to be sure output and input (adaptive) softmax weights are tied \"\"\"\n        # sampled softmax\n        if self.sample_softmax > 0:\n            if self.config.tie_weight:\n                self.out_layer.weight = self.transformer.word_emb.weight\n        # adaptive softmax (including standard softmax)\n        else:\n            if self.config.tie_weight:\n                for i in range(len(self.crit.out_layers)):\n                    self.crit.out_layers[i].weight = self.transformer.word_emb.emb_layers[i].weight\n            if self.config.tie_projs:\n                for i, tie_proj in enumerate(self.config.tie_projs):\n                    if tie_proj and self.config.div_val == 1 and self.config.d_model != self.config.d_embed:\n                        self.crit.out_projs[i] = self.transformer.word_emb.emb_projs[0]\n                    elif tie_proj and self.config.div_val != 1:\n                        self.crit.out_projs[i] = self.transformer.word_emb.emb_projs[i]", "language": "python"}
{"input": "When focusing and collapsing we modify lots of nodes in the tree. This allows us to restore them all to their original state when we revert.", "output": "function()\n    {\n        if (this._savedChildren)\n            return;\n\n        this._savedSelfTime = this.selfTime;\n        this._savedTotalTime = this.totalTime;\n        this._savedNumberOfCalls = this.numberOfCalls;\n\n        this._savedChildren = this.children.slice();\n    }", "language": "javascript"}
{"input": "Evaluate the agent with multiple eval configurations.", "output": "def evaluate_all_configs(\n    hparams, agent_model_dir, eval_fn=_eval_fn_with_learner\n):\n  \"\"\"Evaluate the agent with multiple eval configurations.\"\"\"\n  metrics = {}\n  # Iterate over all combinations of sampling temperatures and whether to do\n  # initial no-ops.\n  for sampling_temp in hparams.eval_sampling_temps:\n    # Iterate over a set so if eval_max_num_noops == 0 then it's 1 iteration.\n    for max_num_noops in set([hparams.eval_max_num_noops, 0]):\n      scores = evaluate_single_config(\n          hparams, sampling_temp, max_num_noops, agent_model_dir, eval_fn\n      )\n      for (score, clipped) in zip(scores, (True, False)):\n        metric_name = get_metric_name(sampling_temp, max_num_noops, clipped)\n        metrics[metric_name] = score\n\n  return metrics", "language": "python"}
{"input": "Return a slice of myself.\n\n        For internal compatibility with numpy arrays.", "output": "def _slice(self, slicer):\n        \"\"\"\n        Return a slice of myself.\n\n        For internal compatibility with numpy arrays.\n        \"\"\"\n\n        # only allow 1 dimensional slicing, but can\n        # in a 2-d case be passd (slice(None),....)\n        if isinstance(slicer, tuple) and len(slicer) == 2:\n            if not com.is_null_slice(slicer[0]):\n                raise AssertionError(\"invalid slicing for a 1-ndim \"\n                                     \"categorical\")\n            slicer = slicer[1]\n\n        codes = self._codes[slicer]\n        return self._constructor(values=codes, dtype=self.dtype, fastpath=True)", "language": "python"}
{"input": "Helper closure to create a function that may be used to respond to a message\n@private\n@param  {Window} source The window from which the message originated\n@param  {String} topic  The topic of the message\n@param  {String} uuid   The \"unique\" ID of the original message\n@return {Function}      A function that may be invoked to respond to the message", "output": "function createResponder(source, topic, uuid) {\n\t\treturn function(message, keepalive, callback) {\n\t\t\tpost(source, topic, message, uuid, keepalive, callback);\n\t\t};\n\t}", "language": "javascript"}
{"input": "Verifies that the meta.messages property is present.\nTODO: check it has the correct value\n@param {RuleContext} context The ESLint rule context.\n@param {ASTNode} exportsNode ObjectExpression node that the rule exports.\n@returns {void}", "output": "function checkMetaMessages(context, exportsNode) {\n    if (exportsNode.type !== \"ObjectExpression\") {\n\n        // if the exported node is not the correct format, \"internal-no-invalid-meta\" will already report this.\n        return;\n    }\n\n    const metaProperty = getPropertyFromObject(\"meta\", exportsNode);\n    const messages = metaProperty && getPropertyFromObject(\"messages\", metaProperty.value);\n\n    if (!messages) {\n        context.report({\n            node: metaProperty,\n            messageId: \"expectedMessages\"\n        });\n    }\n}", "language": "javascript"}
{"input": "Transform this._data into a string.\n@param {function} filter a function String -> String, applied if not null on the result.\n@return {String} the string representing this._data.", "output": "function(asUTF8) {\n    var result = getRawData(this);\n    if (result === null || typeof result === \"undefined\") {\n        return \"\";\n    }\n    // if the data is a base64 string, we decode it before checking the encoding !\n    if (this.options.base64) {\n        result = base64.decode(result);\n    }\n    if (asUTF8 && this.options.binary) {\n        // JSZip.prototype.utf8decode supports arrays as input\n        // skip to array => string step, utf8decode will do it.\n        result = out.utf8decode(result);\n    }\n    else {\n        // no utf8 transformation, do the array => string step.\n        result = utils.transformTo(\"string\", result);\n    }\n\n    if (!asUTF8 && !this.options.binary) {\n        result = out.utf8encode(result);\n    }\n    return result;\n}", "language": "javascript"}
{"input": "Map MXNet's InstanceNorm operator attributes to onnx's InstanceNormalization operator\n    based on the input node's attributes and return the created node.", "output": "def convert_instancenorm(node, **kwargs):\n    \"\"\"Map MXNet's InstanceNorm operator attributes to onnx's InstanceNormalization operator\n    based on the input node's attributes and return the created node.\n    \"\"\"\n    name, input_nodes, attrs = get_inputs(node, kwargs)\n\n    eps = float(attrs.get(\"eps\", 0.001))\n\n    node = onnx.helper.make_node(\n        'InstanceNormalization',\n        inputs=input_nodes,\n        outputs=[name],\n        name=name,\n        epsilon=eps)\n\n    return [node]", "language": "python"}
{"input": "/*\nCreates a view of a file (.brackets.json)\n@param {!File} file - the file to create a view for\n@param {!Pane} pane - the pane where to create the view\n@private", "output": "function _createConfigViewOf(file, pane) {\n        var result = new $.Deferred(),\n            view = pane.findViewOfFile(file.fullPath);\n\n        if (view) {\n            // existing view, then just show it\n            pane.showView(view);\n            result.resolve(view.getFile());\n        } else {\n            DocumentManager.getDocumentForPath(file.fullPath)\n                .done(function (doc) {\n                    var view = new ConfigView(doc, pane.$el);\n                    pane.addView(view, true);\n                    result.resolve(doc.file);\n                })\n                .fail(function (fileError) {\n                    result.reject(fileError);\n                });\n        }\n        return result.promise();\n    }", "language": "javascript"}
{"input": "Builds a full shake-shake sub layer.", "output": "def shake_shake_block(x, output_filters, stride, hparams):\n  \"\"\"Builds a full shake-shake sub layer.\"\"\"\n  is_training = hparams.mode == tf.estimator.ModeKeys.TRAIN\n  batch_size = common_layers.shape_list(x)[0]\n\n  # Generate random numbers for scaling the branches.\n  rand_forward = [\n      tf.random_uniform(\n          [batch_size, 1, 1, 1], minval=0, maxval=1, dtype=tf.float32)\n      for _ in range(hparams.shake_shake_num_branches)\n  ]\n  rand_backward = [\n      tf.random_uniform(\n          [batch_size, 1, 1, 1], minval=0, maxval=1, dtype=tf.float32)\n      for _ in range(hparams.shake_shake_num_branches)\n  ]\n  # Normalize so that all sum to 1.\n  total_forward = tf.add_n(rand_forward)\n  total_backward = tf.add_n(rand_backward)\n  rand_forward = [samp / total_forward for samp in rand_forward]\n  rand_backward = [samp / total_backward for samp in rand_backward]\n  zipped_rand = zip(rand_forward, rand_backward)\n\n  branches = []\n  for branch, (r_forward, r_backward) in enumerate(zipped_rand):\n    with tf.variable_scope(\"branch_{}\".format(branch)):\n      b = shake_shake_branch(x, output_filters, stride, r_forward, r_backward,\n                             hparams)\n      b = tf.nn.dropout(b, 1.0 - hparams.layer_prepostprocess_dropout)\n      branches.append(b)\n  res = shake_shake_skip_connection(x, output_filters, stride, is_training)\n  if hparams.shake_shake_concat:\n    concat_values = [res] + branches\n    concat_output = tf.concat(values=concat_values, axis=-1)\n    concat_output = tf.nn.relu(concat_output)\n    concat_output = tf.layers.conv2d(\n        concat_output, output_filters, (1, 1), name=\"concat_1x1\")\n    concat_output = tf.layers.batch_normalization(\n        concat_output, training=is_training, name=\"concat_bn\")\n    return concat_output\n  else:\n    return res + tf.add_n(branches)", "language": "python"}
{"input": "The tooltips option is a shorthand for using the 'update' event.", "output": "function tooltips ( ) {\n\n            // Tooltips are added with options.tooltips in original order.\n            var tips = scope_Handles.map(addTooltip);\n\n            bindEvent('update', function(values, handleNumber, unencoded) {\n\n                if ( !tips[handleNumber] ) {\n                    return;\n                }\n\n                var formattedValue = values[handleNumber];\n\n                if ( options.tooltips[handleNumber] !== true ) {\n                    formattedValue = options.tooltips[handleNumber].to(unencoded[handleNumber]);\n                }\n\n                tips[handleNumber].innerHTML = '<span>' + formattedValue + '</span>';\n            });\n        }", "language": "javascript"}
{"input": "Returns the Document that is currently open in the editor UI. May be null.\n@return {?Document}", "output": "function getCurrentDocument() {\n        var file = MainViewManager.getCurrentlyViewedFile(MainViewManager.ACTIVE_PANE);\n\n        if (file) {\n            return getOpenDocumentForPath(file.fullPath);\n        }\n\n        return null;\n    }", "language": "javascript"}
{"input": "Stop all the sounds in the pool.", "output": "function () {\n    var i;\n    var sound;\n    this.isPlaying = false;\n    for (i = 0; i < this.pool.children.length; i++) {\n      sound = this.pool.children[i];\n      if (!sound.source || !sound.source.buffer) { return; }\n      sound.stop();\n    }\n  }", "language": "javascript"}
{"input": "returns the current oElement's index in its parentElement's \"children\" collection (but works in IE as well)", "output": "function index() {\n\t\t\treturn Array.prototype.filter.call(oElement.parentNode.childNodes, function (oNode) {\n\t\t\t\t\treturn oNode.nodeType === 1;\n\t\t\t\t}).indexOf(oElement);\n\t\t}", "language": "javascript"}
{"input": "Helper function: Generate a random Zipf sample of given length.\n\n  Args:\n    distr_map: list of float, Zipf's distribution over nbr_symbols.\n    sample_len: integer, length of sequence to generate.\n\n  Returns:\n    sample: list of integer, Zipf's random sample over nbr_symbols.", "output": "def zipf_random_sample(distr_map, sample_len):\n  \"\"\"Helper function: Generate a random Zipf sample of given length.\n\n  Args:\n    distr_map: list of float, Zipf's distribution over nbr_symbols.\n    sample_len: integer, length of sequence to generate.\n\n  Returns:\n    sample: list of integer, Zipf's random sample over nbr_symbols.\n\n  \"\"\"\n  u = np.random.random(sample_len)\n  # Random produces values in range [0.0,1.0); even if it is almost\n  # improbable(but possible) that it can generate a clear 0.000..0.\n  return list(np.searchsorted(distr_map, u))", "language": "python"}
{"input": "Update information for given job.\n\n        Meta file will be loaded if exists, and the job information in\n        in db backend will be updated.\n\n        Args:\n            job_dir (str): Directory path of the job.\n\n        Return:\n            Updated dict of job meta info", "output": "def _update_job_info(cls, job_dir):\n        \"\"\"Update information for given job.\n\n        Meta file will be loaded if exists, and the job information in\n        in db backend will be updated.\n\n        Args:\n            job_dir (str): Directory path of the job.\n\n        Return:\n            Updated dict of job meta info\n        \"\"\"\n        meta_file = os.path.join(job_dir, JOB_META_FILE)\n        meta = parse_json(meta_file)\n\n        if meta:\n            logging.debug(\"Update job info for %s\" % meta[\"job_id\"])\n            JobRecord.objects \\\n                .filter(job_id=meta[\"job_id\"]) \\\n                .update(end_time=timestamp2date(meta[\"end_time\"]))", "language": "python"}
{"input": "The chrome-extension: can map a extension URL request to real file path.", "output": "function (request, callback) {\n  const parsed = url.parse(request.url)\n  if (!parsed.hostname || !parsed.path) return callback()\n\n  const manifest = manifestMap[parsed.hostname]\n  if (!manifest) return callback()\n\n  const page = backgroundPages[parsed.hostname]\n  if (page && parsed.path === `/${page.name}`) {\n    // Disabled due to false positive in StandardJS\n    // eslint-disable-next-line standard/no-callback-literal\n    return callback({\n      mimeType: 'text/html',\n      data: page.html\n    })\n  }\n\n  fs.readFile(path.join(manifest.srcDirectory, parsed.path), function (err, content) {\n    if (err) {\n      // Disabled due to false positive in StandardJS\n      // eslint-disable-next-line standard/no-callback-literal\n      return callback(-6) // FILE_NOT_FOUND\n    } else {\n      return callback(content)\n    }\n  })\n}", "language": "javascript"}
{"input": "Meant to be used in `pre_update` hooks on models to enforce ownership\n\n    Admin have all access, and other users need to be referenced on either\n    the created_by field that comes with the ``AuditMixin``, or in a field\n    named ``owners`` which is expected to be a one-to-many with the User\n    model. It is meant to be used in the ModelView's pre_update hook in\n    which raising will abort the update.", "output": "def check_ownership(obj, raise_if_false=True):\n    \"\"\"Meant to be used in `pre_update` hooks on models to enforce ownership\n\n    Admin have all access, and other users need to be referenced on either\n    the created_by field that comes with the ``AuditMixin``, or in a field\n    named ``owners`` which is expected to be a one-to-many with the User\n    model. It is meant to be used in the ModelView's pre_update hook in\n    which raising will abort the update.\n    \"\"\"\n    if not obj:\n        return False\n\n    security_exception = SupersetSecurityException(\n        \"You don't have the rights to alter [{}]\".format(obj))\n\n    if g.user.is_anonymous:\n        if raise_if_false:\n            raise security_exception\n        return False\n    roles = [r.name for r in get_user_roles()]\n    if 'Admin' in roles:\n        return True\n    session = db.create_scoped_session()\n    orig_obj = session.query(obj.__class__).filter_by(id=obj.id).first()\n\n    # Making a list of owners that works across ORM models\n    owners = []\n    if hasattr(orig_obj, 'owners'):\n        owners += orig_obj.owners\n    if hasattr(orig_obj, 'owner'):\n        owners += [orig_obj.owner]\n    if hasattr(orig_obj, 'created_by'):\n        owners += [orig_obj.created_by]\n\n    owner_names = [o.username for o in owners if o]\n\n    if (\n            g.user and hasattr(g.user, 'username') and\n            g.user.username in owner_names):\n        return True\n    if raise_if_false:\n        raise security_exception\n    else:\n        return False", "language": "python"}
{"input": "Return a tensor with given shape containing coordinate along given axis.\n\n  Args:\n    shape: a Tensor representing the shape of the output Tensor\n    axis: an integer\n\n  Returns:\n    A tensor with shape shape and type tf.int32, where each elements its\n    coordinate along the given axis.", "output": "def coordinate_tensor(shape, axis):\n  \"\"\"Return a tensor with given shape containing coordinate along given axis.\n\n  Args:\n    shape: a Tensor representing the shape of the output Tensor\n    axis: an integer\n\n  Returns:\n    A tensor with shape shape and type tf.int32, where each elements its\n    coordinate along the given axis.\n  \"\"\"\n  if axis < 0:\n    axis = tf.size(shape) + axis  # Convert to positive for the one_hot indice\n\n  r = tf.range(shape[axis])\n  r_shape = tf.one_hot(\n      axis, tf.size(shape), on_value=-1, off_value=1, dtype=tf.int32)\n  return tf.zeros(shape, dtype=tf.int32) + tf.reshape(r, r_shape)", "language": "python"}
{"input": "TODO Normalize this\nHelper function: Create a capture event\n@param {RegExp} rgx\n@param {String} evtName Event name\n@param {String} wholeMatch\n@param {String} text\n@param {String} id\n@param {String} url\n@param {String} title\n@param {{}} options\n@param {{}} globals\n@returns {showdown.helper.Event|*}", "output": "function createEvent (rgx, evtName, wholeMatch, text, id, url, title, options, globals) {\n    return globals.converter._dispatch(evtName, wholeMatch, options, globals, {\n      regexp: rgx,\n      matches: {\n        wholeMatch: wholeMatch,\n        text: text,\n        id: id,\n        url: url,\n        title: title\n      }\n    });\n  }", "language": "javascript"}
{"input": "/* [MS-XLSB] 2.4.662 BrtHLink", "output": "function parse_BrtHLink(data, length) {\n\tvar end = data.l + length;\n\tvar rfx = parse_UncheckedRfX(data, 16);\n\tvar relId = parse_XLNullableWideString(data);\n\tvar loc = parse_XLWideString(data);\n\tvar tooltip = parse_XLWideString(data);\n\tvar display = parse_XLWideString(data);\n\tdata.l = end;\n\tvar o = ({rfx:rfx, relId:relId, loc:loc, display:display});\n\tif(tooltip) o.Tooltip = tooltip;\n\treturn o;\n}", "language": "javascript"}
{"input": "Backwards compatibility hack. Without this slices with since: 7 days will\n    be treated as 7 days in the future.\n\n    :param str since:\n    :returns: Since with ago added if necessary\n    :rtype: str", "output": "def add_ago_to_since(since: str) -> str:\n    \"\"\"\n    Backwards compatibility hack. Without this slices with since: 7 days will\n    be treated as 7 days in the future.\n\n    :param str since:\n    :returns: Since with ago added if necessary\n    :rtype: str\n    \"\"\"\n    since_words = since.split(' ')\n    grains = ['days', 'years', 'hours', 'day', 'year', 'weeks']\n    if (len(since_words) == 2 and since_words[1] in grains):\n        since += ' ago'\n    return since", "language": "python"}
{"input": "Parses coordinates from an \"x y z\" string.\nExample: \"3 10 -5\" to {x: 3, y: 10, z: -5}.\n\n@param {string} val - An \"x y z\" string.\n@param {string} defaults - fallback value.\n@returns {object} An object with keys [x, y, z].", "output": "function parse (value, defaultVec) {\n  var coordinate;\n  var defaultVal;\n  var key;\n  var i;\n  var vec;\n  var x;\n  var y;\n  var z;\n  var w;\n\n  if (value && value instanceof Object) {\n    x = value.x === undefined ? defaultVec && defaultVec.x : value.x;\n    y = value.y === undefined ? defaultVec && defaultVec.y : value.y;\n    z = value.z === undefined ? defaultVec && defaultVec.z : value.z;\n    w = value.w === undefined ? defaultVec && defaultVec.w : value.w;\n    if (x !== undefined && x !== null) { value.x = parseIfString(x); }\n    if (y !== undefined && y !== null) { value.y = parseIfString(y); }\n    if (z !== undefined && z !== null) { value.z = parseIfString(z); }\n    if (w !== undefined && w !== null) { value.w = parseIfString(w); }\n    return value;\n  }\n\n  if (value === null || value === undefined) {\n    return typeof defaultVec === OBJECT ? extend({}, defaultVec) : defaultVec;\n  }\n\n  coordinate = value.trim().split(whitespaceRegex);\n  vec = {};\n  for (i = 0; i < COORDINATE_KEYS.length; i++) {\n    key = COORDINATE_KEYS[i];\n    if (coordinate[i]) {\n      vec[key] = parseFloat(coordinate[i], 10);\n    } else {\n      defaultVal = defaultVec && defaultVec[key];\n      if (defaultVal === undefined) { continue; }\n      vec[key] = parseIfString(defaultVal);\n    }\n  }\n  return vec;\n}", "language": "javascript"}
{"input": "get number of selected rows\n@param {WysiwygEditor} wwe - wysiwygEditor instance\n@returns {number} - number of selected rows\n@ignore", "output": "function getSelectedRowsLength(wwe) {\n  const selectionMgr = wwe.componentManager.getManager('tableSelection');\n  const $selectedCells = selectionMgr.getSelectedCells();\n  let length = 1;\n\n  if ($selectedCells.length > 1) {\n    const first = $selectedCells.first().get(0);\n    const last = $selectedCells.last().get(0);\n    const range = selectionMgr.getSelectionRangeFromTable(first, last);\n    length = range.to.row - range.from.row + 1;\n  }\n\n  return length;\n}", "language": "javascript"}
{"input": "Given an index, find the level length for each element.\n\n    Optional argument is a list of index positions which\n    should not be visible.\n\n    Result is a dictionary of (level, inital_position): span", "output": "def _get_level_lengths(index, hidden_elements=None):\n    \"\"\"\n    Given an index, find the level length for each element.\n\n    Optional argument is a list of index positions which\n    should not be visible.\n\n    Result is a dictionary of (level, inital_position): span\n    \"\"\"\n    sentinel = object()\n    levels = index.format(sparsify=sentinel, adjoin=False, names=False)\n\n    if hidden_elements is None:\n        hidden_elements = []\n\n    lengths = {}\n    if index.nlevels == 1:\n        for i, value in enumerate(levels):\n            if(i not in hidden_elements):\n                lengths[(0, i)] = 1\n        return lengths\n\n    for i, lvl in enumerate(levels):\n        for j, row in enumerate(lvl):\n            if not get_option('display.multi_sparse'):\n                lengths[(i, j)] = 1\n            elif (row != sentinel) and (j not in hidden_elements):\n                last_label = j\n                lengths[(i, last_label)] = 1\n            elif (row != sentinel):\n                # even if its hidden, keep track of it in case\n                # length >1 and later elements are visible\n                last_label = j\n                lengths[(i, last_label)] = 0\n            elif(j not in hidden_elements):\n                lengths[(i, last_label)] += 1\n\n    non_zero_lengths = {\n        element: length for element, length in lengths.items() if length >= 1}\n\n    return non_zero_lengths", "language": "python"}
{"input": "Enables the extension at the given path.\n\n@param {string} path The absolute path to the extension to enable.\n@return {$.Promise} A promise that's resolved when the extenion is enable, or\nrejected if there was an error.", "output": "function enable(path) {\n        var result = new $.Deferred(),\n            file = FileSystem.getFileForPath(path + \"/.disabled\");\n\n        function afterEnable() {\n            ExtensionLoader.loadExtension(FileUtils.getBaseName(path), { baseUrl: path }, \"main\")\n                .done(result.resolve)\n                .fail(result.reject);\n        }\n\n        var defaultExtensionPath = ExtensionLoader.getDefaultExtensionPath();\n        if (file.fullPath.indexOf(defaultExtensionPath) === 0) {\n            toggleDefaultExtension(path, true);\n            afterEnable();\n            return result.promise();\n        }\n\n        file.unlink(function (err) {\n            if (err) {\n                return result.reject(err);\n            }\n            afterEnable();\n        });\n        return result.promise();\n    }", "language": "javascript"}
{"input": "@private\nVerifies if an extension is a theme based on the presence of the field \"theme\"\nin the package.json.  If it is a theme, then the theme file is just loaded by the\nThemeManager\n\n@param {string} id of the theme extension to load", "output": "function loadTheme(id) {\n        var extension = extensions[id];\n        if (extension.installInfo && extension.installInfo.metadata && extension.installInfo.metadata.theme) {\n            ThemeManager.loadPackage(extension.installInfo);\n        }\n    }", "language": "javascript"}
{"input": "Modifies index.html with necessary changes in order to display correctly in codepen See each processor to determine how each modifies the html", "output": "function processHtml(demo) {\n\n      var allContent = demo.files.index.contents;\n\n      var processors = [\n        applyAngularAttributesToParentElement,\n        insertTemplatesAsScriptTags,\n        htmlEscapeAmpersand\n      ];\n\n      processors.forEach(function(processor) {\n        allContent = processor(allContent, demo);\n      });\n\n      return allContent;\n    }", "language": "javascript"}
{"input": "Handles explicit content reset for a document caused by external changes\n@private", "output": "function _handleExternalChange(evt, doc) {\n        if (doc) {\n            _removeBackwardFramesForFile(doc.file);\n            _removeForwardFramesForFile(doc.file);\n            _validateNavigationCmds();\n        }\n    }", "language": "javascript"}
{"input": "Returns log det | dx / dy | = num_events * sum log | scale |.", "output": "def log_det_jacobian(self, inputs):\n    \"\"\"Returns log det | dx / dy | = num_events * sum log | scale |.\"\"\"\n    del inputs  # unused\n    # Number of events is number of all elements excluding the batch and\n    # channel dimensions.\n    num_events = tf.reduce_prod(tf.shape(inputs)[1:-1])\n    log_det_jacobian = num_events * tf.reduce_sum(self.log_scale)\n    return log_det_jacobian", "language": "python"}
{"input": "Find the next tag\n@param {string} source string\n@param {integer} ignore characters before this offset", "output": "function _findTag(src, skip) {\n        var from, to, inc;\n        from = _find(src, [/<[a-z!\\/]/i, 2], skip);\n        if (from < 0) {\n            return null;\n        }\n        if (src.substr(from, 4) === \"<!--\") {\n            // html comments\n            to = _find(src, \"-->\", from + 4);\n            inc = 3;\n        } else if (src.substr(from, 7).toLowerCase() === \"<script\") {\n            // script tag\n            to = _find(src.toLowerCase(), \"</script>\", from + 7);\n            inc = 9;\n        } else if (src.substr(from, 6).toLowerCase() === \"<style\") {\n            // style tag\n            to = _find(src.toLowerCase(), \"</style>\", from + 6);\n            inc = 8;\n        } else {\n            to = _find(src, \">\", from + 1, true);\n            inc = 1;\n        }\n        if (to < 0) {\n            return null;\n        }\n        return {from: from, length: to + inc - from};\n    }", "language": "javascript"}
{"input": "Generate concatenated lines from file upto up_threshold characters.", "output": "def concat_generator(filename, up_threshold, low_threshold=10):\n  \"\"\"Generate concatenated lines from file upto up_threshold characters.\"\"\"\n  txt = \"\"\n  for line in tf.gfile.Open(filename):\n    line = line.strip()\n    if len(txt) + len(line) + 1 >= up_threshold:\n      ret = txt\n      txt = \"\"\n      # We don't yield very short long parts to prevent noisy examples.\n      if len(ret) > low_threshold and len(ret) < up_threshold:\n        yield {\"targets\": ret}\n\n    if not txt:\n      txt = line\n    else:\n      txt = \" \".join([txt, line])", "language": "python"}
{"input": "Callback function after each epoch. Now it records each epoch time\n        and append it to epoch dataframe.", "output": "def epoch_cb(self):\n        \"\"\"Callback function after each epoch. Now it records each epoch time\n        and append it to epoch dataframe.\n        \"\"\"\n        metrics = {}\n        metrics['elapsed'] = self.elapsed()\n        now = datetime.datetime.now()\n        metrics['epoch_time'] = now - self.last_epoch_time\n        self.append_metrics(metrics, 'epoch')\n        self.last_epoch_time = now", "language": "python"}
{"input": "Applies a rolling sum operator to the stream.\n\n        Attributes:\n             sum_attribute_index (int): The index of the attribute to sum\n             (assuming tuple records).", "output": "def sum(self, attribute_selector, state_keeper=None):\n        \"\"\"Applies a rolling sum operator to the stream.\n\n        Attributes:\n             sum_attribute_index (int): The index of the attribute to sum\n             (assuming tuple records).\n        \"\"\"\n        op = Operator(\n            _generate_uuid(),\n            OpType.Sum,\n            \"Sum\",\n            _sum,\n            other=attribute_selector,\n            state_actor=state_keeper,\n            num_instances=self.env.config.parallelism)\n        return self.__register(op)", "language": "python"}
{"input": "Converting metrics to numeric when pandas.read_sql cannot", "output": "def df_metrics_to_num(self, df, query_object):\n        \"\"\"Converting metrics to numeric when pandas.read_sql cannot\"\"\"\n        metrics = [metric for metric in query_object.metrics]\n        for col, dtype in df.dtypes.items():\n            if dtype.type == np.object_ and col in metrics:\n                df[col] = pd.to_numeric(df[col], errors='coerce')", "language": "python"}
{"input": "XOR (false/true)\n\n    This tests how well a feature attribution method agrees with human intuition\n    for an eXclusive OR operation combined with linear effects. This metric deals\n    specifically with the question of credit allocation for the following function\n    when all three inputs are true:\n    if fever: +2 points\n    if cough: +2 points\n    if fever or cough but not both: +6 points\n\n    transform = \"identity\"\n    sort_order = 4", "output": "def human_xor_01(X, y, model_generator, method_name):\n    \"\"\" XOR (false/true)\n\n    This tests how well a feature attribution method agrees with human intuition\n    for an eXclusive OR operation combined with linear effects. This metric deals\n    specifically with the question of credit allocation for the following function\n    when all three inputs are true:\n    if fever: +2 points\n    if cough: +2 points\n    if fever or cough but not both: +6 points\n\n    transform = \"identity\"\n    sort_order = 4\n    \"\"\"\n    return _human_xor(X, model_generator, method_name, False, True)", "language": "python"}
{"input": "Compares 2 UI5 version strings taking into account only major and minor version info\n@returns {boolean}", "output": "function (sVersionA, sVersionB) {\n\t\t\t\tvar oVA = Version(sVersionA),\n\t\t\t\t\toVB = Version(sVersionB);\n\n\t\t\t\treturn (oVA.getMajor() + \".\" + oVA.getMinor()) === (oVB.getMajor() + \".\" + oVB.getMinor());\n\t\t\t}", "language": "javascript"}
{"input": "Start animation from scratch.", "output": "function () {\n    var data = this.data;\n\n    this.updateConfig();\n    this.animationIsPlaying = false;\n    this.animation = anime(this.config);\n    this.animation.began = true;\n\n    this.removeEventListeners();\n    this.addEventListeners();\n\n    // Wait for start events for animation.\n    if (!data.autoplay || data.startEvents && data.startEvents.length) { return; }\n\n    // Delay animation.\n    if (data.delay) {\n      setTimeout(this.beginAnimation, data.delay);\n      return;\n    }\n\n    // Play animation.\n    this.beginAnimation();\n  }", "language": "javascript"}
{"input": "Return (sha_or_none, is_branch), where sha_or_none is a commit hash\n        if the revision names a remote branch or tag, otherwise None.\n\n        Args:\n          dest: the repository directory.\n          rev: the revision name.", "output": "def get_revision_sha(self, dest, rev):\n        \"\"\"\n        Return (sha_or_none, is_branch), where sha_or_none is a commit hash\n        if the revision names a remote branch or tag, otherwise None.\n\n        Args:\n          dest: the repository directory.\n          rev: the revision name.\n        \"\"\"\n        # Pass rev to pre-filter the list.\n        output = self.run_command(['show-ref', rev], cwd=dest,\n                                  show_stdout=False, on_returncode='ignore')\n        refs = {}\n        for line in output.strip().splitlines():\n            try:\n                sha, ref = line.split()\n            except ValueError:\n                # Include the offending line to simplify troubleshooting if\n                # this error ever occurs.\n                raise ValueError('unexpected show-ref line: {!r}'.format(line))\n\n            refs[ref] = sha\n\n        branch_ref = 'refs/remotes/origin/{}'.format(rev)\n        tag_ref = 'refs/tags/{}'.format(rev)\n\n        sha = refs.get(branch_ref)\n        if sha is not None:\n            return (sha, True)\n\n        sha = refs.get(tag_ref)\n\n        return (sha, False)", "language": "python"}
{"input": "Return a sorted list of strings representing all possible actions\n        of the form: nonterminal -> [right_hand_side]", "output": "def all_possible_actions(self) -> List[str]:\n        \"\"\"\n        Return a sorted list of strings representing all possible actions\n        of the form: nonterminal -> [right_hand_side]\n        \"\"\"\n        all_actions = set()\n        for _, action_list in self.valid_actions.items():\n            for action in action_list:\n                all_actions.add(action)\n        return sorted(all_actions)", "language": "python"}
{"input": "Ensures all trials get fair share of time (as defined by time_attr).\n\n        This enables the PBT scheduler to support a greater number of\n        concurrent trials than can fit in the cluster at any given time.", "output": "def choose_trial_to_run(self, trial_runner):\n        \"\"\"Ensures all trials get fair share of time (as defined by time_attr).\n\n        This enables the PBT scheduler to support a greater number of\n        concurrent trials than can fit in the cluster at any given time.\n        \"\"\"\n\n        candidates = []\n        for trial in trial_runner.get_trials():\n            if trial.status in [Trial.PENDING, Trial.PAUSED] and \\\n                    trial_runner.has_resources(trial.resources):\n                candidates.append(trial)\n        candidates.sort(\n            key=lambda trial: self._trial_state[trial].last_perturbation_time)\n        return candidates[0] if candidates else None", "language": "python"}
{"input": "Initialize optimizer and learner hyperparameters.", "output": "def on_train_begin(self, pbar, **kwargs:Any)->None:\n        \"Initialize optimizer and learner hyperparameters.\"\n        setattr(pbar, 'clean_on_interrupt', True)\n        self.learn.save('tmp')\n        self.opt = self.learn.opt\n        self.opt.lr = self.sched.start\n        self.stop,self.best_loss = False,0.\n        return {'skip_validate': True}", "language": "python"}
{"input": "Removes an item from the given map by path.\n\n@param {object} mMap\nA map from path to a list of items\n@param {string} sPath\nThe path\n@param {object} oItem\nThe item", "output": "function (mMap, sPath, oItem) {\n\t\t\tvar aItems = mMap[sPath],\n\t\t\t\tiIndex;\n\n\t\t\tif (aItems) {\n\t\t\t\tiIndex = aItems.indexOf(oItem);\n\t\t\t\tif (iIndex >= 0) {\n\t\t\t\t\tif (aItems.length === 1) {\n\t\t\t\t\t\tdelete mMap[sPath];\n\t\t\t\t\t} else {\n\t\t\t\t\t\taItems.splice(iIndex, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Generate summaries for features.", "output": "def summarize_features(features, num_shards=1):\n  \"\"\"Generate summaries for features.\"\"\"\n  if not common_layers.should_generate_summaries():\n    return\n\n  with tf.name_scope(\"input_stats\"):\n    for (k, v) in sorted(six.iteritems(features)):\n      if (isinstance(v, tf.Tensor) and (v.get_shape().ndims > 1) and\n          (v.dtype != tf.string)):\n        tf.summary.scalar(\"%s_batch\" % k, tf.shape(v)[0] // num_shards)\n        tf.summary.scalar(\"%s_length\" % k, tf.shape(v)[1])\n        nonpadding = tf.to_float(tf.not_equal(v, 0))\n        nonpadding_tokens = tf.reduce_sum(nonpadding)\n        tf.summary.scalar(\"%s_nonpadding_tokens\" % k, nonpadding_tokens)\n        tf.summary.scalar(\"%s_nonpadding_fraction\" % k,\n                          tf.reduce_mean(nonpadding))", "language": "python"}
{"input": "mobile nav back handling", "output": "function (sRoute, oData) {\n\t\t\tvar oHistory = History.getInstance();\n\t\t\tvar oPrevHash = oHistory.getPreviousHash();\n\t\t\tif (oPrevHash !== undefined) {\n\t\t\t\twindow.history.go(-1);\n\t\t\t} else {\n\t\t\t\tvar bReplace = true; // otherwise we go backwards with a forward history\n\t\t\t\tthis.navTo(sRoute, oData, bReplace);\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Consolidate _data -- if the blocks have changed, then clear the\n        cache", "output": "def _protect_consolidate(self, f):\n        \"\"\"Consolidate _data -- if the blocks have changed, then clear the\n        cache\n        \"\"\"\n        blocks_before = len(self._data.blocks)\n        result = f()\n        if len(self._data.blocks) != blocks_before:\n            self._clear_item_cache()\n        return result", "language": "python"}
{"input": "Just converts from an ``argparse.Namespace`` object to params.", "output": "def make_vocab_from_args(args: argparse.Namespace):\n    \"\"\"\n    Just converts from an ``argparse.Namespace`` object to params.\n    \"\"\"\n    parameter_path = args.param_path\n    overrides = args.overrides\n    serialization_dir = args.serialization_dir\n\n    params = Params.from_file(parameter_path, overrides)\n\n    make_vocab_from_params(params, serialization_dir)", "language": "python"}
{"input": "Given an element and a selector that finds that element (but possibly other sibling elements)\nreturn the :nth-child(n) pseudo selector that uniquely finds the node within its siblings\n@param {Element} elm\t\t\t The Element\n@param {String} selector\t The selector\n@return {String}\t\t\t\t\t The nth-child selector", "output": "function getNthChildString(elm, selector) {\n\tconst siblings =\n\t\t(elm.parentNode && Array.from(elm.parentNode.children || '')) || [];\n\tconst hasMatchingSiblings = siblings.find(\n\t\tsibling => sibling !== elm && axe.utils.matchesSelector(sibling, selector)\n\t);\n\tif (hasMatchingSiblings) {\n\t\tconst nthChild = 1 + siblings.indexOf(elm);\n\t\treturn ':nth-child(' + nthChild + ')';\n\t} else {\n\t\treturn '';\n\t}\n}", "language": "javascript"}
{"input": "Instance normalization layer.", "output": "def instance_norm(x):\n  \"\"\"Instance normalization layer.\"\"\"\n  with tf.variable_scope(\"instance_norm\"):\n    epsilon = 1e-5\n    mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\n    scale = tf.get_variable(\n        \"scale\", [x.get_shape()[-1]],\n        initializer=tf.truncated_normal_initializer(mean=1.0, stddev=0.02))\n    offset = tf.get_variable(\n        \"offset\", [x.get_shape()[-1]], initializer=tf.constant_initializer(0.0))\n    out = scale * tf.div(x - mean, tf.sqrt(var + epsilon)) + offset\n\n    return out", "language": "python"}
{"input": "Initializes the state of parsed content from updateHelper.json\nreturns Promise Object Which is resolved when parsing is success\nand rejected if parsing is failed.", "output": "function initState() {\n        var result = $.Deferred();\n        updateJsonHandler.parse()\n            .done(function() {\n                result.resolve();\n            })\n            .fail(function (code) {\n                var logMsg;\n                switch (code) {\n                case StateHandlerMessages.FILE_NOT_FOUND:\n                    logMsg = \"AutoUpdate : updateHelper.json cannot be parsed, does not exist\";\n                    break;\n                case StateHandlerMessages.FILE_NOT_READ:\n                    logMsg = \"AutoUpdate : updateHelper.json could not be read\";\n                    break;\n                case StateHandlerMessages.FILE_PARSE_EXCEPTION:\n                    logMsg = \"AutoUpdate : updateHelper.json could not be parsed, exception encountered\";\n                    break;\n                case StateHandlerMessages.FILE_READ_FAIL:\n                    logMsg = \"AutoUpdate : updateHelper.json could not be parsed\";\n                    break;\n                }\n                console.log(logMsg);\n                result.reject();\n            });\n        return result.promise();\n    }", "language": "javascript"}
{"input": "return a new manager with the blocks", "output": "def combine(self, blocks, copy=True):\n        \"\"\" return a new manager with the blocks \"\"\"\n        if len(blocks) == 0:\n            return self.make_empty()\n\n        # FIXME: optimization potential\n        indexer = np.sort(np.concatenate([b.mgr_locs.as_array\n                                          for b in blocks]))\n        inv_indexer = lib.get_reverse_indexer(indexer, self.shape[0])\n\n        new_blocks = []\n        for b in blocks:\n            b = b.copy(deep=copy)\n            b.mgr_locs = algos.take_1d(inv_indexer, b.mgr_locs.as_array,\n                                       axis=0, allow_fill=False)\n            new_blocks.append(b)\n\n        axes = list(self.axes)\n        axes[0] = self.items.take(indexer)\n\n        return self.__class__(new_blocks, axes, do_integrity_check=False)", "language": "python"}
{"input": "Returns a function that will map names/labels, dependent if mapper\n    is a dict, Series or just a function.", "output": "def _get_rename_function(mapper):\n    \"\"\"\n    Returns a function that will map names/labels, dependent if mapper\n    is a dict, Series or just a function.\n    \"\"\"\n    if isinstance(mapper, (abc.Mapping, ABCSeries)):\n\n        def f(x):\n            if x in mapper:\n                return mapper[x]\n            else:\n                return x\n    else:\n        f = mapper\n\n    return f", "language": "python"}
{"input": "@private\n\nWatches the project for filesystem changes so that the tree can be updated.", "output": "function _watchProjectRoot(rootPath) {\n        FileSystem.on(\"change\", _fileSystemChange);\n        FileSystem.on(\"rename\", _fileSystemRename);\n\n        FileSystem.watch(FileSystem.getDirectoryForPath(rootPath), ProjectModel._shouldShowName, ProjectModel.defaultIgnoreGlobs, function (err) {\n            if (err === FileSystemError.TOO_MANY_ENTRIES) {\n                if (!_projectWarnedForTooManyFiles) {\n                    _showErrorDialog(ERR_TYPE_MAX_FILES);\n                    _projectWarnedForTooManyFiles = true;\n                }\n            } else if (err) {\n                console.error(\"Error watching project root: \", rootPath, err);\n            }\n        });\n\n        // Reset allFiles cache\n        model._resetCache();\n    }", "language": "javascript"}
{"input": "Removes top level TimeLimit Wrapper.\n\n  Removes TimeLimit Wrapper from top level if exists, throws error if any other\n  TimeLimit Wrapper is present in stack.\n\n  Args:\n    env: environment\n\n  Returns:\n    the env with removed time limit wrapper.", "output": "def remove_time_limit_wrapper(env):\n  \"\"\"Removes top level TimeLimit Wrapper.\n\n  Removes TimeLimit Wrapper from top level if exists, throws error if any other\n  TimeLimit Wrapper is present in stack.\n\n  Args:\n    env: environment\n\n  Returns:\n    the env with removed time limit wrapper.\n  \"\"\"\n  if isinstance(env, gym.wrappers.TimeLimit):\n    env = env.env\n  env_ = env\n  while isinstance(env_, gym.Wrapper):\n    if isinstance(env_, gym.wrappers.TimeLimit):\n      raise ValueError(\"Can remove only top-level TimeLimit gym.Wrapper.\")\n    env_ = env_.env\n  return env", "language": "python"}
{"input": "Handle a key from the keypress event", "output": "function handleCharBinding(cm, e, ch) {\n  return dispatchKey(cm, \"'\" + ch + \"'\", e, b => doHandleBinding(cm, b, true))\n}", "language": "javascript"}
{"input": "Generate a random array with a fixed seed.", "output": "def const_rand(size, seed=23980):\n    \"\"\" Generate a random array with a fixed seed.\n    \"\"\"\n    old_seed = np.random.seed()\n    np.random.seed(seed)\n    out = np.random.rand(size)\n    np.random.seed(old_seed)\n    return out", "language": "python"}
{"input": "Returns value of the header with the specified <code>sHeaderName</code> from\nthe specified <code>sHeaders</code> section of MIME part.\n\n@param {string} sHeaders\nSection of MIME part representing HTTP headers\n@param {string} sHeaderName\nName of HTTP header in lower case\n@returns {string} The HTTP header value", "output": "function getHeaderValue(sHeaders, sHeaderName) {\n\t\tvar i,\n\t\t\taHeaderParts,\n\t\t\taHeaders = sHeaders.split(\"\\r\\n\");\n\n\t\tfor (i = 0; i < aHeaders.length; i += 1) {\n\t\t\taHeaderParts = aHeaders[i].split(\":\");\n\n\t\t\tif (aHeaderParts[0].toLowerCase().trim() === sHeaderName) {\n\t\t\t\treturn aHeaderParts[1].trim();\n\t\t\t}\n\t\t}\n\t}", "language": "javascript"}
{"input": "check for and remaining history items and destroy them", "output": "function remove(id) {\n\t\t\tvar oItem = sap.ui.getCore().byId(id);\n\t\t\tif (oItem) {\n\t\t\t\toItem.destroy();\n\t\t\t}\n\t\t}", "language": "javascript"}
{"input": "Rotate the player's viewing direction.\n@param  {Number} angle Angle to rotate by.", "output": "function(angle) {\n    this.dir = (this.dir + angle + circle) % circle;\n\n    // Calculate the rotation vector and update the orientation of the listener.\n    var x = Math.cos(this.dir);\n    var y = 0;\n    var z = Math.sin(this.dir);\n    Howler.orientation(x, y, z, 0, 1, 0);\n  }", "language": "javascript"}
{"input": "Workaround for touch devices routing all events for a mouse gesture (down, move, up) via the initial DOM node. Same for HTML images in all IE versions (VML images are working).", "output": "function(evt)\n\t{\n\t\tvar result = state;\n\t\t\n\t\tif ((graph.dialect != mxConstants.DIALECT_SVG && mxEvent.getSource(evt).nodeName == 'IMG') || mxClient.IS_TOUCH)\n\t\t{\n\t\t\tvar x = mxEvent.getClientX(evt);\n\t\t\tvar y = mxEvent.getClientY(evt);\n\t\t\t\n\t\t\t// Dispatches the drop event to the graph which\n\t\t\t// consumes and executes the source function\n\t\t\tvar pt = mxUtils.convertPoint(graph.container, x, y);\n\t\t\tresult = graph.view.getState(graph.getCellAt(pt.x, pt.y));\n\t\t}\n\t\t\n\t\treturn result;\n\t}", "language": "javascript"}
{"input": "statement   : ruleset | at-rule;", "output": "function statement(toks, i, n, handler) {\n    if (i < n) {\n      var tok = toks[i];\n      if (tok.charAt(0) === '@') {\n        return atrule(toks, i, n, handler, true);\n      } else {\n        return ruleset(toks, i, n, handler);\n      }\n    } else {\n      return i;\n    }\n  }", "language": "javascript"}
{"input": "Construct an Element instance from regexp\n    groups.", "output": "def interpret_element(element_type: str, text: str, span: str) -> Element:\n    \"\"\"\n    Construct an Element instance from regexp\n    groups.\n    \"\"\"\n    return Element(element_type,\n                   interpret_span(span),\n                   text)", "language": "python"}
{"input": "Returns true if commit should NOT be cherry-picked.", "output": "function shouldSkipCommit(logLine, mode) {\n  const parsedCommit = parser.sync(logLine.message, parserOpts);\n  return (parsedCommit.type === 'feat' && mode === 'patch') || // feature commit\n    parsedCommit.notes.find((note) => note.title === 'BREAKING CHANGE') || // breaking change commit\n    (parsedCommit.type === 'chore' && parsedCommit.subject === 'Publish'); // Publish (version-rev) commit\n}", "language": "javascript"}
{"input": "Check whether `key` is ambiguous.\n\n        By ambiguous, we mean that it matches both a level of the input\n        `axis` and a label of the other axis.\n\n        Parameters\n        ----------\n        key: str or object\n            label or level name\n        axis: int, default 0\n            Axis that levels are associated with (0 for index, 1 for columns)\n\n        Raises\n        ------\n        ValueError: `key` is ambiguous", "output": "def _check_label_or_level_ambiguity(self, key, axis=0):\n        \"\"\"\n        Check whether `key` is ambiguous.\n\n        By ambiguous, we mean that it matches both a level of the input\n        `axis` and a label of the other axis.\n\n        Parameters\n        ----------\n        key: str or object\n            label or level name\n        axis: int, default 0\n            Axis that levels are associated with (0 for index, 1 for columns)\n\n        Raises\n        ------\n        ValueError: `key` is ambiguous\n        \"\"\"\n        if self.ndim > 2:\n            raise NotImplementedError(\n                \"_check_label_or_level_ambiguity is not implemented for {type}\"\n                .format(type=type(self)))\n\n        axis = self._get_axis_number(axis)\n        other_axes = (ax for ax in range(self._AXIS_LEN) if ax != axis)\n\n        if (key is not None and\n                is_hashable(key) and\n                key in self.axes[axis].names and\n                any(key in self.axes[ax] for ax in other_axes)):\n\n            # Build an informative and grammatical warning\n            level_article, level_type = (('an', 'index')\n                                         if axis == 0 else\n                                         ('a', 'column'))\n\n            label_article, label_type = (('a', 'column')\n                                         if axis == 0 else\n                                         ('an', 'index'))\n\n            msg = (\"'{key}' is both {level_article} {level_type} level and \"\n                   \"{label_article} {label_type} label, which is ambiguous.\"\n                   ).format(key=key,\n                            level_article=level_article,\n                            level_type=level_type,\n                            label_article=label_article,\n                            label_type=label_type)\n            raise ValueError(msg)", "language": "python"}
{"input": "Construct a pooling layer.", "output": "def _pool(self, pool_name, pool_function, k_height, k_width, d_height,\n              d_width, mode, input_layer, num_channels_in):\n        \"\"\"Construct a pooling layer.\"\"\"\n        if input_layer is None:\n            input_layer = self.top_layer\n        else:\n            self.top_size = num_channels_in\n        name = pool_name + str(self.counts[pool_name])\n        self.counts[pool_name] += 1\n        if self.use_tf_layers:\n            pool = pool_function(\n                input_layer, [k_height, k_width], [d_height, d_width],\n                padding=mode,\n                data_format=self.channel_pos,\n                name=name)\n        else:\n            if self.data_format == \"NHWC\":\n                ksize = [1, k_height, k_width, 1]\n                strides = [1, d_height, d_width, 1]\n            else:\n                ksize = [1, 1, k_height, k_width]\n                strides = [1, 1, d_height, d_width]\n            pool = tf.nn.max_pool(\n                input_layer,\n                ksize,\n                strides,\n                padding=mode,\n                data_format=self.data_format,\n                name=name)\n        self.top_layer = pool\n        return pool", "language": "python"}
{"input": "Returns a cached view for a given name or creates it if it does not yet exists\n\n@deprecated Since 1.28.1 use {@link #getViews} instead.\n@param {string} sViewName Name of the view\n@param {string} sViewType Type of the view\n@param {string} sViewId Optional view id\n@return {sap.ui.core.mvc.View} the view instance\n@public", "output": "function (sViewName, sViewType, sViewId) {\n\t\t\t\tLog.warning(\"Deprecated API Router#getView called - use Router#getViews instead.\", this);\n\n\t\t\t\tvar oView = this._oViews._getViewWithGlobalId({\n\t\t\t\t\tviewName: sViewName,\n\t\t\t\t\ttype: sViewType,\n\t\t\t\t\tid: sViewId\n\t\t\t\t});\n\n\t\t\t\tthis.fireViewCreated({\n\t\t\t\t\tview: oView,\n\t\t\t\t\tviewName: sViewName,\n\t\t\t\t\ttype: sViewType\n\t\t\t\t});\n\n\t\t\t\treturn oView;\n\t\t\t}", "language": "javascript"}
{"input": "Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.", "output": "def resize_img(fname, targ, path, new_path, fn=None):\n    \"\"\"\n    Enlarge or shrink a single image to scale, such that the smaller of the height or width dimension is equal to targ.\n    \"\"\"\n    if fn is None:\n        fn = resize_fn(targ)\n    dest = os.path.join(path_for(path, new_path, targ), fname)\n    if os.path.exists(dest): return\n    im = Image.open(os.path.join(path, fname)).convert('RGB')\n    os.makedirs(os.path.split(dest)[0], exist_ok=True)\n    fn(im).save(dest)", "language": "python"}
{"input": "/* 18.3 Worksheets also covers Chartsheets", "output": "function parse_cs_xml(data/*:?string*/, opts, idx/*:number*/, rels, wb/*::, themes, styles*/)/*:Worksheet*/ {\n\tif(!data) return data;\n\t/* 18.3.1.12 chartsheet CT_ChartSheet */\n\tif(!rels) rels = {'!id':{}};\n\tvar s = {'!type':\"chart\", '!chart':null, '!rel':\"\"};\n\tvar m;\n\n\t/* 18.3.1.83 sheetPr CT_ChartsheetPr */\n\tvar sheetPr = data.match(sheetprregex);\n\tif(sheetPr) parse_ws_xml_sheetpr(sheetPr[0], s, wb, idx);\n\n\t/* 18.3.1.36 drawing CT_Drawing */\n\tif((m = data.match(/drawing r:id=\"(.*?)\"/))) s['!rel'] = m[1];\n\n\tif(rels['!id'][s['!rel']]) s['!chart'] = rels['!id'][s['!rel']];\n\treturn s;\n}", "language": "javascript"}
{"input": "Returns the number symbols and formats for a locale\n@returns [ symbols, formats ]\nsymbols: [ decimal, group, list, percentSign, plusSign, minusSign, exponential, superscriptingExponent, perMille, infinity, nan, timeSeparator, currencyDecimal?, currencyGroup? ]\nformats: [ currency, decimal, percent, scientific ]", "output": "function getNumberSettings(localeData) {\n  const decimalFormat = localeData.main('numbers/decimalFormats-numberSystem-latn/standard');\n  const percentFormat = localeData.main('numbers/percentFormats-numberSystem-latn/standard');\n  const scientificFormat = localeData.main('numbers/scientificFormats-numberSystem-latn/standard');\n  const currencyFormat = localeData.main('numbers/currencyFormats-numberSystem-latn/standard');\n  const symbols = localeData.main('numbers/symbols-numberSystem-latn');\n  const symbolValues = [\n    symbols.decimal,\n    symbols.group,\n    symbols.list,\n    symbols.percentSign,\n    symbols.plusSign,\n    symbols.minusSign,\n    symbols.exponential,\n    symbols.superscriptingExponent,\n    symbols.perMille,\n    symbols.infinity,\n    symbols.nan,\n    symbols.timeSeparator,\n  ];\n\n  if (symbols.currencyDecimal || symbols.currencyGroup) {\n    symbolValues.push(symbols.currencyDecimal);\n  }\n\n  if (symbols.currencyGroup) {\n    symbolValues.push(symbols.currencyGroup);\n  }\n\n  return [\n    symbolValues,\n    [decimalFormat, percentFormat, currencyFormat, scientificFormat]\n  ];\n}", "language": "javascript"}
{"input": "Generates temporary markdown file that will be sourced by Typedoc to\ncreate index.html.\n\n@param {string} tocRaw\n@param {string} homeRaw", "output": "function generateTempHomeMdFile(tocRaw, homeRaw) {\n  const { toc } = yaml.safeLoad(tocRaw);\n  let tocPageLines = [homeRaw, '# API Reference'];\n  toc.forEach(group => {\n    tocPageLines.push(`\\n## [${group.title}](${stripPath(group.path)}.html)`);\n    group.section.forEach(item => {\n      tocPageLines.push(`- [${item.title}](${stripPath(item.path)}.html)`);\n    });\n  });\n  return fs.writeFile(tempHomePath, tocPageLines.join('\\n'));\n}", "language": "javascript"}
{"input": "reverse of try_coerce_args", "output": "def _try_coerce_result(self, result):\n        \"\"\" reverse of try_coerce_args \"\"\"\n        if isinstance(result, np.ndarray):\n            if result.dtype.kind in ['i', 'f']:\n                result = result.astype('M8[ns]')\n\n        elif isinstance(result, (np.integer, np.float, np.datetime64)):\n            result = self._box_func(result)\n        return result", "language": "python"}
{"input": "Returns the data associated to the given document\n@private\n@param {Document} ownerDocument The document.\n@returns {Object} An object of data.", "output": "function getExpandoData(ownerDocument) {\n    var data = expandoData[ownerDocument[expando]];\n    if (!data) {\n        data = {};\n        expanID++;\n        ownerDocument[expando] = expanID;\n        expandoData[expanID] = data;\n    }\n    return data;\n  }", "language": "javascript"}
{"input": "Gate values corresponding to the examples in the per-expert `Tensor`s.\n\n    Returns:\n      a list of `num_experts` one-dimensional `Tensor`s of type `tf.float32`.", "output": "def expert_to_gates(self):\n    \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n\n    Returns:\n      a list of `num_experts` one-dimensional `Tensor`s of type `tf.float32`.\n    \"\"\"\n    return self._ep(\n        tf.concat,\n        transpose_list_of_lists(\n            self._dp(lambda d: d.expert_to_gates(), self._dispatchers)), 0)", "language": "python"}
{"input": "Add merged cell.\n@param {object} base - base table data\n@param {object} cellData - cell data\n@param {number} startRowIndex - start row index\n@param {number} startCellIndex - start cell index\n@private", "output": "function _addMergedCell(base, cellData, startRowIndex, startCellIndex) {\n  const {\n    colspan,\n    rowspan,\n    nodeName\n  } = cellData;\n  const colMerged = colspan > 1;\n  const rowMerged = rowspan > 1;\n\n  if (!colMerged && !rowMerged) {\n    return;\n  }\n\n  const limitRowIndex = startRowIndex + rowspan;\n  const limitCellIndex = startCellIndex + colspan;\n\n  util.range(startRowIndex, limitRowIndex).forEach(rowIndex => {\n    base[rowIndex] = base[rowIndex] || [];\n\n    util.range(startCellIndex, limitCellIndex).forEach(cellIndex => {\n      const mergedData = {\n        nodeName\n      };\n\n      if (rowIndex === startRowIndex && cellIndex === startCellIndex) {\n        return;\n      }\n\n      if (colMerged) {\n        mergedData.colMergeWith = startCellIndex;\n      }\n\n      if (rowMerged) {\n        mergedData.rowMergeWith = startRowIndex;\n      }\n\n      base[rowIndex][cellIndex] = mergedData;\n    });\n  });\n}", "language": "javascript"}
{"input": "Initializes the parameters and auxiliary states.", "output": "def init_params(self, initializer=mx.init.Uniform(0.01), **kwargs):\n        \"\"\"Initializes the parameters and auxiliary states.\n        \"\"\"\n        self._module.init_params(initializer=initializer, **kwargs)", "language": "python"}
{"input": "/*\nUpdate the for association of the related label", "output": "function _updateLabelFor(){\n\t\tvar aFields = this.getFields();\n\t\tvar oField = aFields.length > 0 ? aFields[0] : null;\n\n\t\tvar oLabel = this._oLabel;\n\t\tif (oLabel) {\n\t\t\toLabel.setLabelFor(oField); // as Label is internal of FormElement, we can use original labelFor\n\t\t} else {\n\t\t\toLabel = this.getLabel();\n\t\t\tif (oLabel instanceof Control /*might also be a string*/) {\n\t\t\t\toLabel.setAlternativeLabelFor(oField);\n\t\t\t}\n\t\t}\n\t}", "language": "javascript"}
{"input": "Initialize the iterator given eval_data.", "output": "def _init_eval_iter(self, eval_data):\n        \"\"\"Initialize the iterator given eval_data.\"\"\"\n        if eval_data is None:\n            return eval_data\n        if isinstance(eval_data, (tuple, list)) and len(eval_data) == 2:\n            if eval_data[0] is not None:\n                if eval_data[1] is None and isinstance(eval_data[0], io.DataIter):\n                    return eval_data[0]\n                input_data = (np.array(eval_data[0]) if isinstance(eval_data[0], list)\n                              else eval_data[0])\n                input_label = (np.array(eval_data[1]) if isinstance(eval_data[1], list)\n                               else eval_data[1])\n                return self._init_iter(input_data, input_label, is_train=True)\n            else:\n                raise ValueError(\"Eval data is NONE\")\n        if not isinstance(eval_data, io.DataIter):\n            raise TypeError('Eval data must be DataIter, or ' \\\n                            'NDArray/numpy.ndarray/list pair (i.e. tuple/list of length 2)')\n        return eval_data", "language": "python"}
{"input": "For inference, will briefly replace the dataset with one that only contains `item`.", "output": "def set_item(self,item):\n        \"For inference, will briefly replace the dataset with one that only contains `item`.\"\n        self.item = self.x.process_one(item)\n        yield None\n        self.item = None", "language": "python"}
{"input": "Logs transition during exploit/exploit step.\n\n        For each step, logs: [target trial tag, clone trial tag, target trial\n        iteration, clone trial iteration, old config, new config].", "output": "def _log_config_on_step(self, trial_state, new_state, trial,\n                            trial_to_clone, new_config):\n        \"\"\"Logs transition during exploit/exploit step.\n\n        For each step, logs: [target trial tag, clone trial tag, target trial\n        iteration, clone trial iteration, old config, new config].\n        \"\"\"\n        trial_name, trial_to_clone_name = (trial_state.orig_tag,\n                                           new_state.orig_tag)\n        trial_id = \"\".join(itertools.takewhile(str.isdigit, trial_name))\n        trial_to_clone_id = \"\".join(\n            itertools.takewhile(str.isdigit, trial_to_clone_name))\n        trial_path = os.path.join(trial.local_dir,\n                                  \"pbt_policy_\" + trial_id + \".txt\")\n        trial_to_clone_path = os.path.join(\n            trial_to_clone.local_dir,\n            \"pbt_policy_\" + trial_to_clone_id + \".txt\")\n        policy = [\n            trial_name, trial_to_clone_name,\n            trial.last_result[TRAINING_ITERATION],\n            trial_to_clone.last_result[TRAINING_ITERATION],\n            trial_to_clone.config, new_config\n        ]\n        # Log to global file.\n        with open(os.path.join(trial.local_dir, \"pbt_global.txt\"), \"a+\") as f:\n            f.write(json.dumps(policy) + \"\\n\")\n        # Overwrite state in target trial from trial_to_clone.\n        if os.path.exists(trial_to_clone_path):\n            shutil.copyfile(trial_to_clone_path, trial_path)\n        # Log new exploit in target trial log.\n        with open(trial_path, \"a+\") as f:\n            f.write(json.dumps(policy) + \"\\n\")", "language": "python"}
{"input": "Encode character string in the Series/Index using indicated encoding.\n    Equivalent to :meth:`str.encode`.\n\n    Parameters\n    ----------\n    encoding : str\n    errors : str, optional\n\n    Returns\n    -------\n    encoded : Series/Index of objects", "output": "def str_encode(arr, encoding, errors=\"strict\"):\n    \"\"\"\n    Encode character string in the Series/Index using indicated encoding.\n    Equivalent to :meth:`str.encode`.\n\n    Parameters\n    ----------\n    encoding : str\n    errors : str, optional\n\n    Returns\n    -------\n    encoded : Series/Index of objects\n    \"\"\"\n    if encoding in _cpython_optimized_encoders:\n        # CPython optimized implementation\n        f = lambda x: x.encode(encoding, errors)\n    else:\n        encoder = codecs.getencoder(encoding)\n        f = lambda x: encoder(x, errors)[0]\n    return _na_map(f, arr)", "language": "python"}
{"input": "Add mixup https://arxiv.org/abs/1710.09412 to `learn`.", "output": "def mixup(learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True) -> Learner:\n    \"Add mixup https://arxiv.org/abs/1710.09412 to `learn`.\"\n    learn.callback_fns.append(partial(MixUpCallback, alpha=alpha, stack_x=stack_x, stack_y=stack_y))\n    return learn", "language": "python"}
{"input": "Collect internal arrays from executors.", "output": "def _collect_arrays(self):\n        \"\"\"Collect internal arrays from executors.\"\"\"\n        # convenient data structures\n        self.data_arrays = [[(self.slices[i], e.arg_dict[name]) for i, e in enumerate(self.execs)]\n                            for name, _ in self.data_shapes]\n\n        self.state_arrays = [[e.arg_dict[name] for e in self.execs]\n                             for name in self.state_names]\n\n        if self.label_shapes is not None:\n            self.label_arrays = [[(self.slices[i], e.arg_dict[name])\n                                  for i, e in enumerate(self.execs)]\n                                 for name, _ in self.label_shapes]\n        else:\n            self.label_arrays = None\n\n        self.param_arrays = [[exec_.arg_arrays[i] for exec_ in self.execs]\n                             for i, name in enumerate(self.arg_names)\n                             if name in self.param_names]\n        if self.for_training:\n            self.grad_arrays = [[exec_.grad_arrays[i] for exec_ in self.execs]\n                                for i, name in enumerate(self.arg_names)\n                                if name in self.param_names]\n        else:\n            self.grad_arrays = None\n\n        data_names = [x[0] for x in self.data_shapes]\n        if self.inputs_need_grad:\n            self.input_grad_arrays = [[exec_.grad_arrays[self.arg_names.index(name)]\n                                       for exec_ in self.execs]\n                                      for name in data_names if name in self.arg_names]\n        else:\n            self.input_grad_arrays = None\n\n        self.aux_arrays = [[exec_.aux_arrays[i] for exec_ in self.execs]\n                           for i in range(len(self.aux_names))]", "language": "python"}
{"input": "Reports with the first extra statement, and clears it.\n\n@returns {void}", "output": "function reportFirstExtraStatementAndClear() {\n            if (firstExtraStatement) {\n                context.report({\n                    node: firstExtraStatement,\n                    messageId: \"exceed\",\n                    data: {\n                        numberOfStatementsOnThisLine,\n                        maxStatementsPerLine,\n                        statements: numberOfStatementsOnThisLine === 1 ? \"statement\" : \"statements\"\n                    }\n                });\n            }\n            firstExtraStatement = null;\n        }", "language": "javascript"}
{"input": "Create self-attention layer based on hyperparameters.", "output": "def self_attention_layer(hparams, prefix):\n  \"\"\"Create self-attention layer based on hyperparameters.\"\"\"\n  return transformer_layers.SelfAttention(\n      num_heads=hparams.get(prefix + \"num_heads\"),\n      num_memory_heads=hparams.get(prefix + \"num_memory_heads\"),\n      key_value_size=hparams.d_kv,\n      shared_kv=hparams.get(prefix + \"shared_kv\", False),\n      attention_kwargs=attention_kwargs_from_hparams(hparams))", "language": "python"}
{"input": "Returns `True` if we can get output of the command in the\n    `settings.wait_command` time.\n\n    Command will be killed if it wasn't finished in the time.\n\n    :type popen: Popen\n    :rtype: bool", "output": "def _wait_output(popen, is_slow):\n    \"\"\"Returns `True` if we can get output of the command in the\n    `settings.wait_command` time.\n\n    Command will be killed if it wasn't finished in the time.\n\n    :type popen: Popen\n    :rtype: bool\n\n    \"\"\"\n    proc = Process(popen.pid)\n    try:\n        proc.wait(settings.wait_slow_command if is_slow\n                  else settings.wait_command)\n        return True\n    except TimeoutExpired:\n        for child in proc.children(recursive=True):\n            _kill_process(child)\n        _kill_process(proc)\n        return False", "language": "python"}
{"input": "When we add a new expression, there may be other expressions that refer to\n        it, and we need to update those to point to the new expression.", "output": "def _update_expression_reference(self, # pylint: disable=no-self-use\n                                     grammar: Grammar,\n                                     parent_expression_nonterminal: str,\n                                     child_expression_nonterminal: str) -> None:\n        \"\"\"\n        When we add a new expression, there may be other expressions that refer to\n        it, and we need to update those to point to the new expression.\n        \"\"\"\n        grammar[parent_expression_nonterminal].members = \\\n                [member if member.name != child_expression_nonterminal\n                 else grammar[child_expression_nonterminal]\n                 for member in grammar[parent_expression_nonterminal].members]", "language": "python"}
{"input": "Config video types", "output": "def handle_type(self, frames):\n        \"\"\"\n        Config video types\n        \"\"\"\n        if self.vtype == 'mouth':\n            self.process_frames_mouth(frames)\n        elif self.vtype == 'face':\n            self.process_frames_face(frames)\n        else:\n            raise Exception('Video type not found')", "language": "python"}
{"input": "Export the svn repository at the url to the destination location", "output": "def export(self, location):\n        \"\"\"Export the svn repository at the url to the destination location\"\"\"\n        url, rev_options = self.get_url_rev_options(self.url)\n\n        logger.info('Exporting svn repository %s to %s', url, location)\n        with indent_log():\n            if os.path.exists(location):\n                # Subversion doesn't like to check out over an existing\n                # directory --force fixes this, but was only added in svn 1.5\n                rmtree(location)\n            cmd_args = ['export'] + rev_options.to_args() + [url, location]\n            self.run_command(cmd_args, show_stdout=False)", "language": "python"}
{"input": "If the current element was not in the old DOM, then we will create\nan elementInsert edit for it.\n\nIf the element was in the old DOM, this will return false and the\nmain loop will either spot this element later in the child list\nor the element has been moved.\n\n@return {boolean} true if an elementInsert was created", "output": "function () {\n            if (!oldNodeMap[newChild.tagID]) {\n                newEdit = {\n                    type: \"elementInsert\",\n                    tag: newChild.tag,\n                    tagID: newChild.tagID,\n                    parentID: newChild.parent.tagID,\n                    attributes: newChild.attributes\n                };\n\n                newEdits.push(newEdit);\n\n                // This newly inserted node needs to have edits generated for its\n                // children, so we add it to the queue.\n                newElements.push(newChild);\n\n                // A textInsert edit that follows this elementInsert should use\n                // this element's ID.\n                textAfterID = newChild.tagID;\n\n                // new element means we need to move on to compare the next\n                // of the current tree with the one from the old tree that we\n                // just compared\n                newIndex++;\n                return true;\n            }\n            return false;\n        }", "language": "javascript"}
{"input": "Creates a masking layer for the discrete actions\n        :param all_logits: The concatenated unnormalized action probabilities for all branches\n        :param action_masks: The mask for the logits. Must be of dimension [None x total_number_of_action]\n        :param action_size: A list containing the number of possible actions for each branch\n        :return: The action output dimension [batch_size, num_branches] and the concatenated normalized logits", "output": "def create_discrete_action_masking_layer(all_logits, action_masks, action_size):\n        \"\"\"\n        Creates a masking layer for the discrete actions\n        :param all_logits: The concatenated unnormalized action probabilities for all branches\n        :param action_masks: The mask for the logits. Must be of dimension [None x total_number_of_action]\n        :param action_size: A list containing the number of possible actions for each branch\n        :return: The action output dimension [batch_size, num_branches] and the concatenated normalized logits\n        \"\"\"\n        action_idx = [0] + list(np.cumsum(action_size))\n        branches_logits = [all_logits[:, action_idx[i]:action_idx[i + 1]] for i in range(len(action_size))]\n        branch_masks = [action_masks[:, action_idx[i]:action_idx[i + 1]] for i in range(len(action_size))]\n        raw_probs = [tf.multiply(tf.nn.softmax(branches_logits[k]) + 1.0e-10, branch_masks[k])\n                     for k in range(len(action_size))]\n        normalized_probs = [\n            tf.divide(raw_probs[k], tf.reduce_sum(raw_probs[k], axis=1, keepdims=True))\n            for k in range(len(action_size))]\n        output = tf.concat([tf.multinomial(tf.log(normalized_probs[k]), 1) for k in range(len(action_size))], axis=1)\n        return output, tf.concat([tf.log(normalized_probs[k] + 1.0e-10) for k in range(len(action_size))], axis=1)", "language": "python"}
{"input": "TODO Style override ?", "output": "function IncrementalDisplayble(opts) {\n\n    Displayble.call(this, opts);\n\n    this._displayables = [];\n\n    this._temporaryDisplayables = [];\n\n    this._cursor = 0;\n\n    this.notClear = true;\n}", "language": "javascript"}
{"input": "Draws a report (multiple tables).\n@param {Array} results Report results for every file.\n@returns {string} A column of text tables.", "output": "function drawReport(results) {\n    let files;\n\n    files = results.map(result => {\n        if (!result.messages.length) {\n            return \"\";\n        }\n\n        return `\\n${result.filePath}\\n\\n${drawTable(result.messages)}`;\n    });\n\n    files = files.filter(content => content.trim());\n\n    return files.join(\"\");\n}", "language": "javascript"}
{"input": "Computes the Hadamard product of the vector.", "output": "def transform(self, vector):\n        \"\"\"\n        Computes the Hadamard product of the vector.\n        \"\"\"\n        if isinstance(vector, RDD):\n            vector = vector.map(_convert_to_vector)\n\n        else:\n            vector = _convert_to_vector(vector)\n        return callMLlibFunc(\"elementwiseProductVector\", self.scalingVector, vector)", "language": "python"}
{"input": "Gets the areas of the table which can be scrolled horizontally.\n\n@param {sap.ui.table.Table} oTable Instance of the table.\n@returns {HTMLElement[]} Returns only elements which exist in the DOM.\n@private", "output": "function(oTable) {\n\t\t\tvar oDomRef = oTable.getDomRef();\n\t\t\tvar aScrollableColumnAreas;\n\n\t\t\tif (oDomRef) {\n\t\t\t\taScrollableColumnAreas = Array.prototype.slice.call(oTable.getDomRef().querySelectorAll(\".sapUiTableCtrlScr\"));\n\t\t\t}\n\n\t\t\tvar aScrollAreas = [\n\t\t\t\toTable._getScrollExtension().getHorizontalScrollbar()\n\t\t\t].concat(aScrollableColumnAreas);\n\n\t\t\treturn aScrollAreas.filter(function(oScrollArea) {\n\t\t\t\treturn oScrollArea != null;\n\t\t\t});\n\t\t}", "language": "javascript"}
{"input": "<rect x=\"0\" y=\"0\" width=\"100%\" height=\"100%\" mask=\"url(#shepherdModalMask)\"/>", "output": "function _createMaskConsumer() {\n  const element = document.createElementNS(svgNS, 'rect');\n\n  _setAttributes(element, {\n    height: '100%',\n    width: '100%',\n    x: '0',\n    y: '0'\n  });\n  element.setAttribute('mask', `url(#${elementIds.modalOverlayMask})`);\n\n  return element;\n}", "language": "javascript"}
{"input": "Performs division and handles divide-by-zero.\n\n    On zero-division, sets the corresponding result elements to zero.", "output": "def _prf_divide(numerator, denominator):\n    \"\"\"Performs division and handles divide-by-zero.\n\n    On zero-division, sets the corresponding result elements to zero.\n    \"\"\"\n    result = numerator / denominator\n    mask = denominator == 0.0\n    if not mask.any():\n        return result\n\n    # remove nan\n    result[mask] = 0.0\n    return result", "language": "python"}
{"input": "Return a JSON representation of a page\n\n@param {Page} page\n@param {Summary} summary\n@return {Object}", "output": "function encodePage(page, summary) {\n    var file = page.getFile();\n    var attributes = page.getAttributes();\n    var article = summary.getByPath(file.getPath());\n\n    var result = attributes.toJS();\n\n    if (article) {\n        result.title = article.getTitle();\n        result.level = article.getLevel();\n        result.depth = article.getDepth();\n\n        var nextArticle = summary.getNextArticle(article);\n        if (nextArticle) {\n            result.next = encodeSummaryArticle(nextArticle);\n        }\n\n        var prevArticle = summary.getPrevArticle(article);\n        if (prevArticle) {\n            result.previous = encodeSummaryArticle(prevArticle);\n        }\n    }\n\n    result.content = page.getContent();\n    result.dir = page.getDir();\n\n    return result;\n}", "language": "javascript"}
{"input": "Determine whether the supplied filename looks like a possible name of python.\n\n    :param str name: The name of the provided file.\n    :return: Whether the provided name looks like python.\n    :rtype: bool", "output": "def looks_like_python(name):\n    # type: (str) -> bool\n    \"\"\"\n    Determine whether the supplied filename looks like a possible name of python.\n\n    :param str name: The name of the provided file.\n    :return: Whether the provided name looks like python.\n    :rtype: bool\n    \"\"\"\n\n    if not any(name.lower().startswith(py_name) for py_name in PYTHON_IMPLEMENTATIONS):\n        return False\n    match = RE_MATCHER.match(name)\n    if match:\n        return any(fnmatch(name, rule) for rule in MATCH_RULES)\n    return False", "language": "python"}
{"input": "Create the factorized Adam accumulators for diet variables.", "output": "def create_slots(self, var):\n    \"\"\"Create the factorized Adam accumulators for diet variables.\"\"\"\n    params = self.params\n    shape = var.get_shape().as_list()\n\n    if not hasattr(params, \"slots\"):\n      params.slots = defaultdict(dict)\n\n    name = var.op.name\n    slots = params.slots[name]\n\n    if params.factored_second_moment_accumulator and len(shape) == 2:\n      slots[\"adam_vr\"] = tf.get_variable(\n          name + \"_adam_vr\", [shape[0], 1],\n          trainable=False,\n          initializer=tf.zeros_initializer())\n      slots[\"adam_vc\"] = tf.get_variable(\n          name + \"_adam_vc\", [1, shape[1]],\n          trainable=False,\n          initializer=tf.zeros_initializer())\n    else:\n      slots[\"adam_v\"] = tf.get_variable(\n          name + \"_adam_v\",\n          shape,\n          trainable=False,\n          initializer=tf.zeros_initializer())\n    if params.beta1 != 0.0:\n      slots[\"adam_m\"] = tf.get_variable(\n          name + \"_adam_m\",\n          shape,\n          trainable=False,\n          initializer=tf.zeros_initializer())", "language": "python"}
{"input": "Yield non-empty lines from file at path", "output": "def non_empty_lines(path):\n    \"\"\"\n    Yield non-empty lines from file at path\n    \"\"\"\n    with open(path) as f:\n        for line in f:\n            line = line.strip()\n            if line:\n                yield line", "language": "python"}
{"input": "### Model Query\nMake the call to the Model layer\n@param {Object} options\n@returns {Object} options", "output": "function doQuery(options) {\n            return models.Subscriber.findOne(options.data, _.omit(options, ['data']))\n                .then((model) => {\n                    if (!model) {\n                        return Promise.reject(new common.errors.NotFoundError({\n                            message: common.i18n.t('errors.api.subscribers.subscriberNotFound')\n                        }));\n                    }\n\n                    return {\n                        subscribers: [model.toJSON(options)]\n                    };\n                });\n        }", "language": "javascript"}
{"input": "Prototype to capture a navigation frame and it's various data/functional attributues", "output": "function NavigationFrame(editor, selectionObj) {\n        this.cm = editor._codeMirror;\n        this.filePath = editor.document.file._path;\n        this.inMem = editor.document.file.constructor.name === \"InMemoryFile\";\n        this.paneId = editor._paneId;\n        this._hash = editor.document.file._hash;\n        this.uId = (new Date()).getTime();\n        this.selections = [];\n        this.bookMarkIds = [];\n        this._createMarkers(selectionObj.ranges);\n    }", "language": "javascript"}
{"input": "Calls the addClass providers to get the classes (in string form) to add for the current\nfile or directory.\n\n@param {string} classes Initial classes for this node\n@return {string} classes for the current node", "output": "function (classes) {\n            var extensions = this.props.extensions;\n\n            if (extensions && extensions.get(\"addClass\")) {\n                var data = this.getDataForExtension();\n                classes = classes + \" \" + extensions.get(\"addClass\").map(function (callback) {\n                    try {\n                        return callback(data);\n                    } catch (e) {\n                        console.error(\"Exception thrown in FileTreeView addClass provider: \" + e, e.stack);\n                    }\n                }).filter(isDefined).toArray().join(\" \");\n            }\n\n            return classes;\n        }", "language": "javascript"}
{"input": "Create a `tls.TLSSocket` and initiate a connection.\n\n@param {Object} options Connection options\n@return {tls.TLSSocket} The newly created socket used to start the connection\n@private", "output": "function tlsConnect(options) {\n  options.path = undefined;\n  options.servername = options.servername || options.host;\n  return tls.connect(options);\n}", "language": "javascript"}
{"input": "Pad batch dim of features to nearest multiple of batch_multiple.", "output": "def pad_batch(features, batch_multiple):\n  \"\"\"Pad batch dim of features to nearest multiple of batch_multiple.\"\"\"\n  feature = list(features.items())[0][1]\n  batch_size = tf.shape(feature)[0]\n  mod = batch_size % batch_multiple\n  has_mod = tf.cast(tf.cast(mod, tf.bool), tf.int32)\n  batch_padding = batch_multiple * has_mod - mod\n\n  padded_features = {}\n  for k, feature in features.items():\n    rank = len(feature.shape)\n    paddings = [[0, 0] for _ in range(rank)]\n    paddings[0][1] = batch_padding\n    padded_feature = tf.pad(feature, paddings)\n    padded_features[k] = padded_feature\n  return padded_features", "language": "python"}
{"input": "Function: escapeNode\nEscape the node part (also called local part) of a JID.\n\nParameters:\n(String) node - A node (or local part).\n\nReturns:\nAn escaped node (or local part).", "output": "function (node)\r\n    {\r\n        if (typeof node !== \"string\") { return node; }\r\n        return node.replace(/^\\s+|\\s+$/g, '')\r\n            .replace(/\\\\/g,  \"\\\\5c\")\r\n            .replace(/ /g,   \"\\\\20\")\r\n            .replace(/\\\"/g,  \"\\\\22\")\r\n            .replace(/\\&/g,  \"\\\\26\")\r\n            .replace(/\\'/g,  \"\\\\27\")\r\n            .replace(/\\//g,  \"\\\\2f\")\r\n            .replace(/:/g,   \"\\\\3a\")\r\n            .replace(/</g,   \"\\\\3c\")\r\n            .replace(/>/g,   \"\\\\3e\")\r\n            .replace(/@/g,   \"\\\\40\");\r\n    }", "language": "javascript"}
{"input": "Loads a ORC file stream, returning the result as a :class:`DataFrame`.\n\n        .. note:: Evolving.\n\n        >>> orc_sdf = spark.readStream.schema(sdf_schema).orc(tempfile.mkdtemp())\n        >>> orc_sdf.isStreaming\n        True\n        >>> orc_sdf.schema == sdf_schema\n        True", "output": "def orc(self, path):\n        \"\"\"Loads a ORC file stream, returning the result as a :class:`DataFrame`.\n\n        .. note:: Evolving.\n\n        >>> orc_sdf = spark.readStream.schema(sdf_schema).orc(tempfile.mkdtemp())\n        >>> orc_sdf.isStreaming\n        True\n        >>> orc_sdf.schema == sdf_schema\n        True\n        \"\"\"\n        if isinstance(path, basestring):\n            return self._df(self._jreader.orc(path))\n        else:\n            raise TypeError(\"path can be only a single string\")", "language": "python"}
{"input": "Allow `fields.` prefix in placeholder to override built in replacements like \"slug\" and \"year\" with values from fields of the same name.", "output": "function getExplicitFieldReplacement(key, data) {\n  if (!key.startsWith(FIELD_PREFIX)) {\n    return;\n  }\n  const fieldName = key.substring(FIELD_PREFIX.length);\n  return data.get(fieldName, '');\n}", "language": "javascript"}
{"input": "TODO(mesch): The following functions are custom. There is a standard that defines how to add functions, which should be applied here.", "output": "function(ctx) {\n    assert(this.args.length == 2);\n    var nodes = this.args[0].evaluate(ctx).nodeSetValue();\n    var delim = this.args[1].evaluate(ctx).stringValue();\n    var ret = '';\n    for (var i = 0; i < nodes.length; ++i) {\n      if (ret) {\n        ret += delim;\n      }\n      ret += xmlValue(nodes[i]);\n    }\n    return new StringValue(ret);\n  }", "language": "javascript"}
{"input": "Dummy vars for restore to work when not using TPU codepath.", "output": "def create_dummy_vars():\n  \"\"\"Dummy vars for restore to work when not using TPU codepath.\"\"\"\n  var_names = set([v.name for v in tf.global_variables()])\n  if \"losses_avg/problem_0/total_loss:0\" in var_names:\n    return\n  with tf.variable_scope(\"losses_avg\"):\n    with tf.variable_scope(\"problem_0\"):\n      for var_name in [\"total\", \"extra\", \"training\"]:\n        tf.get_variable(\n            \"%s_loss\" % var_name, initializer=100.0, trainable=False)\n  with tf.variable_scope(\"train_stats\"):\n    tf.get_variable(\"problem_0_steps\", initializer=0, trainable=False)", "language": "python"}
{"input": "A policy and value net function.", "output": "def policy_and_value_net(rng_key,\n                         batch_observations_shape,\n                         num_actions,\n                         bottom_layers=None):\n  \"\"\"A policy and value net function.\"\"\"\n\n  # Layers.\n  cur_layers = []\n  if bottom_layers is not None:\n    cur_layers.extend(bottom_layers)\n\n  # Now, with the current logits, one head computes action probabilities and the\n  # other computes the value function.\n  # NOTE: The LogSoftmax instead of the Softmax because of numerical stability.\n  cur_layers.extend([layers.Branch(), layers.Parallel(\n      layers.Serial(layers.Dense(num_actions), layers.LogSoftmax()),\n      layers.Dense(1)\n  )])\n  net = layers.Serial(*cur_layers)\n  return net.initialize(batch_observations_shape, rng_key), net", "language": "python"}
{"input": "return the results for the rows", "output": "def wrap_results_for_axis(self):\n        \"\"\" return the results for the rows \"\"\"\n\n        results = self.results\n        result = self.obj._constructor(data=results)\n\n        if not isinstance(results[0], ABCSeries):\n            try:\n                result.index = self.res_columns\n            except ValueError:\n                pass\n\n        try:\n            result.columns = self.res_index\n        except ValueError:\n            pass\n\n        return result", "language": "python"}
{"input": "Initialize the weights.", "output": "def init_weights(self, module):\n        \"\"\" Initialize the weights.\n        \"\"\"\n        if isinstance(module, (nn.Linear, nn.Embedding)):\n            # Slightly different from the TF version which uses truncated_normal for initialization\n            # cf https://github.com/pytorch/pytorch/pull/5617\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n        elif isinstance(module, LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        if isinstance(module, nn.Linear) and module.bias is not None:\n            module.bias.data.zero_()", "language": "python"}
{"input": "Gets next line of random_file and starts over when reaching end of file", "output": "def get_next_line(self):\n        \"\"\" Gets next line of random_file and starts over when reaching end of file\"\"\"\n        try:\n            line = next(self.random_file).strip()\n            #keep track of which document we are currently looking at to later avoid having the same doc as t1\n            if line == \"\":\n                self.current_random_doc = self.current_random_doc + 1\n                line = next(self.random_file).strip()\n        except StopIteration:\n            self.random_file.close()\n            self.random_file = open(self.corpus_path, \"r\", encoding=self.encoding)\n            line = next(self.random_file).strip()\n        return line", "language": "python"}
{"input": "Return what this distribution's standard .egg filename should be", "output": "def egg_name(self):\n        \"\"\"Return what this distribution's standard .egg filename should be\"\"\"\n        filename = \"%s-%s-py%s\" % (\n            to_filename(self.project_name), to_filename(self.version),\n            self.py_version or PY_MAJOR\n        )\n\n        if self.platform:\n            filename += '-' + self.platform\n        return filename", "language": "python"}
{"input": "Encode a summary to JSON\n\n@param {Summary}\n@return {Object}", "output": "function encodeSummary(summary) {\n    var file = summary.getFile();\n    var parts = summary.getParts();\n\n    return {\n        file: encodeFile(file),\n        parts: parts.map(encodeSummaryPart).toJS()\n    };\n}", "language": "javascript"}
{"input": "Convert data based on dtype conventions, issuing deprecation warnings\n    or errors where appropriate.\n\n    Parameters\n    ----------\n    data : np.ndarray or pd.Index\n    copy : bool\n\n    Returns\n    -------\n    data : np.ndarray or pd.Index\n    copy : bool\n\n    Raises\n    ------\n    TypeError : PeriodDType data is passed", "output": "def maybe_convert_dtype(data, copy):\n    \"\"\"\n    Convert data based on dtype conventions, issuing deprecation warnings\n    or errors where appropriate.\n\n    Parameters\n    ----------\n    data : np.ndarray or pd.Index\n    copy : bool\n\n    Returns\n    -------\n    data : np.ndarray or pd.Index\n    copy : bool\n\n    Raises\n    ------\n    TypeError : PeriodDType data is passed\n    \"\"\"\n    if is_float_dtype(data):\n        # Note: we must cast to datetime64[ns] here in order to treat these\n        #  as wall-times instead of UTC timestamps.\n        data = data.astype(_NS_DTYPE)\n        copy = False\n        # TODO: deprecate this behavior to instead treat symmetrically\n        #  with integer dtypes.  See discussion in GH#23675\n\n    elif is_timedelta64_dtype(data):\n        warnings.warn(\"Passing timedelta64-dtype data is deprecated, will \"\n                      \"raise a TypeError in a future version\",\n                      FutureWarning, stacklevel=5)\n        data = data.view(_NS_DTYPE)\n\n    elif is_period_dtype(data):\n        # Note: without explicitly raising here, PeriodIndex\n        #  test_setops.test_join_does_not_recur fails\n        raise TypeError(\"Passing PeriodDtype data is invalid.  \"\n                        \"Use `data.to_timestamp()` instead\")\n\n    elif is_categorical_dtype(data):\n        # GH#18664 preserve tz in going DTI->Categorical->DTI\n        # TODO: cases where we need to do another pass through this func,\n        #  e.g. the categories are timedelta64s\n        data = data.categories.take(data.codes, fill_value=NaT)._values\n        copy = False\n\n    elif is_extension_type(data) and not is_datetime64tz_dtype(data):\n        # Includes categorical\n        # TODO: We have no tests for these\n        data = np.array(data, dtype=np.object_)\n        copy = False\n\n    return data, copy", "language": "python"}
{"input": "### Delete User\nMake the call to the Model layer\n@param {Object} options", "output": "function deleteUser(options) {\n            return models.Base.transaction((t) => {\n                options.transacting = t;\n\n                return Promise.all([\n                    models.Accesstoken.destroyByUser(options),\n                    models.Refreshtoken.destroyByUser(options),\n                    models.Post.destroyByAuthor(options)\n                ]).then(() => {\n                    return models.User.destroy(options);\n                }).return(null);\n            }).catch((err) => {\n                return Promise.reject(new common.errors.NoPermissionError({\n                    err: err\n                }));\n            });\n        }", "language": "javascript"}
{"input": "Removes unnecessary whitespace from an HTML document:\n- if the text between two adjacent HTML tags consists of whitespace only, the whole text is removed\n- otherwise, any sequence of whitespace in the text is reduced to a single blank\n- inside a <pre> tag, whitespace is preserved\n\nWhitespace inside an element tag is not touched (although it could be normalized as well)\n@param {string} content raw HTML file\n@returns {string} HTML file with normalized whitespace", "output": "function normalizeWhitespace(content) {\n\tvar compressed = '',\n\t\tpreformatted = 0,\n\t\tp = 0, m, text;\n\n\tREGEXP_TAG.lastIndex = 0;\n\twhile ( (m = REGEXP_TAG.exec(content)) ) {\n\t\tif ( m.index > p ) {\n\t\t\ttext = content.slice(p, m.index);\n\t\t\tif ( preformatted ) {\n\t\t\t\tcompressed += text;\n\t\t\t\t// debug('  \"' + text + '\" (preformatted)');\n\t\t\t} else {\n\t\t\t\ttext = text.replace(/\\s+/g,' ');\n\t\t\t\tif ( text.trim() ) {\n\t\t\t\t\tcompressed += text;\n\t\t\t\t}\n\t\t\t\t// debug('  \"' + text + '\" (trimmed)');\n\t\t\t}\n\t\t}\n\n\t\tcompressed += m[0];\n\t\t// debug('  \"' + m[0] + '\" (tag)');\n\t\tp = m.index + m[0].length;\n\n\t\tif ( /^pre$/i.test(m[1]) ) {\n\t\t\tpreformatted++;\n\t\t} else if ( /^\\/pre$/i.test(m[1]) && preformatted ) {\n\t\t\tpreformatted--;\n\t\t}\n\n\t}\n\n\tif ( content.length > p ) {\n\t\ttext = content.slice(p, content.length);\n\t\tif ( preformatted ) {\n\t\t\tcompressed += text;\n\t\t\t// debug('  \"' + text + '\" (preformatted)');\n\t\t} else {\n\t\t\ttext = text.replace(/\\s+/g,' ');\n\t\t\tif ( text.trim() ) {\n\t\t\t\tcompressed += text;\n\t\t\t}\n\t\t\t// debug('  \"' + text + '\" (trimmed)');\n\t\t}\n\t}\n\n\treturn compressed;\n}", "language": "javascript"}
{"input": "Gets the function which encloses a given reference.\nThis supports only FunctionDeclaration.\n\n@param {eslint-scope.Reference} reference - A reference to get.\n@returns {ASTNode|null} The function node or null.", "output": "function getEncloseFunctionDeclaration(reference) {\n    let node = reference.identifier;\n\n    while (node) {\n        if (node.type === \"FunctionDeclaration\") {\n            return node.id ? node : null;\n        }\n\n        node = node.parent;\n    }\n\n    return null;\n}", "language": "javascript"}
{"input": "Gets the arguments to a function in an array\n@param   {object} args - the arguments object\n@returns {Array}   - array of actual arguments", "output": "function getFunctionArgs(args) {\n        if (args.length > 2) {\n            var fnArgs = new Array(args.length - 2),\n                i;\n            for (i = 2; i < args.length; ++i) {\n                fnArgs[i - 2] = args[i];\n            }\n            return fnArgs;\n        }\n        return [];\n    }", "language": "javascript"}
{"input": "check if loss is reduction", "output": "def on_train_begin(self, **kwargs):\n        \"check if loss is reduction\"\n        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n             warn(\"For better gradients consider 'reduction=sum'\")", "language": "python"}
{"input": "Check whether a given node can connect the next line if the next line is unreliable.\n@param {Node} node A statement node to check.\n@returns {boolean} `true` if the node can connect the next line.", "output": "function maybeAsiHazardAfter(node) {\n            const t = node.type;\n\n            if (t === \"DoWhileStatement\" ||\n                t === \"BreakStatement\" ||\n                t === \"ContinueStatement\" ||\n                t === \"DebuggerStatement\" ||\n                t === \"ImportDeclaration\" ||\n                t === \"ExportAllDeclaration\"\n            ) {\n                return false;\n            }\n            if (t === \"ReturnStatement\") {\n                return Boolean(node.argument);\n            }\n            if (t === \"ExportNamedDeclaration\") {\n                return Boolean(node.declaration);\n            }\n            if (isEndOfArrowBlock(sourceCode.getLastToken(node, 1))) {\n                return false;\n            }\n\n            return true;\n        }", "language": "javascript"}
{"input": "Set the amount of time to wait for a page load to complete\n           before throwing an error.\n\n        :Args:\n         - time_to_wait: The amount of time to wait\n\n        :Usage:\n            ::\n\n                driver.set_page_load_timeout(30)", "output": "def set_page_load_timeout(self, time_to_wait):\n        \"\"\"\n        Set the amount of time to wait for a page load to complete\n           before throwing an error.\n\n        :Args:\n         - time_to_wait: The amount of time to wait\n\n        :Usage:\n            ::\n\n                driver.set_page_load_timeout(30)\n        \"\"\"\n        try:\n            self.execute(Command.SET_TIMEOUTS, {\n                'pageLoad': int(float(time_to_wait) * 1000)})\n        except WebDriverException:\n            self.execute(Command.SET_TIMEOUTS, {\n                'ms': float(time_to_wait) * 1000,\n                'type': 'page load'})", "language": "python"}
{"input": "Embed x of type int64 into dense vectors, reducing to max 4 dimensions.", "output": "def embedding(x,\n              vocab_size,\n              dense_size,\n              name=None,\n              reuse=None,\n              multiplier=1.0,\n              symbol_dropout_rate=0.0,\n              embedding_var=None,\n              dtype=tf.float32):\n  \"\"\"Embed x of type int64 into dense vectors, reducing to max 4 dimensions.\"\"\"\n  with tf.variable_scope(\n      name, default_name=\"embedding\", values=[x], reuse=reuse, dtype=dtype):\n    if embedding_var is None:\n      embedding_var = tf.get_variable(\"kernel\", [vocab_size, dense_size])\n    # On the backwards pass, we want to convert the gradient from\n    # an indexed-slices to a regular tensor before sending it back to the\n    # parameter server. This avoids excess computation on the parameter server.\n    if not tf.executing_eagerly():\n      embedding_var = convert_gradient_to_tensor(embedding_var)\n    x = dropout_no_scaling(x, 1.0 - symbol_dropout_rate)\n    emb_x = gather(embedding_var, x, dtype)\n    if multiplier != 1.0:\n      emb_x *= multiplier\n    static_shape = emb_x.shape.as_list()\n    if len(static_shape) < 5:\n      return emb_x\n    assert len(static_shape) == 5\n    # If we had an extra channel dimension, assume it's 1, i.e. shape[3] == 1.\n    return tf.squeeze(emb_x, 3)", "language": "python"}
{"input": "Scaled dot-product attention. One head. One spatial dimension.\n\n  Args:\n    q: a Tensor with shape [batch, length_q, depth_k]\n    k: a Tensor with shape [batch, length_kv, depth_k]\n    v: a Tensor with shape [batch, length_kv, depth_v]\n    bias: optional Tensor broadcastable to [batch, length_q, length_kv]\n    name: an optional string\n\n  Returns:\n    A Tensor.", "output": "def scaled_dot_product_attention_simple(q, k, v, bias, name=None):\n  \"\"\"Scaled dot-product attention. One head. One spatial dimension.\n\n  Args:\n    q: a Tensor with shape [batch, length_q, depth_k]\n    k: a Tensor with shape [batch, length_kv, depth_k]\n    v: a Tensor with shape [batch, length_kv, depth_v]\n    bias: optional Tensor broadcastable to [batch, length_q, length_kv]\n    name: an optional string\n\n  Returns:\n    A Tensor.\n  \"\"\"\n  with tf.variable_scope(\n      name, default_name=\"scaled_dot_product_attention_simple\"):\n    scalar = tf.rsqrt(tf.to_float(common_layers.shape_list(q)[2]))\n    logits = tf.matmul(q * scalar, k, transpose_b=True)\n    if bias is not None:\n      logits += bias\n    weights = tf.nn.softmax(logits, name=\"attention_weights\")\n    if common_layers.should_generate_summaries():\n      tf.summary.image(\n          \"attention\", tf.expand_dims(tf.pow(weights, 0.2), 3), max_outputs=1)\n    return tf.matmul(weights, v)", "language": "python"}
{"input": "Get number of features.\n\n        Returns\n        -------\n        num_feature : int\n            The number of features.", "output": "def num_feature(self):\n        \"\"\"Get number of features.\n\n        Returns\n        -------\n        num_feature : int\n            The number of features.\n        \"\"\"\n        out_num_feature = ctypes.c_int(0)\n        _safe_call(_LIB.LGBM_BoosterGetNumFeature(\n            self.handle,\n            ctypes.byref(out_num_feature)))\n        return out_num_feature.value", "language": "python"}
{"input": "Determines whether the current FunctionExpression node has a name that would be\ninferred from context in a conforming ES6 environment.\n@param {ASTNode} node - A node to check.\n@returns {boolean} True if the node would have a name assigned automatically.", "output": "function hasInferredName(node) {\n            const parent = node.parent;\n\n            return isObjectOrClassMethod(node) ||\n                (parent.type === \"VariableDeclarator\" && parent.id.type === \"Identifier\" && parent.init === node) ||\n                (parent.type === \"Property\" && parent.value === node) ||\n                (parent.type === \"AssignmentExpression\" && parent.left.type === \"Identifier\" && parent.right === node) ||\n                (parent.type === \"ExportDefaultDeclaration\" && parent.declaration === node) ||\n                (parent.type === \"AssignmentPattern\" && parent.right === node);\n        }", "language": "javascript"}
{"input": "Creates a :class:`WindowSpec` with the partitioning defined.", "output": "def partitionBy(*cols):\n        \"\"\"\n        Creates a :class:`WindowSpec` with the partitioning defined.\n        \"\"\"\n        sc = SparkContext._active_spark_context\n        jspec = sc._jvm.org.apache.spark.sql.expressions.Window.partitionBy(_to_java_cols(cols))\n        return WindowSpec(jspec)", "language": "python"}
{"input": "Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).", "output": "def log_uniform(low, high, size:Optional[List[int]]=None)->FloatOrTensor:\n    \"Draw 1 or shape=`size` random floats from uniform dist: min=log(`low`), max=log(`high`).\"\n    res = uniform(log(low), log(high), size)\n    return exp(res) if size is None else res.exp_()", "language": "python"}
{"input": "Track textures used by material components, so that they can be safely\ndisposed when no longer in use. Textures must be registered here, and not\nthrough registerMaterial(), because textures may not be attached at the\ntime the material is registered.\n\n@param {Event} e", "output": "function (e) {\n    if (!this.textureCounts[e.detail.texture.uuid]) {\n      this.textureCounts[e.detail.texture.uuid] = 0;\n    }\n    this.textureCounts[e.detail.texture.uuid]++;\n  }", "language": "javascript"}
